id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1961195096,"> Hi @jesseengel
> 
> Where can we obtain the `model.ckpt-200000`?
> 
> I used the link http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar and these is the content of that .tar:
> 
> ```
> -rw-r----- 1 ubuntu ubuntu 986763532 Apr  3  2017 model.ckpt-200000.data-00000-of-00001
> -rw-r----- 1 ubuntu ubuntu     63671 Apr  3  2017 model.ckpt-200000.index
> -rw-r----- 1 ubuntu ubuntu   7060787 Apr  3  2017 model.ckpt-200000.meta
> ```
> 
> <img alt=""image"" width=""838"" src=""https://private-user-images.githubusercontent.com/23288462/306682803-77e8906c-8718-4fa5-aee5-974d102049a6.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MDg2ODk0MzEsIm5iZiI6MTcwODY4OTEzMSwicGF0aCI6Ii8yMzI4ODQ2Mi8zMDY2ODI4MDMtNzdlODkwNmMtODcxOC00ZmE1LWFlZTUtOTc0ZDEwMjA0OWE2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAyMjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMjIzVDExNTIxMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI5YTY1MzQyNzA5ZDdiNmJjY2EyOWFhNTllNmY4NTFjNWM1NDNkYjM2MzQ4ZTE3MWUxNWMwYjc3NjA2MGZhMGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.2YQ8nl28x3RN9VfIG99kEcZeS30slfa2GZtJa2oABJI"">



> I tried converting it using `tensorflow==1.15.0`and the script:
> 
> ```
> import tensorflow_text
> import tensorflow as tf
> 
> tf.compat.v1.disable_eager_execution()
> 
> # Now the rest of your code
> saver = tf.compat.v1.train.import_meta_graph('model.ckpt-200000.meta')
> 
> # Restore the weights
> saver.restore(sess, 'model.ckpt-200000')
> ```
> 
> I can't go over this error:
> 
> ```
> Traceback (most recent call last):
>   File ""converter.py"", line 9, in <module>
>     saver = tf.compat.v1.train.import_meta_graph('model.ckpt-200000.meta')
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph
>     **kwargs)[0]
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements
>     **kwargs))
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements
>     return_elements=return_elements)
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
>     return func(*args, **kwargs)
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def
>     producer_op_list=producer_op_list)
>   File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal
>     graph._c_graph, serialized, options)  # pylint: disable=protected-access
> tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'SSTableReader' in binary running on locally. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
> ```

@cghawthorne @adarob @iansimon Can you give my some pointers on how to get a working checkpoint for `wavenet-ckpt.tar`?",hi obtain used link content image tried converting script import import rest code saver restore sess ca go error recent call last file line module saver file line file line file line file line return file line file line type registered binary running locally make sure kernel registered binary running process note loading saved graph used done graph lazily registered module first give get working,issue,positive,positive,neutral,neutral,positive,positive
1956998846,"I tried converting it using `tensorflow==1.15.0`and the script:

```
import tensorflow_text
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

# Now the rest of your code
saver = tf.compat.v1.train.import_meta_graph('model.ckpt-200000.meta')

# Restore the weights
saver.restore(sess, 'model.ckpt-200000')
```

I can't go over this error:

```
Traceback (most recent call last):
  File ""converter.py"", line 9, in <module>
    saver = tf.compat.v1.train.import_meta_graph('model.ckpt-200000.meta')
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph
    **kwargs)[0]
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements
    return_elements=return_elements)
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def
    producer_op_list=producer_op_list)
  File ""/home/ubuntu/vertate-nsynth/virtual-trans/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal
    graph._c_graph, serialized, options)  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'SSTableReader' in binary running on locally. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
```",tried converting script import import rest code saver restore sess ca go error recent call last file line module saver file line file line file line file line return file line file line type registered binary running locally make sure kernel registered binary running process note loading saved graph used done graph lazily registered module first,issue,positive,positive,neutral,neutral,positive,positive
1956993358,"Hi @jesseengel

Where can we obtain the `model.ckpt-200000`?

I used the link http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar and these is the content of that .tar:

```
-rw-r----- 1 ubuntu ubuntu 986763532 Apr  3  2017 model.ckpt-200000.data-00000-of-00001
-rw-r----- 1 ubuntu ubuntu     63671 Apr  3  2017 model.ckpt-200000.index
-rw-r----- 1 ubuntu ubuntu   7060787 Apr  3  2017 model.ckpt-200000.meta
``` 

<img width=""838"" alt=""image"" src=""https://github.com/magenta/magenta/assets/23288462/77e8906c-8718-4fa5-aee5-974d102049a6"">

",hi obtain used link content image,issue,negative,neutral,neutral,neutral,neutral,neutral
1937608142,"> I have managed to get Magenta running on my M2 by shoehorning dependencies together. Unfortunately there is a bug in Apple's tensorflow GPU acceleration (reported and acknowledge by Apple, see [forum post](https://developer.apple.com/forums//thread/723816?answerId=743019022#743019022)) which breaks generation but not training, very conveniently I may add.
> 
> I have a virtualenv with gpu acceleration that I'm using for training, and one without acceleration that I'm using for generation. It's not the best but it works for me. I have shared these virtualenvs for you and any others that may find this comment on a [gist](https://gist.github.com/xstasi/30123f5976abb5b6c90114b92986a155). The files are to be used as such:
> 
> ```
> pip install -r requirements-magenta-gpu-apple-m1-m2-metal.txt --no-deps
> ```

Hi @xstasi 
I'm trying to make magenta work in my M2 mac, but using your list throws many errors regarding the python version. Any tips? 
Thx in advance",get magenta running together unfortunately bug apple acceleration acknowledge apple see forum post generation training conveniently may add acceleration training one without acceleration generation best work may find comment gist used pip install hi trying make magenta work mac list many regarding python version advance,issue,negative,positive,positive,positive,positive,positive
1925507949,"Not seeing support for Apple silicon. I have an M2 Max was able to get TensorFlow working without issue (w/Metal).
""pip install magenta"" is not working with Python 3.11.7; C compile issues with numba and a couple other packages.

I would also like to get this working.",seeing support apple silicon able get working without issue pip install magenta working python compile couple would also like get working,issue,positive,positive,positive,positive,positive,positive
1879390387,"I had the same errors too,  I have tried to install Magenta for a whole day. Thanks for the tips I finally succeeded in installing Magenta. I wish my comment could also help others. My configuration is Windows 11, python version is 3.9. 
1. git clone https://github.com/magenta/magenta.git
2. Install these packages first 
    pip install wheel==0.42.0
    pip install numba==0.57.1 (I tried 0.58.1, but numpy version would have conflicts)
    pip install python-rtmidi==1.5.8
3. Set the same version in setup.py as Freud16 said 
4.  pip install D:\coda\envs\CC\magenta (your file path)",tried install magenta whole day thanks finally magenta wish comment could also help configuration python version git clone install first pip install pip install tried version would pip install set version said pip install file path,issue,positive,positive,positive,positive,positive,positive
1875764162,"This is due to librosa later versions forcing you to name your parameters.

A workaround is to edit `/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py`

And comment out this line:

```
def melspectrogram(
    #*,
    y: Optional[np.ndarray] = None,
```",due later forcing name edit comment line optional none,issue,negative,negative,neutral,neutral,negative,negative
1875751018,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/magenta/magenta/pull/2086/checks?check_run_id=20134847643) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement view invocation check information date status view section bottom pull request,issue,positive,positive,positive,positive,positive,positive
1875261717,"here's how you download it : first you registering,then wait for the email that they open the permissions for you.
then you download FileZilla,just the most basic one would work,then you Type in the url he gave you,your email when you registeringed and the password you set,wait a sec ,you can download",first wait open basic one would work type gave password set wait sec,issue,negative,positive,neutral,neutral,positive,positive
1873027637,"Clone from repository and change `'python-rtmidi == 1.1.2',` in `setup.py` to `'python-rt-midi==1.5.8'` prior to installing. That worked for me. 

Or just [use this repo](https://github.com/olaviinha/magenta). I don't actively maintain it but every now and then I fix Colab issues in there as they come along, so still more actively maintained than this repo lol.",clone repository change prior worked use actively maintain every fix come along still actively,issue,positive,negative,neutral,neutral,negative,negative
1837273769,"Hi,

Try these, worked for me:
`pip install keras==2.10.0

pip install tensorflow==2.10.0

pip install tensorflow-probability==0.18.0`",hi try worked pip install pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1826052218,"I found a really hacky way to run magenta in colab. It also works for Ubuntu and WSL with nearly the same commands. The basis of it is to install python3.7, then create a virtual env inside there. For colab, you then use the xterm extension (or just open the terminal if you have colab-pro) to pop up a terminal and interact with your python 3.7
 
(https://github.com/InfuseAI/colab-xterm)

Here is a screenshot: 

![image](https://github.com/magenta/magenta/assets/26504/77304052-df99-499e-8942-3ec33cd1bea6)

Here is a colab: 

https://colab.research.google.com/drive/1gDcjWFS2EgXHJS2lFo8NJQV1f8FDjwbU?usp=sharing

These are the commands - you can run these on a regular ubuntu:

```
# https://stackoverflow.com/questions/52816156/how-to-create-virtual-environment-for-python-3-7-0
sudo add-apt-repository ppa:deadsnakes/ppa -y
sudo apt-get install -y  build-essential libasound2-dev libjack-dev portaudio19-dev python3.7 python3.7-venv python3.7-dev
python3.7 -m venv ~/Python/mag37
source ~/Python/mag37/bin/activate
pip install magenta
pip install google.colab # if on colab only I think
# https://stackoverflow.com/questions/41415629/importerror-no-module-named-tensorflow-python
pip uninstall tensorflow
pip install tensorflow

```
I know I know... GPU? no idea! Running notebook cells? Didn't try it... 
",found really hacky way run magenta also work nearly basis install create virtual inside use extension open terminal pop terminal interact python image run regular install python python source pip install magenta pip install think pip pip install know know idea running notebook try,issue,negative,positive,neutral,neutral,positive,positive
1823806893,"@kachraf , if you happen to still have it working, would you mind sharing what python version and a pip freeze?

I know I got it working once a few years ago but now, it seems to be in an impossible state of dependency conflicts.
Thanks!

",happen still working would mind python version pip freeze know got working ago impossible state dependency thanks,issue,negative,negative,negative,negative,negative,negative
1811966127,"Note that the tfrecord is generated correctly. In my case, the above symptoms occurred when the contents of the tfrecord was empty.",note correctly case content empty,issue,negative,negative,neutral,neutral,negative,negative
1811738082,"> > Did you solve this issue? I also run into the same problem as you did and can't fix it.
> 
> No, I think the problem is with the Tensorflow or other modules installed in the Google colaboratory.

This is likely the issue, CoLab updated their python version awhile ago and may have done again recently, this causes a lot of old ML packages and dependencies to no longer work, I had the same issue trying to use Jukebox awhile back in CoLab. Really annoying they don't allow for multiple versions of python or virtual environments easily.

Just checked stack overflow and looks like there are some people who have reported luck manually downgrading python version, haven't been able to accomplish it personally though.

Link to most promising thread: https://stackoverflow.com/questions/60775160/install-python-3-8-kernel-in-google-colaboratory/71511943#71511943",solve issue also run problem ca fix think problem likely issue python version awhile ago may done recently lot old longer work issue trying use jukebox awhile back really annoying allow multiple python virtual easily checked stack overflow like people luck manually python version able accomplish personally though link promising thread,issue,positive,positive,neutral,neutral,positive,positive
1811721457,"I installed python 3.7 and that solved the issue for me. I couldn't get the colab notebooks to work, but I was able to successfully install the magenta package. I installed pyenv on my mac and got this working.",python issue could get work able successfully install magenta package mac got working,issue,negative,positive,positive,positive,positive,positive
1811657172,"> Did you solve this issue? I also run into the same problem as you did and can't fix it.

No, I think the problem is with the Tensorflow or other modules installed in the Google colaboratory.",solve issue also run problem ca fix think problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1806759582,Hey! Could you share your solution as to how you got this error resolved?,hey could share solution got error resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
1806758894,+1 Same here as well. I have the same problem as well. None of the suggestions I found online worked for me. ,well problem well none found worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1806656391,Did you solve this issue? I also run into the same problem as you did and can't fix it.,solve issue also run problem ca fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1771376568,"I forked the project to [https://github.com/OmikronApex/magenta/](https://github.com/OmikronApex/magenta/) and manged to find a workaround for the problem.
I implemented a trim_steps_from_start function in the PolyphonicSequence-Class in polyphony_lib.py and call it right after the generation in polyphony_sequence_generator.py

This way the midi_primer is removed after generation and is no longer part of the output files.",forked project find problem function call right generation way removed generation longer part output,issue,negative,positive,positive,positive,positive,positive
1771041872,"Digging this back up, since I'm trying to get rid of this bug.

It seems the flag does indeed work, but there is an initial injection of the primer that the flag does not affect. If you set inject_primer_during_generation to True, you'll receive an output that contains the primer twice.

The initial injection of the primer seems to happen way before the flag is processed.",digging back since trying get rid bug flag indeed work initial injection primer flag affect set true receive output primer twice initial injection primer happen way flag,issue,negative,positive,neutral,neutral,positive,positive
1768516290,"Thank you so much I got it installed. Have you made any of your works open anywhere so that I can go through it?
Thanks again,
~Shakthivel.",thank much got made work open anywhere go thanks,issue,positive,positive,positive,positive,positive,positive
1764319970,"I managed to get Magenta working again in Colab by using Conda.

First installing conda and creating a new virtual environment running Python 3.8:

!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
!chmod +x Miniconda3-latest-Linux-x86_64.sh
!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local/
!conda update conda
!conda create -n magenta python=3.8

Then using pip to install magenta in the virtual environment:
%%shell
eval ""$(conda shell.bash hook)""
conda activate magenta
pip install magenta

Afterwards I'm able to use the magenta modules (for example Polyphony_RNN):

%%shell
eval ""$(conda shell.bash hook)""
conda activate magenta
polyphony_rnn_generate...

It seems to work quite well, but you have to activate the environment by adding

%%shell
eval ""$(conda shell.bash hook)""
conda activate magenta

everytime before using a magenta command.",get magenta working first new virtual environment running python update create magenta pip install magenta virtual environment shell hook activate magenta pip install magenta afterwards able use magenta example shell hook activate magenta work quite well activate environment shell hook activate magenta magenta command,issue,positive,positive,positive,positive,positive,positive
1722472445,"Hi
I couldn't install magenta successfully.
Do you have any suggestions?",hi could install magenta successfully,issue,negative,positive,positive,positive,positive,positive
1694486395,"Per this thread on stackoverflow:
https://stackoverflow.com/questions/73918403/why-is-it-showing-guvectorize-missing-1-required-positional-argument-signat

pip install resampy==0.3.1",per thread pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1692858845,"pying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_destroyer_saw_F.wav to audio/KOAN_SOUND_bass_destroyer_saw_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_wet_filter_02_F.wav to audio/KOAN_SOUND_bass_wet_filter_02_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_02_Eb.wav to audio/KOAN_SOUND_bass_pitch_punch_02_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_dirt_hit_02_Eb.wav to audio/KOAN_SOUND_bass_dirt_hit_02_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_100_bass_loop_tech_bounce_02_F.wav to audio/KOAN_SOUND_100_bass_loop_tech_bounce_02_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_wet_n_wide_03_Eb.wav to audio/KOAN_SOUND_bass_wet_n_wide_03_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_03_Eb.wav to audio/KOAN_SOUND_bass_pitch_punch_03_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_08_F.wav to audio/KOAN_SOUND_bass_pitch_punch_08_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_86_bass_loop_square_fuzz_F.wav to audio/KOAN_SOUND_86_bass_loop_square_fuzz_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_07_F.wav to audio/KOAN_SOUND_bass_pitch_punch_07_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_wet_n_wide_04_F.wav to audio/KOAN_SOUND_bass_wet_n_wide_04_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_wet_filter_01_Eb.wav to audio/KOAN_SOUND_bass_wet_filter_01_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_neuro_stab_07_F.wav to audio/KOAN_SOUND_bass_neuro_stab_07_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_04_F.wav to audio/KOAN_SOUND_bass_pitch_punch_04_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_verb_reese_F.wav to audio/KOAN_SOUND_bass_verb_reese_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_neuro_stab_04_Eb.wav to audio/KOAN_SOUND_bass_neuro_stab_04_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_noisy_reese_01_F.wav to audio/KOAN_SOUND_bass_noisy_reese_01_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_square_fuzz_F.wav to audio/KOAN_SOUND_bass_square_fuzz_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_06_F.wav to audio/KOAN_SOUND_bass_pitch_punch_06_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_dirt_hit_01_Eb.wav to audio/KOAN_SOUND_bass_dirt_hit_01_Eb.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_86_bass_loop_chunk_chop_01_F.wav to audio/KOAN_SOUND_86_bass_loop_chunk_chop_01_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_thick_saw_03_F.wav to audio/KOAN_SOUND_bass_thick_saw_03_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_86_bass_loop_mid_square_F.wav to audio/KOAN_SOUND_86_bass_loop_mid_square_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_thick_saw_05_F.wav to audio/KOAN_SOUND_bass_thick_saw_05_F.wav
Copying /content/gdrive/MyDrive/allshiz/Just bass/KOAN_SOUND_bass_pitch_punch_01_Eb.wav to audio/KOAN_SOUND_bass_pitch_punch_01_Eb.wav
Preparing new dataset from `audio/`

Creating dataset...
This usually takes around 2-3 minutes for each minute of audio
(10 minutes of training audio -> 20-30 minutes)

Training...
2023-08-25 06:51:20.227175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia
2023-08-25 06:51:20.227309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia
2023-08-25 06:51:20.227330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Traceback (most recent call last):
  File ""/usr/local/bin/ddsp_run"", line 5, in <module>
    from ddsp.training.ddsp_run import console_entry_point
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/__init__.py"", line 21, in <module>
    from ddsp import losses
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/losses.py"", line 23, in <module>
    from ddsp import spectral_ops
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/spectral_ops.py"", line 25, in <module>
    import tensorflow_probability as tfp
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/__init__.py"", line 20, in <module>
    from tensorflow_probability import substrates
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/__init__.py"", line 17, in <module>
    from tensorflow_probability.python.internal import all_util
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py"", line 138, in <module>
    dir(globals()[pkg_name])  # Forces loading the package from its lazy loader.
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py"", line 57, in __dir__
    module = self._load()
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py"", line 37, in _load
    self._on_first_access()
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py"", line 59, in _validate_tf_environment
    raise ImportError(
ImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.12; Detected an installation of version 2.11.1. Please upgrade TensorFlow to proceed.

Exporting model...
2023-08-25 06:51:24.279297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia
2023-08-25 06:51:24.279423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia
2023-08-25 06:51:24.279448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Traceback (most recent call last):
  File ""/usr/local/bin/ddsp_export"", line 5, in <module>
    from ddsp.training.ddsp_export import console_entry_point
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/__init__.py"", line 21, in <module>
    from ddsp import losses
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/losses.py"", line 23, in <module>
    from ddsp import spectral_ops
  File ""/usr/local/lib/python3.10/dist-packages/ddsp/spectral_ops.py"", line 25, in <module>
    import tensorflow_probability as tfp
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/__init__.py"", line 20, in <module>
    from tensorflow_probability import substrates
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/__init__.py"", line 17, in <module>
    from tensorflow_probability.python.internal import all_util
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py"", line 138, in <module>
    dir(globals()[pkg_name])  # Forces loading the package from its lazy loader.
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py"", line 57, in __dir__
    module = self._load()
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py"", line 37, in _load
    self._on_first_access()
  File ""/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py"", line 59, in _validate_tf_environment
    raise ImportError(
ImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.12; Detected an installation of version 2.11.1. Please upgrade TensorFlow to proceed.
Export complete! Zipping /content/gdrive/MyDrive/allshiz/Just bass/ddsp-training-2023-08-24-2337/Koan to /content/gdrive/MyDrive/allshiz/Just bass/ddsp-training-2023-08-24-2337/Koan.zip
	zip warning: name not matched: ./Koan

zip error: Nothing to do! (try: zip -r Koan.zip . -i ./Koan)
Zipping Complete! Downloading... Koan.zip
You can also find your model at /content/gdrive/MyDrive/allshiz/Just bass/ddsp-training-2023-08-24-2337/Koan
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
[/usr/local/lib/python3.10/dist-packages/ipyfilechooser/filechooser.py](https://localhost:8080/#) in _on_select_click(self, _b)
    315             if self._callback is not None:
    316                 try:
--> 317                     self._callback(self)
    318                 except TypeError:
    319                     # Support previous behaviour of not passing self

3 frames
[/usr/local/lib/python3.10/dist-packages/google/colab/files.py](https://localhost:8080/#) in download(filename)
    223   if not _os.path.exists(filename):
    224     msg = 'Cannot find file: {}'.format(filename)
--> 225     raise FileNotFoundError(msg)  # pylint: disable=undefined-variable
    226 
    227   comm_manager = _IPython.get_ipython().kernel.comm_manager

FileNotFoundError: Cannot find file: /content/gdrive/MyDrive/allshiz/Just bass/ddsp-training-2023-08-24-2337/Koan.zip",new usually around minute audio training audio training could load dynamic library open object file file directory could load dynamic library open object file file directory warning would like use please make sure missing properly recent call last file line module import file line module import file line module import file line module import file line module import file line module import file line module loading package lazy loader file line module file line file line raise version probability version installation version please upgrade proceed model could load dynamic library open object file file directory could load dynamic library open object file file directory warning would like use please make sure missing properly recent call last file line module import file line module import file line module import file line module import file line module import file line module import file line module loading package lazy loader file line module file line file line raise version probability version installation version please upgrade proceed export complete zipping zip warning name zip error nothing try zip zipping complete also find model recent call last self none try self except support previous behaviour passing self find file raise find file,issue,positive,positive,neutral,neutral,positive,positive
1614283685,@iljab You can prevent this by modifying the `MAX_TICKS` variable in `convert_dir_to_note_sequences.py`. Here's a patch that makes it a command-line flag: https://github.com/magenta/magenta/compare/main...jvlmdr:magenta:oom-bug,prevent variable patch flag,issue,negative,neutral,neutral,neutral,neutral,neutral
1565288757,"> Did you end up resolving the issues? This is an issue with dependency and I've been able to solve it by updating the deps in [setup.py](https://github.com/tensorflow/magenta/blob/main/setup.py#L158-L158)
> 
> Specifically, I updated these two package versions:
> 
> ```python
>     'numba == 0.56.4',
>     'python-rtmidi == 1.4.9',
> ```
> 
> See the full file (here](https://gist.github.com/dok/dd8e10ce2677f310f6a97c83eaa3558a)

I followed the instructions but still got similar errors as before. Make sure you changed to the correct version by refering to packages you already installed. 

1. If you do not know which one you previousuly installed, download them again from https://pypi.org/ by entering the package name (eg numba). If you see multiple candidates use the one compatible with your current python version and laptop system (you can always try until find one that does not give error in step 2.). 
2. Excute pip install [path of the new package\package_name.whl]. 
3. Change version in the mentioned setup.py to be consistent with the newly downloaded ones (you can tell the new version by the naming of the package on the website).
4. Excute pip install [fiile path of downloaded github magenta]. 

This solves for me.",end issue dependency able solve specifically two package python see full file still got similar make sure correct version already know one entering package name see multiple use one compatible current python version system always try find one give error step pip install path new change version consistent newly tell new version naming package pip install path magenta,issue,negative,positive,positive,positive,positive,positive
1545944404,"> @chunchet-ng Did you make it work in the end? Thanks

Sorry, I do not proceed with this line of work.",make work end thanks sorry proceed line work,issue,negative,negative,negative,negative,negative,negative
1543717428,"I tried to install magenta on my m1 laptop so I could run the [Music Transformer colab notebook locally](https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb).

here is how i created the conda environment and installed packages:

```
conda create -n music-transformer python=3.8 -y
conda activate music-transformer
pip install tensor2tensor==1.15.7 note-seq # these are only needed for the music-transformer notebook
pip install \
    numpy==1.23 \
    tensorflow==2.13.0rc0 \
    absl-py \
    dm-sonnet \
    imageio \
    librosa \
    matplotlib \
    mido \
    mir_eval \
    note-seq \
    numba \
    Pillow \
    pretty_midi \
    pygtrie \
    python-rtmidi \
    scikit-image \
    scipy \
    six \
    sk-video \
    sox \
    tensorflow-datasets \
    tensorflow-probability \
    tf_slim \
    wheel
pip install magenta --no-dependencies
```

then i downloaded the weights so i didn't have to worry about google-cloud stuff:

```
gsutil cp ""gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt.meta
gsutil cp ""gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt.index
gsutil cp ""gs://magentadata/models/music_transformer/checkpoints/unconditional_model_16.ckpt.data-00000-of-00001
```

and this is minimal code for unconditional generation:

```python
import numpy as np
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
from magenta.models.score2perf import score2perf

class PianoPerformanceLanguageModelProblem(score2perf.Score2PerfProblem):
  @property
  def add_eos_symbol(self):
    return True
  
problem = PianoPerformanceLanguageModelProblem()

from tensor2tensor import problems
unconditional_encoders = problem.get_feature_encoders()

from tensor2tensor.utils import trainer_lib
hparams = trainer_lib.create_hparams(hparams_set='transformer_tpu')
trainer_lib.add_problem_hparams(hparams, problem)
hparams.num_hidden_layers = 16
hparams.sampling_method = 'random'

from tensor2tensor.utils import decoding
decode_hparams = decoding.decode_hparams()
decode_hparams.alpha = 0.0
decode_hparams.beam_size = 1
run_config = trainer_lib.create_run_config(hparams)

estimator = trainer_lib.create_estimator(
    'transformer', hparams, run_config,
    decode_hparams=decode_hparams)

ckpt_path = 'unconditional_model_16.ckpt'

def input_generator():
    global targets
    global decode_length
    while True:
        print('yielding', len(targets))
        yield {
            'targets': np.array([targets], dtype=np.int32),
            'decode_length': np.array(decode_length, dtype=np.int32)
        }
targets = []
decode_length = 0
input_fn = decoding.make_input_fn_from_generator(input_generator())
unconditional_samples = estimator.predict(
    input_fn, checkpoint_path=ckpt_path)
_ = next(unconditional_samples)

targets = []
decode_length = 1024
sample_ids = next(unconditional_samples)['outputs']

from tensor2tensor.data_generators import text_encoder

def decode(ids, encoder):
    ids = list(ids)
    if text_encoder.EOS_ID in ids:
        ids = ids[:ids.index(text_encoder.EOS_ID)]
    return encoder.decode(ids)

midi_filename = decode(
    sample_ids,
    encoder=unconditional_encoders['targets'])

import note_seq
unconditional_ns = note_seq.midi_file_to_note_sequence(midi_filename)

import shutil
shutil.copyfile(midi_filename, 'output.midi')
```

(i realize it's all out of order, if i move the imports around it fails!)

i got two separate errors. to fix the first one i had to edit the file `site-packages/tensorflow_addons/optimizers/discriminative_layer_training.py` on line 25 to change `from keras.utils import tf_utils` to `from keras.src.utils import tf_utils`.

then i changed `site-packages/gym/envs/registration.py` on line 572, i replaced `_kwargs = spec_.kwargs.copy()` with:

```python
    try:
        _kwargs = spec_.kwargs.copy()
    except:
        _kwargs = {}
```

in the end, my m1 generates 1024 steps in around 13 seconds. it's actually faster than a 2080 Ti for this task, where it takes around 20 seconds!",tried install magenta could run music transformer notebook locally environment create activate pip install notebook pip install pillow six wheel pip install magenta worry stuff minimal code unconditional generation python import import import class property self return true problem import import problem import estimator global global true print yield next next import decode list return decode import import realize order move around got two separate fix first one edit file line change import import line python try except end around actually faster ti task around,issue,negative,positive,neutral,neutral,positive,positive
1522876775,"> Okay, I think that worked! Did you also have the same trouble with the checkpoint file for the basic RNN after this?



> Hello, how exactly do I need to modify the code for the placeholder problem? From your conversations, I do not understand the specific solution
",think worked also trouble file basic hello exactly need modify code problem understand specific solution,issue,negative,positive,neutral,neutral,positive,positive
1519092922,"> > Hi @dok sorry for asking I'm quite new to this topic. I encounter the same issue as mentioned above, in total i have problems with wheel building in llvmlite, numba and python-rtmidi. I tried to update the versions as you have commented before but it didn't work for me. I haven't updated the setup.py though, but I don't know where to put this file since there are many setup.py. Thank you for your help, I really appreciate it!
> 
> To fix the setup.py dependencies, you shall:
> 
>     1. Clone the repo `git clone https://github.com/tensorflow/magenta.git` (or download the zip file)
> 
>     2. Fix the setup.py file as @dok suggested
> 
>     3. Run `pip install .`

I think they changed the organization name or something because now the clone link is:

`https://github.com/magenta/magenta.git`
",hi sorry quite new topic encounter issue total wheel building tried update work though know put file since many thank help really appreciate fix shall clone git clone zip file fix file run pip install think organization name something clone link,issue,positive,positive,neutral,neutral,positive,positive
1510607944,"> 



> I actually found a cause here, you'll get this error if the midi sequences don't have the same length: magenta.models.music_vae.trained_model.NoExtractedExamplesError: No examples extracted from NoteSequence: tempos Even if you pass in assert_same_length = False, the error still occurs. Here's the code I'm using generated_melody = melody_model.interpolate( start_sequence = melody_start, end_sequence =end_sequence, num_steps = 1,length=16 * bars, temperature=melody_temperature,assert_same_length = True)[0]

Thanks for the insight. I understood that the error in the model.encode() function occurs because of the incorrect input from the previous step. Can you please provide more insight on how to provide the arguments to the interpolate function more appropriately?",actually found cause get error length extracted even pas false error still code true thanks insight understood error function incorrect input previous step please provide insight provide interpolate function appropriately,issue,negative,positive,neutral,neutral,positive,positive
1506994256,"> @eisneim Can you provide more informations? Like which python version do you used, what version of each dependency package, is conda used.

Conda is used, miniforge
Python 3.10.10
Mac OS 12.4 Montery Apple M1 Pro



",provide like python version used version dependency package used used python mac o apple pro,issue,negative,neutral,neutral,neutral,neutral,neutral
1506313485,"@eisneim 
Can you provide more informations? Like which python version do you used, what version of each dependency package, is conda used.",provide like python version used version dependency package used,issue,negative,neutral,neutral,neutral,neutral,neutral
1505864982,"Yes same thing is happening to me. Used to work, within last few months it suddenly stopped.",yes thing happening used work within last suddenly stopped,issue,negative,neutral,neutral,neutral,neutral,neutral
1496767249,"Hey your notebook is broken, and so are the other NSynth notebooks. Do you know what's going on? Is there a way to get your notebook working again? Errors attached
![image](https://user-images.githubusercontent.com/109197712/229951470-f875c275-09b7-467a-87a6-60487d18f5f8.png)
![image](https://user-images.githubusercontent.com/109197712/229951580-ebfe295a-9413-4ca3-bb2f-1cd6162d4144.png)
",hey notebook broken know going way get notebook working attached image image,issue,negative,negative,negative,negative,negative,negative
1493281739,"here is my solution, manually install all requirements and lastly, install magenta without dependency
```
pip install magenta --no-dependencies
```
",solution manually install lastly install magenta without dependency pip install magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
1487641232,"Dear olavinha, I am yojibee-yamazaki who opened this issue,
Thank you for your comment.
I followed your advice and ran the code you showed. As a result, magenta was successfully installed. I tested the polyphony rnn command for learning in my own notebook and it worked.
Thank you very much for your advice. 
The result of the installation is as follows.

```
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting hmmlearn
  Downloading hmmlearn-0.2.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (217 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 217.2/217.2 KB 4.6 MB/s eta 0:00:00
Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.2.2)
Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.10.1)
Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.9/dist-packages (from hmmlearn) (1.22.4)
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)
Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.1)
Installing collected packages: hmmlearn
Successfully installed hmmlearn-0.2.8
Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease
Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]
Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease
Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]
Get:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease
Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease
Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease
Get:11 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,322 kB]
Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease
Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,065 kB]
Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,198 kB]
Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,411 kB]
Get:16 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,060 kB]
Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,143 kB]
Get:18 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,025 kB]
Get:19 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,587 kB]
Fetched 16.2 MB in 4s (4,529 kB/s)
Reading package lists... Done
Reading package lists... Done
Building dependency tree       
Reading state information... Done
python3.8 is already the newest version (3.8.10-0ubuntu1~20.04.7).
python3.8 set to manually installed.
0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.
update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 2513k  100 2513k    0     0  16.8M      0 --:--:-- --:--:-- --:--:-- 16.8M
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting pip
  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 28.1 MB/s eta 0:00:00
Collecting setuptools
  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 61.0 MB/s eta 0:00:00
Collecting wheel
  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.5/64.5 kB 6.7 MB/s eta 0:00:00
Installing collected packages: wheel, setuptools, pip
Successfully installed pip-23.0.1 setuptools-67.6.1 wheel-0.40.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting numba==0.48
  Downloading numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 27.2 MB/s eta 0:00:00
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.48) (67.6.1)
Collecting llvmlite<0.32.0,>=0.31.0dev0
  Downloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.2/20.2 MB 55.6 MB/s eta 0:00:00
Collecting numpy>=1.15
  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 57.7 MB/s eta 0:00:00
Installing collected packages: llvmlite, numpy, numba
Successfully installed llvmlite-0.31.0 numba-0.48.0 numpy-1.24.2
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting numpy==1.23
  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 76.7 MB/s eta 0:00:00
Installing collected packages: numpy
  Attempting uninstall: numpy
    Found existing installation: numpy 1.24.2
    Uninstalling numpy-1.24.2:
      Successfully uninstalled numpy-1.24.2
Successfully installed numpy-1.23.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting librosa==0.7.2
  Downloading librosa-0.7.2.tar.gz (1.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 21.0 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting audioread>=2.0.0
  Downloading audioread-3.0.0.tar.gz (377 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 377.0/377.0 kB 32.6 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (1.23.0)
Collecting scipy>=1.0.0
  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 29.8 MB/s eta 0:00:00
Collecting scikit-learn!=0.19.0,>=0.14.0
  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 66.1 MB/s eta 0:00:00
Collecting joblib>=0.12
  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 20.5 MB/s eta 0:00:00
Collecting decorator>=3.0.0
  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting six>=1.3
  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting resampy>=0.2.2
  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 62.8 MB/s eta 0:00:00
Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (0.48.0)
Collecting soundfile>=0.9.0
  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 58.6 MB/s eta 0:00:00
Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (67.6.1)
Collecting numba>=0.43.0
  Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 73.1 MB/s eta 0:00:00
  Downloading numba-0.56.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 72.5 MB/s eta 0:00:00
  Downloading numba-0.56.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 72.2 MB/s eta 0:00:00
  Downloading numba-0.56.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 62.5 MB/s eta 0:00:00
  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 68.7 MB/s eta 0:00:00
  Downloading numba-0.55.1-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 73.9 MB/s eta 0:00:00
  Downloading numba-0.55.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 70.0 MB/s eta 0:00:00
  Downloading numba-0.54.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 70.2 MB/s eta 0:00:00
Collecting numpy>=1.15.0
  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.4/15.4 MB 62.8 MB/s eta 0:00:00
Collecting numba>=0.43.0
  Downloading numba-0.54.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 42.0 MB/s eta 0:00:00
  Downloading numba-0.53.1-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 63.5 MB/s eta 0:00:00
  Downloading numba-0.53.0-cp38-cp38-manylinux2014_x86_64.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 10.3 MB/s eta 0:00:00
INFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.
Collecting resampy>=0.2.2
  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 62.4 MB/s eta 0:00:00
  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 72.1 MB/s eta 0:00:00
  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 63.3 MB/s eta 0:00:00
Collecting threadpoolctl>=2.0.0
  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)
Collecting cffi>=1.0
  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.7/442.7 kB 33.9 MB/s eta 0:00:00
Collecting pycparser
  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.7/118.7 kB 13.7 MB/s eta 0:00:00
Building wheels for collected packages: librosa, audioread
  Building wheel for librosa (setup.py) ... done
  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612900 sha256=741d605b3d59efe759fba119177af0ecec81340abbae96916bede1f9e5f00ba0
  Stored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f
  Building wheel for audioread (setup.py) ... done
  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=5f7eaa86680986691f973bb49fd91b41976e58e5d1bd759ca9a5e5d821691837
  Stored in directory: /root/.cache/pip/wheels/0a/ed/be/49df2538fca496690a024a4374455584d65c2afd6fc3d6e9c7
Successfully built librosa audioread
Installing collected packages: threadpoolctl, six, scipy, pycparser, joblib, decorator, audioread, scikit-learn, resampy, cffi, soundfile, librosa
Successfully installed audioread-3.0.0 cffi-1.15.1 decorator-5.1.1 joblib-1.2.0 librosa-0.7.2 pycparser-2.21 resampy-0.3.1 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 soundfile-0.12.1 threadpoolctl-3.1.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: The following packages were previously imported in this runtime:
  [cffi,six]
You must restart the runtime in order to use newly installed versions.
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting magenta
  Downloading magenta-2.1.4-py3-none-any.whl (1.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 19.3 MB/s eta 0:00:00
Collecting mido==1.2.6
  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.8/69.8 kB 7.5 MB/s eta 0:00:00
Collecting imageio==2.20.0
  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 66.5 MB/s eta 0:00:00
Collecting tensorflow-datasets==4.6.0
  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 58.5 MB/s eta 0:00:00
Collecting note-seq==0.0.3
  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.1/210.1 kB 18.1 MB/s eta 0:00:00
Collecting tensorflow-probability==0.17.0
  Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl (6.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 62.6 MB/s eta 0:00:00
Collecting scipy==1.7.3
  Downloading scipy-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.3/39.3 MB 17.0 MB/s eta 0:00:00
Collecting matplotlib==3.5.2
  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 91.0 MB/s eta 0:00:00
Collecting Pillow==9.2.0
  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 95.7 MB/s eta 0:00:00
Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.8/dist-packages (from magenta) (1.16.0)
Collecting tf-slim==1.1.0
  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 352.1/352.1 kB 36.1 MB/s eta 0:00:00
Collecting sk-video==1.1.10
  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 89.3 MB/s eta 0:00:00
Collecting pretty-midi==0.2.9
  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 89.9 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting scikit-image==0.19.3
  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.0/14.0 MB 87.8 MB/s eta 0:00:00
Collecting tensorflow==2.9.1
  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 511.7/511.7 MB 3.1 MB/s eta 0:00:00
Collecting wheel==0.37.1
  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)
Collecting numpy==1.21.6
  Downloading numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 77.7 MB/s eta 0:00:00
Collecting numba==0.49.1
  Downloading numba-0.49.1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 96.1 MB/s eta 0:00:00
Collecting dm-sonnet==2.0.0
  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 254.5/254.5 kB 28.6 MB/s eta 0:00:00
Collecting sox==1.4.1
  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)
Collecting mir-eval==0.7
  Downloading mir_eval-0.7.tar.gz (90 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.7/90.7 kB 11.3 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting absl-py==1.2.0
  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.4/123.4 kB 15.3 MB/s eta 0:00:00
Requirement already satisfied: librosa==0.7.2 in /usr/local/lib/python3.8/dist-packages (from magenta) (0.7.2)
Collecting python-rtmidi==1.1.2
  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 204.5/204.5 kB 23.5 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting pygtrie==2.5.0
  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)
Collecting tabulate>=0.7.5
  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
Collecting wrapt>=1.11.1
  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 kB 10.3 MB/s eta 0:00:00
Collecting dm-tree>=0.1.1
  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.9/152.9 kB 18.0 MB/s eta 0:00:00
Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (1.2.2)
Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (3.0.0)
Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (5.1.1)
Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (0.12.1)
Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (1.2.0)
Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (0.3.1)
Collecting pyparsing>=2.2.1
  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 12.3 MB/s eta 0:00:00
Collecting kiwisolver>=1.0.1
  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 65.8 MB/s eta 0:00:00
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta) (23.0)
Collecting python-dateutil>=2.7
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 27.0 MB/s eta 0:00:00
Collecting cycler>=0.10
  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0
  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 71.2 MB/s eta 0:00:00
Collecting future
  Downloading future-0.18.3.tar.gz (840 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 840.9/840.9 kB 53.1 MB/s eta 0:00:00
  Preparing metadata (setup.py) ... done
Collecting IPython
  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.3/793.3 kB 54.7 MB/s eta 0:00:00
Collecting attrs
  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 kB 7.3 MB/s eta 0:00:00
Collecting pandas>=0.18.1
  Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 92.3 MB/s eta 0:00:00
Collecting bokeh>=0.12.0
  Downloading bokeh-3.1.0-py3-none-any.whl (8.3 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 101.4 MB/s eta 0:00:00
Collecting intervaltree>=2.1.0
  Downloading intervaltree-3.1.0.tar.gz (32 kB)
  Preparing metadata (setup.py) ... done
Collecting pydub
  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)
Collecting protobuf>=3.6.1
  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.4/302.4 kB 29.5 MB/s eta 0:00:00
Requirement already satisfied: llvmlite<=0.33.0.dev0,>=0.31.0.dev0 in /usr/local/lib/python3.8/dist-packages (from numba==0.49.1->magenta) (0.31.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.49.1->magenta) (67.6.1)
Collecting networkx>=2.2
  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 81.4 MB/s eta 0:00:00
Collecting PyWavelets>=1.1.1
  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 105.7 MB/s eta 0:00:00
Collecting tifffile>=2019.7.26
  Downloading tifffile-2023.3.21-py3-none-any.whl (218 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.7/218.7 kB 25.4 MB/s eta 0:00:00
Collecting h5py>=2.9.0
  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 43.7 MB/s eta 0:00:00
Collecting termcolor>=1.1.0
  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)
Collecting keras<2.10.0,>=2.9.0rc0
  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 77.6 MB/s eta 0:00:00
Collecting google-pasta>=0.1.1
  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 7.7 MB/s eta 0:00:00
Collecting libclang>=13.0.0
  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 22.9/22.9 MB 37.3 MB/s eta 0:00:00
Collecting grpcio<2.0,>=1.24.3
  Downloading grpcio-1.53.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 77.8 MB/s eta 0:00:00
Collecting flatbuffers<2,>=1.12
  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)
Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0
  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 438.7/438.7 kB 25.3 MB/s eta 0:00:00
Collecting gast<=0.4.0,>=0.2.1
  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)
Collecting keras-preprocessing>=1.1.1
  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 5.2 MB/s eta 0:00:00
Collecting typing-extensions>=3.6.6
  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)
Collecting opt-einsum>=2.3.2
  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 7.8 MB/s eta 0:00:00
Collecting tensorboard<2.10,>=2.9
  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 62.5 MB/s eta 0:00:00
Collecting tensorflow-io-gcs-filesystem>=0.23.1
  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 71.1 MB/s eta 0:00:00
Collecting astunparse>=1.6.0
  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)
Collecting protobuf>=3.6.1
  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 53.0 MB/s eta 0:00:00
Collecting promise
  Downloading promise-2.3.tar.gz (19 kB)
  Preparing metadata (setup.py) ... done
Collecting toml
  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)
Collecting requests>=2.19.0
  Downloading requests-2.28.2-py3-none-any.whl (62 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 4.4 MB/s eta 0:00:00
Collecting tqdm
  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 6.5 MB/s eta 0:00:00
Collecting dill
  Downloading dill-0.3.6-py3-none-any.whl (110 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 12.4 MB/s eta 0:00:00
Collecting etils[epath]
  Downloading etils-1.1.1-py3-none-any.whl (115 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.4/115.4 kB 13.0 MB/s eta 0:00:00
Collecting importlib-resources
  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)
Collecting tensorflow-metadata
  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.3/52.3 kB 6.7 MB/s eta 0:00:00
Collecting cloudpickle>=1.3
  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)
Collecting xyzservices>=2021.09.1
  Downloading xyzservices-2023.2.0-py3-none-any.whl (55 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.4/55.4 kB 6.5 MB/s eta 0:00:00
Collecting Jinja2>=2.9
  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 14.8 MB/s eta 0:00:00
Collecting contourpy>=1
  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.0/300.0 kB 27.5 MB/s eta 0:00:00
Collecting PyYAML>=3.10
  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 50.4 MB/s eta 0:00:00
Collecting tornado>=5.1
  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 424.0/424.0 kB 26.5 MB/s eta 0:00:00
Collecting sortedcontainers<3.0,>=2.0
  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
Collecting pytz>=2020.1
  Downloading pytz-2023.2-py2.py3-none-any.whl (502 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.1/502.1 kB 45.4 MB/s eta 0:00:00
Collecting certifi>=2017.4.17
  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 19.3 MB/s eta 0:00:00
Collecting urllib3<1.27,>=1.21.1
  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.9/140.9 kB 17.6 MB/s eta 0:00:00
Collecting idna<4,>=2.5
  Downloading idna-3.4-py3-none-any.whl (61 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 5.2 MB/s eta 0:00:00
Collecting charset-normalizer<4,>=2
  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 195.9/195.9 kB 22.2 MB/s eta 0:00:00
Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->magenta) (3.1.0)
Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.9.0->librosa==0.7.2->magenta) (1.15.1)
Collecting tensorboard-plugin-wit>=1.6.0
  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 60.4 MB/s eta 0:00:00
Collecting google-auth<3,>=1.6.3
  Downloading google_auth-2.17.0-py2.py3-none-any.whl (178 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.1/178.1 kB 22.1 MB/s eta 0:00:00
Collecting werkzeug>=1.0.1
  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.6/233.6 kB 25.3 MB/s eta 0:00:00
Collecting google-auth-oauthlib<0.5,>=0.4.1
  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)
Collecting tensorboard-data-server<0.7.0,>=0.6.0
  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 92.4 MB/s eta 0:00:00
Collecting markdown>=2.6.8
  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 12.6 MB/s eta 0:00:00
Collecting zipp
  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)
Collecting traitlets>=5
  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.4/117.4 kB 16.2 MB/s eta 0:00:00
Collecting backcall
  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)
Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30
  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.8/385.8 kB 38.2 MB/s eta 0:00:00
Collecting stack-data
  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)
Collecting matplotlib-inline
  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)
Collecting pexpect>4.3
  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 kB 7.5 MB/s eta 0:00:00
Collecting jedi>=0.16
  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 74.8 MB/s eta 0:00:00
Collecting pickleshare
  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)
Collecting pygments>=2.4.0
  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 81.6 MB/s eta 0:00:00
Collecting googleapis-common-protos<2,>=1.52.0
  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 223.6/223.6 kB 29.2 MB/s eta 0:00:00
Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->magenta) (2.21)
Collecting rsa<5,>=3.1.4
  Downloading rsa-4.9-py3-none-any.whl (34 kB)
Collecting cachetools<6.0,>=2.0.0
  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)
Collecting pyasn1-modules>=0.2.1
  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 19.6 MB/s eta 0:00:00
Collecting requests-oauthlib>=0.7.0
  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)
Collecting parso<0.9.0,>=0.8.0
  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.8/100.8 kB 12.4 MB/s eta 0:00:00
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Collecting importlib-metadata>=4.4
  Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)
Collecting ptyprocess>=0.5
  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting wcwidth
  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)
Collecting pure-eval
  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)
Collecting executing>=1.2.0
  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)
Collecting asttokens>=2.1.0
  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)
Collecting pyasn1<0.5.0,>=0.4.6
  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 8.0 MB/s eta 0:00:00
Collecting oauthlib>=3.0.0
  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 18.1 MB/s eta 0:00:00
Building wheels for collected packages: mir-eval, pretty-midi, python-rtmidi, intervaltree, future, promise
  Building wheel for mir-eval (setup.py) ... done
  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100718 sha256=cb3a473c7d75292fa46e5d1ff5b8be02099fe11de96ad2697d13f03ec56cc98d
  Stored in directory: /root/.cache/pip/wheels/20/53/83/1d50d15a666140d53eda589db005f7cb53b739c7e54711f51f
  Building wheel for pretty-midi (setup.py) ... done
  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591953 sha256=0f842257b757632f3e1dec64ef593a58a572b0a3d764a6354e1b33edc8a9b392
  Stored in directory: /root/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6
  Building wheel for python-rtmidi (setup.py) ... done
  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp38-cp38-linux_x86_64.whl size=592073 sha256=0d8807dd52c991a63b28317b808e8da64b7c384704d7be7ae830d5f080fccfa6
  Stored in directory: /root/.cache/pip/wheels/23/93/e9/7d805b982c4cb5c6cec3e77e1fc6e7417a193beca2230cea52
  Building wheel for intervaltree (setup.py) ... done
  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26114 sha256=d2201c5b118883788e77e52c38267e867f7a3f4578b300dc3400a946ecb2f1be
  Stored in directory: /root/.cache/pip/wheels/45/23/de/5789a92962483fd33cb06674792b9697c1b3766d7c7742830e
  Building wheel for future (setup.py) ... done
  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492035 sha256=dfe67e0faceacfd9f4d0628fa70aa0cf98f6f986a6c0f7b7ec2985052fa67823
  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11
  Building wheel for promise (setup.py) ... done
  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21501 sha256=030be6cd4c1c3e0d247013699935c665a449be0f24d4401f6ef848b73a1ed24c
  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8
Successfully built mir-eval pretty-midi python-rtmidi intervaltree future promise
Installing collected packages: wcwidth, tensorboard-plugin-wit, sortedcontainers, pytz, python-rtmidi, pygtrie, pydub, pyasn1, pure-eval, ptyprocess, pickleshare, mido, libclang, keras, flatbuffers, executing, dm-tree, backcall, zipp, xyzservices, wrapt, wheel, urllib3, typing-extensions, traitlets, tqdm, tornado, toml, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, rsa, PyYAML, python-dateutil, pyparsing, pygments, pyasn1-modules, protobuf, prompt-toolkit, promise, Pillow, pexpect, parso, oauthlib, numpy, networkx, MarkupSafe, kiwisolver, intervaltree, idna, grpcio, google-pasta, gast, future, fonttools, etils, dill, cycler, cloudpickle, charset-normalizer, certifi, cachetools, attrs, asttokens, absl-py, werkzeug, tifffile, tf-slim, tensorflow-probability, stack-data, sox, scipy, requests, PyWavelets, pretty-midi, pandas, opt-einsum, numba, matplotlib-inline, matplotlib, keras-preprocessing, Jinja2, jedi, importlib-resources, importlib-metadata, imageio, h5py, googleapis-common-protos, google-auth, dm-sonnet, contourpy, astunparse, tensorflow-metadata, sk-video, scikit-image, requests-oauthlib, mir-eval, markdown, IPython, bokeh, tensorflow-datasets, google-auth-oauthlib, tensorboard, note-seq, tensorflow, magenta
  Attempting uninstall: wheel
    Found existing installation: wheel 0.40.0
    Uninstalling wheel-0.40.0:
      Successfully uninstalled wheel-0.40.0
  Attempting uninstall: numpy
    Found existing installation: numpy 1.23.0
    Uninstalling numpy-1.23.0:
      Successfully uninstalled numpy-1.23.0
  Attempting uninstall: scipy
    Found existing installation: scipy 1.10.1
    Uninstalling scipy-1.10.1:
      Successfully uninstalled scipy-1.10.1
  Attempting uninstall: numba
    Found existing installation: numba 0.48.0
    Uninstalling numba-0.48.0:
      Successfully uninstalled numba-0.48.0
Successfully installed IPython-8.11.0 Jinja2-3.1.2 MarkupSafe-2.1.2 Pillow-9.2.0 PyWavelets-1.4.1 PyYAML-6.0 absl-py-1.2.0 asttokens-2.2.1 astunparse-1.6.3 attrs-22.2.0 backcall-0.2.0 bokeh-3.1.0 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 dill-0.3.6 dm-sonnet-2.0.0 dm-tree-0.1.8 etils-1.1.1 executing-1.2.0 flatbuffers-1.12 fonttools-4.39.3 future-0.18.3 gast-0.4.0 google-auth-2.17.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.59.0 grpcio-1.53.0 h5py-3.8.0 idna-3.4 imageio-2.20.0 importlib-metadata-6.1.0 importlib-resources-5.12.0 intervaltree-3.1.0 jedi-0.18.2 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 libclang-16.0.0 magenta-2.1.4 markdown-3.4.3 matplotlib-3.5.2 matplotlib-inline-0.1.6 mido-1.2.6 mir-eval-0.7 networkx-3.0 note-seq-0.0.3 numba-0.49.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-1.5.3 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pretty-midi-0.2.9 promise-2.3 prompt-toolkit-3.0.38 protobuf-3.19.6 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydub-0.25.1 pygments-2.14.0 pygtrie-2.5.0 pyparsing-3.0.9 python-dateutil-2.8.2 python-rtmidi-1.1.2 pytz-2023.2 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 scikit-image-0.19.3 scipy-1.7.3 sk-video-1.1.10 sortedcontainers-2.4.0 sox-1.4.1 stack-data-0.6.2 tabulate-0.9.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.31.0 tensorflow-metadata-1.12.0 tensorflow-probability-0.17.0 termcolor-2.2.0 tf-slim-1.1.0 tifffile-2023.3.21 toml-0.10.2 tornado-6.2 tqdm-4.65.0 traitlets-5.9.0 typing-extensions-4.5.0 urllib3-1.26.15 wcwidth-0.2.6 werkzeug-2.2.3 wheel-0.37.1 wrapt-1.15.0 xyzservices-2023.2.0 zipp-3.15.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: Upgrading ipython, ipykernel, tornado, prompt-toolkit or pyzmq can
cause your runtime to repeatedly crash or behave in unexpected ways and is not
recommended. If your runtime won't connect or execute code, you can reset it
with ""Disconnect and delete runtime"" from the ""Runtime"" menu.
WARNING: The following packages were previously imported in this runtime:
  [certifi,cycler,dateutil,google,importlib_resources,kiwisolver,pexpect,pickleshare,pygments,tornado,wcwidth,zipp]
You must restart the runtime in order to use newly installed versions.
```
",dear issue thank comment advice ran code result magenta successfully tested polyphony command learning notebook worked thank much advice result installation looking eta requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected successfully hit get hit focal get focal get get get hit focal hit focal hit focal get hit focal get get get get get get get fetched reading package done reading package done building dependency tree reading state information done python already version python set manually newly remove provide python manual mode total received average speed time time time current total spent left speed looking pip eta eta wheel eta collected wheel pip successfully warning running pip user result broken conflicting behaviour system package manager use virtual environment instead looking eta requirement already satisfied dev eta eta collected successfully warning running pip user result broken conflicting behaviour system package manager use virtual environment instead looking eta collected found installation successfully uninstalled successfully warning running pip user result broken conflicting behaviour system package manager use virtual environment instead warning running pip user result broken conflicting behaviour system package manager use virtual environment instead looking eta done eta done requirement already satisfied eta eta eta decorator six eta requirement already satisfied eta requirement already satisfied dev requirement already satisfied eta eta eta eta eta eta eta eta eta eta eta eta pip looking multiple determine version compatible could take eta eta eta eta eta building collected building wheel done wheel directory building wheel done wheel directory successfully built collected six decorator successfully warning running pip user result broken conflicting behaviour system package manager use virtual environment instead warning following previously six must restart order use newly looking magenta eta eta eta eta eta eta eta eta eta requirement already satisfied magenta eta eta eta done eta eta eta eta eta eta done eta requirement already satisfied magenta eta done tabulate eta eta requirement already satisfied magenta requirement already satisfied magenta requirement already satisfied decorator magenta requirement already satisfied magenta requirement already satisfied magenta requirement already satisfied magenta eta eta requirement already satisfied magenta eta cycler eta future eta done eta eta eta eta done eta requirement already satisfied dev dev magenta requirement already satisfied magenta eta eta eta eta eta eta eta eta eta gast eta eta eta eta eta promise done eta eta dill eta eta eta eta jinja eta eta eta tornado eta eta eta eta eta eta requirement already satisfied magenta requirement already satisfied magenta eta eta eta eta markdown eta eta eta eta eta eta eta requirement already satisfied magenta eta eta eta eta building collected future promise building wheel done wheel directory building wheel done wheel directory building wheel done wheel directory building wheel done wheel directory building wheel future done wheel future directory building wheel promise done wheel promise directory successfully built future promise collected wheel tornado tabulate promise pillow gast future dill cycler jinja markdown magenta wheel found installation wheel successfully uninstalled found installation successfully uninstalled found installation successfully uninstalled found installation successfully uninstalled successfully warning running pip user result broken conflicting behaviour system package manager use virtual environment instead warning tornado cause repeatedly crash behave unexpected way wo connect execute code reset disconnect delete menu warning following previously cycler tornado must restart order use newly,issue,positive,positive,positive,positive,positive,positive
1485251033,"I'm actually fighting with the ddsp package myself,  so I'm not entirely sure if all of these steps are necessary for magenta package. Leaving this filthy workaround here in any case, since it still solves magenta installation problem too.

DO NOT change the order of these lines and DO NOT restart runtime despite such suggestions/buttons provided during the process.

```
# Install hmmlearn before downgrading Python
!pip install hmmlearn

# Downgrade Python
!apt-get update -y
!apt-get install python3.8
!update-alternatives --set python3 /usr/bin/python3.8
!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
!python get-pip.py
import sys
# This path is Colab-runtime specific, check path in other systems.
_ = (sys.path.append(""/usr/local/lib/python3.8/dist-packages""))


# Preinstall legacy packages
!pip install numba==0.48
!pip install numpy==1.23
!pip install packaging>=21.3
!pip install librosa==0.7.2

# Install Magenta
!pip install magenta
```",actually fighting package entirely sure necessary magenta package leaving filthy case since still magenta installation problem change order restart despite provided process install python pip install downgrade python update install python set python curl python import path specific check path preinstall legacy pip install pip install pip install pip install install magenta pip install magenta,issue,negative,negative,neutral,neutral,negative,negative
1483964402,"I actually found a cause here, you'll get this error if the midi sequences don't have the same length:
magenta.models.music_vae.trained_model.NoExtractedExamplesError: No examples extracted from NoteSequence: tempos 
Even if you pass in assert_same_length = False, the error still occurs. Here's the code I'm using
        generated_melody = melody_model.interpolate( start_sequence = melody_start, end_sequence =end_sequence, num_steps = 1,length=16 * bars, temperature=melody_temperature,assert_same_length = True)[0]
",actually found cause get error length extracted even pas false error still code true,issue,negative,negative,neutral,neutral,negative,negative
1474932378,"I will assume that given the time that has past since the question was posted, that indeed magenta is more likely dead than alive.",assume given time past since question posted indeed magenta likely dead alive,issue,negative,negative,neutral,neutral,negative,negative
1474916118,Many of the colab examples online do not work due to this issue.,many work due issue,issue,negative,positive,positive,positive,positive,positive
1464923321,"> Perhaps you have tf 2.0 installed? For future compatibility, we should switch to absl logging, but this should work with tf 1.x for now.

How to do it? I'm not sure. I'm trying to run scripts of magenta
",perhaps future compatibility switch logging work sure trying run magenta,issue,negative,positive,positive,positive,positive,positive
1456429882,"@chunchet-ng Did you make it work in the end?
Thanks",make work end thanks,issue,negative,positive,positive,positive,positive,positive
1433196208,"> Hey @Luka27 I was facing a similar issue, but on Mac OS Big Sur version 11.6. The thing that helped me resolve was to use python 3.7 instead of 3.9. I think that maybe helpful in your case too. Also I had to manually install the JACK driver, you can find it here: https://jackaudio.org/downloads/
> 
> I hope this helps.

I have done as you recommend but I also encounter the same errors. I am on Ubuntu, have tried both python3.9 and python3.7 in venv without success despite the other required packages being installed.

Do you have any other recommendations I could try? I'm really keen to get this up and running.

My error is slightly different to that of the OP:
```
DEPRECATION: python-rtmidi is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559
  Running setup.py install for python-rtmidi ... error
  error: subprocess-exited-with-error
  
  × Running setup.py install for python-rtmidi did not run successfully.
  │ exit code: 1
  ╰─> [20 lines of output]
      running install
      running build
      running build_py
      creating build
      creating build/lib.linux-x86_64-3.7
      creating build/lib.linux-x86_64-3.7/rtmidi
      copying rtmidi/__init__.py -> build/lib.linux-x86_64-3.7/rtmidi
      copying rtmidi/midiconstants.py -> build/lib.linux-x86_64-3.7/rtmidi
      copying rtmidi/release.py -> build/lib.linux-x86_64-3.7/rtmidi
      copying rtmidi/midiutil.py -> build/lib.linux-x86_64-3.7/rtmidi
      running build_ext
      building 'rtmidi._rtmidi' extension
      creating build/temp.linux-x86_64-3.7
      creating build/temp.linux-x86_64-3.7/src
      x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -D__LINUX_ALSA__ -D__UNIX_JACK__ -Isrc -I/home/freqee/musicgen/magenta-env/include -I/usr/include/python3.7m -c src/_rtmidi.cpp -o build/temp.linux-x86_64-3.7/src/_rtmidi.o
      src/_rtmidi.cpp:39:10: fatal error: Python.h: No such file or directory
         39 | #include ""Python.h""
            |          ^~~~~~~~~~
      compilation terminated.
      error: command 'x86_64-linux-gnu-gcc' failed with exit status 1
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: legacy-install-failure

× Encountered error while trying to install package.
╰─> python-rtmidi
```",hey facing similar issue mac o big sur version thing resolve use python instead think maybe helpful case also manually install jack driver find hope done recommend also encounter tried python python without success despite could try really keen get running error slightly different deprecation legacy install method package pip enforce behaviour change possible replacement enable option discussion found running install error error running install run successfully exit code output running install running build running build running building extension fatal error file directory include compilation error command exit status end output note error likely problem pip error error trying install package,issue,negative,positive,positive,positive,positive,positive
1424172486,"Hey @Luka27 I was facing a similar issue, but on Mac OS Big Sur version 11.6.
The thing that helped me resolve was to use python 3.7 instead of 3.9. I think that maybe helpful in your case too.
Also I had to manually install the JACK driver, you can find it here: https://jackaudio.org/downloads/

I hope this helps.",hey facing similar issue mac o big sur version thing resolve use python instead think maybe helpful case also manually install jack driver find hope,issue,positive,neutral,neutral,neutral,neutral,neutral
1409295207,"I have managed to get Magenta running on my M2 by shoehorning dependencies together. Unfortunately there is a bug in Apple's tensorflow GPU acceleration (reported and acknowledge by Apple, see [forum post](https://developer.apple.com/forums//thread/723816?answerId=743019022#743019022)) which breaks generation but not training, very conveniently I may add.

I have a virtualenv with gpu acceleration that I'm using for training, and one without acceleration that I'm using for generation. It's not the best but it works for me. I have shared these virtualenvs for you and any others that may find this comment on a [gist](https://gist.github.com/xstasi/30123f5976abb5b6c90114b92986a155). The files are to be used as such:

```
pip install -r requirements-magenta-gpu-apple-m1-m2-metal.txt --no-deps
```
",get magenta running together unfortunately bug apple acceleration acknowledge apple see forum post generation training conveniently may add acceleration training one without acceleration generation best work may find comment gist used pip install,issue,negative,positive,positive,positive,positive,positive
1404179649,"i got it working by using ubuntu 20.04 

`# Use Ubuntu as the base image
FROM ubuntu:20.04

ENV TZ=Europe/Minsk
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone`",got working use base image run echo,issue,negative,negative,negative,negative,negative,negative
1376742720,Part of the issue is I just don't have the time to setup a local instance.,part issue time setup local instance,issue,negative,neutral,neutral,neutral,neutral,neutral
1376344466,"Hey @abrosen,
Have you ever found a way to make this colab run? 🤔",hey ever found way make run,issue,negative,neutral,neutral,neutral,neutral,neutral
1374566016,"> Hi @dok sorry for asking I'm quite new to this topic. I encounter the same issue as mentioned above, in total i have problems with wheel building in llvmlite, numba and python-rtmidi. I tried to update the versions as you have commented before but it didn't work for me. I haven't updated the setup.py though, but I don't know where to put this file since there are many setup.py. Thank you for your help, I really appreciate it!

To fix the setup.py dependencies, you shall:

1. Clone the repo `git clone https://github.com/tensorflow/magenta.git` (or download the zip file)
2. Fix the setup.py file as @dok suggested
3. Run `pip install .`",hi sorry quite new topic encounter issue total wheel building tried update work though know put file since many thank help really appreciate fix shall clone git clone zip file fix file run pip install,issue,positive,positive,neutral,neutral,positive,positive
1369085407,"I pip installed magenta locally with these modifications and was at least able to get `import magenta` to work.
```
tensorflow-macos==2.9.2
librosa==0.9.2
numba==0.56.4
numpy==1.22.4
```

I understand this repo is largely academic/historical at this point but with 18k stars it'd be nice if even the happy path just worked on a macbook manufactured in the last 2 years.

I suppose a one repo model like this `magenta` is very limiting when you have lots of different models developed over different years which could explain why they seem to be going with different repos for each new project (i.e. ddsp, mt3, etc.). But still annoying if all you want to do is `pip install magenta` and try out a project from 2 years ago.",pip magenta locally least able get import magenta work understand largely point nice even happy path worked last suppose one model like magenta limiting lot different different could explain seem going different new project still annoying want pip install magenta try project ago,issue,positive,positive,positive,positive,positive,positive
1348877679,"Hi @dok sorry for asking I'm quite new to this topic. I encounter the same issue as mentioned above, in total i have problems with wheel building in llvmlite, numba and python-rtmidi. I tried to update the versions as you have commented before but it didn't work for me. I haven't updated the setup.py though, but I don't know where to put this file since there are many setup.py. Thank you for your help, I really appreciate it!",hi sorry quite new topic encounter issue total wheel building tried update work though know put file since many thank help really appreciate,issue,positive,positive,neutral,neutral,positive,positive
1346619623,"@Subham-create I have the same issue! Could you solve this issue yet? I tried downgrading magenta and the other packages throwing errors, installing visual studio (working on pycharm), installing windows sdk, using another device and so on... It didn't help at all, unfortunately. If you have solved this issue I would be very grateful if you could send me instructions how to solve this, thank you :)",issue could solve issue yet tried magenta throwing visual studio working another device help unfortunately issue would grateful could send solve thank,issue,positive,negative,negative,negative,negative,negative
1345400193,"Really hope someone looks at this soon.

I've attempted to build a docker container that can run magenta for me.

Dockerfile:
```
# Use Ubuntu as the base image
FROM ubuntu:18.04

# Install all of Magenta's dependencies
RUN apt-get update && apt-get install -y \
  build-essential \
  libasound2-dev \
  libjack-dev \
  libsndfile1-dev \
  python3-dev \
  python3-pip

# Install Magenta
RUN pip3 install magenta

# Set the default command to run when the container starts
CMD [""/bin/bash""]
```

the error whilst building is as follows:
=> ERROR [3/3] RUN pip3 install magenta                                                                                                 1.4s
------
 > [3/3] RUN pip3 install magenta:
#6 0.695 Collecting magenta
#6 0.865   Downloading https://files.pythonhosted.org/packages/69/5f/19404b46dfd62c44225e14ebd917042d6c61cb1532bc8ef5a3b1cb2a3eea/magenta-2.1.4-py3-none-any.whl (1.4MB)
#6 1.132 Collecting six==1.16.0 (from magenta)
#6 1.204   Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl
#6 1.211 Collecting tensorflow==2.9.1 (from magenta)
#6 1.386   Could not find a version that satisfies the requirement tensorflow==2.9.1 (from magenta) (from versions: )
#6 1.393 No matching distribution found for tensorflow==2.9.1 (from magenta)
------
executor failed running [/bin/sh -c pip3 install magenta]: exit code: 1",really hope someone soon build docker container run magenta use base image install magenta run update install install magenta run pip install magenta set default command run container error whilst building error run pip install magenta run pip install magenta magenta magenta magenta could find version requirement magenta matching distribution found magenta executor running pip install magenta exit code,issue,negative,negative,negative,negative,negative,negative
1336762840,"Did you end up resolving the issues? This is an issue with dependency and I've been able to solve it by updating the deps in [setup.py](https://github.com/tensorflow/magenta/blob/main/setup.py#L158-L158)

Specifically, I updated these two package versions:

```python
    'numba == 0.56.4',
    'python-rtmidi == 1.4.9',
```

See the full file (here](https://gist.github.com/dok/dd8e10ce2677f310f6a97c83eaa3558a)",end issue dependency able solve specifically two package python see full file,issue,negative,positive,positive,positive,positive,positive
1331029126,Thanks! It looks like we need the CLA signed before we can accept this change.,thanks like need accept change,issue,positive,positive,positive,positive,positive,positive
1323652675,"> I also used ableton to make midi files, what other software do you recommend to create MIDI?

U should put them into Channel 10 (with midi editing software so they are drums)",also used make recommend create put channel,issue,positive,neutral,neutral,neutral,neutral,neutral
1322082567,"I also used ableton to make midi files, what other software do you recommend to create MIDI?",also used make recommend create,issue,positive,neutral,neutral,neutral,neutral,neutral
1322056879,"> Did you solve this problem? i still cannot

I haven't. Seems like if you create MIDI files with Ableton, Magenta doesn't accept them. I wonder how to fix this.
",solve problem still like create magenta accept wonder fix,issue,positive,neutral,neutral,neutral,neutral,neutral
1313922490,"i have the same problem.. seems there are lots of issues with drums_rnn..

Also the dataset with 0 kb generated.

can any mod please answer to these issues..?",problem lot also please answer,issue,negative,neutral,neutral,neutral,neutral,neutral
1300300410,"Hi, how did you solve this problem? I meet the same one!",hi solve problem meet one,issue,negative,neutral,neutral,neutral,neutral,neutral
1269544318,"Hi,
I am getting the same issue, was anyone able to resolve it. Thanks.",hi getting issue anyone able resolve thanks,issue,positive,positive,positive,positive,positive,positive
1268977057,"I had the same problem when trying to encode melodies previously generated by the model's (`MusicVAE`) `sample` function.
The following example illustrates how seemingly arbitrary the difference is between a sequence provoking the error and one that doesn't:
``` 
seq = music_pb2.NoteSequence()
seq.tempos.add(qpm=120)
seq.ticks_per_quarter = 220
seq.total_time = 5.0

seq.notes.add(pitch=51, start_time=3.0, end_time=5.0, velocity=80)

_, enc, _ = mel_2bar.encode([seq])  # this works

seq2 = music_pb2.NoteSequence()
seq2.tempos.add(qpm=120)
seq2.ticks_per_quarter=220
seq2.total_time=4.0

seq2.notes.add(pitch=51, start_time=2.0, end_time=4.0, velocity=80) 

_, enc2, _ = mel_2bar.encode([seq2]) # this yields NoExtractedExamplesError
```
It would be really great if this could be fixed or at least explained. Thanks in advance!",problem trying encode previously model sample function following example seemingly arbitrary difference sequence provoking error one work would really great could fixed least thanks advance,issue,negative,positive,neutral,neutral,positive,positive
1265886377,"Ah, looks like you still need to sign the CLA. Once you do that, we can merge the change. Thanks!",ah like still need sign merge change thanks,issue,positive,positive,positive,positive,positive,positive
1264611072,I'm new to the github thing so hopefully now it should be done,new thing hopefully done,issue,negative,positive,positive,positive,positive,positive
1235520792,"> I had this problem and to isolate it I switched to a clean venv via pycharm and installed only magenta (without conda). I dug through the output and found that the common issue between my failure to get good output was magenta not finding my model directory. It was then that I realized the directory I was pointing it to had a typo, so it was failing to find a trained model, and understandably outputting gibberish because it was using some default model ill-suited to the task.
> 
> Looking through @xMcouro's output, I also see buried in there the line:
> 
> > INFO:tensorflow:Could not find trained model in model_dir: d/train, running initialization to predict.
> 
> So it looks like that may be the problem here too. Once I fixed the directory I was pointing to when running the command, it started working perfectly.

Thank you!",problem isolate switched clean via magenta without dug output found common issue failure get good output magenta finding model directory directory pointing typo failing find trained model understandably gibberish default model task looking output also see buried line could find trained model running predict like may problem fixed directory pointing running command working perfectly thank,issue,negative,positive,positive,positive,positive,positive
1214425588,"I fill like RL is not the sollution,
there are so many songs out there,
maybe we should aprouch this wuth another way,
there are models that can sepperate songs into stemps (drums, synth, vocal, guitar, ect) [""like moses ai""]
than we should find the corelation between the bass and the drums, or find the harmony from the instrumental, by the spectogram: (A spectrogram is a visual representation of the [spectrum](https://en.wikipedia.org/wiki/Spectral_density) of [frequencies](https://en.wikipedia.org/wiki/Frequencies) of a signal as it varies with time.)
the low frequencies are the fandamentals and by them you can find the root of the harmony ect...

Then to understand what shape of synths used, (shape like :attake ,relise ,sustaine ,hold ,pitch ,tember, ect)

There are more subjects to explore with this topic, fortunately I dont have the resourses, Im a developer and a producer/player and very interested by DL
you can see my 
linkedin : https://www.linkedin.com/in/shay-melamud-2a01b4152/
git : https://github.com/shaymelamud95
instefram for music I play or beats I'v produced: https://www.instagram.com/shaymelamud/

I hope to find the right guide to start working in the DL field if you can help me ritch me out:) Im very pationing about it.
",fill like many maybe another way vocal guitar like ai find bass find harmony instrumental spectrogram visual representation spectrum signal time low find root harmony understand shape used shape like hold pitch explore topic fortunately dont developer interested see git music play produced hope find right guide start working field help,issue,positive,positive,positive,positive,positive,positive
1200280503,"Yes, it worked. Took about 15 min, but completed successfully!

",yes worked took min successfully,issue,positive,positive,positive,positive,positive,positive
1198835800,"Try this instead: 

`!pip install -qU magenta==2.1.0`

It still takes longer than it should, but it works for me. Using the latest version of magenta worked fine for me up until about 2 weeks ago. ",try instead pip install still longer work latest version magenta worked fine ago,issue,negative,positive,positive,positive,positive,positive
1198572007,"Hello @xiaoyisha @howardlau1999, just wondering how you accomplished this? 

I'm trying to train the pre-trained hierdec-mel-16bar model. I downloaded the two files: ""hierdec-mel_16bar.ckpt.data-00000-of-00001"" and ""hierdec-mel_16bar.ckpt.index"", and then ran music_vae_train with run_dir pointing to the the train directory where those 2 files are stored. However, the model ignores those 2 files and trains from 0. I also tried renaming those files as ""model.ckpt"" instead, but no luck there. 

Thanks! ",hello wondering accomplished trying train model two ran pointing train directory however model also tried instead luck thanks,issue,positive,positive,positive,positive,positive,positive
1193364732,"I'm having the same problem. I'm using the official nvidia cuda docker image (tried both 18.04 and 20.04). I also tried the magenta install script. None worked.

````
FROM nvidia/cuda:11.7.0-runtime-ubuntu18.04
SHELL [""/bin/bash"", ""-c""]

# Install base utilities
RUN apt-get update && \
    apt-get install -y libfluidsynth1 && \
    apt-get install -y build-essential && \
    apt-get install -y wget &&\
    apt-get install -y git &&\
    apt-get install -y fluid-soundfont-gm && \
    apt-get install -y libasound2-dev && \
    apt-get install -y libjack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install miniconda
ENV CONDA_DIR /opt/conda
RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh && \
     /bin/bash ~/miniconda.sh -b -p /opt/conda
ENV PATH=$CONDA_DIR/bin:$PATH
RUN conda init bash

RUN pip install magenta```",problem official docker image tried also tried magenta install script none worked shell install base run update install install install install git install install install clean install run quiet path run bash run pip install magenta,issue,negative,negative,negative,negative,negative,negative
1191088821,"> I can reproduce. Using `note-seq==0.0.2` fixed the backtracking error for me, although I still can't install with Python 3.10 on Windows (seems like it's trying to build numba 0.48 and failed…)

Managed to install successfully on Windows with Python 3.8, VC++ build tools and `note-seq==0.0.3 magenta`.",reproduce fixed error although still ca install python like trying build install successfully python build magenta,issue,negative,positive,positive,positive,positive,positive
1187744109,"I'm having a similar problem. I'm getting a maximum accuracy of about 0.32 on the eval set and 0.85 on the training data. However, I've tried techniques to reduce overfitting such as reducing network size/nodes, lowering dropout_keep_prob, lowering learning rate, and experimenting with num_steps (early stopping). 

Were you ever able to figure out optimal parameters @ysig ??",similar problem getting maximum accuracy set training data however tried reduce reducing network lowering lowering learning rate early stopping ever able figure optimal,issue,negative,positive,positive,positive,positive,positive
1184621274,"I see. I believe that maybe python 3.10 may conflict with other libraries. I set my versions accordingly to collab and deployed the whole thing as a conda environment. 

If you have conda, you might be able to make it work on your machine with the following command:

`conda env create -f env_file.yml`

env_file.yml:
```yml
name: magenta
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.7.13
  - jupyter
  - pip
  - pip:
    - numpy==1.19
    - tensorflow==1.15.2
    - note-seq==0.0.2
    - tensorflow-datasets==3.2.1
    - magenta
```",see believe maybe python may conflict set accordingly whole thing environment might able make work machine following command create name magenta pip pip magenta,issue,negative,positive,positive,positive,positive,positive
1184131090,"I can reproduce. Using `note-seq==0.0.2` fixed the backtracking error for me, although I still can't install with Python 3.10 on Windows (seems like it's trying to build numba 0.48 and failed…)",reproduce fixed error although still ca install python like trying build,issue,negative,positive,neutral,neutral,positive,positive
1183549732,"Indeed, I just tested your code  on my side and I had the same issue as you

I believe that maybe because note-seq is being manually set to an older version, pip will resolve magenta with an older version as well, one that does not have the `score2perf` module.

One way that I found to work around that is to use the `-U`  flag on the `pip install` command, where `-U` will [upgrade magenta to the newest version](https://pip.pypa.io/en/stable/cli/pip_install/#cmdoption-U), which have the `score2perf` module.

You can either add the `note-seq==0.0.2` before magenta in the already existing command, like:

```python
!pip install -qU google-cloud note-seq==0.0.2 magenta pyfluidsynth
```

Or add the `-U` flag to the command that you added:

```python
!pip install -U note-seq==0.0.2 magenta
```

Side note, this type of dependency problem is real cumbersome to troubleshoot, which consequently complicates the access of this type of resource to the community. I hope magenta team fix this dependency issue soon so we don't have more problems with it 
",indeed tested code side issue believe maybe manually set older version pip resolve magenta older version well one module one way found work around use flag pip install command upgrade magenta version module either add magenta already command like python pip install magenta add flag command added python pip install magenta side note type dependency problem real cumbersome consequently access type resource community hope magenta team fix dependency issue soon,issue,positive,positive,positive,positive,positive,positive
1182674048,"I try to work your method (pip install note-seq==0.0.2 magenta)
(Generating Piano Music with Transformer.ipynb, https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb#scrollTo=tciXVi5eWG_1)

but I have the same problem as below shown,
#@title Setup Environment
#@markdown Copy some auxiliary data from Google Cloud Storage.
#@markdown Also install and import Python dependencies needed
#@markdown for running the Transformer models.

%tensorflow_version 1.x

print('Copying Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')
!gsutil -q -m cp -r gs://magentadata/models/music_transformer/primers/* /content/
!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/

print('Installing dependencies...')
!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev
!pip install -q 'tensorflow-datasets < 4.0.0'
#!pip install -qU google-cloud magenta pyfluidsynth
!pip install note-seq==0.0.2 magenta
!pip install -qU google-cloud pyfluidsynth

print('Importing libraries...')

import numpy as np
import os
import tensorflow.compat.v1 as tf

from google.colab import files

from tensor2tensor import models
from tensor2tensor import problems
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.utils import decoding
from tensor2tensor.utils import trainer_lib

from magenta.models.score2perf import score2perf
import note_seq

tf.disable_v2_behavior()

print('Done!')

---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
[<ipython-input-2-5be00b904752>](https://localhost:8080/#) in <module>()
     31 from tensor2tensor.utils import trainer_lib
     32 
---> 33 from magenta.models.score2perf import score2perf
     34 import note_seq
     35 

ModuleNotFoundError: No module named 'magenta.models.score2perf'

",try work method pip install magenta generating piano music problem shown title setup environment markdown copy auxiliary data cloud storage markdown also install import python markdown running transformer print salamander piano via print update install pip install pip install magenta pip install magenta pip install print import import o import import import import import import import import import print recent call last module import import import module,issue,negative,neutral,neutral,neutral,neutral,neutral
1182349426,"I'm having the same problem on my side, and not only with collab but in other instances as well, such as installing magenta with `pip install magenta` , use their installation bash script and building the source code locally.

I was able to make it work with the insight of @f403 to downgrade note-seq. But in my end, I was only able to make it work using `note-seq===0.0.2`, version 0.0.3 didn't work for me.

**Downgrading note-seq command example:**

`pip install note-seq==0.0.2 magenta`

",problem side well magenta pip install magenta use installation bash script building source code locally able make work insight downgrade end able make work version work command example pip install magenta,issue,negative,positive,positive,positive,positive,positive
1180123586,"Looks like latest `note-seq` is breaking dependencies.
Try downgrading with: `pip install note-seq==0.0.3 magenta`

Magenta has no pinned version of `note-seq` in its dependencies, 
as well as for a plenty of other packages, this can cause same issues any time in the future.
",like latest breaking try pip install magenta magenta pinned version well plenty cause time future,issue,positive,positive,positive,positive,positive,positive
1174964575,"Thanks u,
I try to do !pip install -qU google-cloud magenta==2.1.0 pyfluidsynth

print('Installing dependencies...')
!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev
!pip install -q 'tensorflow-datasets < 4.0.0'
!pip install -qU google-cloud magenta==2.1.0 pyfluidsynth

print('Importing libraries...')

import numpy as np
import os
import tensorflow.compat.v1 as tf

from google.colab import files

from tensor2tensor import models
from tensor2tensor import problems
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.utils import decoding
from tensor2tensor.utils import trainer_lib

but I see the same issue:

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
[<ipython-input-17-a22d2132865e>](https://localhost:8080/#) in <module>()
     23 from google.colab import files
     24 
---> 25 from tensor2tensor import models
     26 from tensor2tensor import problems
     27 from tensor2tensor.data_generators import text_encoder

6 frames
[/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py](https://localhost:8080/#) in make(id, max_episode_steps, autoreset, disable_env_checker, **kwargs)
    579             raise error.Error(f""No registered env with id: {id}"")
    580 
--> 581     _kwargs = spec_.kwargs.copy()
    582     _kwargs.update(kwargs)
    583 

AttributeError: 'NoneType' object has no attribute 'copy'",thanks try pip install print update install pip install pip install print import import o import import import import import import import see issue recent call last ade module import import import import make id raise registered id id object attribute,issue,negative,positive,neutral,neutral,positive,positive
1174953824,"Just write ""import magenta"" instead of ""from magenta.models.score2perf import score2perf"". Maybe like this it'll work with 2.1.0

",write import magenta instead import maybe like work,issue,negative,neutral,neutral,neutral,neutral,neutral
1174923545,"Thanks u, 
I try to do !pip install -qU google-cloud magenta==2.1.1 pyfluidsynth
but I see the same issue:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
[<ipython-input-4-1c024adeb728>](https://localhost:8080/#) in <module>()
     23 from google.colab import files
     24 
---> 25 from tensor2tensor import models
     26 from tensor2tensor import problems
     27 from tensor2tensor.data_generators import text_encoder

6 frames
[/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py](https://localhost:8080/#) in make(id, max_episode_steps, autoreset, disable_env_checker, **kwargs)
    579             raise error.Error(f""No registered env with id: {id}"")
    580 
--> 581     _kwargs = spec_.kwargs.copy()
    582     _kwargs.update(kwargs)
    583 

AttributeError: 'NoneType' object has no attribute 'copy'

I don't know how to do import magenta as a whole.
Can you give me that?",thanks try pip install see issue recent call last module import import import import make id raise registered id id object attribute know import magenta whole give,issue,negative,positive,neutral,neutral,positive,positive
1174920067,"Version 2.1.0 might be to old for the model you're using, it was just the first I tried and it worked for me. Maybe try 2.1.1 and see if it works.

Or try to just import magenta as a whole",version might old model first tried worked maybe try see work try import magenta whole,issue,negative,positive,positive,positive,positive,positive
1174914955,"Last week, it ran without any problem, but after changing magenta==2.1.0, an error occurs as shown below.
(https://colab.research.google.com/notebooks/magenta/piano_transformer/piano_transformer.ipynb#scrollTo=tciXVi5eWG_1)

%tensorflow_version 1.x

print('Copying Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')
!gsutil -q -m cp -r gs://magentadata/models/music_transformer/primers/* /content/
!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/

print('Installing dependencies...')
!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev
!pip install -q 'tensorflow-datasets < 4.0.0'
!pip install -qU google-cloud magenta==2.1.0 pyfluidsynth
print('Importing libraries...')

import numpy as np
import os
import tensorflow.compat.v1 as tf

from google.colab import files

from tensor2tensor import models
from tensor2tensor import problems
from tensor2tensor.data_generators import text_encoder
from tensor2tensor.utils import decoding
from tensor2tensor.utils import trainer_lib

from magenta.models.score2perf import score2perf
import note_seq

tf.disable_v2_behavior()

print('Done!')
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ModuleNotFoundError                       Traceback (most recent call last)
[<ipython-input-3-52ffe6d503c9>](https://localhost:8080/#) in <module>()
     29 from tensor2tensor.utils import trainer_lib
     30 
---> 31 from magenta.models.score2perf import score2perf
     32 import note_seq
     33 

ModuleNotFoundError: No module named 'magenta.models.score2perf'
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
",last week ran without problem error shown print salamander piano via print update install pip install pip install print import import o import import import import import import import import import print recent call last module import import import module,issue,positive,neutral,neutral,neutral,neutral,neutral
1173799870,"> the same issue, How can I resolve this problem?

It worked for me by installing an older version of magenta:

pip install magenta==2.1.0",issue resolve problem worked older version magenta pip install,issue,negative,positive,positive,positive,positive,positive
1172756795,"What's the goal of this change? Also, we typically use single quotes in our python files.",goal change also typically use single python,issue,negative,negative,negative,negative,negative,negative
1171566895,"My bad. I was so stunned by commit in recent hours that I didn't read the README. 
Thanks 👍🏼",bad commit recent read thanks,issue,negative,negative,negative,negative,negative,negative
1171553466,"Hey @bizzyvinci Magenta as a project is very much active! However, this repository is not: https://github.com/magenta/magenta#status. Is there a better way we could display that status message to reduce confusion?",hey magenta project much active however repository better way could display status message reduce confusion,issue,positive,positive,positive,positive,positive,positive
1170324355,"Interesting! For the ""Transformer"" results, did you use the ISMIR checkpoint or the MT3 checkpoint? I would guess that MT3 would work better for this specific task since it's trained on both MAESTRO (acoustic piano) and Slakh, which has piano synths and may be a closer match to OMAPS.",interesting transformer use would guess would work better specific task since trained maestro acoustic piano piano may closer match,issue,positive,positive,positive,positive,positive,positive
1150617228,"sorry long time to reply and lucky this issue is still open. I am free now :).  Here is the test results of Onsets and Frames and Transformer model on OMAPS dataset mentioned above. The onset tolerance is ± 50 ms.

|          | P (%) | R (%) | F1 (%) |
| :----- | :-----: | :----: | :----: |
| Onsets and Frames | 81.03 | 90.22 | 85.17 |
| Transformer | 59.91 | 88.65 | 71.23 |",sorry long time reply lucky issue still open free test transformer model onset tolerance transformer,issue,positive,positive,neutral,neutral,positive,positive
1149014103,"I've found this project, may be handy:
https://github.com/kmonachopoulos/ImageNet-to-TFrecord",found project may handy,issue,negative,positive,positive,positive,positive,positive
1134821656,I understand. Training such models is often a challenge of patience. Either get a stronger GPU (or multiple) or be patient 🤗,understand training often challenge patience either get multiple patient,issue,negative,neutral,neutral,neutral,neutral,neutral
1134765508,"> > How did you delete the memory in the disk? I have RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[16,12804,24] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc error with: GeForce930mx and I have 140gb free memory on disk C ( which is also my SSD)
> 
> OOM usually points at an exhaustion of GPU memory. You might try: Check if there is any other process blocking the GPU (such as other Jupyter notebooks), or tune down the batch size.

Unfortunately I just had one notebook that is open and when I reduce batch size it took so many hours like 5-6",delete memory disk tensor shape type float allocator error free memory disk also usually exhaustion memory might try check process blocking tune batch size unfortunately one notebook open reduce batch size took many like,issue,negative,positive,neutral,neutral,positive,positive
1134209875,"> How did you delete the memory in the disk? I have RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[16,12804,24] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc error with: GeForce930mx and I have 140gb free memory on disk C ( which is also my SSD)

OOM usually points at an exhaustion of GPU memory. You might try: Check if there is any other process blocking the GPU (such as other Jupyter notebooks), or tune down the batch size.

",delete memory disk tensor shape type float allocator error free memory disk also usually exhaustion memory might try check process blocking tune batch size,issue,negative,positive,neutral,neutral,positive,positive
1133848893,"> Great thank you! Yes, i run the code the same way, seems that written checkpoints from previous trials ate all memory of the disk. Now i cleaned it and seems that it works! Great thank you again!

How did you delete the memory in the disk? I have **RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[16,12804,24] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc** error with: GeForce930mx and I have  140gb free memory on disk C ( which is also my SSD)",great thank yes run code way written previous ate memory disk work great thank delete memory disk tensor shape type float allocator error free memory disk also,issue,positive,positive,positive,positive,positive,positive
1128853276,"Possibly dupe of the still open #1862 , will try ToT tensor2tensor

EDIT: yep -- installing tensor2tensor from source solves the issue",possibly dupe still open try tot edit yep source issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1127498575,"This kfac and tensor2tensor issue is reproducible in my setup -- with a completely fresh virtualenv installation of Magenta. 

EDIT: I am able to work around it via `pip install kfac==0.2.0 tensor2tensor` and `pip install tensorflow-probability==0.7.0`",issue reproducible setup completely fresh installation magenta edit able work around via pip install pip install,issue,negative,positive,positive,positive,positive,positive
1126836557,"solved it, in logic pro x I used a general MIDI track, set it like this
<img width=""308"" alt=""屏幕快照 2022-05-14 18 42 54"" src=""https://user-images.githubusercontent.com/105380211/168453143-a6aa3dad-e242-49a3-90f8-ad9941b992dd.png"">
,",logic pro used general track set like,issue,negative,positive,neutral,neutral,positive,positive
1121990031,With which version of TF and Python did you made the training work? It does not work with TF version 2.3.0 for me.,version python made training work work version,issue,negative,neutral,neutral,neutral,neutral,neutral
1121378331,"I believe I did eventually get it to run, but I'm afraid to say I no longer recall precisely what I did. Possibly it involved using an older version of tensorflow in the virtual environment. Best of luck.",believe eventually get run afraid say longer recall precisely possibly involved older version virtual environment best luck,issue,positive,positive,positive,positive,positive,positive
1120606481,Same problem on my windows 11 laptop. I tried bash then install MSVC C++ 14.0,problem tried bash install,issue,negative,neutral,neutral,neutral,neutral,neutral
1117921470,"The deprecation warnings seem to be mostly coming from the tensor2tensor framework, which IIRC is not under active development.  As for the colab, we're not really planning to make any major updates to the project, only simple changes to fix breakages as they occur.",deprecation seem mostly coming framework active development really make major project simple fix occur,issue,negative,positive,positive,positive,positive,positive
1117703685,"Hi Ian, thank you for helping. It works. 
There are some deprecation warnings, is it going to be updated or the project will stay as it is?
Thank you",hi thank helping work deprecation going project stay thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1114402104,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

For more information, open the [CLA check for this pull request](https://github.com/magenta/magenta/pull/1997/checks?check_run_id=6251053788).",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement information open check pull request,issue,positive,positive,positive,positive,positive,positive
1112649645,"One note: after ""upgrading"" tensor2tensor (as @Chinatown1444 suggested), I also had to re-train. After that, everything appeared to work as expected.",one note also everything work,issue,negative,neutral,neutral,neutral,neutral,neutral
1111218213,"Ah yes, forgetting sustain processing has certainly caused me problems too. We'll try to be more clear about that in future papers.

I'd be curious to see how our MT3 model performs on OMAPS. It's possible that the more powerful transformer model is just overfitting more to the specifics of MAESTRO, but perhaps the additional training on other instruments would help prevent that. How much worse was the transformer model?",ah yes forgetting sustain certainly try clear future curious see model possible powerful transformer model maestro perhaps additional training would help prevent much worse transformer model,issue,positive,positive,neutral,neutral,positive,positive
1110450270,"The idea of your recent transcription work (which achieves better results) https://g.co/magenta/mt3 inspired me a lot. I also followed that work a few days ago. On our electronic MIDI piano (Yamaha P115) dataset, called OMAPS (https://github.com/itec-hust/transition-aware/tree/main/OMAPS), the transformer model is not as robust as the onsets and frames model and its evaluation result is not as good as onsets and frames. Maybe it is due to more parameters in the transformer and it can be improved later.",idea recent transcription work better inspired lot also work day ago electronic piano transformer model robust model evaluation result good maybe due transformer later,issue,positive,positive,positive,positive,positive,positive
1110444091,"@cghawthorne Hello, I've solved this problem. As described in your ISMIR paper ONSETS AND FRAMES: DUAL-OBJECTIVE PIANO TRANSCRIPTION, 

> when processing the MAPS MIDI files for training and evaluation, **we first translate “sustain pedal” control changes into longer note durations**. If a note is active when sustain goes on, that note will be extended until either sustain goes off or the same note is played again. This process gives the same note durations as the text files included with the dataset.


This statement is not clearly included in the ICLR paper mentioned above, I followed the onsets and frames code and found that the actual annotations used for evaluation were processed by **apply_sustain_control_changes** . I use the following conversion code to sustain or end the offset in the MIDI file ( hope it will help other researchers :), and the final evaluation results are normal, which are

note transcription is **P 97.92 R 91.82 F1 94.73**
note with offset is     **P 81.15 R 76.16 F1 78.55**

```python
from note_seq import midi_io
from note_seq import sequences_lib
from functools import partial
from multiprocessing import Pool
import pandas
import os

data_csv_path = '/home/data/wxk/other_dataset/maestro-v1.0.0/maestro-v1.0.0.csv'
data_root = '/home/data/wxk/other_dataset/maestro-v1.0.0/'
padal_extend_root = '/home/data/wxk/other_dataset/maestro_testset/maestro-v1.0.0_test_labels_extend_pedal_megenta'

def get_maestro_annotations():

  csv_data = pandas.read_csv(data_csv_path)
  data_info = csv_data.loc[csv_data['split'] == 'test']

  wav_name = list(data_info['audio_filename'])
  wav_paths = list(map(partial(os.path.join, data_root), wav_name))
  wav_paths.sort(key=lambda x: os.path.basename(x).lower())

  label_paths = list(map(lambda x: x.replace('.wav', '.midi'), wav_paths))
  return label_paths

def convert_midis_to_txt(sequence, savepath):

  notes = []
  for note in sequence.notes:
  onset, offset, pitch, velocity = note.start_time, note.end_time, note.pitch, note.velocity
  notes.append([onset, offset, pitch, velocity])
  notes.sort(key=lambda note: note[0])

  with open(savepath, 'wt', encoding='utf8') as f:
    for onset, offset, pitch, velocity in notes:
      f.write(""%-8.4f  %-8.4f  %-3d  %-3d\n""%(onset, offset, pitch, velocity))


def process_one_file(midipath):
  ns = midi_io.midi_file_to_note_sequence(midipath)
  sequence = sequences_lib.apply_sustain_control_changes(ns)
  pedal_extend_path = os.path.join(padal_extend_root, os.path.basename(midipath).replace('.midi', '.txt'))
  convert_midis_to_txt(sequence, pedal_extend_path)


def multi_process(midipaths):
  pool = Pool(16)
  res = pool.map_async(process_one_file, midipaths)
  print(res.get())
  pool.close()
  pool.join()

if __name__ == '__main__':
  annotation_paths = get_maestro_annotations()
  # process_one_file(annotation_paths[0])
  multi_process(annotation_paths)
```
",hello problem paper piano transcription training evaluation first translate sustain pedal control longer note note active sustain go note extended either sustain go note process note text included statement clearly included paper code found actual used evaluation use following conversion code sustain end offset file hope help final evaluation normal note transcription note offset python import import import partial import pool import import o list list map partial list map lambda return sequence note onset offset pitch velocity onset offset pitch velocity note note open onset offset pitch velocity onset offset pitch velocity sequence sequence pool pool print,issue,positive,positive,neutral,neutral,positive,positive
1110337249,"Hi @xk-wang. I'm not sure why you're getting such bad results for note with offset. I don't see anything obviously wrong with your code, but the problem could be happening earlier in the pipeline. I'd start by printing out offset times and see if there's anything wrong there, like maybe some confusion between offset time and note duration.

You might also be interested in our more recent transcription work (which achieves better results) here: https://g.co/magenta/mt3",hi sure getting bad note offset see anything obviously wrong code problem could happening pipeline start printing offset time see anything wrong like maybe confusion offset time note duration might also interested recent transcription work better,issue,negative,negative,neutral,neutral,negative,negative
1101158568,"here is the whole info:

(rl_tunner) D:\magenta-main\magenta\models\rl_tuner>python rl_tuner_train.py
['D:\\magenta-main\\magenta\\models\\rl_tuner', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\python37.zip', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\DLLs', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\lib', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\lib\\site-packages', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\lib\\site-packages\\win32', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\lib\\site-packages\\win32\\lib', 'C:\\Users\\wzj1\\.conda\\envs\\rl_tunner\\lib\\site-packages\\Pythonwin', 'D:\\magenta-main']
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\librosa\util\decorators.py:9: NumbaDeprecationWarning: [1mAn import was requested from a module that has moved location.
Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.[0m
  from numba.decorators import jit as optional_jit
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\librosa\util\decorators.py:9: NumbaDeprecationWarning: [1mAn import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.[0m
  from numba.decorators import jit as optional_jit
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\pydub\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work
  warn(""Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work"", RuntimeWarning)
WARNING:tensorflow:From C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\compat\v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
INFO:tensorflow:Initializing q network
I0418 14:10:10.780586  4104 rl_tuner.py:268] Initializing q network
INFO:tensorflow:Using custom hparams
I0418 14:10:10.780586  4104 note_rnn_loader.py:101] Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope q_network
I0418 14:10:10.781583  4104 note_rnn_loader.py:201] Initializing melody RNN graph for scope q_network
D:\magenta-main\magenta\models\shared\events_rnn_graph.py:50: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.
  cell = base_cell(rnn_layer_sizes[i], state_is_tuple=False)  # add
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C20E048>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.784575  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C20E048>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BE22748>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.790563  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BE22748>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C204908>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.794549  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C204908>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C121A48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.798538  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C121A48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1AF148>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.807553  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1AF148>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BEEE248>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:10.812501  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BEEE248>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
W0418 14:10:10.817520  4104 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From D:\magenta-main\magenta\models\rl_tuner\note_rnn_loader.py:256: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
W0418 14:10:10.820479  4104 deprecation.py:347] From D:\magenta-main\magenta\models\rl_tuner\note_rnn_loader.py:256: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:756: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
  shape=[input_depth + h_depth, 4 * self._num_units])
WARNING:tensorflow:From C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:760: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0418 14:10:10.876546  4104 deprecation.py:551] From C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:760: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:760: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
  initializer=tf.compat.v1.zeros_initializer(dtype=self.dtype))
C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\keras\engine\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
W0418 14:10:11.040083  4104 note_rnn_loader.py:315] ERROR! No such primer file exists! ./testdata/primer.mid
INFO:tensorflow:Initializing target q network
I0418 14:10:11.041079  4104 rl_tuner.py:278] Initializing target q network
INFO:tensorflow:Using custom hparams
I0418 14:10:11.041079  4104 note_rnn_loader.py:101] Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope target_q_network
I0418 14:10:11.042076  4104 note_rnn_loader.py:201] Initializing melody RNN graph for scope target_q_network
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C5E55C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.044072  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C5E55C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1213C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.053049  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1213C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1ED2C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.057036  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1ED2C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C17F048>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.065015  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C17F048>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C11A708>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.069004  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C11A708>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A872A9F388>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.073990  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A872A9F388>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
W0418 14:10:11.079037  4104 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
W0418 14:10:11.194668  4104 note_rnn_loader.py:315] ERROR! No such primer file exists! ./testdata/primer.mid
INFO:tensorflow:Initializing reward network
I0418 14:10:11.195668  4104 rl_tuner.py:289] Initializing reward network
INFO:tensorflow:Using custom hparams
I0418 14:10:11.196662  4104 note_rnn_loader.py:101] Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope reward_rnn
I0418 14:10:11.196662  4104 note_rnn_loader.py:201] Initializing melody RNN graph for scope reward_rnn
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A872BE5C48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.198657  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A872BE5C48>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BE58808>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.202646  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86BE58808>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C051108>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.212622  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C051108>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C17F4C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.216609  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C17F4C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1FA7C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.220598  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1FA7C8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:<keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1EDAC8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
W0418 14:10:11.227582  4104 rnn_cell_impl.py:718] <keras.layers.legacy_rnn.rnn_cell_impl.BasicLSTMCell object at 0x000001A86C1EDAC8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
W0418 14:10:11.232568  4104 rnn_cell_impl.py:1259] `tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
W0418 14:10:11.346303  4104 note_rnn_loader.py:315] ERROR! No such primer file exists! ./testdata/primer.mid
INFO:tensorflow:Q network cell: <keras.layers.legacy_rnn.rnn_cell_impl.MultiRNNCell object at 0x000001A86C148148>
I0418 14:10:11.348299  4104 rl_tuner.py:299] Q network cell: <keras.layers.legacy_rnn.rnn_cell_impl.MultiRNNCell object at 0x000001A86C148148>
INFO:tensorflow:Adding RL graph variables
I0418 14:10:11.349263  4104 rl_tuner.py:302] Adding RL graph variables
INFO:tensorflow:Adding reward computation portion of the graph
I0418 14:10:11.351264  4104 rl_tuner.py:428] Adding reward computation portion of the graph
INFO:tensorflow:Adding taking action portion of graph
I0418 14:10:11.432033  4104 rl_tuner.py:432] Adding taking action portion of graph
WARNING:tensorflow:From C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\util\dispatch.py:1096: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
W0418 14:10:11.513855  4104 deprecation.py:551] From C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\util\dispatch.py:1096: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
INFO:tensorflow:Add estimating future rewards portion of graph
I0418 14:10:11.520846  4104 rl_tuner.py:460] Add estimating future rewards portion of graph
INFO:tensorflow:Adding q value prediction portion of graph
I0418 14:10:11.601579  4104 rl_tuner.py:494] Adding q value prediction portion of graph
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.196138  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.197395  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.198400  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.199422  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.201416  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.202384  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.202384  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.204405  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.205405  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.205405  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.207372  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.208369  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.209366  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.210363  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.211360  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.212355  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.213352  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.214352  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.215347  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.216344  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.217344  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0/gradients instead.
I0418 14:10:12.217344  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.218339  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0/gradients instead.
I0418 14:10:12.219336  4104 summary_op_util.py:66] Summary name q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0/gradients instead.
INFO:tensorflow:Summary name q_network/fully_connected/weights:0 is illegal; using q_network/fully_connected/weights_0 instead.
I0418 14:10:12.219336  4104 summary_op_util.py:66] Summary name q_network/fully_connected/weights:0 is illegal; using q_network/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name q_network/fully_connected/weights:0/gradients is illegal; using q_network/fully_connected/weights_0/gradients instead.
I0418 14:10:12.220337  4104 summary_op_util.py:66] Summary name q_network/fully_connected/weights:0/gradients is illegal; using q_network/fully_connected/weights_0/gradients instead.
INFO:tensorflow:Summary name q_network/fully_connected/biases:0 is illegal; using q_network/fully_connected/biases_0 instead.
I0418 14:10:12.221331  4104 summary_op_util.py:66] Summary name q_network/fully_connected/biases:0 is illegal; using q_network/fully_connected/biases_0 instead.
INFO:tensorflow:Summary name q_network/fully_connected/biases:0/gradients is illegal; using q_network/fully_connected/biases_0/gradients instead.
I0418 14:10:12.222336  4104 summary_op_util.py:66] Summary name q_network/fully_connected/biases:0/gradients is illegal; using q_network/fully_connected/biases_0/gradients instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.223325  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.224327  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.225323  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.225323  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.226318  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.227316  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.228315  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.229310  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.229310  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.230307  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.231304  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.232302  4104 summary_op_util.py:66] Summary name target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name target_q_network/fully_connected/weights:0 is illegal; using target_q_network/fully_connected/weights_0 instead.
I0418 14:10:12.233299  4104 summary_op_util.py:66] Summary name target_q_network/fully_connected/weights:0 is illegal; using target_q_network/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name target_q_network/fully_connected/biases:0 is illegal; using target_q_network/fully_connected/biases_0 instead.
I0418 14:10:12.234296  4104 summary_op_util.py:66] Summary name target_q_network/fully_connected/biases:0 is illegal; using target_q_network/fully_connected/biases_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.234296  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.235297  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.236291  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.237288  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.238286  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.239283  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.239283  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.241281  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.241281  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.242275  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
I0418 14:10:12.243272  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
I0418 14:10:12.247265  4104 summary_op_util.py:66] Summary name reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/fully_connected/weights:0 is illegal; using reward_rnn/fully_connected/weights_0 instead.
I0418 14:10:12.247265  4104 summary_op_util.py:66] Summary name reward_rnn/fully_connected/weights:0 is illegal; using reward_rnn/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name reward_rnn/fully_connected/biases:0 is illegal; using reward_rnn/fully_connected/biases_0 instead.
I0418 14:10:12.248262  4104 summary_op_util.py:66] Summary name reward_rnn/fully_connected/biases:0 is illegal; using reward_rnn/fully_connected/biases_0 instead.
INFO:tensorflow:Adding target network update portion of graph
I0418 14:10:12.323098  4104 rl_tuner.py:528] Adding target network update portion of graph
[<tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam_1:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam_1:0' shape=(256,) dtype=float32_ref>]
[<tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam_1:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam_1:0' shape=(256,) dtype=float32_ref>]
2022-04-18 14:10:12.364352: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-18 14:10:13.068385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6
INFO:tensorflow:Restoring variables from checkpoint
I0418 14:10:13.759770  4104 note_rnn_loader.py:292] Restoring variables from checkpoint
[<tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'target_q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'target_q_network/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'reward_rnn/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/weights:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'reward_rnn/fully_connected/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta1_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_value_prediction/beta2_power:0' shape=() dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1:0' shape=(1280, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_3/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_4/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/kernel/Adam_1:0' shape=(2048, 4096) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/rnn/multi_rnn_cell/cell_5/basic_lstm_cell/bias/Adam_1:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/weights/Adam_1:0' shape=(1024, 256) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'q_network/fully_connected/biases/Adam_1:0' shape=(256,) dtype=float32_ref>]
INFO:tensorflow:Checkpoint dir: D:\magenta-main\magenta
I0418 14:10:13.775319  4104 note_rnn_loader.py:298] Checkpoint dir: D:\magenta-main\magenta
Traceback (most recent call last):
  File ""rl_tuner_train.py"", line 154, in <module>
    console_entry_point()
  File ""rl_tuner_train.py"", line 150, in console_entry_point
    tf.app.run(main)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\absl\app.py"", line 303, in run
    _run_main(main, args)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""rl_tuner_train.py"", line 127, in main
    algorithm=FLAGS.algorithm)
  File ""D:\magenta-main\magenta\models\rl_tuner\rl_tuner.py"", line 248, in __init__
    self.initialize_internal_models_graph_session()
  File ""D:\magenta-main\magenta\models\rl_tuner\rl_tuner.py"", line 312, in initialize_internal_models_graph_session
    self.q_network.initialize_and_restore(self.session)
  File ""D:\magenta-main\magenta\models\rl_tuner\note_rnn_loader.py"", line 147, in initialize_and_restore
    self.restore_vars_from_checkpoint(self.checkpoint_dir)
  File ""D:\magenta-main\magenta\models\rl_tuner\note_rnn_loader.py"", line 299, in restore_vars_from_checkpoint
    checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\training\checkpoint_management.py"", line 352, in latest_checkpoint
    ckpt = get_checkpoint_state(checkpoint_dir, latest_filename)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\training\checkpoint_management.py"", line 280, in get_checkpoint_state
    coord_checkpoint_filename)
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 353, in read_file_to_string
    return f.read()
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 118, in read
    self._preread_check()
  File ""C:\Users\wzj1\.conda\envs\rl_tunner\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 81, in _preread_check
    compat.path_to_str(self.__name), 1024 * 512)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 80: invalid start byte
",whole python man import module location import please update use pin version alias present version import man import module location import please update use pin version alias present version import could find may work warn could find may work warning removed future version long term network network custom custom melody graph scope melody graph scope removed future version class equivalent cell add warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning class equivalent class equivalent warning removed future version please use cell equivalent removed future version please use cell equivalent removed future version please use method instead warning calling removed future version call instance argument instead passing constructor calling removed future version call instance argument instead passing constructor removed future version please use method instead removed future version please use method instead warning error primer file error primer file target network target network custom custom melody graph scope melody graph scope warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning class equivalent class equivalent warning error primer file error primer file reward network reward network custom custom melody graph scope melody graph scope warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning object state soon use object state soon use warning class equivalent class equivalent warning error primer file error primer file network cell object network cell object graph graph reward computation portion graph reward computation portion graph taking action portion graph taking action portion graph warning calling dimension removed future version use axis argument instead calling dimension removed future version use axis argument instead add future portion graph add future portion graph value prediction portion graph value prediction portion graph summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead target network update portion graph target network update portion graph binary deep neural network library use following enable rebuild appropriate compiler device memory device name bus id compute capability recent call last file line module file line main file line run file line run main file line main file line main file line file line file line file line file line file line file line return file line read file line ca decode position invalid start,issue,negative,negative,negative,negative,negative,negative
1099054420,"No clue why, but @Chinatown1444 solution worked for me! Weird as Magenta environment already requires the latest version of T2T...",clue solution worked weird magenta environment already latest version,issue,negative,neutral,neutral,neutral,neutral,neutral
1097842772,"I can confirm that this error is still producing when running from a mac terminal, but @iansimon solution still works! A massive thank you!",confirm error still running mac terminal solution still work massive thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1097512489,"It's working right now! Thanks A Lot!



---Original---
From: ""Ian ***@***.***&gt;
Date: Tue, Apr 12, 2022 05:32 AM
To: ***@***.***&gt;;
Cc: ***@***.******@***.***&gt;;
Subject: Re: [magenta/magenta] Generating Piano Music with Transformer forcolab bug (Issue #1988)




 
Annoyingly, you now need to downgrade numpy in order to make the notebook work.  We'll update the notebook soon, but for now you can add a cell before the first first cell that looks like:
 !pip install numpy==1.19  
After running that cell you will be prompted to (and must) restart the runtime.  Then, all the subsequent cells should work as is.
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",working right thanks lot date tue subject generating piano music transformer bug issue annoyingly need downgrade order make notebook work update notebook soon add cell first first cell like pip install running cell must restart subsequent work reply directly view id,issue,positive,positive,neutral,neutral,positive,positive
1096558912,"Same issue here. numba, python-rtmidi (pain in the butt to get installed) and llvmlite all installed independently. But magenta still giving errors:

Building wheels for collected packages: llvmlite
  Building wheel for llvmlite (setup.py) ... error
  error: subprocess-exited-with-error

  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> [24 lines of output]
      running bdist_wheel
      C:\Users\legen\AppData\Local\Programs\Python\Python39\python.exe C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py
      Trying generator 'Visual Studio 14 2015 Win64'
      Traceback (most recent call last):
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 192, in <module>
          main()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 180, in main
          main_win32()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 89, in main_win32
          generator = find_win32_generator()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 77, in find_win32_generator
          try_cmake(cmake_dir, build_dir, generator)
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 28, in try_cmake
          subprocess.check_call(['cmake', '-G', generator, cmake_dir])
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 368, in check_call
          retcode = call(*popenargs, **kwargs)
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 349, in call
          with Popen(*popenargs, **kwargs) as p:
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 951, in __init__
          self._execute_child(args, executable, preexec_fn, close_fds,
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 1420, in _execute_child
          hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
      FileNotFoundError: [WinError 2] The system cannot find the file specified
      error: command 'C:\\Users\\legen\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' failed with exit code 1
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building wheel for llvmlite
  Running setup.py clean for llvmlite
Failed to build llvmlite
Installing collected packages: llvmlite, gym-notices, gin-config, executing, dm-tree, bz2file, backcall, audioread, zope.interface, zope.event, typeguard, traitlets, tornado, tifffile, tensorflow-hub, sympy, sox, PyYAML, PyWavelets, prompt-toolkit, promise, pretty-midi, parso, numba, networkx, MarkupSafe, itsdangerous, intervaltree, imageio, gunicorn, greenlet, future, dill, decorator, cloudpickle, click, asttokens, tf-slim, tensorflow-probability, tensorflow-metadata, tensorflow-addons, stack-data, soundfile, sk-video, scikit-image, resampy, mir-eval, mesh-tensorflow, matplotlib-inline, Jinja2, jedi, gym, gevent, dm-sonnet, tensorflow-gan, tensorflow-datasets, librosa, kfac, IPython, flask, dopamine-rl, bokeh, note-seq, tensor2tensor, magenta
  Attempting uninstall: llvmlite
    Found existing installation: llvmlite 0.38.0
    Uninstalling llvmlite-0.38.0:
      Successfully uninstalled llvmlite-0.38.0
  Running setup.py install for llvmlite ... error
  error: subprocess-exited-with-error

  × Running setup.py install for llvmlite did not run successfully.
  │ exit code: 1
  ╰─> [27 lines of output]
      running install
      running build
      got version from file C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\llvmlite/_version.py {'version': '0.32.1', 'full': 'aa11b129c0b55973067422397821ae6d44fa5e70'}
      running build_ext
      C:\Users\legen\AppData\Local\Programs\Python\Python39\python.exe C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py
      Trying generator 'Visual Studio 14 2015 Win64'
      Traceback (most recent call last):
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 192, in <module>
          main()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 180, in main
          main_win32()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 89, in main_win32
          generator = find_win32_generator()
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 77, in find_win32_generator
          try_cmake(cmake_dir, build_dir, generator)
        File ""C:\Users\legen\AppData\Local\Temp\pip-install-vfkmfe55\llvmlite_83502f9aef2a450699eb92c40949888e\ffi\build.py"", line 28, in try_cmake
          subprocess.check_call(['cmake', '-G', generator, cmake_dir])
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 368, in check_call
          retcode = call(*popenargs, **kwargs)
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 349, in call
          with Popen(*popenargs, **kwargs) as p:
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 951, in __init__
          self._execute_child(args, executable, preexec_fn, close_fds,
        File ""C:\Users\legen\AppData\Local\Programs\Python\Python39\lib\subprocess.py"", line 1420, in _execute_child
          hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
      FileNotFoundError: [WinError 2] The system cannot find the file specified
      error: command 'C:\\Users\\legen\\AppData\\Local\\Programs\\Python\\Python39\\python.exe' failed with exit code 1
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
  WARNING: No metadata found in c:\users\legen\appdata\local\programs\python\python39\lib\site-packages
  Rolling back uninstall of llvmlite
  Moving to c:\users\legen\appdata\local\programs\python\python39\lib\site-packages\llvmlite-0.38.0.dist-info\
   from C:\Users\legen\AppData\Local\Programs\Python\Python39\Lib\site-packages\~lvmlite-0.38.0.dist-info
  Moving to c:\users\legen\appdata\local\programs\python\python39\lib\site-packages\llvmlite\
   from C:\Users\legen\AppData\Local\Programs\Python\Python39\Lib\site-packages\~lvmlite
error: legacy-install-failure

× Encountered error while trying to install package.
╰─> llvmlite


It looks like the issue is here when it tries to uninstalll then reinstall it: 

 Attempting uninstall: llvmlite
    Found existing installation: llvmlite 0.38.0
    Uninstalling llvmlite-0.38.0:
      Successfully uninstalled llvmlite-0.38.0
  Running setup.py install for llvmlite ... error
  error: subprocess-exited-with-error

This could be because llvmlite binaries aren't officially supported for python 3.9 so I got them off another website and manually installed.",issue pain butt get independently magenta still giving building collected building wheel error error python run successfully exit code output running trying generator studio recent call last file line module main file line main file line generator file line generator file line generator file line call file line call file line executable file line tid executable system find file error command exit code end output note error likely problem pip error building wheel running clean build collected tornado promise greenlet future dill decorator click jinja gym flask magenta found installation successfully uninstalled running install error error running install run successfully exit code output running install running build got version file running trying generator studio recent call last file line module main file line main file line generator file line generator file line generator file line call file line call file line executable file line tid executable system find file error command exit code end output note error likely problem pip warning found rolling back moving moving error error trying install package like issue reinstall found installation successfully uninstalled running install error error could officially python got another manually,issue,negative,positive,positive,positive,positive,positive
1095588993,"The numpy downgrade fix should work on a fresh runtime.  Just add a cell before the very first cell that looks like:

```
!pip uninstall -y numpy
!pip install numpy==1.19
```

You will then be prompted to restart the runtime, which you should.  After that, the subsequent cells should work.",downgrade fix work fresh add cell first cell like pip pip install restart subsequent work,issue,positive,positive,positive,positive,positive,positive
1095587618,"Annoyingly, you now need to downgrade numpy in order to make the notebook work.  We'll update the notebook soon, but for now you can add a cell before the first first cell that looks like:

```
!pip uninstall -y numpy
!pip install numpy==1.19
```

After running that cell you will be prompted to (and must) restart the runtime.  Then, all the subsequent cells should work as is.",annoyingly need downgrade order make notebook work update notebook soon add cell first first cell like pip pip install running cell must restart subsequent work,issue,negative,negative,neutral,neutral,negative,negative
1094575282,"It didn't work for me, but thanks anyway!



---Original---
From: ***@***.***&gt;
Date: Fri, Apr 8, 2022 14:18 PM
To: ***@***.***&gt;;
Cc: ***@***.******@***.***&gt;;
Subject: Re: [magenta/magenta] Colab notebook - Generating Piano Music with Transformer environment error (#1675)




 
I'm not sure it. I figured out that my issue was because I was in safari because I tried doing the same thing on another computer and was able to download it after switching to a windows laptop using chrome I believe. Maybe try that?
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you commented.Message ID: ***@***.***&gt;",work thanks anyway date subject notebook generating piano music transformer environment error sure figured issue safari tried thing another computer able switching chrome believe maybe try reply directly view id,issue,negative,positive,positive,positive,positive,positive
1092479979,I'm not sure it. I figured out that my issue was because I was in safari because I tried doing the same thing on another computer and was able to download it after switching to a windows laptop using chrome I believe. Maybe try that?,sure figured issue safari tried thing another computer able switching chrome believe maybe try,issue,negative,positive,positive,positive,positive,positive
1086240982,"Same issues: 
ERROR: kfac 0.2.4 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.16.0 which is incompatible.
ERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.16.0 which is incompatible.",error requirement incompatible error requirement incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
1080898297,"No sorry.

On Mon, Mar 28, 2022 at 11:34 AM aadarshb09 ***@***.***>
wrote:

> Did you end up fixing this error? I have the same issue
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1878#issuecomment-1080804392>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACBHMRNC3SJ3P2N65XLOPTDVCHGQFANCNFSM4WBA6R4A>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",sorry mon mar wrote end fixing error issue reply directly view id,issue,negative,negative,negative,negative,negative,negative
1080804392,Did you end up fixing this error? I have the same issue,end fixing error issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1080395236,"i think the wrong version of numpy may be part of this problem.However, i get another bug about the _=next(unconditional_model) and i dont know how to solve it.
it seems that something is missing in the checkpoint
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):
<tf.Operation 'transformer/while/assert_greater/Assert/AssertGuard/Merge' type=Merge>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/check_ops.py"", line 1044, in assert_greater
    y, data, summarize, message, name)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/check_ops.py"", line 425, in _binary_assert
    return control_flow_ops.Assert(condition, data, summarize=summarize)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py"", line 155, in error_handler
    del filtered_tb  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py"", line 1082, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 245, in wrapped
    error_in_function=error_in_function)
==================================
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):
<tf.Operation 'transformer/while/assert_greater/Assert/AssertGuard/Merge' type=Merge>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/check_ops.py"", line 1044, in assert_greater
    y, data, summarize, message, name)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/check_ops.py"", line 425, in _binary_assert
    return control_flow_ops.Assert(condition, data, summarize=summarize)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py"", line 155, in error_handler
    del filtered_tb  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py"", line 1082, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 245, in wrapped
    error_in_function=error_in_function)
==================================
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /content/unconditional_model_16.ckpt
INFO:tensorflow:Restoring parameters from /content/unconditional_model_16.ckpt
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
[/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py](https://localhost:8080/#) in _do_call(self, fn, *args)
   1376     try:
-> 1377       return fn(*args)
   1378     except errors.OpError as e:

23 frames
NotFoundError: 2 root error(s) found.
  (0) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
	 [[save/RestoreV2_1/_55]]
  (1) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
NotFoundError: Graph execution error:

Detected at node 'save/RestoreV2_1' defined at (most recent call last):
    File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
      ""__main__"", mod_spec)
    File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
      exec(code, run_globals)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
      app.launch_new_instance()
    File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
      app.start()
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
      self.io_loop.start()
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
      self.asyncio_loop.run_forever()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
      self._run_once()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
      handle._run()
    File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
      self._context.run(self._callback, *self._args)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
      handler_func(fileobj, events)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
      self._handle_recv()
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
      self._run_callback(callback, msg)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
      callback(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
      return self.dispatch_shell(stream, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
      handler(stream, idents, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
      user_expressions, allow_stdin)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
      interactivity=interactivity, compiler=compiler, result=result)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
      if self.run_code(code, result):
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
      _ = next(unconditional_samples)
    File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
      hooks=all_hooks) as mon_sess:
Node: 'save/RestoreV2_1'
Detected at node 'save/RestoreV2_1' defined at (most recent call last):
    File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
      ""__main__"", mod_spec)
    File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
      exec(code, run_globals)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
      app.launch_new_instance()
    File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
      app.start()
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
      self.io_loop.start()
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
      self.asyncio_loop.run_forever()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
      self._run_once()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
      handle._run()
    File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
      self._context.run(self._callback, *self._args)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
      handler_func(fileobj, events)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
      self._handle_recv()
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
      self._run_callback(callback, msg)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
      callback(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
      return self.dispatch_shell(stream, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
      handler(stream, idents, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
      user_expressions, allow_stdin)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
      interactivity=interactivity, compiler=compiler, result=result)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
      if self.run_code(code, result):
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
      _ = next(unconditional_samples)
    File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
      hooks=all_hooks) as mon_sess:
Node: 'save/RestoreV2_1'
2 root error(s) found.
  (0) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
	 [[save/RestoreV2_1/_55]]
  (1) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'save/RestoreV2_1':
  File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
    self.io_loop.start()
  File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
    self.asyncio_loop.run_forever()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
    self._run_once()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
    handle._run()
  File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
    self._context.run(self._callback, *self._args)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
    handler_func(fileobj, events)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
    _ = next(unconditional_samples)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
    hooks=all_hooks) as mon_sess:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1058, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 757, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1263, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1268, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 910, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 668, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 232, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""[/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py](https://localhost:8080/#)"", line 621, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 919, in __init__
    self.build()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 931, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 969, in _build
    build_restore=build_restore)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 524, in _build_internal
    restore_sequentially, reshape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 403, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 350, in _AddRestoreOps
    restore_sequentially)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 597, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1504, in restore_v2
    name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 3784, in _create_op_internal
    op_def=op_def)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 2175, in __init__
    self._traceback = tf_stack.extract_stack_for_node(self._c_op)


During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)
   1415         # a helpful message (b/110263146)
   1416         raise _wrap_restore_error_with_msg(
-> 1417             err, ""a Variable name or other graph key that is missing"")
   1418 
   1419       # This is an object-based checkpoint. We'll print a warning and then do

NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Graph execution error:

Detected at node 'save/RestoreV2_1' defined at (most recent call last):
    File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
      ""__main__"", mod_spec)
    File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
      exec(code, run_globals)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
      app.launch_new_instance()
    File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
      app.start()
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
      self.io_loop.start()
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
      self.asyncio_loop.run_forever()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
      self._run_once()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
      handle._run()
    File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
      self._context.run(self._callback, *self._args)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
      handler_func(fileobj, events)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
      self._handle_recv()
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
      self._run_callback(callback, msg)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
      callback(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
      return self.dispatch_shell(stream, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
      handler(stream, idents, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
      user_expressions, allow_stdin)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
      interactivity=interactivity, compiler=compiler, result=result)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
      if self.run_code(code, result):
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
      _ = next(unconditional_samples)
    File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
      hooks=all_hooks) as mon_sess:
Node: 'save/RestoreV2_1'
Detected at node 'save/RestoreV2_1' defined at (most recent call last):
    File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
      ""__main__"", mod_spec)
    File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
      exec(code, run_globals)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
      app.launch_new_instance()
    File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
      app.start()
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
      self.io_loop.start()
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
      self.asyncio_loop.run_forever()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
      self._run_once()
    File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
      handle._run()
    File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
      self._context.run(self._callback, *self._args)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
      handler_func(fileobj, events)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
      self._handle_recv()
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
      self._run_callback(callback, msg)
    File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
      callback(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
      return self.dispatch_shell(stream, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
      handler(stream, idents, msg)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
      user_expressions, allow_stdin)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
      interactivity=interactivity, compiler=compiler, result=result)
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
      if self.run_code(code, result):
    File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
      _ = next(unconditional_samples)
    File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
      hooks=all_hooks) as mon_sess:
Node: 'save/RestoreV2_1'
2 root error(s) found.
  (0) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
	 [[save/RestoreV2_1/_55]]
  (1) NOT_FOUND: Key transformer/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'save/RestoreV2_1':
  File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 499, in start
    self.io_loop.start()
  File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 132, in start
    self.asyncio_loop.run_forever()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
    self._run_once()
  File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
    handle._run()
  File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
    self._context.run(self._callback, *self._args)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 122, in _handle_events
    handler_func(fileobj, events)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 452, in _handle_events
    self._handle_recv()
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 481, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py"", line 431, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py"", line 300, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-10-46025b3d678c>"", line 56, in <module>
    _ = next(unconditional_samples)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict
    hooks=all_hooks) as mon_sess:
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1058, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 757, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1263, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1268, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 910, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 668, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 232, in finalize
    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 621, in _get_saver_or_default
    saver = Saver(sharded=True, allow_empty=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 919, in __init__
    self.build()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 931, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 969, in _build
    build_restore=build_restore)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 524, in _build_internal
    restore_sequentially, reshape)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 403, in _AddShardedRestoreOps
    name=""restore_shard""))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 350, in _AddRestoreOps
    restore_sequentially)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py"", line 597, in bulk_restore
    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1504, in restore_v2
    name=name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 3784, in _create_op_internal
    op_def=op_def)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 2175, in __init__
    self._traceback = tf_stack.extract_stack_for_node(self._c_op)


",think wrong version may part get another bug dont know solve something missing error object never used type class want mark used call method originally file line data summarize message name file line return condition data file line file line return file line wrapped error object never used type class want mark used call method originally file line data summarize message name file line return condition data file line file line return file line wrapped done calling done calling graph graph recent call last self try return except root error found key found node key found node successful derived handling exception another exception recent call last graph execution error node defined recent call last file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict node node defined recent call last file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict node root error found key found node key found node successful derived original stack trace file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict file line file line file line self file line return file line file line file line finalize file line saver saver file line file line build file line file line reshape file line file line file line return file line file line file line file line handling exception another exception recent call last key found handling exception another exception recent call last key found handling exception another exception recent call last restore self sess helpful message raise err variable name graph key missing print warning likely due variable name graph key missing please ensure graph based original error graph execution error node defined recent call last file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict node node defined recent call last file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict node root error found key found node key found node successful derived original stack trace file line file line code file line module file line file line start file line start file line file line file line file line file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file line module next file line predict file line file line file line self file line return file line file line file line finalize file line saver saver file line file line build file line file line reshape file line file line file line return file line file line file line file line,issue,positive,positive,neutral,neutral,positive,positive
1062059981,"Sorry, I think this question is about another codebase, not magenta.",sorry think question another magenta,issue,negative,negative,negative,negative,negative,negative
1056682570,Hi. I managed to fix the problem for myself by cloning the latest [tensor2tensor](https://github.com/tensorflow/tensor2tensor) master branch and installing it by using `pip install -e .` in the local tensor2tensor repository.,hi fix problem latest master branch pip install local repository,issue,negative,positive,positive,positive,positive,positive
1053667579,"The errors appear when the IDE tries to: 
""Building wheels for collected packages: numba, python-rtmidi, llvmlite""

I can successfully install all these three packages on my machine manually using pip:

pip install numba
pip install python-rtmidi
pip install llvmlite

But when I run the command ""pip install magenta"", it issues an error installing these three packages.",appear ide building collected successfully install three machine manually pip pip install pip install pip install run command pip install magenta error three,issue,negative,positive,positive,positive,positive,positive
1053605123,"Another cause of the error I have faced during the MAGENTA installation on my local machine. You can find my machine configuration in my earlier message above.
(I tried using different ways to install the MAGENTA, but unfortunately, any time I tried I got a new error!)

I have used the following command:

python -m venv _magenta_env_
magenta_env\Script\activate.bat
pip install magenta

####################################################################################

....
....
Running setup.py install for llvmlite ... error
    ERROR: Command errored out with exit status 1:
     command: 'C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\Scripts\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\pip-install-px9bg341\\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\\setup.py'""'""'; __file__='""'""'C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\pip-install-px9bg341\\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\\setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-record-phr_mua7\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\include\site\python3.10\llvmlite'
         cwd: C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\
    Complete output (27 lines):
    running install
    running build
    got version from file C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\llvmlite/_version.py {'version': '0.32.1', 'full': 'aa11b129c0b55973067422397821ae6d44fa5e70'}
    running build_ext
    C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\Scripts\python.exe C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py
    Trying generator 'Visual Studio 14 2015 Win64'
    Traceback (most recent call last):
      File ""C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py"", line 192, in <module>
        main()
      File ""C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py"", line 180, in main
        main_win32()
      File ""C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py"", line 89, in main_win32
        generator = find_win32_generator()
      File ""C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py"", line 77, in find_win32_generator
        try_cmake(cmake_dir, build_dir, generator)
      File ""C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-px9bg341\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\ffi\build.py"", line 28, in try_cmake
        subprocess.check_call(['cmake', '-G', generator, cmake_dir])
      File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\subprocess.py"", line 364, in check_call
        retcode = call(*popenargs, **kwargs)
      File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\subprocess.py"", line 345, in call
        with Popen(*popenargs, **kwargs) as p:
      File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\subprocess.py"", line 966, in __init__
        self._execute_child(args, executable, preexec_fn, close_fds,
      File ""C:\Users\User\AppData\Local\Programs\Python\Python310\lib\subprocess.py"", line 1435, in _execute_child
        hp, ht, pid, tid = _winapi.CreateProcess(executable, args,
    FileNotFoundError: [WinError 2] The system cannot find the file specified
    error: command 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\magenta_env\\Scripts\\python.exe' failed with exit code 1
    ----------------------------------------
ERROR: Command errored out with exit status 1: 'C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\Scripts\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\pip-install-px9bg341\\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\\setup.py'""'""'; __file__='""'""'C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\pip-install-px9bg341\\llvmlite_b2de6523b6f5445ca60ea2d3d6834c92\\setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-record-phr_mua7\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\include\site\python3.10\llvmlite' Check the logs for full command output.
WARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.
You should consider upgrading via the 'C:\Users\User\AppData\Local\Programs\Python\Python310\magenta_env\Scripts\python.exe -m pip install --upgrade pip' command.

###################################################################################

**After getting this error, I tried to install ""llvmlite"" manually using ""pip"" (pip install llvmlite), but again I got the following error:

Collecting tensorflow-hub>=0.2
Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)
Using legacy 'setup.py install' for numba, since package 'wheel' is not installed.
Using legacy 'setup.py install' for llvmlite, since package 'wheel' is not installed.
Using legacy 'setup.py install' for python-rtmidi, since package 'wheel' is not installed.
Attempting uninstall: llvmlite
    Found existing installation: llvmlite 0.38.0
    Uninstalling llvmlite-0.38.0:
      Successfully uninstalled llvmlite-0.38.0
    Running setup.py install for llvmlite ... error**

Any help would be appreciated!",another cause error faced magenta installation local machine find machine configuration message tried different way install magenta unfortunately time tried got new error used following command python pip install magenta running install error error command exit status command io o open else import setup setup code compile code install record compile complete output running install running build got version file running trying generator studio recent call last file line module main file line main file line generator file line generator file line generator file line call file line call file line executable file line tid executable system find file error command exit code error command exit status io o open else import setup setup code compile code install record compile check full command output warning pip version however version available consider via pip install upgrade pip command getting error tried install manually pip pip install got following error legacy install since package legacy install since package legacy install since package found installation successfully uninstalled running install error help would,issue,negative,positive,neutral,neutral,positive,positive
1049261175,"The issue is that Colab comes with numpy version 1.21.5 by default. I'm not sure the exact issue, but has to do with the notebook only using tensorflow 1.x. Seems like it isn't until tensorflow 2.x that they allow ops to be represented as numpy arrays?

The solution is to get an earlier version of numpy.

In the first code block (""Environment Setup"") I added
`!pip uninstall numpy`

`!pip install numpy==1.19.5`

In order for it to take effect, you need to run this code block once after connecting, then restart the runtime and run it all again.",issue come version default sure exact issue notebook like allow solution get version first code block environment setup added pip pip install order take effect need run code block restart run,issue,negative,positive,positive,positive,positive,positive
1039722829,@zkpowergrind no I was not.  The only solution I found was to install [pyenv](https://github.com/pyenv/pyenv) and set it to Python 3.7.,solution found install set python,issue,negative,neutral,neutral,neutral,neutral,neutral
1039545710,"Hey alembcke, 

Were you able to get Magenta running on Python 3.8 or greater yet?",hey able get magenta running python greater yet,issue,negative,positive,positive,positive,positive,positive
1037983476,Hello. I also have the same problem. Are there any solutions yet?,hello also problem yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1021398069,"@wraybowling Last year this issue was such a headache, I ended up tossing magenta for a custom built model in tensorflow.  Unless the devs respond with a quick fix on how to integrate Magenta on ARM, I would recommend using another package. The other option is to use an API. Depending on your needs, you can use magenta.js to call magentas pre-trained models. If your trying to retrain the models, you could use a server and build your own API calls. I know this isn't the answer you are looking for, but I hope it is insightful all the same.",last year issue headache ended tossing magenta custom built model unless respond quick fix integrate magenta arm would recommend another package option use depending need use call trying retrain could use server build know answer looking hope insightful,issue,positive,positive,positive,positive,positive,positive
1019306975,"I am in a similar boat. I've got a newer portable Linux machine using an ARM64 Rockfish CPU. I'm told these will be increasingly common, a Jetson Nano which is also ARM64, and an M1 Mac Mini which yet again is ARM64. I'm blocked on basically all fronts.",similar boat got portable machine arm rockfish told increasingly common also arm mac yet arm blocked basically,issue,negative,negative,negative,negative,negative,negative
999608028,"> in note_rnn_loader.py:
> 
> print('var_dict: ', var_dict) if '/Adam' in var.name: # TODO(lukaszkaiser): investigate the problem here and remove this hack. pass elif self.note_rnn_type == 'basic_rnn':
> 
> * ```
>      print(""debuggggingg!!!!!!!!!!!!!!!!!!!***********"")
>      var_dict[inner_name] = var
>    else:
>   ```
> 
> * ```
>      var_dict[self.checkpoint_scope + '/' + inner_name] = var
>   ```
> 
> * ```
>      print(""debuggggingg!!!!!"")
>   ```
> * ```
>      scope = self.checkpoint_scope + '/' + inner_name
>   ```
> * ```
>      print(""scope: "", scope)
>   ```
> * ```
>      print(""var: "", var)
>   ```
> * ```
>      if scope == 'rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias':
>   ```
> * ```
>        var_dict['rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/B'] = var
>   ```
> * ```
>      elif scope == 'rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel':
>   ```
> * ```
>        var_dict['rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0'] = var
>   ```

Useful! Now its running due to this solution! thx!",print investigate problem remove hack pas print else print scope print scope scope print scope scope useful running due solution,issue,negative,positive,neutral,neutral,positive,positive
998650589,"I'm trying this and it's not letting me do it. I've tried at least 10 times

<img width=""660"" alt=""Screen Shot 2021-12-21 at 5 16 00 AM"" src=""https://user-images.githubusercontent.com/67026227/146912883-efbfa7eb-de29-4102-a1c6-6848ad763f1f.png"">

",trying tried least time screen shot,issue,negative,negative,negative,negative,negative,negative
998156121,"The version from the MAESTRO paper 28M parameters. I think we forgot to mention that in the MAESTRO paper, but we do discuss it in the Sequence-to-Sequence Piano Transcription paper: https://arxiv.org/pdf/2107.09142.pdf (section 3.1)",version maestro paper think forgot mention maestro paper discus piano transcription paper section,issue,negative,neutral,neutral,neutral,neutral,neutral
982022992,I am having the same problem but on my M1 Mac. pip install magenta is not working neither due to the updated dependancies. ,problem mac pip install magenta working neither due,issue,negative,negative,negative,negative,negative,negative
971489296,Same here when running in colab. Any idea what is causing this? I am inclined to think it is a TF version compatibility issue.,running idea causing think version compatibility issue,issue,negative,neutral,neutral,neutral,neutral,neutral
970791678,"Hi @Thanyanit-J, you're right that those aren't standard MIDI notes. They come as a result of using a Roland drum kit to do the recording, which uses a non-standard set of notes to represent different hits.

You can see the full mapping in the dataset E-GMD was based on: [Groove MIDI Dataset](https://g.co/magenta/groove-dataset).

You may also find the mappings we used for our paper useful in [Table 2](https://goo.gl/magenta/e-gmd-paper) or in [drump_mappings.py](https://github.com/magenta/magenta/blob/main/magenta/models/onsets_frames_transcription/drum_mappings.py).

Let me know if you have any other questions!",hi right standard come result drum kit recording set represent different see full based groove may also find used paper useful table let know,issue,negative,positive,positive,positive,positive,positive
929844654,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fmagenta%2Fmagenta%2Fpull%2F1953) for more info**.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account information go,issue,positive,positive,neutral,neutral,positive,positive
903834488,"I'm getting the same error, and its a common TF error.
When I record it works fine",getting error common error record work fine,issue,negative,positive,neutral,neutral,positive,positive
895953032,"I ran into the same issue. I am trying to use the GrooVAE model to generate predictions for predetermined note sequences so that I can compare its performance against a different model's performance. (I am using the Tap2Drum model, and the drumify function as defined in the GrooVAE colab notebook).
For example, this sequence always raises the NoExtractedExamplesError:
```
time_signatures {
  numerator: 4
  denominator: 4
}
tempos {
  qpm: 130.00013000013
}
notes {
  pitch: 42
  velocity: 10
  start_time: 0.15769214999999998
  end_time: 0.21538439999999986
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 48
  start_time: 0.2721151125
  end_time: 0.32980736249999987
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 79
  start_time: 0.2999997
  end_time: 0.35769194999999987
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 14
  start_time: 0.45961492499999995
  end_time: 0.5173071749999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 74
  start_time: 0.6173070749999999
  end_time: 0.6749993249999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 14
  start_time: 0.7798069124999999
  end_time: 0.8374991624999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 103
  start_time: 0.9346144499999999
  end_time: 0.9923066999999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 62
  start_time: 1.0894219875
  end_time: 1.1471142374999999
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 56
  start_time: 1.236537225
  end_time: 1.2942294749999999
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 127
  start_time: 1.3913447625
  end_time: 1.4490370124999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 93
  start_time: 1.5461523
  end_time: 1.6038445499999998
  instrument: 9
  is_drum: true
}
notes {
  pitch: 42
  velocity: 26
  start_time: 1.6903829249999998
  end_time: 1.7480751749999996
  instrument: 9
  is_drum: true
}
total_time: 1.7480751749999996
```

thank you in advance! 😄 ",ran issue trying use model generate note compare performance different model performance model function defined notebook example sequence always numerator denominator pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true pitch velocity instrument true thank advance,issue,positive,positive,positive,positive,positive,positive
895342718,"HI @cghawthorne ! 

I have one question for you.
Is it okay to send the PR that I uploaded the flutter plugin link that I developed on /onsets_frames_transcription/realtime/readme ?",hi one question send flutter link,issue,negative,neutral,neutral,neutral,neutral,neutral
894811659,"I've met the same error as you mister. Ddi you mix it? I have got no idea how to fix this bug, If you fix it, please tell me. Thank you very much!",met error mister mix got idea fix bug fix please tell thank much,issue,negative,positive,positive,positive,positive,positive
892453720,"Yes, it works well with .wav files. Thanks",yes work well thanks,issue,positive,positive,positive,positive,positive,positive
892268611,I think the audio pipeline on colab doesn't support mp3s. Can you try uploading a .wav?,think audio pipeline support try,issue,negative,neutral,neutral,neutral,neutral,neutral
891958651,I have the same error when I try to run locally,error try run locally,issue,negative,neutral,neutral,neutral,neutral,neutral
891915873,"I can confirm this issue. I'm running `magenta==2.1.3` with `Python 3.8.8` and the `polyphony_rnn_generate` command always includes the primer on the output.

It looks like a bug with the `config['no_inject_primer_during_generation']` and `config['inject_primer_during_generation']` flags - they seem to have no effect over the output of the `PolyphonyRnnSequenceGenerator`.

",confirm issue running python command always primer output like bug seem effect output,issue,negative,neutral,neutral,neutral,neutral,neutral
888003679,"> Wow, that's great! Do you have a demo we could link to?

@cghawthorne  I uploaded a short demo video to my repository readme!
Here is the link. https://github.com/WonyJeong/flutter_piano_audio_detection

",wow great could link short video repository link,issue,positive,positive,positive,positive,positive,positive
887092216,"Wow, that's great! Do you have a demo we could link to?",wow great could link,issue,positive,positive,positive,positive,positive,positive
886005257,"I read the paper and got an understanding of the output of onsets_frames_wavinput.tflite.
And by processing onset and frame, the code for recognizing the piano keyboard was completed.

I have distributed a flutter plugin applicable to iOS and Android, except for the method channel code for communication between flutter and native, it can be applied to react-native, kotlin, and swift as well.

Here is the link.

https://pub.dev/packages/flutter_piano_audio_detection",read paper got understanding output onset frame code piano keyboard distributed flutter applicable android except method channel code communication flutter native applied swift well link,issue,negative,neutral,neutral,neutral,neutral,neutral
871747553,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fmagenta%2Fmagenta%2Fpull%2F1939) for more info**.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm order pas check please resolve problem comment fixed bot comment think anything information go,issue,positive,negative,neutral,neutral,negative,negative
864565047,"Hi @markhanslip and @Junpyer, I see that we are in the same situation, were you able to make any progress ?

Thank you for your consideration.",hi see situation able make progress thank consideration,issue,positive,positive,positive,positive,positive,positive
864564759,"Hi, were you able to figure it out ? I have the same issue",hi able figure issue,issue,negative,positive,positive,positive,positive,positive
860996656,I wouldn't recommend trying to train the whole model on colab because of the limited access to accelerators and limited time you can use them. We trained the piano Onsets and Frames models on 3 P100 GPUs and the Drums model on 16 TPUv3 cores.,would recommend trying train whole model limited access limited time use trained piano model,issue,negative,positive,neutral,neutral,positive,positive
860797270,Actually i fixed the error thanks a lot however i can't train the model on colab could you please specify what did you train your model on??,actually fixed error thanks lot however ca train model could please specify train model,issue,negative,positive,positive,positive,positive,positive
860150532,"Thank you for your reply, thank you very much!",thank reply thank much,issue,positive,positive,positive,positive,positive,positive
859717919,"Hi @chris666-sys, unfortunately this isn't entirely unexpected. In the very first few steps of the model, you're correct that it will output a lot of random garbage, with a lot of predicted notes. But quickly after that, the model learns that for any given ""pitch"" (kind of drum hit) and timestep combination, silence is more likely than anything else, so the model switches to predicting zero or very few notes. Only after training longer than that will you start to see note prediction results.

I don't remember offhand how many steps each of those ""phases"" of learning lasted, but outputting 0 notes after 4.2k steps seems in line with what I'd expect.

Unfortunately, for a model and dataset of this size, I think you'll need more accelerator resources for practical training. For the model in the paper, we used 16 TPUv3 cores over 3 days. In GPUs, that's around the same as 16 V100 GPUs. So, not only parallelizing across more GPUs than you're using, but considerably more powerful than a K80 too.

Perhaps for your use case it would work to start with our pretrained model and finetune it rather than training from scratch?",hi unfortunately entirely unexpected first model correct output lot random garbage lot quickly model given pitch kind drum hit combination silence likely anything else model zero training longer start see note prediction remember offhand many phase learning line expect unfortunately model size think need accelerator practical training model paper used day around across considerably powerful perhaps use case would work start model rather training scratch,issue,negative,positive,positive,positive,positive,positive
859220678,"> I'm not sure exactly what all is happening here, but keep in mind that the original MAESTRO paper had results for MAESTRO v1, which is not comparable to MAESTRO v3 because they have different test sets.

i did reevaluate the test data of v1 , but metrics still quite different with those in the  Paper which are much better....
 any advance?  thx.",sure exactly happening keep mind original maestro paper maestro comparable maestro different test test data metric still quite different paper much better advance,issue,positive,positive,positive,positive,positive,positive
857322287,"> TRO paper had results for MAESTRO v1, which is not comparable to MAESTRO v3 because they have different test sets.

thank u :) 
I'll  reevaluate on the test data of V1",paper maestro comparable maestro different test thank test data,issue,negative,neutral,neutral,neutral,neutral,neutral
855335526,"@cghawthorne Thank you for your reply and guidance, thank you very much！",thank reply guidance thank,issue,positive,neutral,neutral,neutral,neutral,neutral
855159360,"I'm not sure exactly what all is happening here, but keep in mind that the original MAESTRO paper had results for MAESTRO v1, which is not comparable to MAESTRO v3 because they have different test sets.",sure exactly happening keep mind original maestro paper maestro comparable maestro different test,issue,positive,positive,positive,positive,positive,positive
855159000,"I think the issue is that after running `onsets_frames_transcription_create_tfrecords`, you still need to run `onsets_frames_transcription_create_dataset` with the relevant flags to process the data for training.

The error that you're seeing indicates that the data is longer than expected for training: https://github.com/magenta/magenta/blob/master/magenta/models/onsets_frames_transcription/data.py#L375 The create_dataset script will take care of splitting full length examples into shorter sequences for training.",think issue running still need run relevant process data training error seeing data longer training script take care splitting full length shorter training,issue,negative,positive,positive,positive,positive,positive
855156094,Glad to hear that it worked for you. Would you mind sending a PR with your fix?,glad hear worked would mind sending fix,issue,negative,positive,positive,positive,positive,positive
855155586,"It looks like the prediction loop finished immediately. Can you verify that `/content/drive/MyDrive/maps/maps_config2_test.tfrecord` contains the records you want to use?

Also, it looks like you're loading `/content/drive/MyDrive/NewTrain/model.ckpt-0`, which seems like a model that was trained for 0 steps. Is that what you're wanting to do?",like prediction loop finished immediately verify want use also like loading like model trained wanting,issue,positive,neutral,neutral,neutral,neutral,neutral
855149657,"Hmm, that's definitely odd. I wonder if a new Tensorflow version has changed where the adam weights are expected to be stored. Can you provide a full stacktrace ?",definitely odd wonder new version provide full,issue,negative,positive,positive,positive,positive,positive
855142592,"Hi @samar-fathallah. I agree that the error message is annoying (a few of our transitive dependencies have conflicting requirements), but the colab should continue to work even with the error. Are you unable to upload a file for transcription if you just let it continue running?",hi agree error message annoying transitive conflicting continue work even error unable file transcription let continue running,issue,negative,negative,negative,negative,negative,negative
854422169,"> to upgrade to 0.4

hey, i had the same issue when i use the pretrained model to evaluate on the test dataset (detailed in https://github.com/magenta/magenta/issues/1920)

 the magenta version is 2.1.3 and tensorflow version is  2.4.1 , can u tell me how to solve such issue?

",upgrade hey issue use model evaluate test detailed magenta version version tell solve issue,issue,negative,positive,positive,positive,positive,positive
851952304,"Hello,

@cghawthorne @SashaBurashnikova 

I am not good at English, Hope to hear from you, very grateful...

I am trying to train drums model on GPU (not TPU) using E-GMD dataset (run drum config in onset and frames model on GPU).

1. First I used (onsets_frames_transcription_create_tfrecords script) to get (train.tfrecord-00000-of-00001 file), and then started to use the official method of github (TPUonsets_frames_transcription_train script) to try training...

2.I set ('config', ‘drums’,’use_tpu’, False) in the (onsets_frames_transcription_train.py) file

3. Then I continue to try the above solutions, because I have the same error
   optimizer=‘Adam’,
   tf.tpu.estimator.TPUEstimatorSpec -> tf.estimator.EstimatorSpec

4. But got this errors:

**tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: assertion failed: [Condition x <= y did not hold element-wise:] [x (wav_to_num_frames_op:0) = ] [178] [y (assert_less_equal
/y:0) = ] [100]
         [[{{node assert_less_equal/Assert/Assert}}]]
         [[IteratorGetNext]]
  (1) Invalid argument: assertion failed: [Condition x <= y did not hold element-wise:] [x (wav_to_num_frames_op:0) = ] [178] [y (assert_less_equal
/y:0) = ] [100]
         [[{{node assert_less_equal/Assert/Assert}}]]
         [[IteratorGetNext]]
         [[IteratorGetNext/_1047]]**


5.Thank you very much for your reply！",hello good hope hear grateful trying train model run drum onset model first used script get file use official method script try training set false file continue try error got root error found invalid argument assertion condition hold node invalid argument assertion condition hold node much,issue,negative,positive,positive,positive,positive,positive
850867410,what did you write exactly on windows to run the model plz??,write exactly run model,issue,negative,positive,positive,positive,positive,positive
849271647,"> Hmm, perhaps something changed with a recent version of TensorFlow. We do leave the loss as None during eval: https://github.com/magenta/magenta/blob/master/magenta/models/onsets_frames_transcription/model.py#L375
> 
> You could try changing that so that `loss = tf.losses.get_total_loss()` for both train and eval mode and see if that works.

i made the changes as you mentioned, it works. 
thank u.",perhaps something recent version leave loss none could try loss train mode see work made work thank,issue,negative,neutral,neutral,neutral,neutral,neutral
849096673,"Hmm, perhaps something changed with a recent version of TensorFlow. We do leave the loss as None during eval: https://github.com/magenta/magenta/blob/master/magenta/models/onsets_frames_transcription/model.py#L375

You could try changing that so that `loss = tf.losses.get_total_loss()` for both train and eval mode and see if that works.",perhaps something recent version leave loss none could try loss train mode see work,issue,negative,neutral,neutral,neutral,neutral,neutral
847589007,"> First, I use MAPS dataset as inference material, just ENSTDkAm/MUS this part.
> The test.tfrecord-00003-of-00004 just seems to loss some data when inference.
> And using [this code](https://github.com/tensorflow/magenta/tree/master/magenta/models/onsets_frames_transcription#maps-dataset-optional) converts dataset to TFrecord file.
> Then by pre-trained [checkpoint](https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/maestro_checkpoint.zip) infering adding the argument `--preprocess_examples=True`.
> It works, but `tensorboard --logdir=""${OUTPUT_DIR}""`, I got some results,
> ![metrics1](https://user-images.githubusercontent.com/48265203/66396432-53ec1a00-ea0c-11e9-90e1-c24f2db748b2.png)
> So, where am I wrong? Thanks!
hey, i  got such results too,  how u solve it？ 

INFO:tensorflow:Saving dict for global step 100: global_step = 100, loss = 0.39757368, losses/frame = 0.21719432, losses/offset = 0.048358064, losses/onset = 0.04870561, losses/velocity = 0.07781867, metrics/frame_accuracy = 0.9231014, metrics/frame_accuracy_without_true_negatives = 0.0, metrics/frame_f1_score = 0.0, metrics/frame_precision = 0.0, metrics/frame_recall = 0.0, metrics/note_density = 0.0, metrics/note_f1_score = 0.0, metrics/note_precision = 0.0, metrics/note_recall = 0.0, metrics/note_with_offsets_f1_score = 0.0, metrics/note_with_offsets_precision = 0.0, metrics/note_with_offsets_recall = 0.0, metrics/note_with_offsets_velocity_f1_score = 0.0, metrics/note_with_offsets_velocity_precision = 0.0, metrics/note_with_offsets_velocity_recall = 0.0, metrics/note_with_velocity_f1_score = 0.0, metrics/note_with_velocity_precision = 0.0, metrics/note_with_velocity_recall = 0.0
I0525 11:41:23.122856 139871819388672 estimator.py:2066] Saving dict for global step 100: global_step = 100, loss = 0.39757368, losses/frame = 0.21719432, losses/offset = 0.048358064, losses/onset = 0.04870561, losses/velocity = 0.07781867, metrics/frame_accuracy = 0.9231014, metrics/frame_accuracy_without_true_negatives = 0.0, metrics/frame_f1_score = 0.0, metrics/frame_precision = 0.0, metrics/frame_recall = 0.0, metrics/note_density = 0.0, metrics/note_f1_score = 0.0, metrics/note_precision = 0.0, metrics/note_recall = 0.0, metrics/note_with_offsets_f1_score = 0.0, metrics/note_with_offsets_precision = 0.0, metrics/note_with_offsets_recall = 0.0, metrics/note_with_offsets_velocity_f1_score = 0.0, metrics/note_with_offsets_velocity_precision = 0.0, metrics/note_with_offsets_velocity_recall = 0.0, metrics/note_with_velocity_f1_score = 0.0, metrics/note_with_velocity_precision = 0.0, metrics/note_with_velocity_recall = 0.0
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: /DATA/disk1/juliayang/data/maestro-v3/test_maestro/onsets_frames/model.ckpt-100



",first use inference material part loss data inference code file argument work got metric wrong thanks hey got solve saving global step loss saving global step loss saving summary global step,issue,negative,negative,neutral,neutral,negative,negative
847476198,"> Hi @nkjulia, it looks like you're using a custom script to set up model training (`onsets_frames_transcription_train_maestro.py`), so I'm not sure what all is going on. Does training work with the standard script?

it's no different with the standard script  , i just rename it,  training  works  well ....",hi like custom script set model training sure going training work standard script different standard script rename training work well,issue,positive,positive,positive,positive,positive,positive
847253909,"Hi @nkjulia, it looks like you're using a custom script to set up model training (`onsets_frames_transcription_train_maestro.py`), so I'm not sure what all is going on. Does training work with the standard script?",hi like custom script set model training sure going training work standard script,issue,positive,positive,positive,positive,positive,positive
846383025,"i encounter an  error as below  when use onsets_frames_transcription_train.py to evaluate on test data, is there any solution? thanks a lot

W0522 17:40:45.179362 140664331384576 error_handling.py:149] Reraising captured error
Traceback (most recent call last):
  File ""./magenta/models/onsets_frames_transcription/onsets_frames_transcription_train_maestro.py"", line 133, in <module>
    console_entry_point()
  File ""./magenta/models/onsets_frames_transcription/onsets_frames_transcription_train_maestro.py"", line 129, in console_entry_point
    tf.app.run(main)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 303, in run
    _run_main(main, args)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""./magenta/models/onsets_frames_transcription/onsets_frames_transcription_train_maestro.py"", line 124, in main
    additional_trial_info=additional_trial_info)
  File ""./magenta/models/onsets_frames_transcription/onsets_frames_transcription_train_maestro.py"", line 113, in run
    num_steps=FLAGS.eval_num_steps)
  File ""/DATA/disk1/juliayang/magenta-master/magenta/models/onsets_frames_transcription/train_util.py"", line 253, in evaluate
    checkpoint_path=checkpoint_path, name=name)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3151, in evaluate
    rendezvous.raise_errors()
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors
    six.reraise(typ, value, traceback)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/six.py"", line 703, in reraise
    raise value
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3146, in evaluate
    name=name)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 467, in evaluate
    name=name)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 510, in _actual_eval
    return _evaluate()
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 492, in _evaluate
    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1531, in _evaluate_build_graph
    self._call_model_fn_eval(input_fn, self.config))
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1567, in _call_model_fn_eval
    config)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 2962, in _call_model_fn
    config)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1163, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3220, in _model_fn
    features, labels, is_export_mode=is_export_mode)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 1729, in call_without_tpu
    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 2072, in _call_model_fn
    estimator_spec = self._model_fn(features=features, **kwargs)
  File ""/DATA/disk1/juliayang/magenta-master/magenta/models/onsets_frames_transcription/train_util.py"", line 78, in wrapped_model_fn
    return model_fn(features, labels, mode, params, config)
  File ""/DATA/disk1/juliayang/magenta-master/magenta/models/onsets_frames_transcription/model.py"", line 420, in model_fn
    eval_metric_ops=metric_ops)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/model_fn.py"", line 155, in __new__
    loss = _validate_estimator_spec_loss(loss, mode)
  File ""/DATA/disk1/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/model_fn.py"", line 329, in _validate_estimator_spec_loss
    raise ValueError('Missing loss.')
ValueError: Missing loss.
",encounter error use evaluate test data solution thanks lot error recent call last file line module file line main file line run file line run main file line main file line main file line run file line evaluate file line evaluate file line value file line reraise raise value file line evaluate file line evaluate file line return file line file line file line file line file line file line file line return file line file line return mode file line file line loss loss mode file line raise loss missing loss,issue,negative,positive,neutral,neutral,positive,positive
835422967,"Same here! It seems to work, but getting these errors:

ERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.12.1 which is incompatible.
ERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.12.1 which is incompatible.

Hopefully, these are are not real errors. But bugs that will be fixed in TensorFlow????",work getting error requirement incompatible error requirement incompatible hopefully real fixed,issue,negative,positive,positive,positive,positive,positive
833319825,"Maybe I'm too late but in #1602 appears the same issue, with a different metric (""tracks_discarded_more_than_1_program"") and a different model (Polyphony RNN).

I think you should check the metric ""DAGPipeline_LeadSheetExtractor_training_empty_chord_progressions"". It's telling you that, somehow, you have empty chord progressions (I suppose that's necessary to Improv RNN).",maybe late issue different metric different model polyphony think check metric telling somehow empty chord suppose necessary,issue,negative,negative,neutral,neutral,negative,negative
831842134,"Hey @SimpleXP, were you able to solve the problem? I was trying to convert Imagenet Raw Data to TF-Record but I am struggling with it. Let me know!",hey able solve problem trying convert raw data struggling let know,issue,negative,positive,positive,positive,positive,positive
828706914,"Hi @namtm84. You should try reaching out to piano-e-competition.com. They were the source of the raw data we used when creating the dataset and distributing MAESTRO under a noncommercial license is a part of our agreement with them, so they would be the right people to talk to about getting a commercial license for it.

Best of luck on the app, and keep us posted on how it goes!",hi try reaching source raw data used maestro noncommercial license part agreement would right people talk getting commercial license best luck keep u posted go,issue,positive,positive,positive,positive,positive,positive
821542197,"@jesseengel Is that still valid? I tried installing from pip and ended up having to install bazel. Anyway, I can't install magenta from pip so I'm also dependent on a docker image. Is there a workaround for this issue?",still valid tried pip ended install anyway ca install magenta pip also dependent docker image issue,issue,negative,neutral,neutral,neutral,neutral,neutral
816002179,Looks like things are at the same point since I get  `assert len(extracted_melodies) <= 1` for file having multiple voices?,like point since get assert file multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
815927585,Same error for me too as I try to _gansynth_generate --ckpt_dir=acoustic_only --output_dir=output_ in command line.,error try command line,issue,negative,neutral,neutral,neutral,neutral,neutral
814323091,"We have some demos of realtime transcription using TFLite here: https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription/realtime

Unfortunately, we haven't had time to develop them beyond the initial experimental demo. Let us know if you end up doing something interesting with them!",demo transcription unfortunately time develop beyond initial experimental let u know end something interesting,issue,negative,positive,neutral,neutral,positive,positive
813768968,Still failing on rtmidi `ERROR: Failed building wheel for python-rtmidi`,still failing error building wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
810649751,"We don't currently have any code that handles pitch bends for transcription. It would be an interesting thing to try, though. Part of the difficulty would be getting a dataset with an accurate pairing of audio and pitch bend events. From there, I could imagine modeling the bends either as a series of discrete notes (probably easiest) or as additional bend or F0 contour events.

If you try it out, I'd love to hear how it goes!",currently code pitch transcription would interesting thing try though part difficulty would getting accurate audio pitch bend could imagine modeling either series discrete probably easiest additional bend contour try love hear go,issue,positive,positive,positive,positive,positive,positive
808830212,"exosome12 - Thanks so much for the suggestion. In and of itself it did NOT fix it, BUT it did lead straight to the cause. On my older Win7 PC when the Max editor came up the design window looked normal, but the window that displays the selected object had a few lines of code then kept scrolling out the same error-type message ""stopping server port 3333"". That told me everything I needed to know. In setting up the new machine I spent several days getting RDPWrapper working so I could use Windows Remote Desktop Connection to work over ethernet (for my 3 ""music studio"" machines)  and WiFi (to manage other machines we have). RDPWrapper was listening on port 3333. As soon as I stopped it Magenta behaved normally. Looks like I will have to use Magenta outside of my RDP setup where my Win7 machine is running in a window on my new machine (or see if I can find a port where both can run). Thanks again for quickly recommending the click that led to the solution.

Before I close this and spend time on research and testing - are there specific ports or a range that Max has to have for itself - besides 3333? ",thanks much suggestion fix lead straight cause older win editor came design window normal window selected object code kept message stopping server port told everything know setting new machine spent several day getting working could use remote connection work music studio manage listening port soon stopped magenta normally like use magenta outside setup win machine running window new machine see find port run thanks quickly click led solution close spend time research testing specific range besides,issue,positive,positive,positive,positive,positive,positive
808806993,try clicking the max4live button on the device (first button on the upper right corner) and than closing max,try button device first button upper right corner,issue,negative,positive,positive,positive,positive,positive
800187918,"> Please replace the file ""checkpoint"" in your coconet_checkpoint\coconet-64layers-128filters folder with the following one: [checkpoint.zip](https://github.com/tensorflow/magenta/files/3763823/checkpoint.zip).
> This is not an issue in code. we can close this item.

This is not correct. To actually fix the problem, you need to update the `checkpoint` file as discussed in a [previous issue](https://github.com/magenta/magenta/issues/1292).",please replace file folder following one issue code close item correct actually fix problem need update file previous issue,issue,negative,negative,neutral,neutral,negative,negative
794706861,"Yeah, I think your general understanding is correct. If the truncated_length is longer than the input tensors, they'll be padded to the correct length: https://github.com/magenta/magenta/blob/9885adef56d134763a89de5584f7aa18ca7d53b6/magenta/models/onsets_frames_transcription/data.py#L395",yeah think general understanding correct longer input correct length,issue,negative,positive,neutral,neutral,positive,positive
794703372,Related answer in #1839. I think you'll still need to use the code in infer.py so that it uses the entire example instead of a smaller chunk.,related answer think still need use code entire example instead smaller chunk,issue,negative,neutral,neutral,neutral,neutral,neutral
794701206,"The two big differences between the eval code and the infer.py code are that infer evaluates on the entire example and applies the post-processing steps. For comparison to the paper, you should use infer.py.",two big code code infer entire example comparison paper use,issue,negative,neutral,neutral,neutral,neutral,neutral
794620820,I'm getting a similar error. Would appreciate an answer for this!,getting similar error would appreciate answer,issue,negative,neutral,neutral,neutral,neutral,neutral
791820068,"The error caused by note-seq should be gone now (https://github.com/magenta/note-seq/pull/31). I think the others are caused by some tensor2tensor-specific requirements issues. In any case, the colab should still work if you just ignore those errors.",error gone think case still work ignore,issue,negative,neutral,neutral,neutral,neutral,neutral
791800363,"Hi @sharp-trickster. I agree the error is annoying, and I'll see if I can change some of the package requirements to get rid of at least one of those.

However, I think the colab should continue to work. If you scroll down, are you able to upload a file for inference?",hi agree error annoying see change package get rid least one however think continue work scroll able file inference,issue,negative,negative,negative,negative,negative,negative
790463118,"this fuction _multiple_styles in file image_stylization_transform.py just like this



    def _multiple_styles(input_image, which_styles, output_dir):
        with tf.Graph().as_default(), tf.Session() as sess:
            mixture = _style_mixture(which_styles, FLAGS.num_styles)
            stylized_images = model.transform(
                input_image,
                alpha=FLAGS.alpha,
                normalizer_fn=ops.weighted_instance_norm,
                normalizer_params={
                    'weights': tf.constant(mixture),
                    'num_categories': FLAGS.num_styles,
                    'center': True,
                    'scale': True
                })
            _load_checkpoint(sess, FLAGS.checkpoint)
    
            for var in tf.global_variables():
                w = var.eval()
                w = np.nan_to_num(w)
                var.assign(w).eval()
    
            stylized_images = stylized_images.eval()
            stylized_images = stylized_images[0]
            stylized_images = (stylized_images*255).astype(np.uint8)
            img = Image.fromarray(stylized_images)
            img.save(""name.jpg"")
            return img",file like sess mixture mixture true true sess return,issue,positive,positive,positive,positive,positive,positive
790094946,"Hi @YawYoung. There's actually no need to train MusicVAE on E-GMD. E-GMD does have much more audio data than the original GMD (because we used a lot of different drum patches), but all the symbolic sequence data it has came from GMD. MusicVAE works in the symbolic domain, so training on GMD is best.",hi actually need train much audio data original used lot different drum symbolic sequence data came work symbolic domain training best,issue,positive,positive,positive,positive,positive,positive
789531613,"I tried following steps, but I am facing issue:

Setup:
Python: 3.6
TensorFlow 1.14.0 (Docker Image: **tensorflow/tensorflow:1.14.0-py3-jupyter**)
Machine: macOS Big Sur 11.2.1 (MacBook Pro 16 Inch 2019 Model)
CoreMLTools: 4.1

Downloaded https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2 model to local ""hub"" directory.
 
Script:
```
import coremltools as ct
import tensorflow as tf

def convert_hub_model():
    saved_model_path = 'hub'
    coreml_path = 'hub_style_transfer.mlmodel'
    print(saved_model_path)

    mlmodel = ct.convert(saved_model_path,
                         source='tensorflow',
                         inputs=[ct.ImageType(name=""placeholder:0"", bias=[0,0,0], scale=1/255.0),
                                 ct.ImageType(name=""placeholder_1:0"", bias=[0,0,0], scale=1/255.0)],
                         outputs=[""output_0""])
    print(mlmodel)
    mlmodel.save(coreml_path)
```

I am getting following error:
```
InvalidArgumentErrorTraceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    426         results = c_api.TF_GraphImportGraphDefWithResults(
--> 427             graph._c_graph, serialized, options)  # pylint: disable=protected-access
    428         results = c_api_util.ScopedTFImportGraphDefResults(results)

InvalidArgumentError: Input 2 of node StatefulPartitionedCall was passed float from InceptionV3/Conv2d_1a_3x3/weights:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

ValueErrorTraceback (most recent call last)
<ipython-input-21-54a0cdc2b239> in <module>
      1 # convert_predict_model('original')
      2 # convert_transfer_model('original')
----> 3 convert_hub_model()

<ipython-input-20-8a7c8923c5de> in convert_hub_model()
     33                          inputs=[ct.ImageType(name=""placeholder:0"", bias=[0,0,0], scale=1/255.0),
     34                                  ct.ImageType(name=""placeholder_1:0"", bias=[0,0,0], scale=1/255.0)],
---> 35                          outputs=[""output_0""])
     36     print(mlmodel)
     37     mlmodel.save(coreml_path)

/usr/local/lib/python3.6/dist-packages/coremltools/converters/_converters_entry.py in convert(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, **kwargs)
    180         outputs=outputs,
    181         classifier_config=classifier_config,
--> 182         **kwargs
    183     )
    184 

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/converter.py in mil_convert(model, convert_from, convert_to, **kwargs)
    127     """"""
    128     proto = mil_convert_to_proto(model, convert_from, convert_to,
--> 129         ConverterRegistry, **kwargs)
    130     if convert_to == 'mil':
    131         return proto

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/converter.py in mil_convert_to_proto(model, convert_from, convert_to, converter_registry, **kwargs)
    169     frontend_converter = frontend_converter_type()
    170 
--> 171     prog = frontend_converter(model, **kwargs)
    172     common_pass(prog)
    173 

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/converter.py in __call__(self, *args, **kwargs)
     62 
     63         tf1_loader = TF1Loader(*args, **kwargs)
---> 64         return tf1_loader.load()
     65 
     66 

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/frontend/tensorflow/load.py in load(self)
     56         logging.info(""Loading TensorFlow model '{}'"".format(self.model))
     57         outputs = self.kwargs.get(""outputs"", None)
---> 58         self._graph_def = self._graph_def_from_model(outputs)
     59 
     60         if self._graph_def is not None and len(self._graph_def.node) == 0:

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/frontend/tensorflow/load.py in _graph_def_from_model(self, outputs)
    164                 return self.extract_sub_graph(graph_def, outputs)
    165             elif os.path.isdir(str(self.model)):
--> 166                 graph_def = self._from_saved_model(self.model)
    167                 return self.extract_sub_graph(graph_def, outputs)
    168             else:

/usr/local/lib/python3.6/dist-packages/coremltools/converters/mil/frontend/tensorflow/load.py in _from_saved_model(saved_model_dir)
    286             graph_def = tf.compat.v1.graph_util.remove_training_nodes(graph_def)
    287         with tf.Graph().as_default() as graph:
--> 288             tf.graph_util.import_graph_def(graph_def, name="""")
    289         return graph.as_graph_def(add_shapes=True)
    290 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    429       except errors.InvalidArgumentError as e:
    430         # Convert to ValueError for backwards compatibility.
--> 431         raise ValueError(str(e))
    432 
    433     # Create _DefinedFunctions for any imported functions.

ValueError: Input 2 of node StatefulPartitionedCall was passed float from InceptionV3/Conv2d_1a_3x3/weights:0 incompatible with expected resource.
```",tried following facing issue setup python docker image machine big sur pro inch model model local hub directory script import import print print getting following error recent call last name input node float incompatible resource handling exception another exception recent call last module print convert model source model proto model return proto model prog model prog self return load self loading model none none self return return else graph return future version date none else date return doc name except convert backwards compatibility raise create input node float incompatible resource,issue,negative,neutral,neutral,neutral,neutral,neutral
775362718,"If you have time, I would definitely appreciate a PR with exactly what you changed to get things running on GPU. Thanks for figuring out the problems!",time would definitely appreciate exactly get running thanks,issue,positive,positive,positive,positive,positive,positive
771259567,"Sorry, I haven't tried training that model on multiple GPUs and am not totally sure how to set that up with TPUEstimator. Training on multiple TPU chips is pretty straightforward, so you could try that. Multi-GPU may require more of an ambitious rewrite to use the new TFv2 distribution strategies.",sorry tried training model multiple totally sure set training multiple chip pretty straightforward could try may require ambitious rewrite use new distribution,issue,positive,positive,positive,positive,positive,positive
771165791,"Hello, 

To run on gpu in estimator_spec_util.py i changed:

1. optimizer='Adam'
2. tf.tpu.estimator.TPUEstimatorSpec -> tf.estimator.EstimatorSpec

But in this way i could run only on one gpu. Do you know how to run your code on multiple cards?
I tried MirrorDistributedStrategy, but maybe added it not in right place, because it doesnt work for me. Could you please help, how to run it correctly on multiple cards?

",hello run way could run one know run code multiple tried maybe added right place doesnt work could please help run correctly multiple,issue,negative,positive,neutral,neutral,positive,positive
770333578,"I had this problem and to isolate it I switched to a clean venv via pycharm and installed only magenta (without conda).  I dug through the output and found that the common issue between my failure to get good output was magenta not finding my model directory. It was then that I realized the directory I was pointing it to had a typo, so it was failing to find a trained model, and understandably outputting gibberish because it was using some default model ill-suited to the task.

Looking through @xMcouro's output, I also see buried in there the line:
> INFO:tensorflow:Could not find trained model in model_dir: d/train, running initialization to predict.

So it looks like that may be the problem here too. Once I fixed the directory I was pointing to when running the command, it started working perfectly. ",problem isolate switched clean via magenta without dug output found common issue failure get good output magenta finding model directory directory pointing typo failing find trained model understandably gibberish default model task looking output also see buried line could find trained model running predict like may problem fixed directory pointing running command working perfectly,issue,negative,positive,positive,positive,positive,positive
769494616,"I'm getting this error for the real time demo:
```
(magenta) ulaili@DESKTOP-UM451RI:~$ onsets_frames_transcription_realtime \
>   --model_path /onsets_frames_wavinput.tflite
Listening to results..
Traceback (most recent call last):
  File ""/home/ulaili/miniconda3/envs/magenta/bin/onsets_frames_transcription_realtime"", line 8, in <module>
    sys.exit(console_entry_point())
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/realtime/onsets_frames_transcription_realtime.py"", line 232, in console_entry_point
    app.run(main)
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/realtime/onsets_frames_transcription_realtime.py"", line 185, in main
    model = tflite_model.Model(model_path=FLAGS.model_path)
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/realtime/tflite_model.py"", line 42, in __init__
    self._interpreter = tflite.Interpreter(model_path=model_path)
  File ""/home/ulaili/miniconda3/envs/magenta/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py"", line 206, in __init__
    model_path))
ValueError: Could not open '/onsets_frames_wavinput.tflite'.
```",getting error real time magenta listening recent call last file line module file line main file line run main file line main file line main model file line file line could open,issue,negative,positive,positive,positive,positive,positive
769440230,"OK, if it works in the colab, I suspect a problem with your local setup. I noticed that you're running onsets_frames_transcription_transcribe.py directly. You probably want to pip install the package and then just run the onsets_frames_transcription_transcribe that gets installed in your path. That way all the imports will work correctly.

For realtime, we haven't done too much, but you can see a preliminary demo here: https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription/realtime",work suspect problem local setup running directly probably want pip install package run path way work correctly done much see preliminary,issue,negative,positive,positive,positive,positive,positive
769260815,"The range of notes on a standard piano is [21, 108]. The training datasets were all piano music, so that's why that range was used.

Yes, it's possible that the model could decode a 0 or 1. The 0 is unlikely because I think that isn't ever encountered in training. If I remember correctly, we would just ignore it on decode if it happened. Decoding an EOS token would just indicate that the model believes that is the end of the piece and we should stop decoding.",range standard piano training piano music range used yes possible model could decode unlikely think ever training remember correctly would ignore decode token would indicate model end piece stop,issue,negative,negative,negative,negative,negative,negative
769010663,"> Thank you! I see now, sorry, thought that you closed the issue

how to solve this problem? thank you.",thank see sorry thought closed issue solve problem thank,issue,negative,negative,negative,negative,negative,negative
768553829,"Yes, I just tried it and it works =). By the way, I dont know if this is the place to ask, but I wonder if theres a way to do these transcriptions in real time",yes tried work way dont know place ask wonder there way real time,issue,negative,positive,positive,positive,positive,positive
768051165,"As a quick check, can you try that same file in the colab notebook and see if it works? https://goo.gl/magenta/onsets-frames-colab",quick check try file notebook see work,issue,negative,positive,positive,positive,positive,positive
766849833,"Thanks @kristychoi! We can pretty readily expand our dataset; I'll try that plus the masking (if present). For the perturbations, masks and substitutions we'll definitely try. If we try anything else that works, I'll be sure to post it here.

Thank you for your help! It's good to know we're more or less on the right track.",thanks pretty readily expand try plus present definitely try try anything else work sure post thank help good know le right track,issue,positive,positive,positive,positive,positive,positive
766418400,"hi @apteryxlabs! let me know if anything is unclear or if i missed anything important.

- that's a good point re: potentially mean-aggregating over padded tokens. i wasn't *too* worried about this because the performance sequences were all quite long (and we had to truncate them during the data generation process), but it's possible that some were padded. the ""FFN"" encoding method you just described is something i'd wanted to try!
- during training, the decoder is provided two things: (1) the performance and/or melody vector representation, which was mean-aggregated across time, and (2) a perturbed performance sequence. you can think of (2) as the input with some added noise (in the music domain it was pitch shifts/time stretches, but I imagine for NLP tasks they could look like masking tokens or random word substitutions). i didn't modify anything else in terms of attention mechanisms in the decoder from what was originally there in [tensor2tensor.](https://github.com/tensorflow/tensor2tensor/blob/21dba2c1bdcc7ab582a2bfd8c0885c217963bb4f/tensor2tensor/models/transformer.py#L117)
- not all the samples we obtained at test time sounded great -- we had to filter some out. the ""noisy training"" helped quite a bit on this front.",hi let know anything unclear anything important good point potentially worried performance quite long truncate data generation process possible method something try training provided two performance melody vector representation across time perturbed performance sequence think input added noise music domain pitch imagine could look like random word modify anything else attention originally test time great filter noisy training quite bit front,issue,positive,positive,positive,positive,positive,positive
766401865,"Thanks @cghawthorne for your response! @kristychoi, I would love to get your input. 

Our current approach is to mask out (set to zero) all encoder outputs which correspond to pad tokens, and then (rather than averaging) to stack the tensor along the seq-aka-time (hereinafter 'time') axis (where the encoder output is of shape (batch, time, d_model), and project the resulting (batch, time*d_model) tensor through a feed forward network onto a (batch, d_encoding) space. This is our autoencoded vector, which we use for later sampling.

That vector is then mapped back to the original encoder shape via another feed-forward net + reshape (in pytorch, tensor.view()) step, and the result is used for decoder attentions. The rest of the architecture is identical to yours.

Would love to hear your thoughts. Currently the decoder outputs, while containing some of the original signal, are QUITE noisy. If I'm missing anything here, I'd love to know.",thanks response would love get input current approach mask set zero correspond pad rather stack tensor along hereinafter axis output shape batch time project resulting batch time tensor feed forward network onto batch space vector use later sampling vector back original shape via another net reshape step result used rest architecture identical would love hear currently original signal quite noisy missing anything love know,issue,positive,positive,positive,positive,positive,positive
765814419,Good questions! @kristychoi would probably be the best to answer here.,good would probably best answer,issue,positive,positive,positive,positive,positive,positive
765608209,"Sorry about the typo! A PR would be appreciated for that.

I'm not sure what's causing the other error. Can you verify that `use_tpu=False` is being passed through to the `TPUEstimator`?",sorry typo would sure causing error verify,issue,negative,neutral,neutral,neutral,neutral,neutral
765445725,"Hello again,

Sorry, i found the solution for the previous problem. It was a typo in the script  - estimator_spec_util.py. It should be changed tf.tpu.estimator on tf.estimator.tpu

But after that i still couldnt run this drums config on the gpu. Could you please help me and say, how i should run it correctly? Now i have this error:

tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CrossReplicaSum' used by node training/CrossReplicaSum (defined at /lib/python3.6/site-packages/tf_slim/layers/optimizers.py:296) with these attrs: [T=DT_FLOAT, _class=[""loc:@training/gradients/onsets/conv0/Conv2D_grad/Conv2DBackpropFilter""]]
Registered devices: [CPU, GPU, XLA_CPU, XLA_GPU]
Registered kernels:
  <no registered kernels>

         [[training/CrossReplicaSum]]

",hello sorry found solution previous problem typo script still run could please help say run correctly error registered support used node defined registered registered registered,issue,positive,negative,negative,negative,negative,negative
764794770,"Bumping this - any thoughts? @cghawthorne I'm particularly stuck on what the decoder inputs should look like, and the shape of the aggregated vector. 

Correct me if I'm wrong - again, I'm coming at this from a Huggingface background -  but it looks like at **train time** you'd be providing the encoder _and_ the decoder the same inputs, possibly (but I'm not sure, looking at the code) right-shifting the decoder inputs by one, and doing a single forward pass through the decoder. But at **generation time**, encoder inputs would be the original sequence (same at train), and decoder inputs would be the <pad> token - you'd then loop the decoder to generate a new sequence. My question - how does training with a full sequence as input for the decoder translate well, or at all, to generating a new sequence from <pad>? Or am I completely missing something here?",bumping particularly stuck look like shape vector correct wrong coming background like train time providing possibly sure looking code one single forward pas generation time would original sequence train would pad token loop generate new sequence question training full sequence input translate well generating new sequence pad completely missing something,issue,positive,positive,neutral,neutral,positive,positive
763842837,"This was a part of our agreement for how the data would be redistributed. If you need a commercial license, you could try reaching out to piano-e-competition.com (the source of the raw data we used when creating the dataset).",part agreement data would need commercial license could try reaching source raw data used,issue,positive,negative,negative,negative,negative,negative
759146948,"Sorry, we ran it on an internal tool that's similar to but not quite the same as Dataflow, so I'm not sure what all the differences are. Is there a way to just request more memory for the worker instances?",sorry ran internal tool similar quite sure way request memory worker,issue,negative,neutral,neutral,neutral,neutral,neutral
758827201,"Hi, I have the same issue when trying to install the DDSP package. Does anyone have a work around? ",hi issue trying install package anyone work around,issue,negative,neutral,neutral,neutral,neutral,neutral
756853362,We already don't require a specific tensorflow version in the latest package.,already require specific version latest package,issue,negative,positive,positive,positive,positive,positive
755443358,Great! The colab should be updated with the samplerate fix in the next couple days.,great fix next couple day,issue,positive,positive,positive,positive,positive,positive
755155211,"Oh nice! I ran this and sonified the [resultant MIDI](https://drive.google.com/file/d/1o5iYR0iAZzhKqSLXSRjalvemZqkq2b3h/view?usp=sharing) with the soundfont from the paper and it sounds almost identical to the reference. Thanks so much for your help with this! Hugely appreciated

Final `Dockerfile` for posterity:

```
FROM tensorflow/tensorflow:1.15.4-gpu

RUN apt-get -y update; apt-get -y install \
  wget
RUN pip install --upgrade pip

RUN apt-get -y install \
  libasound2-dev \
  libjack-dev \
  libsndfile1 \
  libsndfile-dev \
  ffmpeg

WORKDIR /models
RUN wget https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/e-gmd_checkpoint.zip
RUN ls
RUN unzip e-gmd_checkpoint.zip -d /models/e-gmd

WORKDIR /code
RUN wget https://github.com/magenta/magenta/archive/94529798dfbbb14c27ddfd76f23027dc8e2ce185.zip
RUN unzip 94529798dfbbb14c27ddfd76f23027dc8e2ce185.zip
RUN pip install --no-cache-dir -e magenta-94529798dfbbb14c27ddfd76f23027dc8e2ce185/

RUN wget https://github.com/magenta/magenta/files/5774206/Chorus03_Crispy_95bpm.wav.zip
RUN unzip Chorus03_Crispy_95bpm.wav.zip
RUN onsets_frames_transcription_transcribe \
  --model_dir=""/models/e-gmd"" \
  --config=""drums"" \
  --load_audio_with_librosa=True \
  Chorus03_Crispy_95bpm.wav
```
",oh nice ran resultant paper almost identical reference thanks much help hugely final posterity run update install run pip install upgrade pip run install run run run run run run pip install run run run,issue,positive,positive,positive,positive,positive,positive
755114840,"Yeah, given that the samplerate made such a big difference, I definitely suspect the mp3 compression could be causing problems as well. Here's the original .wav file. Note that you'll need to have `--load_audio_with_librosa=True` on the command line because the original file is a 24-bit wav.

[Chorus03_Crispy_95bpm.wav.zip](https://github.com/magenta/magenta/files/5774206/Chorus03_Crispy_95bpm.wav.zip)

",yeah given made big difference definitely suspect compression could causing well original file note need command line original file,issue,positive,positive,positive,positive,positive,positive
755096575,"Thanks so much for looking into this! I really appreciate it :pray: 

Ah, a lower sample rate would explain why the hi-hats had mysteriously disappeared :). I'm not sure how to make this change in the Colab notebook, but I was able to run the command line tool (`Dockerfile` below for reference)

Unfortunately, the results ([wav](https://drive.google.com/file/d/10O0aUZ-nK6XACBogqOhM0qAQTNJ3yUfa/view?usp=sharing), [midi](https://drive.google.com/file/d/12Pbx4ukxfgwI5zD7mbjtK8CHIpa4b289/view?usp=sharing)) are still not quite as rich as the reference transcription from the online supplement. In particular, the reference really nails the syncopation of the cymbals compared to the results I'm hearing. A visual comparison (from top to bottom is original, reference, colab output, command line output):

![2021-01-05_21-38](https://user-images.githubusercontent.com/748399/103733348-6d2c9f00-4f9e-11eb-9e11-32f07d84c979.png)

One possibility I can think of is that the original file (`chorus-193_original.mp3`) was uncompressed and/or uncropped when originally fed to the network to produce the reference. Do you happen to have the original uncompressed/full-length audio file so I could test that hypothesis?

**`Dockerfile`** using the [suggested checkpoint in the README](https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription#onsets-and-frames-transcription)

```
FROM tensorflow/tensorflow:1.15.4-gpu

RUN apt-get -y update; apt-get -y install \
  wget
RUN pip install --upgrade pip

RUN apt-get -y install \
  libasound2-dev \
  libjack-dev \
  libsndfile1 \
  libsndfile-dev \
  ffmpeg

WORKDIR /models
RUN wget https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/e-gmd_checkpoint.zip
RUN ls
RUN unzip e-gmd_checkpoint.zip -d /models/e-gmd

WORKDIR /code
RUN wget https://github.com/magenta/magenta/archive/94529798dfbbb14c27ddfd76f23027dc8e2ce185.zip
RUN unzip 94529798dfbbb14c27ddfd76f23027dc8e2ce185.zip
RUN pip install --no-cache-dir -e magenta-94529798dfbbb14c27ddfd76f23027dc8e2ce185/

RUN wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UmduMXP-rvsNIR2hgxiTmHzbclT9VSUV' -O input.wav
RUN onsets_frames_transcription_transcribe \
  --model_dir=""/models/e-gmd"" \
  --config=""drums"" \
  input.wav
```",thanks much looking really appreciate pray ah lower sample rate would explain mysteriously sure make change notebook able run command line tool reference unfortunately still quite rich reference transcription supplement particular reference really syncopation hearing visual comparison top bottom original reference output command line output one possibility think original file uncompressed uncropped originally fed network produce reference happen original audio file could test hypothesis run update install run pip install upgrade pip run install run run run run run run pip install run run,issue,positive,positive,positive,positive,positive,positive
755076553,"Ah, I think the problem is I forgot to pass `sample_rate=hparams.sample_rate` to `audio_label_data_utils.process_record`, which is already done in the transcribe script. Without that, it will default to 16 KHz instead of the desired 44.1 KHz. Can you try adding that and see if it helps?

Also, the fact that this makes as much of a difference as it does probably means we should be doing additional training on downsampled or otherwise corrupted/augmented audio. We found that training in 44.1 KHz does help with higher frequency content like cymbal crashes, but I suspect the model could be made more robust to handling lower sample rates.",ah think problem forgot pas already done transcribe script without default instead desired try see also fact much difference probably additional training otherwise audio found training help higher frequency content like cymbal suspect model could made robust handling lower sample,issue,negative,positive,positive,positive,positive,positive
755032236,"Hmm, I think there might be something wrong with the colab notebook. Can you try installing the pip package and doing inference on the command line? I'm currently getting better results that way, though I'm not sure why yet. I'll try to dig into that more soon.

Sorry for the confusion!",think might something wrong notebook try pip package inference command line currently getting better way though sure yet try dig soon sorry confusion,issue,negative,neutral,neutral,neutral,neutral,neutral
754812862,"Fixed! For posterity, the problem was that Tone.js had a breaking change which we reflected in the latest magenta.js version (which gets loaded), but the demos were still loading the old Tone.js versions, pre-breaking change.
",fixed posterity problem breaking change reflected latest version loaded demo still loading old change,issue,negative,positive,positive,positive,positive,positive
753739147,"Oh no! Thanks for flagging this, I’ll take a look tomorrow!

On Sat, Jan 2, 2021 at 1:41 AM vumaasha <notifications@github.com> wrote:

> https://magenta.github.io/listen-to-transformer/#a1_40926.mid
> https://drumbot.glitch.me/
>
> both the links are not working. There are errors on inspecting the console.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1871>, or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAKOIUSVZA3R3EGMNERNVILSX3S4VANCNFSM4VQ53GLA>
> .
>
",oh thanks flagging take look tomorrow sat wrote link working console thread reply directly view,issue,negative,positive,positive,positive,positive,positive
753058697,"I found the problem, on `train_util.py` you need to pass the weights from maestro in a missing parameter, that is `warm_start_from`, I will made an PR after to add this new parameter to onset_and_frames cli.

```python
  estimator = create_estimator(
      model_fn=model_fn,
      model_dir=model_dir,
      master=master,
      tpu_cluster=tpu_cluster,
      hparams=hparams,
      keep_checkpoint_max=keep_checkpoint_max,
      use_tpu=use_tpu,
      warm_start_from='<dir to maestro weights>'
  )
```",found problem need pas maestro missing parameter made add new parameter python estimator maestro,issue,negative,negative,neutral,neutral,negative,negative
751370794,Can confirm it still fails to build on Windows 10 `ERROR: Failed building wheel for python-rtmidi`,confirm still build error building wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
751058166,"Hello, 

Thank you, i solved the problem with soundfile library, the problem was in the uninstalled libsndfile1 package, that could be added to workers by changing setup.py file as was shown here: https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/complete/juliaset/setup.py

However, now it seems that I'm stuck with OOM error in Dataflow, do you have any configuration on which it was run, or maybe some suggestions fo handling it?",hello thank problem library problem uninstalled package could added file shown however stuck error configuration run maybe handling,issue,negative,neutral,neutral,neutral,neutral,neutral
749844371,"Sorry you're having trouble with the dataset! I haven't used dataflow recently, but if dependencies are causing problems, you may need to use a custom container: https://cloud.google.com/dataflow/docs/guides/using-custom-containers",sorry trouble used recently causing may need use custom container,issue,negative,negative,negative,negative,negative,negative
748902690,Hi. I had the same error as you. Did you solve this problem?,hi error solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
748894661,"I was wrong :( . 
shift right makes the network learn to predict the next value (as desired) while shift left makes the previous value.",wrong shift right network learn predict next value desired shift left previous value,issue,negative,negative,neutral,neutral,negative,negative
746928281,"Ah, it turns out that this was a limited project and only ran for a small amount of time. Sorry about that :( 
I'll reach out to the owner of the post to see if we can update the copy on that to make it more clear.
",ah turn limited project ran small amount time sorry reach owner post see update copy make clear,issue,negative,negative,negative,negative,negative,negative
739061354,"@cghawthorne Are there plans to open source the WaveNet model that is used for the Midi2Wave in the future? It would be extremely nice to be able to use it for piano music synthesis, even for music that is not part of the MAESTRO dataset. ",open source model used future would extremely nice able use piano music synthesis even music part maestro,issue,negative,positive,positive,positive,positive,positive
736379349,I also noticed that for the training part is missing a huge part of documentation. For example I don't understand which are all the hyperparams that can be set since is not written somewhere and so on. ,also training part missing huge part documentation example understand set since written somewhere,issue,negative,positive,positive,positive,positive,positive
733947446,"@iansimon, thank you for your reply! I wish we could know how things really are regarding the duration of the sample so I could fully commit myself to Magenta or move on to some other project.

Theoretically, there should be no reason why training and sampling a 1-minute-long song would be impossible, if the dataset is proper and all the songs in it are longer than 1 minute. It seems that the only bottleneck is the hardware power / speed,  but I totally might be wrong.",thank reply wish could know really regarding duration sample could fully commit magenta move project theoretically reason training sampling song would impossible proper longer minute bottleneck hardware power speed totally might wrong,issue,positive,negative,negative,negative,negative,negative
733481273,"[solved] 
For my case, it was because I was trying to pre-process polyphonic data (Maestro) for a monophonic model (Melody RNN). Do take note of the type of model you are using - polyphonic vs monophonic, or whether the instrument should be a drum. 
Hope this helps!",case trying polyphonic data maestro monophonic model melody take note type model polyphonic monophonic whether instrument drum hope,issue,negative,neutral,neutral,neutral,neutral,neutral
733238642,I couldn't get training to work very well for longer samples in the hierarchical VAE.  I'm not sure if there's some simple change to model architecture that would greatly improve things or if it would require a different kind of architecture entirely.,could get training work well longer hierarchical sure simple change model architecture would greatly improve would require different kind architecture entirely,issue,positive,positive,positive,positive,positive,positive
733059400,"Hello there people!
@iansimon, and others - I'm not sure if I understand well. Is it that it is very hard to achieve samples longer than 30 seconds ANYWAY (as in - there is an intrinsic hardware related/technological/complexity related bottleneck), or is it just that one has to train the model with settings adjusted for a longer sample in order to get a proper longer sample, but it just takes way more time?

I'd really appreciate an explanation!",hello people sure understand well hard achieve longer anyway intrinsic hardware related bottleneck one train model longer sample order get proper longer sample way time really appreciate explanation,issue,positive,positive,neutral,neutral,positive,positive
732360851,"I still have the same issue even after updating magenta to 2.1.3 with pip install -U magenta. Is the fix already in the latest version? Thanks.
![Screen Shot 2020-11-23 at 10 55 19 AM](https://user-images.githubusercontent.com/41763/100003408-e3709b80-2d7a-11eb-98d6-09575e8179c7.png)
",still issue even magenta pip install magenta fix already latest version thanks screen shot,issue,negative,positive,positive,positive,positive,positive
732231273,"Ran the test script which gave the following output:
```
2020-11-23 23:14:16.732609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
WARNING:tensorflow:From <path to anaconda>/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Running tests under Python 3.7.9: <path to anaconda>/anaconda3/envs/magenta/bin/python
[ RUN      ] MelodyRNNPipelineTest.testMelodyRNNPipeline
INFO:tensorflow:time(__main__.MelodyRNNPipelineTest.testMelodyRNNPipeline): 0.01s
I1123 23:14:19.222388 139634966488896 test_util.py:1973] time(__main__.MelodyRNNPipelineTest.testMelodyRNNPipeline): 0.01s
[       OK ] MelodyRNNPipelineTest.testMelodyRNNPipeline
[ RUN      ] MelodyRNNPipelineTest.test_session
[  SKIPPED ] MelodyRNNPipelineTest.test_session
----------------------------------------------------------------------
Ran 2 tests in 0.014s

OK (skipped=1)
```
Any ideas as to how we can overcome this? Thanks in advance!",ran test script gave following output successfully dynamic library warning path anaconda removed future version long term running python path anaconda run time time run ran overcome thanks advance,issue,positive,positive,neutral,neutral,positive,positive
732229601,"I'm facing the same issue as well. I see the following warnings before the output INFO lines as well.
```
WARNING:tensorflow:From <path to anaconda>/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
WARNING:tensorflow:From <path to repo>/magenta/magenta/pipelines/pipeline.py:310: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
W1123 23:14:42.132252 140004163573568 deprecation.py:323] From <path to repo>/magenta/magenta/pipelines/pipeline.py:310: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`
```",facing issue well see following output well warning path anaconda removed future version long term warning path removed future version use eager execution path path removed future version use eager execution path,issue,positive,negative,neutral,neutral,negative,negative
727821769,"yes @chrisdonahue , thanks
I'll leave open in case you want to add this somewhere into documentation, this was not something I understood trivially
",yes thanks leave open case want add somewhere documentation something understood trivially,issue,positive,positive,neutral,neutral,positive,positive
727680628,"Hi @AmitMY . It's been a while since I've looked at this, but from what I recall, the tensors will be dynamically instantiated with different examples from the training data when these tensors are evaluated within a Session. Does this help?",hi since recall dynamically different training data within session help,issue,positive,neutral,neutral,neutral,neutral,neutral
726110870,Thank you so much:) Keep up the great work! 👍 ,thank much keep great work,issue,positive,positive,positive,positive,positive,positive
726109601,You can ignore the version error. The Colab will work again once #1850 is in and we push the new pip package. Probably later today.,ignore version error work push new pip package probably later today,issue,negative,positive,neutral,neutral,positive,positive
726107357,"Aha... thank you. Does the colab demo have to work now? I still get the following error.
`AttributeError: 'PrefetchDataset' object has no attribute 'make_initializable_iterator'`
Plus there is an additional version error.
`ERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.11.0 which is incompatible.
ERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.11.0 which is incompatible.`",aha thank work still get following error object attribute plus additional version error error requirement incompatible error requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
726101256,"@jesseengel FYI

Yes, this is an unfortunate issue where the model restoration requires the train dataset to be loaded. Rather than refactoring this legacy code, I created #1851 a bandaid.",yes unfortunate issue model restoration train loaded rather legacy code,issue,negative,negative,negative,negative,negative,negative
726096141,"`gansynth_generate --ckpt_dir=/path/to/acoustic_only --output_dir=/path/to/output/dir --midi_file=/path/to/file.mid`
I bet it's similar with this one: https://github.com/magenta/magenta/issues/1794
I pip installed gansynth, and it gave me this error.",bet similar one pip gave error,issue,negative,neutral,neutral,neutral,neutral,neutral
726092838,"I actually got the error above when I ran the colab demo on GANSynth. So I ran the code in Read.me using my local device which gave me the error in this thread.
Thank you.",actually got error ran ran code local device gave error thread thank,issue,negative,neutral,neutral,neutral,neutral,neutral
726088235,"I cannot reproduce this error. Instead I get a different error: 

`AttributeError: 'PrefetchDataset' object has no attribute 'make_initializable_iterator'`

I will put in a fix for this new error.",reproduce error instead get different error object attribute put fix new error,issue,negative,positive,neutral,neutral,positive,positive
723737644,"okay it's running and I don't want to get too optimistic, but here's what I did to get lines of code rolling:

(cloned the magenta repo)
!pip install -e .
!pip install tensor2tensor==1.15.6 cloudpickle==1.2.0 kfac==0.2.0

Then I had to change two lines:
gansynth/lib/datasets.py:
line 67 changed to `data_dir=""gs://tfds-data/datasets""`

gansynth/lib/data_helpers.py:
line 72 changed to `iterator = tf.data.make_initializable_iterator(dataset)`

Got to the point where I am generating samples!

edit: wav file successfully generated",running want get optimistic get code rolling magenta pip install pip install change two line line got point generating edit file successfully,issue,positive,positive,positive,positive,positive,positive
723699682,"running the colab notebook as it stands currently yields the result `AttributeError: 'PrefetchDataset' object has no attribute 'make_initializable_iterator'`

Tried following the instructions here [https://stackoverflow.com/questions/61318842/attributeerror-prefetchdataset-object-has-no-attribute-make-initializable-it] to fix the problem in a cloned copy of the repository but I'm running into the same error even with the refactored code.

I'm new to tensorflow, but I'm wondering if the problem could be resolved with more explicit versions of the dependencies specified in the requirements? ",running notebook currently result object attribute tried following fix problem copy repository running error even code new wondering problem could resolved explicit,issue,negative,positive,neutral,neutral,positive,positive
716126937,"This problem was fixed (as in the colab notebook) by using `--checkpoint_path=path/to/model.ckpt-200000` without the `.index`, does that help?",problem fixed notebook without help,issue,negative,positive,neutral,neutral,positive,positive
716103133,"Hi @adarob , I'm still facing an issue here and was wondering if you could please explain how to iterate over the dataset.
",hi still facing issue wondering could please explain iterate,issue,negative,neutral,neutral,neutral,neutral,neutral
710021147,"> If you train with exactly the same parameters as the existing TensorFlow.js model, you can use just a checkpoint. (However, I don't think we have those written down anywhere right now) Otherwise, you'll need to port/convert the model to TensorFlow.js. For our port, we actually did the conversion by hand for performance reasons and to make sure the frontend spectrogram processing was completely compatible. @adarob would have more details on that.

could you release some example code of onsets model conversion, I get problem on conversion from ckpt to pb model.",train exactly model use however think written anywhere right otherwise need model port actually conversion hand performance make sure spectrogram completely compatible would could release example code model conversion get problem conversion model,issue,negative,positive,positive,positive,positive,positive
709964451,"https://github.com/magenta/magenta/blob/master/magenta/models/onsets_frames_transcription/data.py
In line 133, length = features.length

When I call tf.estimator.export.build_raw_serving_input_receiver_fn, it raise the error of 'AttributeError: 'dict' object has no attribute 'length'.
Does the input arg 'feature' the type of dict?  If that, how can I get 'length' use ""features.""?
So what's type of arg 'feature' here I can use for tf.estimator.export.build_raw_serving_input_receiver_fn?
Thanks",line length call raise error object attribute input type get use type use thanks,issue,negative,positive,positive,positive,positive,positive
709605325,This doesn't look like a PR we want to merge.,look like want merge,issue,negative,neutral,neutral,neutral,neutral,neutral
709483534,"Yes, but it really is a on model-by-model basis. I'd suggest searching for ""TPU"" in our docs or code. For example, the Onsets and Frames Drums model has TPU training support documented here: https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription#training",yes really basis suggest searching code example model training support,issue,positive,positive,positive,positive,positive,positive
709480800,"Unfortunately, no, it also does not support TPU training.",unfortunately also support training,issue,negative,negative,negative,negative,negative,negative
709471894,"There are many models within the magenta repo. Unfortunately, polyphony_rnn does not support TPU training. You'll need to use either GPU or CPU.",many within magenta unfortunately support training need use either,issue,negative,neutral,neutral,neutral,neutral,neutral
709467900,"> Which model are you wanting to train?

oh, I will train with the `polyphony_rnn_train` command 

are there even any other options?",model wanting train oh train command even,issue,negative,neutral,neutral,neutral,neutral,neutral
709432447,Also the TPU model I want to use is TPU v3,also model want use,issue,negative,neutral,neutral,neutral,neutral,neutral
708086484,"It's very likely there are portions of that code that do not work with Python 3 because we were using Python 2 at the time. However, we can only provide support for the code at HEAD, which should be fully py3 compatible.",likely code work python python time however provide support code head fully compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
707977300,"I'm using Firefox, I just tried Chromium and got all the same errors. And yeah, the one you linked only seems to be related to the last one.",tried chromium got yeah one linked related last one,issue,negative,neutral,neutral,neutral,neutral,neutral
707884498,I would recommend setting up a conda environment (https://docs.conda.io/en/latest/miniconda.html) for magenta so you can install/upgrade dependencies without worrying about modifying your system-wide Python setup.,would recommend setting environment magenta without worrying python setup,issue,positive,neutral,neutral,neutral,neutral,neutral
707881800,"Yes, the dataset creation/parsing code that was used for the paper correctly processes the sustain control changes. Look for calls to `apply_sustain_control_changes`.

In V2 of the MAESTRO dataset, we include the following control changes: sostenuto (CC 66), una corda (CC 67), and sustain pedal (CC 64). We haven't explored processing any of those signals other than sustain, and our sustain handling is pretty simple: we consider sustain on if the value is >= 64, otherwise off.",yes code used paper correctly sustain control look maestro include following control sostenuto sustain pedal sustain sustain handling pretty simple consider sustain value otherwise,issue,positive,positive,neutral,neutral,positive,positive
707877353,"I haven't really done in-depth analysis for what's going on in the first steps of training. If you want to know exactly what's happening, I think the best thing to do would be to run inference using a checkpoint from that period and take a look at what the model is predicting for some sample files.",really done analysis going first training want know exactly happening think best thing would run inference period take look model sample,issue,positive,positive,positive,positive,positive,positive
707872686,I just tried the colab and it works for me. What browser are you using? I saw some discussion that the error about `google.colab._files` being undefined may be related to browser settings: https://github.com/googlecolab/colabtools/issues/51,tried work browser saw discussion error undefined may related browser,issue,negative,neutral,neutral,neutral,neutral,neutral
705179630,"> The metrics in the paper all come from the infer script, which we ran after training was complete. The frame metrics end up being calculated in infer_util.py, look in `define_metrics`.

Thank you so much! I'm sorry that I have just seen your reply, because I have earlier updated a question related to this. I'll read carefully infer_util.py.
",metric paper come infer script ran training complete frame metric end calculated look thank much sorry seen reply question related read carefully,issue,negative,negative,negative,negative,negative,negative
705177116,"Thank you very much for your reply. I'm very sorry for this so late reply, because of a busy period in last month.

It's still a bit difficult for me to understand that the ""valley"" of the recall and precision just after the training has started was **completely** zero (not nearly zero).
And this pattern seems to repeat each time a new training begins.

Could you please give me some intuition about this?

And has this phenomenon anything to do with the truncated_length, which has been set to 500 (original value is 1500, commented by 48s)? 

Thank you again!",thank much reply sorry late reply busy period last month still bit difficult understand valley recall precision training completely zero nearly zero pattern repeat time new training could please give intuition phenomenon anything set original value thank,issue,positive,negative,neutral,neutral,negative,negative
705162315,"Thank you very much for your detailed reply! I'm sorry to reply to you so late, because I was very busy last month and didn't log in Github.

Your reply has helped me a lot to form a much clearer picture of these two datasets. I want to try to modify the code of onsets_frames_transcription_create_dataset.py of the paper's version for the MAESTRO dataset.

To achieve this, I'd like to further consult you one more question about this: 
You mentioned that midi files in MAESTRO contain some control information. I'd like to know whether some of this control information would **affect the actual onsets and offsets** of the notes and (if yes) whether the onsets_frames_transcription_create_dataset.py of the paper's version **has functions to process this information** in order to acquire accurate onsets and offsets, (under the assumption that MAESTRO contains some **more** control information than MAPS which affects the onsets and offsets of the notes). 
This paragraph in your paper has inspired me of this question. 
""
> _we first translate “sustain pedal” control changes into longer note durations. If a note is active when sustain goes on, that note will be extended until either sustain goes off or the same note is played again_

"". 

In short, I just would like to know whether the onsets and offsets can be accurately derived by onsets_frames_transcription_create_dataset.py of the paper's version.

Thank you very much!



",thank much detailed reply sorry reply late busy last month log reply lot form much clearer picture two want try modify code paper version maestro achieve like consult one question maestro contain control information like know whether control information would affect actual yes whether paper version process information order acquire accurate assumption maestro control information paragraph paper inspired first translate sustain pedal control longer note note active sustain go note extended either sustain go note short would like know whether accurately derived paper version thank much,issue,positive,positive,neutral,neutral,positive,positive
704571806,"No problem, and yeah it's is an old stuff. However, I will try to investigate the issue carefully and ask for help as you suggest. 
Thanks for your response.  
Wish you good luck too! ",problem yeah old stuff however try investigate issue carefully ask help suggest thanks response wish good luck,issue,positive,positive,positive,positive,positive,positive
704556264,"Hi,
Really sorry about this but I have not actively worked on this code for a while and I have now moved on to working almost entirely on Pytorch projects, so I'm really not familiar with this issue anymore. I can't remember if I ended up having a solution for this, or what the solution was. I would suggesting trying to contact the magenta devs or contacting the user who made a pull request about his recently. I hope you can find a solution, good luck.",hi really sorry actively worked code working almost entirely really familiar issue ca remember ended solution solution would suggesting trying contact magenta user made pull request recently hope find solution good luck,issue,positive,positive,neutral,neutral,positive,positive
703958160,"> @ml4046 I got it to work! I am currently using the Basic RNN by the way, not the NoteRNN. It is generating proper MIDI outputs. By the way, I am actually editing the file in anaconda/envs/magenta...../rl_tuner.py and then running ""python rl_tuner.py"". Is there a better way to do this? I apologize if this is a pretty ridiculous question.
> 
> Thank you very much for the help.

Hi, sorry but I am facing the exact problem now. I am trying to tune an attention RNN, and still the dynamic batch size is creating problems. So how you got this to work?

Sorry for reopening an old thread. ",got work currently basic way generating proper way actually file running python better way apologize pretty ridiculous question thank much help hi sorry facing exact problem trying tune attention still dynamic batch size got work sorry old thread,issue,positive,negative,neutral,neutral,negative,negative
703943701,"CLAs look good, thanks!

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fmagenta%2Fmagenta%2Fpull%2F1832) for more info**.

<!-- ok -->",look good thanks information go,issue,positive,positive,positive,positive,positive,positive
703936735,"RNN network that downloaded from server has different vars names. Your fixes only works on basic rnn type, not the default tho. ",network server different work basic type default tho,issue,negative,neutral,neutral,neutral,neutral,neutral
703293602,I was able to solve the issue by remapping variable names explicitly from note_rnn_loader.py function get_variable_name_dict()  ,able solve issue variable explicitly function,issue,negative,positive,positive,positive,positive,positive
702915547,"It happens when I run on my computer too, but it doesn't cause errors, I am still able to make stuff.",run computer cause still able make stuff,issue,negative,positive,positive,positive,positive,positive
702147104,"Update: So I tried to run the training with a different dataset - and it seems to work.

So the problem is with my original dataset - can anyone point out what I can change to make it work? It's a nice one.",update tried run training different work problem original anyone point change make work nice one,issue,negative,positive,positive,positive,positive,positive
698240505,"@AI-Guru I have the same problem.
Did you manage to convert lakh dataset to tfrecord? If so, could you please share how?",problem manage convert could please share,issue,negative,neutral,neutral,neutral,neutral,neutral
697709938,Going to close this one in favor of #1822 because this one has something weird about its commit history that's causing problems with our import process.,going close one favor one something weird commit history causing import process,issue,negative,negative,negative,negative,negative,negative
697017100,"I'm not sure what you mean by target, but our pip package should be compatible with tensorflow v2 (though much of our code still uses the v1 compatibility module).",sure mean target pip package compatible though much code still compatibility module,issue,negative,positive,positive,positive,positive,positive
696443969,"


> Good morning I'm running on google collaborate the training of a model, tensorflow 2 and api object detection. It ran and stopped a few times because google colab disconnects from the notebook and I have to reconnect, but even every time the training continued where it left off. And now I have the message below:
> 
> RuntimeError: models/my_ssd_resnet50_v1_fpn/ckpt-23.data-00000-of-00001; No such file or directory
> 
> I tried to search all the directories for these files that you don't find, but there is no such file.
> 
> follow images:
> 
> first: error
> second: files on path within google colab ""models/my_ssd_resnet50_v1_fpn/""
> third: file checkpoint on ""models/my_ssd_resnet50_v1_fpn/""
> 
> ![colab-error](https://user-images.githubusercontent.com/71648038/93770939-3d29dd80-fbf3-11ea-8a54-b620acdc494c.JPG)
> ![path-](https://user-images.githubusercontent.com/71648038/93770957-431fbe80-fbf3-11ea-909d-00e1029e4ade.JPG)
> ![chk](https://user-images.githubusercontent.com/71648038/93787342-c0a0fa00-fc06-11ea-972c-fb506e204e67.JPG)

",good morning running collaborate training model object detection ran stopped time notebook reconnect even every time training continued left message file directory tried search find file follow first error second path within third file,issue,negative,positive,positive,positive,positive,positive
696371182,Can you clarify which Magenta project this question is about?,clarify magenta project question,issue,negative,neutral,neutral,neutral,neutral,neutral
695182268,"> How do you deal with the output corresponding to each frame under the condition that each adjacent frame overlaps, and 32 output results are obtained every 17920 sampling points. Is this the result of just retaining the first 512 of each frame ? If so, what is the length corresponding to the result of the last frame? Or you have used another processing method, may I have your idea?Looking forward to your answer, thank you!

Hi, I have the same question 
hop size = 512
input size = 17920
output shape = (32, 88)
17920/512 = 35
 32*512 = 16384
35 - 32 = 3 chunks
My question is, where are the positions of the three chunks that you ignore? or the 32 chunks represent only the first 13824 samples of the input ?",deal output corresponding frame condition adjacent frame output every sampling result retaining first frame length corresponding result last frame used another method may idea looking forward answer thank hi question hop size input size output shape question three ignore represent first input,issue,negative,positive,positive,positive,positive,positive
694515548,"Hi, nice catch! I've updated the notebook to Python 3 and tested it so it should be good to go. Thanks!",hi nice catch notebook python tested good go thanks,issue,positive,positive,positive,positive,positive,positive
691346084,"The metrics in the paper all come from the infer script, which we ran after training was complete. The frame metrics end up being calculated in infer_util.py, look in `define_metrics`.",metric paper come infer script ran training complete frame metric end calculated look,issue,negative,positive,neutral,neutral,positive,positive
689260482,"Then I encountered another problem. During my train time, my progress was killed by the system. My system version is ubuntu 20.04.
```
I0908 20:25:18.083855 140431052494592 transform.py:629] Created /tmp/tmpu_k00450.wav with effects: pitch contrast equalizer equalizer reverb
train.sh: line 7:  2988 Killed                  onsets_frames_transcription_train --examples_path=""${TRAIN_EXAMPLES}"" --model_dir=""${RUN_DIR}"" --mode='train'
```
My system log is as follows:
```
/var/log/kern.log:Sep  7 20:25:18 ubuntu kernel: [ 1559.596931] Out of memory: Killed process 2988 (onsets_frames_t) total-vm:8923132kB, anon-rss:4976568kB, file-rss:0kB, shmem-rss:0kB, UID:1000 pgtables:14880kB oom_score_adj:0
```
My system's memory is just 4G, so at least how much memory is needed to run this train? My tfrecord file is 681MB.",another problem train time progress system system version effect pitch contrast equalizer equalizer reverb line system log kernel memory process system memory least much memory run train file,issue,negative,negative,neutral,neutral,negative,negative
689253006,"> There's a typo when you're defining the path to the tfrecord (extra `i`): `TRAIN_EXAMPLEiS='./maps_config2_test.tfrecord'`. Is that what's causing the problem?

OMG! That's it. Thank you very much!",typo path extra causing problem thank much,issue,negative,positive,neutral,neutral,positive,positive
688999457,"I think what's happening here is that when the model is first initialized, it's making essentially random frame predictions, which results in a lot of note predictions, but most of them are wrong. The model then quickly learns that most frames do not have active notes, so note predictions drop to near zero. After that, you see it start to learn to actually recognize notes.",think happening model first making essentially random frame lot note wrong model quickly active note drop near zero see start learn actually recognize,issue,negative,negative,negative,negative,negative,negative
688997182,"The data used by Onsets and Frames from the two different datasets end up being basically the same: note start time, duration, and velocity. The goal of the dataset creation script is to take input from different datasets and convert it to a common input format.

The way that information is represented varies a little bit between MAPS and MAESTRO.  The txt files in MAPS have information that's equivalent to what's in the midi files (the extension doesn't matter). MAESTRO just uses midi files, but those midi files also contain some control changes that the MAPS ones don't (sostenuto and una corda), though this additional information is not used by Onsets and Frames. This is because the MAPS dataset started as MIDIs and was played back on a Disklavier, but MAESTRO started as live piano performances and was recorded by a Disklavier.",data used two different end basically note start time duration velocity goal creation script take input different convert common input format way information little bit maestro information equivalent extension matter maestro also contain control sostenuto though additional information used back maestro live piano,issue,negative,negative,neutral,neutral,negative,negative
688988751,There's a typo when you're defining the path to the tfrecord (extra `i`): `TRAIN_EXAMPLEiS='./maps_config2_test.tfrecord'`. Is that what's causing the problem?,typo path extra causing problem,issue,negative,neutral,neutral,neutral,neutral,neutral
687826041,"Hi, the Colab give me a new error :(

```
NotFoundError                             Traceback (most recent call last)
<ipython-input-3-98d96ca35b58> in <module>()
     66     'tfds_data_dir': ""gs://tfds-data/datasets"",
     67 })
---> 68 model = lib_model.Model.load_from_path(CKPT_DIR, flags)
     69 
     70 # Helper functions

2 frames
/usr/local/lib/python3.6/dist-packages/magenta/models/gansynth/lib/model.py in load_from_path(cls, path, flags)
    161     flags.print_values()
    162     # Get list_of_directories
--> 163     train_sub_dirs = sorted([sub_dir for sub_dir in tf.gfile.ListDirectory(path)
    164                              if sub_dir.startswith('stage_')])
    165     if not train_sub_dirs:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py in list_directory(dirname)
    669     errors.NotFoundError if directory doesn't exist
    670   """"""
--> 671   return list_directory_v2(dirname)
    672 
    673 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py in list_directory_v2(path)
    692         node_def=None,
    693         op=None,
--> 694         message=""Could not find directory {}"".format(path))
    695 
    696   # Convert each element to string, since the return values of the

NotFoundError: Could not find directory /content/gs:/magentadata/models/gansynth/acoustic_only
```",hi give new error recent call last module model helper path get sorted path directory exist return path could find directory path convert element string since return could find directory,issue,negative,positive,neutral,neutral,positive,positive
687416782,"Thank you for your kind reply. The reason why I'm trying to use MAESTRO with the older code is just that I'd like to be sure the model is exactly the same version as the paper.
If it's not sure that the provided tfrecords created by the newer version of onsets_frames_transcription_create_dataset.py, do you think I can use the original version of onsets_frames_transcription_create_dataset.py to make the tfrecords myself? I ask this question is because I'm not sure whether there are any difference in the data structure or information included between MAPS and MAESTRO. Just a brief looking:
MAP contains an additional txt for each piece of music, which seemed never used by onsets_frames_transcription_create_dataset.py. So this doesn't seem to be a problem.
MAESTRO has the midi files with the extension of midi, while MAPS with mid
MAESTRO has additional files related to splitting datasets, which can be done manually also with the older version of the onsets_frames_transcription_create_dataset.py. So this doesn't seem to be a problem.
And if there's any other difference in the information contained in the midi files which could matter?

Thank you very much!
",thank kind reply reason trying use maestro older code like sure model exactly version paper sure provided version think use original version make ask question sure whether difference data structure information included maestro brief looking map additional piece music never used seem problem maestro extension mid maestro additional related splitting done manually also older version seem problem difference information could matter thank much,issue,positive,positive,positive,positive,positive,positive
687379207,"Thank you so much for your reply, really very clear!
Just to make sure my understanding is right or not.
I'd like to further ask whether the frame-based metrics in Table 1 in the paper is calculated by the lines of 285-290 and 387-394 in _get_eval_metrics() in train_util.py when running onsets_frames_transcription_train.py with the parameter mode being ""eval"" and dataset used being the test-split of MAPS dataset (i.e. maps_config2_test.tfrecord) created by onsets_frames_transcription_create_dataset.py.

Sorry for taking up your time and thank you!",thank much reply really clear make sure understanding right like ask whether metric table paper calculated running parameter mode used sorry taking time thank,issue,positive,positive,positive,positive,positive,positive
687102754,"I signed it!

2020년 8월 29일 (토) 오후 5:09, googlebot <notifications@github.com>님이 작성:

> Thanks for your pull request. It looks like this may be your first
> contribution to a Google open source project (if not, look below for help).
> Before we can look at your pull request, you'll need to sign a Contributor
> License Agreement (CLA).
>
> 📝 *Please visit https://cla.developers.google.com/
> <https://cla.developers.google.com/> to sign.*
>
> Once you've signed (or fixed any issues), please reply here with @googlebot
> I signed it! and we'll verify it.
> ------------------------------
> What to do if you already signed the CLA Individual signers
>
>    - It's possible we don't have your GitHub username or you're using a
>    different email address on your commit. Check your existing CLA data
>    <https://cla.developers.google.com/clas> and verify that your email is
>    set on your git commits
>    <https://help.github.com/articles/setting-your-email-in-git/>.
>
> Corporate signers
>
>    - Your company has a Point of Contact who decides which employees are
>    authorized to participate. Ask your POC to be added to the group of
>    authorized contributors. If you don't know who your Point of Contact is,
>    direct the Google project maintainer to go/cla#troubleshoot (Public
>    version <https://opensource.google/docs/cla/#troubleshoot>).
>    - The email used to register you as an authorized contributor must be
>    the email used for the Git commit. Check your existing CLA data
>    <https://cla.developers.google.com/clas> and verify that your email is
>    set on your git commits
>    <https://help.github.com/articles/setting-your-email-in-git/>.
>    - The email used to register you as an authorized contributor must
>    also be attached to your GitHub account
>    <https://github.com/settings/emails>.
>
> ℹ️ *Googlers: Go here
> <https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Fmagenta%2Fmagenta%2Fpull%2F1803>
> for more info*.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/pull/1803#issuecomment-683254963>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AI2DFKKINMEQG56KJBNIUITSDCZTTANCNFSM4QO3IXWQ>
> .
>
",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account information go thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
686240980,"I also tried to reproduce with TensorFlow lite's example ""image_classification"" using the following steps:
1. get example app from https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios/ImageClassification
2. follow instructions from https://www.tensorflow.org/lite/performance/gpu to change Podfile to point to 
pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['Metal']
3. in ModelDataHandler/ModelDataHandler.swift add/modify the following lines:
 let delegate = MetalDelegate()
    do {
      // Create the `Interpreter`.
      interpreter = try Interpreter(modelPath: modelPath, options: options, delegates: [delegate])
4. build with the original model file from example, and see that it runs
5. replace Model/mobilenet_quant_v1_224.tflite file with onsets_frames_wavinput.tflite (just copy over and rename is easiest)
6. build and run, it'll throw the following error


2020-09-02 23:07:50.375480-0500 ImageClassification[22868:4422283] Created TensorFlow Lite delegate for Metal.
2020-09-02 23:07:50.375676-0500 ImageClassification[22868:4422283] Metal GPU Frame Capture Enabled
2020-09-02 23:07:50.376394-0500 ImageClassification[22868:4422283] Metal API Validation Enabled
2020-09-02 23:07:50.554220-0500 ImageClassification[22868:4422283] Initialized TensorFlow Lite runtime.
TensorFlow Lite Error: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
Failed to create the interpreter with error: Failed to create the interpreter.
Fatal error: Model set up failed: file /Volumes/TBT3_SSD/git/examples/lite/examples/image_classification/ios/ImageClassification/ViewControllers/ViewController.swift, line 56
2020-09-02 23:07:50.758405-0500 ImageClassification[22868:4422283] Fatal error: Model set up failed: file /Volumes/TBT3_SSD/git/examples/lite/examples/image_classification/ios/ImageClassification/ViewControllers/ViewController.swift, line 56",also tried reproduce lite example following get example follow change point pod following let delegate create interpreter interpreter try interpreter delegate build original model file example see replace file copy rename easiest build run throw following error lite delegate metal metal frame capture metal validation lite lite error use delegate graph create interpreter error create interpreter fatal error model set file line fatal error model set file line,issue,negative,positive,neutral,neutral,positive,positive
686220008,"Sorry I found that the reason I didn't see issues in iOS is because I accidentally disabled the GPU delegate.
here's what I see in Xcode debug console:

Following operations are not supported by GPU delegate:
GATHER: Operation is not supported.
PACK: Operation is not supported.
PAD: Invalid paddings tensor shape: expected 4x2 or 3x2, got 2x2
SPLIT: Operation is not supported.
72 operations will run on the GPU, and the remaining 2658 operations will run on the CPU.Following operations are not supported by GPU delegate:
GATHER: Operation is not supported.
PACK: Operation is not supported.
PAD: Invalid paddings tensor shape: expected 4x2 or 3x2, got 2x2
SPLIT: Operation is not supported.
72 operations will run on the GPU, and the remaining 2658 operations will run on the CPU.
TensorFlowLite.Interpreter:.ctor(Byte[], InterpreterOptions)


Restored original execution plan after delegate application failure.Restored original execution plan after delegate application failure.
TensorFlowLite.Interpreter:.ctor(Byte[], InterpreterOptions)
MnistSample:Start()
 
(Filename: ./Runtime/Export/Debug/Debug.bindings.h Line: 35)

Exception: Failed to create TensorFlowLite Interpreter
  at TensorFlowLite.Interpreter..ctor (System.Byte[] modelData, TensorFlowLite.InterpreterOptions options) [0x00000] in <00000000000000000000000000000000>:0 
  at MnistSample.Start () [0x00000] in <00000000000000000000000000000000>:0 
 
(Filename: currently not available on il2cpp Line: -1)",sorry found reason see accidentally disabled delegate see console following delegate gather operation pack operation pad invalid tensor shape got split operation run run delegate gather operation pack operation pad invalid tensor shape got split operation run run original execution plan delegate application original execution plan delegate application failure start line exception create interpreter currently available line,issue,negative,positive,neutral,neutral,positive,positive
685731036,"Thanks for the reminder. Unfortunately it hasn't been updated on the colab server yet. If it's not up tomorrow, I will see if I can figure out what's going on.",thanks reminder unfortunately server yet tomorrow see figure going,issue,negative,negative,negative,negative,negative,negative
685217615,"Thank you! I’ll see if I could cut other parts of the app.
As you mentioned the amount of calculations is quite big. The phone gets
hot quite quickly. I’ll see if I could figure out when is silence so that I
can skip calculation.

On Tue, Sep 1, 2020 at 5:28 PM Mike Tyka <notifications@github.com> wrote:

> While one could make the chunks smaller and update the output more
> frequently this degrades the performance because the LSTMs need to build up
> state & context. In the unidirectional case one could manually carry over
> the LSTM states from chunk to chunk but we chose not to do that because of
> the additional bookkeeping complexity. In the bidirectional case this isn't
> possible at all unless you know the future.
> However this doesn't really address the amount of computation that needs
> to happen per unit real time, so with these models the GPU you're using may
> be simply too slow to avoid the latency. 150ms on a phone doesn't seem bad
> at all.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1806#issuecomment-685167454>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AQYFWQGLS4HH5J3B223TWLLSDVYSVANCNFSM4QPFHDQQ>
> .
>
",thank see could cut amount quite big phone hot quite quickly see could figure silence skip calculation tue mike wrote one could make smaller update output frequently performance need build state context unidirectional case one could manually carry chunk chunk chose additional bookkeeping complexity bidirectional case possible unless know future however really address amount computation need happen per unit real time may simply slow avoid latency phone seem bad thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
685167454,"While one could make the chunks smaller and update the output more frequently this degrades the performance because the LSTMs need to build up state & context. In the unidirectional case one could manually carry over the LSTM states from chunk to chunk but we chose not to do that because of the additional bookkeeping complexity. In the bidirectional case this isn't possible at all unless you know the future.
However this doesn't really address the amount of computation that needs to happen per unit real time, so with these models the GPU you're using may be simply too slow to avoid the latency. 150ms on a phone doesn't seem bad at all.
",one could make smaller update output frequently performance need build state context unidirectional case one could manually carry chunk chunk chose additional bookkeeping complexity bidirectional case possible unless know future however really address amount computation need happen per unit real time may simply slow avoid latency phone seem bad,issue,negative,negative,neutral,neutral,negative,negative
684867532,"Sorry, I realized it might be because of the old android device I have. It works fine on iPhone 7.
I'm using Unity plugin from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/experimental/examples/unity/TensorFlowLitePlugin

I'll try regular TensorFlow model with Unity ML Agent instructions.
Is there a real time TensorFlow model for Onsets & Frames from Magenta? The real time models require 17920 samples for each frame and 4096 for each incremental, at sampling rate of 16000. That translates to a lot of latency. e.g. on my iPhone 7, it took 150 ms to process each frame. That means noticeable delay when user press a key on piano. Is there any way to reduce this latency?",sorry might old android device work fine unity try regular model unity agent real time model magenta real time require frame incremental sampling rate lot latency took process frame noticeable delay user press key piano way reduce latency,issue,negative,positive,neutral,neutral,positive,positive
684130660,"I'm not sure if that will work or not, but you could certainly try! Is there a reason you want to use MAESTRO with the older code?",sure work could certainly try reason want use maestro older code,issue,positive,positive,positive,positive,positive,positive
684125029,"eval_train is certainly not required. The purpose of that dataset is just as a ""debugging"" evaluation to make sure the model is actually fitting the training dataset. The dataset is generated from the 'train' split (as you can see from the 'maestro' example in configs.py), it's just done with `process_for_training=False`, which means the training data won't be split into smaller chunks and won't have any audio augmentation or other modification done to it.",certainly purpose evaluation make sure model actually fitting training split see example done training data wo split smaller wo audio augmentation modification done,issue,positive,positive,positive,positive,positive,positive
684121187,A Bus error typically indicates you're using a version of TensorFlow compiled with instructions that your CPU/GPU does not support. You'll need to install a different version of TensorFlow or possibly compile from source to ensure your instruction set is supported. More details here: https://www.tensorflow.org/install,bus error typically version support need install different version possibly compile source ensure instruction set,issue,negative,negative,neutral,neutral,negative,negative
684120349,"Hmm that's odd because the model linked from https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription/realtime
*is* a static model. Do you have code that I can try running to reproduce this ?

Also, If you have a GPU - why not use the full Tensorflow model ? The TFlite model is really primarily for CPU execution on embedded CPUs..
",odd model linked static model code try running reproduce also use full model model really primarily execution,issue,negative,positive,positive,positive,positive,positive
684120287,"Is this not covered by the sound libraries installation command above in the readme?

```
sudo apt-get install build-essential libasound2-dev libjack-dev portaudio19-dev
```

At what point do you get the error message?",covered sound installation command install point get error message,issue,negative,positive,positive,positive,positive,positive
684117754,"You're correct, we just use the same frame size as what the model outputs (32ms). I actually hadn't noticed the reference to the 10ms size in that paper before now, so perhaps we should have done something different here.

For the papers we were comparing against, it's not totally clear if they used the 10ms or 32ms frame size for comparison. In any case, as we argue in the paper I think the Note F1 score is a much more important comparison, and that metric isn't tied to frame size.",correct use frame size model actually reference size paper perhaps done something different totally clear used frame size comparison case argue paper think note score much important comparison metric tied frame size,issue,negative,positive,positive,positive,positive,positive
684113256,"It's been a while since I looked at the code as it was in that commit, but I believe 'note_f1' uses the frame prediction output of the model and 'onset_note_f1' uses the onset prediction of the model. Both convert those predictions from a piano roll to a note sequence and then use mir_eval to compute the scores.

That said, what you really want is the output of `onsets_frames_transcription_infer`. The score that script outputs will include inference on the full length of the files and will combine the onset and frame predictions from the model into a single output. The `metrics/note_f1_score1` output of that script is most likely what you're looking for.",since code commit believe frame prediction output model onset prediction model convert piano roll note sequence use compute said really want output score script include inference full length combine onset frame model single output output script likely looking,issue,negative,positive,positive,positive,positive,positive
683835018,Fix is on the way -- should be out in a day or two. Sorry for the issue!,fix way day two sorry issue,issue,negative,negative,negative,negative,negative,negative
683760355,"@adarob Thank you sir. I have set to 'gs://tfds-data/datasets' , but still don't get it. ",thank sir set still get,issue,negative,neutral,neutral,neutral,neutral,neutral
683421442,That value needs to be set to 'gs://tfds-data/datasets'. I can fix this on Monday if nobody gets to it first!,value need set fix nobody first,issue,negative,positive,positive,positive,positive,positive
681893587,"Apparently I was using a wrong DNS, forcing the DNS to 1.1.1.1 made it be reachable.",apparently wrong forcing made reachable,issue,negative,negative,negative,negative,negative,negative
675508285,"Thank you very much,ys23! I appreciate your help.
You temporary solution also shows me that I need to know the python tools (pip) a lot better.",thank much appreciate help temporary solution also need know python pip lot better,issue,positive,positive,positive,positive,positive,positive
675244492,"The latest magenta version 2.1.0, is not working properly on Windows now. So you need to install lower version like 2.0.1 I think.",latest magenta version working properly need install lower version like think,issue,negative,positive,positive,positive,positive,positive
675220410,"Hello nak21 shenyt1569
You need to avoid jaxlib. Below is temporary solution.  I continue to hope that it will be fixed normally.

1. Installing magenta without all dependencies.

pip install --no-deps magenta==2.0.1 

2. Instaling tensor2tensor without all dependencies.

pip install --no-deps tensor2tensor

3. Creating requirements.txt. You need to add libraries that I have listed below.

absl-py
apache-beam[gcp] >= 2.14.0
attrs
bokeh >= 0.12.0
dm-sonnet
imageio
intervaltree >= 2.1.0
IPython
joblib >= 0.12
librosa >= 0.6.2
matplotlib >= 1.5.3
mido == 1.2.6
mir_eval >= 0.4
numba <= 0.43.0
numpy
pandas >= 0.18.1
Pillow >= 3.4.2
pretty_midi >= 0.2.6
protobuf >= 3.6.1
pygtrie >= 2.3
python-rtmidi >= 1.1, < 1.2
scikit-image
scipy >= 0.18.1
six >= 1.12.0
sk-video
sox >= 1.3.7
#tensor2tensor
tensorflow-datasets
tensorflow-probability==0.7.0
tf_slim
wheel
bz2file
flask
future
gevent
gin-config
google-api-python-client
gunicorn
gym
h5py
kfac
llvmlite==0.32.1
mesh-tensorflow
oauth2client
opencv-python
pypng
requests
sympy
tensorflow-addons
tensorflow-gan
tqdm

4. Installing remained libraries through requirements.txt.

pip install -r requirements.txt

",hello nak need avoid temporary solution continue hope fixed normally magenta without pip install without pip install need add listed pillow six wheel flask future gym pip install,issue,negative,positive,neutral,neutral,positive,positive
675020936,"This should be fixed by #1775, but it won't take effect until the next release of the magenta pip package.  For now, if you just run that Setup Environment cell again it should work.",fixed wo take effect next release magenta pip package run setup environment cell work,issue,negative,positive,neutral,neutral,positive,positive
674982832,"Very strange. Could there be something wrong with your network? The only thing I know the piano scribe demo does weirdly is that if you access it over http, it forces a redirect to https, is it possible you have an extension or a security thing that forces redirects? In any case, explicitely accessing https://piano-scribe.glitch.me/ should work.

Do other glitch projects load for you? (like http://drumbot.glitch.me/). 

Here's the ping from my end 🤷‍♀️:
<img width=""656"" alt=""Screen Shot 2020-08-17 at 9 28 01 AM"" src=""https://user-images.githubusercontent.com/1369170/90420138-698a9100-e06c-11ea-9270-0079aa0221ac.png"">

",strange could something wrong network thing know piano scribe weirdly access redirect possible extension security thing case work load like ping end screen shot,issue,negative,negative,negative,negative,negative,negative
674946621,"



> nak21, Thank you for your mention. I temporarily fixed it by myself but I also hope that magenta team fix it fundamentally. It's a bug I think.

Hello,ys23!
Could you tell me how you did the fix?
Thanks so much.",nak thank mention temporarily fixed also hope magenta team fix fundamentally bug think hello could tell fix thanks much,issue,positive,positive,positive,positive,positive,positive
674910690,"Hi Yoshihiro, If it wouldn't be too much trouble,could you tell me how
you did the fix?

I've just noticed that the Magenta team separated music out from the
magenta package.
They call it note-seq. I'll see if this installs correctly.

Thanks, Steve

On 8/17/20, Yoshihiro Saito <notifications@github.com> wrote:
> nak21, Thank you for your mention. I temporarily fixed it by myself but I
> also hope that magenta team fix it fundamentally. It's a bug I think.
>
> --
> You are receiving this because you commented.
> Reply to this email directly or view it on GitHub:
> https://github.com/magenta/magenta/issues/1786#issuecomment-674897347
",hi would much trouble could tell fix magenta team music magenta package call see correctly thanks wrote nak thank mention temporarily fixed also hope magenta team fix fundamentally bug think reply directly view,issue,positive,positive,neutral,neutral,positive,positive
674897347,"nak21, Thank you for your mention. I temporarily fixed it by myself but I also hope that magenta team fix it fundamentally. It's a bug I think.",nak thank mention temporarily fixed also hope magenta team fix fundamentally bug think,issue,positive,positive,neutral,neutral,positive,positive
674893115,"ys23,I've got the same problem. I hope someone from the Magenta team gives some help.
It looks like there isn't a windows version currently of jaxlib which dopamine-rl is dependent on.
",got problem hope someone magenta team help like version currently dependent,issue,positive,neutral,neutral,neutral,neutral,neutral
674855682,"> It works for me right now. Maybe try refreshing again?
> […](#)
> On Sat, Aug 15, 2020 at 10:03 AM Lorenzo Rutayisire < ***@***.***> wrote: Hi, I was reading at the ""Onsets and frames"" project and I was interested in testing out the in-browser demo ""Piano Scribe"", but unfortunately the website hosting it is offline https://piano-scribe.glitch.me/. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#1790>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAKOIUQAJK73KT47NDUGYF3SA25UTANCNFSM4QALSYEA> .

Mh weird, it gives me an error saying it's not able to resolve the domain piano-scribe.glitch.me. I'm not even able to ping it.",work right maybe try refreshing sat wrote hi reading project interested testing piano scribe unfortunately hosting thread reply directly view weird error saying able resolve domain even able ping,issue,negative,positive,positive,positive,positive,positive
674804365,"@ClarkChin08 You are very welcome. 

This link may help you.

👉https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#used-in-the-notebooks_1


And the github path:
👉tensorflow/python/training/tracking/util.py



If there is any question, it is my pleasure to help. ",welcome link may help path question pleasure help,issue,positive,positive,positive,positive,positive,positive
674772252,"> Hello, You can find good tips in this link.
> 
> https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/

thanks @IT-eng-max i have completed the transformation right. but i found tensorflow-hub have a v2 version module(https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2), but seems the pretrained model in this repo's README (https://storage.googleapis.com/download.magenta.tensorflow.org/models/arbitrary_style_transfer.tar.gz) was still v1 version, it's not the same, can you supply the v2 version pretrained checkpoint for me to do some tests?",hello find good link thanks transformation right found version module model still version supply version,issue,positive,positive,positive,positive,positive,positive
674767800,"Hello, You can find good tips in this link.

https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/",hello find good link,issue,negative,positive,positive,positive,positive,positive
674696124,"@khanhlvg hi i noticed tf_hub has add a V2 style transfer model, but the pretrained checkpoint seems still the V1 model, can you share the V2 pretrained checkpoint?",hi add style transfer model still model share,issue,negative,neutral,neutral,neutral,neutral,neutral
674667598,i use tf1.5 completed the transformation. But it's strange why tf2.3 can't do this even we use tf.compat.v1,use transformation strange ca even use,issue,negative,negative,neutral,neutral,negative,negative
674644355,"It works for me right now. Maybe try refreshing again?


On Sat, Aug 15, 2020 at 10:03 AM Lorenzo Rutayisire <
notifications@github.com> wrote:

>
>
> Hi, I was reading at the ""Onsets and frames"" project and I was interested
> in testing out the in-browser demo ""Piano Scribe"", but unfortunately the
> website hosting it is offline https://piano-scribe.glitch.me/.
>
>
>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1790>, or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAKOIUQAJK73KT47NDUGYF3SA25UTANCNFSM4QALSYEA>
> .
>
>
>
",work right maybe try refreshing sat wrote hi reading project interested testing piano scribe unfortunately hosting thread reply directly view,issue,negative,positive,positive,positive,positive,positive
673401938,"> Oops, yes you're correct! If you have time, feel free to send a PR with the fix. Otherwise, I'll get around to updating it at some point.
> […](#)
> On Mon, Aug 3, 2020 at 2:48 PM sweetorangetree ***@***.***> wrote: I think you want the command line argument --hparams=transform_audio=false . Thank you very much for your soon reply! I found it. Please also have a look at this sentence ""Note that if you have the *audio_transform* hparam set to true (which it is by default), you will need to have the sox binary installed on your system."" in the README.md . Guess ""audio_transform"" should be ""transform_audio"". — You are receiving this because you modified the open/close state. Reply to this email directly, view it on GitHub <[#1776 (comment)](https://github.com/magenta/magenta/issues/1776#issuecomment-668258207)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAAFXAVPJCRIKGIXLM2V5DLR64WBLANCNFSM4PSQS37A> .
Thank you for your reply:) I'll send a PR soon.
Sorry for this late reply. I didn't log in Github previously.
",yes correct time feel free send fix otherwise get around point mon wrote think want command line argument thank much soon reply found please also look sentence note set true default need binary system guess state reply directly view comment thank reply send soon sorry late reply log previously,issue,positive,positive,neutral,neutral,positive,positive
673149164,"Hi Mark, I'm in your same situation. I'm doing my master thesis based on GANSynth. I'm trying to study the code for substitute the instruments gived in the Colab file, with mine. I'm trying to understand how modify the code for insert other informations more than the timbre and the pitch for the interpolation. If you have some news to how do this contact me, I'll do the same!

Gianpiero Palermo",hi mark situation master thesis based trying study code substitute file mine trying understand modify code insert timbre pitch interpolation news contact,issue,negative,neutral,neutral,neutral,neutral,neutral
668259223,"Oops, yes you're correct! If you have time, feel free to send a PR with the
fix. Otherwise, I'll get around to updating it at some point.

On Mon, Aug 3, 2020 at 2:48 PM sweetorangetree <notifications@github.com>
wrote:

> I think you want the command line argument --hparams=transform_audio=false
> .
>
> Thank you very much for your soon reply! I found it.
> Please also have a look at this sentence ""Note that if you have the
> *audio_transform* hparam set to true (which it is by default), you will
> need to have the sox binary installed on your system."" in the README.md .
> Guess ""audio_transform"" should be ""transform_audio"".
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1776#issuecomment-668258207>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAAFXAVPJCRIKGIXLM2V5DLR64WBLANCNFSM4PSQS37A>
> .
>
",yes correct time feel free send fix otherwise get around point mon wrote think want command line argument thank much soon reply found please also look sentence note set true default need binary system guess state reply directly view,issue,positive,positive,positive,positive,positive,positive
668258207,"> I think you want the command line argument `--hparams=transform_audio=false`.

Thank you very much for your soon reply! I found it. 
Please also have a look at this sentence ""Note that if you have the _audio_transform_ hparam set to true (which it is by default), you will need to have the sox binary installed on your system."" in the README.md . Guess ""audio_transform"" should be ""transform_audio"".

",think want command line argument thank much soon reply found please also look sentence note set true default need binary system guess,issue,positive,positive,positive,positive,positive,positive
668242702,I think you want the command line argument `--hparams=transform_audio=false`.,think want command line argument,issue,negative,neutral,neutral,neutral,neutral,neutral
667921968,"> Okay, solved. So you don't really need to have a `model.ckpt` file. What I do is that I passed the argument `arbitrary_style_transfer/model.ckpt` into `--checkpoint` and it works. No need to have the `ckpt` file
Hoe to pass arbitrary_style_transfer/model.ckpt to checkpoint
",really need file argument work need file hoe pas,issue,negative,positive,positive,positive,positive,positive
667325444,"@adarob Adam, this is not cool at all. And it is very disrespectful. No wonder Colabs do not work. 

But thank you so much for these clarifications because now I know exactly what to do.",cool disrespectful wonder work thank much know exactly,issue,positive,positive,positive,positive,positive,positive
667320576,"Also, if you're looking for easier-to-use interfaces targeted at musicians instead of researchers, please see g.co/magenta/studio.",also looking targeted instead please see,issue,negative,neutral,neutral,neutral,neutral,neutral
667312700,"Please reconsider how you are addressing people who have put a lot of work into this project, and open a new issue with more respectful language.",please reconsider people put lot work project open new issue respectful language,issue,positive,positive,positive,positive,positive,positive
665033949,"You can try adding a beam.Reshuffle() after the beam.io.tfrecord.ReadAllFromTFRecord (https://github.com/magenta/magenta/blob/425d0e471181a7f3f4af7d13dd34072162304fda/magenta/models/score2perf/datagen_beam.py#L65). I think that will do the trick. If so, we can add it to the code.",try think trick add code,issue,negative,neutral,neutral,neutral,neutral,neutral
664991788,"> @inventor71 Hi, have you figured out the `hparams` if `self_attention_type=dot_product_relative_v2`?
> 
> Thanks.

It's been a while since I last looked into ai-based music. Sorry I couldn't provide you a lot of help. 
I'm closing the issue now.",inventor hi figured thanks since last music sorry could provide lot help issue,issue,positive,negative,neutral,neutral,negative,negative
664796783,"> Not sure which visualization in particular you're referring to -- if you mean the visualizations of MIDI files on the [blog](https://magenta.tensorflow.org/music-transformer), they're done with one of the magenta.js Visualizers (you can see a demo of them in action [here](https://tensorflow.github.io/magenta-js/music/demos/visualizer.html))
> 
> For the attention, we built an interactive [attention visualizer](https://meowni.ca/transformer-visualization/). You can load any of the figures in the paper up, and then click on any of the notes to visualize the attention for that note.

[attention visualizer](https://meowni.ca/transformer-visualization/) page not found.",sure visualization particular mean done one see action attention built interactive attention visualizer load paper click visualize attention note attention visualizer page found,issue,negative,positive,positive,positive,positive,positive
664794427,"@inventor71 Hi, have you figured out the `hparams` if `self_attention_type=dot_product_relative_v2`?

Thanks.",inventor hi figured thanks,issue,negative,positive,positive,positive,positive,positive
664743703,"I see, is it possible if we first load this whole single shard, then do parallel computing on each individual sample? Which maybe a little bit slower than do parallel on each shard.

And, generating training data locally took me about 3hrs, not that ""bad""(days mentioned in the above comment). With more cores, we would expect this process down to minutes. 

For now, my training process looks good, but the outputted ""tfevents"" may be too much(13G `tfevents` for 50k steps, roughly 260G needed for 1M steps), so I was wondering is there any `hparams` to decrease the summarization of the training process.

Thanks for your help.",see possible first load whole single shard parallel individual sample maybe little bit parallel shard generating training data locally took bad day comment would expect process training process good may much roughly wondering decrease summarization training process thanks help,issue,positive,positive,neutral,neutral,positive,positive
664438100,"@attardi can you try installing tensorflow 1.15 and see if it works? You can do this with `pip install ""tensorflow==1.15.*""`",try see work pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
664425682,I think the issue is that the tfrecords only have a single shard each. We should probably release a version with more shards to take advantage of parallelism.,think issue single shard probably release version take advantage parallelism,issue,negative,negative,neutral,neutral,negative,negative
664199588,"Hi, @iansimon on which aspect we can improve the `data-gen` speed locally, like more cores/RAM? Currently, I see only 1 CPU(out of 40) using, also my RAM usage is only about 1%.

Thanks.

",hi aspect improve speed locally like currently see also ram usage thanks,issue,positive,positive,neutral,neutral,positive,positive
662333053,"I have a similar problem running

    t2t_trainer --hparams=label_smoothing=0.0,max_length=0,max_target_seq_length=2048 --hparams_set=score2perf_transformer_base --model=transformer --problem=score2perf_maestro_language_uncropped_aug

    I0721 21:07:22.561720 140600872367936 saver.py:1293] Restoring parameters from maestro/training/model.ckpt-1000
    2020-07-21 21:07:22.727872: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key transformer/parallel_0_3/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
    tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.
      (0) Not found: Key transformer/parallel_0_3/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
    	 [[{{node save/RestoreV2_1}}]]
    	 [[save/RestoreV2_1/_101]]
      (1) Not found: Key transformer/parallel_0_3/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[{{node save/RestoreV2_1}}]]
    0 successful operations.
    0 derived errors ignored.

    During handling of the above exception, another exception occurred:
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py"", line 1299, in restore
    {self.saver_def.filename_tensor_name: save_path})
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 958, in run
    run_metadata_ptr)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1181, in _run
    feed_dict_tensor, options, run_metadata)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1359, in _do_run
    run_metadata)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
    tensorflow.python.framework.errors_impl.NotFoundError: 2 root error(s) found.
      (0) Not found: Key transformer/parallel_0_3/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[node save/RestoreV2_1 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1643) ]]
	 [[save/RestoreV2_1/_101]]
      (1) Not found: Key transformer/parallel_0_3/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel not found in checkpoint
	 [[node save/RestoreV2_1 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1643) ]]
    0 successful operations.
    0 derived errors ignored.

Strangely enough, if I repeat the command, it is able to complete the checkpoint:

    I0721 19:57:16.328476 139716674180928 basic_session_run_hooks.py:613] Saving checkpoints for 1000 into maestro/training/model.ckpt.
    2020-07-21 19:57:19.531857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
    I0721 19:57:22.036410 139716674180928 basic_session_run_hooks.py:262] loss = 4.03043, step = 1000
    I0721 19:57:43.517246 139716674180928 basic_session_run_hooks.py:700] global_step/sec: 4.65139
    I0721 19:57:43.518301 139716674180928 basic_session_run_hooks.py:260] loss = 3.5795429, step = 1100 (21.482 sec)
    I0721 19:57:59.702682 139716674180928 basic_session_run_hooks.py:700] global_step/sec: 6.17837

but it fails again at the next checkpoint after each 1000 steps.

Any help appreciated.
",similar problem running found key found recent call last file line return file line file line root error found found key found node found key found node successful derived handling exception another exception recent call last file line restore file line run file line file line file line raise type message root error found found key found node defined found key found node defined successful derived strangely enough repeat command able complete saving successfully dynamic library loss step loss step sec next help,issue,positive,positive,positive,positive,positive,positive
660519956,"I think I fixed it?? Just added this in `gansynth_generate.py` under `import tensorflow.compat.v1 as tf`

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)",think fixed added import true sess,issue,negative,positive,positive,positive,positive,positive
660334457,I should have a fix for this on Monday. Thanks for your help and patience!,fix thanks help patience,issue,positive,positive,positive,positive,positive,positive
659064089,"Nice! Sorry we're super busy at the moment, but we'll try to update the gansynth code to make this the default way that training happens.",nice sorry super busy moment try update code make default way training,issue,positive,positive,positive,positive,positive,positive
657353076,"Yes! I have also been able to reproduce the results of the paper. Whew. 
I am using TF2, and tfds with the gansynth dataset. I had to make tweaks to dataset.py (for the new data format), and to data_helpers.py for version updating. Also, the hard-coded pitch_counts in datasets.py were incorrect for the gansynth data sets (the sum of the counts=81454 in the code, but nsynth/gansynth_subset has 60,788 in the train set and 886,755 in all). 
Thanks,
",yes also able reproduce paper whew make new data format version also incorrect data sum code train set thanks,issue,positive,positive,positive,positive,positive,positive
656344501,"The code for generating the processed dataset from the parquetio (containing fonts in SFD, a common font file format) is in the [svg vae repository](https://github.com/magenta/magenta/tree/master/magenta/models/svg_vae).

The code for generating the parquetio's SFD from .ttf files should be straightforward to implement with fontforge.

Unfortunately, we are unable to release the processed dataset or the parquetio in their raw formats.",code generating common font file format repository code generating straightforward implement unfortunately unable release raw,issue,negative,negative,negative,negative,negative,negative
655827177,"> Thanks for the question!
> 
> When we started the project, we already had the parquetio database in the format described. The work of collecting fonts (originally in .ttf, and other formats) and converting them to sfd to populate the parquetio was done before we started this project. I know that effort used fontforge to make this conversion, but unfortunately the exact code we used no longer exists.
> 
> Hope this is useful!

Thank you for your reply. If the data generation code is unable, will you consider to release the dataset used for this work? ",thanks question project already format work originally converting populate done project know effort used make conversion unfortunately exact code used longer hope useful thank reply data generation code unable consider release used work,issue,positive,positive,positive,positive,positive,positive
655727795,"Thanks for the question! 

When we started the project, we already had the parquetio database in the format described. The work of collecting fonts (originally in .ttf, and other formats) and converting them to sfd to populate the parquetio was done before we started this project. I know that effort used fontforge to make this conversion, but unfortunately the exact code we used no longer exists.

Hope this is useful!",thanks question project already format work originally converting populate done project know effort used make conversion unfortunately exact code used longer hope useful,issue,positive,positive,positive,positive,positive,positive
655057384,Sorry about this issue. I just sent out a fix internally but it will take 1-2 days for it to appear in Colab. A simple fix is to switch the runtime to py3 and remove the versioning when pip installing magenta.,sorry issue sent fix internally take day appear simple fix switch remove pip magenta,issue,negative,negative,negative,negative,negative,negative
654616700,This should have been fixed recently. Could you try again with tfds-nightly ? Previously there was a bug where only the first 1000 files would be downloaded from GCS.,fixed recently could try previously bug first would,issue,negative,positive,neutral,neutral,positive,positive
654610025,Let's see if @iRapha can help with this one.,let see help one,issue,negative,neutral,neutral,neutral,neutral,neutral
654235441,"Yes, they are too strict on those other packages. Unfortunately we don't control their requirements so we just have to ignore until they update.",yes strict unfortunately control ignore update,issue,negative,negative,negative,negative,negative,negative
652830573,"I have not been able to reconstruct the compatible combination of legacy tensorflow, magenta, tfds, and nsynth versions in order to reproduce the results reported in the GANSynth paper. 

I thought my best hope might be to move to Tensorflow 2.2.0, the latest tdfs and magenta, and nsynth 2.3.2. I am still struggling to make the necessary changes to datasets.py to accommodate tdfs, new nsynth feature formats, etc. Humans reproduce faster than these results!



",able reconstruct compatible combination legacy magenta order reproduce paper thought best hope might move latest magenta still struggling make necessary accommodate new feature reproduce faster,issue,positive,positive,positive,positive,positive,positive
650689230,"> @shansiliu95 - Hey, that's fantastic you were able to reproduce this data!
> What did you have to do to make this work?
> Downloading the tfds nsynth dataset creates multiple tfrecords. Did you somehow combine them to provide the one tfrecord argument that gansynth_train.py expects, or did you make changes to the code in the repository to use tfds to load the data?
> (BTW, I am the one who submitted the previous issue you cited - #1607).
> Many thanks.

I am using Tensorflow 1.15",hey fantastic able reproduce data make work multiple somehow combine provide one argument make code repository use load data one previous issue many thanks,issue,positive,positive,positive,positive,positive,positive
650040019,"> @shansiliu95 - Hey, that's fantastic you were able to reproduce this data!
> What did you have to do to make this work?
> Downloading the tfds nsynth dataset creates multiple tfrecords. Did you somehow combine them to provide the one tfrecord argument that gansynth_train.py expects, or did you make changes to the code in the repository to use tfds to load the data?
> (BTW, I am the one who submitted the previous issue you cited - #1607).
> Many thanks.

Instead of using TFRecords, you can use this function in datasets.py
   def _get_dataset_from_tfds(self):
       nsynth_builder = tfds.builder('nsynth')
       download_config = tfds.download.DownloadConfig(
           beam_options=beam.options.pipeline_options.PipelineOptions())
       nsynth_builder.download_and_prepare(download_config=download_config)
       ds = nsynth_builder.as_dataset(split='train', shuffle_files=True)
       ds = ds.apply(contrib_data.shuffle_and_repeat(buffer_size=1000))
       return ds",hey fantastic able reproduce data make work multiple somehow combine provide one argument make code repository use load data one previous issue many thanks instead use function self return,issue,positive,positive,positive,positive,positive,positive
650026887,"Hi, I'm using another model which is much better for my purposes: performance_rnn.  It works very well from beginning to end.  I'm positive pianoroll_rnn_nade's code is flawed somewhere.  128 steps may be too few,  I usually generate 20000 steps to get 3-4 mins of music.  ",hi another model much better work well beginning end positive code flawed somewhere may usually generate get music,issue,positive,negative,neutral,neutral,negative,negative
649905699,"There's another issue appearing now, the generated output is only 1 bar long even though I explicitly told it to have 128 steps... What may be the problem here?",another issue output bar long even though explicitly told may problem,issue,negative,negative,neutral,neutral,negative,negative
649901311,"I just fixed it, here `return final_state, loglik[:, 0]` you only have to delete the section between brackets [], including them and it works fine!",fixed return delete section work fine,issue,negative,positive,positive,positive,positive,positive
649898585,"I also have this issue while running the code and this looks a very promising idea, can you please help check it out? Polyphony_rnn has also been performing well...

`Traceback (most recent call last):
  File ""/ffs/tmp/hdfd/envs/magenta/bin/pianoroll_rnn_nade_generate"", line 8, in <module>
    sys.exit(console_entry_point())
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 250, in console_entry_point
    tf.app.run(main)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 245, in main
    run_with_flags(generator)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 208, in run_with_flags
    generated_sequence = generator.generate(primer_sequence, generator_options)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/shared/sequence_generator.py"", line 194, in generate
    return self._generate(input_sequence, generator_options)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_sequence_generator.py"", line 127, in _generate
    total_steps, pianoroll_seq, **args)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_model.py"", line 97, in generate_pianoroll_sequence
    steps_per_iteration=steps_per_iteration)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 378, in _generate_events
    steps_per_iteration=steps_per_iteration)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/common/beam_search.py"", line 130, in beam_search
    beam_entries, generate_step_fn, branch_factor, first_iteration_num_steps)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/common/beam_search.py"", line 63, in _generate_branches
    all_sequences, all_states, all_scores)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 232, in _generate_step
    temperature)
  File ""/ffs/tmp/hdfd/envs/magenta/lib/python3.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_model.py"", line 74, in _generate_step_for_batch
    return final_state, loglik[:, 0]
IndexError: too many indices for array
`

I execute the generate command like the following:
""pianoroll_rnn_nade_generate \
--run_dir=""+rundir+"" --sequence_example_file=./tmp/training_pianoroll_tracks.tfrecord \
--output_dir=~/outdir --hparams=\""batch_size=96,rnn_layer_sizes=[128,128]\"" \
--num_outputs=10 \
--num_steps=128 \
--primer_pitches=\""[67,64,60]\""""
Having rundir as the directory it ran the training...",also issue running code promising idea please help check also well recent call last file line module file line main file line run file line run main file line main file line main generator file line file line generate return file line file line file line file line file line file line temperature file line return many index array execute generate command like following directory ran training,issue,positive,positive,positive,positive,positive,positive
649711826,"@iansimon Thank you very much, I just performed the training from a bundle file for Performance RNN and it seems that everything works as expected.",thank much training bundle file performance everything work,issue,negative,positive,positive,positive,positive,positive
649600335,"@GlebBrykin @vdumoulin 

Were you able to achieve Photorealistic Style Transfer? 

I wish to use this on a mobile app (https://www.tensorflow.org/lite/models/style_transfer/overview) but if I select a face as a content image, then I am seeing a lot of distortions (wrinkles on face) after style transfer.

How to solve this issue?",able achieve style transfer wish use mobile select face content image seeing lot face style transfer solve issue,issue,positive,positive,positive,positive,positive,positive
649242509,"> 
> 
> What happens if you do
> 
> ```
> pip uninstall scipy
> pip install scipy==1.2.2
> ```
> 
> after installing magenta?

This worked for me.",pip pip install magenta worked,issue,negative,neutral,neutral,neutral,neutral,neutral
649212759,"A little explanation. 

In pretty_midi MAX_TICKS=1e7 is used to stop parsing MIDI files that are too long. The developer states that this is done in order to prevent pretty_midi to run into OOM.

In the Lakh dataset, there are some files that would be skipped by pretty_midi.

In the note_seq library MAX_TICKS is set to 1e10. The mentioned files would not be skipped. On some systems, we would hit OOM. convert_dir_to_note_sequences thus would die when encountering such a file.",little explanation used stop long developer done order prevent run would library set would would hit thus would die file,issue,negative,negative,negative,negative,negative,negative
649152386,"I actually just downgraded to scipy==1.1.0 in my magenta env, got a few TensorFlow compatibility warnings, but ultimately I was able to run an image stylization model :)",actually magenta got compatibility ultimately able run image stylization model,issue,negative,positive,positive,positive,positive,positive
649150962,"What happens if you do 

```
pip uninstall scipy
pip install scipy==1.2.2
```

after installing magenta?",pip pip install magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
649004095,"Got it.

```
# Allow pretty_midi to read MIDI files with absurdly high tick rates.
# Useful for reading the MAPS dataset.
# https://github.com/craffel/pretty-midi/issues/112
pretty_midi.pretty_midi.MAX_TICK = 1e10
```
(note-seq/note_seq/midi_io.py)

Per default, MAX_TICK is 1e7. Setting it to 1e10 will process corrupt files in the Lakh dataset. And this will cause OOM.
",got allow read absurdly high tick useful reading per default setting process corrupt cause,issue,positive,negative,neutral,neutral,negative,negative
648815463,"Closing this, but please reopen if that didn't solve your issue.",please reopen solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
648235798,"I dug deeper. 

```
import pretty_midi as pm
pm.PrettyMIDI(""a79fe18e50fb30cd1679e3a9e0960620.mid"")
```

yields

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-dc75392dc7a8> in <module>
      1 import pretty_midi as pm
----> 2 pm.PrettyMIDI(""a79fe18e50fb30cd1679e3a9e0960620.mid"")

~/Development/python-venvs/tf2-p37/lib/python3.7/site-packages/pretty_midi/pretty_midi.py in __init__(self, midi_file, resolution, initial_tempo)
     83             if max_tick > MAX_TICK:
     84                 raise ValueError(('MIDI file has a largest tick of {},'
---> 85                                   ' it is likely corrupt'.format(max_tick)))
     86 
     87             # Create list that maps ticks to time in seconds

ValueError: MIDI file has a largest tick of 4295054173, it is likely corrupt
```
What would be the solution? I am considering going through the entire Lakh dataset and removing those files that yield an error. But would it not better so solve this in the original script to make it more robust? Thoughts...",dug import recent call last module import self resolution raise file tick likely create list time file tick likely corrupt would solution considering going entire removing yield error would better solve original script make robust,issue,positive,positive,neutral,neutral,positive,positive
647627915,"We have another chord encoding here that can handle an extended set of chords: https://github.com/magenta/note-seq/blob/master/note_seq/chords_encoder_decoder.py#L139

However, as it's not a one-hot encoding it'll be a little awkward (but certainly possible) getting it to work with the current MusicVAE codebase.  We do have a pretrained RNN model that uses it, though: https://github.com/magenta/magenta/tree/master/magenta/models/improv_rnn#chord-pitches-improv

More recently, we have extended MusicVAE to work with chord + key conditioning, which isn't quite what you asked but is sort of in the same direction, e.g. in the key of C a G major chord is likely to be dominant.",another chord handle extended set however little awkward certainly possible getting work current model though recently extended work chord key quite sort direction key major chord likely dominant,issue,negative,negative,neutral,neutral,negative,negative
647558178,"It looks like your actual error is 

`audioop.error: Size should be 1, 2, 3 or 4 [while running 'Map(_load_audio)']`

This means that your audio may have more than 4 channels? If you could share an audio file it is crashing on, we can help diagnose.",like actual error size running audio may could share audio file help diagnose,issue,positive,neutral,neutral,neutral,neutral,neutral
647463432,"The ""Preprocess raw audio into TFRecord dataset"" cell crashes the whole thing:

_""However getting the following error below from ""Preprocess raw audio into TFRecord dataset"" cell. This happens with Google Drive mounted, or with the .wav files uploaded from my hard drive.""_

So it seemed it was not related to the beam requirements, but now the both issues are closed and the actual problem probably wasn't looked into.",raw audio cell whole thing however getting following error raw audio cell drive mounted hard drive related beam closed actual problem probably,issue,negative,negative,neutral,neutral,negative,negative
646891355,"Amazingly, it looks like fine-tuning has *never* worked for our RNN models, or has at least been broken for years.  #1753 (in progress but the code should work right now) fixes this and supports fine-tuning from a bundle file for Performance RNN.",amazingly like never worked least broken progress code work right bundle file performance,issue,positive,positive,neutral,neutral,positive,positive
646598791,"Hi, sorry for bumping up this post too. I am working with performance_rnn pre-trained models and I am in a similar stage that @zZyan was. I used the unpack_bundle function and then training the model but the parameters are not restored from the downloaded checkpoint. I tried the indications previously posted. Is there any workaround or any news about it @iansimon? Regards.",hi sorry bumping post working similar stage used function training model tried previously posted news,issue,negative,negative,negative,negative,negative,negative
645641238,"By the way, I'm [unable](https://stackoverflow.com/a/21333938) to reopen an issue that was closed by a repo collaborator.",way unable reopen issue closed collaborator,issue,negative,negative,negative,negative,negative,negative
645559930,"Sorry for the delay, notification somehow got into my spam folder. 
The commit should be in sync again now.",sorry delay notification somehow got folder commit sync,issue,negative,negative,negative,negative,negative,negative
645502166,"Pillow is already installed, and the original AttributeError remains.

```
Requirement already satisfied: Pillow in ~/anaconda3/envs/magenta/lib/python3.7/site-packages (7.1.2)
```",pillow already original remains requirement already satisfied pillow,issue,positive,positive,positive,positive,positive,positive
645456663,Please reopen if this is still an issue.,please reopen still issue,issue,negative,neutral,neutral,neutral,neutral,neutral
645455646,Can you try pip installing Pillow (https://pypi.org/project/Pillow/)? It should be a dep already but please reopen if that doesn't fix your problem.,try pip pillow already please reopen fix problem,issue,negative,neutral,neutral,neutral,neutral,neutral
644444142,"[occasionally passed by this old issue]
it seems there was some confusion with config. i supposed it was trained as `performance_with_dynamics_compact` (and resulted checkpoint worked with that config), but the bundle worked only as `performance_with_dynamics`. need to keep an eye on that for future experiments..",occasionally old issue confusion supposed trained worked bundle worked need keep eye future,issue,negative,positive,neutral,neutral,positive,positive
643379995,Can you sync to master? The travis failures should have been fixed.,sync master travis fixed,issue,negative,positive,neutral,neutral,positive,positive
642640932,"Aside from the shuffling, the gansynth_subset actually uses a different
train/test split that should help with training. The original dataset
splits were created so that all pitch/velocities of each instrument were in
exactly one split. In the gansynth_subset, the same instrument may appear
in different splits but not with the same pitch/velocity.

On Wed, Jun 10, 2020 at 11:11 PM Jesse Engel <notifications@github.com>
wrote:

> Hi, sorry for the delay, in the middle of putting a paper together. I just
> checked and can confirm that it is an issue with the dataset. I reproduced
> the not so great result
> <https://drive.google.com/file/d/1T71tpoOkyU1lbb-hxzXOKhNu5O6b3pCj/view?usp=sharing>
> by training on the NSynth dataset available on the website.
>
> Adam highlighted that the issue is likely that the NSynth dataset from
> tensorflow_datasets has been shuffled by shards and is probably much more
> uniformly distributed, which helps with the GAN optimization. So, for now,
> training on the tensorflow_datasets version of the NSynth dataset should do
> the trick (you don't need to use the gansynth_subset since the gansynth
> code already filters the data [The model I trained on GCP that works used
> the full dataset as input, although the two should have the same result]).
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/magenta/magenta/issues/1732#issuecomment-642378936>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2B2AC5IJBBL76ELXC3RWBDMZANCNFSM4NMMIMXQ>
> .
>
",aside shuffling actually different split help training original instrument exactly one split instrument may appear different wed wrote hi sorry delay middle paper together checked confirm issue great result training available issue likely probably much uniformly distributed gan optimization training version trick need use since code already data model trained work used full input although two result thread reply directly view,issue,positive,positive,positive,positive,positive,positive
642519836,"How do you deal with the output corresponding to each frame under the condition that each adjacent frame overlaps, and 32 output results are obtained every 17920 sampling points. Is this the result of just retaining the first 512 of each frame ? If so, what is the length corresponding to the result of the last frame? Or you have used another processing method, may I have your idea?Looking forward to your answer, thank you!",deal output corresponding frame condition adjacent frame output every sampling result retaining first frame length corresponding result last frame used another method may idea looking forward answer thank,issue,negative,positive,positive,positive,positive,positive
642378936,"Hi, sorry for the delay, in the middle of putting a paper together. I just checked and can confirm that it is an issue with the dataset. I reproduced the [not so great result](https://drive.google.com/file/d/1fop6U-YQqlSNB2tVDrBmcQOHLJQm28fN/view?usp=sharing) by training on the NSynth dataset available on the website.

Adam highlighted that the issue is likely that the NSynth dataset from tensorflow_datasets has been shuffled by shards and is probably much more uniformly distributed, which helps with the GAN optimization. 

So, for now, training on the tensorflow_datasets version of the NSynth dataset should do the trick (you don't need to use the gansynth_subset since the gansynth code already filters the data [The model I trained on GCP that works used the full dataset as input, although the two should have the same result]). 

We'll put in a PR to make that the recommended approach from now on.",hi sorry delay middle paper together checked confirm issue great result training available issue likely probably much uniformly distributed gan optimization training version trick need use since code already data model trained work used full input although two result put make approach,issue,positive,positive,positive,positive,positive,positive
641961680,"Great thank you! Yes, i run the code the same way, seems that written checkpoints from previous trials ate all memory of the disk. Now i  cleaned it and seems that it works! Great thank you again!",great thank yes run code way written previous ate memory disk work great thank,issue,positive,positive,positive,positive,positive,positive
641353585,"I was able to run the following code in Colab with a T4 GPU with no issues:

```
!pip install magenta
!nvidia-smi
!mkdir /midi
!gsutil cp gs://download.magenta.tensorflow.org/models/music_vae/colab2/midi/trio_16bar*.mid /midi
!convert_dir_to_note_sequences \
  --input_dir=/midi \
  --output_file=train.tfrecord \
  --recursive
!music_vae_train --run_dir=model --config=hier-trio_16bar --hparams=batch_size=1 --examples_path=train.tfrecord
```

When you run `nvidia-smi` do you see any processes currently using the memory? My guess is that you have a dead job hanging on to the memory.",able run following code pip install magenta recursive run see currently memory guess dead job hanging memory,issue,negative,positive,neutral,neutral,positive,positive
641342343,"Wow, great thank you! i'll wait for your results!)",wow great thank wait,issue,positive,positive,positive,positive,positive,positive
641337811,"I believe these models were trained on multiple V100s, although a batch size of >1 should still work on a single V100. What GPU are you using?",believe trained multiple although batch size still work single,issue,negative,negative,neutral,neutral,negative,negative
641328844,Could you also please tell on which infrastructure you trained the model?,could also please tell infrastructure trained model,issue,negative,neutral,neutral,neutral,neutral,neutral
641310931,I tried even batch size equal to 1 but it still doesn't work(,tried even batch size equal still work,issue,negative,neutral,neutral,neutral,neutral,neutral
641302978,"I have not tried to run MusicVAE in C++. Have you tried what is suggested in that error message? LSTMBlockCell is in tf.contrib.rnn in TF v1.

I think it might actually be best to post this issue to TensorFlow since it seems to be a more general issue.",tried run tried error message think might actually best post issue since general issue,issue,negative,positive,positive,positive,positive,positive
641300628,This means your GPU does not have enough memory to support he model + batch sizes you're using. Try reducing the batch size until it fits.,enough memory support model batch size try reducing batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
641300024,"You need to remove all of the `.*opaque_.*` variables since they are only used during training with cudnn. 

See https://stackoverflow.com/questions/41621071/restore-subset-of-variables-in-tensorflow for examples of how to restore only a subset of the variables.",need remove since used training see restore subset,issue,negative,neutral,neutral,neutral,neutral,neutral
640943176,Glad you were able to figure it out! Feel free to submit a PR for the error message you suggested.,glad able figure feel free submit error message,issue,positive,positive,positive,positive,positive,positive
640761563,"Thank you! I see now, sorry, thought that you closed the issue",thank see sorry thought closed issue,issue,negative,negative,negative,negative,negative,negative
640760208,"It is not fixed, but the fix is coming. This issue is still open.",fixed fix coming issue still open,issue,negative,positive,neutral,neutral,positive,positive
640757916,"Sorry, i don't understand how you fixed it, don't see any changes in repository. If you mean to change tf2 on tf1 (solution from cross link from your comment) - i tried it tf 1.15 and faced with this error on 16bar configuration for trio- 

File ""music_vae_train.py"", line 345, in console_entry_point
tf.app.run(main)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/absl/app.py"", line 299, in run
_run_main(main, args)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
sys.exit(main(argv))
File ""music_vae_train.py"", line 340, in main
run(configs.CONFIG_MAP)
File ""music_vae_train.py"", line 321, in run
task=FLAGS.task)
File ""music_vae_train.py"", line 171, in train
optimizer = model.train(**_get_input_tensors(dataset_fn(), config))
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 299, in train
input_sequence, output_sequence, sequence_length, control_sequence)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 247, in _compute_model_loss
q_z = self.encode(input_sequence, x_length, control_sequence)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 201, in encode
encoder_output = self.encoder.encode(sequence, sequence_length)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/lstm_models.py"", line 262, in encode
split_seqs = tf.split(sequence, num_splits, axis=1)
File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1689, in split
""to split. Argument provided: %s"" % (num_or_size_splits,))
ValueError: Rank-0 tensors are not supported as the num_or_size_splits argument to split. Argument provided: 16",sorry understand fixed see repository mean change solution cross link comment tried faced error bar configuration file line main file line run file line run main file line main file line main run file line run file line train file line train file line file line encode sequence file line encode sequence file line split split argument provided argument split argument provided,issue,negative,negative,neutral,neutral,negative,negative
640594082,"I don't want to add a strict dependency since other parts of the codebase do not play well with 2.x (e.g., Music Transformer). We may want to add `extras_require` for different models. Also, if this is the only thing blocking us from using earlier version of tf, we can just not set determinism.  @cghawthorne, thoughts?",want add strict dependency since play well music transformer may want add different also thing blocking u version set determinism,issue,negative,neutral,neutral,neutral,neutral,neutral
640586278,Addendum: I upgraded Tensorflow from 2.1.0 to 2.2.0. Now this error message is gone. Maybe make 2.2.0 a requirement?,addendum error message gone maybe make requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
640534147,"Update for my issue.
I tried to run for different configurations of MusicVAE - 2 and 16 bars (different tf versions, cuda and magenta, for now its tf 1.15, cuda 10.0, magenta 1.2.0) and what i get is that for 2bar configurations MusicVAE sucessfully executes on gpu, whereas for 16 bars there is still a problem (traceback below). Do you know how to fix it?

  File ""music_vae_train.py"", line 345, in console_entry_point
    tf.app.run(main)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""music_vae_train.py"", line 340, in main
    run(configs.CONFIG_MAP)
  File ""music_vae_train.py"", line 321, in run
    task=FLAGS.task)
  File ""music_vae_train.py"", line 171, in train
    optimizer = model.train(**_get_input_tensors(dataset_fn(), config))
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 299, in train
    input_sequence, output_sequence, sequence_length, control_sequence)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 247, in _compute_model_loss
    q_z = self.encode(input_sequence, x_length, control_sequence)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/base_model.py"", line 201, in encode
    encoder_output = self.encoder.encode(sequence, sequence_length)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/magenta/models/music_vae/lstm_models.py"", line 262, in encode
    split_seqs = tf.split(sequence, num_splits, axis=1)
  File ""/home/burashnikova/env-tf-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py"", line 1689, in split
    ""to split. Argument provided: %s"" % (num_or_size_splits,))
ValueError: Rank-0 tensors are not supported as the num_or_size_splits argument to split. Argument provided: 16
",update issue tried run different different magenta magenta get bar whereas still problem know fix file line main file line run file line run main file line main file line main run file line run file line train file line train file line file line encode sequence file line encode sequence file line split split argument provided argument split argument provided,issue,negative,positive,positive,positive,positive,positive
640281066,"I figured out the issue, I had switched over to a different directory and was passing in a non-existent directory for `model_dir`. As a result I was running a model with random weights. This should output an error message if `model_dir`doesn't exist or is invalid.",figured issue switched different directory passing directory result running model random output error message exist invalid,issue,negative,negative,negative,negative,negative,negative
640130530,"I additionally transcribed the same audio file in the Onsets and Frames Colab Notebook using the MAESTRO model and got good results:
![image](https://user-images.githubusercontent.com/10556549/83956245-a5a1aa00-a810-11ea-9c3f-aac8f91feeef.png)

Is there some hyperparameter I may be missing? Or does the model checkpoint used in the Colab notebook differ from the one linked in the current README?
",additionally audio file notebook maestro model got good image may missing model used notebook differ one linked current,issue,negative,positive,positive,positive,positive,positive
639701838,"Hi, I'm really sorry about that. That code was more intertwined with internal codebases and it was difficult to factorize at the time, but unfortunately even harder now (the residents have left and all the work for the past year or more has been on ddsp). So I can't promise a good time line to get this out unfortunately, but I'll do my best to surface it in the context of the current ddsp research if I can. I know that's not ideal, so apologies again.",hi really sorry code internal difficult factorize time unfortunately even harder left work past year ca promise good time line get unfortunately best surface context current research know ideal,issue,positive,positive,neutral,neutral,positive,positive
639203708,"Dear Both,

I try restart runtime and set **%tensorflow_version 1.x** to the top of the Environment Setup cell.
And It's work!! Thanks @adarob ,

This problem has troubled me for three days..

Thanks..",dear try restart set top environment setup cell work thanks problem three day thanks,issue,positive,positive,positive,positive,positive,positive
639107567,"Hi @James1liu. It looks like the Colab version is a bit behind. Can you try adding the line `%tensorflow_version 1.x` to the top of the `Environment Setup` cell?

While I haven't seen exactly that issue you mentioned, I don't expect the Colab to work correctly without that line.",hi like version bit behind try line top environment setup cell seen exactly issue expect work correctly without line,issue,positive,positive,positive,positive,positive,positive
639103538,I'm not seeing either of those issues.  Can you restart the runtime and try again?,seeing either restart try,issue,negative,neutral,neutral,neutral,neutral,neutral
639036933,"I'm running MusicVae model, code - music_vae_train.py on configuration hier-trio_16bar (last version of the code from git) on tesla t4, ubuntu18.04, cuda 10.1, tensorflow 2.2 and get this error :

No gradient defined for operation 'core_decoder_1/core_decoder_0/decoder/while/BasicDecoderStep/decoder/multi_rnn

",running model code configuration last version code git get error gradient defined operation,issue,negative,neutral,neutral,neutral,neutral,neutral
638838738,"Can you be more specific about what you're trying to do and/or which script
you are using?

On Thu, Jun 4, 2020, 7:51 AM SashaBurashnikova <notifications@github.com>
wrote:

> Hello,
>
> I'm running your updated version for musicvae on tf2 but faced with the
> error: No gradient defined for operation
> 'core_decoder_1/core_decoder_0/decoder/while/BasicDecoderStep/decoder/multi_rnn
>
> Do you know, how to fixed it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1739>, or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2BYZVVZAQ2GMKHRW6DRU6DFTANCNFSM4NSRR34Q>
> .
>
",specific trying script wrote hello running version faced error gradient defined operation know fixed thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
638201491,This appears to be fixed. Please reopen if you still notice the issue.,fixed please reopen still notice issue,issue,negative,positive,neutral,neutral,positive,positive
637659328,Thanks very much Adam!!! It is just so hard to search in Colab. Got it!!!,thanks much hard search got,issue,negative,negative,neutral,neutral,negative,negative
637635214,"That actually shouldn't have changed... you can alter the behavior by changing the `interpolate` function in the ""Setup Environment"" cell.",actually alter behavior interpolate function setup environment cell,issue,negative,neutral,neutral,neutral,neutral,neutral
637062559,"Okay, that helps narrow it down, so it sounds likely to be a dataset issue of some sort. Sorry for the delays (a lot going on at the moment) but I'm going to set my GCP instance to train on the dataset downloaded from https://magenta.tensorflow.org/datasets/nsynth to see if it reproduces your result",narrow likely issue sort sorry lot going moment going set instance train see result,issue,negative,negative,negative,negative,negative,negative
636882936,Thanks very much Adam! The only last thing is different before the meltdown is the midi download... It only downloads the mean sequence rather than the whole progression. Thanks very much!!,thanks much last thing different mean sequence rather whole progression thanks much,issue,positive,positive,neutral,neutral,positive,positive
636514253,"I have finished training with tf 1.13.1, the model still fails to generate good sounds",finished training model still generate good,issue,negative,positive,positive,positive,positive,positive
636448349,"Hi @hardmaru ,

I have another quick question about resuming:
I if I started with 200K steps, training: `step` shouldn't go beyond 200K, right ?

Here's output from running `sketch_rnn_train` with `--resume_training True`:
```bash
INFO:tensorflow:step: 295860, lr: 0.000010, klw: 0.5000, cost: 0.0549, recon: 0.0549, kl: 0.0000, train_time_taken: 7.1699
```

As far as I can tell, if I pass 200K steps and resume, there is nothing using the `model.global_step` in comparison relation to `hps.num_steps`. Shouldn't the train loop be something like `for _ in range(global_step,hps.num_steps):` ?

If so I will be more than happy to submit a PR, otherwise please advise.

Thank you,
George",hi another quick question training step go beyond right output running true bash step cost recon far tell pas resume nothing comparison relation train loop something like range happy submit otherwise please advise thank,issue,positive,positive,positive,positive,positive,positive
636121829,"To be clear, the builder code just downloads the dataset from tensorflow_datasets as a side-effect. I'm going to try training my 1.14 code on the magenta website dataset as well to see if that makes a difference. ",clear builder code going try training code magenta well see difference,issue,positive,positive,positive,positive,positive,positive
636079357,It looks like someone already sent in a PR for this (#1709) but it was never merged for some reason. We are merging it now and then I'll update the pip package.,like someone already sent never reason update pip package,issue,negative,neutral,neutral,neutral,neutral,neutral
636075609,The issue is an indentation error in that commit. Making a fix now.,issue indentation error commit making fix,issue,negative,neutral,neutral,neutral,neutral,neutral
636033147,"Based on the examples you sent me offline and watching the video, it does seem like there is a regression somewhere.",based sent watching video seem like regression somewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
635962965,"So, we haven't been able to make progress on this internally thus far, but we are planning to move our repo to the magenta org in the next 2-3 weeks. I am setting a condition of that move that we split out the magenta music package. Stay tuned, and sorry this has dragged on so long.",able make progress internally thus far move magenta next setting condition move split magenta music package stay tuned sorry dragged long,issue,negative,positive,neutral,neutral,positive,positive
635961951,"This is simply a limitation of the model due to the variational bottleneck. There is a tradeoff when we train: the more we limit information flow through the bottleneck, the worse the reconstructions; the less we limit information flow, the worse the sampling.  Or if you're an optimist: the more we limit information flow through the bottleneck, the better the sampling; the less we limit information flow, the better the reconstructions.  This tradeoff is more pronounced for longer sequences, although the hierarchical models help to overcome it somewhat vs flat models.

In some cases we have a lokl and hikl model. The lokl model has a tight bottleneck and hikl has a loose bottleneck.",simply limitation model due variational bottleneck train limit information flow bottleneck worse le limit information flow worse sampling optimist limit information flow bottleneck better sampling le limit information flow better pronounced longer although hierarchical help overcome somewhat flat model model tight bottleneck loose bottleneck,issue,negative,negative,neutral,neutral,negative,negative
635730464,"> nsynth_builder

Thanks for your code! One more question is how to integrate ""nsynth_builder"" into dataset.py?",thanks code one question integrate,issue,negative,positive,positive,positive,positive,positive
635663407,"So, I forgot our internal PRs aren't visible in this repo (as they are in ddsp). Here's the code I'm trying now to reproduce my October result:

Download NSynth

```
import apache_beam as beam
import tensorflow_datasets as tfds

nsynth_builder = tfds.builder('nsynth')
download_config = tfds.download.DownloadConfig(
    beam_options=beam.options.pipeline_options.PipelineOptions())

nsynth_builder.download_and_prepare(download_config=download_config)
```

Changes to dataset


![Screen Shot 2020-05-28 at 4 07 11 PM](https://user-images.githubusercontent.com/1724681/83203004-7b0f6d00-a0fd-11ea-85b0-ebee2ce5876b.png)",forgot internal visible code trying reproduce result import beam import screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
635653207,"Sure thing, making a PR now. It would still be helpful if you can try training on 1.13 to so if it's a problem from 1.14-1.15",sure thing making would still helpful try training problem,issue,negative,positive,positive,positive,positive,positive
635517408,"Jesse, it would be great if you can provide some code on how to use tensorflow_datasets.",would great provide code use,issue,positive,positive,positive,positive,positive,positive
635224664,"I have solved the issue as it was path issue(in the demo file its Linux file path)
Thanks, @nirajpandkar for your help

",issue path issue file file path thanks help,issue,positive,positive,positive,positive,positive,positive
635143001,"> correction, it was trained on the full dataset downloaded from tfds, but with the filtering already in the gansynth code.

Maybe I should re-train using tfds instead of the tfrecord?",correction trained full filtering already code maybe instead,issue,negative,positive,positive,positive,positive,positive
635059216,"correction, it was trained on the full dataset downloaded from tfds, but with the filtering already in the gansynth code.",correction trained full filtering already code,issue,negative,positive,positive,positive,positive,positive
635041478,"I agree, that's very strange. I found a model that I trained on GCP Nov 1, 2019, using the github code (mel_prog_hires, v100x1, 5 days, TF 1.14.0).

I generated from it and [got expected behavior](https://drive.google.com/file/d/1xqTWok_csr_jKNdsqhSiMt46ZHQoRPtn/view?usp=sharing). Can't pull up the training graphs atm, but I think what you have looks similar to what I remember.

My guess is either something funky happened between 1.14 and 1.15 or it's a problem with dataset mismatch (more likely). 

This model was trained on the [gansynth subset from tensorflow_datasets](https://www.tensorflow.org/datasets/catalog/nsynth#nsynthgansynth_subset), which requires a 4 line tweak to the code. If it's still not working for you on 1.13 I'll go ahead and make a PR to update the dataset loading to use tensorflow_datasets.",agree strange found model trained code day got behavior ca pull training think similar remember guess either something funky problem mismatch likely model trained subset line tweak code still working go ahead make update loading use,issue,negative,negative,neutral,neutral,negative,negative
634949746,"I am pretty sure something is wrong. My colleague trained another model with the recommended hyperparameter, and the generated music is similar to the music generated by me.",pretty sure something wrong colleague trained another model music similar music,issue,negative,positive,neutral,neutral,positive,positive
634903621,"Thanks for your quick reply. Yes, I have a 32GB V100. Here are the training curves.
![image](https://user-images.githubusercontent.com/44488551/83065574-92285f00-a018-11ea-9b5d-8d3f79430bde.png)
",thanks quick reply yes training image,issue,positive,positive,positive,positive,positive,positive
634858844,"Interesting, sorry it's been a while since I trained one of these models, but at least I'm sure we checked the open source code reproduced results when we released. Is that example interpolating in z space? It sounds like mode collapse if that's the case, which was common earlier in training. Did you use a v100 to train? How many iterations did you get through? I'm curious if maybe it just needs to train longer.",interesting sorry since trained one least sure checked open source code example space like mode collapse case common training use train many get curious maybe need train longer,issue,negative,positive,neutral,neutral,positive,positive
634071234,Thank you Adam.  A very quick workaround (I did this in the mean time) is to rename the desired checkpoint.,thank quick mean time rename desired,issue,positive,positive,neutral,neutral,positive,positive
634023560,"I just had a look and the script (strangely) does not support that behavior. It would be fairly straightforward to add a flag to do this. I don't think any of us (at Google) will be able to do it in the short term, so please feel free to make the change!",look script strangely support behavior would fairly straightforward add flag think u able short term please feel free make change,issue,positive,positive,positive,positive,positive,positive
634016490,Thanks very much Adam! It works perfectly now!,thanks much work perfectly,issue,positive,positive,positive,positive,positive,positive
634008232,"Please try https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/MusicVAE.ipynb

It will give you a warning for now that it's not authored by Google but this will go away in a day or so.",please try give warning go away day,issue,negative,neutral,neutral,neutral,neutral,neutral
633995345,Ah nevermind. It looks like the change has not made it to prod yet for some reason. I'm going to move the colab into GitHub so we won't have this issue in the future.,ah like change made prod yet reason going move wo issue future,issue,negative,neutral,neutral,neutral,neutral,neutral
633994841,Please try refreshing. It looks like you're seeing out-of-date code.,please try refreshing like seeing code,issue,positive,positive,positive,positive,positive,positive
633991902,We aren't too far away from this being possible if someone wants to take it on. I'm not sure when we (at Google) will have time since we are focusing our energy on newer models like DDSP.,far away possible someone take sure time since energy like,issue,positive,positive,positive,positive,positive,positive
633989846,"Either would be fine for me. I'd like to be able to

* Use Magenta in a project which depends on TF2 for other reasons.
* Use Magenta with Python 3.8, which TF1 will never support (https://github.com/tensorflow/tensorflow/issues/39768).",either would fine like able use magenta project use magenta python never support,issue,negative,positive,positive,positive,positive,positive
633518436,"update: decoder/multi_rnn_cell/cell_1/lstm_cell/kernel turns out to be a workable candidate, is this correct?",update turn workable candidate correct,issue,negative,neutral,neutral,neutral,neutral,neutral
633457298,"Modify my script and it work : 

```
  # Write the resulting midi file to the output directory
  try:
    os.mkdir(os.path.join(""output""))
  except:
    pass
  midi_file = os.path.join(""output"", ""out.mid"")
  mm.sequence_proto_to_midi_file(sequence, midi_file)
  print(f""Generated midi file: {os.path.abspath(midi_file)}"")
```

Was not a magenta or tensorflow issue :o",modify script work write resulting file output directory try output except pas output sequence print file magenta issue,issue,negative,neutral,neutral,neutral,neutral,neutral
633198712,"I ran into the same issue then ran 
source activate magenta 
to activate magenta before installing magenta again in the magenta environment. So:

source activate magenta
pip install magenta

Worked for me! ",ran issue ran source activate magenta activate magenta magenta magenta environment source activate magenta pip install magenta worked,issue,negative,neutral,neutral,neutral,neutral,neutral
632096773,"For this folks asking for this, are you hoping to see Magenta actually use the new TF 2 API or just be able to support the TF2 package using tf.compat.v1?",see magenta actually use new able support package,issue,negative,positive,positive,positive,positive,positive
631638274,"I just submitted the fix, but it won't appear publicly for ~1 day. Thanks for bringing it to our attention!",fix wo appear publicly day thanks attention,issue,negative,positive,neutral,neutral,positive,positive
631633702,The approach we took for this problem was to just train a new model using a mel spectrogram op that could work in tflite and during TPU/GPU training (see `hparams.spec_type == 'tflite_compat_mel'`).,approach took problem train new model mel spectrogram could work training see,issue,negative,positive,positive,positive,positive,positive
631527467,Working on this today. Sorry for the delay.,working today sorry delay,issue,negative,negative,negative,negative,negative,negative
631034215,Hello Anyone who can help me out to resolve this issue ...,hello anyone help resolve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
629109523,"UPDATE: I just used another model (Performance_rnn) and it worked flawlessly from beginning to end.  There must be some error in the code of pianoroll_rnn_nade.  Can anyone check this out?

Thanks

Gustavo
",update used another model worked flawlessly beginning end must error code anyone check thanks,issue,negative,positive,positive,positive,positive,positive
628307070,"I think using `min_frame_occupancy_for_label` would just shift the error distribution forward by a frame and using `np.around` would result in a more unbiased distribution of quantization errors.

@jesseengel do you have any thoughts here?",think would shift error distribution forward frame would result unbiased distribution quantization,issue,negative,neutral,neutral,neutral,neutral,neutral
628132475,"Hi @lalisalala. There are instructions on how to use the scripts here: https://github.com/tensorflow/magenta/blob/master/magenta/models/onsets_frames_transcription/README.md

The easiest possible way to use it is from our Javascript version: https://goo.gl/magenta/piano-scribe

And only slightly more difficult would be from the colab: https://goo.gl/magenta/onsets-frames-colab

I hope one of those works for you!",hi use easiest possible way use version slightly difficult would hope one work,issue,negative,negative,negative,negative,negative,negative
627857816,"If trained with default hparams values (batch=64, rnn_layer_sizes=[128,128,128], then another error rises:

>     return final_state, loglik[:, 0]
IndexError: too many indices for array

Any help will be  greatly appreciated",trained default another error return many index array help greatly,issue,negative,positive,positive,positive,positive,positive
627787919,"I think `min_frame_occupancy_for_label` parameter in `sequence_to_pianoroll` is determining the relation between onset time in sequence and Head of onset frame in the piano roll.
https://github.com/tensorflow/magenta/blob/85ef5267513f62f4a40b01b2a1ee488f90f64a13/magenta/models/onsets_frames_transcription/data.py#L224
When `min_frame_occupancy_for_label == 0.5` might be the situation we are thinking of.
But I think it doesn't have to be like that, because label annotation can be determined arbitrary and  may have small or big effects on model performance. (have you already tested?)

I think we can compensate the effect of `min_frame_occupancy_for_label` when we decode piano roll to sequence. Maybe in `pianoroll_to_note_sequence`? https://github.com/tensorflow/magenta/blob/dc04ef3ff6a410559106fcf539a259153aae518d/magenta/music/sequences_lib.py#L1927

I'm not sure why offsets are delayed, while onsets are shifted forward. But maybe it happens with similar reason.",think parameter relation onset time sequence head onset frame piano roll might situation thinking think like label annotation determined arbitrary may small big effect model performance already tested think compensate effect decode piano roll sequence maybe sure forward maybe similar reason,issue,positive,positive,neutral,neutral,positive,positive
627662567,Interesting! Maybe we should switch to using `np.around` (bankers' rounding) for both the onset and offset in `sequence_to_pianoroll` during training. Do you think that would fix the issues you're seeing?,interesting maybe switch rounding onset offset training think would fix seeing,issue,negative,positive,positive,positive,positive,positive
627528292,"The latest, because of the specific tensorflow dependencies I moved to colab. I'll give it another shot!",latest specific give another shot,issue,negative,positive,positive,positive,positive,positive
627495904,I just tried pip installing magenta and was able to use 'groovae_4bar' without issue. What version of magenta do you have installed? Why are you not using the installed script?,tried pip magenta able use without issue version magenta script,issue,negative,positive,positive,positive,positive,positive
627375124,"I run the music_vae_generate.py script with the following hardcoded configs:
(this works fine for the 'cat-drums_2bar_small' config using the 'cat-drums_2bar_small.lokl.tar' checkpoints) 
++++++++++++++++++++++++++++++++++++++++++++++

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys
import time

from magenta import music as mm
from magenta.models.music_vae import configs
from magenta.models.music_vae import TrainedModel
import numpy as np
import tensorflow.compat.v1 as tf

flags = tf.app.flags
logging = tf.logging
FLAGS = flags.FLAGS

flags.DEFINE_string(
    'run_dir', None,
    'Path to the directory where the latest checkpoint will be loaded from.')
flags.DEFINE_string(
    'checkpoint_file', 'model-checkpoints/groovae_4bar.tar',
    'Path to the checkpoint file. run_dir will take priority over this flag.')
flags.DEFINE_string(
    'output_dir', '/tmp/music_vae/generated',
    'The directory where MIDI files will be saved to.')
flags.DEFINE_string(
    'config', 'groovae_4bar',
    'The name of the config to use.')
flags.DEFINE_string(
    'mode', 'sample',
    'Generate mode (either `sample` or `interpolate`).')
flags.DEFINE_string(
    'input_midi_1', None,
    'Path of start MIDI file for interpolation.')
flags.DEFINE_string(
    'input_midi_2', None,
    'Path of end MIDI file for interpolation.')
flags.DEFINE_integer(
    'num_outputs', 5,
    'In `sample` mode, the number of samples to produce. In `interpolate` '
    'mode, the number of steps (including the endpoints).')
flags.DEFINE_integer(
    'max_batch_size', 8,
    'The maximum batch size to use. Decrease if you are seeing an OOM.')
flags.DEFINE_float(
    'temperature', 0.5,
    'The randomness of the decoding process.')
flags.DEFINE_string(
    'log', 'INFO',
    'The threshold for what messages will be logged: '
    'DEBUG, INFO, WARN, ERROR, or FATAL.')


def _slerp(p0, p1, t):
  """"""Spherical linear interpolation.""""""
  omega = np.arccos(
      np.dot(np.squeeze(p0/np.linalg.norm(p0)),
             np.squeeze(p1/np.linalg.norm(p1))))
  so = np.sin(omega)
  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1


def run(config_map):
  """"""Load model params, save config file and start trainer.

  Args:
    config_map: Dictionary mapping configuration name to Config object.

  Raises:
    ValueError: if required flags are missing or invalid.
  """"""
  date_and_time = time.strftime('%Y-%m-%d_%H%M%S')

  if FLAGS.run_dir is None == FLAGS.checkpoint_file is None:
    raise ValueError(
        'Exactly one of `--run_dir` or `--checkpoint_file` must be specified.')
  if FLAGS.output_dir is None:
    raise ValueError('`--output_dir` is required.')
  tf.gfile.MakeDirs(FLAGS.output_dir)
  if FLAGS.mode != 'sample' and FLAGS.mode != 'interpolate':
    raise ValueError('Invalid value for `--mode`: %s' % FLAGS.mode)

  if FLAGS.config not in config_map:
    raise ValueError('Invalid config name: %s' % FLAGS.config)
  config = config_map[FLAGS.config]
  config.data_converter.max_tensors_per_item = None

  if FLAGS.mode == 'interpolate':
    if FLAGS.input_midi_1 is None or FLAGS.input_midi_2 is None:
      raise ValueError(
          '`--input_midi_1` and `--input_midi_2` must be specified in '
          '`interpolate` mode.')
    input_midi_1 = os.path.expanduser(FLAGS.input_midi_1)
    input_midi_2 = os.path.expanduser(FLAGS.input_midi_2)
    if not os.path.exists(input_midi_1):
      raise ValueError('Input MIDI 1 not found: %s' % FLAGS.input_midi_1)
    if not os.path.exists(input_midi_2):
      raise ValueError('Input MIDI 2 not found: %s' % FLAGS.input_midi_2)
    input_1 = mm.midi_file_to_note_sequence(input_midi_1)
    input_2 = mm.midi_file_to_note_sequence(input_midi_2)

    def _check_extract_examples(input_ns, path, input_number):
      """"""Make sure each input returns exactly one example from the converter.""""""
      tensors = config.data_converter.to_tensors(input_ns).outputs
      if not tensors:
        print(
            'MusicVAE configs have very specific input requirements. Could not '
            'extract any valid inputs from `%s`. Try another MIDI file.' % path)
        sys.exit()
      elif len(tensors) > 1:
        basename = os.path.join(
            FLAGS.output_dir,
            '%s_input%d-extractions_%s-*-of-%03d.mid' %
            (FLAGS.config, input_number, date_and_time, len(tensors)))
        for i, ns in enumerate(config.data_converter.from_tensors(tensors)):
          mm.sequence_proto_to_midi_file(ns, basename.replace('*', '%03d' % i))
        print(
            '%d valid inputs extracted from `%s`. Outputting these potential '
            'inputs as `%s`. Call script again with one of these instead.' %
            (len(tensors), path, basename))
        sys.exit()
    logging.info(
        'Attempting to extract examples from input MIDIs using config `%s`...',
        FLAGS.config)
    _check_extract_examples(input_1, FLAGS.input_midi_1, 1)
    _check_extract_examples(input_2, FLAGS.input_midi_2, 2)

  logging.info('Loading model...')
  if FLAGS.run_dir:
    checkpoint_dir_or_path = os.path.expanduser(
        os.path.join(FLAGS.run_dir, 'train'))
  else:
    checkpoint_dir_or_path = os.path.expanduser(FLAGS.checkpoint_file)
  model = TrainedModel(
      config, batch_size=min(FLAGS.max_batch_size, FLAGS.num_outputs),
      checkpoint_dir_or_path=checkpoint_dir_or_path)

  if FLAGS.mode == 'interpolate':
    logging.info('Interpolating...')
    _, mu, _ = model.encode([input_1, input_2])
    z = np.array([
        _slerp(mu[0], mu[1], t) for t in np.linspace(0, 1, FLAGS.num_outputs)])
    results = model.decode(
        length=config.hparams.max_seq_len,
        z=z,
        temperature=FLAGS.temperature)
  elif FLAGS.mode == 'sample':
    logging.info('Sampling...')
    results = model.sample(
        n=FLAGS.num_outputs,
        length=config.hparams.max_seq_len,
        temperature=FLAGS.temperature)

  basename = os.path.join(
      FLAGS.output_dir,
      '%s_%s_%s-*-of-%03d.mid' %
      (FLAGS.config, FLAGS.mode, date_and_time, FLAGS.num_outputs))
  logging.info('Outputting %d files as `%s`...', FLAGS.num_outputs, basename)
  for i, ns in enumerate(results):
    mm.sequence_proto_to_midi_file(ns, basename.replace('*', '%03d' % i))

  logging.info('Done.')


def main(unused_argv):
  logging.set_verbosity(FLAGS.log)
  run(configs.CONFIG_MAP)


def console_entry_point():
  tf.app.run(main)


if __name__ == '__main__':
  console_entry_point()


",run script following work fine import import division import import o import import time magenta import music import import import import logging none directory latest loaded file take priority flag directory saved name use mode either sample interpolate none start file interpolation none end file interpolation sample mode number produce interpolate number maximum batch size use decrease seeing randomness process threshold logged warn error fatal spherical linear interpolation omega omega return omega omega run load model save file start trainer dictionary configuration name object missing none none raise one must none raise raise value mode raise name none none none raise must interpolate mode raise found raise found path make sure input exactly one example converter print specific input could valid try another file path enumerate print valid extracted potential call script one instead path extract input model else model mu mu mu enumerate main run main,issue,negative,positive,positive,positive,positive,positive
627351391,Can you past the exact command you used?,past exact command used,issue,negative,neutral,neutral,neutral,neutral,neutral
627118241,"I've checked with lasted version(master) today with one of wav file in MAESTRO set (MIDI-Unprocessed_03_R1_2008_01-04_ORIG_MID--AUDIO_03_R1_2008_wav--4.wav). Here's the piano roll of ground truth(above) and transcirption(below) .
Staccato notes at the beginning becomes longer (in both direction)

![onset_and_frames_rigoletto](https://user-images.githubusercontent.com/19758253/81641520-219c1280-945c-11ea-9287-8a6743473ff3.PNG)

Histogram of onset errors are also seems to be shifted.
![newplot (15)](https://user-images.githubusercontent.com/19758253/81641996-4cd33180-945d-11ea-9bda-b7943dc36d4a.png)
",checked version master today one file maestro set piano roll ground truth staccato beginning becomes longer direction histogram onset also,issue,negative,neutral,neutral,neutral,neutral,neutral
626932431,Sorry that this still hasn't happened yet. @gauravmishra was leading this effort so I will follow up with him and update the thread on Wednesday.,sorry still yet leading effort follow update thread,issue,negative,negative,negative,negative,negative,negative
626217152,I really wish I was smart enough to submit this PR. ,really wish smart enough submit,issue,positive,positive,positive,positive,positive,positive
625556789,"> @iansimon we should verify that none of our models are using stacked bidirectional layers.

Some of the 16-bar models were using multiple bidirectional layers :(",verify none bidirectional multiple bidirectional,issue,negative,neutral,neutral,neutral,neutral,neutral
625549187,"Oh wow. This is only minor if we're not trying to do multiple layers :) Thanks for finding it!

@iansimon we should verify that none of our models are using stacked bidirectional layers.",oh wow minor trying multiple thanks finding verify none bidirectional,issue,positive,positive,neutral,neutral,positive,positive
625482431,"SOLVED: After trying millions of things, including recompiling Tensorflow, etc., I realized I was missing an intermediate step: generating the training_pianoroll_tracks.tfrecord files before training...ah well, stupid of me.  Now it's working and training properly :)))",trying million missing intermediate step generating training ah well stupid working training properly,issue,negative,negative,negative,negative,negative,negative
624663197,"Thank you for your help, I'll try to compile Tensorflow by myself.
This is just weird because everything worked fine in December. And I have already reinstalled the OS twice.",thank help try compile weird everything worked fine already o twice,issue,positive,negative,neutral,neutral,negative,negative
624285960,"bus error typically means that TensorFlow was compiled to use CPU instructions your machine doesn't support. To fix, you can either compile your own copy of TensorFlow or use a hosted virtual machine (e.g., GCP, AWS, etc.).",bus error typically use machine support fix either compile copy use virtual machine,issue,negative,negative,negative,negative,negative,negative
624015600,"Thank you.  I tried with a fresh install of Tensorflow and it didn't work, I even tried with earlier versions of Magenta/Python but nothing seems to work.  Building Tensorflow is out of my reach, so my last chance is trying the VM.  If anyone has this problem and solves it please let me know!",thank tried fresh install work even tried nothing work building reach last chance trying anyone problem please let know,issue,positive,positive,positive,positive,positive,positive
623620877,"This type of error usually indicates a problem with your TensorFlow installation. You could try reinstalling it in a fresh python environment. Or it could be that TensorFlow is compiled with options not supported by your processor. To fix this, you could build your own copy of TensorFlow, or just try things out on a virtual machine (e.g., GCP, AWS, etc.).",type error usually problem installation could try fresh python environment could processor fix could build copy try virtual machine,issue,negative,positive,neutral,neutral,positive,positive
622985368,"I know why it is!
It is because the parameter is prefixed to have the longest input length that you enter in the training dataset (In the case of the example it is 250).",know parameter prefixed input length enter training case example,issue,negative,neutral,neutral,neutral,neutral,neutral
622985068,"That actually worked! Thanks a lot @Pauladds 

Had to put in 75 to make it work. Will investigate further as to why this happened. Thanks again!",actually worked thanks lot put make work investigate thanks,issue,positive,positive,positive,positive,positive,positive
622984462,"Hello!
Yes, I solve it! 
In https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb
in ""encode"" function you have : 
![image](https://user-images.githubusercontent.com/38189240/80870544-5adbc200-8ca7-11ea-8a82-c993ee4c5b34.png)
So, inside of that, you have: ""to_big_strokes""  and one of the parameters of that function is max_len that by default is 251, and you need to change to the number that you need, in your case 76.
For example, you can write: 
![image](https://user-images.githubusercontent.com/38189240/80870613-e3f2f900-8ca7-11ea-9cb7-f0d33ba88391.png)
I hope you understand it! :)
You´re welcome 
Paula

",hello yes solve encode function image inside one function default need change number need case example write image hope understand welcome,issue,positive,positive,positive,positive,positive,positive
622662746,"Hey @Pauladds Did you manage to fix this? I am still getting the same error only now it's - 
```
ValueError: Cannot feed value of shape (1, 251, 5) for Tensor u'vector_rnn_1/Placeholder_1:0', which has shape '(1, 76, 5)'
```

Is the input shape hardcoded somewhere? Can't seem to find it.

Thanks,
Niraj",hey manage fix still getting error feed value shape tensor shape input shape somewhere ca seem find thanks,issue,negative,positive,positive,positive,positive,positive
622462233,"Sorry for the delay, trying to get our internal merge processes to work correctly. It should be merged soon!",sorry delay trying get internal merge work correctly soon,issue,negative,negative,negative,negative,negative,negative
622376801,Is there anything else required from my side for the pull to be merged? @cghawthorne ,anything else side pull,issue,negative,neutral,neutral,neutral,neutral,neutral
621809367,"@adarob Sorry to bother you with this again, I'm just curious if there's anything new...

BTW, I might have some additions to sequences_lib once this is done!",sorry bother curious anything new might done,issue,negative,negative,negative,negative,negative,negative
621752780,"Sounds good, thanks for the PR! (Please also remove the two problematic lines as well when you submit it).",good thanks please also remove two problematic well submit,issue,positive,positive,positive,positive,positive,positive
621602820,"@hardmaru Yes I commented out those lines and it did work though **with an additional step** which I had to employ in the python2.7 environment as well - 

While loading the dataset using `np.load()`, I had to add the following parameters - 

1. If python3, `allow_pickle=True`
2. If python2, `encoding='bytes', allow_pickle=True`

```
if six.PY3:
    data = np.load(data_filepath, encoding='latin1', allow_pickle=True)
else:
    data = np.load(data_filepath, encoding='bytes', allow_pickle=True)
```
These are the [lines](https://github.com/tensorflow/magenta/blob/8e5da380a1cd39d14c5bcbbae0691e7983f833fa/magenta/models/sketch_rnn/sketch_rnn_train.py#L133)

Let me know if this breaks anything else. Otherwise I'll be happy to put in a pull request!
",yes work though additional step employ python environment well loading add following python python data else data let know anything else otherwise happy put pull request,issue,positive,positive,positive,positive,positive,positive
621595095,"Hi,

Can you try commenting out these two lines to see if it trains in your setup?

```
  #for key, val in six.iteritems(list(model_params.values())):
  #  tf.logging.info('%s = %s', key, str(val))
```
(from [these two lines](https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py#L432))

If it works, I may just remove those two lines from the repo code.

Best.
",hi try two see setup key list key two work may remove two code best,issue,positive,positive,positive,positive,positive,positive
620966246,"Managed to get past that error.

Created a python2.7 conda environment. Installed magenta - `pip install magenta`. 

Was slapped with a 
```
ERROR: Failed building wheel for llvmlite
```

So installed llvmlite using conda - 
```
conda install llvmlite
```
**Note**: I also installed it system-wide using `sudo apt-get install llvm`. Don't know whether that made a difference.

Still not able to train completely. But at least past this error. Maybe can someone tell why it doesn't work in a 3.7 environment?

Thanks!",get past error python environment magenta pip install magenta error building wheel install note also install know whether made difference still able train completely least past error maybe someone tell work environment thanks,issue,negative,negative,neutral,neutral,negative,negative
620730430,"Actually I didn't use Ubuntu because it couldn't install the right version of tensorflow, even after many tries with many pip and python versions, so I just had it working in Windows",actually use could install right version even many many pip python working,issue,negative,positive,positive,positive,positive,positive
620564808,"> Hi @defnotanengineer, I'm not familiar with exactly how the Windows command line interprets those commands. I'd suggest using a Linux virtual machine or cloud instance.

I ended up using a ubuntu terminal in Windows and found how to launch the command so that it would work for me (with everything in the same line), like this : 

`onsets_frames_transcription_transcribe --model_dir=""C:\Users\kairo\Downloads\maestro_checkpoint\train"" C:\Users\kairo\Desktop\1.wav --hparams=use_cudnn=false`",hi familiar exactly command line suggest virtual machine cloud instance ended terminal found launch command would work everything line like,issue,negative,positive,positive,positive,positive,positive
620263128,"@cghawthorne Thanks so much! We would love to hear more about how you did the port, @adarob - any input would be appreciated.",thanks much would love hear port input would,issue,positive,positive,positive,positive,positive,positive
620260607,"Yeah, getting pip to do the right thing while we still require an older version of TF is tricky to get right. Glad you got a setup working!",yeah getting pip right thing still require older version tricky get right glad got setup working,issue,positive,positive,positive,positive,positive,positive
620258654,"Appreciate the response, @cghawthorne .

I ended up switching away from Sagemaker to a local, standalone `Dockerfile` and that ended up working. I think the main thing I had to do was pin my version of Tensorflow to `1.15.2`, [similar to this open issue](https://github.com/tensorflow/magenta/issues/1652#issuecomment-594657191); it seems like relying on the specified dependencies just using `pip install magenta` doesn't currently work out of the box.

The `Dockerfile` that worked for me (I'm sure it can be optimized, but this particular incantation is working):

```
FROM ubuntu:latest
RUN apt-get clean \
  && apt-get update \
  && apt-get install -y python3-pip python3-dev \
  && cd /usr/local/bin \
  && ln -s /usr/bin/python3 python \
  && pip3 install --upgrade pip
RUN apt-get install wget curl zip -y

RUN pip3 install tensorflow==1.15.2
RUN apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev ffmpeg 
RUN pip3 install pyfluidsynth pretty_midi
RUN pip3 install -qU magenta
RUN apt autoremove -y
RUN apt-get install --fix-broken
RUN pip3 install librosa
```

[This is largely lifted from the Onsets and Frames colab](https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb).

In any case, I'm happy to close this issue as it seems like it might be the same thing as #1652 - attempting a manual or automatic install of Magenta in a clean Dockerfile, or on Sagemaker, fails.",appreciate response ended switching away local ended working think main thing pin version similar open issue like pip install magenta currently work box worked sure particular incantation working latest run clean update install python pip install upgrade pip run install curl zip run pip install run update install run pip install run pip install magenta run apt run install run pip install largely case happy close issue like might thing manual automatic install magenta clean,issue,positive,positive,positive,positive,positive,positive
620213649,"If you train with exactly the same parameters as the existing TensorFlow.js model, you can use just a checkpoint. (However, I don't think we have those written down anywhere right now) Otherwise, you'll need to port/convert the model to TensorFlow.js. For our port, we actually did the conversion by hand for performance reasons and to make sure the frontend spectrogram processing was completely compatible. @adarob would have more details on that.",train exactly model use however think written anywhere right otherwise need model port actually conversion hand performance make sure spectrogram completely compatible would,issue,positive,positive,positive,positive,positive,positive
620132441,"I'm not sure exactly what's going on, but I suspect your Python environment is in a weird state. I'd suggest using [conda](https://docs.conda.io/en/latest/miniconda.html) to set up a Python environment that is isolated from everything else on your system.",sure exactly going suspect python environment weird state suggest set python environment isolated everything else system,issue,negative,positive,neutral,neutral,positive,positive
620129541,"Hi @defnotanengineer, I'm not familiar with exactly how the Windows command line interprets those commands. I'd suggest using a Linux virtual machine or cloud instance.",hi familiar exactly command line suggest virtual machine cloud instance,issue,negative,positive,positive,positive,positive,positive
620096310,"Hey @cghawthorne ,

Thanks so much for responding. 
Just for some context, we are trying to use the onsets and frames model to do real time polyphonic transcription in the browser.

We have been trying the TensorFlow.js module and it seems to work really great, aside from a few things we had posted on another issue, which limit our ability to run in real time:  https://github.com/magenta/magenta-js/issues/436

We are also hoping to retrain the model locally and be able to export the model to run in the browser. From what I gather, TensorFlow.js requires a ""saved_model"" (.pb file) like format in order to run a model in the browser, which is why I am trying to export this model locally.

Do you know if that is the case, or will the model work in TensorFlow.js with just a checkpoint?

I will investigate using build_raw_serving_input_receiver_fn and get back to you.",hey thanks much context trying use model real time polyphonic transcription browser trying module work really great aside posted another issue limit ability run real time also retrain model locally able export model run browser gather file like format order run model browser trying export model locally know case model work investigate get back,issue,positive,positive,positive,positive,positive,positive
619283400,"First, you might be interested in the TensorFlow.js port we've already done, which also includes some performance improvements: https://g.co/magenta/oaf-js

I'm not super familiar with building SavedModels, but I think you might have better luck with the `build_raw_serving_input_receiver_fn` because it doesn't expect a `tf.Example` input.",first might interested port already done also performance super familiar building think might better luck expect input,issue,positive,positive,positive,positive,positive,positive
614927135,"I am having the same issue, was anyone able to find a fix?",issue anyone able find fix,issue,negative,positive,positive,positive,positive,positive
614104220,This turned out to be a conda v. virtual_env issue where the conda environment was being superseded by the reticulate environment (which did not have magenta nor tensorflow within it). ,turned issue environment reticulate environment magenta within,issue,negative,neutral,neutral,neutral,neutral,neutral
613096477,"I don't think that commit fixed the issue. I'm getting the same error with a fresh clone of the repo, tensorflow v1.15.2 and magenta v1.3.0. @adarob ",think commit fixed issue getting error fresh clone magenta,issue,negative,positive,positive,positive,positive,positive
612952594,@gauravmishra the get_dataset test you added would ideally catch this autograph issue. I think you need to actually make a simple DataConverter instead of mocking the whole thing.,test added would ideally catch autograph issue think need actually make simple instead whole thing,issue,negative,positive,positive,positive,positive,positive
612935563,"@willfenton do you want to make a PR or should I make that change? I'm looking into the second issue now, but i think we just have to add back disabling autograph until we can move to tf 2.x.",want make make change looking second issue think add back autograph move,issue,negative,neutral,neutral,neutral,neutral,neutral
612935191,Thanks! Please sign the CLA and we can pull your change.,thanks please sign pull change,issue,positive,positive,positive,positive,positive,positive
612684998,"Also having this error, tensorflow v1.15.2 and magenta v1.3.0.

Tried checking out 3d707096c8f06f5cf7319691c609ac41dad2543e and getting the same error.",also error magenta tried getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
612684801,"Update: replacing `iterator = dataset.make_one_shot_iterator()` with `iterator = tf.data.make_one_shot_iterator(dataset)` seems to have fixed this. 

Running into this error now: #1622 ",update fixed running error,issue,negative,positive,neutral,neutral,positive,positive
612683027,"I'm having the same issue, just tried `pip install https://github.com/tensorflow/magenta/archive/master.zip` and got the same error.",issue tried pip install got error,issue,negative,neutral,neutral,neutral,neutral,neutral
612590313,I am using the latest magenta version (1.3.0) and still get the same problem. Is there any updates?,latest magenta version still get problem,issue,negative,positive,positive,positive,positive,positive
611982739,"I had the same issue in Visual MIDI: https://github.com/dubreuia/visual_midi/issues/1, changing `previewsave` to `save` fixed it for me (bokeh 2.0.0 removed `previewsave`)",issue visual save fixed removed,issue,negative,positive,neutral,neutral,positive,positive
611233042,"Hi @gudgud96! It's definitely possible to do it that way. Thus far, we've just been using `sequences_lib.apply_sustain_control_changes` to lengthen notes played under sustain. It doesn't capture all the subtleties of sustain pedal usage, but it at least accounts for notes playing longer.

We haven't explored more direct pedal modeling at this point because a lot of our data comes from [transcriptions](https://magenta.tensorflow.org/piano-transformer), and our [transcription model](https://g.co/magenta/onsets-frames) does not currently do anything to predict pedal usage.

If you get interesting results from a more direct modeling of pedal usage, we'd love to hear about them!",hi definitely possible way thus far lengthen sustain capture sustain pedal usage least longer direct pedal modeling point lot data come transcription model currently anything predict pedal usage get interesting direct modeling pedal usage love hear,issue,positive,positive,positive,positive,positive,positive
609929721,I state that I am not very expert ... I noticed that the models used for the iOS application are accompanied by txt files that contain the various classes of objects that the model can recognise. But in this case I don't think there can be one ... To invoke a request to the model I just need to know the inputsand output tensors ? How can I manage them in an appropriate way?,state expert used application contain various class model case think one invoke request model need know output manage appropriate way,issue,negative,positive,positive,positive,positive,positive
609901642,"Sorry for the confusion, the `use_cudnn` hparam does not apply to the drum model. It was written to be trained on TPUs, so it doesn't have any cudnn-specific code.

The bus error indicates that TensorFlow is trying to use instructions your CPU doesn't support. You'll need to either use a different computer or compile TensorFlow specifically for your machine.",sorry confusion apply drum model written trained code bus error trying use support need either use different computer compile specifically machine,issue,negative,negative,negative,negative,negative,negative
609653686,"I'm getting Bus 10 error as well and when I try to add the hparam above I run into:
`ValueError: Unknown hyperparameter type for use_cudnn`

my arguments are:
`python onsets_frames_transcription_transcribe.py --model_dir=e-gmd_checkpoint/ --config=""drums"" --hparams=use_cudnn=false  danny_test.wav 
`

tensorflow version is: 1.15.2

any ideas?
",getting bus error well try add run unknown type python version,issue,negative,negative,neutral,neutral,negative,negative
609433964,"It past over 2 years from the initial post mentioned here. Issue still persist on windows environment. 
Magenta 1.3.0",past initial post issue still persist environment magenta,issue,negative,negative,negative,negative,negative,negative
608934866,"The code is mostly a documentation of the research paper, and isn't actively used for research at the moment (we're focusing on [DDSP](https://github.com/magenta/ddsp)), so it's unlikely to see any speed improvements on our end. Apologies if it's a bit slow, but a single GPU was sufficient for the experiments in the paper, so we stuck to that :).",code mostly documentation research paper actively used research moment unlikely see speed end bit slow single sufficient paper stuck,issue,negative,negative,negative,negative,negative,negative
607955904,"I think some of the confusion comes from the [paper](https://goo.gl/magenta/maestro-paper) talking about several models and also a dataset. The [MAESTRO](https://g.co/magenta/maestro-dataset) dataset has audio that was recorded in 44.1–48 KHz 16-bit PCM stereo, but the [Onsets and Frames](http://goo.gl/magenta/onsets-frames-code) model downsamples it to 16 KHz mono before using it. It would certainly be possible to train a model using the full samplerate of the dataset, it's just something we haven't fully explored.

The part of the paper that talks about a 4ms resolution pianoroll is referring to the Midi2Wave synthesis model, which is a completely separate codebase from the transcription model (and is unfortunately not currently open sourced).",think confusion come paper talking several also maestro audio stereo model mono would certainly possible train model full something fully part paper resolution synthesis model completely separate transcription model unfortunately currently open,issue,negative,positive,neutral,neutral,positive,positive
607589113,"Q1: The model consists of an early CNN followed by an BiLSTM (or simple LSTM) which integrates the date in the time direction across a long sample. In the original model the *entire* performance (many seconds) is treated together as one block, with LSTMs running forward and backward in time. I.e. the individual chunks are not independent from each other. For the tflite version we needed to shorten the block to make it manageable as the entire LSTM is unrolled statically. 
2) No it's not possible to run the BiLSTM version in 30ms chunks. 
2b) Yes theoretically it's possible to run the UnidirectionalLSTM version in chunks but you'd also have to manually manage the LSTM states from chunk to chunk which is awkward, to say the least.
",model early simple date time direction across long sample original model entire performance many together one block running forward backward time individual independent version shorten block make manageable entire unrolled possible run version yes theoretically possible run version also manually manage chunk chunk awkward say least,issue,negative,positive,neutral,neutral,positive,positive
607401718,"Thanks for the report, @opheliagame! The problem ended up being the `%tensorflow_version 1.x` line, which apparently resets the packages installed and reverts the magenta package to a very old version. If you just move that to the top of the cell, it should start working.

We'll have a fixed version posted in a couple days.",thanks report problem ended line apparently magenta package old version move top cell start working fixed version posted couple day,issue,negative,positive,positive,positive,positive,positive
606420888,"I am having the same issue in the Making Sounds with Note Sequences section.
This error appears in the first step, while installing dependencies.
```
Building wheel for hdfs (setup.py) ... done
  Building wheel for httplib2 (setup.py) ... done
  Building wheel for oauth2client (setup.py) ... done
  Building wheel for avro-python3 (setup.py) ... done
  Building wheel for google-apitools (setup.py) ... done
  Building wheel for pypng (setup.py) ... done
  Building wheel for bz2file (setup.py) ... done
  Building wheel for grpc-google-iam-v1 (setup.py) ... done
ERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.
ERROR: google-api-python-client 1.7.12 has requirement httplib2<1dev,>=0.17.0, but you'll have httplib2 0.12.0 which is incompatible.
ERROR: chainer 6.5.0 has requirement typing<=3.6.6, but you'll have typing 3.7.4.1 which is incompatible.
ERROR: chainer 6.5.0 has requirement typing-extensions<=3.6.6, but you'll have typing-extensions 3.7.4.1 which is incompatible.
ERROR: dm-sonnet 1.36 has requirement tensorflow-probability<0.9.0,>=0.8.0, but you'll have tensorflow-probability 0.7.0 which is incompatible.
Importing libraries and defining some helper functions...
TensorFlow 1.x selected.
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/magenta/pipelines/statistics.py:131: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/magenta/music/note_sequence_io.py:60: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

🎉 Done!
0.3.19
1.15.2
```
Next step gives
```
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-2-acbb8b942830> in <module>()
----> 1 from magenta.music.protobuf import music_pb2
      2 
      3 twinkle_twinkle = music_pb2.NoteSequence()
      4 
      5 # Add the notes to the sequence.

ModuleNotFoundError: No module named 'magenta.music.protobuf'

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
""Open Examples"" button below.
---------------------------------------------------------------------------
```

I have tried factory resetting the runtime, but that doesn't help. ",issue making note section error first step building wheel done building wheel done building wheel done building wheel done building wheel done building wheel done building wheel done building wheel done error requirement incompatible error requirement incompatible error chainer requirement incompatible error chainer requirement incompatible error requirement incompatible helper selected warning name please use instead warning name please use instead done next step recent call last module import add sequence module note import failing due missing package manually install either pip apt view common click open button tried factory help,issue,negative,positive,neutral,neutral,positive,positive
606109370,I think you misspelled `--examples_path` in your command line (forgot the 's' on examples).,think command line forgot,issue,negative,neutral,neutral,neutral,neutral,neutral
606108072,"If you want it to just use the CPU, you'll need to pass the option `--hparams=use_cudnn=false`.",want use need pas option,issue,negative,neutral,neutral,neutral,neutral,neutral
605750095,"I am now running on my Mac, but with Linux Ubuntu 18.04 installed through Parallels.

tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /miniconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) with these attrs: [seed=0, dropout=0, num_params=16, T=DT_FLOAT, input_mode=""linear_input"", direction=""bidirectional"", rnn_mode=""lstm"", seed2=0]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]

Do you know if I need tensorflow-gpu installed to run this code?",running mac likely due mismatch current graph graph please ensure graph based original error registered support used node defined bidirectional registered registered know need run code,issue,positive,positive,neutral,neutral,positive,positive
605097926,An Android app would be great! I think the best way to share would be for you to host it in your own github repo and we could post a link to it somewhere.,android would great think best way share would host could post link somewhere,issue,positive,positive,positive,positive,positive,positive
604781378,"Actually, I've never seen this Readme before. @khanhlvg can answer this better probably! ",actually never seen answer better probably,issue,negative,positive,positive,positive,positive,positive
604486811,"It looks like the error is happening after
""INFO:tensorflow:Running inference...""

So I think it has to do with tensorflow. Do you know if this code requires a GPU to run?",like error happening running inference think know code run,issue,negative,neutral,neutral,neutral,neutral,neutral
604486011,"Here is my error message:

Fatal Python error: Bus error

Current thread 0x000070000fe2f000 (most recent call first):
  File ""<__array_function__ internals>"", line 6 in dot
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/librosa/feature/spectral.py"", line 1836 in melspectrogram
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/data.py"", line 88 in _wav_to_mel
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/data.py"", line 121 in wav_to_spec
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py"", line 235 in __call__

Thread 0x0000000106fa65c0 (most recent call first):
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1443 in _call_tf_sessionrun
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1350 in _run_fn
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1365 in _do_call
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1359 in _do_run
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1180 in _run
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 956 in run
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/onsets_frames_transcription_transcribe.py"", line 126 in transcription_data
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/infer_util.py"", line 150 in wrapper
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 2987 in _call_input_fn
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 996 in _get_features_from_input_fn
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 620 in predict
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3072 in predict
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/onsets_frames_transcription_transcribe.py"", line 137 in run
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/onsets_frames_transcription_transcribe.py"", line 150 in main
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 250 in _run_main
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 299 in run
  File ""/anaconda2/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/Users/MLD/Desktop/Programming/MachineLearning/magenta/magenta/models/onsets_frames_transcription/onsets_frames_transcription_transcribe.py"", line 154 in console_entry_point
  File ""/anaconda2/envs/magenta/bin/onsets_frames_transcription_transcribe"", line 11 in <module>
Bus error: 10
",error message fatal python error bus error current thread recent call first file internals line dot file line file line file line file line thread recent call first file line file line file line file line file line file line run file line file line wrapper file line file line file line predict file line predict file line run file line main file line file line run file line run file line file line module bus error,issue,negative,positive,positive,positive,positive,positive
604458235,"#uses pip install magenta
to make sure used the upgrade option
#ALL white",pip install magenta make sure used upgrade option white,issue,negative,positive,positive,positive,positive,positive
604278227,"I haven't unfortunately, not on the macbook. It does work on my PC (running Arch Linux) with the same installation/usage steps",unfortunately work running arch,issue,negative,negative,negative,negative,negative,negative
604204710,"I am currently encountering this same error. 
I setup magenta with a conda env, and am able to run other programs such as melody_rnn just fine.
I am only getting this same Bus Error 10 when I try to run Onsets and Frames.
Have you figured out why this happens?",currently error setup magenta able run fine getting bus error try run figured,issue,negative,positive,positive,positive,positive,positive
602785751,"Do you know where the >0.8.0 requirement is coming from? In our setup.py, we just have the ==0.8.0 requirement.",know requirement coming requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
602783615,"We used to have a Docker image, but we no longer maintain it. You can look at the commit where we removed it (ee21abf65a576388de3a6af289599a536dd3c7c8) for more details and a possible starting point for your project.",used docker image longer maintain look commit removed possible starting point project,issue,negative,neutral,neutral,neutral,neutral,neutral
601211604,"If you think it could be good, I will do it when I'll have the time.",think could good time,issue,negative,positive,positive,positive,positive,positive
600818847,Thanks for testing. Do you want to make a PR to remove the building of it?,thanks testing want make remove building,issue,negative,positive,positive,positive,positive,positive
600168827,"Thanks for the reminder Ondrej. I think we actually need to make these
changes internally first. I will get the ball rolling today.

On Mon, Mar 16, 2020 at 11:50 AM Ondřej Cífka <notifications@github.com>
wrote:

> Any news on this? Any way I can help?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1360#issuecomment-599703954>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2F3FOOEJX4PJXMMDFTRHZYI3ANCNFSM4GGGXB3A>
> .
>
",thanks reminder think actually need make internally first get ball rolling today mon mar wrote news way help reply directly view,issue,positive,positive,positive,positive,positive,positive
599658897,It seems to be a quantization issue.  I'll look into it if I get a chance but for now I recommend picking a tempo that works (it won't have any effect on the model) and changing to the tempo you want afterwards.,quantization issue look get chance recommend tempo work wo effect model tempo want afterwards,issue,positive,neutral,neutral,neutral,neutral,neutral
599373797,Can you post the code so as to replicate the error?,post code replicate error,issue,negative,neutral,neutral,neutral,neutral,neutral
598140371,"Yes, I can delete a level from the hierarchical decoder pre-trained checkpoint (I'm using the `hierdec-trio_16bar` pre-trained checkpoint) and get the same output from the decoder using the same `z`.

I call the method that has the delete instruction at the beginning of the `_hierarchical_decode` method, so that I am absolutely sure that the level is deleted before the graph for the output is built (deleting both levels does result in an error).",yes delete level hierarchical get output call method delete instruction beginning method absolutely sure level graph output built result error,issue,negative,positive,positive,positive,positive,positive
597750705,Thanks Marco. Are you saying you can delete the level and still load a pre-trained checkpoint?,thanks marco saying delete level still load,issue,negative,positive,positive,positive,positive,positive
596712807,Downloads in colab can be a little flaky.  Does it work if you try the same download again?,little flaky work try,issue,negative,negative,negative,negative,negative,negative
596670204,"Hi Adam, yes I did. I started creating my own configurations (which work on CPU) and then tried simplifying things by going back to the ones that come bundled with MusicVAE (nade and cat-drums_2bar_small).

Thank you.",hi yes work tried going back come thank,issue,positive,neutral,neutral,neutral,neutral,neutral
596298126,"I tried different environments and got the same behavior: the loss decreases on CPU but remains pretty much the same using GPU (both in Colab and a P100). All in all, there is no learning using GPU.

I also followed and posted an issue on the [Tensorflow repo](https://github.com/tensorflow/tensorflow/issues/19200#issuecomment-591697944) but got no useful feedback.

I think I gave up with this, but set up a notebook with a minimal working example so that other    people facing the same issue can easily test other approaches:

https://colab.research.google.com/drive/1ZVMYB-UPJIu7ooNYboEKotC6qatHWgBy#scrollTo=INcHdLXkohOp

",tried different got behavior loss remains pretty much learning also posted issue got useful feedback think gave set notebook minimal working example people facing issue easily test,issue,positive,positive,positive,positive,positive,positive
594710799,Is there any way this can be solved w/o having to downgrade any libraries? Feels like a platform related problem with Alpine to me. ,way downgrade like platform related problem alpine,issue,negative,neutral,neutral,neutral,neutral,neutral
594710185,"> Try `pip install --upgrade pip`.

Obviously already done that and it does not solve the problem ",try pip install upgrade pip obviously already done solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
594657191,"Getting a similar error when trying to install magenta through pip letting it handle dependencies on its own. This was after trying the suggested `pip install --upgrade pip`

```
ERROR: Could not find a version that satisfies the requirement tensorflow<2.0.0,>=1.15.0 (from magenta) (from versions: none)
ERROR: No matching distribution found for tensorflow<2.0.0,>=1.15.0 (from magenta)
```

EDIT: guessing this is related to #1649 and #1650 ",getting similar error trying install magenta pip handle trying pip install upgrade pip error could find version requirement magenta none error matching distribution found magenta edit guessing related,issue,negative,neutral,neutral,neutral,neutral,neutral
594313709,"I've two additional questions about the model and thought I'd add them here instead of creating a new issue for this.

@sukun1045 : About your point n°2 : according to the [paper](https://arxiv.org/pdf/1810.12247.pdf), the audio recordings used where:
> (44.1–48 kHz 16-bit PCM stereo)

**but** current code states:
https://github.com/tensorflow/magenta/blob/600ba5438d523f8286c87a34b39be9276e69897a/magenta/models/onsets_frames_transcription/realtime/onsets_frames_transcription_realtime.py#L42-L43



That being said, the paper also states that
> The input to the context stack is an onset “piano roll” representation, a size-88 vector signaling the onset of any keys on the keyboard, with 4ms bins (250Hz).

(quite a high resolution)

**But**, @cghawthorne, the [onsets_frames_wavinput.tflite](https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/tflite/onsets_frames_wavinput.tflite) input tensors expect a list of **17.920** samples (float).
Given that it also explicitly expects them to be float-32 collected from 16khz mono-sampling, that means that it needs exactly 1.12 seconds of audio... (Not quite  _realtime_ ;))

My first reaction was that I'd love to see a variant of [onsets_frames_wavinput_no_offset_uni.tflite](https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/tflite/onsets_frames_wavinput_no_offset_uni.tflite) accepting ~20-30ms worth of audio

**Question 1: What made this model restricted to this huge quantity of samples?**

Note:  Output tensors are structured so to provide 32 ""chronological buckets"".
If I'm right, that means that these 17920 samples (at 16khz, being 1.12s worth) are split in chunks of 35ms and there is **apparently** nothing stopping the model from being fed with a 560-floats buffer (right-padded with `00000...` to fit input tensors size) and only collect the first output tensor's bucket but...


**Question 2: Could you please confirm that's a possible and adequate way to feed the model if we want 30ms-like delays?**

Thank you!",two additional model thought add instead new issue point according paper audio used stereo current code said paper also input context stack onset piano roll representation vector onset keyboard quite high resolution input expect list float given also explicitly collected need exactly audio quite first reaction love see variant worth audio question made model restricted huge quantity note output structured provide chronological right worth split apparently nothing stopping model fed buffer fit input size collect first output tensor bucket question could please confirm possible adequate way feed model want thank,issue,positive,positive,positive,positive,positive,positive
593521958,#https://github.com/tensorflow/magenta/compare/master...abbasidaniyal:patch-1 This patch might be able to help,patch might able help,issue,negative,positive,positive,positive,positive,positive
592394855,Tensorflow 2 is now the official standard in Google.  Let's move to TF2. ,official standard let move,issue,negative,neutral,neutral,neutral,neutral,neutral
590625529,"Thanks for the heads up, we'd be happy to accept a pull request.",thanks happy accept pull request,issue,positive,positive,positive,positive,positive,positive
590074987,"I tried in January but didn't go far because my Python environment was getting messed up by the version changes. I'll need to train a MusicVAE model at some point so I'll get back to it, I don't know when.",tried go far python environment getting version need train model point get back know,issue,negative,positive,neutral,neutral,positive,positive
590050512,"some code in ubuntu may helps.
```
$ sudo apt-get install libasound-dev

$ sudo apt-get install libjack-dev
```",code may install install,issue,negative,neutral,neutral,neutral,neutral,neutral
589322476,"It looks like the original model checkpoints are in the magenta-js directories. You can check out the links in https://goo.gl/magenta/js-checkpoints. For any of the multitrack directories, you should be able to download the files `model.ckpt-100000.data-00000-of-00001` and `model.ckpt-100000.index` which you can use to run the Python models.",like original model check link able use run python,issue,positive,positive,positive,positive,positive,positive
588524771,"@momo1986, the right way to make it work on windows 10, is by using the linux shell.
Install the ubuntu shell on your windows 10 (https://itsfoss.com/install-bash-on-windows/)

After that, follow the steps on setting up the magenta environment using conda or manual installation (https://github.com/tensorflow/magenta/blob/master/README.md), from the linux shell.

Hope it helps!",momo right way make work shell install shell follow setting magenta environment manual installation shell hope,issue,negative,positive,positive,positive,positive,positive
586485898,"Hi,

Just wanted to add few updates after testing:

- I've managed to have multiple versions of CUDA installed (10.0, 10.1, 10.2) as long as the nVidia  driver was the latest one.
- I've installed tensorflow-gpu 1.15.2 (since magenta requires [1.15 or higher](https://github.com/tensorflow/magenta/blob/master/setup.py#L64)) then installed `magenta` (not `magenta-gpu`, however magenta uninstalled tensorflow-gpu and I was back to the CPU only version.
- I've got both magenta with tensorflow-gpu by installing magenta first, uninstalling tensorflow(cpu), then installing tensorflow-gpu (`is_gpu_available()` returned `True` and I could import `magenta` too)

In the next few days I'll try to train a sketch-rnn model to confirm this works and will close the ticket then.

**Update**

I've ran into errors training sketch-rnn that I didn't expect:

```bash
sketch_rnn_train --data_dir=datasets\quickdraw_dataset --hparams=""data_set=[triangle.npz],num_steps=200000,conditional=0,dec_rnn_size=1024"" --log_root=models\triangle
2020-02-15 01:02:35.732466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
WARNING:tensorflow:From c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py:34: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

WARNING:tensorflow:From c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py:34: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.

WARNING:tensorflow:From c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py:474: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py:433: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

W0215 01:02:39.634826  3304 module_wrapper.py:139] From c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py:433: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.

INFO:tensorflow:sketch-rnn
I0215 01:02:39.635821  3304 sketch_rnn_train.py:433] sketch-rnn
INFO:tensorflow:Hyperparams:
I0215 01:02:39.635821  3304 sketch_rnn_train.py:434] Hyperparams:
INFO:tensorflow:data_set = ['triangle.npz']
I0215 01:02:39.635821  3304 sketch_rnn_train.py:436] data_set = ['triangle.npz']
INFO:tensorflow:num_steps = 200000
I0215 01:02:39.636816  3304 sketch_rnn_train.py:436] num_steps = 200000
INFO:tensorflow:save_every = 500
I0215 01:02:39.636816  3304 sketch_rnn_train.py:436] save_every = 500
INFO:tensorflow:max_seq_len = 250
I0215 01:02:39.636816  3304 sketch_rnn_train.py:436] max_seq_len = 250
INFO:tensorflow:dec_rnn_size = 1024
I0215 01:02:39.638809  3304 sketch_rnn_train.py:436] dec_rnn_size = 1024
INFO:tensorflow:dec_model = lstm
I0215 01:02:39.640800  3304 sketch_rnn_train.py:436] dec_model = lstm
INFO:tensorflow:enc_rnn_size = 256
I0215 01:02:39.645778  3304 sketch_rnn_train.py:436] enc_rnn_size = 256
INFO:tensorflow:enc_model = lstm
I0215 01:02:39.647771  3304 sketch_rnn_train.py:436] enc_model = lstm
INFO:tensorflow:z_size = 128
I0215 01:02:39.648765  3304 sketch_rnn_train.py:436] z_size = 128
INFO:tensorflow:kl_weight = 0.5
I0215 01:02:39.650757  3304 sketch_rnn_train.py:436] kl_weight = 0.5
INFO:tensorflow:kl_weight_start = 0.01
I0215 01:02:39.652749  3304 sketch_rnn_train.py:436] kl_weight_start = 0.01
INFO:tensorflow:kl_tolerance = 0.2
I0215 01:02:39.655733  3304 sketch_rnn_train.py:436] kl_tolerance = 0.2
INFO:tensorflow:batch_size = 100
I0215 01:02:39.657727  3304 sketch_rnn_train.py:436] batch_size = 100
INFO:tensorflow:grad_clip = 1.0
I0215 01:02:39.658721  3304 sketch_rnn_train.py:436] grad_clip = 1.0
INFO:tensorflow:num_mixture = 20
I0215 01:02:39.660712  3304 sketch_rnn_train.py:436] num_mixture = 20
INFO:tensorflow:learning_rate = 0.001
I0215 01:02:39.661708  3304 sketch_rnn_train.py:436] learning_rate = 0.001
INFO:tensorflow:decay_rate = 0.9999
I0215 01:02:39.663699  3304 sketch_rnn_train.py:436] decay_rate = 0.9999
INFO:tensorflow:kl_decay_rate = 0.99995
I0215 01:02:39.664695  3304 sketch_rnn_train.py:436] kl_decay_rate = 0.99995
INFO:tensorflow:min_learning_rate = 1e-05
I0215 01:02:39.667681  3304 sketch_rnn_train.py:436] min_learning_rate = 1e-05
INFO:tensorflow:use_recurrent_dropout = True
I0215 01:02:39.668677  3304 sketch_rnn_train.py:436] use_recurrent_dropout = True
INFO:tensorflow:recurrent_dropout_prob = 0.9
I0215 01:02:39.670669  3304 sketch_rnn_train.py:436] recurrent_dropout_prob = 0.9
INFO:tensorflow:use_input_dropout = False
I0215 01:02:39.671664  3304 sketch_rnn_train.py:436] use_input_dropout = False
INFO:tensorflow:input_dropout_prob = 0.9
I0215 01:02:39.674651  3304 sketch_rnn_train.py:436] input_dropout_prob = 0.9
INFO:tensorflow:use_output_dropout = False
I0215 01:02:39.677637  3304 sketch_rnn_train.py:436] use_output_dropout = False
INFO:tensorflow:output_dropout_prob = 0.9
I0215 01:02:39.679629  3304 sketch_rnn_train.py:436] output_dropout_prob = 0.9
INFO:tensorflow:random_scale_factor = 0.15
I0215 01:02:39.680625  3304 sketch_rnn_train.py:436] random_scale_factor = 0.15
INFO:tensorflow:augment_stroke_prob = 0.1
I0215 01:02:39.682616  3304 sketch_rnn_train.py:436] augment_stroke_prob = 0.1
INFO:tensorflow:conditional = False
I0215 01:02:39.684607  3304 sketch_rnn_train.py:436] conditional = False
INFO:tensorflow:is_training = True
I0215 01:02:39.685603  3304 sketch_rnn_train.py:436] is_training = True
INFO:tensorflow:Loading data files.
I0215 01:02:39.688588  3304 sketch_rnn_train.py:437] Loading data files.
Traceback (most recent call last):
  File ""c:\users\administrator\.pyenv-win\pyenv-win\versions\3.6.4-amd64\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\administrator\.pyenv-win\pyenv-win\versions\3.6.4-amd64\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\.menv\Scripts\sketch_rnn_train.exe\__main__.py"", line 7, in <module>
  File ""c:\.menv\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py"", line 474, in console_entry_point
    tf.app.run(main)
  File ""c:\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py"", line 470, in main
    trainer(model_params)
  File ""c:\lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py"", line 438, in trainer
    datasets = load_dataset(FLAGS.data_dir, model_params)
  File ""c:lib\site-packages\magenta\models\sketch_rnn\sketch_rnn_train.py"", line 141, in load_dataset
    len(data['train']), len(data['valid']), len(data['test']),
  File ""c:\lib\site-packages\numpy\lib\npyio.py"", line 262, in __getitem__
    pickle_kwargs=self.pickle_kwargs)
  File ""c:\lib\site-packages\numpy\lib\format.py"", line 739, in read_array
    raise ValueError(""Object arrays cannot be loaded when ""
ValueError: Object arrays cannot be loaded when allow_pickle=False

```

Any hints on what would've changed ?

**Update** passing `allow_pickle=True` to `np.load` (in my case on [line 137](https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py#L137)) solved the problem.

If this change is useful I can easily submit a PR.

",hi add testing multiple long driver latest one since magenta higher magenta however magenta uninstalled back version got magenta magenta first returned true could import magenta next day try train model confirm work close ticket update ran training expect bash successfully dynamic library warning name please use instead warning name please use instead warning name please use instead warning name please use instead name please use instead true true false false false false conditional false conditional false true true loading data loading data recent call last file line file line code file line module file line main file line run file line run main file line main file line main trainer file line trainer file line data data data file line file line raise object loaded object loaded would update passing case line problem change useful easily submit,issue,positive,positive,neutral,neutral,positive,positive
586051884,"Gotcha, I remember in the past having luck with `tensorflow-gpu==1.10.0` + `magenta==0.3.12` (with TF installed first, then magenta which wouldn't re-install TF since it's close enough to what it required).

I'll close the issue as soon as I can confirm.

Thank you very much for your support: very much appreciated 
❤️
",remember past luck first magenta would since close enough close issue soon confirm thank much support much,issue,positive,positive,neutral,neutral,positive,positive
586048917,I'd suggest looking at https://www.tensorflow.org/install/gpu and making sure that you can get a 1.x version of TensorFlow working with GPU first and then try to get it to work with Magenta.,suggest looking making sure get version working first try get work magenta,issue,negative,positive,positive,positive,positive,positive
586043297,"Thank you for the swift reply.

I did actually succeed in installing `magenta`  however

```python
tf.test.is_gpu_available()
```
returns `False` which is why I tried to install `magenta-gpu` which used to work (though using an old version of TF).

Is there any way to run magenta with GPU support ?
If so, how ?
",thank swift reply actually succeed magenta however python false tried install used work though old version way run magenta support,issue,positive,negative,negative,negative,negative,negative
586039025,"You should just be able to use the `magenta` package. Tensorflow no longer requires a separate package for GPU support, so we stopped updating `magenta-gpu`. We tried to update all our docs to just reference the main magenta package, but maybe we missed some? Was there a doc you saw somewhere that recommended installing `magenta-gpu`?",able use magenta package longer separate package support stopped tried update reference main magenta package maybe doc saw somewhere,issue,negative,positive,positive,positive,positive,positive
583620225,I've run into this issue also. Happy to increase it if that helps.,run issue also happy increase,issue,positive,positive,positive,positive,positive,positive
579974936,"Thanks for catching that! Let us know if you find any more cases where this happens.

@cghawthorne @adarob I just exported a fixed version of that midi file using Logic in the same way as the rest of the dataset, so this one should match.
[fixed_149_soul_105_fill_4-4.mid.zip](https://github.com/tensorflow/magenta/files/4130854/fixed_149_soul_105_fill_4-4.mid.zip)
",thanks catching let u know find fixed version file logic way rest one match,issue,negative,positive,positive,positive,positive,positive
579461363,"> You have to specify note_rnn_hparams in RLTuner so it correctly loads from the checkpoint file. After that it'll successfully initialize the Note RNN.

HI, Can you please explain how resolved the issue?",specify correctly file successfully initialize note hi please explain resolved issue,issue,positive,positive,positive,positive,positive,positive
579436461,">  hparams_dict = {
>         'batch_size': 128,
>         'rnn_layer_sizes': [128, 128],
>         'dropout_keep_prob': 0.5,
>         'attn_length': 40,
>         'clip_norm': 3,
>         'learning_rate': 0.001,
>         'residual_connections': False,
>         'use_cudnn': False,
>         'one_hot_length': NUM_CLASSES
>   }
>   hparams = tf.contrib.training.HParams(**hparams_dict)

Hi, were you able to solve this?",false false hi able solve,issue,negative,negative,negative,negative,negative,negative
578540048,"I'm going to close this for now, but feel free to reopen in the future.",going close feel free reopen future,issue,positive,positive,positive,positive,positive,positive
577529031,"Make sure you have installed [magenta](https://github.com/tensorflow/magenta/blob/master/README.md) successfully, I think it should fix this.",make sure magenta successfully think fix,issue,positive,positive,positive,positive,positive,positive
576774124,"I have the same problem, creating dataset and training went fine, but same error when using pianoroll_rnn_nade_generate:
```
  File ""/home/gizmow/magenta/magenta/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_model.py"", line 75, in _generate_step_for_batch
    return final_state, loglik[:, 0]
IndexError: too many indices for array
```
Could someone solve this?
Thanks!",problem training went fine error file line return many index array could someone solve thanks,issue,negative,positive,positive,positive,positive,positive
574359066,"Thanks for the work so far! This has been a problem for us too currently.
Is there anything left to do or could this be pulled now with the requested change?",thanks work far problem u currently anything left could change,issue,negative,positive,neutral,neutral,positive,positive
573790222,"Try `pip install --upgrade pip`.

On Mon, Jan 13, 2020 at 1:02 AM Can Ince <notifications@github.com> wrote:

> I don't think the latest magenta version is supported on Alpine, is it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1652?email_source=notifications&email_token=AAIJV2EHIJU2GRBCZT2MRC3Q5QU27A5CNFSM4J53SWT2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEIX6XBQ#issuecomment-573565830>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2C3AJZOXHWANSKPEDTQ5QU27ANCNFSM4J53SWTQ>
> .
>
",try pip install upgrade pip mon wrote think latest magenta version alpine thread reply directly view,issue,negative,positive,positive,positive,positive,positive
573565830,"I don't think the latest magenta version is supported on Alpine, is it?",think latest magenta version alpine,issue,negative,positive,positive,positive,positive,positive
572526316,"> Sorry, I'm not sure why the automatic installation is failing like that. I would suggest trying the manual install instructions and see if that provides any additional insight.

As you can review in [issue 1650](https://github.com/tensorflow/magenta/issues/1650) I also experienced issues with that. ",sorry sure automatic installation failing like would suggest trying manual install see additional insight review issue also experienced,issue,negative,positive,positive,positive,positive,positive
571847673,"I would recommend not installing tensorflow from a specific .whl package, but just letting the dependencies in the latest version of the magenta package select the correct version.",would recommend specific package latest version magenta package select correct version,issue,negative,positive,positive,positive,positive,positive
571749898,"Sorry, we should have some better examples for that. In the meantime, you can get a good idea of how the process works by looking at onsets_frames_transcription_create_dataset_maps.",sorry better get good idea process work looking,issue,positive,positive,positive,positive,positive,positive
571240680,"I had opened a PR years ago but never got back to finishing it–https://github.com/tensorflow/magenta/pull/359

I'll revisit this week",ago never got back finishing revisit week,issue,negative,neutral,neutral,neutral,neutral,neutral
568756993,I came here looking for the same thing because I want to create a reproducible build env. The commit removing docker is here in case anyone else needs it: https://github.com/tensorflow/magenta/commit/ee21abf65a576388de3a6af289599a536dd3c7c8,came looking thing want create reproducible build commit removing docker case anyone else need,issue,positive,neutral,neutral,neutral,neutral,neutral
568513113,"Hi Ondrej,

Sorry about the delays on this. It is going to be a couple more weeks until
we can do this on our end, but I can commit to having it done by the end of
January.

-Adam

On Tue, Dec 10, 2019 at 12:56 PM Ondřej Cífka <notifications@github.com>
wrote:

> Hi @adarob <https://github.com/adarob>, I just wanted to check to see
> when you see this happening.
>
> I will soon need to release my code which uses NoteSequences, so I'm
> thinking of creating a provisional package containing only the code in
> magenta.music to depend on until this gets resolved. Let me know if I can
> do this in a way that would make it possible for you to reuse that.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1360?email_source=notifications&email_token=AAIJV2HPLSQUKZFA37KAQDLQX77BTA5CNFSM4GGGXB3KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGQ5NVI#issuecomment-564254421>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2A5JQYBSXOUOI66WRTQX77BTANCNFSM4GGGXB3A>
> .
>
",hi sorry going couple end commit done end tue wrote hi check see see happening soon need release code thinking provisional package code depend resolved let know way would make possible reuse reply directly view,issue,negative,negative,negative,negative,negative,negative
567868173,"Here is what I've been trying in my yml file for the reference
```
  - pip install --upgrade pip virtualenv setuptools
  - virtualenv .
  - source bin/activate
  - pip debug --verbose
  - pip install --upgrade pip setuptools wheel
  - pip install six==1.12.0  # temporary fix for astroid compatibility.
  - pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.2.0rc0-cp27-none-linux_x86_64.whl
  - pip install magenta
```",trying file reference pip install upgrade pip source pip verbose pip install upgrade pip wheel pip install temporary fix astroid compatibility pip install pip install magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
567153167,"Sorry, I'm not sure why the automatic installation is failing like that. I would suggest trying the manual install instructions and see if that provides any additional insight.",sorry sure automatic installation failing like would suggest trying manual install see additional insight,issue,negative,neutral,neutral,neutral,neutral,neutral
565465879,"> I'm not sure I understand why pip is having trouble; like @AndrewRahman I was able to get the install to work by manually pre-installing earlier versions of dill, oauth2client, and pyyaml.

Yes, as mentioned at the bottom of my post here I had to manually downgrade all of those dependencies as well, but wouldn't it make more sense to have the proper dependencies outlined in the installation process rather than installing a version that is incompatible? As you can see during the installation process, oauth2client version 4.1.3 is downloaded and installed yet it is incompatible. ",sure understand pip trouble like able get install work manually dill yes bottom post manually downgrade well would make sense proper outlined installation process rather version incompatible see installation process version yet incompatible,issue,positive,positive,positive,positive,positive,positive
565132518,"I'm not sure I understand why pip is having trouble; like @AndrewRahman I was able to get the install to work by manually pre-installing earlier versions of dill, oauth2client, and pyyaml.",sure understand pip trouble like able get install work manually dill,issue,negative,positive,positive,positive,positive,positive
565123789,"@iansimon do you know why there's a version conflict with dill? Also, if beam is going to cause problems, we could look into moving it to an ""extras"" section like I did with pyaudio in 270a9b94100270a673a69889b51c1f8b4132b22f.",know version conflict dill also beam going cause could look moving section like,issue,negative,neutral,neutral,neutral,neutral,neutral
565050752,"Just so you know, I was able to downgrade dill to 0.3.0, oauth2client to 3.0.0, and pyyaml to 3.13 to get magenta to work. ",know able downgrade dill get magenta work,issue,negative,positive,positive,positive,positive,positive
564910973,"Any expected release frame, as tensorflow 2 is now the official standard? ",release frame official standard,issue,negative,neutral,neutral,neutral,neutral,neutral
564714898,"I'm not able to reproduce this problem any more in the Hello Magenta colab. Can you try resetting your runtime (Runtime, Factory reset runtime) and running it again?",able reproduce problem hello magenta try factory reset running,issue,negative,positive,positive,positive,positive,positive
564712206,"Sorry about that, should be fixed now. In 270a9b94100270a673a69889b51c1f8b4132b22f, I removed the extra dependencies from the default magenta package setup that were causing the problems.",sorry fixed removed extra default magenta package setup causing,issue,negative,negative,negative,negative,negative,negative
564651280,"Solved adding this line just added this line before installing pyfluydsynth.

>  !apt-get install portaudio19-dev python-pyaudio python3-pyaudio",line added line install,issue,negative,neutral,neutral,neutral,neutral,neutral
564627806,"Hey, it still has the same problem, I just checked this version and it's still failing.

https://colab.research.google.com/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb

Also I think it's a good idea save the versions of the notebook into the repo, so everyone can see previous versions and maybe find when it broke.

Greetings",hey still problem checked version still failing also think good idea save notebook everyone see previous maybe find broke,issue,negative,positive,positive,positive,positive,positive
564254421,"Hi @adarob, I just wanted to check to see when you see this happening.

I will soon need to release my code which uses `NoteSequence`s, so I'm thinking of creating a provisional package containing only the code in `magenta.music` to depend on until this gets resolved. Let me know if I can do this in a way that would make it possible for you to reuse that.",hi check see see happening soon need release code thinking provisional package code depend resolved let know way would make possible reuse,issue,negative,neutral,neutral,neutral,neutral,neutral
564207438,Mag files contain binary information and aren't expected to be human-readable.,mag contain binary information,issue,negative,neutral,neutral,neutral,neutral,neutral
564135454,"Hey guys, I am still looking for a solution to this issue actually is there any soon?",hey still looking solution issue actually soon,issue,negative,neutral,neutral,neutral,neutral,neutral
564130091,"I'll update the pip package today.

On Tue, Dec 10, 2019, 8:33 AM Andrew James Rahman <notifications@github.com>
wrote:

> I fixed this by pulling directly from GitHub and replacing the 'magenta'
> folder in my Mac Air⁩ ▸ ⁨anaconda3⁩ ▸ ⁨envs⁩ ▸ ⁨magenta⁩ ▸ ⁨lib⁩ ▸
> ⁨python3.7⁩⁩ ▸ site-packages with the GitHub 'magenta' folder.
> I don't think this an ideal fix as I tried to install using Anaconda (with
> many errors) and then was successfully able to install using command line
> without Anaconda, but it's working for now.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1638?email_source=notifications&email_token=AAIJV2HZYAMX4GVZ4RX77BTQX7AGXA5CNFSM4JVL7UN2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGP4CAA#issuecomment-564117760>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2HVORLSTN6AQOUUBUTQX7AGXANCNFSM4JVL7UNQ>
> .
>
",update pip package today tue wrote fixed directly folder mac folder think ideal fix tried install anaconda many successfully able install command line without anaconda working reply directly view,issue,positive,positive,positive,positive,positive,positive
564123114,Would _really_ love to see this implemented guys. Can we fix the issue?,would love see fix issue,issue,positive,positive,positive,positive,positive,positive
564118701,Hey guys? This would be really excellent. It's seriously a huge pain-in-the-@$$ to remove the primer from every generated file. Could we re-open this and get this moving?,hey would really excellent seriously huge remove primer every file could get moving,issue,positive,positive,positive,positive,positive,positive
564117760,"I fixed this by pulling directly from GitHub and replacing the 'magenta' folder in my Mac Air⁩ ▸ ⁨anaconda3⁩ ▸ ⁨envs⁩ ▸ ⁨magenta⁩ ▸ ⁨lib⁩ ▸ ⁨python3.7⁩⁩ ▸ site-packages with the GitHub 'magenta' folder. 
I don't think this an ideal fix as I tried to install using Anaconda (with many errors) and then was successfully able to install using command line without Anaconda, but it's working for now. ",fixed directly folder mac folder think ideal fix tried install anaconda many successfully able install command line without anaconda working,issue,positive,positive,positive,positive,positive,positive
564114143,"I have added @dubreuia 's fixes but now I am getting this error:

ModuleNotFoundError: No module named 'magenta.protobuf'

Which I do not see an existing error for:

```
(magenta) Andrews-MacBook-Air:~ andrewrahman$ BUNDLE_PATH=/Users/andrewrahman/Documents/Soulside/Magenta/Magenta/MagFiles/MelodyRNN/basic_rnn.mag
(magenta) Andrews-MacBook-Air:~ andrewrahman$ CONFIG='basic_rnn'
(magenta) Andrews-MacBook-Air:~ andrewrahman$ 
(magenta) Andrews-MacBook-Air:~ andrewrahman$ melody_rnn_generate \
> --config=${CONFIG} \
> --bundle_file=${BUNDLE_PATH} \
> --output_dir=/Users/andrewrahman/Desktop/Testing/Excited/Melody01/Temp1 \
> --num_outputs=10 \
> --num_steps=512 \
> --temperature=1 \
> --primer_midi=/Users/andrewrahman/Desktop/ExcitedPrimers/Melody01.mid
Traceback (most recent call last):
  File ""/anaconda3/envs/magenta/bin/melody_rnn_generate"", line 5, in <module>
    from magenta.models.melody_rnn.melody_rnn_generate import console_entry_point
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 26, in <module>
    from magenta.models.shared import sequence_generator_bundle
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/shared/sequence_generator_bundle.py"", line 17, in <module>
    from magenta.protobuf import generator_pb2
ModuleNotFoundError: No module named 'magenta.protobuf'
```",added getting error module see error magenta magenta magenta magenta recent call last file line module import file line module import file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
564104173,"Hi! I'm still experiencing this issue with Magenta 1.2.0. Just updated from 0.5.0.

```
(magenta) Andrews-MacBook-Air:~ andrewrahman$ BUNDLE_PATH=/Users/andrewrahman/Documents/Soulside/Magenta/Magenta/MagFiles/MelodyRNN/basic_rnn.mag
(magenta) Andrews-MacBook-Air:~ andrewrahman$ CONFIG='basic_rnn'
(magenta) Andrews-MacBook-Air:~ andrewrahman$ 
(magenta) Andrews-MacBook-Air:~ andrewrahman$ melody_rnn_generate \
> --config=${CONFIG} \
> --bundle_file=${BUNDLE_PATH} \
> --output_dir=/Users/andrewrahman/Desktop/Testing/Excited/Melody01/Temp1 \
> --num_outputs=10 \
> --num_steps=512 \
> --temperature=1 \
> --primer_midi=/Users/andrewrahman/Desktop/ExcitedPrimers/Melody01.mid
WARNING:tensorflow:From /anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py:250: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py:221: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

W1210 17:03:00.819072 4592190912 module_wrapper.py:139] From /anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py:221: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

Traceback (most recent call last):
  File ""/anaconda3/envs/magenta/bin/melody_rnn_generate"", line 8, in <module>
    sys.exit(console_entry_point())
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 250, in console_entry_point
    tf.app.run(main)
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 223, in main
    bundle = get_bundle()
  File ""/anaconda3/envs/magenta/lib/python3.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 125, in get_bundle
    return magenta.music.read_bundle_file(bundle_file)
AttributeError: module 'magenta.music' has no attribute 'read_bundle_file'
(magenta) Andrews-MacBook-Air:~ andrewrahman$ 
```",hi still issue magenta magenta magenta magenta magenta warning name please use instead warning name please use instead name please use instead recent call last file line module file line main file line run file line run main file line main file line main bundle file line return module attribute magenta,issue,negative,positive,positive,positive,positive,positive
563921572,Ok thanks. Will try setting it up with docker. 👍 ,thanks try setting docker,issue,negative,positive,positive,positive,positive,positive
563347469,"Yes, we no longer officially support the Docker setup, but you can look in the repo history to see the old file. It probably wouldn't take too much effort for you to get it working again with the current state of the repo.",yes longer officially support docker setup look history see old file probably would take much effort get working current state,issue,positive,positive,positive,positive,positive,positive
562426061,I can confirm that this is an issue for the [Hello Magenta colab](https://colab.research.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb).,confirm issue hello magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
562360731,"Which colab is this? If it's one that's not actually in the GitHub repo, it is updated once a day automatically.",one actually day automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
562349158,"This seems to be fixed in commit [d40f5c4b](https://github.com/tensorflow/magenta/commit/d40f5c4bccf38e5978d8f1d75b2aef3dded553e2#diff-b2495e2e1d31bd46273496c9921d20fd). However, I guess this needs to be released to the colab.",fixed commit however guess need,issue,negative,positive,neutral,neutral,positive,positive
562032658,"Not exactly what you want @momo1986, but you could use `midi_hub` from the `magenta.interfaces.midi` module and play the MIDI notes from the generated `NoteSequence`. Check this code https://github.com/dubreuia/alexandredubreuil.com/tree/master/conferences/music-generation-with-magenta/code and the ""app.py"" and ""model.py"" files.",exactly want momo could use module play check code,issue,negative,positive,positive,positive,positive,positive
561899336,Magenta is not 2.0-compatible yet. Please try with 1.15 and let us know if you still have issues!,magenta yet please try let u know still,issue,negative,neutral,neutral,neutral,neutral,neutral
561760216,"No problem, thank you for making Magenta, amazing project by the way.",problem thank making magenta amazing project way,issue,positive,positive,positive,positive,positive,positive
561051297,"This issue only happens on Windows, not on Linux.

I have not found a suitable workaround currently.

Is there any suitable comment?

Thanks & regards!
Jun Yan",issue found suitable currently suitable comment thanks yan,issue,negative,positive,positive,positive,positive,positive
559395857,I am also facing the same issue when trying to use Dataflow to train the files. Any help would be much appreciated.,also facing issue trying use train help would much,issue,negative,positive,positive,positive,positive,positive
559324716,"I try it again today ,It's OK ,so amazing! thank you! But I don't know why the error happened in yestorday ",try today amazing thank know error,issue,positive,positive,positive,positive,positive,positive
559323210,"> I'm not able to reproduce this, but I wonder if it's related to a recent package path change we made. Can you try going to the Runtime menu and selecting ""Reset all runtimes"" and see if that fixes it?

Thankyou ,I want to know how to find the ""Reset all runtimes"" menu!",able reproduce wonder related recent package path change made try going menu reset see want know find reset menu,issue,negative,positive,positive,positive,positive,positive
559248237,"I'm not able to reproduce this, but I wonder if it's related to a recent package path change we made. Can you try going to the Runtime menu and selecting ""Reset all runtimes"" and see if that fixes it?",able reproduce wonder related recent package path change made try going menu reset see,issue,negative,positive,positive,positive,positive,positive
559197588,"As a quick temporary solution, change line 40 of setup.py to `'librosa >= 0.6.2, < 0.7',`.  Not sure what to do going forward as I also was unable to get setup.py to install libsndfile on the workers.",quick temporary solution change line sure going forward also unable get install,issue,positive,positive,positive,positive,positive,positive
558325190,We release a new version of the pip package and the notebook should be working again without any changes.,release new version pip package notebook working without,issue,negative,positive,positive,positive,positive,positive
558316332,"Thanks for your contribution! A few requests:

- Let's name the new file `README.ko.md` to be consistent with ISO 639-1 language codes and the file naming convention proposed by https://github.com/tiimgreen/github-cheat-sheet (which is as close as I could find to a standard for markdown files).
- Please add some text at the top of the Korean file explaining that it may be out of date because it is not officially maintained and that any questions about the translation should go to you.",thanks contribution let name new file consistent iso language file naming convention close could find standard markdown please add text top file explaining may date officially translation go,issue,positive,positive,positive,positive,positive,positive
558282704,The `Bus error` problem means that the error is probably coming from within Tensorflow. I'd guess the most likely cause is either your CPU doesn't support some instruction set that Tensorflow was compiled with or there's an error with how your GPU drivers are installed.,bus error problem error probably coming within guess likely cause either support instruction set error,issue,negative,neutral,neutral,neutral,neutral,neutral
558279163,"Sorry about that, but the pip package and colab are out of sync. For now, you can should be able to change that line to

`from magenta.protobuf import music_pb2`",sorry pip package sync able change line import,issue,negative,neutral,neutral,neutral,neutral,neutral
557615811,Sorry about that. I think there's a mismatch between the notebook and some recent changes we made. A fixed version should be live on Monday or Tuesday.,sorry think mismatch notebook recent made fixed version live,issue,negative,negative,neutral,neutral,negative,negative
555657249,"Hi fanzhiyan,

Thanks for the pull request! Sorry I should have jumped on this sooner. The change you've added looks to be more correct, which is great. Unfortunately, this is not an active research project (close to 3 years old now), the public checkpoint was trained without this correction, and unfortunately I won't be able to train a new model and release a new checkpoint for your changes. I'd still be happy to accept it if you can show that resynthesizing a some sounds with the public checkpoint sounds roughly the same before and after the PR. 

Thanks again for the contribution and eye for detail, and sorry for not chiming in sooner.",hi thanks pull request sorry sooner change added correct great unfortunately active research project close old public trained without correction unfortunately wo able train new model release new still happy accept show public roughly thanks contribution eye detail sorry sooner,issue,positive,positive,positive,positive,positive,positive
555161790,"OK, thanks for verifying. I suspect the API changed, especially since at this point we're using wrappers of wrappers of compatibility layers. :-)",thanks suspect especially since point compatibility,issue,negative,positive,neutral,neutral,positive,positive
554851526,"Yes, we didn't get any onsets for a long time with the current values. Even when we tried to overfit by using a very small chunk of data (just 20 odd pieces). Fixing the dropout values fixed this problem. 
Maybe the API in TF changed from the version you used. But keep_prob of 25% will drastically slow down training I think.",yes get long time current even tried overfit small chunk data odd fixing dropout fixed problem maybe version used drastically slow training think,issue,negative,negative,negative,negative,negative,negative
554564288,trying to import again ... stay tuned!,trying import stay tuned,issue,negative,neutral,neutral,neutral,neutral,neutral
554476618,The problem is inside the TensorFlow autograph -- I have a workaround which we'll merge soon.,problem inside autograph merge soon,issue,negative,neutral,neutral,neutral,neutral,neutral
554235051,"I tried on a few; my current build is using 1.15.0. I also tried rc3, hoping this was a strange tensorflow edge-case that got fixed, but to no avail.",tried current build also tried strange got fixed avail,issue,negative,positive,neutral,neutral,positive,positive
554128537,"I think we actually did train with these values (maybe not intentionally!), so I'd like to keep them as is. Have you tried training with these values vs. the changed ones?",think actually train maybe intentionally like keep tried training,issue,negative,neutral,neutral,neutral,neutral,neutral
553294970,"Thank you so much for your suggestions!

Changing the call to optimize_loss to how it was before the [982740e](https://github.com/tensorflow/magenta/commit/982740ee6e56d674e3f220d7bf215ae4132c9c1c) commit helped resolve the problem.

Specifically, changing this snippet: https://github.com/tensorflow/magenta/blob/177416c365bf2d6eea3bb38c1bd2d2a54acf8652/magenta/models/onsets_frames_transcription/model.py#L485-L496 to this 
```
adam_optimizer = tf.train.AdamOptimizer(
                        learning_rate=hparams.learning_rate)
train_op = slim.learning.create_train_op(
          loss,
          adam_optimizer,
          clip_gradient_norm=hparams.clip_norm,
          summarize_gradients=True,
          variables_to_train=None)
``` 
worked!
",thank much call commit resolve problem specifically snippet loss worked,issue,negative,positive,positive,positive,positive,positive
553277166,"I tried a different builds - I don't think that was the bug. In one case it was the custom ftrecord we had built for LMD data which was having some records with more than 20 seconds of wav data which was causing it. Different truncated_length_secs did the trick in that case and got it working with batch size 6. Thank you so much for the help!
Our training is going on, but is slow with single GPU for dataset of the size of maestro. Thanks again.",tried different think bug one case custom built data data causing different trick case got working batch size thank much help training going slow single size maestro thanks,issue,positive,positive,neutral,neutral,positive,positive
552618395,"@adarob I moved `magenta.music` back in the main package as requested but kept the other changes (moving protobuffers and test data). I think this should be ready to merge now.

You might want to re-generate `__init__.py` (I edited it by hand).",back main package kept moving test data think ready merge might want hand,issue,positive,positive,positive,positive,positive,positive
552601388,"I suspect that's due to some training changes I made in 982740ee6e56d674e3f220d7bf215ae4132c9c1c. Sorry about the incompatibility, I've mostly paid attention to making the checkpoints compatible for inference. You could try removing the 'training' parameter in the call to optimize_loss, edit the checkpoint itself, or sync to before that commit.",suspect due training made sorry incompatibility mostly attention making compatible inference could try removing parameter call edit sync commit,issue,negative,negative,neutral,neutral,negative,negative
552376445,"Can you make sure you're using TF 1.15? HParams is removed in TF 2.0.

On Thu, Nov 7, 2019 at 1:28 AM Pauladds <notifications@github.com> wrote:

> The problem is ""tf.contrib.training.HParams"" (from
> magenta/magenta/models/sketch_rnn/model.py)
> [image: Capture]
> <https://user-images.githubusercontent.com/38189240/68376718-5b0c6200-0149-11ea-8755-428aed13575a.PNG>
> does not exist so I don't know what I need to put to replace
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1618?email_source=notifications&email_token=AAIJV2A7LKJIBNFD5ICCXALQSPNU3A5CNFSM4JJUO6ZKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDLYYOY#issuecomment-550997051>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAIJV2HSUY2DE3OZU4OR33TQSPNU3ANCNFSM4JJUO6ZA>
> .
>
",make sure removed wrote problem image capture exist know need put replace thread reply directly view,issue,negative,positive,positive,positive,positive,positive
552322641,"Not a proper midi format: Try changing the files. I found this script in another git https://github.com/mido/mido/issues/107

Script:
import mido
import os 
from mido import Message, MidiFile, MidiTrack
import sys

def process(filename):
    #mid = mido.read_syx_file(filename)
    mid = MidiFile(filename)
    for track in mid.tracks:
       for i, msg in enumerate(track):
            if msg.type == 'control_change':
                ped = msg.value
                pedfix = abs(ped-127)
                # Replace message in track.                                         
                track[i] = msg.copy(value=pedfix)

    mid.save('*' + filename)


for f in os.listdir('.'):
    # for f in os.listdir('./midifiles'):
    process(f)",proper format try found script another git script import import o import message import process mid mid track enumerate track ped replace message track track process,issue,negative,neutral,neutral,neutral,neutral,neutral
551941814,"Hmm, that does seem odd. We used a variety of training setups, and don't remember for sure what we used for that checkpoint, but something along the lines of a V100 GPU with batch size 8 (but we might have done data parallelism across several GPUs).

Maybe it's a TF bug? Could you try an older build of TF?",seem odd used variety training remember sure used something along batch size might done data parallelism across several maybe bug could try older build,issue,negative,positive,positive,positive,positive,positive
551928935,"Sorry for the delays in reviewing this, but I think we'll just go ahead and make the same change in #1614, so I'll close this PR. But thanks for your contribution, and we'd welcome further PRs from you!",sorry think go ahead make change close thanks contribution welcome,issue,positive,positive,positive,positive,positive,positive
551925409,"We're tracking TF2 compatibility in #1594, so closing this issue.

Feel free to send a PR to update the README.",compatibility issue feel free send update,issue,positive,positive,positive,positive,positive,positive
551836560,"@googlebot I signed it!

________________________________
发件人: googlebot <notifications@github.com>
发送时间: 2019年11月7日 23:47
收件人: tensorflow/magenta <magenta@noreply.github.com>
抄送: fanzhiyan <fan_zhiyan@hotmail.com>; Author <author@noreply.github.com>
主题: Re: [tensorflow/magenta] The value of out is 128 if x is 1.0, but it should be 127 (#1619)


Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

📝 Please visit https://cla.developers.google.com/ to sign.

Once you've signed (or fixed any issues), please reply here with @googlebot I signed it! and we'll verify it.

________________________________
What to do if you already signed the CLA
Individual signers

  *   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check your existing CLA data<https://cla.developers.google.com/clas> and verify that your email is set on your git commits<https://help.github.com/articles/setting-your-email-in-git/>.

Corporate signers

  *   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to go/cla#troubleshoot<http://go/cla#troubleshoot> (Public version<https://opensource.google/docs/cla/#troubleshoot>).
  *   The email used to register you as an authorized contributor must be the email used for the Git commit. Check your existing CLA data<https://cla.developers.google.com/clas> and verify that your email is set on your git commits<https://help.github.com/articles/setting-your-email-in-git/>.
  *   The email used to register you as an authorized contributor must also be attached to your GitHub account<https://github.com/settings/emails>.

ℹ️ Googlers: Go here<https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmagenta%2Fpull%2F1619> for more info.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/tensorflow/magenta/pull/1619?email_source=notifications&email_token=ALMN6XOTV3ENDPRXYYGVKZDQSQ2B7A5CNFSM4JKIZEQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDM27DY#issuecomment-551137167>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ALMN6XL2JWZPS3A5XVGZE23QSQ2B7ANCNFSM4JKIZEQQ>.
",magenta author author value thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account information go thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
551543723,"On Ubuntu 18.04
Installed manually magenta-gpu. 
scipy==1.3.1

Traceback (most recent call last):
  File ""/home/superuser/pyenv/magenta/bin/arbitrary_image_stylization_with_weights"", line 8, in <module>
    sys.exit(console_entry_point())
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_with_weights.py"", line 183, in console_entry_point
    tf.app.run(main)
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_with_weights.py"", line 118, in main
    content_img_np = image_utils.load_np_image_uint8(content_img_path)[:, :, :
  File ""/home/superuser/pyenv/magenta/lib/python3.6/site-packages/magenta/models/image_stylization/image_utils.py"", line 407, in load_np_image_uint8
    image = scipy.misc.imread(f.name)
AttributeError: module 'scipy.misc' has no attribute 'imread'",manually recent call last file line module file line main file line run file line run main file line main file line main file line image module attribute,issue,negative,positive,positive,positive,positive,positive
551364767,"https://github.com/tensorflow/magenta/blob/0af29601b9d7e499af83352a9df3e97c7da63cbd/setup.py#L71
 It's not the biggest problem, but I think this info should be front and center in the README.",biggest problem think front center,issue,negative,negative,neutral,neutral,negative,negative
550997051,"The problem is ""tf.contrib.training.HParams"" (from magenta/magenta/models/sketch_rnn/model.py) 
![Capture](https://user-images.githubusercontent.com/38189240/68376718-5b0c6200-0149-11ea-8755-428aed13575a.PNG)
does not exist so I don't know what I need to put to replace ",problem capture exist know need put replace,issue,negative,neutral,neutral,neutral,neutral,neutral
550224873,"This looks like possibly an issue of Cuda version mismatch/ not added to path correctly.

> Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
> Skipping registering GPU devices...

Certainly points to that.
 What's the output of 
`tf.test.is_gpu_available()`?",like possibly issue version added path correctly please make sure missing properly would like use follow guide setup platform skipping certainly output,issue,positive,positive,positive,positive,positive,positive
550116082,"More logs before the previous post:
2019-11-05 20:25:52.957209: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /root/anaconda3/lib/:
2019-11-05 20:25:52.960330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-11-05 20:25:52.960357: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2019-11-05 20:25:52.960723: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-05 20:25:52.969081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
2019-11-05 20:25:52.971085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1e97be5f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-05 20:25:52.971110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-11-05 20:25:52.974750: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:3: failed initializing StreamExecutor for CUDA device ordinal 3: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal
2019-11-05 20:25:52.975185: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:4: failed initializing StreamExecutor for CUDA device ordinal 4: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal
2019-11-05 20:25:53.142180: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:7: failed initializing StreamExecutor for CUDA device ordinal 7: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN: unknown error
2019-11-05 20:25:53.154143: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:5: failed initializing StreamExecutor for CUDA device ordinal 5: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN: unknown error
2019-11-05 20:25:53.163928: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:6: failed initializing StreamExecutor for CUDA device ordinal 6: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN: unknown error
2019-11-05 20:25:54.909159: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1e93af0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2019-11-05 20:25:54.909198: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
2019-11-05 20:25:54.909207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-16GB, Compute Capability 7.0
2019-11-05 20:25:54.909215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-PCIE-16GB, Compute Capability 7.0
Traceback (most recent call last):
  File ""/root/anaconda3/bin/melody_rnn_train"", line 11, in <module>
    load_entry_point('magenta', 'console_scripts', 'melody_rnn_train')()
  File ""/eviluess/magenta/magenta/models/melody_rnn/melody_rnn_train.py"", line 108, in console_entry_point",previous post could load dynamic library open object file file directory successfully dynamic library please make sure missing properly would like use follow guide setup platform skipping binary use frequency service platform host guarantee used device host default version unable create device ordinal internal call invalid device ordinal unable create device ordinal internal call invalid device ordinal unable create device ordinal internal call unknown error unable create device ordinal internal call unknown error unable create device ordinal internal call unknown error service platform guarantee used device compute capability device compute capability device compute capability recent call last file line module file line,issue,positive,negative,negative,negative,negative,negative
550115874,"Now I have a new issue that seems to be the hardware configuration, or could you plz give me some advice to fix it, thanks!

  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 725, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1207, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 1212, in _create_session
    return self._sess_creator.create_session()
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 878, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py"", line 647, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/session_manager.py"", line 290, in prepare_session
    config=config)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/session_manager.py"", line 194, in _restore_checkpoint
    sess = session.Session(self._target, graph=self._graph, config=config)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1585, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 699, in __init__
    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Invalid device ordinal value (3). Valid range is [0, 2].
        while setting up XLA_GPU_JIT device number 3

",new issue hardware configuration could give advice fix thanks file line file line self file line return file line file line file line file line sess file line super session self target graph file line invalid device ordinal value valid range setting device number,issue,positive,positive,positive,positive,positive,positive
549947544,"No I didn't add any more supported notes. It's still at default value. Trying with batch size 1 and keeping truncated_length_secs same it ran for about 1300 steps before the same OOM error. I'm suspecting a gradual filling up of memory at each sample somewhere along the way because even with the big network size, 12 GB wouldn't get filled up this quickly. Will post updates here as I dig more through the code.
Just curious - what GPU and batch size was the original model trained on? ",add still default value trying batch size keeping ran error gradual filling memory sample somewhere along way even big network size would get filled quickly post dig code curious batch size original model trained,issue,positive,positive,positive,positive,positive,positive
549723914,"Hey, Sorry for my late response.
I don't have the machine that has the environment to run the code.

I'll try your solution asap.

Thank you very much.",hey sorry late response machine environment run code try solution thank much,issue,positive,negative,negative,negative,negative,negative
549507947,"I'd try setting the batch size to 1 and maybe trying out different values for truncated_length_secs until you get something that works and then try scaling up from there.

Did you end up changing anything about the size of the pianorolls, like adding more supported notes or something? That could definitely affect things.",try setting batch size maybe trying different get something work try scaling end anything size like something could definitely affect,issue,positive,neutral,neutral,neutral,neutral,neutral
549059235,"So you cannot use look back_rnn in sequence example generation and attention_rnn in training. Both need to be same as input sizes for both configurations are different. Right now, you're generating input for lookback and trying to pass it into attention rnn. Change one of those as per your choice and it should work.

Example, train command could be changed to
melody_rnn_train
--config=lookback_rnn
--run_dir=/tmp/melody_rnn/logdir/run1
--sequence_example_file=/tmp/melody_rnn/sequence_examples/training_melodies.tfrecord
--hparams=""batch_size=64,rnn_layer_sizes=[64,64]""
--num_training_steps=20000",use look sequence example generation training need input size different right generating input trying pas attention change one per choice work example train command could,issue,negative,positive,positive,positive,positive,positive
549028522,"Thanks for your quick reply.

The config is lookback_rnn.

For the detail of what I have done, I'll show you all my steps (from the very beginning to error):

1. I tested the environment using ""Generate a melody"":

BUNDLE_PATH=/eviluess/res/lookback_rnn.mag
CONFIG=lookback_rnn
melody_rnn_generate \
--config=${CONFIG} \
--bundle_file=${BUNDLE_PATH} \
--output_dir=/tmp/melody_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""

And it's fine and shows:
Wrote 10 MIDI files to /tmp/melody_rnn/generated

2.  To build a dataset, I followed ""Building your Dataset"" and actually do the following things:
2.1. I downloaded ""Building your Dataset"" and unpacked it with tar -xf and no error occurs.
2.2. Convert a **subset** of it to NoteSequences:
INPUT_DIRECTORY=/eviluess/res/lmd_matched/A/A
SEQUENCES_TFRECORD=/tmp/notesequences.tfrecord

convert_dir_to_note_sequences \
  --input_dir=$INPUT_DIRECTORY \
  --output_file=$SEQUENCES_TFRECORD \
  --recursive

And it ran fine. The last line of the result is:
INFO:tensorflow:Converted MIDI file /eviluess/res/lmd_matched/A/A/S/TRAASKZ128F9308820/886270e42b69e0983dfd9a591e66f214.mid.
I1102 17:43:05.389676 140640958502656 convert_dir_to_note_sequences.py:133] Converted MIDI file /eviluess/res/lmd_matched/A/A/S/TRAASKZ128F9308820/886270e42b69e0983dfd9a591e66f214.mid.

2.3. Create SequenceExamples -- the step you concert:
melody_rnn_create_dataset \
--**config=lookback_rnn** \
--input=/tmp/notesequences.tfrecord \
--output_dir=/tmp/melody_rnn/sequence_examples \
--eval_ratio=0.10

It succeeded with the following results:
INFO:tensorflow:DAGPipeline_TranspositionPipeline_training_transpositions_generated: 780
I1102 17:48:18.414772 139742925997824 statistics.py:141] DAGPipeline_TranspositionPipeline_training_transpositions_generated: 780

And I checked the directory, the files are there indeed.

2.4. Train and Evaluate the Model
I ran the command directly:

melody_rnn_train \
--config=attention_rnn \
--run_dir=/tmp/melody_rnn/logdir/run1 \
--sequence_example_file=/tmp/melody_rnn/sequence_examples/training_melodies.tfrecord \
--hparams=""batch_size=64,rnn_layer_sizes=[64,64]"" \
--num_training_steps=20000

And I got errors like the post.
",thanks quick reply detail done show beginning error tested environment generate melody fine wrote build building actually following building unpacked tar error convert subset recursive ran fine last line result converted file converted file create step concert following checked directory indeed train evaluate model ran command directly got like post,issue,positive,positive,positive,positive,positive,positive
549011544,"Magenta depends on networkx==1.8.1, which is the broken version. Newer versions of networkx seem to work fine.",magenta broken version seem work fine,issue,negative,positive,neutral,neutral,positive,positive
549009904,Looks like you did not set the config correctly when following the steps for sequenceExamples generation there. That could be causing the difference in shapes it is complaining about. Could you paste the command you used to generate the sequenceExample? ,like set correctly following generation could causing difference could paste command used generate,issue,negative,neutral,neutral,neutral,neutral,neutral
548153146,"Hi @jesseengel, I'm honored that you'd check this out!   I'll happily do as you ask, and will set `use_unwrap=True` and resubmit.   (use_cumsum is elsewhere in my code, and I didn't change that part of your code) 

I think you wouldn't notice any difficulty for short audio clips and/or relatively high numerical precision, but for longer clips (longer than 1 second) and/or lower precision (e.g. FP16), you'll really notice the error accumulation affect the audio.   In my tests with 3-second-long audio and FP32, unwrapping yielded a maximum waveform reconstruction error of around 1e-3, whereas with this 'different' method it was only 4e-6, and the difference was audible.  Plus the modified version ran an average of 30% faster. 

I only ran those measurements using numpy though (in the gist linked to above), not the full TF/magenta suite.  I'd be interested to find out if my modification works better for you, in terms of accuracy and/or execution time
",hi check happily ask set resubmit elsewhere code change part code think would notice difficulty short audio clip relatively high numerical precision longer clip longer second lower precision really notice error accumulation affect audio audio unwrapping maximum reconstruction error around whereas method difference audible plus version ran average faster ran though gist linked full suite interested find modification work better accuracy execution time,issue,negative,positive,positive,positive,positive,positive
548144531,"Cool, thanks for the contribution! This all seems fine, however it doesn't seem to be a limiting factor on audio quality for this model. Can you please set `use_cumsum=True` by default, so that the code still reflects the work of the paper by default?

Thanks!",cool thanks contribution fine however seem limiting factor audio quality model please set default code still work paper default thanks,issue,positive,positive,positive,positive,positive,positive
548134171,Sorry for the extremely late reply. I think you'd have to actually retrain a model to make sense of those conditioning features (as the model expects one-hot pitch features now). ,sorry extremely late reply think actually retrain model make sense model pitch,issue,negative,negative,negative,negative,negative,negative
548126954,"Ah, I think I found it. I retrained a model on GCP to see what you were talking about. It trains fine, but I noticed the generated instruments were mostly organs (which is the majority of ""electronic"" instruments in the nsynth dataset).  Sure enough the code currently is filtering for the electronic subset (which has less diversity). I'll submit a PR, but for now you can just change this line: https://github.com/tensorflow/magenta/blob/0afca8f87dc8af4ef71ded5f680014d00d3da625/magenta/models/gansynth/lib/datasets.py#L114 from filter for index 1 to filtering for index 0.",ah think found model see talking fine mostly majority electronic sure enough code currently filtering electronic subset le diversity submit change line filter index filtering index,issue,negative,positive,positive,positive,positive,positive
548116473,"You should make sure your batch size is 1 (1 input z), but unfortunately, for the python version there's not much more to do  beyond that as GANSynth was trained on fixed-length sequences. 

We did create a javascript version: https://github.com/tensorflow/magenta-js/blob/master/music/demos/gansynth.html
Used in this demo:
https://ganharp.ctpt.co/

That might suit your needs.",make sure batch size input unfortunately python version much beyond trained create version used might suit need,issue,negative,positive,neutral,neutral,positive,positive
547118830,Sorry for the delay...looking at this today.,sorry delay looking today,issue,negative,negative,negative,negative,negative,negative
545572166,"Please replace the file ""checkpoint"" in your coconet_checkpoint\coconet-64layers-128filters folder with the following one: [checkpoint.zip](https://github.com/tensorflow/magenta/files/3763823/checkpoint.zip).
This is not an issue in code. we can close this item.",please replace file folder following one issue code close item,issue,negative,neutral,neutral,neutral,neutral,neutral
545555227,"@adarob Sorry about the delay, had to push to cut an internal release. I've addressed your comments and made a couple small changes to config (a few new fields, and a method for serializing information needed in order to properly serve routines trained with the existing training infrastructure as part of the script)

The ServableModel/Servable VAE module I'll be PRing in a few uses the exported metadata when constructing the a new interface to the actual saved model running on tf-serving (simplified implementations of sample/interpolate in terms of the 'encode' and 'decode' signatures exported here, via PredictRequest proto over grpc) The new fields are strictly additive and default initialized so no existing code is affected.

Let me know if you have any other concerns. 

",sorry delay push cut internal release made couple small new method information order properly serve trained training infrastructure part script module new interface actual saved model running simplified via proto new strictly additive default code affected let know,issue,negative,negative,neutral,neutral,negative,negative
544280291,"Look under https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#train-your-own This has steps for creating TFrecords of 1. Notesequence format and the 2. Sequence examples which are fed into your system. Since as per your problem, none of the inbuilt configs would sove the problem directly for you - you would need to make a new case replacing `basic_rnn` in the create_dataset command which would pair the input output midis as per your requirement.
Basically, you would be needed to add a class here https://github.com/tensorflow/magenta/blob/master/magenta/music/encoder_decoder.py as per your needs which would take in 2 sets of events instead of just one - see some of their examples and you'll get an idea.",look format sequence fed system since per problem none inbuilt would problem directly would need make new case command would pair input output per requirement basically would add class per need would take instead one see get idea,issue,negative,positive,positive,positive,positive,positive
540754950,"Great, I just heard that the corporate CLA has been cleared/signed, so we're good to go. ",great corporate good go,issue,positive,positive,positive,positive,positive,positive
540737221,"You should be able to follow the instructions here: https://cla.developers.google.com/about/google-corporate

Let me know if you have issues.",able follow let know,issue,negative,positive,positive,positive,positive,positive
540736514,"@adarob Thank you so much, I'll address these issues. I realized today that the CLA I signed actually needs to be a corporate one -- what process should I go through to void my individual CLA and sign the corporate one?",thank much address today actually need corporate one process go void individual sign corporate one,issue,negative,positive,neutral,neutral,positive,positive
540700712,"The contents of the GraphDef file should not be affected by how long the model has trained. However, there are a number of other barriers to getting things to work with TFLite, though it's definitely possible. We're also hoping to look at a realtime/TFLite version soon, but not sure when it would be available.",content file affected long model trained however number getting work though definitely possible also look version soon sure would available,issue,positive,positive,positive,positive,positive,positive
540591760,"OK, because of my hardware facility, maybe I have to give up this. 
Thanks!
I really want to know whether the GraphDef file is the same as the full train when I train onsets&frames model just a while. I want to use GraphDef file and checkpoint to generate frozen GraphDef file, and finally, get TFlite file.
Maybe my words is not clear.
Thank you for your hospitality！",hardware facility maybe give thanks really want know whether file full train train model want use file generate frozen file finally get file maybe clear thank,issue,positive,positive,positive,positive,positive,positive
540152010,"You certainly aren't required to use all of the dataset, I'm just curious if the poor results are specific to that shard or if they're consistent across the entire dataset.",certainly use curious poor specific shard consistent across entire,issue,negative,negative,neutral,neutral,negative,negative
539890472,"This happened to me before, try to downgrade the magenta version, the newest version has some conflictions with the model or the environment as I remember.",try downgrade magenta version version model environment remember,issue,negative,neutral,neutral,neutral,neutral,neutral
539776195,"> What happens if you do inference over all the shards of the test.tfrecord file? Do they all get scores that low?

I don't know, I just take a part of dataset, must I use all the dataset?",inference file get low know take part must use,issue,negative,neutral,neutral,neutral,neutral,neutral
539770752,"I think the main thing that's causing inputs to be dropped is ""tracks_discarded_more_than_1_program"". The polyphony_rnn model doesn't support outputting multiple programs (instruments), so the dataset creation setup currently excludes MIDI/NoteSequence inputs with multiple programs.",think main thing causing model support multiple creation setup currently multiple,issue,positive,positive,neutral,neutral,positive,positive
539676308,What happens if you do inference over all the shards of the test.tfrecord file? Do they all get scores that low?,inference file get low,issue,negative,neutral,neutral,neutral,neutral,neutral
538541461,"Ah, I understand now. Sorry for the confusion. I'll get that fixed.",ah understand sorry confusion get fixed,issue,negative,negative,negative,negative,negative,negative
537978774,"> Can you try again with the latest version of the pip package in a clean environment (e.g., a fresh conda env)? For now, we've pinned everything to TensorFlow 1.x until we have better support for 2.0. This should fix some of the issues you were seeing.

Yes now pip can pick the right version (1.14.0) of tensorflow, but the problem about sonnet is still present.
I checked the code and the 'sonnet' package should mean to this:
https://github.com/deepmind/sonnet
https://pypi.org/project/dm-sonnet/
but when you ask pip to install 'sonnet', pip will (at least on my computer) try to install this:
https://pypi.org/project/sonnet/
This package has a dependence networkx==1.8.1, which occurs this issue.",try latest version pip package clean environment fresh pinned everything better support fix seeing yes pip pick right version problem sonnet still present checked code package mean ask pip install pip least computer try install package dependence issue,issue,positive,positive,positive,positive,positive,positive
537705946,"Can you try again with the latest version of the pip package in a clean environment (e.g., a fresh conda env)? For now, we've pinned everything to TensorFlow 1.x until we have better support for 2.0. This should fix some of the issues you were seeing.",try latest version pip package clean environment fresh pinned everything better support fix seeing,issue,positive,positive,positive,positive,positive,positive
536808068,"Right now, Magenta supports only TF1. Renaming this issue to track overall TF2 support.",right magenta issue track overall support,issue,negative,positive,positive,positive,positive,positive
536707331,"+Yotam Mann <yotammann@gmail.com> any insights on this?

On Sat, Sep 28, 2019 at 8:30 AM Arke759 <notifications@github.com> wrote:

> Hello!
> I have just installed Magenta Studio for my Ableton 10.1, but when I try
> to launch any Magenta's plugin nothing happens. Here are some screens.
> I know exactly that it is not the issue of memory, cuz I have 16 Gb RAM.
> Excuse me I am not a programmer at all.
> [image: Screenshot_124]
> <https://user-images.githubusercontent.com/55922530/65818823-0c041080-e21e-11e9-80ad-33c81b4f656e.jpg>
> [image: Screenshot_125]
> <https://user-images.githubusercontent.com/55922530/65818824-0c041080-e21e-11e9-8706-effc5411c393.jpg>
> [image: Screenshot_126]
> <https://user-images.githubusercontent.com/55922530/65818825-0c041080-e21e-11e9-945a-2dc7a00de912.jpg>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1593?email_source=notifications&email_token=AAIJV2FNEVBOUCHAHV5X3CTQL52CNA5CNFSM4I3OSNZKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HOKEAGQ>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAIJV2CZKRX2OYMFNCG2WI3QL52CNANCNFSM4I3OSNZA>
> .
>
",sat wrote hello magenta studio try launch magenta nothing know exactly issue memory ram excuse programmer image image image thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
536656651,"Sorry it was broken for a while. Both the colab and local script should be fixed as of today. If the local script isn't working, can you verify that you have the latest version of the pip package?",sorry broken local script fixed today local script working verify latest version pip package,issue,negative,negative,neutral,neutral,negative,negative
536509996,"Hi! I also have the same problem and I find a solution.
You see [here](https://github.com/tensorflow/magenta/blob/77f867b3821577f3642f34be90e7a4f149e1fe73/setup.py#L61) that magenta tries to install sonnet as a dependency, but I found that it actually means to install another library named dm-sonnet, so you can correct it and manually run setup.py to install it.
By the way it will tend to install tensorflow 2.0 which is incompatible with
magenta itself, so I have to manually uninstall the 2.0 version and install 1.14.0 version (I'm not sure if there is some better way). After that it should work. (with bunch of deprecate warning though)
I hope this will help.",hi also problem find solution see magenta install sonnet dependency found actually install another library correct manually run install way tend install incompatible magenta manually version install version sure better way work bunch deprecate warning though hope help,issue,positive,positive,positive,positive,positive,positive
536368367,From [SoundFile](https://pypi.org/project/SoundFile/) you need to install libsndfile by `sudo apt-get install libsndfile1`. You can change your `setup.py` to install non-python dependencies as suggested [here](https://beam.apache.org/documentation/sdks/python-pipeline-dependencies/). And you can find an example [here](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/complete/juliaset/setup.py).,need install install change install find example,issue,negative,neutral,neutral,neutral,neutral,neutral
536101507,"Great, thanks for doing this! It would hopefully allow us to add these models to TF Hub as well.",great thanks would hopefully allow u add hub well,issue,positive,positive,positive,positive,positive,positive
536064017,"It's incomplete/untested, I accidentally opened the PR upstream instead of against my fork -- after it's finished and tested I will open a new PR. ",accidentally upstream instead fork finished tested open new,issue,negative,positive,neutral,neutral,positive,positive
535259759,"@adarob do you think we should just start switching to abseil logging?

The official [recommendation](https://github.com/tensorflow/community/blob/master/rfcs/20180827-api-names.md#deprecated-namespaces) seems to be to switch to the built-in Python logging, but I'm guess abseil will do a better job of more or less preserving API compatibility with the old tf.logging.",think start switching logging official recommendation switch python logging guess better job le compatibility old,issue,negative,positive,positive,positive,positive,positive
535157380,The new pip package (version 1.1.6) should have a fix for this problem.,new pip package version fix problem,issue,negative,positive,positive,positive,positive,positive
535083477,"Hi I have the same issue, did anyone solve this problem?

Is there anyway to explain what the exactly right MIDI structure manual to follow?",hi issue anyone solve problem anyway explain exactly right structure manual follow,issue,negative,positive,positive,positive,positive,positive
534199821,"@adarob I rebased #1570 to the current master, could you have a look now?",current master could look,issue,negative,neutral,neutral,neutral,neutral,neutral
534199242,"Rebased to master, now the tests are passing.

I tied the versions of the two libraries together, not sure if it's a good idea.",master passing tied two together sure good idea,issue,positive,positive,positive,positive,positive,positive
533981945,"> Thanks for the info. I've reproduced the problem locally and will look into it!

Do you have any clues?",thanks problem locally look,issue,negative,positive,neutral,neutral,positive,positive
532948118,"> Sorry you're having that error. Can you paste the full command line you're using and the full output of the command?
![1](https://user-images.githubusercontent.com/48265203/65210850-2d9f2280-dacf-11e9-8e62-ec4bcdf630ce.png)
![2](https://user-images.githubusercontent.com/48265203/65210851-3263d680-dacf-11e9-8538-1c37704a0c76.png)
![3](https://user-images.githubusercontent.com/48265203/65210854-355ec700-dacf-11e9-93f5-5bb1f32b533f.png)
![4](https://user-images.githubusercontent.com/48265203/65210857-37c12100-dacf-11e9-8f64-7040ea26fae5.png)
![5](https://user-images.githubusercontent.com/48265203/65210859-3b54a800-dacf-11e9-9959-c2f1514248d7.png)

",sorry error paste full command line full output command,issue,negative,positive,neutral,neutral,positive,positive
532588598,"@adarob Great!

There is already #1570, but it will probably need to be updated.

One more idea: According to [this](https://github.com/pypa/packaging.python.org/issues/295), it should be possible to have a namespace package inside a non-namespace package. So we could have a `magenta.lib` namespace package that `music` would get installed into, and keep the top-level `__init__.py`. Later some other independent or optional components of Magenta could also end up in `lib` (or whatever you would like to call it). So maybe that would be cleaner or easier to integrate in the internal codebase?",great already probably need one idea according possible package inside package could package music would get keep later independent optional magenta could also end whatever would like call maybe would cleaner easier integrate internal,issue,positive,positive,positive,positive,positive,positive
532403368,"@cifkao thanks again for your patience with us!

The challenging part is how we sync these changes up with our internal infrastructure, which isn't set up for these types of cases. 

We think the best approach is probably 2. Would you mind preparing a PR for that and we'll see if we can get it to be compatible with our internal codebase?",thanks patience u part sync internal infrastructure set think best approach probably would mind see get compatible internal,issue,positive,positive,positive,positive,positive,positive
531016874,"I think 1 or 2 would be best. @cghawthorne?

On Thu, Sep 12, 2019 at 5:51 AM Ondřej Cífka <notifications@github.com>
wrote:

> @adarob <https://github.com/adarob> @cghawthorne
> <https://github.com/cghawthorne> @iansimon <https://github.com/iansimon>
> I'm still happy to help resolving this. If there's still interest in that,
> can we take a moment to decide what to do?
>
> I think the options are:
>
>    - Moving music out of magenta under a different name (magenta_music,
>    magenta_lib.music?). The only downside I can think of is having to
>    change the name in existing code (but maybe there is some trick that would
>    allow to keep magenta.music as an alias to the new package?).
>    - Namespace package, but this means removing the __init__.py file (as
>    far as I can tell, there's no way around that).
>    - Creating a package out of the code in magenta.music while also
>    keeping the code inside magenta. Not a clean solution since it would
>    make the two packages incompatible (and someone could for example end up
>    with two different versions of the same code in their environment).
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1360?email_source=notifications&email_token=AAIJV2CL67HZMDUI2YRH3Y3QJI3OLA5CNFSM4GGGXB3KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6RYNMA#issuecomment-530810544>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAIJV2BTJP4JBYY45LKLNZDQJI3OLANCNFSM4GGGXB3A>
> .
>
",think would best wrote still happy help still interest take moment decide think moving music magenta different name downside think change name code maybe trick would allow keep alias new package package removing file far tell way around package code also keeping code inside magenta clean solution since would make two incompatible someone could example end two different code environment reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
530810544,"@adarob @cghawthorne @iansimon I'm still happy to help resolving this. If there's still interest in that, can we take a moment to decide what to do?

I think the options are:

1. Moving `music` out of `magenta` under a different name (`magenta_music`, `magenta_lib.music`?). The only downside I can think of is having to change the name in existing code (but maybe there is some trick that would allow to keep `magenta.music` as an alias to the new package?).
2. Namespace package, but this means removing the `__init__.py` file (as far as I can tell, there's no way around that).
3. Creating a package out of the code in `magenta.music` while also keeping the code inside `magenta`. Not a clean solution since it would make the two packages incompatible (and someone could for example end up with two different versions of the same code in their environment).",still happy help still interest take moment decide think moving music magenta different name downside think change name code maybe trick would allow keep alias new package package removing file far tell way around package code also keeping code inside magenta clean solution since would make two incompatible someone could example end two different code environment,issue,positive,positive,positive,positive,positive,positive
530388489,"Hey there, sorry for my late answer but we switched to another concept to convert our files. At first we convert the wavefiles to images of log magnitude and phase, after that we read it into our GAN. At the moment we have no new findings.
 
https://github.com/markus-weiss/AVGAN
https://github.com/markus-weiss/AVGAN/blob/master/AVGAN_Paper.pdf
https://colab.research.google.com/drive/1KSErEzANTaUr3Br7bAO848Pd4K-3oONA",hey sorry late answer switched another concept convert first convert log magnitude phase read gan moment new,issue,negative,negative,negative,negative,negative,negative
530167334,Can you include the full output of your pip install command? Does it make any difference if you include the -U (upgrade) flag?,include full output pip install command make difference include upgrade flag,issue,negative,positive,positive,positive,positive,positive
530012521,"Fixed. Apparently there were changes to the Group Settings for Google
Groups. I set ours be visible to the public and it works for me in
Incognito mode now.

On Tue, Sep 10, 2019 at 5:55 PM Adam Roberts <adarob@google.com> wrote:

> I also see this when I visit the group in incognito mode. It doesn't
> appear that I have admin privileges to try to correct it though. +Douglas
> Eck <deck@google.com> ?
>
> On Mon, Sep 9, 2019 at 11:43 PM dhanainme <notifications@github.com>
> wrote:
>
>> [image: Screen Shot 2019-09-09 at 11 42 05 PM]
>> <https://user-images.githubusercontent.com/1799618/64590072-88ac7900-d35b-11e9-9d94-04a7a34435ca.png>
>>
>> I have just been getting the error message as shown above when i visit
>> the URL.
>>
>> —
>> You are receiving this because you are subscribed to this thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tensorflow/magenta/issues/1585?email_source=notifications&email_token=AAIJV2COIB36AFFEVXB3JITQI46YXA5CNFSM4IURU6A2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6KARDQ#issuecomment-529795214>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AAIJV2A6S5J62BON4RC5V23QI46YXANCNFSM4IURU6AQ>
>> .
>>
>

-- 
deck@google.com | g.co/research/douglaseck | twitter.com/douglas_eck | +1
650-336-8433
",fixed apparently group set visible public work incognito mode tue wrote also see visit group incognito mode appear try correct though deck mon wrote image screen shot getting error message shown visit thread reply directly view mute thread deck,issue,negative,positive,neutral,neutral,positive,positive
530003103,"I also see this when I visit the group in incognito mode. It doesn't appear
that I have admin privileges to try to correct it though. +Douglas Eck
<deck@google.com> ?

On Mon, Sep 9, 2019 at 11:43 PM dhanainme <notifications@github.com> wrote:

> [image: Screen Shot 2019-09-09 at 11 42 05 PM]
> <https://user-images.githubusercontent.com/1799618/64590072-88ac7900-d35b-11e9-9d94-04a7a34435ca.png>
>
> I have just been getting the error message as shown above when i visit the
> URL.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1585?email_source=notifications&email_token=AAIJV2COIB36AFFEVXB3JITQI46YXA5CNFSM4IURU6A2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6KARDQ#issuecomment-529795214>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAIJV2A6S5J62BON4RC5V23QI46YXANCNFSM4IURU6AQ>
> .
>
",also see visit group incognito mode appear try correct though deck mon wrote image screen shot getting error message shown visit thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
529795214,"<img width=""973"" alt=""Screen Shot 2019-09-09 at 11 42 05 PM"" src=""https://user-images.githubusercontent.com/1799618/64590072-88ac7900-d35b-11e9-9d94-04a7a34435ca.png"">

I have just been getting the error message as shown above when i visit the URL.
",screen shot getting error message shown visit,issue,negative,neutral,neutral,neutral,neutral,neutral
529653450,Are you still having this problem? The group definitely exists and is in use.,still problem group definitely use,issue,negative,neutral,neutral,neutral,neutral,neutral
529214179,"I'd really appreciate any contribution, as I need this for a ml project for the end of the week",really appreciate contribution need project end week,issue,negative,positive,positive,positive,positive,positive
528441411,"Yes, that tool does use GrooVAE and the Groove dataset.",yes tool use groove,issue,negative,neutral,neutral,neutral,neutral,neutral
527191749,"Hi,

I tried to play with --input_binary=False/True but still get NANs as a model output. Any solution to this problem?

Many thanks",hi tried play still get model output solution problem many thanks,issue,positive,positive,positive,positive,positive,positive
522227608,"Thank you. I was referring to performance_sequence_generator and the colab-notebook. I wanted to set ""notes_per_second"" in generator_options and failed... it takes the value from control_signals, which I don't know how to adress",thank set value know,issue,positive,neutral,neutral,neutral,neutral,neutral
522088524,"First, make sure you're using the `density_conditioned_performance_with_dynamics` (or `multiconditioned_performance_with_dynamics`) config, and the corresponding checkpoint available [here](https://github.com/tensorflow/magenta/tree/master/magenta/models/performance_rnn#pre-trained).

Then, in the call to `performance_rnn_generate`, set the `--notes_per_second` flag to the desired note density.  It's quantized to powers of 2, so in essence only responds to doublings or halvings of note density.",first make sure corresponding available call set flag desired note density essence note density,issue,positive,positive,positive,positive,positive,positive
522084283,MusicVAE does preprocessing on the fly so you don't need a create_dataset script. Please see the instructions here: https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae#training-your-own-musicvae,fly need script please see,issue,negative,positive,positive,positive,positive,positive
520106882,Thanks Vincent. I've fixed the incorrect indent.,thanks vincent fixed incorrect indent,issue,negative,positive,positive,positive,positive,positive
517815026,So as of now I should use tf 1.X in order to import magenta?,use order import magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
517764451,We should also maybe look at switching to `import tensorflow.compat.v1 as tf` in most places until we actually switch to TF2.,also maybe look switching import actually switch,issue,negative,neutral,neutral,neutral,neutral,neutral
517762795,"Perhaps you have tf 2.0 installed? For future compatibility, we should switch to absl logging, but this should work with tf 1.x for now.",perhaps future compatibility switch logging work,issue,negative,neutral,neutral,neutral,neutral,neutral
516869589,"I tried the trick with `find_packages(exclude=['magenta.music', 'magenta.music.*'])` and symlinking `magenta/music`. It seems to work with `setup.py`, but it breaks installing `magenta.music` with `pip install .` (because it doesn't follow the symlink). In any case, I still think it's not possible to keep magenta's `__init__.py` for this to work.

The other (IMO cleaner) option is to make the package completely separate (e.g. `magenta_music`), as I suggested above.

What do you think? @adarob @cghawthorne",tried trick work pip install follow case still think possible keep magenta work cleaner option make package completely separate think,issue,negative,positive,neutral,neutral,positive,positive
515056604,"@cghawthorne I will try re installing properly, I will let you know. Thanks",try properly let know thanks,issue,negative,positive,neutral,neutral,positive,positive
514571912,"@cghawthorne 
> So, would it be possible to keep the existing directory structure, add `exclude=['magenta/music']` to the current setup.py, and then have a new setup.py in magenta/music for that package?

I doubt the `setup.py` can be *inside* the package it's supposed to install, usually it's one level above the top-level package (and it definitely needs to be run from there to find all the packages correctly). But maybe this could be done by adding a symlink to `music` instead of moving it.

> From reading the [native namespace package docs](https://packaging.python.org/guides/packaging-namespace-packages/#native-namespace-packages), it looks like the main reason `__init__.py` can't be in the main magenta directory is so that `find_packages` ignores it.

I think (one of) the reason(s) is that normally when you `import pkg.subpkg`, `pkg`'s `__init__.py` will run as well. In the namespace package case, you want to avoid this, because:

- You want `import pkg.subpkg` to behave consistently whether or not some other part of `pkg` is installed.
- You don't want to distribute two or more versions of the same `__init__.py` file.

The result is that a namespace package is really just a container for other packages rather than a full-fledged package. Anyway, I think that if you try to keep the current `__init__.py`, you might manage to make the setup work, but then the import mechanism will fail to recognize it as a namespace package and it won't work as expected.

Maybe all this just means that using a namespace package for this purpose is a bad idea, I don't know.",would possible keep directory structure add current new package doubt inside package supposed install usually one level package definitely need run find correctly maybe could done music instead moving reading native package like main reason ca main magenta directory think one reason normally import run well package case want avoid want import behave consistently whether part want distribute two file result package really container rather package anyway think try keep current might manage make setup work import mechanism fail recognize package wo work maybe package purpose bad idea know,issue,negative,negative,neutral,neutral,negative,negative
514478963,"For the record: This is the original image (Free for commercial use, No attribution required) used to generate the benchmark image.
https://pixabay.com/photos/men-women-apparel-couple-people-2425121/",record original image free commercial use attribution used generate image,issue,positive,positive,positive,positive,positive,positive
514417940,"Hi @cifkao. @adarob and I were wondering if there's some way to preserve the current directory structure. From reading the [native namespace package docs](https://packaging.python.org/guides/packaging-namespace-packages/#native-namespace-packages), it looks like the main reason `__init__.py` can't be in the main magenta directory is so that `find_packages` ignores it. However, you can pass an `exclude` list to `find_packages`. So, would it be possible to keep the existing directory structure, add `exclude=['magenta/music']` to the current setup.py, and then have a new setup.py in magenta/music for that package?

BTW, we'd be fine if the resulting packages only work with Python 3, since Python 2 support is going to end soon anyway.",hi wondering way preserve current directory structure reading native package like main reason ca main magenta directory however pas exclude list would possible keep directory structure add current new package fine resulting work python since python support going end soon anyway,issue,positive,positive,positive,positive,positive,positive
514331466,"Refer to [this issue](https://github.com/MaartenBaert/ssr/issues/246).
Make sure you run `sudo make install`
",refer issue make sure run make install,issue,negative,positive,positive,positive,positive,positive
513927533,"It looks like your Tensorflow installation is corrupt. I'd try uninstalling tensorflow, magenta, tensorflow-gpu, magenta-gpu, and then installing from scratch.",like installation corrupt try magenta scratch,issue,negative,negative,negative,negative,negative,negative
513908601,"Yes, we now fully support python 3. This PR is out of date, so I'll close it.",yes fully support python date close,issue,positive,neutral,neutral,neutral,neutral,neutral
513003801,"Thank you. 
My problem was very similar to yours and you were on point. 
I was able to fix it changing my data (MIDI) structure. 
Unfortunately the converter didn't provide any useful info without the new layer of debugging that you suggested.

",thank problem similar point able fix data structure unfortunately converter provide useful without new layer,issue,negative,positive,neutral,neutral,positive,positive
512688342,"I fixed this exact issue for the hierarchical VAE model's recently. In my case, it was caused by the training samples being rejected -- due to an issue with the way parts were being encoded in my output midi compared to what the TrioConverter was expecting . You've probably got a similar issue here. 

I recommend you add some logging in DrumConverter (it's in data.py, a subclass of BaseNoteSequenceConverter)'s _to_notesequences method, to the base class'  to_tensors method, and the get_dataset method here https://github.com/tensorflow/magenta/blob/b0c89b086c74248096c265541b6e84b2af61e9ff/magenta/models/music_vae/data.py#L1189

The last one is invoked during training, and uses the data converter from the config in its subs to transform note-sequences into the actual tensors that feed into the model. Your issue is most likely that due to some kind of malformed midi, the notesequence protos that are being created when you run the note-sequenced converter (the building your data set step in the docs) are not accepted by the DrumsConverter that your model invokes.",fixed exact issue hierarchical model recently case training due issue way output probably got similar issue recommend add logging subclass method base class method method last one training data converter transform actual feed model issue likely due kind malformed run converter building data set step accepted model,issue,positive,negative,neutral,neutral,negative,negative
512575816,"Thank you, I will try with your versions !

Le mer. 17 juil. 2019 à 12:53, Alexandre DuBreuil <notifications@github.com>
a écrit :

> @AlexandreJup <https://github.com/AlexandreJup> Yes magenta_gpu-1.1.2 and
> tensorflow_gpu-1.14.0. Check my previous comment for the specific
> versions you need.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/429?email_source=notifications&email_token=AI4ZPAGXE4Y4EKM7AQILD2LP74B25A5CNFSM4CYEF3JKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2D6BPY#issuecomment-512221375>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AI4ZPAFVDBUFCDTTF4445R3P74B25ANCNFSM4CYEF3JA>
> .
>
",thank try yes check previous comment specific need reply directly view mute thread,issue,positive,negative,neutral,neutral,negative,negative
512221375,@AlexandreJup Yes `magenta_gpu-1.1.2` and `tensorflow_gpu-1.14.0`. Check my previous comment for the specific versions you need.,yes check previous comment specific need,issue,negative,negative,neutral,neutral,negative,negative
511841581,"@dubreuia Awesome, I will have a look at it then. You confirm that you are running tensorflow-gpu? That was the reason of my question in the first place, I am trying to run tensorflow-gpu but was having issues.

",awesome look confirm running reason question first place trying run,issue,positive,positive,positive,positive,positive,positive
511751888,Isn't that fixed? It looks like it is working but I haven't tested all the models yet. See #429,fixed like working tested yet see,issue,negative,positive,neutral,neutral,positive,positive
511750751,"@AlexandreJup I'm using Magenta in Windows (with cmd, and PyCharm), no problem for now, so it seems the support for Python 3.x has been fixed. I haven't tested all the models and training for now, but it looks OK. I'll report back if I see anything that doesn't work.

Some things to know:

- You will need Python 3.5.x (I'm using 3.5.6), because `tensorflow-gpu` requires it (not sure if necessary if you only need `tensorflow`)
- You will need CUDA 10.0 (not 10.1), same reason
- I'm using CudRNN 7.6.1 (not sure if there is a specific version to have), same reason",magenta problem support python fixed tested training report back see anything work know need python sure necessary need need reason sure specific version reason,issue,positive,positive,positive,positive,positive,positive
510966033,could you rebase to master so we can pull in the fixes to travis and have the tests run?,could rebase master pull travis run,issue,negative,neutral,neutral,neutral,neutral,neutral
510568016,"Hello ! 
Any news on running magenta in windows? (not using bash on Windows)",hello news running magenta bash,issue,negative,neutral,neutral,neutral,neutral,neutral
510180008,"@adarob Probably there's a mismatch between the version python on CI and my local mac, which makes test to fail, python 3.5 vs python 3.7 and its safer to close the PR, and do not merge it at all.
Also, master is broken.",probably mismatch version python local mac test fail python python close merge also master broken,issue,negative,negative,negative,negative,negative,negative
509577044,"OK, should be straightforward.

What doesn't seem as straightforward is making the pip package. After reading [this](https://packaging.python.org/guides/packaging-namespace-packages/) and [this](http://peak.telecommunity.com/DevCenter/setuptools#namespace-packages), I think there are two options moving forward:

- Make `magenta` a namespace package and keep `magenta.music` inside.
- Rename `magenta.music` to `magenta_music` (i.e. a completely separate package).

In both cases, `music` needs to be moved out into its own directory so that it can have its own `setup.py`, but the first option will allow it to stay logically inside `magenta`. However, it also **requires removing the top-level `__init__.py`** (I think this is to avoid shipping the same file in two different distributions) and I don't know if it's OK to do that.",straightforward seem straightforward making pip package reading think two moving forward make magenta package keep inside rename completely separate package music need directory first option allow stay logically inside magenta however also removing think avoid shipping file two different know,issue,negative,positive,positive,positive,positive,positive
509425845,"Thanks for the PR! As a followup, would you mind moving performance_rnn_pipeline and pianoroll_rnn_nade_pipeline into magenta.piplines? That way we won't have inter-model dependencies. Sorry, missed this in the initial review.",thanks would mind moving way wo sorry initial review,issue,negative,negative,neutral,neutral,negative,negative
509407041,"Not sure if the pasted text is your exact command, but I think you need a $ in the flag: `--pipeline_options=$PIPELINE_OPTIONS`

From your pasted log, it looks like it's not finding your specified pipeline options and trying to use the DirectRunner on your local machine instead of the DataflowRunner.",sure pasted text exact command think need flag pasted log like finding pipeline trying use local machine instead,issue,positive,positive,positive,positive,positive,positive
509039831,"Also, if I close out the pop up windows the patch does nothing in the problem set. It doesn't matter what I choose, the pop up windows don't appear and Magenta appears to be completely unusable.",also close pop patch nothing problem set matter choose pop appear magenta completely unusable,issue,negative,positive,neutral,neutral,positive,positive
509039730,"I have the same issue. If I open a new set, I can generate through Magenta fine. But on the first set that I generated some melodic clips on, choose clip is not available. The Magenta logo will blink on and off at times as well.",issue open new set generate magenta fine first set melodic clip choose clip available magenta blink time well,issue,negative,positive,positive,positive,positive,positive
508089283,"> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).
> 
>  **Please visit https://cla.developers.google.com/ to sign.**
> 
> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.
> 
> #### What to do if you already signed the CLA
> ##### Individual signers
> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
> 
> ##### Corporate signers
> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
> 
>  **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmagenta%2Fpull%2F1556) for more info**.

I signed it!!",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account go,issue,positive,positive,neutral,neutral,positive,positive
507367129,"I haven't done much with GraphDef files, but the easiest way might be to just modify one of the train or inference scripts to call  [as_graph_def](https://www.tensorflow.org/guide/extend/model_files#graphdef) on the graph as soon as it's finished being created.",done much easiest way might modify one train inference call graph soon finished,issue,negative,positive,positive,positive,positive,positive
506981953,"hi, i'm trying to do the same thing, but can't figure out how to use @prakilambi's example 
because the script expects a .csv input whereas I have a folder full of .wav files that do not need labels.

I tried concatenating all of them with ffmpeg to use the small gist instead but I get an obvious overflow error ",hi trying thing ca figure use example script input whereas folder full need tried use small gist instead get obvious overflow error,issue,negative,positive,neutral,neutral,positive,positive
506248157,"How could I get the GraphDef about the model of onset&frames? And if freezing the model by coreml, is it proper for Android? Thank you very much!!!",could get model onset freezing model proper android thank much,issue,negative,positive,neutral,neutral,positive,positive
505195997,Yeah I used the same.  I eventually was able to get the checkpoints to work.,yeah used eventually able get work,issue,negative,positive,positive,positive,positive,positive
504702689,"After updating to a latest version of OSX (now on 10.12.6) I can install all packages correctly.
So now the installation seems to be successful but unfortunately when I try to run any instruction on the command line I get always an error like:
`[1]    41576 illegal hardware instruction  convert_dir_to_note_sequences   --recursive`

That means that my processor isn't compatible?
As far as I understand tensorflow is properly installed.

My processor is an Intel Xeon 3,33 GHz 6-Core Intel Xeon",latest version install correctly installation successful unfortunately try run instruction command line get always error like illegal hardware instruction recursive processor compatible far understand properly processor,issue,negative,positive,neutral,neutral,positive,positive
504598303,"I dunno, I maybe lean toward just moving the extract_* methods out of music. We don't really want to encourage more use of the pipelines code because all our new pipeline-style code is using Beam, which has its own ideas about metrics.",maybe lean toward moving music really want encourage use code new code beam metric,issue,positive,positive,positive,positive,positive,positive
503591318,The methods could accept a dict of callback functions that would get called in place of `.increment()`. Then the caller would create their own `Counter`s and `Histogram`s (only for the statistics they actually need) and pass their `increment` methods as the callbacks.,could accept would get place caller would create counter histogram statistic actually need pas increment,issue,positive,neutral,neutral,neutral,neutral,neutral
503356825,"That's one option, another is to have those methods return a dict of plain old integer counts instead of a statistics.Counter.  I don't have a strong opinion.",one option another return plain old integer instead strong opinion,issue,positive,positive,positive,positive,positive,positive
503353858,"@iansimon what do you think about the `pipelines.statistics` dependencies (e.g., in `drums_lib.py`)? I'm thinking we can maybe just move the extract_* methods that have that dependency to the relevant files in the pipelines directory.",think thinking maybe move dependency relevant directory,issue,negative,positive,positive,positive,positive,positive
503254835,"First, check out the demo for generating audio in case you haven't already, it has examples: https://colab.sandbox.google.com/notebooks/magenta/gansynth/gansynth_demo.ipynb

More specifically, `data_helper.data_to_waves()` is what you want https://github.com/tensorflow/magenta/blob/master/magenta/models/gansynth/lib/model.py#L381",first check generating audio case already specifically want,issue,negative,positive,positive,positive,positive,positive
503152854,"Hi @Ddedalous, the training instructions is contained in the README in the directory of each model. Agreed it's not as simple as running directly on Colab. I'll reopen this Issue but I doubt any of us on the Google side will be able to get to this anytime soon. Please feel free to contribute a Colab yourself -- it shouldn't be too much work to call the same functions that are in our training script from Colab.",hi training directory model agreed simple running directly reopen issue doubt u side able get soon please feel free contribute much work call training script,issue,positive,positive,positive,positive,positive,positive
502810649,"I've managed to get the same problem both with the Anaconda and manual installation instructions (for python 2.7 and 3.7) and narrow the problem a bit.

Solved the issue with CONDA_PREFIX adding the correct path into bash:
`export PATH=~/anaconda2/bin:$PATH`
and
`export PATH=~/anaconda3/bin:$PATH`
and now using Anaconda for python 2.7 or 3.7 properly but I get the same error:
```
ERROR: Could not find a version that satisfies the requirement tensorflow>=1.13.0 (from magenta) (from versions: none)
ERROR: No matching distribution found for tensorflow>=1.13.0 (from magenta)
```
I dump here the output of the console I'm receiving:
```
Mac OS Detected

=========================================
anaconda detected, skipping conda install
=========================================


==============================
setting up magenta environment
==============================

WARNING: A conda environment already exists at '/Users/adriagil/anaconda3/envs/magenta'
Remove existing environment (y/[n])? y

Collecting package metadata: done
Solving environment: done

## Package Plan ##

  environment location: /Users/adriagil/anaconda3/envs/magenta

  added / updated specs:
    - python=2.7


The following NEW packages will be INSTALLED:

  certifi            pkgs/main/osx-64::certifi-2019.3.9-py27_0
  libcxx             pkgs/main/osx-64::libcxx-4.0.1-hcfea43d_1
  libcxxabi          pkgs/main/osx-64::libcxxabi-4.0.1-hcfea43d_1
  libedit            pkgs/main/osx-64::libedit-3.1.20181209-hb402a30_0
  libffi             pkgs/main/osx-64::libffi-3.2.1-h475c297_4
  ncurses            pkgs/main/osx-64::ncurses-6.1-h0a44026_1
  pip                pkgs/main/osx-64::pip-19.1.1-py27_0
  python             pkgs/main/osx-64::python-2.7.16-h97142e2_0
  readline           pkgs/main/osx-64::readline-7.0-h1de35cc_5
  setuptools         pkgs/main/osx-64::setuptools-41.0.1-py27_0
  sqlite             pkgs/main/osx-64::sqlite-3.28.0-ha441bb4_0
  tk                 pkgs/main/osx-64::tk-8.6.8-ha441bb4_0
  wheel              pkgs/main/osx-64::wheel-0.33.4-py27_0
  zlib               pkgs/main/osx-64::zlib-1.2.11-h1de35cc_3


Proceed ([y]/n)? y

Preparing transaction: done
Verifying transaction: done
Executing transaction: done
#
# To activate this environment, use:
# > conda activate magenta
#
# To deactivate an active environment, use:
# > conda deactivate
#

DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.
Collecting jupyter
  Using cached https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl
Collecting magenta
  Using cached https://files.pythonhosted.org/packages/57/d4/b19aa8215b7c837c454ee74fc013bb46375893002335c1280a3ed9d5f8ef/magenta-1.1.2-py2.py3-none-any.whl
Collecting jupyter-console (from jupyter)
  Using cached https://files.pythonhosted.org/packages/77/82/6469cd7fccf7958cbe5dce2e623f1e3c5e27f1bb1ad36d90519bc2d5d370/jupyter_console-5.2.0-py2.py3-none-any.whl
Collecting qtconsole (from jupyter)
  Using cached https://files.pythonhosted.org/packages/79/0b/efb5a694b6922bb85c35e4f1db6197daae23c764dd384023fc9517d79e26/qtconsole-4.5.1-py2.py3-none-any.whl
Collecting ipykernel (from jupyter)
  Using cached https://files.pythonhosted.org/packages/00/47/764e4fa1b1b89598426b8d79b1c4fbe8042432621b0f8e1991aeb3c24806/ipykernel-4.10.0-py2-none-any.whl
Collecting notebook (from jupyter)
  Using cached https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl
Collecting ipywidgets (from jupyter)
  Using cached https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl
Collecting nbconvert (from jupyter)
  Using cached https://files.pythonhosted.org/packages/35/e7/f46c9d65f149271e47fca6ab084ef5c6e4cb1870f4c5cce6690feac55231/nbconvert-5.5.0-py2.py3-none-any.whl
Collecting pandas>=0.18.1 (from magenta)
  Using cached https://files.pythonhosted.org/packages/52/ff/912fe03a623a70bcf297d466013a0b4f4c68c3b60f86bf226682d061fc09/pandas-0.24.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Requirement already satisfied: wheel in ./anaconda3/envs/magenta/lib/python2.7/site-packages (from magenta) (0.33.4)
Collecting numpy>=1.14.6 (from magenta)
  Using cached https://files.pythonhosted.org/packages/8f/0b/1a2c21bb69138337dc079841aa4a45e5b2fc7a4260c0907f5254fb08f02e/numpy-1.16.4-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Collecting python-rtmidi<1.2,>=1.1 (from magenta)
  Using cached https://files.pythonhosted.org/packages/3b/97/960d5df865460327c756a723952e4cb004a50cb2ebc9abedfc3ac0ca150a/python_rtmidi-1.1.2-cp27-cp27m-macosx_10_6_intel.whl
Collecting intervaltree>=2.1.0 (from magenta)
  Using cached https://files.pythonhosted.org/packages/e8/f9/76237755b2020cd74549e98667210b2dd54d3fb17c6f4a62631e61d31225/intervaltree-3.0.2.tar.gz
Collecting tensorflow>=1.13.0 (from magenta)
  ERROR: Could not find a version that satisfies the requirement tensorflow>=1.13.0 (from magenta) (from versions: none)
ERROR: No matching distribution found for tensorflow>=1.13.0 (from magenta)
```",get problem anaconda manual installation python narrow problem bit issue correct path bash export path export path anaconda python properly get error error could find version requirement magenta none error matching distribution found magenta dump output console mac o anaconda skipping install setting magenta environment warning environment already remove environment package done environment done package plan environment location added spec following new pip python wheel proceed transaction done transaction done transaction done activate environment use activate magenta deactivate active environment use deactivate deprecation python reach end life st please upgrade python python wo date future version pip drop support python magenta notebook magenta requirement already satisfied wheel magenta magenta magenta magenta magenta error could find version requirement magenta none error matching distribution found magenta,issue,negative,positive,neutral,neutral,positive,positive
502798146,"> giving executable permission to all conda variables

How to do that exactly?
I'm not a master in Python so any help would be appreciated.
I have the same problem when trying to install Magenta on my computer.

> For cases where the auto-install script fails, you can also try the manual installation instructions. Please reopen the bug if either of these solutions don't fix the issue.

I'm trying also to do it manually but still getting some errors so I can't install Magenta at all.
I've already opened a but here https://github.com/tensorflow/magenta/issues/1546",giving executable permission exactly master python help would problem trying install magenta computer script also try manual installation please reopen bug either fix issue trying also manually still getting ca install magenta already,issue,positive,positive,positive,positive,positive,positive
502564192,Hi @100376348 I didn't find any solution. I've implemented the GMM in the sketch rnn way.,hi find solution sketch way,issue,negative,neutral,neutral,neutral,neutral,neutral
502478274,"I am having exactly the same problem. It seems a bug to me in the MultivariateNormalFullCovariance code. I am trying to generate random covariance matrix (positive-definite and all the stuff), but I always end up with that exception. @EmanueleGhelfi did you find any solution?",exactly problem bug code trying generate random covariance matrix stuff always end exception find solution,issue,negative,negative,negative,negative,negative,negative
501422197,"Sorry there's no public data ingestion pipeline, we used the tfrecords from the nsynth dataset. Here's a [gist](https://gist.github.com/jesseengel/dedb8bc19212d4b982fb51f879728a0d) that should convert a single wav file to a tfrecord. With the previous link you should be able to make a record out of a whole lot of them.",sorry public data ingestion pipeline used gist convert single file previous link able make record whole lot,issue,negative,negative,neutral,neutral,negative,negative
501048393,"Hey I tried to use my own checkpoints after training the model using my midi files to generate samples, but I get the below error.

**NotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint.** 

I believe @jincong0623 mentioned the issue in the #1253 issue. Was this resolved? I tried to reference MusicVae colab notebook for assistance but I still couldn't get it to work.",hey tried use training model generate get error see likely due variable name graph key missing please ensure graph based believe issue issue resolved tried reference notebook assistance still could get work,issue,negative,negative,neutral,neutral,negative,negative
500673822,"Sorry, but we are both currently out of the office. We'll get back to you
as soon as we can!

On Fri, Jun 7, 2019 at 2:38 AM Ondřej Cífka <notifications@github.com>
wrote:

> @adarob <https://github.com/adarob> @cghawthorne
> <https://github.com/cghawthorne> Any thoughts?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1360?email_source=notifications&email_token=AAIJV2G3B2IGEKSDXIVO3QTPZIUCVA5CNFSM4GGGXB3KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXFLDJA#issuecomment-499823012>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAIJV2CPDYBBTLXBVEZZSU3PZIUCVANCNFSM4GGGXB3A>
> .
>
",sorry currently office get back soon wrote reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
500671919,"check out https://github.com/IBM/tensorflow-hangul-recognition/blob/master/tools/convert-to-tfrecords.py
It converts image to tfrecord but can be implemented for wav files by changing the example format to store wav data instead of raw image data.",check image example format store data instead raw image data,issue,negative,negative,negative,negative,negative,negative
500176752,"I gave up on trying to harmonize a midi file. I looked at `coconet_sample.py` and the entire `HarmonizeMidiMelodyStrategy` class is by itself. With no other attachment of this class to the Generator class or the main class, I don't have any idea on how to make this work.",gave trying harmonize file entire class attachment class generator class main class idea make work,issue,positive,positive,neutral,neutral,positive,positive
499599008,I think we just need to use a six wrapper on one of those calls for py3 compatibility. I'll take a look.,think need use six wrapper one compatibility take look,issue,negative,neutral,neutral,neutral,neutral,neutral
499166124,"Hi @AragakiSaro, we no longer user Bazel for the main Magenta repo. Could you please sync your git client and follow the new installation instructions in our [README](/tensorflow/magenta)?",hi longer user main magenta could please sync git client follow new installation,issue,negative,positive,positive,positive,positive,positive
497930525,"I guess the TF dependencies can stay for now and potentially be removed later after the pip package is done?

As for the `pipelines.statistics` dependency, I can't think of any solution other than also making it a separate package (which does make some sense, since it already seems to be independent, and not tied to pipelines or anything else in Magenta in any way).",guess stay potentially removed later pip package done dependency ca think solution also making separate package make sense since already independent tied anything else magenta way,issue,negative,neutral,neutral,neutral,neutral,neutral
497812432,"I think there might still be some tensorflow dependencies to trim too?

Once those are done, I think we can just add a new setup.py in the music subdir and modify our root setup.py to exclude the music subdir.",think might still trim done think add new music modify root exclude music,issue,negative,positive,positive,positive,positive,positive
497779967,I believe the next step is to make a pip package. @cghawthorne thoughts on how to best do this?,believe next step make pip package best,issue,positive,positive,positive,positive,positive,positive
496731476,"(base) ales-MacBook-Pro:Desktop ale$ sudo music_vae_generate --config=cat-mel_2bar_big --checkpoint_file=midis\train\model.ckpt-64 --mode=sample --num_outputs=5 --output_dir=\midis

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Loading model...
I0528 20:49:27.721372 4764403136 music_vae_generate.py:148] Loading model...
INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:
{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 5, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}
I0528 20:49:27.722443 4764403136 base_model.py:158] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:
{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 5, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
W0528 20:49:27.724976 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
INFO:tensorflow:
Encoder Cells (bidirectional):
  units: [2048]

I0528 20:49:27.726181 4764403136 lstm_models.py:102] 
Encoder Cells (bidirectional):
  units: [2048]

WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:44: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
W0528 20:49:27.728190 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:44: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
INFO:tensorflow:
Decoder Cells:
  units: [2048, 2048, 2048]

I0528 20:49:27.730249 4764403136 lstm_models.py:293] 
Decoder Cells:
  units: [2048, 2048, 2048]

WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.
W0528 20:49:27.730343 4764403136 lstm_utils.py:201] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:207: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
W0528 20:49:27.730480 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:207: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:161: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0528 20:49:27.763297 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:161: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/onehot_categorical.py:172: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.random.categorical instead.
W0528 20:49:27.893079 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/onehot_categorical.py:172: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.random.categorical instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
W0528 20:49:27.945821 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
W0528 20:49:27.946217 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
W0528 20:49:27.950181 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-05-28 20:49:28.262788: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0528 20:49:28.283599 4764403136 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/bin/music_vae_generate"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 191, in console_entry_point
    tf.app.run(main)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 187, in main
    run(configs.CONFIG_MAP)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 156, in run
    checkpoint_dir_or_path=checkpoint_dir_or_path)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/trained_model.py"", line 137, in __init__
    saver.restore(self._sess, checkpoint_path)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 1268, in restore
    + compat.as_text(save_path))
ValueError: The passed save_path is not a valid checkpoint: midistrainmodel.ckpt-64
",base ale warning module included information please see depend functionality listed please file issue loading model loading model building model true false false false building model true false false false warning removed future version handled automatically placer removed future version handled automatically placer bidirectional bidirectional warning removed future version class equivalent removed future version class equivalent warning setting sampling schedule constant setting sampling schedule constant warning removed future version use instead removed future version use instead warning dense removed future version use instead dense removed future version use instead warning multinomial removed future version use instead multinomial removed future version use instead warning removed future version please use cell equivalent removed future version please use cell equivalent warning removed future version please use cell equivalent removed future version please use cell equivalent warning removed future version use instead removed future version use instead binary use warning removed future version use standard file check prefix removed future version use standard file check prefix recent call last file line module file line main file line run main file line main run file line run file line file line restore valid,issue,negative,negative,neutral,neutral,negative,negative
496727719,"assuming `ls /midis/train/model.ckpt-64*` returns the 3 checkpoint files, you should be doing `--checkpoint_file=/midis/train/model.ckpt-64`. You should alternatively be able to just set `--run_dir` to the same value you used during training.",assuming alternatively able set value used training,issue,negative,positive,positive,positive,positive,positive
496691398,is that path correct? your slashes may be backwards,path correct may backwards,issue,negative,neutral,neutral,neutral,neutral,neutral
496688912,"(base) ales-MacBook-Pro:Desktop ale$ sudo music_vae_generate --config=cat-mel_2bar_big --checkpoint_file=\midis\train\model.ckpt-60 --mode=sample --num_outputs=5 --output_dir=/midis
Password:

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Loading model...
I0528 18:02:02.791929 4687758784 music_vae_generate.py:148] Loading model...
INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:
{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 5, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}
I0528 18:02:02.793022 4687758784 base_model.py:158] Building MusicVAE model with BidirectionalLstmEncoder, CategoricalLstmDecoder, and hparams:
{'max_seq_len': 32, 'z_size': 512, 'free_bits': 0, 'max_beta': 0.5, 'beta_rate': 0.99999, 'batch_size': 5, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'inverse_sigmoid', 'sampling_rate': 1000, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
W0528 18:02:02.795577 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
INFO:tensorflow:
Encoder Cells (bidirectional):
  units: [2048]

I0528 18:02:02.796799 4687758784 lstm_models.py:102] 
Encoder Cells (bidirectional):
  units: [2048]

WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:44: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
W0528 18:02:02.798850 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:44: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
INFO:tensorflow:
Decoder Cells:
  units: [2048, 2048, 2048]

I0528 18:02:02.800942 4687758784 lstm_models.py:293] 
Decoder Cells:
  units: [2048, 2048, 2048]

WARNING:tensorflow:Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.
W0528 18:02:02.801048 4687758784 lstm_utils.py:201] Setting non-training sampling schedule from inverse_sigmoid:1000.000000 to constant:1.0.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:207: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
W0528 18:02:02.801175 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:207: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:161: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
W0528 18:02:02.834918 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/lstm_utils.py:161: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/onehot_categorical.py:172: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.random.categorical instead.
W0528 18:02:02.965142 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/onehot_categorical.py:172: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.random.categorical instead.
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
W0528 18:02:03.019156 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/contrib/rnn/python/ops/rnn.py:233: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
W0528 18:02:03.019530 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
W0528 18:02:03.023546 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-05-28 18:02:03.337240: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0528 18:02:03.357867 4687758784 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/bin/music_vae_generate"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 191, in console_entry_point
    tf.app.run(main)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 187, in main
    run(configs.CONFIG_MAP)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/music_vae_generate.py"", line 156, in run
    checkpoint_dir_or_path=checkpoint_dir_or_path)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/magenta/models/music_vae/trained_model.py"", line 137, in __init__
    saver.restore(self._sess, checkpoint_path)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py"", line 1268, in restore
    + compat.as_text(save_path))
ValueError: The passed save_path is not a valid checkpoint: midistrainmodel.ckpt-60",base ale password warning module included information please see depend functionality listed please file issue loading model loading model building model true false false false building model true false false false warning removed future version handled automatically placer removed future version handled automatically placer bidirectional bidirectional warning removed future version class equivalent removed future version class equivalent warning setting sampling schedule constant setting sampling schedule constant warning removed future version use instead removed future version use instead warning dense removed future version use instead dense removed future version use instead warning multinomial removed future version use instead multinomial removed future version use instead warning removed future version please use cell equivalent removed future version please use cell equivalent warning removed future version please use cell equivalent removed future version please use cell equivalent warning removed future version use instead removed future version use instead binary use warning removed future version use standard file check prefix removed future version use standard file check prefix recent call last file line module file line main file line run main file line main run file line run file line file line restore valid,issue,negative,negative,neutral,neutral,negative,negative
496682302,"You do not need to tar them. You can just point to the path of the checkpoint without the suffix (e.g., model.ckpt-1683).",need tar point path without suffix,issue,negative,neutral,neutral,neutral,neutral,neutral
496681128,How did you solve this? I dont even know how to .tar without tar.gz those files?,solve dont even know without,issue,negative,neutral,neutral,neutral,neutral,neutral
496638406,"Nevermind, 'pip3 install magenta' instead of 'pip install magenta' solved it.",install magenta instead install magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
496384626,"Hi,

In our experience the training is quite stable (both for progressive GAN
and not progressive), but must be trained for the full number of
iterations. Early in training, the GAN has only learned a few modes (which
can look like mode collapse), but by the end of training there is a lot
more diversity.

Best,
Jesse

On Fri, May 17, 2019 at 12:25 PM Wokerker <notifications@github.com> wrote:

> Hi, there is one additional question about GANsynth training here.
> Did the author meet the mode collapse scenario during the training?
> It seems that sometimes the model training process is not stable, although
> the loss is using WGAN-GP.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1524?email_source=notifications&email_token=AANFCCMSSTPWUSKJ3W6ABM3PV4BDRA5CNFSM4HLMU6YKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVVUY3I#issuecomment-493571181>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AANFCCPUO6JDSU7PCRE4UG3PV4BDRANCNFSM4HLMU6YA>
> .
>
",hi experience training quite stable progressive gan progressive must trained full number early training gan learned look like mode collapse end training lot diversity best may wrote hi one additional question training author meet mode collapse scenario training sometimes model training process stable although loss reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
495723313,"So there's good news and bad news.

:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.

:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.

*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*

ℹ️ **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmagenta%2Fpull%2F1431) for more info**.

<!-- need_author_consent -->",good news bad news good news everyone need sign pull request submitter commit done everything good confused bad news one someone pull request submitter need confirm project please confirm pull request note project maintainer terminal state meaning commit status change state confirm consent commit author set label yes project merge pull request appropriate information go,issue,positive,positive,positive,positive,positive,positive
495593033,I've tried adding a small (from 1e-5 to 1e-3) to the diagonal. However this does not solve the issue. Thanks @JonasRSV .,tried small diagonal however solve issue thanks,issue,positive,negative,neutral,neutral,negative,negative
495458020,"I'm as well having issue with running a basic example in Docker:
`

    root@42115fd0c838:/magenta# melody_rnn_generate   --config=basic_rnn   --bundle_file=/magenta-models/basic_rnn.mag   --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=10   --num_steps=128   --primer_melody=""[60]""  
    Illegal instruction (core dumped)  
      
    root@42115fd0c838:/magenta# melody_rnn_generate   --config=attention_rnn   --bundle_file=/magenta-models/attention_rnn.mag   --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=10   --num_steps=128   --primer_melody=""[60]""  
    Illegal instruction (core dumped)  
      
    root@42115fd0c838:/magenta# melody_rnn_generate   --config=attention_rnn   --bundle_file=/magenta-models/attention_rnn.mag   --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=1   --num_steps=128   --primer_melody=""[60]""  
    Illegal instruction (core dumped)  
      
    root@42115fd0c838:/magenta# melody_rnn_generate   --config=rl_rnn   --bundle_file=/magenta-models/rl_rnn.mag   --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=1   --num_steps=128   --primer_melody=""[60]""  
    Illegal instruction (core dumped)  
      
    root@42115fd0c838:/magenta# melody_rnn_generate --config=lookback_rnn --bundle_file=/magenta-models/lookback_rnn.mag   --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=10   --num_steps=128   --primer_melody=""[60]""
    Illegal instruction (core dumped)

    root@42115fd0c838:/magenta# drums_rnn_generate --config=drum_kit_rnn --bundle_file=/magenta-models/drum_kit_rnn.mag  --output_dir=/magenta-data/lookback_rnn/generated   --num_outputs=1   --num_steps=128   --primer_melody=""[60]""  
    Illegal instruction (core dumped) `",well issue running basic example docker root illegal instruction core root illegal instruction core root illegal instruction core root illegal instruction core root illegal instruction core root illegal instruction core,issue,negative,negative,negative,negative,negative,negative
494487141,"You'll want to train with a new configuration where hop_size_bars (and potentially chunk_size_bars) is larger than 1.  Probably the most straightforward change would be to change hop_size_bars and chunk_size_bars to e.g. 4, and maybe increase max_events_per_instrument by a factor of 2 or 4 as it's per-chunk.

To explain a bit more, the model uses a 3-level hierarchy.  The top level is a sequence of _chunks_.  Each chunk has multiple _tracks_.  And each track has multiple _events_.

The configuration in the Colab uses one single-bar chunk.  I never really tried using chunks longer than a bar, but probably 2 or 4 bars could work.  I did try using multiple single-bar chunks, and there even 4 bars barely worked.",want train new configuration potentially probably straightforward change would change maybe increase factor explain bit model hierarchy top level sequence chunk multiple track multiple configuration one chunk never really tried longer bar probably could work try multiple even barely worked,issue,positive,positive,positive,positive,positive,positive
494482239,"The checkpoint does have Adam-related weights in it, but it looks like they're ""Adam"" with an uppercase A instead of lowercase.  Did something change in the names expected by Tensorflow?",like instead something change,issue,negative,neutral,neutral,neutral,neutral,neutral
494473156,I'm not sure why the Travis CI tests aren't running. Can you maybe try rebasing your PR against HEAD and see if that triggers it?,sure travis running maybe try head see,issue,negative,positive,positive,positive,positive,positive
494454222,"FYI @iansimon 

The multitrack models output an end token to specify when the sequence should end so the best way to extend the sequences is to retrain the model with longer inputs. You could also modify the config to remove the end sequence token and it may allow it to continue past that point, although I suspect the model will not perform well past the end token.",output end token specify sequence end best way extend retrain model longer could also modify remove end sequence token may allow continue past point although suspect model perform well past end token,issue,positive,positive,positive,positive,positive,positive
494400637,I think it's fine to leave them where they are for now.  @cghawthorne what do you think?,think fine leave think,issue,negative,positive,positive,positive,positive,positive
494268366,Are you thinking that these should be moved out of `music` as part of this pull request?,thinking music part pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
494074095,There is also MusicVAE which supports Trio models with multiple instruments as well as the Multi-Track model.,also trio multiple well model,issue,negative,neutral,neutral,neutral,neutral,neutral
493634824,I think that's due to an incompatibility with how some of our internal code returns results. I'll see if there's a good way to unify the two so it works without that change. Thanks for the report!,think due incompatibility internal code see good way unify two work without change thanks report,issue,negative,positive,positive,positive,positive,positive
493592344,Thanks for pointing this out. You can just change groove_4bar.tar to groovae_4bar.tar and the link should work. I'll fix the README shortly.,thanks pointing change link work fix shortly,issue,negative,positive,neutral,neutral,positive,positive
493571181,"Hi, there is one additional question about GANsynth training here.
Did the author meet the mode collapse scenario during the training?
It seems that sometimes the model training process is not stable, although the loss is using WGAN-GP.",hi one additional question training author meet mode collapse scenario training sometimes model training process stable although loss,issue,negative,neutral,neutral,neutral,neutral,neutral
493406740,"Probably, I found the answer for this question. The problem is the in the class TestData(Dataset) in lib_data.py. The reason of the error that in this class the max_pitch = 127 and in fact in TestData.npz is 46. Therefor to solve this error we need to switch to some another dataset or make another class.",probably found answer question problem class reason error class fact therefor solve error need switch another make another class,issue,negative,neutral,neutral,neutral,neutral,neutral
493360401,"(Not author or anything) Have you checked that the covariance-matrix you created is positive-definite?

Maybe there is some numerical error -- try adding a small number along the diagonal? :) ",author anything checked maybe numerical error try small number along diagonal,issue,negative,negative,negative,negative,negative,negative
492876861,"That fixed it. I ran into another issue at infer.py, line 189: sequences_lib.pianoroll_to_note_sequence expects frame_predictions to be a list of arrays, but the current input is simply an array. I addressed this problem by removing the final zero index in lines 177-181:

```
        frame_probs = prediction_list[0]['frame_probs']
        frame_predictions = prediction_list[0]['frame_predictions']
        onset_predictions = prediction_list[0]['onset_predictions']
        velocity_values = prediction_list[0]['velocity_values']
        offset_predictions = prediction_list[0]['offset_predictions']
```

You'd know better than me whether that's the right fix, but after changing that I got transcription results out that seem reasonable.

Thanks!",fixed ran another issue line list current input simply array problem removing final zero index know better whether right fix got transcription seem reasonable thanks,issue,negative,positive,positive,positive,positive,positive
492860689,"I think this might be a bug introduced by our recent preprocessing code changes. Can you try running the script with `--preprocess_examples=True`? If you can confirm that fixes it, I'll send a PR to make that the default.

@asleep FYI",think might bug recent code try running script confirm send make default asleep,issue,negative,neutral,neutral,neutral,neutral,neutral
492447439,"Agree that the encoder_decoder-named files should not go into magenta music, at least for now.  Later on if some of it is really fundamental it can be moved back.",agree go magenta music least later really fundamental back,issue,negative,negative,neutral,neutral,negative,negative
492438937,"Overall, I think this looks good. One thought I had is that I'm wondering whether or not the encoder/decoder stuff should eventually end up in our separate magenta.music library. It's pretty specific to our *_rnn models, and I think it might make more sense to just move those files to models/shared.

@iansimon what do you think?",overall think good one thought wondering whether stuff eventually end separate library pretty specific think might make sense move think,issue,positive,positive,positive,positive,positive,positive
492069940,"Also, fwiw, I followed np.unwrap closely when writing the tensorflow
version.

*From: *Chris Donahue <notifications@github.com>
*Date: *Mon, May 13, 2019 at 8:46 PM
*To: *tensorflow/magenta
*Cc: *Jesse Engel, Mention

Ah right. It depends on what you set as the maximum discontinuity values
> for np.unwrap. But with the default configuration of np.pi (which we also
> use), you are correct that the range should be [-pi, pi]. If you use a
> larger discontinuity > np.pi, the range will increase accordingly.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1524?email_source=notifications&email_token=AANFCCPUX6HDQPSUYZKB7EDPVIYZ3A5CNFSM4HLMU6YKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVKFX5Q#issuecomment-492067830>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AANFCCIJULXZQNZ4V7ELMJDPVIYZ3ANCNFSM4HLMU6YA>
> .
>
",also closely writing version date mon may mention ah right set maximum discontinuity default configuration also use correct range pi use discontinuity range increase accordingly reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
492067830,"Ah right. It depends on what you set as the maximum discontinuity values for `np.unwrap`. But with the default configuration of `np.pi` (which we also use), you are correct that the range should be [-pi, pi]. If you use a larger discontinuity `> np.pi`, the range will increase accordingly.",ah right set maximum discontinuity default configuration also use correct range pi use discontinuity range increase accordingly,issue,negative,positive,positive,positive,positive,positive
492065046,"> the finite differences across the time axis of the unwrapped phase spectra. The range of IF values is thus [-2pi, 2pi]

I think it could depend on how phase unwrapping was implemented. Was testing with numpy's unwrap function, and the finite difference is precisely in a range of `[-pi, pi]`.

I'll keep it open for some while (i.e. forever) since there's still little ambiguity, although most of my questions were answered :) ",finite across time axis unwrapped phase spectrum range thus pi think could depend phase unwrapping testing unwrap function finite difference precisely range pi keep open forever since still little ambiguity although,issue,negative,positive,neutral,neutral,positive,positive
492051303,"@iansimon Thank you for the response! 

When I've installed llvm 3.x than I've got an error that llvmlite requires llvm 7. And I can't find llvm 7 package for ARMv7l.",thank response got error ca find package,issue,negative,neutral,neutral,neutral,neutral,neutral
492017931,"For cases where the auto-install script fails, you can also try the manual installation instructions. Please reopen the bug if either of these solutions don't fix the issue.",script also try manual installation please reopen bug either fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
492017261,Please reopen if problems persist after verifying installation.,please reopen persist installation,issue,negative,neutral,neutral,neutral,neutral,neutral
491996364,"Sorry about that. Only the first point of my issue was valid; I wrongly assumed by reading the sources, that only strings are ever passed as port parameters, which wasn't the case in the tests.",sorry first point issue valid wrongly assumed reading ever port case,issue,negative,negative,negative,negative,negative,negative
491952490,"It looks like this is failing on Travis: https://travis-ci.org/tensorflow/magenta/builds/531936954

 @SamMichalik can you take a look?",like failing travis take look,issue,negative,neutral,neutral,neutral,neutral,neutral
491943538,"It was painful, and I think I only got it working for Python 2.  I had to install a bunch of dependencies manually.",painful think got working python install bunch manually,issue,negative,negative,negative,negative,negative,negative
491942633,@iansimon I think you figured out how to do this at one point?,think figured one point,issue,negative,neutral,neutral,neutral,neutral,neutral
491880989,"Please do open a PR. Thanks!

*From: *Samuel Michalik <notifications@github.com>
*Date: *Mon, May 13, 2019, 6:38 AM
*To: *tensorflow/magenta
*Cc: *Subscribed

I think I may have solved it. In MidiHub's constructor the
> _timestamp_and_handle_message callback is attached to inport, however
> inport is only a local variable and is never assigned anywhere, so the
> port instance gets garbage collected later on, while the interaction is
> still active.
>
> Starting on line 904 in midi_hub.py :
>
>     if input_midi_ports:
>       for port in input_midi_ports:
>         if isinstance(port, mido.ports.BaseInput):
>           inport = port
>         else:
>           virtual = port not in get_available_input_ports()
>           if virtual:
>             tf.logging.info(
>                 ""Opening '%s' as a virtual MIDI port for input."", port)
>           inport = mido.open_input(port, virtual=virtual)
>         # Start processing incoming messages.
>         inport.callback = self._timestamp_and_handle_message
>
> Additionally, input_midi_ports elements are strings, so the isinstance
> test always fails and all ports are in effect virtual.
>
> If you want, I can open a pull request to fix this.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1527?email_source=notifications&email_token=AAIJV2DDLVF2BJM4E6P32P3PVFVMLA5CNFSM4HMJBER2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVIKVPI#issuecomment-491825853>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAIJV2GLNZHJXRRPPSLXFOTPVFVMLANCNFSM4HMJBERQ>
> .
>
",please open thanks date mon may think may constructor attached inport however inport local variable never assigned anywhere port instance garbage collected later interaction still active starting line port port inport port else virtual port virtual opening virtual port input port inport port start incoming additionally test always effect virtual want open pull request fix thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
491825853,"I think I may have solved it. In MidiHub's constructor the `_timestamp_and_handle_message` callback is attached to `inport`, however `inport` is only a local variable and is never assigned anywhere, so the port instance gets garbage collected later on, while the interaction is still active. 

Starting on line 904 in `midi_hub.py` :
```
    if input_midi_ports:
      for port in input_midi_ports:
        if isinstance(port, mido.ports.BaseInput):
          inport = port
        else:
          virtual = port not in get_available_input_ports()
          if virtual:
            tf.logging.info(
                ""Opening '%s' as a virtual MIDI port for input."", port)
          inport = mido.open_input(port, virtual=virtual)
        # Start processing incoming messages.
        inport.callback = self._timestamp_and_handle_message
```
Additionally, `input_midi_ports` elements are strings, so the `isinstance` test always fails and all ports are in effect virtual.

If you want, I can open a pull request to fix this.",think may constructor attached inport however inport local variable never assigned anywhere port instance garbage collected later interaction still active starting line port port inport port else virtual port virtual opening virtual port input port inport port start incoming additionally test always effect virtual want open pull request fix,issue,negative,negative,neutral,neutral,negative,negative
491151310,"Haha yeah I saw someone close their parentheses with a smiley face once and adopted the practice.

Yes I believe this means it is done for each item.",yeah saw someone close parenthesis face adopted practice yes believe done item,issue,positive,neutral,neutral,neutral,neutral,neutral
491119842,"Hi Chris! Thanks for your answer. Especially..
> :)

Was it possible to close a parenthesis with :)? Whoa 🤯

> ""independently""

Then it probably means the processing has been done for each item --  'data sample-wisely'. ",hi thanks answer especially possible close parenthesis whoa independently probably done item,issue,negative,positive,neutral,neutral,positive,positive
490857285,"> I solve This Errors

@JangminSon Can you please tell how you solved the error? 
I'm facing the same issue and would like your help.
Thanks :)",solve please tell error facing issue would like help thanks,issue,positive,positive,positive,positive,positive,positive
490689798,"Hi Keunwoo! Thanks for your interest in the work (and for defending it on twitter :). I will try to answer your questions below, though other authors may know more.

I am not sure about the answers to Q 1-1 and Q 1-2. I think Jesse or Shuo would be the right people to ask about that as they were more closely involved with the design of the architecture.

For Q 2-1, we find the minimum (a) and maximum (b) values of 100 (somewhat arbitrary choice) log-amplitude spectrograms from the training set. We normalize all of the dataset spectrograms by a linear rescaling from [a, b] -> [-0.8, 0.8]. Because a and b were computed from only 100 examples, other examples in the dataset might have values outside of [-0.8, 0.8] after rescaling, but likely not by much considering that they are log amplitudes. I am not sure what is meant by the term ""independently"" (I didn't write this section), but one of the other authors might know.

For Q 2-2, the phase is scaled from [-pi, pi] to [-1, 1]. I am not sure why we didn't also scale these values to [-0.8, 0.8], given that the generator also has a tanh nonlinearity for producing phase.

For Q 2-3, Instaneous frequency is computed by taking the finite differences across the time axis of the unwrapped phase spectra. The range of IF values is thus [-2pi, 2pi]. I assume (but am not certain) that we are rescaling this to [-1, 1].

If another author could chime in to verify my explanations, that would be helpful :)",hi thanks interest work twitter try answer though may know sure think would right people ask closely involved design architecture find minimum maximum somewhat arbitrary choice training set normalize linear might outside likely much considering log sure meant term independently write section one might know phase scaled pi sure also scale given generator also tanh phase frequency taking finite across time axis unwrapped phase spectrum range thus pi assume certain another author could chime verify would helpful,issue,positive,positive,positive,positive,positive,positive
490275107,"all of the links posted show how to use magenta trained models to make music but not how to take your own data for something like performanceRNN and train it using the gpu on colab and then create music. this is totally missing from the documentation
",link posted show use magenta trained make music take data something like train create music totally missing documentation,issue,negative,negative,negative,negative,negative,negative
489590978,"It is true that creating a new conda environment (https://github.com/conda/conda/issues/6748) faces issues when the root directory is read only; this is probably because conda requires to create temporary files in root directory for environment management and storage purposes, and read only mode does not let it to do so. The error is in line 59 of file /home/itspeter_google_com/miniconda2/etc/profile.d/conda.sh requires execution permission for variable CONDA_PREFIX. You can try giving executable permission to all conda variables, as most likely more than one variables may require executable permissions. Is your current user have administration privileges? Try giving it so might help it.",true new environment root directory read probably create temporary root directory environment management storage read mode let error line file execution permission variable try giving executable permission likely one may require executable current user administration try giving might help,issue,positive,positive,positive,positive,positive,positive
489587953,"Make sure your system (or virtual environment) has successfully installed Tensorflow and Magenta. Most likely either they are not installed or corrupted installed.  The error line showing ""The specific module could not be found"" hinted that there is problem with installation. Review your installation procedure (via pip or via source) for further debugging.",make sure system virtual environment successfully magenta likely either corrupted error line showing specific module could found problem installation review installation procedure via pip via source,issue,negative,positive,positive,positive,positive,positive
489585798,"@terraxoxo You might want to consider exploring more about MIDI here at http://www.indiana.edu/~emusic/361/midi.htm I'm new to music generation and digitization. I'm more of programmer than a composer. Extremely interested in development of Asian music composition using magenta. I'm trying to convert standard melodies/songs to standard formats such as MusicXML. Hey @adarob, feel free to give more pointers on that.",might want consider exploring new music generation programmer composer extremely interested development music composition magenta trying convert standard standard hey feel free give,issue,positive,positive,positive,positive,positive,positive
489225381,"Trying to add harmonies myself. Got the feeling that I am almost there. 

```
python coconet_sample.py \
--checkpoint=""$checkpoint"" \
--generation_output_dir=samples \
--prime_midi_melody_fpath=$midipath \
--strategy=""harmonize_midi_melody""
```

--strategy seems to be the crucial part. 

Any successes?",trying add got feeling almost python strategy crucial part,issue,negative,neutral,neutral,neutral,neutral,neutral
488684930,"There is still the dependency on `pipelines.statistics`, not sure what to do about that. Also should I move `protobuf` inside `music`?

As for the CLA, hopefully I'll be able to have it signed next week.",still dependency sure also move inside music hopefully able next week,issue,positive,positive,positive,positive,positive,positive
488368620,"Thanks! @cghawthorne can you help review this?
Doing this will also allow us to put MAESTRO in TFDS.",thanks help review also allow u put maestro,issue,positive,positive,positive,positive,positive,positive
487571749,"Hey Curtis,
sorry for my late reply. 
Thanks for your response.
I'm currently a bit busy working abroad. I'll check it out as soon as I find some time!

Best
C.
",hey sorry late reply thanks response currently bit busy working abroad check soon find time best,issue,positive,positive,neutral,neutral,positive,positive
487414206,"I gave it a stab (see #1519). The only dependency left seems to be `pipeline.statistics`; I'm not sure what it does, but it doesn't seem to be music-specific enough to move it under `music`.",gave stab see dependency left sure seem enough move music,issue,negative,positive,positive,positive,positive,positive
487274871,"OK, thanks for clarifying. So the goal would be to move the code (everything under `music` and `protobuf`?) to a new directory in this repo (eventually with its own `setup.py`), is that correct?

I tried to find things that `music` depends on. The only ones which I don't really see how to resolve are `pipeline.statistics` and `common.testing_lib`, which are imported in `music.*_lib` or the associated tests. On the other hand, many modules (notably `music.*_io` plus the protobuffers) seem to be already self-contained. I'm wondering if it would be reasonable to start by moving out the self-contained or easy-to-resolve things and leave the rest for later.",thanks goal would move code everything music new directory eventually correct tried find music really see resolve music associated hand many notably music plus seem already wondering would reasonable start moving leave rest later,issue,positive,positive,positive,positive,positive,positive
487197807,"No, it does mean a separate package. But before we can do that we first need to break all of the internal dependencies.",mean separate package first need break internal,issue,negative,negative,neutral,neutral,negative,negative
486949982,"Maybe I misunderstood what ""library"" meant in this context (presumably it's about creating a Bazel rule and not a separate Python package). If that's the case, sorry for spamming this issue (even though it's probably related) and I should probably create a new one.",maybe misunderstood library meant context presumably rule separate python package case sorry issue even though probably related probably create new one,issue,negative,negative,negative,negative,negative,negative
486904592,"I have the same issue: "" too many indices for array"".  Run with my checkpoint 'loglik' shape is (1,),  in the demo is (1,1)",issue many index array run shape,issue,negative,positive,positive,positive,positive,positive
486756378,"Most of the tensorflow dependencies are around tf.logging, which we can easily replace with abseil, and tf.gfile, which is more of a problem since we need it for internal compatibility. I suppose we could do something like write our own magenta.gfile wrapper, but that seems a little hacky.",around easily replace problem since need internal compatibility suppose could something like write wrapper little hacky,issue,negative,positive,neutral,neutral,positive,positive
486737977,"Thanks for the offer! Like I mention here, a first step would be refactoring what's under magenta/music and exposing it (for now) as a library within magenta. That would make it easier to pull out later and put into its own package. Of course, totally separating it from tensorflow dependencies might be a challenge still...",thanks offer like mention first step would library within magenta would make easier pull later put package course totally separating might challenge still,issue,positive,positive,positive,positive,positive,positive
486736202,"+1. There are functions and data structures in Magenta that could be very useful to the MIR community, but it can be impractical to have Magenta as a dependency. For example, I would like to use the `NoteSequence` proto to store some pre-processed MIDI files, but I can't install Magenta because I need to use an older version of TensorFlow.

If there's any way I can help with this, I can look into it.",data magenta could useful mir community impractical magenta dependency example would like use proto store ca install magenta need use older version way help look,issue,positive,positive,positive,positive,positive,positive
486330209,"Hi @thunderzwei, closing because I don't see any changes here! let us know what you're trying to do.",hi see let u know trying,issue,negative,neutral,neutral,neutral,neutral,neutral
484621187,"This shouldn't be necessary. I think the thing we need to change is to switch our dev environment setup instructions to use `pip install -e .` instead of setup.py. pip handles dependencies better than setup.py, including not pulling in prerelease versions. I'll send a PR for that shortly.",necessary think thing need change switch dev environment setup use pip install instead pip better prerelease send shortly,issue,negative,positive,positive,positive,positive,positive
484590249,"i'm still stuck on training the Music Transformer with relative attention. 
Can you please elaborate more on how to use the `self_attention_type=dot_product_relative_v2` flag and its parameters on training? It is not so clear for me, switching from the transformer baseline to the TF with relative global attention (as in the Music Transformer paper)

Here's list of the hyper-parameters that i am using. 

```
{
""activation_dtype"": ""float32"", 
""add_relative_to_values"": false, 
""attention_dropout"": 0.1, 
""attention_dropout_broadcast_dims"": """", 
""attention_key_channels"": 128, 
""attention_value_channels"": 128, 
""attention_variables_3d"": false, 
""batch_shuffle_size"": 512, 
""batch_size"": 4096, 
""bottom"": {}, 
""causal_decoder_self_attention"": true, 
""clip_grad_norm"": 0.0, 
""compress_steps"": 0, 
""conv_first_kernel"": 3, 
""daisy_chain_variables"": true, 
""data_dir"": ""/media/ramdisk2/datagen"", 
""dropout"": 0.2, 
""eval_drop_long_sequences"": false, 
""eval_freq_in_steps"": 1000, 
""eval_run_autoregressive"": false, 
""eval_steps"": 100, 
""eval_timeout_mins"": 240, 
""factored_logits"": false, 
""ffn_layer"": ""dense_relu_dense"", 
""filter_size"": 2048, 
""force_full_predict"": false, 
""grad_noise_scale"": 0.0, 
""hard_attention_k"": 0, 
""heads_share_relative_embedding"": false, 
""hidden_size"": 256, 
""initializer"": ""uniform_unit_scaling"", 
""initializer_gain"": 1.0, 
""kernel_height"": 3, 
""kernel_width"": 1, 
""label_smoothing"": 0.0, 
""layer_postprocess_sequence"": ""da"", 
""layer_prepostprocess_dropout"": 0.1, 
""layer_prepostprocess_dropout_broadcast_dims"": """", 
""layer_preprocess_sequence"": ""n"", 
""learning_rate"": 0.2, 
""learning_rate_constant"": 2.0, 
""learning_rate_cosine_cycle_steps"": 250000, 
""learning_rate_decay_rate"": 1.0, 
""learning_rate_decay_scheme"": ""noam"", 
""learning_rate_decay_staircase"": false, 
""learning_rate_decay_steps"": 5000, 
""learning_rate_minimum"": null, 
""learning_rate_schedule"": ""constant*linear_warmup*rsqrt_decay*rsqrt_hidden_size"", 
""learning_rate_warmup_steps"": 8000, 
""length_bucket_step"": 1.1, 
""loss"": {}, 
""max_input_seq_length"": 0, 
""max_length"": 0, 
""max_relative_position"": 1024, 
""max_target_seq_length"": 2048, 
""min_length"": 0, 
""min_length_bucket"": 8, 
""mixed_precision_optimizer_init_loss_scale"": 32768, 
""mixed_precision_optimizer_loss_scaler"": ""exponential"", 
""mlperf_mode"": false, 
""model_dir"": ""/home/data/jihoonpark/training/PROBLEM1/"", 
""moe_hidden_sizes"": ""2048"", 
""moe_k"": 2, 
""moe_loss_coef"": 0.001, 
""moe_num_experts"": 16, 
""moe_overhead_eval"": 2.0, 
""moe_overhead_train"": 1.0, 
""multiply_embedding_mode"": ""sqrt_depth"", 
""multiproblem_fixed_train_length"": -1, 
""multiproblem_label_weight"": 0.5, 
""multiproblem_max_input_length"": -1, 
""multiproblem_max_target_length"": -1, 
""multiproblem_mixing_schedule"": ""constant"", 
""multiproblem_per_task_threshold"": """", 
""multiproblem_reweight_label_loss"": false, 
""multiproblem_schedule_max_examples"": 10000000.0, 
""multiproblem_schedule_threshold"": 0.5, 
""multiproblem_target_eval_only"": false, 
""multiproblem_vocab_size"": -1, 
""name"": {}, 
""nbr_decoder_problems"": 1, 
""no_data_parallelism"": false, 
""norm_epsilon"": 1e-06, 
""norm_type"": ""layer"", 
""num_decoder_layers"": 0, 
""num_encoder_layers"": 0, 
""num_heads"": 8, 
""num_hidden_layers"": 6, 
""optimizer"": ""adam"", 
""optimizer_adafactor_beta1"": 0.0, 
""optimizer_adafactor_beta2"": 0.999, 
""optimizer_adafactor_clipping_threshold"": 1.0, 
""optimizer_adafactor_decay_type"": ""pow"", 
""optimizer_adafactor_factored"": true, 
""optimizer_adafactor_memory_exponent"": 0.8, 
""optimizer_adafactor_multiply_by_parameter_scale"": true, 
""optimizer_adam_beta1"": 0.9, 
""optimizer_adam_beta2"": 0.997, 
""optimizer_adam_epsilon"": 1e-09, 
""optimizer_momentum_momentum"": 0.9, 
""optimizer_momentum_nesterov"": false, 
""optimizer_multistep_accumulate_steps"": null, 
""optimizer_zero_grads"": false, 
""overload_eval_metric_name"": """", 
""pack_dataset"": false, 
""pad_batch"": false, 
""parameter_attention_key_channels"": 0, 
""parameter_attention_value_channels"": 0, 
""pos"": ""timing"", 
""prepend_mode"": ""none"", 
""pretrained_model_dir"": """", 
""proximity_bias"": false, 
""relu_dropout"": 0.1, 
""relu_dropout_broadcast_dims"": """", 
""sampling_keep_top_k"": -1, 
""sampling_method"": ""argmax"", 
""sampling_temp"": 1.0, 
""schedule"": ""train_and_evaluate"", 
""scheduled_sampling_gold_mixin_prob"": 0.5, 
""scheduled_sampling_prob"": 0.0, 
""scheduled_sampling_warmup_steps"": 50000, 
""self_attention_type"": ""dot_product_relative_v2"", 
""shared_embedding"": false, 
""shared_embedding_and_softmax_weights"": true, 
""split_targets_chunk_length"": 0, 
""split_targets_max_chunks"": 100, 
""split_to_length"": 0, 
""std_server_protocol"": ""grpc"", 
""summarize_grads"": false, 
""summarize_vars"": false, 
""symbol_dropout"": 0.0, 
""symbol_modality_num_shards"": 16, 
""top"": {}, 
""tpu_enable_host_call"": false, 
""train_steps"": 1000000, 
""unidirectional_encoder"": false, 
""use_custom_ops"": true, 
""use_fixed_batch_size"": false, 
""use_pad_remover"": true, 
""use_target_space_embedding"": true, 
""video_num_input_frames"": 1, 
""video_num_target_frames"": 1, 
""vocab_divisor"": 1, 
""warm_start_from"": null, 
""warm_start_from_second"": """", 
""weight_decay"": 0.0, 
""weight_dtype"": ""float32"", 
""weight_noise"": 0.0, 
""weights_fn"": {}
}
```",still stuck training music transformer relative attention please elaborate use flag training clear switching transformer relative global attention music transformer paper list float false false bottom true true dropout false false false false false da false null constant loss exponential false constant false false name false layer pow true true false null false false false timing none false schedule false true false false top false false true false true true null float,issue,positive,negative,negative,negative,negative,negative
484328669,"That makes sense, the docker image hasn't been updated since we simplified the build system (removed the need for bazel). It's now a lot easier to use pip to install which is what we recommend.",sense docker image since simplified build system removed need lot easier use pip install recommend,issue,positive,neutral,neutral,neutral,neutral,neutral
483996679,"Thanks for the quick response @jesseengel ! I am running with docker and on the latest image...

$ docker pull tensorflow/magenta
Using default tag: latest
latest: Pulling from tensorflow/magenta
Digest: sha256:ca8094cc110cd9dd2a4ed0a2650c1c51a5dfe6d1a13279d2832da5b198db72f3
Status: Image is up to date for tensorflow/magenta:latest",thanks quick response running docker latest image docker pull default tag latest latest digest sha status image date latest,issue,negative,positive,positive,positive,positive,positive
483956234,Did a little more sleuthing. If your command is `nsynth_generate --source_path=/path/to/file.wav` you need to also specify `--sample_length=number_of_audio_samples`  where number of audio samples is >= 16000 * number of seconds. Otherwise it runs out of memory on the CPU. I'll submit a PR to avoid this.,little command need also specify number audio number otherwise memory submit avoid,issue,negative,negative,negative,negative,negative,negative
483955134,"Hi! I think you're using an old version of magenta, `fastgen.load_batch()` was split in a previous PR. `pip install --upgrade magenta-gpu` should do it.",hi think old version magenta split previous pip install upgrade,issue,negative,negative,neutral,neutral,negative,negative
483878379,"Hm, yes it seems to have been a one-off issue on that host. Sorry! I thought I had tried restarting the runtime but it would seem I did not.",yes issue host sorry thought tried would seem,issue,negative,negative,negative,negative,negative,negative
483876187,I'm not able to reproduce this issue. Is it possible your environment is modified in a way that's causing problems? Can you try resetting your colab runtime?,able reproduce issue possible environment way causing try,issue,negative,positive,positive,positive,positive,positive
483813728,@cghawthorne I appreciate your help and support. I learned from the process. Thanks! ,appreciate help support learned process thanks,issue,positive,positive,positive,positive,positive,positive
483695464,"I got some errors when trying to change the author on the commits, so I sign the individual CLA as well (for David.primor@gmail.com). I hope now it's OK and the CLA can be fixed. Thanks!",got trying change author sign individual well hope fixed thanks,issue,positive,positive,positive,positive,positive,positive
483518111,"i only changed the tfrecords path and the data_dir where it stores the newly generated outputs
but it gives the same result. 

But it does seems that there is some kind of mistake that i made, since your runs seem normal. 
If I find out the problem i will update. Thank you!",path newly result kind mistake made since seem normal find problem update thank,issue,negative,positive,positive,positive,positive,positive
483486078,"That's very strange; I would have expected identical data (other than possibly using a different number of shards, but that doesn't seem to be what's going on as the file sizes are very different).  Are you absolutely sure nothing else was different between the two runs?  I tried running based on TFRecord files copied to my own bucket but my output was roughly the correct size.",strange would identical data possibly different number seem going file size different absolutely sure nothing else different two tried running based copied bucket output roughly correct size,issue,negative,positive,neutral,neutral,positive,positive
483461999,Was merged in 677a6ba6574dee66ddce7887e77bbcd06de3d0c8 by our internal tool. That should have closed this PR but it didn't get linked for some reason. Closing this manually.,internal tool closed get linked reason manually,issue,negative,negative,neutral,neutral,negative,negative
483445413,"A segmentation fault likely indicates an issue with your TensorFlow installation or maybe your GPU drivers. Can you try uninstalling the magenta-gpu and tensorflow-gpu packages and installing the CPU-only versions? If those work, then we know for sure it's a bug with TensorFlow and/or the GPU drivers.",segmentation fault likely issue installation maybe try work know sure bug,issue,negative,positive,positive,positive,positive,positive
483377952,"Thanks, I think the PR is almost done!

To fix the CLA error, you'll need to change the author on the commits. Here's some info on how to do that: https://stackoverflow.com/questions/3042437/how-to-change-the-commit-author-for-one-specific-commit",thanks think almost done fix error need change author,issue,negative,positive,positive,positive,positive,positive
483073199,"Hi, I'm sorry but I'm not able to reproduce your error. I can run the code locally on a Titan X (12GB). Also, Also, the EZ NSynth Colab (https://colab.sandbox.google.com/notebooks/magenta/nsynth/nsynth.ipynb) runs the same methods on a Colab GPU, which I believe has <= 16GB. ",hi sorry able reproduce error run code locally also also believe,issue,negative,neutral,neutral,neutral,neutral,neutral
482998965,The CLA was filled with the Email address david@musicmind.ai . I added this address to my GitHub account as my primary. I hope it's OK since originally I committed with my gmail.com account.,filled address added address account primary hope since originally account,issue,negative,positive,positive,positive,positive,positive
482990258,I commited two files - `midi_io.py`  that fixes CI problem and `midi_io_test` with the unit test with pretty_midi object in memory. CLA was filled and sent. Thanks!,two problem unit test object memory filled sent thanks,issue,negative,positive,positive,positive,positive,positive
482175599,That should not be the case. Perhaps you had already installed tf 2 previously? Alpha versions shouldn't get installed by our setup.py. Can you try removing tf 2 and re-running the magenta install?,case perhaps already previously alpha get try removing magenta install,issue,negative,negative,negative,negative,negative,negative
482168992,Yes - but I think this is the version that is installed by default using your setup procedures.,yes think version default setup,issue,negative,neutral,neutral,neutral,neutral,neutral
482163974,That appears to be an incompatibility issue with python3. You can try using python2 or update the file for compatibility.,incompatibility issue python try python update file compatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
482163294,Noticed that this works if I manually create the directory `val` before running the script,work manually create directory running script,issue,negative,neutral,neutral,neutral,neutral,neutral
482077830,Is this related to a specific colab? Because this seems to be working for me. (Maybe fixed now),related specific working maybe fixed,issue,negative,positive,neutral,neutral,positive,positive
482059009,"It's using dynamic_rnn during generation and (when use_cudnn parameter is off). This allows dynamic length input (i.e. it will back propagate till the sequence length provided as input). The lengths for all inputs in a batch are being provided as input (see line 271 of https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/events_rnn_graph.py)
So, essentially it depends on the length of the input sequences.
",generation parameter dynamic length input back propagate till sequence length provided input batch provided input see line essentially length input,issue,negative,neutral,neutral,neutral,neutral,neutral
481845236,"Not sure which visualization in particular you're referring to -- if you mean the visualizations of MIDI files on the [blog](https://magenta.tensorflow.org/music-transformer), they're done with one of the magenta.js Visualizers (you can see a demo of them in action [here](https://tensorflow.github.io/magenta-js/music/demos/visualizer.html))

For the attention, we built an interactive [attention visualizer](https://meowni.ca/transformer-visualization/). You can load any of the figures in the paper up, and then click on any of the notes to visualize the attention for that note.
",sure visualization particular mean done one see action attention built interactive attention visualizer load paper click visualize attention note,issue,negative,positive,positive,positive,positive,positive
481627746,"I believe [utils.py](https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/utils.py) is used for this task, but the resulting file format/contents isn't exactly what is expected, I'd love to hear about ways to use it correctly, or an update on the manual.",believe used task resulting file exactly love hear way use correctly update manual,issue,positive,positive,positive,positive,positive,positive
481480581,"I'd probably prefer that you create the pretty_midi object in memory. That will make the test much easier to maintain.

Also, don't forget to fix the CLA and Travis CI errors for this PR.",probably prefer create object memory make test much easier maintain also forget fix travis,issue,negative,positive,positive,positive,positive,positive
481418942,"There are two possibilities for a unit test.
If I create a pretty_midi object in memory, It could be a function in `midi_io_test.py` : 
  ```
def testInstrumentInfo_NoteSequenceToPrettyMidi(self):
    source_sequence = music_pb2.NoteSequence()
    source_sequence.notes.add(pitch=60, start_time=0.0, end_time=0.5, velocity=80, instrument=0)
    source_sequence.notes.add(pitch=60, start_time=0.5, end_time=1.0, velocity=80, instrument=1)
    instrument_info1 = source_sequence.instrument_infos.add()
    instrument_info1.name = 'inst_0'
    instrument_info1.instrument = 0
    instrument_info2 = source_sequence.instrument_infos.add()
    instrument_info2.name = 'inst_1'
    instrument_info2.instrument = 1
    translated_midi = midi_io.sequence_proto_to_pretty_midi(source_sequence)
    translated_sequence = midi_io.midi_to_note_sequence(translated_midi)
    if translated_sequence.instrument_infos:
      self.assertEqual(len(source_sequence.instrument_infos), len(translated_sequence.instrument_infos))
      self.assertEqual(source_sequence.instrument_infos[0].name, translated_sequence.instrument_infos[0].name)
      self.assertEqual(source_sequence.instrument_infos[1].name, translated_sequence.instrument_infos[1].name)
```
Another possibility is adding an instrument name to `example.mid` and then checking the name values  after converting to NoteSequence and back to PrettyMidi object
Please advise.",two unit test create object memory could function self another possibility instrument name name converting back object please advise,issue,positive,neutral,neutral,neutral,neutral,neutral
480917985,"@LegendFC We don't use the metrics in Andrew McLeod's paper because they deal more with a representation that is closer to sheet music, whereas our model currently just outputs a pianoroll/MIDI representation of the transcription. We instead use the suite of metrics that is collected in the [mir_eval](https://github.com/craffel/mir_eval) package. You can read more about exactly what metrics we use and our results in our two papers:

[Onsets and Frames: Dual-Objective Piano Transcription
](https://goo.gl/magenta/onsets-frames-paper)
[Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset](https://goo.gl/magenta/maestro-paper)",use metric paper deal representation closer sheet music whereas model currently representation transcription instead use suite metric collected package read exactly metric use two piano transcription piano music modeling generation maestro,issue,negative,positive,positive,positive,positive,positive
480913492,"@Ghastlcon, we no longer use Bazel for the main Magenta library. You can just develop using standard python tools (setup.py, pip, etc.)",longer use main magenta library develop standard python pip,issue,negative,positive,neutral,neutral,positive,positive
480628997,"Thank you for your help! I've just add a PR with InstrumentInfo message for your review. I changed the .proto file and add some functionality in midi_io.py.  As I mentioned before, I checked it with my external code with additional logic for fixing the midi channel order, and it works. Thanks!",thank help add message review file add functionality checked external code additional logic fixing channel order work thanks,issue,positive,positive,neutral,neutral,positive,positive
480560163,@hardmaru sorry for my delayed reply. Thanks for your suggestion! Everything works very well now. ,sorry reply thanks suggestion everything work well,issue,positive,negative,negative,negative,negative,negative
480548622,"same question. i am in the magenta directory.
```
ghastlcon@GHASTLCON-U18:~/magenta$ ll
total 160
drwxr-xr-x  5 ghastlcon ghastlcon  4096 Apr  7 00:05 ./
drwxr-xr-x 12 ghastlcon ghastlcon  4096 Apr  7 00:24 ../
-rw-r--r--  1 ghastlcon ghastlcon    49 Apr  7 00:05 AUTHORS
-rwxr-xr-x  1 ghastlcon ghastlcon  1096 Apr  7 00:05 ci-install.sh*
-rwxr-xr-x  1 ghastlcon ghastlcon   704 Apr  7 00:05 ci-script.sh*
-rw-r--r--  1 ghastlcon ghastlcon   761 Apr  7 00:05 conftest.py
drwxr-xr-x  2 ghastlcon ghastlcon  4096 Apr  7 00:05 demos/
drwxr-xr-x  8 ghastlcon ghastlcon  4096 Apr  7 00:05 .git/
-rw-r--r--  1 ghastlcon ghastlcon    93 Apr  7 00:05 .gitignore
-rw-r--r--  1 ghastlcon ghastlcon     0 Apr  7 00:05 .gitmodules
-rw-r--r--  1 ghastlcon ghastlcon   183 Apr  7 00:05 .isort.cfg
-rw-r--r--  1 ghastlcon ghastlcon 11410 Apr  7 00:05 LICENSE
drwxr-xr-x 15 ghastlcon ghastlcon  4096 Apr  7 00:05 magenta/
-rw-r--r--  1 ghastlcon ghastlcon 69114 Apr  7 00:05 magenta-logo-bg.png
-rw-r--r--  1 ghastlcon ghastlcon  8014 Apr  7 00:05 .pylintrc
-rw-r--r--  1 ghastlcon ghastlcon  8389 Apr  7 00:05 README.md
-rw-r--r--  1 ghastlcon ghastlcon    73 Apr  7 00:05 setup.cfg
-rw-r--r--  1 ghastlcon ghastlcon  6764 Apr  7 00:05 setup.py
-rw-r--r--  1 ghastlcon ghastlcon   148 Apr  7 00:05 .travis.yml
ghastlcon@GHASTLCON-U18:~/magenta$ bazel test //magenta/...
ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).
See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
ghastlcon@GHASTLCON-U18:~/magenta$
```",question magenta directory total license test error command within directory file see documentation warning batch mode please instead explicitly shut server command shutdown,issue,negative,neutral,neutral,neutral,neutral,neutral
479835113,Thank you for sharing this. Is there any way I can work with my own MIDI files and train them?,thank way work train,issue,negative,neutral,neutral,neutral,neutral,neutral
479667946,"@jesseengel thanx for you help. I tryed before: played with versions of dependencies - no results, create new conda env - no results. Finally I just finished total reinstall of Anaconda3 and it finally work! Of course I cant finish training on macbook but at least it started and I was able to generate sounds with pretrained models. So I assume that something was broken inside my anaconda (however everything else worked fine). Thanx again for your help.",help create new finally finished total reinstall anaconda finally work course cant finish training least able generate assume something broken inside anaconda however everything else worked fine help,issue,positive,positive,neutral,neutral,positive,positive
479661097,"The _beam_size_ parameter is the number of highest-likelihood sequences maintained during beam search.  At each generation step, _branch_factor_ next samples are taken for each sequence in the beam, and then all but the top _beam_size_ sequences (across all branches) are discarded.

Unless you're doing some kind of conditional generation (e.g. with Improv RNN), you probably want to use a beam size and branch factor of 1.",parameter number beam search generation step next taken sequence beam top across unless kind conditional generation probably want use beam size branch factor,issue,positive,positive,positive,positive,positive,positive
479659629,"Tensor2Tensor appears to have a dependency on Jax, which does not currently support Windows.  You can try using the Magenta development environment as described [here](https://github.com/tensorflow/magenta#development-environment); unless you're using Transformer you won't need the Tensor2Tensor dependency.",dependency currently support try magenta development environment unless transformer wo need dependency,issue,negative,neutral,neutral,neutral,neutral,neutral
479654140,"Hey, I just did a fresh install with miniconda2 on my MacBookPro (Mojave 10.14.3) following  `https://github.com/tensorflow/magenta/blob/master/magenta/tools/magenta-install.sh`, and it worked. Can you confirm if that works for you? You might also be able to get away with just setting up a new conda environment.",hey fresh install following worked confirm work might also able get away setting new environment,issue,negative,positive,positive,positive,positive,positive
479633385,"You should only need to modify the .proto file. The *pb2.py files are autogenerated by protobuf compiler. There are instructions in the README in the protobuf directory on how to install and run it.

You can see some more information about protocol buffers here: https://developers.google.com/protocol-buffers/",need modify file compiler directory install run see information protocol,issue,negative,neutral,neutral,neutral,neutral,neutral
479578657,Even I'm looking for an update to this. Want to train a model using Coconet but not sure how to.,even looking update want train model sure,issue,negative,positive,positive,positive,positive,positive
479578246,The training set wasn't empty. The training of the model was done successfully. Am using this MIDI dataset here: https://mega.nz/#!Elg1TA7T!MXEZPzq9s9YObiUcMCoNQJmCbawZqzAkHzY4Ym6Gs_Q. I converted these MIDI files in NodeSequences and then SequenceExamples as per the tutorial given for Melody RNN.,training set empty training model done successfully converted per tutorial given melody,issue,negative,positive,positive,positive,positive,positive
479170110,I've got the fix checked in on our side. It will deploy publicly in a couple days.,got fix checked side deploy publicly couple day,issue,negative,neutral,neutral,neutral,neutral,neutral
479045711,"@jesseengel thanx for reply. I've got version which pip installed. My env:
```
MacOS Mojave 10.14.4
pip 19.0.3
Python 3.6.5 Anaconda
tensorflow==1.13.1
numpy==1.16.2
magenta==1.0.5
```
<details>
<summary>All intalled packages list</summary>

```
absl-py==0.4.0
alabaster==0.7.10
anaconda-client==1.6.14
anaconda-navigator==1.9.6
anaconda-project==0.8.2
appnope==0.1.0
appscript==1.0.1
asn1crypto==0.24.0
astor==0.7.1
astroid==1.6.3
astropy==3.0.2
attrs==18.1.0
audioread==2.1.6
autobahn==18.9.2
Automat==0.7.0
Babel==2.5.3
backcall==0.1.0
backports.shutil-get-terminal-size==1.0.0
backports.tempfile==1.0
backports.weakref==1.0.post1
beautifulsoup4==4.6.0
bitarray==0.8.1
bkcharts==0.2
blaze==0.11.3
bleach==2.1.3
bokeh==0.12.16
boto==2.48.0
Bottleneck==1.2.1
bz2file==0.98
cachetools==3.1.0
certifi==2018.4.16
cffi==1.11.5
chardet==3.0.4
click==6.7
cloudpickle==0.5.3
clyent==1.2.2
colorama==0.3.9
conda==4.6.8
conda-build==3.10.5
conda-verify==2.0.0
constantly==15.1.0
contextlib2==0.5.5
cryptography==2.2.2
cycler==0.10.0
Cython==0.28.2
cytoolz==0.9.0.1
dask==0.17.5
datashape==0.5.4
dateparser==0.7.0
decorator==4.3.0
distributed==1.21.8
docutils==0.14
dopamine-rl==2.0.1
entrypoints==0.2.3
enum34==1.1.6
et-xmlfile==1.0.1
fastcache==1.0.2
filelock==3.0.4
Flask==1.0.2
Flask-Cors==3.0.4
future==0.17.1
gast==0.2.0
gevent==1.3.0
gin-config==0.1.4
glob2==0.6
gmpy2==2.0.8
google-api-python-client==1.7.8
google-auth==1.6.3
google-auth-httplib2==0.0.3
googleapis-common-protos==1.5.9
greenlet==0.4.13
grpcio==1.12.1
gunicorn==19.9.0
gym==0.12.1
h5py==2.7.1
heapdict==1.0.0
html5lib==1.0.1
httplib2==0.12.1
hyperlink==18.0.0
idna==2.6
imageio==2.3.0
imagesize==1.0.0
incremental==17.5.0
int-date==0.1.8
intervaltree==3.0.2
ipykernel==4.8.2
ipython==6.4.0
ipython-genutils==0.2.0
ipywidgets==7.2.1
isort==4.3.4
itsdangerous==0.24
jax==0.1.22
jaxlib==0.1.12
jdcal==1.4
jedi==0.12.0
Jinja2==2.10
joblib==0.13.2
jsonschema==2.6.0
jupyter==1.0.0
jupyter-client==5.2.3
jupyter-console==5.2.0
jupyter-core==4.4.0
jupyterlab==0.32.1
jupyterlab-launcher==0.10.5
Keras==2.2.4
Keras-Applications==1.0.7
Keras-Preprocessing==1.0.9
kfac==0.1.4
kiwisolver==1.0.1
lazy-object-proxy==1.3.1
librosa==0.6.3
llvmlite==0.23.1
locket==0.2.0
lxml==4.2.1
magenta==1.0.5
Markdown==2.6.11
MarkupSafe==1.0
matplotlib==2.2.2
mccabe==0.6.1
mesh-tensorflow==0.0.5
mido==1.2.6
mir-eval==0.5
mistune==0.8.3
mkl-fft==1.0.0
mkl-random==1.0.1
mock==2.0.0
more-itertools==4.1.0
mpmath==1.0.0
msgpack==0.5.6
msgpack-python==0.5.6
multipledispatch==0.5.0
navigator-updater==0.2.1
nbconvert==5.3.1
nbformat==4.4.0
networkx==1.8.1
nltk==3.3
nose==1.3.7
notebook==5.5.0
numba==0.38.0
numexpr==2.6.5
numpy==1.16.2
numpydoc==0.8.0
oauth2client==4.1.3
odo==0.5.1
olefile==0.45.1
opencv-python==4.0.0.21
openpyxl==2.5.3
opt-einsum==2.3.2
packaging==17.1
pandas==0.23.0
pandocfilters==1.4.2
parso==0.2.0
partd==0.3.8
path.py==11.0.1
pathlib2==2.3.2
patsy==0.5.0
pbr==5.1.3
pep8==1.7.1
pexpect==4.5.0
pickleshare==0.7.4
Pillow==5.1.0
pkginfo==1.4.2
plotly==3.1.1
pluggy==0.6.0
ply==3.11
pretty-midi==0.2.8
promise==2.2.1
prompt-toolkit==1.0.15
protobuf==3.7.1
psutil==5.4.5
ptyprocess==0.5.2
py==1.5.3
pyasn1==0.4.4
pyasn1-modules==0.2.2
pycodestyle==2.4.0
pycosat==0.6.3
pycparser==2.18
pycrypto==2.6.1
pycurl==7.43.0.1
pyflakes==1.6.0
pyglet==1.3.2
Pygments==2.2.0
pygtrie==2.3
PyHamcrest==1.9.0
pylint==1.8.4
pyodbc==4.0.23
pyOpenSSL==18.0.0
pyparsing==2.2.0
pypng==0.0.19
PySocks==1.6.8
pytest==3.5.1
pytest-arraydiff==0.2
pytest-astropy==0.3.0
pytest-doctestplus==0.1.3
pytest-openfiles==0.3.0
pytest-remotedata==0.2.1
python-binance==0.7.0
python-dateutil==2.7.3
python-rtmidi==1.1.2
pytz==2018.4
PyWavelets==0.5.2
PyYAML==3.12
pyzmq==17.0.0
QtAwesome==0.4.4
qtconsole==4.3.1
QtPy==1.4.1
regex==2018.8.29
requests==2.18.4
resampy==0.2.1
retrying==1.3.3
rope==0.10.7
rsa==4.0
ruamel-yaml==0.15.35
scikit-image==0.13.1
scikit-learn==0.19.1
scipy==1.1.0
seaborn==0.8.1
Send2Trash==1.5.0
service-identity==17.0.0
simplegeneric==0.8.1
singledispatch==3.4.0.3
six==1.11.0
sk-video==1.1.10
snowballstemmer==1.2.1
sonnet==0.1.6
sortedcollections==0.6.1
sortedcontainers==2.1.0
sox==1.3.7
Sphinx==1.7.4
sphinxcontrib-websupport==1.0.1
spyder==3.2.8
SQLAlchemy==1.2.7
statsmodels==0.9.0
stevedore==1.30.0
stockstats==0.2.0
sympy==1.1.1
ta==0.2.0
tables==3.4.3
tblib==1.3.2
tensoflow==0.0.5
tensor2tensor==1.13.1
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-datasets==1.0.1
tensorflow-estimator==1.13.0
tensorflow-metadata==0.13.0
tensorflow-probability==0.6.0
termcolor==1.1.0
terminado==0.8.1
testpath==0.3.1
toolz==0.9.0
tornado==5.0.2
tqdm==4.31.1
traitlets==4.3.2
Twisted==18.7.0
txaio==18.8.1
typing==3.6.4
tzlocal==1.5.1
unicodecsv==0.14.1
uritemplate==3.0.0
urllib3==1.22
virtualenv==16.1.0
virtualenv-clone==0.4.0
virtualenvwrapper==4.8.2
wcwidth==0.1.7
webencodings==0.5.1
Werkzeug==0.14.1
widgetsnbextension==3.2.1
wrapt==1.10.11
xlrd==1.1.0
XlsxWriter==1.0.4
xlwings==0.11.8
xlwt==1.2.0
zict==0.1.3
zope.interface==4.5.0
```
</details>

I can provide any additional information you need. Is this exception could be a result of wrong versions of dependencies?  ",reply got version pip pip python anaconda summary list post provide additional information need exception could result wrong,issue,negative,negative,negative,negative,negative,negative
479035653,"Hi George, 

Sorry you're having trouble. I'm not able to reproduce your error on my local linux box. When I run

```
gansynth_train --config=mel_prog_hires --hparams='{""train_data_path"":""~/nsynth-test.tfrecord"", ""train_root_dir"":""/tmp/gansynth/train""}'
```

It seems to train fine for me. Have you updated to the latest pip package?",hi sorry trouble able reproduce error local box run train fine latest pip package,issue,negative,positive,positive,positive,positive,positive
479029433,Currently there are no chords -> performance problems registered; the main reason is that we don't have a good dataset of performances with chord labels.  We're working on a way around this...,currently performance registered main reason good chord working way around,issue,negative,positive,positive,positive,positive,positive
478927760,"Python-rtmidi is OK currently.
However, it failed in ""llvmlite"" step.
**""
Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.""**",currently however step project thus accurately determine belong would lead partial,issue,negative,positive,positive,positive,positive,positive
478926023,"Still exists same issue.
![image](https://user-images.githubusercontent.com/34225874/55393570-16e03000-5570-11e9-906f-a9dfc97e46e2.png)
  Failed building wheel for python-rtmidi
",still issue image building wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
478670162,Is it possible your training set is empty? How many examples are you training on?,possible training set empty many training,issue,negative,positive,positive,positive,positive,positive
478387116,"from reading the code, if you want to use the npz file provided, you need to rename it from TestData.npz to Jsb16thSeparated.npz, however the TestData.npz doesn't provide enough data, to train anything meaningful. I wrote something on my branch to generate midi -> the npz format that they use, but I can't be for sure that my data is right/ accurate.",reading code want use file provided need rename however provide enough data train anything meaningful wrote something branch generate format use ca sure data accurate,issue,positive,positive,positive,positive,positive,positive
478363685,"A friend and I are interested in using coconet to generate new SNES-era game music, but aren't sure what format the training data needs to be in.  Any update on this?  Even a simple description would be helpful!",friend interested generate new game music sure format training data need update even simple description would helpful,issue,positive,positive,neutral,neutral,positive,positive
478270150,"Please ignore the above! I had missed that the passed in bias doubles as the mask and is supposedly lower-diagonal.

Best.",please ignore bias mask supposedly best,issue,positive,positive,positive,positive,positive,positive
478254564,"**@cghawthorne** In order to test your approach I used PartInfo message and added the right functionality to midi_io.py in two places: `note_sequence_to_pretty_midi` and `midi_to_note_sequence(midi_data)`. I also added the functionality in my code to keep and rearrange the midi channels. I'm happy to say that it works on my framework using the cloned magenta code with Partinfo message. However, when trying to add InstrumentInfo message instead of PartInfo, I found it quite complex and not streight forward. I tried to change `music.proto` and `music_pb2.py` by copy creating almost similar messege as PartInfo:
```
_NOTESEQUENCE_INSTRUMENTINFO = _descriptor.Descriptor(
  name='InstrumentInfo',
  full_name='tensorflow.magenta.NoteSequence.InstrumentInfo',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='instrument', full_name='tensorflow.magenta.NoteSequence.PartInfo.part', index=0,
      number=1, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='name', full_name='tensorflow.magenta.NoteSequence.PartInfo.name', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("""").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=4325,
  serialized_end=4363,
)

```
and:

```
// Stores information about an instrument name
  // See usage within Note for more details.
  message InstrumentInfo {
    // The instrument index.
    int32 part = 1;
    // The name of the instrument. Examples: ""Piano"" or ""bass"".
    string name = 2;
  }

```
 I'm sure there is something I'm missing since I don't know which values to put in `serialized_start` and `serialized_end` and when trying to run it I got an error: 
```
File ""/Users/didi/PycharmProjects/MusicMindServer/nvenv/lib/python3.7/site-packages/google/protobuf/descriptor.py"", line 288, in __new__
    return _message.default_pool.FindMessageTypeByName(full_name)
KeyError: ""Couldn't find message tensorflow.magenta.NoteSequence.InstrumentInfo""
```
Can you please advise what is the proper way to add message to NoteSequence?
Thanks!",order test approach used message added right functionality two also added functionality code keep rearrange happy say work framework magenta code message however trying add message instead found quite complex forward tried change copy almost similar information instrument name see usage within note message instrument index part name instrument piano bass string name sure something missing since know put trying run got error file line return could find message please advise proper way add message thanks,issue,positive,positive,positive,positive,positive,positive
477905230,"Thanks @cghawthorne Done : https://github.com/tensorflow/magenta-demos/pull/64 The colab is now online and the link is there in the PR Readme.  [(Colab link)](https://colab.research.google.com/drive/1uxtG69W4vYjSF9NebsYSZnpnLoqa09aT)
Should we put the ipython notebook in there too and send a pull request? ",thanks done link link put notebook send pull request,issue,negative,positive,positive,positive,positive,positive
477762547,"Hi @falaktheoptimist, we're thinking it would probably be best to use colab notebooks, just because the environment is a little more predictable. Would you mind converting your notebook into something that can work in colab and then making a PR to put it in a colab-notebooks directory in our [magenta-demos](https://github.com/tensorflow/magenta-demos) repo?

We'll then be able to load those notebooks directly in colab with links like  https://colab.research.google.com/github/tensorflow/magenta-demos/blob/master/colab-notebooks/NotebookName.ipynb",hi thinking would probably best use environment little predictable would mind converting notebook something work making put directory able load directly link like,issue,positive,positive,positive,positive,positive,positive
477743399,I'm facing the same issue. Has there been any solution found to this?,facing issue solution found,issue,negative,neutral,neutral,neutral,neutral,neutral
477703752,"Sorry, I need to update the colab to work with some changes in the codebase. Will have a fix shortly.",sorry need update work fix shortly,issue,negative,negative,negative,negative,negative,negative
477439200,"Hi @giada1198 

I wonder if the data loader is doing something funky due to the big difference in dataset sizes between the two datasets.

If you have tried training sketch-rnn on both datasets (en.npz, airplane.npz) individually, and they both work, then a fix you can do is to manually concatenate the datasets together and train sketch-rnn on a single, combined npz file (perhaps even using the validation and test data in `en.npz` as well in the training). To ensure that the random training batches are not skewed towards having mostly airplanes (since they dominate in terms of the number of training samples), you may want to duplicate `en.npz` a few times so that the size is comparable, and perhaps use some data augmentation as well to avoid overfitting the model.
",hi wonder data loader something funky due big difference size two tried training individually work fix manually concatenate together train single combined file perhaps even validation test data well training ensure random training skewed towards mostly since dominate number training may want duplicate time size comparable perhaps use data augmentation well avoid model,issue,positive,negative,neutral,neutral,negative,negative
477425346,"@hardmaru thanks for your prompt reply, let me clarify my question:

I prepared two datasets: one is my hand-made small dataset(200/100/100), another is the airplane dataset from quick draw(7000/2500/2500). RNNs worked very well if I trained them individually. However, when I tried to trained them together in order to create some interesting interpolations, the outputs became a bunch of chaotic lines. I guess I used the wrong command:

```
python2 sketch_rnn_train.py --log_root='/home/giada1198/raw' --data_dir='/home/giada1198/raw' --hparams=""data_set=[ren.npz, airplane.npz],enc_model=layer_norm,enc_rnn_size=512,save_every=500""
```
I used your [demo](https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb) and merely changed the model path to generate outputs.

Thanks again!",thanks prompt reply let clarify question prepared two one small another airplane quick draw worked well trained individually however tried trained together order create interesting bunch chaotic guess used wrong command python used merely model path generate thanks,issue,positive,negative,neutral,neutral,negative,negative
477017516,"Hi @giada1198 

Are you able to train sketch-rnn on a single .npz file with your current setup?

Can you let me know the exact command you used, to see if I can reproduce the error?

Thanks",hi able train single file current setup let know exact command used see reproduce error thanks,issue,negative,positive,positive,positive,positive,positive
476997099,"Thanks for update.
But error in building with ""python-rtmidi"", if needs, I will file a new issue. Is there any work-around to solve the issue?
> Building wheels for collected packages: python-rtmidi
>   Running setup.py bdist_wheel for python-rtmidi ... error
>   Complete output from command /root/anaconda3/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-9355z8fs/python-rtmidi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d /tmp/pip-wheel-eqpt0tok --python-tag cp36:
>   running bdist_wheel
>   running build
>   running build_py
>   creating build
>   creating build/lib.linux-x86_64-3.6
>   creating build/lib.linux-x86_64-3.6/rtmidi
>   copying rtmidi/__init__.py -> build/lib.linux-x86_64-3.6/rtmidi
>   copying rtmidi/midiutil.py -> build/lib.linux-x86_64-3.6/rtmidi
>   copying rtmidi/midiconstants.py -> build/lib.linux-x86_64-3.6/rtmidi
>   copying rtmidi/release.py -> build/lib.linux-x86_64-3.6/rtmidi
>   running build_ext
>   building 'rtmidi._rtmidi' extension
>   creating build/temp.linux-x86_64-3.6
>   creating build/temp.linux-x86_64-3.6/src
>   gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -D__LINUX_ALSA__ -Isrc -I/root/anaconda3/include/python3.6m -c src/_rtmidi.cpp -o build/temp.linux-x86_64-3.6/src/_rtmidi.o
>   cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
>   gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -D__LINUX_ALSA__ -Isrc -I/root/anaconda3/include/python3.6m -c src/RtMidi.cpp -o build/temp.linux-x86_64-3.6/src/RtMidi.o
>   cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
>   src/RtMidi.cpp:1101:10: fatal error: alsa/asoundlib.h: No such file or directory
>    #include <alsa/asoundlib.h>
>             ^~~~~~~~~~~~~~~~~~
>   compilation terminated.
>   error: command 'gcc' failed with exit status 1
> 
>   ----------------------------------------
>   Failed building wheel for python-rtmidi
>   Running setup.py clean for python-rtmidi
> Failed to build python-rtmidi
> tensorflow-metadata 0.13.0 has requirement protobuf<4,>=3.7, but you'll have protobuf 3.6.1 which is incompatible.
> Installing collected packages: bokeh, python-rtmidi, sox, llvmlite, numba, resampy, librosa, intervaltree, enum34, gin-config, rsa, httplib2, oauth2client, tensorflow-probability, pyglet, gym, dopamine-rl, mesh-tensorflow, gunicorn, jaxlib, cachetools, google-auth, uritemplate, google-auth-httplib2, google-api-python-client, kfac, promise, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets, opt-einsum, jax, tensor2tensor, backports.weakref, backports.tempfile, pygtrie, mido, pretty-midi, mir-eval, networkx, sonnet, magenta-gpu
>   Running setup.py install for python-rtmidi ... error
>     Complete output from command /root/anaconda3/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-9355z8fs/python-rtmidi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-record-kf146je9/install-record.txt --single-version-externally-managed --compile:
>     running install
>     running build
>     running build_py
>     creating build
>     creating build/lib.linux-x86_64-3.6
>     creating build/lib.linux-x86_64-3.6/rtmidi
>     copying rtmidi/__init__.py -> build/lib.linux-x86_64-3.6/rtmidi
>     copying rtmidi/midiutil.py -> build/lib.linux-x86_64-3.6/rtmidi
>     copying rtmidi/midiconstants.py -> build/lib.linux-x86_64-3.6/rtmidi
>     copying rtmidi/release.py -> build/lib.linux-x86_64-3.6/rtmidi
>     running build_ext
>     building 'rtmidi._rtmidi' extension
>     creating build/temp.linux-x86_64-3.6
>     creating build/temp.linux-x86_64-3.6/src
>     gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -D__LINUX_ALSA__ -Isrc -I/root/anaconda3/include/python3.6m -c src/_rtmidi.cpp -o build/temp.linux-x86_64-3.6/src/_rtmidi.o
>     cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
>     gcc -pthread -B /root/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -D__LINUX_ALSA__ -Isrc -I/root/anaconda3/include/python3.6m -c src/RtMidi.cpp -o build/temp.linux-x86_64-3.6/src/RtMidi.o
>     cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
>     src/RtMidi.cpp:1101:10: fatal error: alsa/asoundlib.h: No such file or directory
>      #include <alsa/asoundlib.h>
>               ^~~~~~~~~~~~~~~~~~
>     compilation terminated.
>     error: command 'gcc' failed with exit status 1
> 
>     ----------------------------------------
> Command ""/root/anaconda3/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/pip-install-9355z8fs/python-rtmidi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-record-kf146je9/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-install-9355z8fs/python-rtmidi",thanks update error building need file new issue solve issue building collected running error complete output command import open compile code running running build running build running building extension warning command line option valid warning command line option valid fatal error file directory include compilation error command exit status building wheel running clean build requirement incompatible collected gym promise sonnet running install error complete output command import open compile code install record compile running install running build running build running building extension warning command line option valid warning command line option valid fatal error file directory include compilation error command exit status command import open compile code install record compile error code,issue,negative,positive,positive,positive,positive,positive
476990194,"The tensor2tensor had been fixed on version 1.13.1 (latest), and now magenta could be installed on version 1.0.5 with pip.",fixed version latest magenta could version pip,issue,negative,positive,positive,positive,positive,positive
476884619,Sorry this was an error due to the pypi version not being updated (which it now is). I tested it and this should now be resolved.,sorry error due version tested resolved,issue,negative,negative,negative,negative,negative,negative
476848302,"If you update tensor2tensor to 1.13.1 it removed the tf-agents dependency until we fix the issue

https://github.com/tensorflow/tensor2tensor/commit/a4071d62f510a3b0dace62f9fa78e2f9a60c5c40#diff-2eeaed663bd0d25b7e608891384b7298",update removed dependency fix issue,issue,negative,neutral,neutral,neutral,neutral,neutral
476836419,"> It is funny that the tf-agents pip library is no longer available while its maintainer forces us to turn to the tf-agents-nightly.

@wushaobo - Could you try `pip install tf-agents` again, potentially with `--upgrade`? 

",funny pip library longer available maintainer u turn could try pip install potentially upgrade,issue,negative,positive,positive,positive,positive,positive
475438155,"I have also reported the following related issue to tensor2tensor team:

https://github.com/tensorflow/tensor2tensor/issues/1506",also following related issue team,issue,negative,neutral,neutral,neutral,neutral,neutral
475400493,"@magnus-gross thanks do you also know how to start training it? I am getting this when trying to train 
INFO:tensorflow:Saving checkpoint to path /content/magenta/magenta/models/coconet/logging/dilated-10-64_bs=1,corrupt=0.5,len=32,lr=0.0625,mm=orderless,nreg_conv=2,num_i=4,n_pch=128,mask_only=False,quant=0.125,rescale=True,depth_mul=1,sep=True,res=True,sconv=True,soft=True/model.ckpt
Traceback (most recent call last):
  File ""coconet_train.py"", line 378, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""coconet_train.py"", line 285, in main
    epoch_count)
  File ""coconet_train.py"", line 178, in run_epoch
    fetches, feed_dict=feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1128, in _run
    str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (1, 7, 46, 4) for Tensor u'Placeholder_1:0', which has shape '(?, ?, 128, 4)'",thanks also know start training getting trying train saving path recent call last file line module file line run main file line main file line file line run file line feed value shape tensor shape,issue,positive,positive,positive,positive,positive,positive
475365157,"@ak9250 See #1292 

You have to replace the content of the `checkpoint` file with:

```bash
model_checkpoint_path: ""best_model.ckpt""
```",ak see replace content file bash,issue,negative,neutral,neutral,neutral,neutral,neutral
475357616,"not sure about this but how did you get the sh `sample_bazel.sh /tmp/coconet_checkpoint/coconet-64layers-128filters/` to work i am using `sh sample_bazel.sh /content/magenta/magenta/models/coconet/coconet_checkpoint/coconet-64layers-128filters/` and getting a value error

ERROR:tensorflow:Couldn't match files for checkpoint /content/magenta/magenta/models/coconet/coconet_checkpoint/coconet-64layers-128filters/model.ckpt
Traceback (most recent call last):
  File ""coconet_sample.py"", line 692, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""coconet_sample.py"", line 66, in main
    gen_batch_size=FLAGS.gen_batch_size, piece_length=FLAGS.piece_length)
  File ""coconet_sample.py"", line 272, in run_generation
    temperature=temperature)
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/coconet/lib_tfsampling.py"", line 249, in run
    self.instantiate_sess_and_restore_checkpoint()
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/coconet/lib_tfsampling.py"", line 197, in instantiate_sess_and_restore_checkpoint
    saver.restore(sess, chkpt_fpath)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1264, in restore
    raise ValueError(""Can't load save_path when it is None."")
ValueError: Can't load save_path when it is None.",sure get sh work sh getting value error error could match recent call last file line module file line run main file line main file line file line run file line sess file line restore raise ca load none ca load none,issue,negative,positive,positive,positive,positive,positive
475257469,Pinging @czhuang as the file upstream still contains the wrong checkpoint configuration,file upstream still wrong configuration,issue,negative,negative,negative,negative,negative,negative
475179869,@hedonistrh that didn't work for me. changing config.hparams.max_seq_len doesn't effect the output file time. ,work effect output file time,issue,negative,neutral,neutral,neutral,neutral,neutral
474921514,"Hi @ricardobnjunior , unfortunately I'm still stuck at this point with no solution. Sorry.",hi unfortunately still stuck point solution sorry,issue,negative,negative,negative,negative,negative,negative
474914182,@ema987 Did you solve the problem? Can you share the solution with us ? ,solve problem share solution u,issue,negative,neutral,neutral,neutral,neutral,neutral
474721143,"It is funny that the tf-agents pip library is no longer available while its maintainer forces us to turn to the tf-agents-nightly (I got his reply to my issue there). So all the library depending on tf-agents are broken, including the tensor2tensor required by magenta. 
We have to wait tensor2tensor gets fixed first before fixing magenta.",funny pip library longer available maintainer u turn got reply issue library depending broken magenta wait fixed first fixing magenta,issue,negative,positive,positive,positive,positive,positive
474426355,@**cghawthorne** thank you. I think it is a good solution. I'll be happy to write a PR (first contribution to Magenta :) ) for your review. ,thank think good solution happy write first contribution magenta review,issue,positive,positive,positive,positive,positive,positive
474224963,"IMHO, your explanation is correct. Beam size is just a name given to the dimension having number of event sequences. This nomenclature makes sense as the number of event sequences would be equal to the beam size of beam search.
Hence, _**[beam_size, event_num, softmax_size]**_ is equivalent to _**[ num_of_event_sequences, event_in_event_sequence, softmax_size]**_
@cghawthorne @iansimon: Can you please confirm this? Thanks in advance.",explanation correct beam size name given dimension number event nomenclature sense number event would equal beam size beam search hence equivalent please confirm thanks advance,issue,positive,positive,neutral,neutral,positive,positive
474166745,"And a request: would be really helpful if you could facilitate it for other people/researchers working on this line of work to compare the training performance of their models with that of the published baseline Music Transformer model you have trained, so that they don't have to train the baseline themselves, which is expensive and time-consuming for people not having access to Google scale compute. For example, I'd like to see how slower or faster a new model I'm working on gets trained compared to such baseline. 
If I'm not mistaken, looks like the corresponding events.out.tfevents file(s) is what is needed in Tensorboard for comparing the training performance of different models, but a checkpoint file is not needed (in case you don't plan to release a checkpoint yet). Would it be possible to include such files (events and other necessary files), e.g., as part of your releases?

Thanks again, and for your patience with my many questions and requests.",request would really helpful could facilitate working line work compare training performance music transformer model trained train expensive people access scale compute example like see faster new model working trained mistaken like corresponding file training performance different file case plan release yet would possible include necessary part thanks patience many,issue,positive,positive,neutral,neutral,positive,positive
474154666,And another question: what is the recommended value for hparams.max_relative_position to go with dot_product_relative_v2? And are there other hparams that need to be set for relative_position?,another question value go need set,issue,negative,neutral,neutral,neutral,neutral,neutral
474109209,"Update: I am training a model with a modified decoder bottom (it has a modulo-encoding bias) using the maestro dataset. At 9K steps the eval loss is 2.6, and still trending down, but running very slow on a Mac. The model seems to have a serious failure mode in that it tends to generate sequences with very long time shifts; likely repeated back to back time shifts. I think this makes sense and can be explained, and points out that low NLL for eval or test sequences may not translate to high quality generation. Looks like other Transformer based language models have this failure mode too (e.g., GPT-2). Wanted to see how often you see this issue with your trained Music Transformer models (that are trained much longer), and if perhaps longer training will remove the issue (I tend to think it won't).

Thanks in advance.",update training model bottom bias maestro loss still running slow mac model serious failure mode generate long time likely repeated back back time think sense low test may translate high quality generation like transformer based language failure mode see often see issue trained music transformer trained much longer perhaps longer training remove issue tend think wo thanks advance,issue,negative,negative,neutral,neutral,negative,negative
474076274,"Hi @cghawthorne!
We made it with local usage in mind (users would need magenta of course). But with some modifications could be easily made into colab too I guess. We'd like to really get the notebooks published out and get some feedback before we go into more detail on the next ones. ",hi made local usage mind would need magenta course could easily made guess like really get get feedback go detail next,issue,positive,positive,positive,positive,positive,positive
474035318,"I think the most straightforward thing to do would be to add an InstrumentInfo message to NoteSequence, similar to PartInfo. It could contain the track name from pretty_midi, indexed on instrument id. During conversion back to pretty_midi, that field could be used to populate the track name, which pretty_midi would then include in the midi file.

Then, as long as your source has a track name that you can map to channel, all the information would be present. You could either modify whatever your output system is to use track name instead of channel, or add a post-processing step using Mido or something similar to remap the channels of the MIDI file based on their track names.

I'd be happy to review a PR for adding the InstrumentInfo message and carrying the track name across.",think straightforward thing would add message similar could contain track name indexed instrument id conversion back field could used populate track name would include file long source track name map channel information would present could either modify whatever output system use track name instead channel add step something similar remap file based track happy review message carrying track name across,issue,positive,positive,positive,positive,positive,positive
474029906,"In f272e6df4a9164fcaef77ed3ce8bc3c89b0a1f79, I removed the upper bound on the numpy version, which should hopefully simplify some of the issues you were having. Can you try installing with the latest code and see if that fixes the problem?",removed upper bound version hopefully simplify try latest code see problem,issue,negative,positive,positive,positive,positive,positive
474029190,"setup.py should depend on just `tensorflow`, not `tensorflow-gpu` unless you add the `--gpu` option, so I'm not sure why that happened. Do you have suggestions for how we should change our setup.py to better support locally-installed tensorflow versions?",depend unless add option sure change better support,issue,positive,positive,positive,positive,positive,positive
474028148,Magenta should be compatible with Python 3. Would you want to try updating the auto install script to use py3 and submit a PR if that works?,magenta compatible python would want try auto install script use submit work,issue,negative,neutral,neutral,neutral,neutral,neutral
474027557,Thanks for creating that notebook! Is it intended to run as a local Jupyter notebook or a [Colab](https://colab.research.google.com)?,thanks notebook intended run local notebook,issue,negative,positive,neutral,neutral,positive,positive
474024181,You can either use the mono_rnn config (https://github.com/tensorflow/magenta/blob/2cbc96922b7933549983a8d8845f46002974becb/magenta/models/melody_rnn/melody_rnn_model.py#L149) or set the min_note and max_note as you see fit. ,either use set see fit,issue,negative,positive,positive,positive,positive,positive
474011146,"I'm not familiar with Fedora, but you'll need to install the JACK library development package. The equivalent Debian/Ubuntu command is: `sudo apt-get install build-essential libasound2-dev libjack-dev`. You could try asking on a Fedora support forum to see what the Fedora version of that is.",familiar need install jack library development package equivalent command install could try support forum see version,issue,negative,positive,positive,positive,positive,positive
473594823,"If I'd like to train my midi in full range, should I modify the code fragment in magenta/magenta/music/melody_encoder_decoder.py?  Or I just need to set the min to 0 and max note to 128.

`def events_to_input(self, events, position):
    """"""Returns the input vector for the given position in the melody.
    Returns a self.input_size length list of floats. Assuming
    self._min_note = 48, self._note_range = 36, two lookback distances, and
    seven binary counters, then self.input_size = 74. Each index represents a
    different input signal to the model.
    Indices [0, 73]:
    [0, 35]: A note is playing at that pitch [48, 84).
    36: Any note is playing.
    37: Silence is playing.
    38: The current event is the note-on event of the currently playing note.
    39: Whether the melody is currently ascending or descending.
    40: The last event is repeating (first lookback distance).
    41: The last event is repeating (second lookback distance).
    [42, 48]: Time keeping toggles.
    49: The next event is the start of a bar.
    [50, 61]: The keys the current melody is in.
    [62, 73]: The keys the last 3 notes are in.
`",like train full range modify code fragment need set min note self position input vector given position melody length list assuming two seven binary index different input signal model index note pitch note silence current event event currently note whether melody currently ascending descending last event first distance last event second distance time keeping next event start bar current melody last,issue,negative,positive,neutral,neutral,positive,positive
472758099,"Welcome :) @jimmyai  

With this code block, you can generate 5 **2-bar** melody samples. 

```sh
music_vae_generate \
--config=cat-mel_2bar_big \
--checkpoint_file=/path/to/music_vae/checkpoints/cat-mel_2bar_big.tar \
--mode=sample \
--num_outputs=5 \
--output_dir=/tmp/music_vae/generated
```

So that, you should increase the bar length. You can use *hierdec-mel_16bar* Also, you can generate more sample and concatenate those samples. :) Before this method, we can check source code and see are there any place we can change the length of output.

Lets check the [source code](https://github.com/tensorflow/magenta/blob/master/magenta/models/music_vae/music_vae_generate.py#L167). 

```python
  elif FLAGS.mode == 'sample':
    logging.info('Sampling...')
    results = model.sample(
        n=FLAGS.num_outputs,
        length=config.hparams.max_seq_len,
        temperature=FLAGS.temperature)

```

We should increase the length. So that, you should change the [config file.](https://github.com/tensorflow/magenta/blob/master/magenta/models/music_vae/configs.py#L51) 

If you want, I can give more detailed explanation, when I have time.",welcome code block generate melody sh increase bar length use also generate sample concatenate method check source code see place change length output check source code python increase length change file want give detailed explanation time,issue,positive,positive,positive,positive,positive,positive
472756423,"**@cghawthorne** I understand that changes to pretty_midi are not trivial; however I’ve spent tens hours working with Magenta for our project, and I really want to continue to use it, even more intensively. I couldn't come up with a workaround that can fit a long term solution. I would appreciate if you can help me find a workaround to maintain the midi channels information. I don’t mind to add any code at my side or contribute to Magenta. Thanks!",understand trivial however spent working magenta project really want continue use even intensively could come fit long term solution would appreciate help find maintain information mind add code side contribute magenta thanks,issue,positive,positive,positive,positive,positive,positive
472699021,The output of datagen will be examples with lists of integer indices.  You should be able to use tf.one_hot on those.,output integer index able use,issue,negative,positive,positive,positive,positive,positive
472639112,"Reporting that I have been able to pass beyond the abort issue above by setting make_image_summary=False, in transformer_decoder() of transformer.py. Didn't see an alternative way of overriding the default True value.

",able pas beyond abort issue setting see alternative way default true value,issue,positive,positive,positive,positive,positive,positive
472611917,"I have modified setup.py to have tensorflow == 1.12.0, and tensorflow-probability == 0.5.0, in order to run t2t_trainer. But then right after ""Saving checkpoint for 0 ..."" I get the following without further insight:

F tensorflow/core/lib/png/png_io.cc:341] 'image' Must be non NULL
Abort trap: 6

I wonder if this is also a dependency issue. Would appreciate your help fixing/debugging this issue.

Thanks.",order run right saving get following without insight must non null abort trap wonder also dependency issue would appreciate help issue thanks,issue,positive,positive,positive,positive,positive,positive
472607334,"> I don't find its propagation to noteSequence in def midi_to_note_sequence(midi_data):

@cghawthorne will have to answer this, I'm not sure if note sequences use track names or not (and if not, why not).

> If you can add the midi channel information it could really help!

I don't have any plans to add channel information to `pretty_midi`. It's not within the scope of the project since it's not a musically meaningful concept.",find propagation answer sure note use track add channel information could really help add channel information within scope project since musically meaningful concept,issue,positive,positive,positive,positive,positive,positive
472606512,"Looking at pretty_midi, in `def _load_instruments(self, midi_data):` 
I can see the track name events, however I don't find its propagation to noteSequence in 
`def midi_to_note_sequence(midi_data): ` . Can you please note the exact place?
I tried to make another workaround by creating an ""almost"" empty channel by using one note with velocity = 0. Unfortunately it is ignored by prety_midi. So currently I create one note with low velocity and non-existing pitch, so this empty channel will exist and keep the midi channels order. 
If you can add the midi channel information it could really help!
",looking self see track name however find propagation please note exact place tried make another almost empty channel one note velocity unfortunately currently create one note low velocity pitch empty channel exist keep order add channel information could really help,issue,negative,positive,neutral,neutral,positive,positive
472524007,"Which model are you using to generate sequences?

If you are using Melody RNN, you should increase the **number of steps** parameter. [Source](https://github.com/tensorflow/magenta/blob/master/magenta/models/melody_rnn/melody_rnn_generate.py#L57) 

It is [originally](https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#generate-a-melody) 128, however, you can increase it like 512. :)

Example:
```bash
BUNDLE_PATH=<absolute path of .mag file>
CONFIG=<one of 'basic_rnn', 'lookback_rnn', or 'attention_rnn', matching the bundle>

melody_rnn_generate \
--config=${CONFIG} \
--bundle_file=${BUNDLE_PATH} \
--output_dir=/tmp/melody_rnn/generated \
--num_outputs=10 \
--num_steps=512 \
--primer_melody=""[60]""
```",model generate melody increase number parameter source originally however increase like example bash absolute path file one matching bundle,issue,positive,positive,positive,positive,positive,positive
472486720,"> Concerning the track name events, if the channel is empty (no notes) pretty_midi fill it with the next channel. I guess in this case the track names wouldn't help, right?

I'm sorry, I don't know what you mean.",concerning track name channel empty fill next channel guess case track would help right sorry know mean,issue,negative,negative,negative,negative,negative,negative
472294123,"Thanks for your answers. Actually, this functionality is required for my music program. I'm using DAW with third party sound (VST) libraries to create basic music tracks. Then, I export the midi files and use it within my python program. I'm doing midi manipulations as well as some AI stuff. All manipulations are done using Magenta and noteSequence. Then, I convert it back to midi and produce wave file with high quality, using this VST. I was trying to do direct conversion to wave using SF2 libraries, but the quality is not good enough so I have to use a better sampler.
Concerning the track name events, if the channel is empty (no notes) pretty_midi fill it with the next channel. I guess in this case the track names wouldn't help, right?
Thanks!",thanks actually functionality music program daw third party sound create basic music export use within python program well ai stuff done magenta convert back produce wave file high quality trying direct conversion wave quality good enough use better sampler concerning track name channel empty fill next channel guess case track would help right thanks,issue,positive,positive,positive,positive,positive,positive
472217435,"Yah, that should be pretty straightforward. If you look in datasets.py you see that it's actually reading waveforms as the input data. I think you just need to write a script to turn  you waveforms into a tfrecord file and read from it in a similar way. (wave_to_data is specified in the subclass DataMelHelper)",yah pretty straightforward look see actually reading input data think need write script turn file read similar way subclass,issue,negative,positive,positive,positive,positive,positive
472108169,"Yes, `pretty_midi` does not store or preserve any information about which notes happened on which channel. I don't have any plans to add this functionality, since it does not really map to anything intuitive about music. However, I'd be happy to be convinced that this is important.

A simple workaround which I think should work is to add track name events to each of the channels. This name will propagate into the Instrument, and will be written out onto the instrument's channel when using `pretty_midi.PrettyMIDI.write`. You could do some simple post-processing to re-assign different channels based on their track names.",yes store preserve information channel add functionality since really map anything intuitive music however happy convinced important simple think work add track name name propagate instrument written onto instrument channel could simple different based track,issue,positive,positive,positive,positive,positive,positive
472096913,@craffel am I correct in understanding that pretty_midi doesn't preserve this information?,correct understanding preserve information,issue,negative,neutral,neutral,neutral,neutral,neutral
471988801,"Thanks. So any advise how to use Magenta for this midi manipulation, keeping the consistancy of the midi channels ?",thanks advise use magenta manipulation keeping,issue,negative,positive,positive,positive,positive,positive
471675398,"Our MIDI conversion code preserves the concept of ""instrument"" (all events in a track with the same program and channel) and what MIDI program each instrument should have. Unfortunately, we do not specifically preserve MIDI channel, so when we convert from NoteSequence to MIDI, the channel assignment is arbitrary (but the programs should be correct).",conversion code concept instrument track program channel program instrument unfortunately specifically preserve channel convert channel assignment arbitrary correct,issue,negative,negative,negative,negative,negative,negative
471170487,"@Jaehaerys-III May you share the _exact_ output of the command. So, we can try to understand the problem 👩‍💻 ",may share output command try understand problem,issue,negative,neutral,neutral,neutral,neutral,neutral
471144937,"Docker isn't working... I install tensorflow/magenta on my system using
docker run -it -p 6006:6006 -v /tmp/magenta:/magenta-data tensorflow/magenta
But then afterwards I try to use the melody_rnn_generate command in docker and it doesn't recognise the function.",docker working install system docker run afterwards try use command docker function,issue,negative,neutral,neutral,neutral,neutral,neutral
471138598,"> The error message about missing `MThd` at the beginning of the file seems to imply the MIDI file is not valid. Are you able to open the MIDI in other programs successfully (e.g., GarageBand on Mac)?

Yes the MIDI file works elsewhere. I can open it in other programs, such as MIDI visualisations and Audacity. I'm currently trying to do @hedonistrh 's method using Docker :)",error message missing beginning file imply file valid able open successfully mac yes file work elsewhere open audacity currently trying method docker,issue,negative,positive,positive,positive,positive,positive
470245946,I am using magenta via [**Docker** installation](https://github.com/tensorflow/magenta#docker). My os is _OsX Mojave_. ,magenta via docker installation o,issue,negative,neutral,neutral,neutral,neutral,neutral
470219410,Can you please tell which version of magenta are you using. Also can you provide with Your OS and other specs.,please tell version magenta also provide o spec,issue,negative,neutral,neutral,neutral,neutral,neutral
469847081,"Shit, I missed it too.  Intended to use GPU, thanks for checking it out,
Curtis!

Ok.

On Tuesday, March 5, 2019, cghawthorne <notifications@github.com> wrote:

> Oh sorry, I think I missed an important part of the error last time. It
> looks like you're training on just CPU. If that's the case, you'll need to
> add the argument --hparams=use_cudnn=false to your training job. Note
> that if you're training on CPU, it will take a very long time.
>
> Feel free to reopen if you're still having problems.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1449#issuecomment-469836858>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/Ad-IDn2k3R30YCRgs9Z_FCAB2P6X683Tks5vTs2WgaJpZM4bFlc7>
> .
>


-- 
Jason St. George
",intended use thanks march wrote oh sorry think important part error last time like training case need add argument training job note training take long time feel free reopen still thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
469838110,"The error message about missing `MThd` at the beginning of the file seems to imply the MIDI file is not valid. Are you able to open the MIDI in other programs successfully (e.g., GarageBand on Mac)?",error message missing beginning file imply file valid able open successfully mac,issue,negative,positive,positive,positive,positive,positive
469836858,"Oh sorry, I think I missed an important part of the error last time. It looks like you're training on just CPU. If that's the case, you'll need to add the argument `--hparams=use_cudnn=false` to your training job. Note that if you're training on CPU, it will take a very long time.

Feel free to reopen if you're still having problems.",oh sorry think important part error last time like training case need add argument training job note training take long time feel free reopen still,issue,negative,positive,neutral,neutral,positive,positive
469795300,Please reopen at https://github.com/tensorflow/magenta-studio/issues if you're still having this problem.,please reopen still problem,issue,negative,neutral,neutral,neutral,neutral,neutral
469794214,"If you're still having this issue, please reopen at https://github.com/tensorflow/magenta-studio",still issue please reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
469773298,"Yes, I pulled the latest checkpoint again at the link you provided, and wiped my venv to do a fresh magenta pip install with the new checkpoint, but still was unable to fix the exact same error.  

I'm wondering if the current pip release is not updated to reflect the new changes in the model's hparams?

For completeness here's the full stack trace:

` INFO:tensorflow:Restoring parameters from /home/jason/magenta/train/model.ckpt
Traceback (most recent call last):
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _run_fn
    self._extend_graph()
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1352, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by {{node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams}}with these attrs: [seed=0, dropout=0, num_params=16, T=DT_FLOAT, input_mode=""linear_input"", direction=""bidirectional"", rnn_mode=""lstm"", seed2=0]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  <no registered kernels>

	 [[{{node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1276, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py:148) with these attrs: [seed=0, dropout=0, num_params=16, T=DT_FLOAT, input_mode=""linear_input"", direction=""bidirectional"", rnn_mode=""lstm"", seed2=0]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  <no registered kernels>

	 [[node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py:148) ]]

Caused by op 'onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams', defined at:
  File ""onsets_frames_transcription_transcribe.py"", line 240, in <module>
    console_entry_point()
  File ""onsets_frames_transcription_transcribe.py"", line 234, in console_entry_point
    tf.app.run(main)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""onsets_frames_transcription_transcribe.py"", line 182, in main
    transcription_session = initialize_session(acoustic_checkpoint, hparams)
  File ""onsets_frames_transcription_transcribe.py"", line 109, in initialize_session
    model.get_model(batch, hparams, is_training=False)
  File ""/home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py"", line 231, in get_model
    is_training=is_training)
  File ""/home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py"", line 203, in acoustic_model
    bidirectional=hparams.bidirectional)
  File ""/home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py"", line 166, in lstm_layer
    rnn_dropout_drop_amt, is_training, bidirectional)
  File ""/home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py"", line 148, in cudnn_lstm_layer
    outputs, _ = lstm(inputs_t, (h, c), training=is_training)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 530, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 538, in __call__
    self._maybe_build(inputs)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1603, in _maybe_build
    self.build(input_shapes)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py"", line 353, in build
    opaque_params_t = self._canonical_to_opaque(weights, biases)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py"", line 476, in _canonical_to_opaque
    direction=self._direction)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py"", line 1343, in cudnn_rnn_canonical_to_opaque_params
    name=name)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py"", line 685, in cudnn_rnn_canonical_to_params
    seed=seed, seed2=seed2, name=name)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/jason/onsets/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py:148) with these attrs: [seed=0, dropout=0, num_params=16, T=DT_FLOAT, input_mode=""linear_input"", direction=""bidirectional"", rnn_mode=""lstm"", seed2=0]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  <no registered kernels>

	 [[node onsets/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at /home/jason/onsets/lib/python3.6/site-packages/magenta/models/onsets_frames_transcription/model.py:148) ]]
 `",yes latest link provided fresh magenta pip install new still unable fix exact error wondering current pip release reflect new model completeness full stack trace recent call last file line return file line file line registered support used node bidirectional registered registered registered node handling exception another exception recent call last file line restore file line run file line file line file line raise type message registered support used node defined bidirectional registered registered registered node defined defined file line module file line main file line run main file line main file line batch file line file line file line bidirectional file line file line super layer self file line file line file line build file line file line file line file line file line return file line file line see registered support used node defined bidirectional registered registered registered node defined,issue,positive,positive,positive,positive,positive,positive
469362269,"Yeah, installing via pip rather than setup.py (even if it's pip -e .) definitely does a better job of handling dependencies. Glad you go things working.",yeah via pip rather even pip definitely better job handling glad go working,issue,positive,positive,positive,positive,positive,positive
469317628,"Are you using [_Docker container_](https://github.com/tensorflow/magenta/blob/master/README.md#docker) or _Conda_ installation?

_Ps. I am trying to use Magenta RNN and I wrote my experiments' result [here](https://github.com/hedonistrh/TurkishMusicGeneration/blob/5876b823cf4a9455695586c96692901515ab061e/tmg_open_source_experiment.md). It is draft, however, you can check it. :)_",installation trying use magenta wrote result draft however check,issue,negative,neutral,neutral,neutral,neutral,neutral
469130211,"How do you override the pkg_resources.DistributionNotFound: The 'numpy<=1.15.4,>=1.14.6' distribution was not found and is required by magenta
error?",override distribution found magenta error,issue,negative,neutral,neutral,neutral,neutral,neutral
469066336,"So in my conda environment, I would typically install all magenta dependencies with pip install magenta-gpu. If I don't do this and directly go with setup.py it fails to install many of the other dependencies that are required. It is in this step that scipy 1.2.1 is installed and after that during the setup.py installation scipy 1.2.0 is also installed making both the versions useless. But after uninstalling both versions and reinstalling scipy 1.2.0 solves the problem.",environment would typically install magenta pip install directly go install many step installation also making useless problem,issue,negative,negative,neutral,neutral,negative,negative
469033795,Thanks for sharing. I encountered the same error with importing tensorflow. And upgrading numpy seems working. Thanks.,thanks error working thanks,issue,negative,positive,positive,positive,positive,positive
468890215,"I figured it out finally. To make 4 channels, the last step remained:

```diff
+      for n in synth_ns.notes:
+        n.instrument = 2
+        n.program = 89
+      for n in mel_ns.notes:
+        n.instrument = 3
+        n.program = 29
       for n in bass_ns.notes:
         n.instrument = 1
         n.program = ELECTRIC_BASS_PROGRAM
       for n in drums_ns.notes:
         n.instrument = 9      
```",figured finally make last step,issue,negative,neutral,neutral,neutral,neutral,neutral
468834389,Thank you for your responses. Would love to check out the mono_rnn!,thank would love check,issue,positive,positive,positive,positive,positive,positive
468747599,"We have no melody rn paper, so you can cite the blog post as in that first article. For music vae please cite:
```
@inproceedings{47078,
title	= {A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music},
author	= {Adam Roberts and Jesse Engel and Colin Raffel and Curtis Hawthorne and Douglas Eck},
year	= {2018},
URL	= {http://proceedings.mlr.press/v80/roberts18a.html},
booktitle	= {International Conference on Machine Learning (ICML)}
}
```",melody paper cite post first article music please cite title hierarchical latent vector model learning structure music author colin year international conference machine learning,issue,negative,positive,positive,positive,positive,positive
468746773,I added a new model config called `mono_rnn` that uses the full range. I think we just need to publish a bundle for it. Would that be of interest?,added new model full range think need publish bundle would interest,issue,negative,positive,positive,positive,positive,positive
468656915,"I think, the reason comes from [the model.](https://github.com/tensorflow/magenta/blob/master/magenta/models/melody_rnn/melody_rnn_model.py)

```
DEFAULT_MIN_NOTE = 48
DEFAULT_MAX_NOTE = 84
```

Also, if you check [melody encoder-decoder](https://github.com/tensorflow/magenta/blob/master/magenta/music/melody_encoder_decoder.py), you can see that
```python
def events_to_input(self, events, position):
    """"""Returns the input vector for the given position in the melody.
    Returns a self.input_size length list of floats. Assuming
    self._min_note = 48, self._note_range = 36, two lookback distances, and
    seven binary counters, then self.input_size = 74. Each index represents a
    different input signal to the model.
    Indices [0, 73]:
    [0, 35]: A note is playing at that pitch [48, 84).
    36: Any note is playing.
    37: Silence is playing.
    38: The current event is the note-on event of the currently playing note.
    39: Whether the melody is currently ascending or descending.
    40: The last event is repeating (first lookback distance).
    41: The last event is repeating (second lookback distance).
    [42, 48]: Time keeping toggles.
    49: The next event is the start of a bar.
    [50, 61]: The keys the current melody is in.
    [62, 73]: The keys the last 3 notes are in.

```

",think reason come model also check melody see python self position input vector given position melody length list assuming two seven binary index different input signal model index note pitch note silence current event event currently note whether melody currently ascending descending last event first distance last event second distance time keeping next event start bar current melody last,issue,negative,positive,neutral,neutral,positive,positive
468609228,"In [this paper](https://arxiv.org/pdf/1712.05274.pdf), they cited like:

> Waite,  E.;  Eck,  D.;  Roberts,  A.;  and  Abolafia,  D.   2016.Project  magenta:  Generating  long-term  structure  in  songs and storie

Also, [in this paper](https://arxiv.org/pdf/1709.01620.pdf), they cited MusicVae like:

> Adam Roberts, Jesse Engel, Colin Raffel, Ian Simon, and Curtis Hawthorne.  MusicVAE: Creating a palette for musical scores withmachine learning, March 2018. https://magenta.tensorflow.org/music-vae.

I am not quite sure about the _paper_, however, i think, you can directly cite the blogpost. :)",paper like magenta generating structure also paper like colin palette musical learning march quite sure however think directly cite,issue,positive,positive,positive,positive,positive,positive
467568980,"Thanks for the response. The issue still exists when using conda also. The system Python installation was on a new PC with not much applications installed, so there is less chance of any corrupted packages. But I still installed conda to check if it was a corruption issue; however, I still get the exact same errors when trying to use either NumPy 1.15.4 or 1.16.1.",thanks response issue still also system python installation new much le chance corrupted still check corruption issue however still get exact trying use either,issue,positive,positive,positive,positive,positive,positive
467206064,That sounds like a corrupt numpy installation. I've seen problems like that before when a user numpy installation is interacting with a site numpy install. Can you try using [conda](https://conda.io/en/latest/miniconda.html) (or virtualenv) to set up an isolated environment that is definitely separate from your system python installation?,like corrupt installation seen like user installation site install try set isolated environment definitely separate system python installation,issue,positive,negative,negative,negative,negative,negative
467204732,"Can you give some more details on how installing the magenta pip package ended up installing scipy-1.2.1? Our setup.py should restrict it to 1.2.0: https://github.com/tensorflow/magenta/blob/master/setup.py#L53

That said, I'm not sure why 1.2.1 would cause that error anyway.",give magenta pip package ended restrict said sure would cause error anyway,issue,negative,positive,positive,positive,positive,positive
467169812,"Hi,

Thanks for your response. This is the error I get when I try to import either Magenta or Tensorflow with Numpy 1.15.4 installed.

```
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
ImportError: numpy.core.multiarray failed to import

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""<frozen importlib._bootstrap>"", line 980, in _find_and_load
SystemError: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set
ImportError: numpy.core._multiarray_umath failed to import
ImportError: numpy.core.umath failed to import
2019-02-25 15:17:31.842994: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr
```
[Magenta Error with Numpy 1.16.1.txt](https://github.com/tensorflow/magenta/files/2902475/Magenta.Error.with.Numpy.1.16.1.txt)

When I use Numpy 1.16.1, Tensorflow imports successfully, but Magenta continues to give errors. I've attached a notepad with the error log when I try to import Magenta using Numpy 1.16.1, as it is very long.

I have tried uninstalling, reinstalling, and using different versions of NumPy, but to no avail. Appreciate any help regarding this issue.",hi thanks response error get try import either magenta module import exception direct cause following exception recent call last file frozen line class returned result error set import import check magenta error use successfully magenta give attached error log try import magenta long tried different avail appreciate help regarding issue,issue,negative,positive,positive,positive,positive,positive
467147202,"I suspect that your tensorflow installation has maybe gotten messed up due to the different packages. The `tensorflow` and `tensorflow-gpu` packages end up installing many of the same files and if you install one after the other, it will just overwrite a lot of those files. The only difference between `magenta` and `magenta-gpu` is whether the package depends on `tensorflow` or `tensorflow-gpu`.

If you need to use a custom compiled version of TensorFlow, I'd recommend the following:
- Install the `magenta` package.
- `pip uninstall tensorflow`, `pip uninstall tensorflow-gpu` (to ensure that you've removed all tensorflow files from your virtualenv)
- Install your custom built version of tensorflow.",suspect installation maybe gotten due different end many install one overwrite lot difference magenta whether package need use custom version recommend following install magenta package pip pip ensure removed install custom built version,issue,negative,positive,neutral,neutral,positive,positive
467144795,"Can you be more specific about the errors you're seeing with TensorFlow or Magenta with the different numpy versions? Either 1.15.4 or 1.16.1 should work fine with either Magenta or TensorFlow, we just restrict to 1.15.4 because newer versions cause problems with our pylint checks.",specific seeing magenta different either work fine either magenta restrict cause,issue,negative,positive,positive,positive,positive,positive
467143856,"That chess_master.py file is also a part of networkx, so I think the problem is still somehow related to that package. I'd suggest asking on the networkx issue tracker.",file also part think problem still somehow related package suggest issue tracker,issue,negative,neutral,neutral,neutral,neutral,neutral
467136180,"Yeah, unfortunately it does run quite slow. For the paper, we distributed training across 3 machines with async updates, each with V100 GPUs, and even that took something like a week to train.

I'm working on some updates now that will allow training across multiple local GPUs, and at some point I think we'll need to do the audio augmentation at dataset creation time.",yeah unfortunately run quite slow paper distributed training across even took something like week train working allow training across multiple local point think need audio augmentation creation time,issue,positive,negative,negative,negative,negative,negative
466705117,"Evening,

I have some more questions:

1. I'm using you save model text that you have posted in this post, but on the separable convs. I have tried to change 


         _var_names = [
        'transformer/residual/residual1/conv1/weights',
        'transformer/residual/residual1/conv2/weights',
                                  ...._

with 

 _var_names = [
        'transformer/residual/residual1/dilated_conv1/StyleNorm/weights',
        'transformer/residual/residual1/dilated_conv2/StyleNorm/weights',
                                ...._


But it's apparently wrong... Do you have any ideas what's wrong?

2. Then I seems to get error in the  slim.get_variables_to_restore() part in,

            _init_fn = slim.assign_from_checkpoint_fn(checkpoint,
                                             slim.get_variables_to_restore())_

Where the different dilated_conv layers cannot be found. I guess that because they are not part of the ordinary slim library? I have tried to work my way around this by renaming back the layers to suit the slim build. But this sees to be a rather dumb way to do it? Do you have any suggestions have to work around it? 

Thank you

Best regards,
Markus",evening save model text posted post separable tried change apparently wrong wrong get error part different found guess part ordinary slim library tried work way around back suit slim build rather dumb way work around thank best,issue,negative,negative,neutral,neutral,negative,negative
466641477,"Ajit, I will do it your way :) Thank you for the fast answer!

",way thank fast answer,issue,negative,positive,positive,positive,positive,positive
466641407,"Do you need a pretrained transformer net? I just trained mine from scratch.
(of course the style prediction net was the original one from magenta)

On Sat, Feb 23, 2019, 8:40 PM Markus Ekvall <notifications@github.com>
wrote:

> Thank you for a quick answer!
>
> The file you sent contains these MirrorPads, do you have any checkpoint
> folder with constant padding instead? In addition, do you have the
> checkpoint folder rather than the SaveModel folder? So I can make my own
> training, or it's maybe a simple way to go from SavedModel => Checkpoint
> Folder (couldn't find any good answer on google)?
>
> Best regards,
>
> Markus
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1437#issuecomment-466641269>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ARg1VvJ0vR27x0WGdsQoiNosUoYmIdsVks5vQSipgaJpZM4a5Nl5>
> .
>
",need transformer net trained mine scratch course style prediction net original one magenta sat wrote thank quick answer file sent folder constant padding instead addition folder rather folder make training maybe simple way go folder could find good answer best reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
466641269,"Thank you for a quick answer! 

The file you sent contains these MirrorPads, do you have any checkpoint folder with constant padding instead? In addition, do you have the checkpoint folder rather than the SaveModel folder? So I can make my own training, or it's maybe a simple way to go from SavedModel => Checkpoint Folder (couldn't find any good answer on google)?

Best regards,

Markus 

",thank quick answer file sent folder constant padding instead addition folder rather folder make training maybe simple way go folder could find good answer best,issue,positive,positive,positive,positive,positive,positive
466605333,"Figured out the issue.
`pip install magenta-gpu` installs scipy-1.2.1
which is incompatible and while running setup.py it also installs scipy-1.2.0
after uninstalling both versions and installing scipy-1.2.0 after `python setup.py install` started working fine.",figured issue pip install incompatible running also python install working fine,issue,negative,positive,positive,positive,positive,positive
466267737,"Thanks, I was having the same issue. Splitting my midi files also seemed to work ",thanks issue splitting also work,issue,negative,positive,positive,positive,positive,positive
466107185,"We did make some significant changes to the model recently (2ffbee556e7f58696352aa98ddca8d6e82b9330d), and with those changes, we released an updated checkpoint. Are you sure you have both the latest code and the latest [checkpoint](https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/maestro_checkpoint.zip)?",make significant model recently sure latest code latest,issue,negative,positive,positive,positive,positive,positive
465760812,"Hey @RootofalleviI, I would like to ask that how we can see details of _NoteSequence segment_ :) Thanks for help ^^",hey would like ask see thanks help,issue,positive,positive,positive,positive,positive,positive
465754880,passing --data_dir as a flag of t2t_decoder worked. thanks!,passing flag worked thanks,issue,negative,positive,positive,positive,positive,positive
465727230,"@cghawthorne I'm running in to this same issue. Pip install networkx works fine, but pip install magenta still fails. 

It looks like it fails on this line:
 error: can't copy 'examples\drawing\chess_masters.py': doesn't exist or not a regular file

Thanks!",running issue pip install work fine pip install magenta still like line error ca copy exist regular file thanks,issue,positive,positive,positive,positive,positive,positive
465689067,"The error is happening because FLAGS.data_dir is None.  BTW the way flags work (which I personally think is a little scary) is that they can be defined in any of the imports, not just the module being executed.  Did you try passing --data_dir and get an unknown flag error?

It's also possible there's an issue with tensor2tensor.",error happening none way work personally think little scary defined module executed try passing get unknown flag error also possible issue,issue,negative,negative,negative,negative,negative,negative
465520707,"i'm getting same error.

i don't see --data_dir as a flag for t2t_decoder. do you mean setting TRAIN_DIR to same directory as --data_dir during training?",getting error see flag mean setting directory training,issue,negative,negative,negative,negative,negative,negative
465279772,Can you try setting --data_dir to the same value you used for training?,try setting value used training,issue,negative,neutral,neutral,neutral,neutral,neutral
465244036,"This looks like a problem with the `networkx` package. Can you try just doing `pip install networkx` by itself? If that doesn't work, it might just be an issue with their package on Windows, and you could try asking on their issue tracker: https://github.com/networkx/networkx/issues",like problem package try pip install work might issue package could try issue tracker,issue,negative,neutral,neutral,neutral,neutral,neutral
465219107,"Yeah, my bad. It's the opposite way.",yeah bad opposite way,issue,negative,negative,negative,negative,negative,negative
465173316,"oh weird, I had to do the opposite -> replace the ""green"" with the ""red"" and now it's training. i must have an old version in my environment?",oh weird opposite replace green red training must old version environment,issue,negative,negative,negative,negative,negative,negative
465169690,Clicked on the commit link that Kangmo posted and then I manually deleted the code in red and pasted the code in green in it's place and then saved the file. Now I don't get that error anymore.,commit link posted manually code red pasted code green place saved file get error,issue,negative,negative,neutral,neutral,negative,negative
465168084,"using this command:

DATA_DIR=/Users/xxxxxx/transformer-model/tfrecord/
HPARAMS_SET=transformer_base
MODEL=transformer
PROBLEM=score2perf_maestro_language_uncropped_aug
TRAIN_DIR=/Users/xxxxxx/transformer-model/training/

HPARAMS=\
""label_smoothing=0.0,""\
""max_length=0,""\
""max_target_seq_length=2048""

t2t_trainer \
  --data_dir=""${DATA_DIR}"" \
  --hparams=${HPARAMS} \
  --hparams_set=${HPARAMS_SET} \
  --model=${MODEL} \
  --output_dir=${TRAIN_DIR} \
  --problem=${PROBLEM} \
  --train_steps=1000000


i get the following error:

Traceback (most recent call last):
  File ""/anaconda3/envs/magenta/bin/t2t_trainer"", line 10, in <module>
    sys.exit(console_entry_point())
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/tensor2tensor/t2t_trainer.py"", line 34, in console_entry_point
    tf.app.run(main)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/tensor2tensor/t2t_trainer.py"", line 29, in main
    t2t_trainer.main(argv)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py"", line 390, in main
    exp = exp_fn(create_run_config(hparams), hparams)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py"", line 806, in experiment_fn
    return create_experiment(run_config, hparams, *args, **kwargs)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py"", line 696, in create_experiment
    add_problem_hparams(hparams, problem_name)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensor2tensor/utils/trainer_lib.py"", line 817, in add_problem_hparams
    p_hparams = problem.get_hparams(hparams)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/tensor2tensor/data_generators/problem.py"", line 499, in get_hparams
    ret = self.hparams(hp, model_hparams)
  File ""/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/score2perf/score2perf.py"", line 162, in hparams
    defaults.modality = {'targets': t2t_modalities.ModalityType.SYMBOL}
AttributeError: 'module' object has no attribute 'ModalityType'
",command model problem get following error recent call last file line module file line main file line run main file line main file line main file line return file line file line file line ret file line object attribute,issue,negative,positive,neutral,neutral,positive,positive
465160009,I'm getting the same error. how did you fix it? how do i revert to a previous commit?,getting error fix revert previous commit,issue,negative,negative,negative,negative,negative,negative
464798008,"Right, that's also something I've been meaning to contribute but so far haven't had the time to rewrite it in a state that fits in with the rest of the Magenta codebase.

Not sure if you've seen https://reiinakano.github.io/arbitrary-image-stylization-tfjs but there's a noticeable quality drop + noticeable speed boost when separable convs are used.

If it helps I'll dump most of the relevant code here. Take note of the `dilate` argument I add in the methods (I keep confusing separable convs for dilated convs so this explains the weird naming, sorry). The point is to just replace the conv layers with separable convs. Note that I run this in a Colab notebook so I use a class with static methods in lieu of a separate module (it's very ugly yes):

```python
class model_util:
  @staticmethod
  def conv2d(input_,
           kernel_size,
           stride,
           num_outputs,
           scope,
           activation_fn=tf.nn.relu,
           dilate=False,
           variables_collections=None):
    """"""Same-padded convolution with mirror padding instead of zero-padding.
    This function expects `kernel_size` to be odd.
    Args:
      input_: 4-D Tensor input.
      kernel_size: int (odd-valued) representing the kernel size.
      stride: int representing the strides.
      num_outputs: int. Number of output feature maps.
      scope: str. Scope under which to operate.
      activation_fn: activation function.
      dilate: If True, uses slim.separable_conv2d instead of slim.conv2d
      variables_collections: optional list of collections for variables
    Returns:
      4-D Tensor output.
    Raises:
      ValueError: if `kernel_size` is even.
    """"""
    if kernel_size % 2 == 0:
      raise ValueError('kernel_size is expected to be odd.')
    padding = kernel_size // 2
    padded_input = tf.pad(
        input_, [[0, 0], [padding, padding], [padding, padding], [0, 0]],
        mode='REFLECT') #REFLECT/CONSTANT
    if not dilate:
      return slim.conv2d(
        padded_input,
        padding='VALID',
        kernel_size=kernel_size,
        stride=stride,
        num_outputs=num_outputs,
        activation_fn=activation_fn,
        scope=scope)
    else:
      return slim.separable_conv2d(
        padded_input,
        padding='VALID',
        kernel_size=kernel_size,
        stride=stride,
        num_outputs=num_outputs,
        activation_fn=activation_fn,
        scope=scope,
        variables_collections=variables_collections
      )
  
  @staticmethod
  def upsampling(input_,
               kernel_size,
               stride,
               num_outputs,
               scope,
               activation_fn=tf.nn.relu,
               dilate=False,
               variables_collections=None):
    """"""A smooth replacement of a same-padded transposed convolution.
    This function first computes a nearest-neighbor upsampling of the input by a
    factor of `stride`, then applies a mirror-padded, same-padded convolution.
    It expects `kernel_size` to be odd.
    Args:
      input_: 4-D Tensor input.
      kernel_size: int (odd-valued) representing the kernel size.
      stride: int representing the strides.
      num_outputs: int. Number of output feature maps.
      scope: str. Scope under which to operate.
      activation_fn: activation function.
      dilate: If True, uses slim.separable_conv2d instead of slim.conv2d
      variables_collections: optional list of collections for variables
    Returns:
      4-D Tensor output.
    Raises:
      ValueError: if `kernel_size` is even.
    """"""
    if kernel_size % 2 == 0:
      raise ValueError('kernel_size is expected to be odd.')
    with tf.variable_scope(scope):
      shape = tf.shape(input_)
      height = shape[1]
      width = shape[2]
      upsampled_input = tf.image.resize_nearest_neighbor(
          input_, [stride * height, stride * width])
      return model_util.conv2d(
          upsampled_input,
          kernel_size,
          1,
          num_outputs,
          'conv' if not dilate else 'dilate_conv',
          activation_fn=activation_fn,
          dilate=dilate,
          variables_collections=variables_collections
          )

  @staticmethod
  def residual_block(
      input_, 
      kernel_size, 
      scope, 
      activation_fn=tf.nn.relu,
      dilate=False,
      variables_collections=None):
    """"""A residual block made of two mirror-padded, same-padded convolutions.
    This function expects `kernel_size` to be odd.
    Args:
      input_: 4-D Tensor, the input.
      kernel_size: int (odd-valued) representing the kernel size.
      scope: str, scope under which to operate.
      activation_fn: activation function.
      dilate: If True, uses slim.separable_conv2d instead of slim.conv2d
      variables_collections: optional list of collections for variables
    Returns:
      4-D Tensor, the output.
    Raises:
      ValueError: if `kernel_size` is even.
    """"""
    if kernel_size % 2 == 0:
      raise ValueError('kernel_size is expected to be odd.')
    with tf.variable_scope(scope):
      num_outputs = input_.get_shape()[-1].value
      h_1 = model_util.conv2d(
          input_, 
          kernel_size, 1, 
          num_outputs, 
          'conv1' if not dilate else 'dilate_conv1', 
          activation_fn,
          dilate=dilate,
          variables_collections=variables_collections)
      h_2 = model_util.conv2d(
          h_1, 
          kernel_size, 1, 
          num_outputs, 
          'conv2' if not dilate else 'dilate_conv2', 
          None,
          dilate=dilate,
          variables_collections=variables_collections)
      return input_ + h_2

class transformer_model:
  @staticmethod
  def style_normalization_activations(pre_name='transformer',
                                    post_name='StyleNorm',
                                     dilate=False):
    """"""Returns scope name and depths of the style normalization activations.
    Args:
      pre_name: string. Prepends this name to the scope names.
      post_name: string. Appends this name to the scope names.
    Returns:
      string. Scope names of the activations of the transformer network which are
          used to apply style normalization.
      int[]. Depths of the activations of the transformer network which are used
          to apply style normalization.
    """"""
    
    conv_string = 'conv' if not dilate else 'dilate_conv'

    scope_names = ['residual/residual1/'+conv_string+'1',
                   'residual/residual1/'+conv_string+'2',
                   'residual/residual2/'+conv_string+'1',
                   'residual/residual2/'+conv_string+'2',
                   'residual/residual3/'+conv_string+'1',
                   'residual/residual3/'+conv_string+'2',
                   'residual/residual4/'+conv_string+'1',
                   'residual/residual4/'+conv_string+'2',
                   'residual/residual5/'+conv_string+'1',
                   'residual/residual5/'+conv_string+'2',
                   'expand/conv1/'+conv_string,
                   'expand/conv2/'+conv_string,
                   'expand/conv3/'+conv_string]
    scope_names = ['{}/{}/{}'.format(pre_name, name, post_name)
                   for name in scope_names]
    depths = [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 64, 32, 3]

    return scope_names, depths
  
  @staticmethod
  def transform(input_, normalizer_fn=None, normalizer_params=None,
              reuse=False, trainable=True, is_training=True,
               dilate=False, variables_collections=None):
    """"""Maps content images to stylized images.
    Args:
      input_: Tensor. Batch of input images.
      normalizer_fn: normalization layer function for applying style
          normalization.
      normalizer_params: dict of parameters to pass to the style normalization op.
      reuse: bool. Whether to reuse model parameters. Defaults to False.
      trainable: bool. Should the parameters be marked as trainable?
      is_training: bool. Is it training phase or not?
      dilate: If True, uses slim.separable_conv2d instead of slim.conv2d
      variables_collections: optional list of collections for variables
    Returns:
      Tensor. The output of the transformer network.
    """"""
    with tf.variable_scope('transformer', reuse=reuse):
      with slim.arg_scope(
          [slim.conv2d, slim.separable_conv2d],
          activation_fn=tf.nn.relu,
          normalizer_fn=normalizer_fn,
          normalizer_params=normalizer_params,
          weights_initializer=tf.random_normal_initializer(0.0, 0.01),
          biases_initializer=tf.constant_initializer(0.0),
          trainable=trainable):
        with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm,
                            normalizer_params=None,
                            trainable=trainable):
          with slim.arg_scope([slim.batch_norm], is_training=is_training,
                              trainable=trainable):
            with tf.variable_scope('contract'):
              h = model_util.conv2d(input_, 9, 1, 32, 'conv1')
              h = model_util.conv2d(h, 3, 2, 64, 'conv2')
              h = model_util.conv2d(h, 3, 2, 128, 'conv3')
        with tf.variable_scope('residual'):
          h = model_util.residual_block(h, 3, 'residual1', dilate=dilate, variables_collections=variables_collections)
          h = model_util.residual_block(h, 3, 'residual2', dilate=dilate, variables_collections=variables_collections)
          h = model_util.residual_block(h, 3, 'residual3', dilate=dilate, variables_collections=variables_collections)
          h = model_util.residual_block(h, 3, 'residual4', dilate=dilate, variables_collections=variables_collections)
          h = model_util.residual_block(h, 3, 'residual5', dilate=dilate, variables_collections=variables_collections)
        with tf.variable_scope('expand'):
          h = model_util.upsampling(h, 3, 2, 64, 'conv1', dilate=dilate, variables_collections=variables_collections)
          h = model_util.upsampling(h, 3, 2, 32, 'conv2', dilate=dilate, variables_collections=variables_collections)
          return model_util.upsampling(
              h, 9, 1, 3, 'conv3', activation_fn=tf.nn.sigmoid, dilate=dilate, variables_collections=variables_collections)

class build_model:
  @staticmethod
  def build_model(content_input_,
                style_input_,
                trainable,
                is_training,
                reuse=None,
                inception_end_point='Mixed_6e',
                style_prediction_bottleneck=100,
                adds_losses=True,
                content_weights=None,
                style_weights=None,
                total_variation_weight=None,
                dilate=False,
                variables_collections=None):
    """"""The image stylize function.
    Args:
      content_input_: Tensor. Batch of content input images.
      style_input_: Tensor. Batch of style input images.
      trainable: bool. Should the parameters be marked as trainable?
      is_training: bool. Is it training phase or not?
      reuse: bool. Whether to reuse model parameters. Defaults to False.
      inception_end_point: string. Specifies the endpoint to construct the
          inception_v3 network up to. This network is used for style prediction.
      style_prediction_bottleneck: int. Specifies the bottleneck size in the
          number of parameters of the style embedding.
      adds_losses: wheather or not to add objectives to the model.
      content_weights: dict mapping layer names to their associated content loss
          weight. Keys that are missing from the dict won't have their content
          loss computed.
      style_weights: dict mapping layer names to their associated style loss
          weight. Keys that are missing from the dict won't have their style
          loss computed.
      total_variation_weight: float. Coefficient for the total variation part of
          the loss.
    Returns:
      Tensor for the output of the transformer network, Tensor for the total loss,
      dict mapping loss names to losses, Tensor for the bottleneck activations of
      the style prediction network.
    """"""
    # Gets scope name and shape of the activations of transformer network which
    # will be used to apply style.
    [activation_names,
     activation_depths] = transformer_model.style_normalization_activations(dilate=dilate)

    # Defines the style prediction network.
    style_params, bottleneck_feat = build_model.style_prediction(
        style_input_,
        activation_names,
        activation_depths,
        is_training=is_training,
        trainable=trainable,
        inception_end_point=inception_end_point,
        style_prediction_bottleneck=style_prediction_bottleneck,
        reuse=reuse)

    # Defines the style transformer network.
    stylized_images = transformer_model.transform(
        content_input_,
        normalizer_fn=ops.conditional_style_norm,
        reuse=reuse,
        trainable=trainable,
        is_training=is_training,
        normalizer_params={'style_params': style_params},
        dilate=dilate,
        variables_collections=variables_collections)

    # Adds losses.
    loss_dict = {}
    total_loss = []
    if adds_losses:
      total_loss, loss_dict = losses.total_loss(
          content_input_,
          style_input_,
          stylized_images,
          content_weights=content_weights,
          style_weights=style_weights,
          total_variation_weight=total_variation_weight)

    return stylized_images, total_loss, loss_dict, bottleneck_feat
  
  @staticmethod
  def build_model_w_mobilenet(content_input_,
                style_input_,
                mobilenet_trainable=True,
                style_params_trainable=False,
                transformer_trainable=False,
                reuse=None,
                mobilenet_end_point='layer_19',
                style_prediction_bottleneck=100,
                adds_losses=True,
                content_weights=None,
                style_weights=None,
                total_variation_weight=None):
    """"""The image stylize function with Mobilenet.
    Args:
      content_input_: Tensor. Batch of content input images.
      style_input_: Tensor. Batch of style input images.
      trainable: bool. Should the parameters be marked as trainable?
      is_training: bool. Is it training phase or not?
      reuse: bool. Whether to reuse model parameters. Defaults to False.
      inception_end_point: string. Specifies the endpoint to construct the
          inception_v3 network up to. This network is used for style prediction.
      style_prediction_bottleneck: int. Specifies the bottleneck size in the
          number of parameters of the style embedding.
      adds_losses: wheather or not to add objectives to the model.
      content_weights: dict mapping layer names to their associated content loss
          weight. Keys that are missing from the dict won't have their content
          loss computed.
      style_weights: dict mapping layer names to their associated style loss
          weight. Keys that are missing from the dict won't have their style
          loss computed.
      total_variation_weight: float. Coefficient for the total variation part of
          the loss.
    Returns:
      Tensor for the output of the transformer network, Tensor for the total loss,
      dict mapping loss names to losses, Tensor for the bottleneck activations of
      the style prediction network.
    """"""
    # Gets scope name and shape of the activations of transformer network which
    # will be used to apply style.
    [activation_names,
     activation_depths] = transformer_model.style_normalization_activations()

    # Defines the style prediction network.
    style_params, bottleneck_feat = build_model.style_prediction_mobilenet(
        style_input_,
        activation_names,
        activation_depths,
        mobilenet_end_point=mobilenet_end_point,
        mobilenet_trainable=mobilenet_trainable,
        style_params_trainable=style_params_trainable,
        style_prediction_bottleneck=style_prediction_bottleneck,
        reuse=reuse)

    # Defines the style transformer network.
    stylized_images = transformer_model.transform(
        content_input_,
        normalizer_fn=ops.conditional_style_norm,
        reuse=reuse,
        trainable=transformer_trainable,
        is_training=transformer_trainable,
        normalizer_params={'style_params': style_params})

    # Adds losses.
    loss_dict = {}
    total_loss = []
    if adds_losses:
      total_loss, loss_dict = losses.total_loss(
          content_input_,
          style_input_,
          stylized_images,
          content_weights=content_weights,
          style_weights=style_weights,
          total_variation_weight=total_variation_weight)

    return stylized_images, total_loss, loss_dict, bottleneck_feat
  
  @staticmethod
  def style_prediction(style_input_,
                     activation_names,
                     activation_depths,
                     is_training=True,
                     trainable=True,
                     inception_end_point='Mixed_6e',
                     style_prediction_bottleneck=100,
                     reuse=None):
    """"""Maps style images to the style embeddings (beta and gamma parameters).
    Args:
      style_input_: Tensor. Batch of style input images.
      activation_names: string. Scope names of the activations of the transformer
          network which are used to apply style normalization.
      activation_depths: Shapes of the activations of the transformer network
          which are used to apply style normalization.
      is_training: bool. Is it training phase or not?
      trainable: bool. Should the parameters be marked as trainable?
      inception_end_point: string. Specifies the endpoint to construct the
          inception_v3 network up to. This network is part of the style prediction
          network.
      style_prediction_bottleneck: int. Specifies the bottleneck size in the
          number of parameters of the style embedding.
      reuse: bool. Whether to reuse model parameters. Defaults to False.
    Returns:
      Tensor for the output of the style prediction network, Tensor for the
          bottleneck of style parameters of the style prediction network.
    """"""
    with tf.name_scope('style_prediction') and tf.variable_scope(
        tf.get_variable_scope(), reuse=reuse):
      with slim.arg_scope(build_model._inception_v3_arg_scope(is_training=is_training)):
        with slim.arg_scope(
            [slim.conv2d, slim.fully_connected, slim.batch_norm],
            trainable=trainable):
          with slim.arg_scope(
              [slim.batch_norm, slim.dropout], is_training=is_training):
            _, end_points = inception_v3.inception_v3_base(
                style_input_,
                scope='InceptionV3',
                final_endpoint=inception_end_point)

      # Shape of feat_convlayer is (batch_size, ?, ?, depth).
      # For Mixed_6e end point, depth is 768, for input image size of 256x265
      # width and height are 14x14.
      feat_convlayer = end_points[inception_end_point]
      with tf.name_scope('bottleneck'):
        # (batch_size, 1, 1, depth).
        bottleneck_feat = tf.reduce_mean(
            feat_convlayer, axis=[1, 2], keep_dims=True)

      if style_prediction_bottleneck > 0:
        with slim.arg_scope(
            [slim.conv2d],
            activation_fn=None,
            normalizer_fn=None,
            trainable=trainable):
          # (batch_size, 1, 1, style_prediction_bottleneck).
          bottleneck_feat = slim.conv2d(bottleneck_feat,
                                        style_prediction_bottleneck, [1, 1])

      style_params = {}
      with tf.variable_scope('style_params'):
        for i in range(len(activation_depths)):
          # We want to force reuse the variables for style_params but keep the dictionary keys if dilate=True
          with tf.variable_scope(activation_names[i].replace('dilate_conv', 'conv'), reuse=reuse):
            with slim.arg_scope(
                [slim.conv2d],
                activation_fn=None,
                normalizer_fn=None,
                trainable=trainable):

              # Computing beta parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              beta = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              beta = tf.squeeze(beta, [1, 2], name='SpatialSqueeze')
              style_params['{}/beta'.format(activation_names[i])] = beta

              # Computing gamma parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              gamma = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              gamma = tf.squeeze(gamma, [1, 2], name='SpatialSqueeze')
              style_params['{}/gamma'.format(activation_names[i])] = gamma

    return style_params, bottleneck_feat
  
  @staticmethod
  def style_prediction_inception_only(style_input_,
                     is_training=True,
                     trainable=True,
                     inception_end_point='Mixed_6e',
                     style_prediction_bottleneck=100,
                     reuse=None):
    """"""Maps style images to the style embeddings (beta and gamma parameters).
    Args:
      style_input_: Tensor. Batch of style input images.
      activation_names: string. Scope names of the activations of the transformer
          network which are used to apply style normalization.
      activation_depths: Shapes of the activations of the transformer network
          which are used to apply style normalization.
      is_training: bool. Is it training phase or not?
      trainable: bool. Should the parameters be marked as trainable?
      inception_end_point: string. Specifies the endpoint to construct the
          inception_v3 network up to. This network is part of the style prediction
          network.
      style_prediction_bottleneck: int. Specifies the bottleneck size in the
          number of parameters of the style embedding.
      reuse: bool. Whether to reuse model parameters. Defaults to False.
    Returns:
      Tensor for the output of the style prediction network
    """"""
    with tf.name_scope('style_prediction') and tf.variable_scope(
        tf.get_variable_scope(), reuse=reuse):
      with slim.arg_scope(build_model._inception_v3_arg_scope(is_training=is_training)):
        with slim.arg_scope(
            [slim.conv2d, slim.fully_connected, slim.batch_norm],
            trainable=trainable):
          with slim.arg_scope(
              [slim.batch_norm, slim.dropout], is_training=is_training):
            _, end_points = inception_v3.inception_v3_base(
                style_input_,
                scope='InceptionV3',
                final_endpoint=inception_end_point)

      # Shape of feat_convlayer is (batch_size, ?, ?, depth).
      # For Mixed_6e end point, depth is 768, for input image size of 256x265
      # width and height are 14x14.
      feat_convlayer = end_points[inception_end_point]
      with tf.name_scope('bottleneck'):
        # (batch_size, 1, 1, depth).
        bottleneck_feat = tf.reduce_mean(
            feat_convlayer, axis=[1, 2], keep_dims=True)

      if style_prediction_bottleneck > 0:
        with slim.arg_scope(
            [slim.conv2d],
            activation_fn=None,
            normalizer_fn=None,
            trainable=trainable):
          # (batch_size, 1, 1, style_prediction_bottleneck).
          bottleneck_feat = slim.conv2d(bottleneck_feat,
                                        style_prediction_bottleneck, [1, 1])
      return bottleneck_feat

  
  @staticmethod
  def style_prediction_mobilenet(style_input_,
                     activation_names,
                     activation_depths,
                     mobilenet_end_point='layer_19',
                     mobilenet_trainable=True,
                     style_params_trainable=False,
                     style_prediction_bottleneck=100,
                     reuse=None):
    """"""Maps style images to the style embeddings (beta and gamma parameters) using mobilenet.
    Args:
      style_input_: Tensor. Batch of style input images.
      activation_names: string. Scope names of the activations of the transformer
          network which are used to apply style normalization.
      activation_depths: Shapes of the activations of the transformer network
          which are used to apply style normalization.
      is_training: bool. Is it training phase or not?
      style_params_trainable: bool. Should the style_params be marked as trainable?
      style_prediction_bottleneck: int. Specifies the bottleneck size in the
          number of parameters of the style embedding.
      reuse: bool. Whether to reuse model parameters. Defaults to False.
    Returns:
      Tensor for the output of the style prediction network, Tensor for the
          bottleneck of style parameters of the style prediction network.
    """"""
    with tf.name_scope('style_prediction_mobilenet') and tf.variable_scope(
        tf.get_variable_scope(), reuse=reuse):
      with slim.arg_scope(mobilenet_v2.training_scope(is_training=mobilenet_trainable)):
        #bottleneck_feat, _ = mobilenet_v2.mobilenet(
        #    style_input_,
        #    num_classes=style_prediction_bottleneck,
        #    )
        _, end_points = mobilenet.mobilenet_base(
            style_input_,
            conv_defs=mobilenet_v2.V2_DEF,
            final_endpoint=mobilenet_end_point,
            scope='MobilenetV2'
        )
        
        
      feat_convlayer = end_points[mobilenet_end_point]
      with tf.name_scope('bottleneck'):
        # (batch_size, 1, 1, depth).
        bottleneck_feat = tf.reduce_mean(
            feat_convlayer, axis=[1, 2], keep_dims=True)

      if style_prediction_bottleneck > 0:
        with tf.variable_scope('mobilenet_conv'):
          with slim.arg_scope(
              [slim.conv2d],
              activation_fn=None,
              normalizer_fn=None,
              trainable=mobilenet_trainable):
            # (batch_size, 1, 1, style_prediction_bottleneck).
            bottleneck_feat = slim.conv2d(bottleneck_feat,
                                          style_prediction_bottleneck, [1, 1])

      style_params = {}
      with tf.variable_scope('style_params'):
        for i in range(len(activation_depths)):
          with tf.variable_scope(activation_names[i], reuse=reuse):
            with slim.arg_scope(
                [slim.conv2d],
                activation_fn=None,
                normalizer_fn=None,
                trainable=style_params_trainable):

              # Computing beta parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              beta = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              beta = tf.squeeze(beta, [1, 2], name='SpatialSqueeze')
              style_params['{}/beta'.format(activation_names[i])] = beta

              # Computing gamma parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              gamma = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              gamma = tf.squeeze(gamma, [1, 2], name='SpatialSqueeze')
              style_params['{}/gamma'.format(activation_names[i])] = gamma

    return style_params, bottleneck_feat
  
  @staticmethod
  def _inception_v3_arg_scope(is_training=True,
                            weight_decay=0.00004,
                            stddev=0.1,
                            batch_norm_var_collection='moving_vars'):
    """"""Defines the default InceptionV3 arg scope.
    Args:
      is_training: Whether or not we're training the model.
      weight_decay: The weight decay to use for regularizing the model.
      stddev: The standard deviation of the trunctated normal weight initializer.
      batch_norm_var_collection: The name of the collection for the batch norm
        variables.
    Returns:
      An `arg_scope` to use for the inception v3 model.
    """"""
    batch_norm_params = {
        'is_training': is_training,
        # Decay for the moving averages.
        'decay': 0.9997,
        # epsilon to prevent 0s in variance.
        'epsilon': 0.001,
        # collection containing the moving mean and moving variance.
        'variables_collections': {
            'beta': None,
            'gamma': None,
            'moving_mean': [batch_norm_var_collection],
            'moving_variance': [batch_norm_var_collection],
        }
    }
    normalizer_fn = slim.batch_norm

    # Set weight_decay for weights in Conv and FC layers.
    with slim.arg_scope(
        [slim.conv2d, slim.fully_connected],
        weights_regularizer=slim.l2_regularizer(weight_decay)):
      with slim.arg_scope(
          [slim.conv2d],
          weights_initializer=tf.truncated_normal_initializer(stddev=stddev),
          activation_fn=tf.nn.relu6,
          normalizer_fn=normalizer_fn,
          normalizer_params=batch_norm_params) as sc:
        return sc
```

",right also something meaning contribute far time rewrite state rest magenta sure seen noticeable quality drop noticeable speed boost separable used dump relevant code take note dilate argument add keep separable dilated weird naming sorry point replace separable note run notebook use class static lieu separate module ugly yes python class stride scope convolution mirror padding instead function odd tensor input kernel size stride number output feature scope scope operate activation function dilate true instead optional list tensor output raise odd padding padding padding padding padding dilate return else return stride scope smooth replacement convolution function first input factor stride convolution odd tensor input kernel size stride number output feature scope scope operate activation function dilate true instead optional list tensor output raise odd scope shape height shape width shape stride height stride width return dilate else scope residual block made two function odd tensor input kernel size scope scope operate activation function dilate true instead optional list tensor output raise odd scope dilate else dilate else none return class scope name style normalization string name scope string name scope string scope transformer network used apply style normalization transformer network used apply style dilate else name name return transform content tensor batch input normalization layer function style normalization pas style normalization reuse bool whether reuse model false trainable bool marked trainable bool training phase dilate true instead optional list tensor output transformer return class trainable image stylize function tensor batch content input tensor batch style input trainable bool marked trainable bool training phase reuse bool whether reuse model false string construct network network used style prediction bottleneck size number style add model layer associated content loss weight missing wo content loss layer associated style loss weight missing wo style loss float coefficient total variation part loss tensor output transformer network tensor total loss loss tensor bottleneck style prediction scope name shape transformer network used apply style style prediction network style transformer network return image stylize function tensor batch content input tensor batch style input trainable bool marked trainable bool training phase reuse bool whether reuse model false string construct network network used style prediction bottleneck size number style add model layer associated content loss weight missing wo content loss layer associated style loss weight missing wo style loss float coefficient total variation part loss tensor output transformer network tensor total loss loss tensor bottleneck style prediction scope name shape transformer network used apply style style prediction network style transformer network return style style beta gamma tensor batch style input string scope transformer network used apply style normalization transformer network used apply style normalization bool training phase trainable bool marked trainable string construct network network part style prediction network bottleneck size number style reuse bool whether reuse model false tensor output style prediction network tensor bottleneck style style prediction shape depth end point depth input image size width height depth range want force reuse keep dictionary beta parameter style normalization layer style transformer network beta beta beta beta gamma parameter style normalization layer style transformer network gamma gamma gamma gamma return style style beta gamma tensor batch style input string scope transformer network used apply style normalization transformer network used apply style normalization bool training phase trainable bool marked trainable string construct network network part style prediction network bottleneck size number style reuse bool whether reuse model false tensor output style prediction network shape depth end point depth input image size width height depth return style style beta gamma tensor batch style input string scope transformer network used apply style normalization transformer network used apply style normalization bool training phase bool marked trainable bottleneck size number style reuse bool whether reuse model false tensor output style prediction network tensor bottleneck style style prediction depth range beta parameter style normalization layer style transformer network beta beta beta beta gamma parameter style normalization layer style transformer network gamma gamma gamma gamma return default scope whether training model weight decay use model standard deviation normal weight name collection batch norm use inception decay moving epsilon prevent variance collection moving mean moving variance none none set return,issue,negative,negative,neutral,neutral,negative,negative
464506793,"I will definitely use saved_model_cli from now on, thanks.

Ohh, I see! Yeah, I will try to find a way to implement mirror padding to tfjs and submit a PR :)

One last thing. So you mentioned that you trained a Seperable Depthwise Convnet for the Transformer net. In the magenta repo you distributed the Standard Convs instead. Was there any particular reason for that?

Thank for the help!



",definitely use thanks see yeah try find way implement mirror padding submit one last thing trained depthwise transformer net magenta distributed standard instead particular reason thank help,issue,positive,positive,neutral,neutral,positive,positive
464486772,"To inspect a SavedModel you can use 

`saved_model_cli show --dir saved_model_transformer --tag_set serve --signature_def serving_default`

This outputs the following

```
The given SavedModel SignatureDef contains the following input(s):
  inputs['bottleneck'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 1, 1, 100)
      name: Placeholder_1:0
  inputs['content'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, -1, 3)
      name: Placeholder:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['styled'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, -1, 3)
      name: transformer/expand/conv3/conv/Sigmoid:0
Method name is: tensorflow/serving/predict
```

So, you are correct that the output is indeed `transformer/expand/conv3/conv/Sigmoid`. 

The problem you are seeing is a problem in TensorFlow.js (see https://github.com/tensorflow/tfjs/issues/900). The MirrorPad op is not yet supported. You will have to replace the mirror padding operations in the graph (https://github.com/tensorflow/magenta/blob/master/magenta/models/image_stylization/model.py#L100) to use regular padding (change 'REFLECT' to 'CONSTANT'). Perhaps it would be good to submit a PR that modifies `conv2d()` to accept a padding mode? Conversely you can also submit a PR to tfjs to support mirror padding ;)",inspect use show serve following given following input shape name shape name given following output shape name method name correct output indeed problem seeing problem see yet replace mirror padding graph use regular padding change perhaps would good submit accept padding mode conversely also submit support mirror padding,issue,negative,positive,positive,positive,positive,positive
464401516,"We'll have to do a t2t release soon

On Sat, Feb 16, 2019, 1:25 PM Dustin Tran <notifications@github.com> wrote:

> Seems like a dependency issue. Latest T2T release (v.1.12.0) doesn't have
> ModalityType. @afrozenator <https://github.com/afrozenator>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1435#issuecomment-464387206>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABFCFj3DunsbKNW5OKj8j0EGOaGvFWxNks5vOHdegaJpZM4au049>
> .
>
",release soon sat wrote like dependency issue latest release reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
464387206,Seems like a dependency issue. Latest T2T release (v.1.12.0) doesn't have ModalityType. @afrozenator ,like dependency issue latest release,issue,negative,positive,positive,positive,positive,positive
464377975,"Got the same error, I'm gonna try reverting to that commit.",got error gon na try commit,issue,negative,neutral,neutral,neutral,neutral,neutral
464335466,"@reiinakano 
Hi again! 

1) I cannot mange to opent the model generated from  save_transformer in tensorboard. This makes it hard to find the output node. This is not a problem on the model generated from save_style_model, where I manage to open the the model in Tensorboard.

2) If I guess the output node to be _""transformer/expand/conv3/conv/Sigmoid""_ from the original graph  I get some strange error when trying the tfjs_convert, namely ""ValueError: Unsupported Ops in the model before optimization MirrorPad""... And I guess that --skip_op_check=SKIP_OP_CHECK flag is not the way to solve this.

Do you have any ideas what to do? 
",hi mange model hard find output node problem model manage open model guess output node original graph get strange error trying namely unsupported model optimization guess flag way solve,issue,negative,positive,neutral,neutral,positive,positive
464284372,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

Googlers can find more info about SignCLA and this PR by [following this link](go/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmagenta%2Fpull%2F1442).

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account find following link,issue,positive,positive,neutral,neutral,positive,positive
464223920,"Yes, correct.  Sorry about the confusion.",yes correct sorry confusion,issue,negative,negative,negative,negative,negative,negative
464223088,"Ooooh, I see. So I need to create those files with my MIDIs and convert_dir_to_note_sequences.py, and THEN point at them in the source code so it transforms them to the format that works with Transformer. Is that right?",see need create point source code format work transformer right,issue,negative,positive,positive,positive,positive,positive
464219089,"I'm confused now.  You don't, you can just point to your own TFRecord files, like the ones that would be created by https://github.com/tensorflow/magenta/blob/master/magenta/scripts/convert_dir_to_note_sequences.py",confused point like would,issue,negative,negative,negative,negative,negative,negative
464217762,What I don't understand is why do I need to use those datasets if I'm going to use my own?,understand need use going use,issue,negative,neutral,neutral,neutral,neutral,neutral
464214563,"BTW I was able to get things to run locally (just extremely slowly), even with the data in Google Cloud Storage.",able get run locally extremely slowly even data cloud storage,issue,negative,positive,neutral,neutral,positive,positive
464214012,"The dataset still lives in Google Cloud Storage.  Alternatively, you can download the datasets locally:

https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_train.tfrecord
https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_validation.tfrecord
https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_test.tfrecord

But then you'll also need to modify the problem in score2perf.py to point to your local copies.",still cloud storage alternatively locally also need modify problem point local,issue,negative,neutral,neutral,neutral,neutral,neutral
464212198,"I did, the problem is, like I told you, doing the 1st step on my machine. I see DirectRunner activates but shouldn't this paths  in score2perf.py change if I'm doing it locally?

'train': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_train.tfrecord',
    'dev': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_validation.tfrecord',
    'test': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_test.tfrecord'",problem like told st step machine see change locally,issue,negative,neutral,neutral,neutral,neutral,neutral
464207155,I think you'll need to `pip install apache-beam[gcp]`.  Let me know if that doesn't help.,think need pip install let know help,issue,negative,neutral,neutral,neutral,neutral,neutral
464200745,"Ok, I reinstalled magenta with conda so now I'm using 2.7 and getting:

ValueError: Unable to get the Filesystem for path gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_train.tfrecord [while running 'input_transform_train/ReadAllFromTFRecord/ReadAllFiles/ExpandIntoRanges']
",magenta getting unable get path running,issue,negative,negative,negative,negative,negative,negative
464183331,Unfortunately Apache Beam doesn't work with Python 3 (yet?).,unfortunately apache beam work python yet,issue,negative,negative,negative,negative,negative,negative
464168093,"I commented a line and fixed it, now I get:

RuntimeError: The Apache Beam SDK for Python is supported only on Python 2.7. It is not supported on Python [sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)].",line fixed get apache beam python python python,issue,negative,positive,neutral,neutral,positive,positive
464154834,"After upgrading to the latest magenta version now I get:

NameError: name 'datagen_beam' is not defined
",latest magenta version get name defined,issue,negative,positive,positive,positive,positive,positive
464147789,"I do on my machine:

t2t_datagen --data_dir=/home/usuario/Escritorio/dataset/ --problem=score2perf_maestro_language_uncropped_aug --alsologstderr

But I get this error:

IOError: No files found based on the file pattern /home/usuario/Escritorio/maestro/maestro-v1.0.0_test.tfrecord

Any ideas what could I be doing wrong?
",machine get error found based file pattern could wrong,issue,negative,negative,negative,negative,negative,negative
463916358,"I found it was mkl that resulted in this error in my case. Replace mkl-2019 with mkl-2018 as follows solves it.
```
# Name                    Version                   Build  Channel
mkl                       2018.0.3                 pypi_0    pypi
mkl-fft                   1.0.2                    pypi_0    pypi
mkl-random                1.0.1.1                  pypi_0    pypi
```

my environment is:
```
macos majave
tensorflow 1.12.0
magenta 1.0.2
python 3.6.8
```",found error case replace name version build channel environment magenta python,issue,negative,neutral,neutral,neutral,neutral,neutral
463874155,"You can download tf-agents from pypi website yourself and pip install it. There is only pre-release version tf-agents on pypi and pip only recognizes stable version lib by default , so pip can not find it.",pip install version pip stable version default pip find,issue,negative,neutral,neutral,neutral,neutral,neutral
463420583,"It doesn't look like that's the problem. I have some MIDI files which use channel 10 that don't work either, I also tried converting the others to channel 10 without any luck.",look like problem use channel work either also tried converting channel without luck,issue,negative,neutral,neutral,neutral,neutral,neutral
463401314,I believe drum tracks need to be on Channel 10 for Magenta to recognize them. Give that a shot and reopen if you still have an issue.,believe drum need channel magenta recognize give shot reopen still issue,issue,negative,neutral,neutral,neutral,neutral,neutral
463400837,"I fixed these internally but you won't see the updates in colab for a day or two. You can make the local modifications yourself however:

1. Fixed this by adding `-U` to the magenta pip install so it becomes: `!pip install -qU magenta`
2. Fixed this (in hello magenta only) by removing the temporary hack that uninstalls the pre-installed TensorFlow version (`!pip uninstall -y tensorflow`).",fixed internally wo see day two make local however fixed magenta pip install becomes pip install magenta fixed hello magenta removing temporary hack version pip,issue,negative,positive,neutral,neutral,positive,positive
463389814,"Thanks for reporting this! It looks like a couple of issues:

1. We should always be installing magenta with ""pip install -U magenta"" since it looks like Colab will keep an older version if it was previously installed on the same machine.
2. tensorflow_probability may be pointing to a different version of TF as we are.

1 is easy to fix, and I'm still investigating 2.",thanks like couple always magenta pip install magenta since like keep older version previously machine may pointing different version easy fix still investigating,issue,positive,positive,positive,positive,positive,positive
463361807,"Great, thank you so much for the support!

Nice work btw!",great thank much support nice work,issue,positive,positive,positive,positive,positive,positive
463294819,"Sorry! I forgot to add this part in when I was porting my code to magenta. Now I realize it's rather important...

I can't give you a better answer right now but the idea is to create a separate graph for the *style transfer network* and the *style prediction network*. The style prediction network will only output the 100-d vector while the style transfer network will take this 100-d vector + content image and map it to the output.

Here are snippets of code from my private notebook. They most likely won't work immediately with what's in the Magenta repo but I hope they give you an idea of what needs to be done. When I have time I will port this to Magenta.

```python
class build_saved_model:  
  @staticmethod
  def style_params_only(bottleneck_feat, 
                     activation_names,
                     activation_depths,
                     trainable=False,
                     reuse=None):
    """"""Used only for saving as a SavedModel""""""
    with tf.name_scope('style_prediction_mobilenet') and tf.variable_scope(
        tf.get_variable_scope(), reuse=reuse):
      style_params = {}
      with tf.variable_scope('style_params'):
        for i in range(len(activation_depths)):
          with tf.variable_scope(activation_names[i], reuse=reuse):
            with slim.arg_scope(
                [slim.conv2d],
                activation_fn=None,
                normalizer_fn=None,
                trainable=trainable):

              # Computing beta parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              beta = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              beta = tf.squeeze(beta, [1, 2], name='SpatialSqueeze')
              style_params['{}/beta'.format(activation_names[i])] = beta

              # Computing gamma parameter of the style normalization for the
              # activation_names[i] layer of the style transformer network.
              # (batch_size, 1, 1, activation_depths[i])
              gamma = slim.conv2d(bottleneck_feat, activation_depths[i], [1, 1])
              # (batch_size, activation_depths[i])
              gamma = tf.squeeze(gamma, [1, 2], name='SpatialSqueeze')
              style_params['{}/gamma'.format(activation_names[i])] = gamma
    return style_params 
  
  @staticmethod
  def build_transformer_saved_model(content_input, bottleneck_feat):
    # Gets scope name and shape of the activations of transformer network which
    # will be used to apply style.
    [activation_names,
     activation_depths] = transformer_model.style_normalization_activations()

    # Defines the style prediction network.
    style_params = build_saved_model.style_params_only(
        bottleneck_feat,
        activation_names,
        activation_depths)

    # Defines the style transformer network.
    stylized_images = transformer_model.transform(
        content_input,
        normalizer_fn=ops.conditional_style_norm,
        trainable=False,
        is_training=False,
        normalizer_params={'style_params': style_params})

    return stylized_images
  
  @staticmethod
  def build_mobilenet_saved_model(style_input, mobilenet_end_point='layer_19', style_prediction_bottleneck=100):
    with tf.name_scope('style_prediction_mobilenet') and tf.variable_scope(
        tf.get_variable_scope()):
      with slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):
        _, end_points = mobilenet.mobilenet_base(
            style_input,
            conv_defs=mobilenet_v2.V2_DEF,
            final_endpoint=mobilenet_end_point,
            scope='MobilenetV2'
        )
        
        
      feat_convlayer = end_points[mobilenet_end_point]
      with tf.name_scope('bottleneck'):
        # (batch_size, 1, 1, depth).
        bottleneck_feat = tf.reduce_mean(
            feat_convlayer, axis=[1, 2], keep_dims=True)
        
      with tf.variable_scope('mobilenet_conv'):
        with slim.arg_scope(
            [slim.conv2d],
            activation_fn=None,
            normalizer_fn=None,
            trainable=False):
          # (batch_size, 1, 1, style_prediction_bottleneck).
          bottleneck_feat = slim.conv2d(bottleneck_feat,
                                        style_prediction_bottleneck, [1, 1])
     
    return bottleneck_feat
```

```python
def save_transformer():
  tf.logging.set_verbosity(tf.logging.INFO)
  with tf.Graph().as_default(), tf.Session() as sess:
    content_img_ph = tf.placeholder(tf.float32, shape=[None, None, None, 3])
    bottleneck_feat = tf.placeholder(tf.float32, shape=[None, 1, 1, 100])
    stylized_images = build_saved_model.build_transformer_saved_model(content_img_ph, bottleneck_feat)
    
    # Multiply these weights by 10 to prevent underflow on half-precision devices.
    var_names = [
        'transformer/residual/residual1/conv1/weights',
        'transformer/residual/residual1/conv2/weights',
        'transformer/residual/residual2/conv1/weights',
        'transformer/residual/residual2/conv2/weights',
        'transformer/residual/residual3/conv1/weights',
        'transformer/residual/residual3/conv2/weights',
        'transformer/residual/residual4/conv1/weights',
        'transformer/residual/residual4/conv2/weights',
        'transformer/residual/residual5/conv1/weights',
        'transformer/residual/residual5/conv2/weights',
        'transformer/expand/conv1/conv/weights',
        'transformer/expand/conv2/conv/weights',
        'transformer/expand/conv3/conv/weights',
    ]

    with tf.variable_scope('', reuse=True):
      assign_ops = [tf.get_variable(var_name).assign(tf.get_variable(var_name)*10.0) for var_name in var_names]
      update_op = tf.group(*assign_ops)
    
    if tf.gfile.IsDirectory(FLAGS.checkpoint):
      print('here!')
      checkpoint = tf.train.latest_checkpoint(FLAGS.checkpoint)
    else:
      print('no here!')
      checkpoint = FLAGS.checkpoint
      tf.logging.info('loading latest checkpoint file: {}'.format(checkpoint))
      
    print(checkpoint)
    init_fn = slim.assign_from_checkpoint_fn(checkpoint,
                                             slim.get_variables_to_restore())
    sess.run([tf.local_variables_initializer()])
    init_fn(sess)
    
    for i in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='transformer'):
      print(i)   # i.name if you want just a name
      
    with tf.variable_scope('', reuse=True):
      [print(var_name, sess.run(tf.math.reduce_min(tf.math.abs(tf.get_variable(var_name))))) for var_name in var_names[:]]
    print(sess.run([update_op]))
    with tf.variable_scope('', reuse=True):
      [print(var_name, sess.run(tf.math.reduce_min(tf.math.abs(tf.get_variable(var_name))))) for var_name in var_names[:]]
    
    tf.saved_model.simple_save(sess,
            'saved_model_transformer',
            inputs={""content"": content_img_ph, ""bottleneck"": bottleneck_feat},
            outputs={""styled"": stylized_images})
    

#TODO: TRY TO SAVE THEM INDIVIDUALLY...
def save_style_model():
  tf.logging.set_verbosity(tf.logging.INFO)
  
  with tf.Graph().as_default(), tf.Session() as sess:
    # Defines place holder for the style image.
    style_img_ph = tf.placeholder(tf.float32, shape=[None, None, None, 3])
    
    # Defines the model.
    bottleneck_feat = build_saved_model.build_mobilenet_saved_model(style_img_ph)
    
    
    if tf.gfile.IsDirectory(FLAGS.checkpoint):
      print('here!')
      checkpoint = tf.train.latest_checkpoint(FLAGS.checkpoint)
    else:
      print('no here!')
      checkpoint = FLAGS.checkpoint
      tf.logging.info('loading latest checkpoint file: {}'.format(checkpoint))
      
    print(checkpoint)
    init_fn = slim.assign_from_checkpoint_fn(checkpoint,
                                             slim.get_variables_to_restore())
    sess.run([tf.local_variables_initializer()])
    init_fn(sess)
    
    tf.saved_model.simple_save(sess,
                              'saved_model_style',
            inputs={""style"": style_img_ph},
            outputs={""bottleneck"": bottleneck_feat})

```

`save_transformer` builds the graph with only the variables needed for the style transfer network

`save_style_model` builds the graph for the style prediction network.

The `checkpoint` in the code is the path to your saved checkpoint file from running the distill mobilenet code.

Please let me know if you have more questions.",sorry forgot add part code magenta realize rather important ca give better answer right idea create separate graph style transfer network style prediction network style prediction network output vector style transfer network take vector content image map output code private notebook likely wo work immediately magenta hope give idea need done time port magenta python class used saving range beta parameter style normalization layer style transformer network beta beta beta beta gamma parameter style normalization layer style transformer network gamma gamma gamma gamma return scope name shape transformer network used apply style style prediction network style transformer network return depth return python sess none none none none multiply prevent underflow print else print latest file print sess print want name print print print sess content bottleneck try save individually sess place holder style image none none none model print else print latest file print sess sess style bottleneck graph style transfer network graph style prediction network code path saved file running distill code please let know,issue,positive,positive,positive,positive,positive,positive
461764876,"In my environment, reverting the above commit from v1.0.2 fixes the issue.
Not sure if the above commit was the root cause though.",environment commit issue sure commit root cause though,issue,positive,positive,positive,positive,positive,positive
461762197,"Wondering if this commit is causing this issue. 

https://github.com/tensorflow/magenta/commit/89f9c29b59bb309af4dbe86328e2788448dc6621",wondering commit causing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
461757920,"Here is my code to repro the issue.

> DATA_DIR=`pwd`/datagen
> HPARAMS_SET=transformer_base
> MODEL=transformer
> PROBLEM=score2perf_maestro_language_uncropped_aug
> TRAIN_DIR=`pwd`/train_dir
> 
> HPARAMS=\
> ""label_smoothing=0.0,""\
> ""max_length=0,""\
> ""max_target_seq_length=2048""
> 
> python $SCRIPT_HOME/tensor2tensor/t2t_trainer.py \
>   --data_dir=""${DATA_DIR}"" \
>   --hparams=${HPARAMS} \
>   --hparams_set=${HPARAMS_SET} \
>   --model=${MODEL} \
>   --output_dir=${TRAIN_DIR} \
>   --problem=${PROBLEM} \
>   --train_steps=1000000",code issue python model problem,issue,negative,neutral,neutral,neutral,neutral,neutral
461706740,"It seems these three lines are the root cause of the issue. After changing /bigstore/ to gs:// the problem is gone.

magenta/models/score2perf/score2perf.py

> MAESTRO_TFRECORD_PATHS = {
>     'train': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_train.tfrecord',
>     'dev': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_validation.tfrecord',
>     'test': 'gs://magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_test.tfrecord'
> #    'train': '/bigstore/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_train.tfrecord',
> #    'dev': '/bigstore/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_validation.tfrecord',
> #    'test': '/bigstore/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0_test.tfrecord'
> }
> # pylint: enable=line-too-long
> ",three root cause issue problem gone,issue,negative,neutral,neutral,neutral,neutral,neutral
460861422,Just making a note for future reference - #1345 was continued and finished up in #1429. Thanks.,making note future reference continued finished thanks,issue,negative,positive,neutral,neutral,positive,positive
460547963,"Well, checking the installation guide if you can install the rtmidi package through pip instead of apt-get then a snap may not be as helpful than installing via pip.
![magneta](https://user-images.githubusercontent.com/45159366/52260213-347b7b00-28da-11e9-97e7-6df55367ddf4.png)
",well installation guide install package pip instead snap may helpful via pip magneta,issue,positive,neutral,neutral,neutral,neutral,neutral
460443230,"Actually, @vitorarrais, is there a way to have the pylint py2 requirement specified only in the `test_requires` portion of setup.py? We don't necessarily want to require pylint for all python 2 installations of the package.",actually way requirement portion necessarily want require python package,issue,negative,neutral,neutral,neutral,neutral,neutral
460443008,"Hey @cghawthorne, you're right, I just realized I hadn't configured my email in first the commit. I pushed another commit after configuring the email but that doesn't work either.

I haven't really done an interactive rebase before, I'm going to follow the steps [here](https://stackoverflow.com/a/3042512) to see if I can amend the author for my first commit.",hey right first commit another commit work either really done interactive rebase going follow see amend author first commit,issue,positive,positive,positive,positive,positive,positive
460436145,Hey @vaipatel it looks like the CLA bot still isn't happy. You might have to edit your commit (possibly with some form of rebase/squash) to make the author email address correct.,hey like bot still happy might edit commit possibly form make author address correct,issue,positive,positive,positive,positive,positive,positive
460431683,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to determine that you authored the commits in this PR.  Maybe you used a different email address in the git commits than was used to sign the CLA?  If someone else authored these commits, then please add them to this pull request and have them confirm that they're okay with them being contributed to Google.  If there are co-authors, make sure they're formatted properly.
In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.

<!-- unknown_author -->",found contributor license agreement sender pull request unable determine maybe used different address git used sign someone else please add pull request confirm make sure properly order pas check please resolve problem pull request author add another comment bot run bot comment think anything,issue,positive,neutral,neutral,neutral,neutral,neutral
460431289,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer public version used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account,issue,positive,positive,neutral,neutral,positive,positive
460423890,Is this still helpful since everything can now be installed via pip?,still helpful since everything via pip,issue,negative,neutral,neutral,neutral,neutral,neutral
460359496,@vaipatel the author of #1345 has been unresponsive. Can you continue that fix?,author unresponsive continue fix,issue,negative,neutral,neutral,neutral,neutral,neutral
460166807,Sorry just saw pull request #1345 addresses this and a few more problems related to [sketch_rnn_train.py](https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py) and Python 3. Add I guess a better more concise fix was to use `six.moves.urllib.request` per this [review note](https://github.com/tensorflow/magenta/pull/1345/files#r233199710). I'll close this issue.,sorry saw pull request related python add guess better concise fix use per review note close issue,issue,negative,positive,neutral,neutral,positive,positive
459168374,"This is more of a numpy and Arch Linux question than a Magenta question. I'd try asking on an Arch Linux forum where you can install the required header files. Alternatively, according to the numpy website, there's an Arch Linux numpy package you can try installing: https://www.scipy.org/scipylib/download.html",arch question magenta question try arch forum install header alternatively according arch package try,issue,negative,neutral,neutral,neutral,neutral,neutral
459056177,"Yeah, this is because the tensorflow-metadata version requirement is too strict. Their python_requires of '>=2.7,<=3.7' will accept only up to Python 3.7.0. Can you file a bug on their repo (https://github.com/tensorflow/metadata/issues)? I'll close this bug since it's not a Magenta issue. Thanks!",yeah version requirement strict accept python file bug close bug since magenta issue thanks,issue,positive,positive,positive,positive,positive,positive
459048404,"@cghawthorne 

```
$ python3
Python 3.7.2 (default, Jan 10 2019, 23:51:51) 
[GCC 8.2.1 20181127] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 
```
(on an up-to-date Arch Linux system BTW.)",python python default type help copyright license information arch system,issue,negative,neutral,neutral,neutral,neutral,neutral
459044035,Can you list the exact version of python you're running? It looks like tensorflow-metadata does have some restrictions for python version: https://github.com/tensorflow/metadata/blob/master/setup.py#L56,list exact version python running like python version,issue,negative,positive,positive,positive,positive,positive
458744331,@adarob I think you mentioned that pytest only works in python 3. Should we modify setup.py to behave differently for py2 or something?,think work python modify behave differently something,issue,negative,neutral,neutral,neutral,neutral,neutral
458374472,"Also, you should know that I've been making significant changes to the code base over the last few days to bring it up to date with the latest changes from our paper, [Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset](https://goo.gl/magenta/maestro-paper). So it's likely that there will be some incompatibilities with any checkpoints you've previously trained after you sync.",also know making significant code base last day bring date latest paper piano music modeling generation maestro likely previously trained sync,issue,negative,negative,neutral,neutral,negative,negative
458373938,Hi @JulienCardiff. I suspect the error you're having was fixed by #1353. Can you try syncing to the latest version of the code and see if that fixes it?,hi suspect error fixed try latest version code see,issue,negative,positive,positive,positive,positive,positive
458208836,"I have similar issues to the ones @ema987 mentioned in his latest post. I can't get a satisfying output from a 256x256 input image. I followed every step of the OP link.

The content loss appears to be definitely smaller than the style loss ",similar latest post ca get satisfying output input image every step link content loss definitely smaller style loss,issue,negative,positive,positive,positive,positive,positive
456602182,"Just don't pass the --pipeline_options flag, and it should use the [DirectRunner](https://beam.apache.org/documentation/runners/direct/) that uses your local machine.",pas flag use local machine,issue,negative,neutral,neutral,neutral,neutral,neutral
456598013,"Thanks, I still would like to do it locally if it's possible. Can you tell me what do I need to change please?",thanks still would like locally possible tell need change please,issue,positive,positive,neutral,neutral,positive,positive
456563674,"You can certainly try running t2t_datagen locally, but it won't take advantage of your GPU; note that this isn't training, just preprocessing the dataset.  I'd expect it to take days locally vs minutes on Cloud.",certainly try running locally wo take advantage note training expect take day locally cloud,issue,positive,positive,neutral,neutral,positive,positive
456551396,"I'm sorry but it's not clear why do we need to use Google Cloud. I have a really fast GTX1080 8gb GPU on my laptop. How using Apache Beam and Google Cloud will make anything faster? And if so, how much faster?",sorry clear need use cloud really fast apache beam cloud make anything faster much faster,issue,negative,positive,neutral,neutral,positive,positive
456490081,"You need to do ""pip install apache-beam[gcp]"".  @adarob I guess we should add the beam + cloud dependency to setup.py.",need pip install guess add beam cloud dependency,issue,negative,neutral,neutral,neutral,neutral,neutral
456484086,"Sorry @Gnefi but I never got around to publishing this portion of the code. However, it should be fairly straightforward to reproduce these particular functions in Python. Please reopen if you have specific questions about those functions.",sorry never got around portion code however fairly straightforward reproduce particular python please reopen specific,issue,negative,positive,neutral,neutral,positive,positive
456483311,Luckily the warning isn't actually a problem so just ignore it for now. I'm hoping these will disappear once everyone moves to py3.,luckily warning actually problem ignore disappear everyone,issue,negative,positive,positive,positive,positive,positive
455959834,"Hi,

For specific processing of QuickDraw data (rather than issues specifically related to the sketch-rnn model), you might want to try to ask this forum instead:

https://github.com/googlecreativelab/quickdraw-dataset

Thanks",hi specific data rather specifically related model might want try ask forum instead thanks,issue,negative,positive,neutral,neutral,positive,positive
455959449,"Hi, the aim for sketch-rnn codebase is to work with the .npz file format provided. Data must be specified to such a format for this algorithm to work. While we don't support how one converts other formats to/from the format specified in the paper (which is beyond the scope here), I can point you to the direction where you might be able to get some help. You might want to raise an issue here instead:

https://github.com/googlecreativelab/quickdraw-dataset",hi aim work file format provided data must format algorithm work support one format paper beyond scope point direction might able get help might want raise issue instead,issue,positive,positive,positive,positive,positive,positive
455743978,"I have also solved it. For my case, my gcc version was 4.3 which is too old for the python-rtmidi library. So I need to install gcc 6.3.
After installing, you need to run the following line to check what is the name for the gcc that you install
`dpkg -l | grep gcc | awk '{print $2}'`
And it output the followings
> gcc
> gcc-5
> gcc-5-base:amd64
> gcc-6
> gcc-6-base:amd64
> gcc-7-base:amd64
> gcc-8-base:amd64
> libcaca0:amd64
> libgcc-5-dev:amd64
> libgcc-6-dev:amd64
> libgcc1:amd64

So, even I have installed gcc 6.3, the package name is actually gcc-6, then I run the following line to switch my default gcc to 6 (The last word in the following line is the version you want to change to).

`ls -la /usr/bin/ | grep -oP ""[\S]*(gcc|g\+\+)(-[a-z]+)*[\s]"" | xargs bash -c 'for link in ${@:1}; do sudo ln -s -f ""/usr/bin/${link}-${0}"" ""/usr/bin/${link}""; done' 6`

I found most of my answer in this stack post
[https://askubuntu.com/questions/26498/how-to-choose-the-default-gcc-and-g-version](url)",also case version old library need install need run following line check name install print output base base base base dev dev even package name actually run following line switch default last word following line version want change bash link link link done found answer stack post,issue,negative,negative,negative,negative,negative,negative
455615868,"Well I don't remember everything, but it was python packages/modules problem.
Maybe you missed some python packages/modules.
Install everything packages/modules what you need to your project!
I also tried to search packages/modules and when I installed it all, it worked well :)
I hope you find it! 
I recommend that analyse magenta code, and find what you need! Good luck 👍 ",well remember everything python problem maybe python install everything need project also tried search worked well hope find recommend analyse magenta code find need good luck,issue,positive,positive,positive,positive,positive,positive
455543331,May I know how did you solve it? I am encountering the same problem,may know solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
455348375,"Travis has some errors:
```
E           FileNotFoundError: [Errno 2] No such file or directory: 'magenta/testing/data/example_nsynth_audio.npy'
../../../virtualenv/python3.5.6/lib/python3.5/site-packages/numpy/lib/npyio.py:384: FileNotFoundError
============= 4 failed, 675 passed, 695 warnings in 160.19 seconds =============
The command ""pytest"" exited with 1.
```",travis file directory command,issue,negative,neutral,neutral,neutral,neutral,neutral
454924593,"I used the 1.12.0 version that magenta pulls when installing it via pip. Also, the same problem doesn't happen on Ubuntu 16.04, so it must be some weird TF+mac+magenta combination. Other TF programs on the same mac machine work fine",used version magenta via pip also problem happen must weird combination mac machine work fine,issue,negative,negative,neutral,neutral,negative,negative
454921226,I agree this sounds more like a general TF issue. Have you tried upgrading to the final 1.12.0 release?,agree like general issue tried final release,issue,positive,positive,neutral,neutral,positive,positive
454618612,Hum I upgraded numpy version 1.14.5 to 1.16.0 but it still have a warning ;(,hum version still warning,issue,negative,neutral,neutral,neutral,neutral,neutral
454465422,"According to https://github.com/numpy/numpy/issues/11788, upgrading your
numpy should fix it. Can you give that a try?

On Tue, Jan 15, 2019 at 2:14 AM JinSolChoi <notifications@github.com> wrote:

> Oh it was pyasn1 and pyasn1-modules version problem.
> But there appeared so many RuntimeWarning.
> When I try to import magenta again, I imported well.
> But I want to solve this RuntimeWarning.
>
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ..utils.seq_dataset import ArrayDataset, CSRDataset
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated
> /usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._random import sample_without_replacement
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:30:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import cd_fast
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/*init*.py:22:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/*init*.py:22:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber
> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .sag_fast import sag
> /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import libsvm, liblinear
> /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import libsvm, liblinear
> /usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import libsvm_sparse
> /usr/local/lib/python2.7/dist-packages/sklearn/neighbors/*init*.py:6:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .ball_tree import BallTree
> /usr/local/lib/python2.7/dist-packages/sklearn/neighbors/*init*.py:6:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .ball_tree import BallTree
> /usr/local/lib/python2.7/dist-packages/sklearn/neighbors/*init*.py:6:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .ball_tree import BallTree
> /usr/local/lib/python2.7/dist-packages/sklearn/neighbors/*init*.py:7:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .kd_tree import KDTree
> /usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:28:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._online_lda import (mean_change, _dirichlet_expectation_1d,
> /usr/local/lib/python2.7/dist-packages/sklearn/utils/graph.py:16:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .graph_shortest_path import graph_shortest_path # noqa
> /usr/local/lib/python2.7/dist-packages/sklearn/isotonic.py:11:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._isotonic import _inplace_contiguous_isotonic_regression,
> _make_unique
> /usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:26:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import _utils
> /usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import _barnes_hut_tsne
> /usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import _barnes_hut_tsne
> /usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._criterion import Criterion
> /usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._criterion import Criterion
> /usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._criterion import Criterion
> /usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from .
> *criterion import Criterion
> /usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means*.py:37:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import
> *k_means /usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means*.py:38:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._k_means_elkan import k_means_elkan
> /usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import _hierarchical
> /usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from . import
> *hierarchical
> /usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan*.py:20:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._dbscan_inner import dbscan_inner
> /usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:14:
> RuntimeWarning: numpy.dtype size changed, may indicate binary
> incompatibility. Expected 96, got 88
> from ._hashing import transform as _hashing_transform
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1409#issuecomment-454338359>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6CTd3Z88E0JdFactjT4HIPVskz72ks5vDan6gaJpZM4aAkmN>
> .
>
",according fix give try tue wrote oh version problem many try import magenta well want solve size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import hinge log size may indicate binary incompatibility got import hinge log size may indicate binary incompatibility got import sag size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got criterion import criterion size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import hierarchical size may indicate binary incompatibility got import size may indicate binary incompatibility got import transform thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
454338359,"Oh it was pyasn1 and pyasn1-modules version problem.
But there appeared so many RuntimeWarning.
When I try to import magenta again, I imported well.
But I want to solve this RuntimeWarning.

> /usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ..utils.seq_dataset import ArrayDataset, CSRDataset
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated
/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._random import sample_without_replacement
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import cd_fast
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber
/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .sag_fast import sag
/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import libsvm, liblinear
/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import libsvm, liblinear
/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import libsvm_sparse
/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .ball_tree import BallTree
/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .ball_tree import BallTree
/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .ball_tree import BallTree
/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .kd_tree import KDTree
/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._online_lda import (mean_change, _dirichlet_expectation_1d,
/usr/local/lib/python2.7/dist-packages/sklearn/utils/graph.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from .graph_shortest_path import graph_shortest_path  # noqa
/usr/local/lib/python2.7/dist-packages/sklearn/isotonic.py:11: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique
/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _utils
/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _barnes_hut_tsne
/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _barnes_hut_tsne
/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._criterion import Criterion
/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._criterion import Criterion
/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._criterion import Criterion
/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._criterion import Criterion
/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _k_means
/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._k_means_elkan import k_means_elkan
/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _hierarchical
/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from . import _hierarchical
/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._dbscan_inner import dbscan_inner
/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  from ._hashing import transform as _hashing_transform",oh version problem many try import magenta well want solve size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import hinge log size may indicate binary incompatibility got import hinge log size may indicate binary incompatibility got import sag size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import criterion size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import size may indicate binary incompatibility got import transform,issue,negative,positive,positive,positive,positive,positive
454115293,"Thanks, but I had already seen that link and tried the things suggested there to no avail.",thanks already seen link tried avail,issue,negative,positive,positive,positive,positive,positive
454101998,"Hi, not sure about this one. Is this helpful? https://github.com/tensorflow/tensorflow/issues/15604#issuecomment-426688560",hi sure one helpful,issue,positive,positive,positive,positive,positive,positive
454021665,"@adarob thanks for your input. 

I tried to add ""quantize_weights"" transformation and the .pb file shrinked to 1.7MB. 
I then tried adding ""quantize_nodes"" (without customizing any argument) but the file was slightly bigger than without it (1.9MB).

I then used both of them on the same Android device as the one not quantized, they work the same way as of quality of picture, but unfortunately processing is still slow.

Any other suggestion will be appreciated. Thank you!",thanks input tried add transformation file tried without argument file slightly bigger without used android device one work way quality picture unfortunately still slow suggestion thank,issue,positive,negative,negative,negative,negative,negative
453669721,@kiddungy can you paste the output of the create dataset command and also the file sizes of the generated tfrecord files?,paste output create command also file size,issue,negative,neutral,neutral,neutral,neutral,neutral
453606417,Sorry about the trouble. Can you try changing the line `conda create -n magenta python=2.7` to `conda create -n magenta python=3.5` in magenta-install.sh and see if that fixes it?,sorry trouble try line create magenta create magenta see,issue,negative,negative,negative,negative,negative,negative
453602121,"The issue is likely that you did not quantize, which is what shrinks the model the most. Adding @vdumoulin in case he has any other model-specific information.",issue likely quantize model case information,issue,negative,neutral,neutral,neutral,neutral,neutral
452652573,"Hi @adarob , could you please reopen the ticket? I have got time to work on it only in the last few days, that's why I didn't reply earlier.

@vdumoulin I followed your suggestions and I trained a new model from a 256x256px starry night image, the following one.

![starry_night_256_256](https://user-images.githubusercontent.com/9298564/50893886-3e58ae00-1402-11e9-8117-84a341307b88.jpg)

After that, I tried to stylize the same image I used in the previous attempts, but actually not much seems to be changed. Here the result.

![starry256_1600](https://user-images.githubusercontent.com/9298564/50893964-647e4e00-1402-11e9-81ff-02f7491954f9.png)

Even using smaller content images the transfer result looks like this one. A smaller one attached.

![starry256_480](https://user-images.githubusercontent.com/9298564/50894057-94c5ec80-1402-11e9-84b2-a5e6f84ec410.png)

--------

I tried using another content image, the following:

![japan-panorama-12-min](https://user-images.githubusercontent.com/9298564/50894148-cccd2f80-1402-11e9-8644-b87304b529d1.jpg)

And I transferred the style of my model:

![starry256_japan_0](https://user-images.githubusercontent.com/9298564/50894229-fb4b0a80-1402-11e9-8908-b51565abb6a3.png)

and of yours:

![varied_japan_22](https://user-images.githubusercontent.com/9298564/50894237-01d98200-1403-11e9-9e6f-128dbfb97a6b.png)

Here the result looks much better than the one transferred to the previous content image (the house) but still I see imperfections and I see your model does a better job, so actually I wasn't able to recreate one similar to yours.

Any further suggestion you have will be very appreciated. Thank you for your time.",hi could please reopen ticket got time work last day reply trained new model starry night image following one tried stylize image used previous actually much result even smaller content transfer result like one smaller one attached tried another content image following min transferred style model result much better one transferred previous content image house still see see model better job actually able recreate one similar suggestion thank time,issue,positive,positive,positive,positive,positive,positive
452566557,"Yes I did but I still got same errors.
Should I have to format my ubuntu and reinstall all packages and environments again?
I got stress too much",yes still got format reinstall got stress much,issue,negative,positive,positive,positive,positive,positive
452199573,You should run t2t_datagen (note the underscore) rather than t2t-datagen.  Magenta's t2t_datagen imports the score2perf problems.,run note underscore rather magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
452199018,"The setup.py location you should point to is wherever you cloned the magenta git repo; in other words, the same directory from which you ran ""python setup.py develop"".",location point wherever magenta git directory ran python develop,issue,negative,neutral,neutral,neutral,neutral,neutral
452028103,"Can you try running this command before installing:

`sudo apt-get -y install build-essential libasound2-dev libjack-dev libav-tools`",try running command install,issue,negative,neutral,neutral,neutral,neutral,neutral
452022308,"You can use standard pitch shifting techniques to get different pitches of any input sound. However, having multiple pitches is not required unless you want to be able to play back different pitches.",use standard pitch shifting get different input sound however multiple unless want able play back different,issue,negative,positive,positive,positive,positive,positive
451653512,Any ideas? I think we can use some solutions from here: https://github.com/reiinakano/arbitrary-image-stylization-tfjs Here are the compressed coder and decoder that can be quickly trained and get acceptable quality.,think use compressed coder quickly trained get acceptable quality,issue,negative,positive,positive,positive,positive,positive
451251972,"It sounds like your dataset is much too small. Since the longest MIDI you included is providing most of the training data, you are likely overfitting on it. You could try adding more dropout and stopping training once you see the evaluation loss increasing, but it would be even better if you added more data.",like much small since included providing training data likely could try dropout stopping training see evaluation loss increasing would even better added data,issue,negative,positive,neutral,neutral,positive,positive
451249948,Unfortunately the generator script is not yet compatible with the multitrack models. Would you be able to add it?,unfortunately generator script yet compatible would able add,issue,negative,neutral,neutral,neutral,neutral,neutral
451245951,"I'm guessing you're trying to install tensorflow-gpu on a mac, which doesn't have a pip package for GPUs. Please reopen if there is a magenta-related issue here.",guessing trying install mac pip package please reopen issue,issue,negative,neutral,neutral,neutral,neutral,neutral
450786884,"Hello
In addition to install tensorflow, you may have to install magenta separately.
",hello addition install may install magenta separately,issue,negative,neutral,neutral,neutral,neutral,neutral
450782502,"Which OS?

On Tue, Jan 1, 2019, 5:42 PM Dan1900 <notifications@github.com wrote:

> I use this command install tensorflow:
> pip install tensorflow-gpu
> but the magenta seems can't find it .
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1395>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6FSL0Dau5Xh5c5_NMlmF1xsJHAGiks5u_A50gaJpZM4ZmHou>
> .
>
",o tue dan wrote use command install pip install magenta ca find thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
450506303,"It seems to me that this architecture does not require semantic segmentation, which means that the use of the model will be simplified, and resources will be required much less.",architecture require semantic segmentation use model simplified much le,issue,negative,positive,positive,positive,positive,positive
450202308,"Awesome, thanks! Can you please confirm that it also works for py2?",awesome thanks please confirm also work,issue,positive,positive,positive,positive,positive,positive
449443587,"Hi vdumoulin,

I really appreciate all the information you gave me and the time you spent giving all these insights!
I'll study them and make other attempts, then I'll let you know!

Thank you very much indeed!",hi really appreciate information gave time spent giving study make let know thank much indeed,issue,positive,positive,positive,positive,positive,positive
449436033,"Hi Emanuele!

The resolution of the content and style images you are using is probably too large for the model. We usually train on square content images of size 256px (see [here](https://github.com/tensorflow/magenta/blob/master/magenta/models/image_stylization/image_stylization_train.py#L40)). I don't recall what exact style image sizes we used, but I remember them being smaller than the resolutions you trained at (this is also the case for other commonly-used fast stylization models; see [here](https://github.com/tensorflow/magenta/blob/master/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_train.py#L90) and [here](https://github.com/jcjohnson/fast-neural-style/blob/master/scripts/make_style_dataset.py#L58)).

This has several consequences which could explain your observations:
* The VGG network which is used to compute the style transfer loss was trained on 224x224 inputs, and feeding in much larger inputs runs the risk of getting OOM errors. Likewise, the style transfer network architecture proposed by Johnson et al. and adopted for this model was built with 256x256 inputs in mind.
* The Gram matrices computed from the VGG feature maps are not input-scale invariant, meaning that feeding in the same style image at different resolutions will produce different Gram matrices, and consequently will lead to the style loss emphasizing different kinds of visual textures.
* Once the style transfer network is trained, there's an inherent spatial scale to the visual textures that get embedded onto the stylized image. Given that the model is trained with 256x256 content images, feeding a much larger content image at evaluation time will result in the brush strokes and ""swirls"" appearing comparatively smaller (this is visible in the image you included in point 5). Also, note that stylizing large content images is non-trivial, and this is true even for the optimization-based procedure (see [this paper](https://arxiv.org/abs/1611.07865) for more details).

With all of that in mind, I would suggest that you lower the resolution of the style image you use to train as well as the resolution of the content image you use for evaluation.

Please don't hesitate to reach out again if you have further questions!",hi resolution content style probably large model usually train square content size see recall exact style image size used remember smaller trained also case fast stylization see several could explain network used compute style transfer loss trained feeding much risk getting likewise style transfer network architecture al adopted model built mind gram matrix feature invariant meaning feeding style image different produce different gram matrix consequently lead style loss different visual style transfer network trained inherent spatial scale visual get onto image given model trained content feeding much content image evaluation time result brush comparatively smaller visible image included point also note large content true even procedure see paper mind would suggest lower resolution style image use train well resolution content image use evaluation please hesitate reach,issue,negative,positive,neutral,neutral,positive,positive
449270402,I tried to modify the DockerFile line 1  FROM tensorflow/tensorflow:latest-devel to FROM tensorflow/tensorflow:latest-devel-gpu but it still running on CPU,tried modify line still running,issue,negative,neutral,neutral,neutral,neutral,neutral
448945867,"I made another test and I want to report here the results: same flow as above, I just changed the resolution of the style image used to create the model.

I have used the following one, which has a resolution of 3000 × 2375px. I've tried with a 4000px one but I get OOM errors when I run the model training.

![starry_night_3000](https://user-images.githubusercontent.com/9298564/50278837-72b2fd00-0448-11e9-8c70-83e11984a3b1.jpg)

This is the image with the style applied which I got as a result.

![stylized_starry3000_0](https://user-images.githubusercontent.com/9298564/50278879-86f6fa00-0448-11e9-9dc4-69e7c2d56f43.png)

Unfortunately, also this image doesn't show any sign of the starry night style as the one created with the varied model.
",made another test want report flow resolution style image used create model used following one resolution tried one get run model training image style applied got result unfortunately also image show sign starry night style one varied model,issue,negative,negative,negative,negative,negative,negative
448297230,"> What about the slim-models dependency? Right now the only way people can use it is to clone it and ensure the module is in the path.

Ah, please explain this in the README. I don't think there is a better solution unfortunately, aside from writing a script to do this for the user.",dependency right way people use clone ensure module path ah please explain think better solution unfortunately aside writing script user,issue,positive,positive,neutral,neutral,positive,positive
448294987,What about the slim-models dependency? Right now the only way people can use it is to clone it and ensure the module is in the path.,dependency right way people use clone ensure module path,issue,negative,positive,positive,positive,positive,positive
448292243,@reiinakano please add the binary to https://github.com/tensorflow/magenta/blob/52e6ca806df312ae10d4e32852ecae9675cc4996/setup.py#L67 and this will be good to go,please add binary good go,issue,positive,positive,positive,positive,positive,positive
448271462,"Done. For the docstrings, I just copied over the relevant description from the original functions I based this on.",done copied relevant description original based,issue,negative,positive,positive,positive,positive,positive
447608425,"Which notebook are you referring to?

On Sat, Dec 15, 2018, 12:32 PM Xavier Rey-Robert <notifications@github.com
wrote:

> Hi there,
> Seems like the notebook is broken...
>
> NotFoundError: Restoring from checkpoint failed.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1382>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6ANR6xU2B88utNZR7j4_8oHfCi2aks5u5VxRgaJpZM4ZU44d>
> .
>
",notebook sat wrote hi like notebook broken thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
447162785,@lisiping0817 can you merge with master and make the requested changes so we can pull this in? Thanks!,merge master make pull thanks,issue,negative,positive,positive,positive,positive,positive
447162442,@catherinelee274 can you make the requested changes? We'd love to pull this in! Thanks.,make love pull thanks,issue,positive,positive,positive,positive,positive,positive
446926778,"@ml4046 could you share how you resolved this? 
I use below function to set note_rnn_hparams in RLTuner, values are same as what I used in training attention_rnn, but still got the error : NotFoundError: Key rnn_model/fully_connected/bias not found in checkpoint.

How did you resolved these variable name mismatch between model checkpoint file and var_dict, 'fully_connected/bias'  vs 'fully_connected/biases'? or it's tensorflow version issue

```
def attention_rnn_hparams():
  hparams_dict = {
        'batch_size': 128,
        'rnn_layer_sizes': [128, 128],
        'dropout_keep_prob': 0.5,
        'attn_length': 40,
        'clip_norm': 3,
        'learning_rate': 0.001,
        'residual_connections': False,
        'use_cudnn': False,
        'one_hot_length': NUM_CLASSES
  }
  hparams = tf.contrib.training.HParams(**hparams_dict)
  return hparams
```",could share resolved use function set used training still got error key found resolved variable name mismatch model file version issue false false return,issue,negative,negative,negative,negative,negative,negative
445295429,OK. `--run_dir=/magenta-data/tmp` works if i rename the file _model.ckpt-200.data-00000-of-00001_ to _model.ckpt-200_. Thanks!,work rename file thanks,issue,negative,positive,positive,positive,positive,positive
445289772,You need to upgrade to 0.4.0 (`pip install --upgrade magenta`) to get the new version of the model.,need upgrade pip install upgrade magenta get new version model,issue,negative,positive,positive,positive,positive,positive
445287182,@JoeThanks67 you shouldn't actually need to tar your checkpoint. You can either leave `--checkpoint_file` blank and set `--run_dir=/magenta-data/tmp` to use the latest checkpoint or set `--checkoint_file=/magenta-data/tmp/train/model.ckpt-200`. Please reopen if you still have issues.,actually need tar either leave blank set use latest set please reopen still,issue,negative,positive,positive,positive,positive,positive
445168304,"I encountered the same issue. The pretrained model at https://storage.googleapis.com/magentadata/models/onsets_frames_transcription/checkpoint.zip still works, but I guess it is not the MAESTRO dataset",issue model still work guess maestro,issue,negative,neutral,neutral,neutral,neutral,neutral
444764264,"At first I thought the database was taken down from the ftp server, but I was wrong. It's tricky. Here's how I got it to work:
`ftp -p ftps.tsi.telecom-paristech.fr`
then enter your credentials. Now, if you try `ls` you won't get anything, but if you type `cd maps` it puts you in the right place and then `ls` does work. If you want to download all the files in the database you should first type `prompt` to turn off interactive mode (so it doesn't prompt you for every file), then `mget *`. Hope this helps other lost souls.",first thought taken server wrong tricky got work enter try wo get anything type right place work want first type prompt turn interactive mode prompt every file hope lost,issue,negative,positive,neutral,neutral,positive,positive
444616795,"Thanks very much for the reply Damien, even though this seems very well constructed and easy to execute its seems I'm a bit unlucky about it. It's just that I've been wanting to try this for a long time!

I have tried it as you said, first I went to folder with cd then ran the bazel but still I got the same error.
My video.mp4 is inside the 'working_folder' as well.

```
cd /Users/myname/Desktop/ml/tensorflow/magenta-master

bazel run //magenta/video/next_frame_prediction_pix2pix:create_video  \
  /Users/myname/Desktop/my_project/working_folder  \
  20  \
  500 \
  /Users/myname/Desktop/my_project/backup_folder
```
This is the execution:

```
Last login: Wed Dec  5 22:25:14 on ttys000
cd /Users/myname/Desktop/ml/tensorflow/magenta-master
mynames-iMac:~ myname$ cd /Users/myname/Desktop/ml/tensorflow/magenta-master
mynames-iMac:magenta-master myname$ 
mynames-iMac:magenta-master myname$ bazel run //magenta/video/next_frame_prediction_pix2pix:create_video  \
>   /Users/myname/Desktop/my_project/working_folder  \
>   20  \
>   500 \
>   /Users/myname/Desktop/my_project/backup_folder
INFO: Analysed target //magenta/video/next_frame_prediction_pix2pix:create_video (0 packages loaded).
INFO: Found 1 target...
Target //magenta/video/next_frame_prediction_pix2pix:create_video up-to-date:
  bazel-bin/magenta/video/next_frame_prediction_pix2pix/create_video
INFO: Elapsed time: 0.120s, Critical Path: 0.00s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/magenta/video/next_frame_prediction_pix2pix/create_video /Users/myname/Desktop/my_project/working_folder 20 500 /Users/myname/INFO: Build completed successfully, 1 total action
Train a model and make videos, including steps that generate pre recursive pairs
This script need to be launched from the main tf_toolbox directory, not from the directory witch the script is
!!! This script contains some rm -rf !!! use with care, check arg1 carfully
Train pix2pix to predict the next frame
Do you want to generate the frames from video.mp4? [y/N] y
creating the 'frames' dir
rm: /Users/myname/Desktop/my_project/working_folder/frames/*.jpg: No such file or directory
argument to expand /Users/myname/Desktop/my_project/working_folder/video.mp4
argument expanded ['/Users/myname/Desktop/my_project/working_folder/video.mp4']
start parsing /Users/myname/Desktop/my_project/working_folder/video.mp4
Traceback (most recent call last):
  File ""./magenta/video/tools/extract_frames.py"", line 173, in <module>
    main(0)
  File ""./magenta/video/tools/extract_frames.py"", line 136, in main
    data = skvideo.io.ffprobe(video_filename)['video']
KeyError: 'video'
Do you want to reset the first-frame using a frame from the video? [y/N] 

```


Later on, I manually created the 'frames' folder inside the working_directory, with ~100 RGB 1024x1024 .jpg files inside.

Then this is what happened later on, sorry for the extensive script.

```
Train a model and make videos, including steps that generate pre recursive pairs
This script need to be launched from the main tf_toolbox directory, not from the directory witch the script is
!!! This script contains some rm -rf !!! use with care, check arg1 carfully
Train pix2pix to predict the next frame
Do you want to generate the frames from video.mp4? [y/N] n
keeping 'frames' folder
Do you want to reset the first-frame using a frame from the video? [y/N] y
copying the test frame
cp: /Users/myname/Desktop/my_project/working_folder/frames/f0000001.jpg: No such file or directory
Do you want to generate the 'good' directory? just by copying the frame folder [y/N] y
creating the 'good' dir copying the frame folder
Do you want to (re)create 'train' [y/N] y
recreate 'train'
Do you want to remove or recreate the previous logs (to clean tensorboard)? [y/N] y
removing logs
Do you want to remove the previous generated video? [y/N] y
removing video
rm: /Users/myname/Desktop/my_project/backup_folder/video*.mp4: No such file or directory
Do you want to remove the CURENT model? [y/N] y
removing model checkpoint
rm: /Users/myname/Desktop/my_project/working_folder/pix2pix.model*: No such file or directory
rm: /Users/myname/Desktop/my_project/working_folder/checkpoint: No such file or directory
Do you want to (re)create 'test' and 'val'? [y/N] y
recreate 'test'
rm: /Users/myname/Desktop/my_project/working_folder/test/*.jpg: No such file or directory
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
found  100 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
Traceback (most recent call last):
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 123, in <module>
    main(0)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 99, in main
    match, i = is_match(left, r_list)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 71, in is_match
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
recreate 'val'
rm: /Users/myname/Desktop/my_project/working_folder/val/*.jpg: No such file or directory
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
found  100 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
Traceback (most recent call last):
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 123, in <module>
    main(0)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 99, in main
    match, i = is_match(left, r_list)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 71, in is_match
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
#######################################
starting sequence from 1 to 20
making pairs 1/20
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
found  100 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
Traceback (most recent call last):
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 123, in <module>
    main(0)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 99, in main
    match, i = is_match(left, r_list)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 71, in is_match
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
trainning 1/20
2018-12-05 22:26:15.610410: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
 [*] Reading checkpoint...
 [!] Load failed...
looking for trainning data in /Users/myname/Desktop/my_project/working_folder/train/*.jpg
found 0 data
looking for trainning data in /Users/myname/Desktop/my_project/working_folder/train/*.jpg
found 0 data
looking for trainning data in /Users/myname/Desktop/my_project/working_folder/train/*.jpg
found 0 data
looking for trainning data in /Users/myname/Desktop/my_project/working_folder/train/*.jpg
found 0 data
looking for trainning data in /Users/myname/Desktop/my_project/working_folder/train/*.jpg
found 0 data
cleaning logs
backup model 1
cp: /Users/myname/Desktop/my_project/working_folder/checkpoint: No such file or directory
cp: /Users/myname/Desktop/my_project/working_folder/pix2pix.model*: No such file or directory
generate video test 1
2018-12-05 22:26:35.466466: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Users/myname/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
 [*] Reading checkpoint...
 [!] Load failed...
('sampling image for recursion', 1, '/Users/myname/Desktop/my_project/working_folder/img/first.jpg')
Loading one image ...
Traceback (most recent call last):
  File ""./external/pix2pix_tensorflow/main.py"", line 75, in <module>
    tf.app.run()
  File ""/Users/myname/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./external/pix2pix_tensorflow/main.py"", line 67, in main
    model.recursion(args)
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/model.py"", line 489, in recursion
    sample = [load_data(sample_file, is_test=True, is_one=True) for sample_file in sample_files]
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/utils.py"", line 21, in load_data
    img_A, img_B = load_image(image_path, is_one)
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/utils.py"", line 32, in load_image
    input_img = imread(image_path)
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/utils.py"", line 73, in imread
    return scipy.misc.imread(path).astype(np.float)
  File ""/Users/myname/anaconda2/lib/python2.7/site-packages/numpy/lib/utils.py"", line 101, in newfunc
    return func(*args, **kwds)
  File ""/Users/myname/anaconda2/lib/python2.7/site-packages/scipy/misc/pilutil.py"", line 164, in imread
    im = Image.open(name)
  File ""/Users/myname/anaconda2/lib/python2.7/site-packages/PIL/Image.py"", line 2580, in open
    fp = builtins.open(filename, ""rb"")
IOError: [Errno 2] No such file or directory: '/Users/myname/Desktop/my_project/working_folder/img/first.jpg'
looking for all files in /Users/myname/Desktop/my_project/backup_folder/model_001/*
found  0 files
dyld: Library not loaded: @rpath/libiconv.2.dylib
  Referenced from: /Users/myname/anaconda3/bin/ffmpeg
  Reason: Incompatible library version: ffmpeg requires version 8.0.0 or later, but libiconv.2.dylib provides version 7.0.0
./magenta/video/next_frame_prediction_pix2pix/recursion_640.sh: line 22:  1303 Abort trap: 6           ffmpeg -i $4/%04d.jpg -vcodec libx264 $4.mp4
select some pairs for recursion
looking for all files in /Users/myname/Desktop/my_project/working_folder/good/*
found  100 files
will use limit of 100 files
1 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/46.jpg to /Users/myname/Desktop/my_project/working_folder/recur/46.jpg
2 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/28.jpg to /Users/myname/Desktop/my_project/working_folder/recur/28.jpg
3 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/26.jpg to /Users/myname/Desktop/my_project/working_folder/recur/26.jpg
4 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/72.jpg to /Users/myname/Desktop/my_project/working_folder/recur/72.jpg
5 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/100.jpg to /Users/myname/Desktop/my_project/working_folder/recur/100.jpg
6 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/65.jpg to /Users/myname/Desktop/my_project/working_folder/recur/65.jpg
7 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/67.jpg to /Users/myname/Desktop/my_project/working_folder/recur/67.jpg
8 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/71.jpg to /Users/myname/Desktop/my_project/working_folder/recur/71.jpg
9 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/10.jpg to /Users/myname/Desktop/my_project/working_folder/recur/10.jpg
10 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/4.jpg to /Users/myname/Desktop/my_project/working_folder/recur/4.jpg
11 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/18.jpg to /Users/myname/Desktop/my_project/working_folder/recur/18.jpg
12 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/90.jpg to /Users/myname/Desktop/my_project/working_folder/recur/90.jpg
13 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/82.jpg to /Users/myname/Desktop/my_project/working_folder/recur/82.jpg
14 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/32.jpg to /Users/myname/Desktop/my_project/working_folder/recur/32.jpg
15 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/74.jpg to /Users/myname/Desktop/my_project/working_folder/recur/74.jpg
16 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/48.jpg to /Users/myname/Desktop/my_project/working_folder/recur/48.jpg
17 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/45.jpg to /Users/myname/Desktop/my_project/working_folder/recur/45.jpg
18 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/60.jpg to /Users/myname/Desktop/my_project/working_folder/recur/60.jpg
19 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/58.jpg to /Users/myname/Desktop/my_project/working_folder/recur/58.jpg
20 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/15.jpg to /Users/myname/Desktop/my_project/working_folder/recur/15.jpg
21 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/55.jpg to /Users/myname/Desktop/my_project/working_folder/recur/55.jpg
22 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/87.jpg to /Users/myname/Desktop/my_project/working_folder/recur/87.jpg
23 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/13.jpg to /Users/myname/Desktop/my_project/working_folder/recur/13.jpg
24 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/61.jpg to /Users/myname/Desktop/my_project/working_folder/recur/61.jpg
25 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/47.jpg to /Users/myname/Desktop/my_project/working_folder/recur/47.jpg
26 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/98.jpg to /Users/myname/Desktop/my_project/working_folder/recur/98.jpg
27 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/54.jpg to /Users/myname/Desktop/my_project/working_folder/recur/54.jpg
28 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/16.jpg to /Users/myname/Desktop/my_project/working_folder/recur/16.jpg
29 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/51.jpg to /Users/myname/Desktop/my_project/working_folder/recur/51.jpg
30 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/49.jpg to /Users/myname/Desktop/my_project/working_folder/recur/49.jpg
31 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/19.jpg to /Users/myname/Desktop/my_project/working_folder/recur/19.jpg
32 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/40.jpg to /Users/myname/Desktop/my_project/working_folder/recur/40.jpg
33 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/42.jpg to /Users/myname/Desktop/my_project/working_folder/recur/42.jpg
34 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/70.jpg to /Users/myname/Desktop/my_project/working_folder/recur/70.jpg
35 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/44.jpg to /Users/myname/Desktop/my_project/working_folder/recur/44.jpg
36 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/31.jpg to /Users/myname/Desktop/my_project/working_folder/recur/31.jpg
37 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/68.jpg to /Users/myname/Desktop/my_project/working_folder/recur/68.jpg
38 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/59.jpg to /Users/myname/Desktop/my_project/working_folder/recur/59.jpg
39 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/64.jpg to /Users/myname/Desktop/my_project/working_folder/recur/64.jpg
40 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/95.jpg to /Users/myname/Desktop/my_project/working_folder/recur/95.jpg
41 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/23.jpg to /Users/myname/Desktop/my_project/working_folder/recur/23.jpg
42 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/50.jpg to /Users/myname/Desktop/my_project/working_folder/recur/50.jpg
43 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/41.jpg to /Users/myname/Desktop/my_project/working_folder/recur/41.jpg
44 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/89.jpg to /Users/myname/Desktop/my_project/working_folder/recur/89.jpg
45 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/21.jpg to /Users/myname/Desktop/my_project/working_folder/recur/21.jpg
46 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/11.jpg to /Users/myname/Desktop/my_project/working_folder/recur/11.jpg
47 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/69.jpg to /Users/myname/Desktop/my_project/working_folder/recur/69.jpg
48 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/38.jpg to /Users/myname/Desktop/my_project/working_folder/recur/38.jpg
49 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/5.jpg to /Users/myname/Desktop/my_project/working_folder/recur/5.jpg
50 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/6.jpg to /Users/myname/Desktop/my_project/working_folder/recur/6.jpg
51 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/62.jpg to /Users/myname/Desktop/my_project/working_folder/recur/62.jpg
52 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/2.jpg to /Users/myname/Desktop/my_project/working_folder/recur/2.jpg
53 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/99.jpg to /Users/myname/Desktop/my_project/working_folder/recur/99.jpg
54 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/12.jpg to /Users/myname/Desktop/my_project/working_folder/recur/12.jpg
55 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/92.jpg to /Users/myname/Desktop/my_project/working_folder/recur/92.jpg
56 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/24.jpg to /Users/myname/Desktop/my_project/working_folder/recur/24.jpg
57 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/25.jpg to /Users/myname/Desktop/my_project/working_folder/recur/25.jpg
58 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/96.jpg to /Users/myname/Desktop/my_project/working_folder/recur/96.jpg
59 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/94.jpg to /Users/myname/Desktop/my_project/working_folder/recur/94.jpg
60 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/30.jpg to /Users/myname/Desktop/my_project/working_folder/recur/30.jpg
61 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/83.jpg to /Users/myname/Desktop/my_project/working_folder/recur/83.jpg
62 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/20.jpg to /Users/myname/Desktop/my_project/working_folder/recur/20.jpg
63 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/34.jpg to /Users/myname/Desktop/my_project/working_folder/recur/34.jpg
64 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/81.jpg to /Users/myname/Desktop/my_project/working_folder/recur/81.jpg
65 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/35.jpg to /Users/myname/Desktop/my_project/working_folder/recur/35.jpg
66 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/86.jpg to /Users/myname/Desktop/my_project/working_folder/recur/86.jpg
67 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/91.jpg to /Users/myname/Desktop/my_project/working_folder/recur/91.jpg
68 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/93.jpg to /Users/myname/Desktop/my_project/working_folder/recur/93.jpg
69 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/52.jpg to /Users/myname/Desktop/my_project/working_folder/recur/52.jpg
70 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/56.jpg to /Users/myname/Desktop/my_project/working_folder/recur/56.jpg
71 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/66.jpg to /Users/myname/Desktop/my_project/working_folder/recur/66.jpg
72 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/43.jpg to /Users/myname/Desktop/my_project/working_folder/recur/43.jpg
73 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/1.jpg to /Users/myname/Desktop/my_project/working_folder/recur/1.jpg
74 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/27.jpg to /Users/myname/Desktop/my_project/working_folder/recur/27.jpg
75 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/29.jpg to /Users/myname/Desktop/my_project/working_folder/recur/29.jpg
76 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/85.jpg to /Users/myname/Desktop/my_project/working_folder/recur/85.jpg
77 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/63.jpg to /Users/myname/Desktop/my_project/working_folder/recur/63.jpg
78 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/7.jpg to /Users/myname/Desktop/my_project/working_folder/recur/7.jpg
79 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/9.jpg to /Users/myname/Desktop/my_project/working_folder/recur/9.jpg
80 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/76.jpg to /Users/myname/Desktop/my_project/working_folder/recur/76.jpg
81 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/73.jpg to /Users/myname/Desktop/my_project/working_folder/recur/73.jpg
82 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/37.jpg to /Users/myname/Desktop/my_project/working_folder/recur/37.jpg
83 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/97.jpg to /Users/myname/Desktop/my_project/working_folder/recur/97.jpg
84 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/75.jpg to /Users/myname/Desktop/my_project/working_folder/recur/75.jpg
85 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/3.jpg to /Users/myname/Desktop/my_project/working_folder/recur/3.jpg
86 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/17.jpg to /Users/myname/Desktop/my_project/working_folder/recur/17.jpg
87 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/88.jpg to /Users/myname/Desktop/my_project/working_folder/recur/88.jpg
88 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/57.jpg to /Users/myname/Desktop/my_project/working_folder/recur/57.jpg
89 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/79.jpg to /Users/myname/Desktop/my_project/working_folder/recur/79.jpg
90 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/77.jpg to /Users/myname/Desktop/my_project/working_folder/recur/77.jpg
91 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/8.jpg to /Users/myname/Desktop/my_project/working_folder/recur/8.jpg
92 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/78.jpg to /Users/myname/Desktop/my_project/working_folder/recur/78.jpg
93 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/53.jpg to /Users/myname/Desktop/my_project/working_folder/recur/53.jpg
94 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/33.jpg to /Users/myname/Desktop/my_project/working_folder/recur/33.jpg
95 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/36.jpg to /Users/myname/Desktop/my_project/working_folder/recur/36.jpg
96 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/39.jpg to /Users/myname/Desktop/my_project/working_folder/recur/39.jpg
97 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/84.jpg to /Users/myname/Desktop/my_project/working_folder/recur/84.jpg
98 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/22.jpg to /Users/myname/Desktop/my_project/working_folder/recur/22.jpg
99 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/80.jpg to /Users/myname/Desktop/my_project/working_folder/recur/80.jpg
100 / 100   copying /Users/myname/Desktop/my_project/working_folder/good/14.jpg to /Users/myname/Desktop/my_project/working_folder/recur/14.jpg
use pre-recursion
2018-12-05 22:26:38.979707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
pre recursion
WARNING:tensorflow:From /Users/myname/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
 [*] Reading checkpoint...
 [!] Load failed...
look for files in /Users/myname/Desktop/my_project/working_folder/recur/*.jpg
look for files in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
Traceback (most recent call last):
  File ""./external/pix2pix_tensorflow/main.py"", line 75, in <module>
    tf.app.run()
  File ""/Users/myname/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./external/pix2pix_tensorflow/main.py"", line 70, in main
    model.pre_recursion(args)
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/model.py"", line 544, in pre_recursion
    match, frame_number = self.find_frame(filename, args.recursion, frames_files)
  File ""/private/var/tmp/_bazel_myname/45335007f54935be7f3218e2298a1b20/external/pix2pix_tensorflow/model.py"", line 517, in find_frame
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
generate pairs from recursion
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/recur/*.jpg
found  100 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
Traceback (most recent call last):
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 123, in <module>
    main(0)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 99, in main
    match, i = is_match(left, r_list)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 71, in is_match
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
select some pairs for recursion (long)
looking for all files in /Users/myname/Desktop/my_project/working_folder/good/*
found  100 files
will use limit of 2 files
1 / 2   copying /Users/myname/Desktop/my_project/working_folder/good/65.jpg to /Users/myname/Desktop/my_project/working_folder/recur/65.jpg
2 / 2   copying /Users/myname/Desktop/my_project/working_folder/good/19.jpg to /Users/myname/Desktop/my_project/working_folder/recur/19.jpg
use pre-recursion (long)
2018-12-05 22:26:42.492129: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
pre recursion
WARNING:tensorflow:From /Users/myname/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
 [*] Reading checkpoint...
 [!] Load failed...
look for files in /Users/myname/Desktop/my_project/working_folder/recur/*.jpg
look for files in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
generate pairs from recursion (long)
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/recur/*.jpg
found  2 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
making pairs 2/20
looking for recursive img in /Users/myname/Desktop/my_project/working_folder/frames/*.jpg
found  100 for left list
looking for frames img in /Users/myname/Desktop/my_project/working_folder/good/*.jpg
found  100 for right list
Traceback (most recent call last):
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 123, in <module>
    main(0)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 99, in main
    match, i = is_match(left, r_list)
  File ""./magenta/video/next_frame_prediction_pix2pix/join_pairs.py"", line 71, in is_match
    frame_number = int(basename.split('.')[0][1:])
ValueError: invalid literal for int() with base 10: ''
trainning 2/20
```
",thanks much reply even though well easy execute bit unlucky wanting try long time tried said first went folder ran still got error inside well run execution last login wed run target loaded found target target time critical path build successfully total action running command line build successfully total action train model make generate recursive script need main directory directory witch script script use care check train predict next frame want generate file directory argument expand argument expanded start recent call last file line module main file line main data want reset frame video later manually folder inside inside later sorry extensive script train model make generate recursive script need main directory directory witch script script use care check train predict next frame want generate keeping folder want reset frame video test frame file directory want generate directory frame folder frame folder want create recreate want remove recreate previous clean removing want remove previous video removing video file directory want remove model removing model file directory file directory want create recreate file directory looking recursive found left list looking found right list recent call last file line module main file line main match left file line invalid literal base recreate file directory looking recursive found left list looking found right list recent call last file line module main file line main match left file line invalid literal base starting sequence making looking recursive found left list looking found right list recent call last file line module main file line main match left file line invalid literal base binary use reading load looking data found data looking data found data looking data found data looking data found data looking data found data cleaning backup model file directory file directory generate video test binary use warning removed use instead reading load image recursion loading one image recent call last file line module file line run main file line main file line recursion sample file line file line file line return path file line return file line name file line open file directory looking found library loaded reason incompatible library version version later version line abort trap select recursion looking found use limit use binary use recursion warning removed use instead reading load look look recent call last file line module file line run main file line main file line match file line invalid literal base generate recursion looking recursive found left list looking found right list recent call last file line module main file line main match left file line invalid literal base select recursion long looking found use limit use long binary use recursion warning removed use instead reading load look look generate recursion long looking recursive found left list looking found right list making looking recursive found left list looking found right list recent call last file line module main file line main match left file line invalid literal base,issue,positive,positive,neutral,neutral,positive,positive
443738066,"I wonder why @vdumoulin was assigned in this Issue, shall I reopen this one again? cc: @adarob ",wonder assigned issue shall reopen one,issue,negative,neutral,neutral,neutral,neutral,neutral
443475383,"Okay, now I have seen the problem. Both parameters (`style_images_paths` and `content_images_paths`) accept multiple paths, with a regular expression / pattern. The problem is that paths with regular expressions need to be quoted. Example:

```
arbitrary_image_stylization_with_weights \
  --checkpoint=checkpoint/model.ckpt \
  --output_dir=images/output \
  --style_images_paths='images/style_images/*.jpg' \
  --content_images_paths='images/content_images/*.jpg' \
  --image_size=256 \
  --content_square_crop=False \
  --style_image_size=256 \
  --style_square_crop=False \
  --logtostderr
```",seen problem accept multiple regular expression pattern problem regular need example,issue,negative,neutral,neutral,neutral,neutral,neutral
443474179,"Thanks for your help! it works when when you set an specific content and style image path. The example command in the README is misleading and not working. Looking at the implementation and the name of the parameters (`style_images_paths` and `content_images_paths`) I understood it was accepting multiple paths or a directory. There are some things to improve, definitely. Thanks!",thanks help work set specific content style image path example command misleading working looking implementation name understood multiple directory improve definitely thanks,issue,positive,positive,neutral,neutral,positive,positive
443443271,"Hi @pjmartorell ,

I usually include the actual file in `content_images_paths` and `style_images_paths`. So what I'd probably do is:

```shell
arbitrary_image_stylization_with_weights \
  --maximum_styles_to_evaluate=1000 --checkpoint=checkpoint/model.ckpt \
  --output_dir=images/output/  \
  --style_images_paths=images/style_images/my_style.jpg \  # Put actual style
  --content_images_paths=images/content_images/my_content.jpg \ # Put actual image
  --image_size=256 \
  --content_square_crop=False \
  --style_image_size=256 \
  --style_square_crop=False \
  --logtostderr
```

If you wish to style transfer multiple contents or styles, just use `*.jpg`",hi usually include actual file probably shell put actual style put actual image wish style transfer multiple content use,issue,negative,negative,neutral,neutral,negative,negative
443431811,"This are my parameters and call:

```
arbitrary_image_stylization_with_weights \
  --maximum_styles_to_evaluate=1000 --checkpoint=checkpoint/model.ckpt \
  --output_dir=images/output/  \
  --style_images_paths=images/style_images/ \
  --content_images_paths=images/content_images/ \
  --image_size=256 \
  --content_square_crop=False \
  --style_image_size=256 \
  --style_square_crop=False \
  --logtostderr
```

And this is my output:
```
2018-12-01 15:52:01.205088: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /home/pjmartorell/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_build_model.py:158: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
INFO:tensorflow:loading latest checkpoint file: checkpoint/model.ckpt
INFO:tensorflow:Restoring parameters from checkpoint/model.ckpt
```

The contents and styles are in the correct directory but nothing is generated in the output directory",call output binary use warning calling removed future version use instead loading latest file content correct directory nothing output directory,issue,negative,positive,positive,positive,positive,positive
443429449,"Thanks! seems that now it actually loads the model. Anyway, it's not producing any output given the styles and contents directories. Did it work for you? ",thanks actually model anyway output given content work,issue,negative,positive,neutral,neutral,positive,positive
443427884,"Yes, same thing with me, if your directory structure looks like this:

I suggest you untar it inside a `checkpoint` directory such that (note, I forgot the actual file names):

```
arbitrary_style_transfer_with_weights.py
checkpoint/model.ckpt.data-00000-of-00001
checkpoint/model.meta
checkpoint/model.index
```

Then pass `--checkpoint=checkpoint/model.ckpt` to the arguments. As far as I know it should already load your model automatically",yes thing directory structure like suggest untar inside directory note forgot actual file pas far know already load model automatically,issue,positive,positive,neutral,neutral,positive,positive
443425550,"yes, but it's not ckpt file, it's an index, a meta and data. How do you pass the .ckpt?",yes file index meta data pas,issue,negative,neutral,neutral,neutral,neutral,neutral
443424320,"Hi, for me it's not working,it's not doing anything. You have to load the pre-trained model somehow. Any clue on how to load the pre-trained model?

Thanks",hi working anything load model somehow clue load model thanks,issue,negative,positive,positive,positive,positive,positive
443303250,"Yeah, added them in another commit here. Wasn't sure if the change would be backwards compatible but looks like it is.",yeah added another commit sure change would backwards compatible like,issue,positive,positive,positive,positive,positive,positive
443285211,Could you also make the py3 changes here or in a separate PR?,could also make separate,issue,negative,neutral,neutral,neutral,neutral,neutral
443260339,"Pppp

Regards,
Nitin Naidu

On Fri, 30 Nov 2018, 21:54 Lj Miranda <notifications@github.com wrote:

> I'm trying to follow the instructions for arbitrary style transfer here
> <https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization#stylizing-an-image-using-a-pre-trained-model>,
> and it says that I need to download a pretrained model from this link
> <https://storage.googleapis.com/download.magenta.tensorflow.org/models/arbitrary_style_transfer.tar.gz>.
> However, what I get is a tar.gz file and whenever I extract it, I only
> get the following files:
>
> $ tar xvzf arbitrary_style_transfer.tar.gz
> $ ls arbitrary_style_transfer
> model.ckpt-data-00000-of-000001 model.ckpt.index model.ckpt.meta
>
> Which one here should I use?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1369>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AYeqODiofMdXJqvYGW_l-_4azQ-NlAAmks5u0VulgaJpZM4Y7-au>
> .
>
",wrote trying follow arbitrary style transfer need model link however get file whenever extract get following tar one use thread reply directly view mute thread,issue,negative,neutral,neutral,neutral,neutral,neutral
443260228,"Okay, solved. So  you don't really need to have a `model.ckpt` file. What I do is that I passed the argument `arbitrary_style_transfer/model.ckpt` into `--checkpoint` and it works. No need to have the `ckpt` file",really need file argument work need file,issue,negative,positive,positive,positive,positive,positive
442687970,Sorry about this. The fix should be pushed by end of day tomorrow. Please reopen if it is still broken on Friday. ,sorry fix end day tomorrow please reopen still broken,issue,negative,negative,negative,negative,negative,negative
442539470,"The issue appears to be that the number of records is smaller than your batch size which means 
num_batches is being set to 0. 

To fix this, just reduce your batch size to be the number of records.

I'll add an error message specifying this issue.",issue number smaller batch size set fix reduce batch size number add error message issue,issue,negative,neutral,neutral,neutral,neutral,neutral
442499031,"instead of:

mynames-iMac:magenta-master myname$ bazel run //magenta/video/next_frame_prediction_pix2pix:create_video  \
>   /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder  \
>   20  \
>   500 \
>   /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_

can you try:
//magenta/video/next_frame_prediction_pix2pix:create_video  \
   /Users/myname/Desktop/my_project/working_folder  \
   20  \
   500 \
  Users/myname/Desktop/my_project/backup_folder

and be sure you have a video.mp4 there:
/Users/myname/Desktop/my_project/working_folder 


",instead run try sure,issue,negative,positive,positive,positive,positive,positive
442242177,"I've been running into this same error when using melody_rnn. After some digging I found some relevant code in magenta/models/shared/events_rnn_train.py.

It seems that a flag 'num_eval_examples' is set to a default value of 0. Later on, num_batches is assigned to num_eval_examples (if set) otherwise it attempts to count the number of examples. 

`num_batches = (
        (FLAGS.num_eval_examples if FLAGS.num_eval_examples else
         magenta.common.count_records(sequence_example_file_paths)) //
        config.hparams.batch_size)`

I haven't been setting the num_eval_examples flag so for some reason I suppose the method of counting the eval examples doesn't work properly.

I was able to successfully run evaluation after I added this flag to the melody_rnn_train script:
--num_eval_examples=100",running error digging found relevant code flag set default value later assigned set otherwise count number else setting flag reason suppose method counting work properly able successfully run evaluation added flag script,issue,negative,positive,positive,positive,positive,positive
442225075,"yes, 'unbundled' checkpoint works again. 
here is that problematic bundle: https://yadi.sk/d/yYOojBLh-H0wYQ",yes work problematic bundle,issue,negative,neutral,neutral,neutral,neutral,neutral
442219618,"If you extract the checkpoint from the bundle, can you then make it work with that checkpoint?",extract bundle make work,issue,negative,neutral,neutral,neutral,neutral,neutral
442063698,"observed the same thing with newly trained performance_rnn model (run eval once after the training). 
there were other problems with that process though, possibly unrelated -  https://github.com/tensorflow/magenta/issues/1364",thing newly trained model run training process though possibly unrelated,issue,negative,positive,neutral,neutral,positive,positive
441757114,"Hi @lisiping0817, thanks for reaching out! Can you provide me with more information on the problem you're having?

* What command did you run to create the style dataset?
* What style images did you provide for training? What are their resolution?
* What command did you run to train the model? In particular, did you use the default content/style loss hyperparameters?
* What command did you run to perform the stylization?
* What is the resolution of the content image you stylized?
* What is it about the stylization which does not meet your expectations? Is it the grainy visual artifact, the fact that the sky is not stylized uniformly, or something else?",hi thanks reaching provide information problem command run create style style provide training resolution command run train model particular use default loss command run perform stylization resolution content image stylization meet grainy visual artifact fact sky uniformly something else,issue,negative,positive,positive,positive,positive,positive
441749999,Which model are you referring to? Please reopen with the answer.,model please reopen answer,issue,negative,neutral,neutral,neutral,neutral,neutral
441410181,@kr-ish i have also submitted a change to the colab. Thanks for letting us know!,also change thanks u know,issue,negative,positive,positive,positive,positive,positive
441379872,"Oops I figured it out.
Try this:
```
from magenta.music import sequences_lib
splitted = sequences_lib.split_note_sequence_on_time_changes(<seq>) # a list of node seqs
```",figured try import list node,issue,negative,neutral,neutral,neutral,neutral,neutral
441366964,seems this was missed in #1299 - @kmalta it seems this change also needs to be made in the colab notebook,change also need made notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
441246057,running 0.3.18 and I still get this error when running melody_rnn_train,running still get error running,issue,negative,neutral,neutral,neutral,neutral,neutral
440806706,This is an incompatibility issue with Python3. I have a solution and I will patch this later today.,incompatibility issue python solution patch later today,issue,negative,neutral,neutral,neutral,neutral,neutral
440784602,I just pulled in #895. Please give it a shot and re-open if it doesn't work.,please give shot work,issue,negative,neutral,neutral,neutral,neutral,neutral
440775270,"It looks like #895 may be the fix, but it was never pulled. Looking now.",like may fix never looking,issue,negative,neutral,neutral,neutral,neutral,neutral
440566611,"I came across the same problem. I also got the two midi file from generating model, and as I fed them into the interpolate model, it started to produce UnicodeDecodeError",came across problem also got two file generating model fed interpolate model produce,issue,negative,neutral,neutral,neutral,neutral,neutral
440520783,"some results of a week of investigating this issue:
- it does work out of the box on ubuntu 18.04, tf 1.12, python 2.7 (though with software midi input only - magenta was seeing hardware controller directly but not through alsa, which needed to connect software synth). 
- there's something wrong with current midi input on windows 10 (python 3.5.2, tf 1.8); as soon as generator starts generating, midi input is dead indeed. no idea how these two are linked but it's the fact (both midi io and generator worked ok on their own). midi output/playback is ok though, no problems whatsoever.  // UPD: it depended on the midi sequence length as well, so probably kind of buffer issue. 
- final workaround: made it work by adding OSC input to midi_hub, serving mido.Messages to the rest of the pipeline. can share the code if someone need it, but doubt about official contribution (not so familiar with git alas).",week investigating issue work box python though input magenta seeing hardware controller directly connect something wrong current input python soon generator generating input dead indeed idea two linked fact io generator worked though whatsoever sequence length well probably kind buffer issue final made work input serving rest pipeline share code someone need doubt official contribution familiar git ala,issue,negative,positive,neutral,neutral,positive,positive
440496498,"Thanks for the enthusiasm! Distillation is a cool trick, and we've worked with the authors, but it is a non-trivial amount of work to adapt to something like NSynth because of the multi-step training and broader range of timbres in the dataset, so I don't see us working on that any time soon. We _are_ very excited about some work coming down the line for efficient and maybe realtime audio synthesis, so stay tuned!",thanks enthusiasm distillation cool trick worked amount work adapt something like training range see u working time soon excited work coming line efficient maybe audio synthesis stay tuned,issue,positive,positive,positive,positive,positive,positive
440493753,"Hi, there are some colab notebooks available at:
https://magenta.tensorflow.org/demos/colab/

Also check out the getting started colab:
https://colab.sandbox.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb

That parallels the javascript getting started:
https://hello-magenta.glitch.me/",hi available also check getting getting,issue,negative,positive,positive,positive,positive,positive
440480182,@sonicviz it looks like bazel said this is a TensorFlow problem. Did you find/file a bug there?,like said problem bug,issue,negative,neutral,neutral,neutral,neutral,neutral
440479847,"@Jymfletzfur, if you used Anaconda, did you activate magenta before trying to use bazel?",used anaconda activate magenta trying use,issue,negative,neutral,neutral,neutral,neutral,neutral
440468686,@ericosmic did you solve this problem? Unfortunately your attachments weren't included.,solve problem unfortunately included,issue,negative,negative,negative,negative,negative,negative
440467523,Closing this one since it is fixed according to @eps696.,one since fixed according,issue,negative,positive,neutral,neutral,positive,positive
440467252,"Assuming you are dealing with MIDI output, you can either select the instrument mapping in a DAW or change the program numbers for each instrument to use with a General Midi Soundfont (https://en.wikipedia.org/wiki/General_MIDI).",assuming dealing output either select instrument daw change program instrument use general,issue,negative,positive,neutral,neutral,positive,positive
440015404,@AndreyShagal I bumped the tf and tfp versions in 0.3.15. Please give it a try and reopen if there is still an issue. Thanks!,please give try reopen still issue thanks,issue,positive,positive,positive,positive,positive,positive
439683048,"Could be fixed with:
https://github.com/tensorflow/probability/issues/215

So,
from tensorflow.contrib.linalg.python.ops import linear_operator_addition as linop_add_lib
in /tensorflow_probability/python/distributions/vector_diffeomixture.py
should be changed to
from tensorflow.python.ops.linalg import linear_operator_addition as linop_add_lib",could fixed import import,issue,negative,positive,neutral,neutral,positive,positive
439681466,@cherily which version of python are you using ? I was able to solve the second problem by switching to python 2.7 from 3.6 ... I'm assuming it has something to do with differences in the return type of `tf.size()` when using python 2.7 versus 3.6. The reason this issue exists in the first place may be due to the fact that `tf.train.shuffle_batch()` is deprecated in favor of `tf.data.Dataset.shuffle().batch()`,version python able solve second problem switching python assuming something return type python versus reason issue first place may due fact favor,issue,negative,positive,positive,positive,positive,positive
439641465,@cherily were you able to figure out the second issue ? I am also running into that TypeError,able figure second issue also running,issue,negative,positive,positive,positive,positive,positive
439546271,"Hi, sorry for taking very long to get back on this. Finally found time to set up and test the code. It seems that there are some errors with the handling of the flags variable. `if(flags.mkl)` gives an error when flags is None. This happened to me when running the nsynth_save_embeddings binary or when running nsynth_generate with --gpu_number=1. 

Sorry there's not a test suite, but you should make sure that your code can run the basic binaries (nsynth_save_embeddings) on a bactch of files and run (nsynth_generate) on both audio and embedding files, both with and without gpu.

Here's an example I ran on my own desktop
```
bazel run models/nsynth/wavenet:nsynth_save_embeddings -- --source_path=~/Desktop/nsynth-unit-test/wavs --save_path=~/Desktop/nsynth-unit-test/embeddings --checkpoint_path=~/Desktop/nsynth-unit-test/wavenet-ckpt/model.ckpt-200000 --sample_length=3263400 --alsologtostderr --batch_size=2

bazel run models/nsynth/wavenet:nsynth_generate -- --source_path=~/Desktop/nsynth-unit-test/embeddings --save_path=~/Desktop/nsynth-unit-test/generated  --checkpoint_path=~/Desktop/nsynth-unit-test/wavenet-ckpt/model.ckpt-200000 --sample_length=3263400 --alsologtostderr --encodings=true

bazel run models/nsynth/wavenet:nsynth_generate -- --source_path=~/Desktop/nsynth-unit-test/wavs --save_path=~/Desktop/nsynth-unit-test/generated  --checkpoint_path=~/Desktop/nsynth-unit-test/wavenet-ckpt/model.ckpt-200000 --sample_length=3263400 --alsologtostderr
```",hi sorry taking long get back finally found time set test code handling variable error none running binary running sorry test suite make sure code run basic run audio without example ran run run run,issue,negative,negative,neutral,neutral,negative,negative
439102996,"Ok,  After reinstalling almost everything ( including python 2.7.15 and 3.6.5 ) I've found the solution! I've checked all the versions of tensorflow/magenta/python used in the docker image. It seems like the newest tensorflow ver 1.12.0 which is installed automatically (via pip install tensorflow) produces this problem. Docker image uses ver 1.10.0 (pip install tensorflow==1.10.0) so I've installed the previous version and it started working :) I'm just not sure if its an tensorflow issue itself or how it is used as a dependency in magenta.
Altough its working now I got a couple of warnings :
`WARNING:tensorflow:From /Users/***/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
WARNING:tensorflow:From /Users/***/miniconda2/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
2018-11-15 17:28:49.865877: I tensorflow/core/platform/cpu_feature_guard.cc:141]`",almost everything python found solution checked used docker image like automatically via pip install problem docker image pip install previous version working sure issue used dependency magenta working got couple warning calling removed future version use instead warning calling removed future version use instead,issue,negative,positive,neutral,neutral,positive,positive
438974853,"It might be something with the installation, becuase it seems to work well from the magenta docker image. I've already tried reinstaling both tensorflow and magenta (a couple of times ) and still got the bus error. Gonna try reinstalling python today and maybe use the GPU version. Will post the results here as soon as possible. 
PS. Sorry if this is not the right place for that issue but couldn't help anywhere and I was previously using the tensorflow for other project, which worked fine.",might something installation work well magenta docker image already tried magenta couple time still got bus error gon na try python today maybe use version post soon possible sorry right place issue could help anywhere previously project worked fine,issue,negative,positive,neutral,neutral,positive,positive
438862692,"ouch, it seems i mixed up two threads - current problem is in this one (opened by the same guy and you as assignee): https://github.com/tensorflow/magenta/issues/860
that is, midi interface stops getting any input after first response. and it's pretty hard to debug (i spent few days already with no success). 

btw this issue seems fixed already - in the last version `queue` is imported from `six` and there are no `iteritems` in the code (and obviously all imports are ok - that would be easy to fix)",ouch mixed two current problem one guy assignee interface getting input first response pretty hard spent day already success issue fixed already last version queue six code obviously would easy fix,issue,positive,positive,neutral,neutral,positive,positive
438856984,"You shouldn't need to worry about TensorFlow. You should see which imports etc are failing and fix them one by one until it works :)

You can start by replacing `iteritems` with `items` and  using `six` (https://pythonhosted.org/six/) to fix the Queue module.",need worry see failing fix one one work start six fix queue module,issue,negative,neutral,neutral,neutral,neutral,neutral
438854281,"Adam, thanks for replying! 
Could you maybe give some hints - what directions to go / which modules to check - to try fixing this or find some workaround? I can definitely invest some time in this issue, but my knowledge is rather limited yet, and it's pretty tricky to dissect your system without prior knowledge 'what does what'.
As for Py2 - alas, i'm on Windows (and have to stay with it for reasons) and TF does not support Python 2 on Win platform in general (let alone the very last 1.12 version). ",thanks could maybe give go check try fixing find definitely invest time issue knowledge rather limited yet pretty tricky dissect system without prior knowledge ala stay support python win platform general let alone last version,issue,positive,positive,positive,positive,positive,positive
438837108,"Sorry but this is not something I'll be able to work on in the near future. Can you try using Python2 instead? Also, external contributions are welcome!",sorry something able work near future try python instead also external welcome,issue,negative,positive,positive,positive,positive,positive
438759573,"@fenrirx22 I'm not sure what would cause that error, but I suspect it's something with your Python or Tensorflow setup, since all our code is in Python and shouldn't be capable of causing bus errors. Can you try reinstalling Tensorflow, perhaps without GPU support and see if that helps? If not, this might be a bug report for the Tensorflow issue tracker.",sure would cause error suspect something python setup since code python capable causing bus try perhaps without support see might bug report issue tracker,issue,negative,positive,positive,positive,positive,positive
438747872,"Sounds like a bazel bug then? Maybe try re-installing?

On Mon, Nov 12, 2018 at 6:44 AM tahercoolguy <notifications@github.com>
wrote:

> I am also getting the same Error for bazel --version
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1232#issuecomment-437906794>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6LjpWXaOBFh_AUCClO8-vCQq1aIuks5uuYlbgaJpZM4VQJj1>
> .
>
",like bug maybe try mon wrote also getting error version thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
438157145,"Hi,
Thanks a lot. I will explore these options and see if I will invest or not.

Regards,",hi thanks lot explore see invest,issue,negative,positive,positive,positive,positive,positive
438088083,"Thank you for your interest. This should be possible through software such as [OSCulator](https://osculator.net/) and [MidiStroke](http://charlie-roberts.com/midiStroke/), which can both be used to bind MIDI events from the launchpad to virtual keyboard strokes on your computer.

You can map the MIDI events for a row of your launchpad controller to keyboard keys [1-8] and then use them to control our [web demo](https://tensorflow.github.io/magenta-demos/piano-genie/).

If you have a MIDI keyboard lying around, you might want to test this setup before purchasing a launchpad.

Let me know if you need any additional help.",thank interest possible used bind virtual keyboard computer map row controller keyboard use control web keyboard lying around might want test setup let know need additional help,issue,positive,neutral,neutral,neutral,neutral,neutral
438078515,"hello dear sirs 
any progress on making magenta_midi work with python 3? 
issue is still open, so there's a hope yet.. ",hello dear progress making work python issue still open hope yet,issue,positive,neutral,neutral,neutral,neutral,neutral
438059803,"same here, python 3, win 10
midi input is stopped as soon as _sequence_generator.generate() is called ",python win input stopped soon,issue,negative,positive,positive,positive,positive,positive
437906794,I am also getting the same Error for bazel --version,also getting error version,issue,negative,neutral,neutral,neutral,neutral,neutral
437166150,"Done. I provided as many details as I knew. Please, let me know if I missed something. ",done provided many knew please let know something,issue,negative,positive,positive,positive,positive,positive
437096083,"Oh, I didn't notice your version of MacOS. I'm still on 10.13, so it's certainly possible that something in 10.14 is causing problems with the protobuf library. Can you file a bug over on the protobuf repo about it? https://github.com/protocolbuffers/protobuf",oh notice version still certainly possible something causing library file bug,issue,negative,neutral,neutral,neutral,neutral,neutral
437046659,"Yes, I did. I also installed bazel using brew. I also tried to re-install using the binary installer, but it didn't help. Also, I got a new bunch of errors...

>WARNING: Processed legacy workspace file /Users/admin/magenta/tools/bazel.rc. This file will not be processed in the next release of Bazel. Please read https://github.com/bazelbuild/bazel/issues/6319 for further information, including how to upgrade.
Starting local Bazel server and connecting to it...
INFO: Analysed 282 targets (56 packages loaded).
INFO: Found 226 targets and 56 test targets...
ERROR: /private/var/tmp/_bazel_admin/1176f1bbe090aa2200898e6d3db6281e/external/com_google_protobuf/BUILD:70:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1)
In file included from external/com_google_protobuf/src/google/protobuf/implicit_weak_message.cc:31:
external/com_google_protobuf/src/google/protobuf/implicit_weak_message.h:57:41: error: allocating an object of abstract class type 'google::protobuf::internal::ImplicitWeakMessage'
  MessageLite* New() const { return new ImplicitWeakMessage; }
                                        ^
/usr/local/include/google/protobuf/message_lite.h:247:15: note: unimplemented pure virtual method 'ByteSize' in 'ImplicitWeakMessage'
  virtual int ByteSize() const = 0;
              ^
external/com_google_protobuf/src/google/protobuf/implicit_weak_message.cc:47:31: error: no template named 'ExplicitlyConstructed' in namespace 'google::protobuf::internal'
::google::protobuf::internal::ExplicitlyConstructed<ImplicitWeakMessage>
^
In file included from external/com_google_protobuf/src/google/protobuf/implicit_weak_message.cc:31:
In file included from external/com_google_protobuf/src/google/protobuf/implicit_weak_message.h:35:
/usr/local/include/google/protobuf/arena.h:252:18: error: allocating an object of abstract class type 'google::protobuf::internal::ImplicitWeakMessage'
      return new T;
                 ^
external/com_google_protobuf/src/google/protobuf/implicit_weak_message.h:59:19: note: in instantiation of function template specialization 'google::protobuf::Arena::CreateMessage<google::protobuf::internal::ImplicitWeakMessage>' requested here
    return Arena::CreateMessage<ImplicitWeakMessage>(arena);
                  ^
3 errors generated.
INFO: Elapsed time: 4.549s, Critical Path: 0.81s
INFO: 1 process: 1 local.
FAILED: Build did NOT complete successfully


Can I re-install everything from scratch somehow? It worked until I did an update to 10.14",yes also brew also tried binary installer help also got new bunch warning legacy file file next release please read information upgrade starting local server loaded found test error compilation rule exit file included error object abstract class type new return new note pure virtual method virtual error template file included file included error object abstract class type return new note function template specialization return arena arena time critical path process local build complete successfully everything scratch somehow worked update,issue,negative,positive,positive,positive,positive,positive
436845538,I'm not able to reproduce that error building on Mac with bazel 0.18.1-homebrew. Have you installed xcode as described in the Bazel installation instructions? https://docs.bazel.build/versions/master/install-os-x.html#step-1-install-xcode-command-line-tools,able reproduce error building mac installation,issue,negative,positive,positive,positive,positive,positive
436751622,Updated the [zip file](https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0-midi.zip). Correct sha256 is `f620f9e1eceaab8beea10617599add2e9c83234199b550382a2f603098ae7135`. Will update the website with that info in a bit.,zip file correct sha update bit,issue,negative,neutral,neutral,neutral,neutral,neutral
436316179,"Hi @dugarsumit, I actually had an intern attempt this last summer and the results were not very good. I honestly don't think it's worth the time to pursue further. Thanks for checking!",hi actually intern attempt last summer good honestly think worth time pursue thanks,issue,positive,positive,positive,positive,positive,positive
436313764,Hey @adarob Is this still open? I would like to look into this.,hey still open would like look,issue,negative,neutral,neutral,neutral,neutral,neutral
436307097,@cghawthorne Is this still open? I would like to give it a try.,still open would like give try,issue,negative,neutral,neutral,neutral,neutral,neutral
436191802,"I tried to run 'python music_vae_generate.py ' and addition config , before question is no more occor , but it would report the pretrain checkpoint not found ,  if I change the checkpoint path to the own training checkpoint , it all be ok . So I think the pretrain model maybe unnormal.   ",tried run addition question would report pretrain found change path training think pretrain model maybe unnormal,issue,negative,neutral,neutral,neutral,neutral,neutral
436186466,"I tried to use two midi files(1 and 2 in attachment) generated by hier-tiro_16bar_sample mode as input file for interpolate mode , but it is reported same problem.  Before that,  I have tried to product two three-tracks midi files (11 & 12 file )from polyphone midi  ,  then it would report  unicodedecode error .   






At 2018-11-06 01:16:45, ""Adam Roberts"" <notifications@github.com> wrote:
It seems like it's having trouble reading your MIDI file. If you are
willing to send it over, I can have a look.

On Thu, Nov 1, 2018 at 3:38 AM ericosmic <notifications@github.com> wrote:

> I try to run the interpolate mode in music_ave model to generate example,
> but it is always produce unicodedecode error
> [image: 2018-11-01 18-26-39]
> <https://user-images.githubusercontent.com/35327931/47846950-ae482800-de04-11e8-8358-f0a8f3c0b446.png>
> Is it about the my midi example wrong. I selected two midi exmaple played
> with three tracks(piano, bass, and drum) and 4 bars long. who know what is
> wrong about it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1330>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6M8wffIi9OKNkDXFLtAAjIP6OTMwks5uqs8UgaJpZM4YGKTL>
> .
>


—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or mute the thread.",tried use two attachment mode input file interpolate mode problem tried product two file polyphone would report error wrote like trouble reading file willing send look wrote try run interpolate mode model generate example always produce error image example wrong selected two three piano bass drum long know wrong thread reply directly view mute thread thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
435977963,"It seems like it's having trouble reading your MIDI file. If you are
willing to send it over, I can have a look.

On Thu, Nov 1, 2018 at 3:38 AM ericosmic <notifications@github.com> wrote:

> I try to run the interpolate mode in music_ave model to generate example,
> but it is always produce unicodedecode error
> [image: 2018-11-01 18-26-39]
> <https://user-images.githubusercontent.com/35327931/47846950-ae482800-de04-11e8-8358-f0a8f3c0b446.png>
> Is it about the my midi example wrong. I selected two midi exmaple played
> with three tracks(piano, bass, and drum) and 4 bars long. who know what is
> wrong about it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1330>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6M8wffIi9OKNkDXFLtAAjIP6OTMwks5uqs8UgaJpZM4YGKTL>
> .
>
",like trouble reading file willing send look wrote try run interpolate mode model generate example always produce error image example wrong selected two three piano bass drum long know wrong thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
434395694,"So there's good news and bad news.

:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.

:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.

*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*

<!-- need_author_consent -->",good news bad news good news everyone need sign pull request submitter commit done everything good confused bad news one someone pull request submitter need confirm project please confirm pull request note project maintainer terminal state meaning commit status change state confirm consent commit author set label yes project merge pull request appropriate,issue,positive,positive,positive,positive,positive,positive
434099037,"By default, the eval job expects a new checkpoint every 5 minutes or else it will timeout: https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/events_rnn_train.py#L89

This usually isn't a problem because checkpoints are saved every minute: https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/events_rnn_train.py#L20

But it could happen if your training setup is very slow. You could try altering that code to have a longer timeout, but if your training is really taking >5 minutes for a single step, it might be better to try to find a faster training environment.",default job new every else usually problem saved every minute could happen training setup slow could try code longer training really taking single step might better try find faster training environment,issue,negative,positive,neutral,neutral,positive,positive
432929564,"@cghawthorne @Calvin-Shen   I also try to run train and eval script at same time , but the eval script will report error 
 waiting for new checkpoint in training dir  and time out waiting , just like this :
![2018-10-25 14-20-47](https://user-images.githubusercontent.com/35327931/47479969-5d16c200-d861-11e8-8f3d-e85e3671a01b.png)
Do you know what's wrong with this ?   Thanks",also try run train script time script report error waiting new training time waiting like know wrong thanks,issue,negative,negative,neutral,neutral,negative,negative
432741135,@ericosmic can you try uninstalling and re-installing it? You may also want to try uninstall with pip2 (or pip3) depending on which version of Python you want to keep.,try may also want try pip pip depending version python want keep,issue,negative,neutral,neutral,neutral,neutral,neutral
432682952,Following the above instruction try to utilize all the path to the file because of the absolute unpresent access to the descriptor.,following instruction try utilize path file absolute access,issue,negative,positive,neutral,neutral,positive,positive
432679061,"@ericosmic  I think your system doesn't know what is `music_vae_generate`. When I explored PerformanceRNN model I found the next example:

https://github.com/tensorflow/magenta/blob/master/magenta/scripts/convert_dir_to_note_sequences.py#L19-L25

So you may try to build `music_vae_generate` the same way and run it like in an example. Or you can simply run it using python : `python path_to_file/music_vae_generate.py ...`. I'm not sure but it should help.",think system know model found next example may try build way run like example simply run python python sure help,issue,positive,positive,positive,positive,positive,positive
432667284,"* Try to compile a version of tensorflow on your machine to accompain those kind of changes of API access.
* Freeze a version with that method present on the contrib module",try compile version machine kind access freeze version method present module,issue,positive,positive,positive,positive,positive,positive
431594332,i am also facing this problem since one week but could not fix it till now if any one have any idea pleas guide mee ,also facing problem since one week could fix till one idea guide,issue,negative,neutral,neutral,neutral,neutral,neutral
431452356,Thanks @pbaylies. I don't have a Windows machine around to test it on unfortunately (or fortunately?) :),thanks machine around test unfortunately fortunately,issue,negative,positive,positive,positive,positive,positive
431448240,@adarob There are [some platform-specific differences](https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile) with how Windows handles a NamedTemporaryFile. I'll see if I can test this again and get you the specific error I encountered 11 months ago.,see test get specific error ago,issue,negative,neutral,neutral,neutral,neutral,neutral
431424157,"Ah, sorry I missed that part of the issue. Is this an open issue with Python?",ah sorry part issue open issue python,issue,negative,negative,negative,negative,negative,negative
431395858,"@adarob if that's the case, can you at least test that it works on Windows? Cheers.",case least test work,issue,negative,negative,negative,negative,negative,negative
431107996,"Hi, I think you want to use the name `model.ckpt-200000` without the .index as we do in the colab notebook: https://colab.research.google.com/notebooks/magenta/nsynth/nsynth.ipynb",hi think want use name without notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
430945900,"I have the same problem, I've fixed it by editing the file `~/.local/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/fastgen.py` like this:

```diff
150,153c150
<       #import pdb
<       #pdb.set_trace()
<       #batch_data[i] = data[np.newaxis, :, :]
<       batch_data[i] = data[np.newaxis, :]
---
>       batch_data[i] = data[np.newaxis, :, :]
```

The array `data` is 2D, not 3D here.

EDIT: I'll submit a PR with the fix if I can get the checkpoints to work",problem fixed file like import data data data array data edit submit fix get work,issue,negative,positive,neutral,neutral,positive,positive
430876664,"Sma for me under linux mint.... any update on this issue? I cannot see where the error is.
I can see that the virtual midi input is destroyed after the first message is completed, but no errors or logs, also running it with --log=DEBUG",sma mint update issue see error see virtual input first message also running,issue,negative,positive,positive,positive,positive,positive
430699585,Tried to sync this PR to get it ready for commit and apparently accidentally closed it. Will just create the same change in #1312.,tried sync get ready commit apparently accidentally closed create change,issue,positive,positive,neutral,neutral,positive,positive
430463838,Please also add tensorflow_probability to the required pip packages in https://github.com/tensorflow/magenta/blob/master/magenta/tools/pip/setup.py. Thanks!,please also add pip thanks,issue,positive,positive,positive,positive,positive,positive
430185271,"Hi, thanks for the answer.

It actually is called 'video.mp4'. Here is the full path:
/Users/myname/Desktop/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/video.mp4

I wasn't sure what is tf_toolbox so I'm running magenta from tensorflow folder, perhaps that could be the problem? I feel kinda stuck cause to me everything looks orderly!

Here is the full transcript 

```
mynames-iMac:tensorflow myname$ cd /Users/myname/Desktop/ml/tensorflow/magenta-master
mynames-iMac:magenta-master myname$ 
mynames-iMac:magenta-master myname$ bazel run //magenta/video/next_frame_prediction_pix2pix:create_video  \
>   /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder  \
>   20  \
>   500 \
>   /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/output_folder
Starting local Bazel server and connecting to it...
INFO: Analysed target //magenta/video/next_frame_prediction_pix2pix:create_video (15 packages loaded).
INFO: Found 1 target...
Target //magenta/video/next_frame_prediction_pix2pix:create_video up-to-date:
  bazel-bin/magenta/video/next_frame_prediction_pix2pix/create_video
INFO: Elapsed time: 2.122s, Critical Path: 0.13s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/magenta/video/next_frame_prediction_pix2pix/create_video /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder 20 500 /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_preINFO: Build completed successfully, 1 total action
Train a model and make videos, including steps that generate pre recursive pairs
This script need to be launched from the main tf_toolbox directory, not from the directory witch the script is
!!! This script contains some rm -rf !!! use with care, check arg1 carfully
Train pix2pix to predict the next frame
Do you want to generate the frames from video.mp4? [y/N] y
creating the 'frames' dir
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/*.jpg: No such file or directory
argument to expand /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/video.mp4
argument expanded ['/Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/video.mp4']
start parsing /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/video.mp4
Traceback (most recent call last):
  File ""./magenta/video/tools/extract_frames.py"", line 173, in <module>
    main(0)
  File ""./magenta/video/tools/extract_frames.py"", line 136, in main
    data = skvideo.io.ffprobe(video_filename)['video']
KeyError: 'video'
Do you want to reset the first-frame using a frame from the video? [y/N] y
copying the test frame
cp: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/f0000001.jpg: No such file or directory
Do you want to generate the 'good' directory? just by copying the frame folder [y/N] y
creating the 'good' dir copying the frame folder
cp: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/*: No such file or directory
Do you want to (re)create 'train' [y/N] y
recreate 'train'
Do you want to remove or recreate the previous logs (to clean tensorboard)? [y/N] y
removing logs
Do you want to remove the previous generated video? [y/N] y
removing video
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/output_folder/video*.mp4: No such file or directory
Do you want to remove the CURENT model? [y/N] y
removing model checkpoint
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/pix2pix.model*: No such file or directory
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/checkpoint: No such file or directory
Do you want to (re)create 'test' and 'val'? [y/N] y
recreate 'test'
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/test/*.jpg: No such file or directory
looking for recursive img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/*.jpg
found  0 for left list
looking for frames img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/good/*.jpg
found  0 for right list
recreate 'val'
rm: /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/val/*.jpg: No such file or directory
looking for recursive img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/*.jpg
found  0 for left list
looking for frames img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/good/*.jpg
found  0 for right list
#######################################
starting sequence from 1 to 20
making pairs 1/20
looking for recursive img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/frames/*.jpg
found  0 for left list
looking for frames img in /Users/myname/Desktop/ml/tensorflow/magenta-master/magenta/video/next_frame_prediction_pix2pix/working_folder/good/*.jpg
found  0 for right list
trainning 1/20
```

Thanks so much.
",hi thanks answer actually full path sure running magenta folder perhaps could problem feel stuck cause everything orderly full transcript run starting local server target loaded found target target time critical path build successfully total action running command line build successfully total action train model make generate recursive script need main directory directory witch script script use care check train predict next frame want generate file directory argument expand argument expanded start recent call last file line module main file line main data want reset frame video test frame file directory want generate directory frame folder frame folder file directory want create recreate want remove recreate previous clean removing want remove previous video removing video file directory want remove model removing model file directory file directory want create recreate file directory looking recursive found left list looking found right list recreate file directory looking recursive found left list looking found right list starting sequence making looking recursive found left list looking found right list thanks much,issue,positive,positive,positive,positive,positive,positive
430094870,"@adarob   I'm sure it had upgraded to 0.3.12,  but the same problem exist.  But  I could run the training script  (music_vae_train) successfully.   ",sure problem exist could run training script successfully,issue,negative,positive,positive,positive,positive,positive
430091040,Try doing `pip install -U magenta` and see if it upgrades you to 0.3.12.,try pip install magenta see,issue,negative,neutral,neutral,neutral,neutral,neutral
430089888,"@adarob  sorry,    I don't know how to check the version of magenta , actually I just installed the magenta environment last week.  ",sorry know check version magenta actually magenta environment last week,issue,negative,negative,negative,negative,negative,negative
429991970,"Hi Ailgun.

Your video need to be named video.mp4. An other name won't work for now.

About file structure, the script is just extracting frames as jpg image, but stretch them so they are square.
",hi video need name wo work file structure script image stretch square,issue,negative,neutral,neutral,neutral,neutral,neutral
429536963,"> @dh7

Thanks Adam, it was just that I double checked everything and as far as I see it just should work. 

If perhaps someone who could manage to run this could share the files/folder structure frame_extraction.py creates I can manually create it as well.

Thanks for the fantastic addition to the magenta collection by the way!",thanks double checked everything far see work perhaps someone could manage run could share structure manually create well thanks fantastic addition magenta collection way,issue,positive,positive,positive,positive,positive,positive
429495249,"Change was made in another PR, closing this one.",change made another one,issue,negative,neutral,neutral,neutral,neutral,neutral
426007070,I think @czhuang will need to update it. I'll leave this open until she's able to do it. Thanks!,think need update leave open able thanks,issue,negative,positive,positive,positive,positive,positive
426001621,"@adarob yes, it works. Thank you!
In checkpoint there was:

> model_checkpoint_path: ""model.ckpt""
all_model_checkpoint_paths: ""best_model.ckpt""
all_model_checkpoint_paths: ""model.ckpt""


I reduced to one line:

> model_checkpoint_path: ""best_model.ckpt""


I'm not familiar with TF so I thought there should real file.
Can I re-upload the model to prevent further misunderstanding?",yes work thank reduced one line familiar thought real file model prevent misunderstanding,issue,negative,positive,positive,positive,positive,positive
425966731,"I think you should be pointing to `best_model.ckpt` instead of `model.ckpt`.
---------- Forwarded message ---------
From: oshyshkin <notifications@github.com>
Date: Sun, Sep 30, 2018 at 1:12 PM
Subject: [tensorflow/magenta] CocoNET error: couldn't match model.ckpt
(#1292)
To: tensorflow/magenta <magenta@noreply.github.com>
Cc: Subscribed <subscribed@noreply.github.com>


Hi everyone!

When I tried to generate some samples using pretrained model I got the next
error:

ERROR:tensorflow:Couldn't match files for checkpoint
/Users/admin/coconet_checkpoint/coconet-64layers-128filters/model.ckpt

The folder content:
[image: image]
<https://user-images.githubusercontent.com/13902645/46262175-1ce44e00-c506-11e8-9edb-1212306ee93d.png>

Link on the model I downloaded:
http://download.magenta.tensorflow.org/models/coconet/checkpoint.zip

Do I need to change something or there should be more files?

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub
<https://github.com/tensorflow/magenta/issues/1292>, or mute the thread
<https://github.com/notifications/unsubscribe-auth/ABCa6MlZtjYHTVpmtB6hJxxYkWRkR53Uks5ugSW_gaJpZM4XBIlq>
.
",think pointing instead message date sun subject error could match magenta hi everyone tried generate model got next error error could match folder content image image link model need change something thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
425308867,I don't know if this is related https://github.com/tensorflow/magenta/issues/1183 but seems Windows support is not a priority for some strange reason.,know related support priority strange reason,issue,negative,negative,neutral,neutral,negative,negative
422790208,"I changed the code in magenta\models\pianoroll_rnn_nade\pianoroll_rnn_nade_model.py and fixed it. However, I don't know if it's the correct solution.

line 74
-    return final_state, loglik[:, 0]
+    return final_state, loglik
BTW, when I change it like that, it generates nothing but a starting chord.
",code fixed however know correct solution line return return change like nothing starting chord,issue,positive,positive,neutral,neutral,positive,positive
421675591,"I was looking the old version, sorry.",looking old version sorry,issue,negative,negative,negative,negative,negative,negative
421469279,You might want to take a look at our Performance RNN encoding: https://g.co/magenta/performance-rnn,might want take look performance,issue,negative,neutral,neutral,neutral,neutral,neutral
421232403,"Oh.That's great.I thought that too.Out of 20, i got a bit of error reconstruction in 1 MIDI file.
But can you please guide me to solve this problem,
""How could i vectorize the NoteSequence TFRecord file for feeding into my own neural network and again reconstruct  the midi from the vectorized form. I am using a Variational Autoencoder to train my MIDI file. ""

I will be grateful if you just guide me on this issue.",thought got bit error reconstruction file please guide solve problem could file feeding neural network reconstruct form variational train grateful guide issue,issue,negative,neutral,neutral,neutral,neutral,neutral
421181907,"It could be metadata in the MIDI, we don't support all of that. Are there errors in reconstruction that you see other than the file size changing?",could support reconstruction see file size,issue,negative,neutral,neutral,neutral,neutral,neutral
420412656,"Have a look at the ""Attribute Vectors"" section of the paper (https://goo.gl/magenta/musicvae-paper). Feel free to reopen if you have any specific questions. Good luck!",look attribute section paper feel free reopen specific good luck,issue,positive,positive,positive,positive,positive,positive
418990615,"What you can try is to do a similar process to your midi data, and try to subtract ""dubstep"" vectors with ""classical"" vectors. The subtraction may extract some information about the difference between dubstep songs and classical songs. Then after encoding a classical song, you can add the difference and hopefully get a dubstep song. ",try similar process data try subtract classical subtraction may extract information difference classical classical song add difference hopefully get song,issue,negative,neutral,neutral,neutral,neutral,neutral
418989840,"Hi there, I'm doing a similar project like yours with my friends. What they have done is firstly to manually label different types of music, and then encode these types of music into latent vectors. Then we calculate the average of the latent vectors of one group. For instance, we have calculated the average latent vectors of country music and hip-hop music. Then we encode a random piece of music into a latent vector, add one of the ""style"" vectors calculated before, and then decode the final vector. In fact, this will take effect and make a song sound like ""country music"". But some of my friends said this didn't work. So I think it depends on the dataset you use.

What's more, we have also tried many different ways of operating the latent vectors. For example, we also tried manually label emotions of songs. Then we got ""happy"" vectors and so on. Greater weight applied to ""mood vectors"" did lead to different strength of emotions. Therefore, the latent vector may contain some attribute information based on your labels.

Hopefully my reply can help you :)",hi similar project like done firstly manually label different music encode music latent calculate average latent one group instance calculated average latent country music music encode random piece music latent vector add one style calculated decode final vector fact take effect make song sound like country music said work think use also tried many different way operating latent example also tried manually label got happy greater weight applied mood lead different strength therefore latent vector may contain attribute information based hopefully reply help,issue,positive,positive,positive,positive,positive,positive
418567279,"@wSedler you're likely using a machine that doesn't support some of the instructions the default Tensorflow package is compiled with (e.g., FMA or AVX2). You'll probably need to install Tensorflow from source and not enable some of these instructions.",likely machine support default package probably need install source enable,issue,negative,neutral,neutral,neutral,neutral,neutral
418449824,"if you have some quick time, you can please verify if I addressed the issues correctly.",quick time please verify correctly,issue,negative,positive,positive,positive,positive,positive
417417329,"Yes, it looks like it should have a `console_entry_point` method similar to the other commands in that directory. Can you try adding that and send a pull request?",yes like method similar directory try send pull request,issue,positive,neutral,neutral,neutral,neutral,neutral
417179436,code in the image stylization create dataset,code image stylization create,issue,negative,neutral,neutral,neutral,neutral,neutral
417040214,"It looks like listdir doesn't return the full path, only the filename. You'll need to do `os.path.join(dir_dataset, midi)` to get the full path.",like return full path need get full path,issue,negative,positive,positive,positive,positive,positive
415870947,"Sorry for the confusion. 

The purpose of the different `input_sequence` and `output_sequence` is to allow this to be used effectively as a Seq2Seq model instead of a VAE. The `input_sequence` is what is encoded and the `output_sequence` is what is decoded. In all of the current configs, these are identical.",sorry confusion purpose different allow used effectively model instead current identical,issue,negative,positive,neutral,neutral,positive,positive
415626736,"thank you i slove this problem  but there is new problem
",thank problem new problem,issue,negative,positive,positive,positive,positive,positive
415488116,That looks like an issue with your Python distribution. I'd recommend going through the manual installation steps in our main README and installing a separate conda environment: https://github.com/tensorflow/magenta#manual-install,like issue python distribution recommend going manual installation main separate environment,issue,positive,positive,positive,positive,positive,positive
415472291,"There's no ""big"" model available at this time, but there is a hier-multiperf_vel_1bar_med_chords model that's used by the Multitrack MusicVAE notebook: https://colab.research.google.com/notebooks/magenta/music_vae/multitrack.ipynb

The checkpoint files are here:
https://storage.cloud.google.com/download.magenta.tensorflow.org/models/music_vae/multitrack/model_chords_fb64.ckpt.data-00000-of-00001
https://storage.cloud.google.com/download.magenta.tensorflow.org/models/music_vae/multitrack/model_chords_fb64.ckpt.index
https://storage.cloud.google.com/download.magenta.tensorflow.org/models/music_vae/multitrack/model_chords_fb64.ckpt.meta",big model available time model used notebook,issue,negative,positive,positive,positive,positive,positive
415360697,i want to know the JACK library commands in centos .how can i get it ,want know jack library get,issue,negative,neutral,neutral,neutral,neutral,neutral
415071056,"I believe Nan loss is caused, in this case, by exploding/vanishing gradients. In order to fix this you can decrease the size of your layers, as I did, or try decreasing the clip_norm in order to prevent exploding gradients. Let me know if any of these options help.",believe nan loss case order fix decrease size try decreasing order prevent let know help,issue,negative,neutral,neutral,neutral,neutral,neutral
414994843,Are there any updates on this? I am also having this error and I'm unable to create any images at all. Tried downgrading to tf 1.0.1 without success. @hav4ik would it be easy to share how you edited the scripts with the above code? Thanks in advance.,also error unable create tried without success would easy share code thanks advance,issue,negative,positive,positive,positive,positive,positive
414745168,This may be related to https://stackoverflow.com/questions/49094597/illegal-instruction-core-dumped-after-running-import-tensorflow. Do you have an older CPU that doesn't support AVX instructions? You may have to either manually build tensorflow or pip install an older version of tensorflow.,may related older support may either manually build pip install older version,issue,negative,positive,positive,positive,positive,positive
414729560,"I've updated the checkpoints.tar.gz file, which resolves this issue. 

@jincong0623 please open a separate issue. As a quick answer: the checkpoints contain model weights, not MIDI files. I have not added a script to generate yet (see #1199) but you can see how to do it in https://g.co/magenta/musicvae-colab.",file issue please open separate issue quick answer contain model added script generate yet see see,issue,negative,positive,positive,positive,positive,positive
414639727,"Got the same error, which can be fixed by changing the above.
Would be great if a default installation ""just worked"".",got error fixed would great default installation worked,issue,negative,positive,positive,positive,positive,positive
414590220,"I updated docker package.
And after that any execution (training/) gives only one line ""Illegal instruction""   no stack trace or any other error messages. For example - music_vae_train (or any other method)  execution with or without parameters gives ""Illegal instruction""  
",docker package execution one line illegal instruction stack trace error example method execution without illegal instruction,issue,negative,negative,negative,negative,negative,negative
414534755,"Hi, @adarob 
I was training the musicvae model, and batch size=32, but it's too slow just generate 50 model.ckpt files for 3 days. However, I'm not sure how to open the ckpt files or switch them to midi files and normally most of the generated files are midi files. Could you offer me some references or instruct me how to resolve the ckpt files to midi files. Thanks a lot!",hi training model batch slow generate day however sure open switch normally could offer instruct resolve thanks lot,issue,positive,positive,positive,positive,positive,positive
414492516,@AndreyShagal Can you provide a little more context? Is there a longer error message or a stack trace? Does this happen for training or inference?,provide little context longer error message stack trace happen training inference,issue,negative,negative,negative,negative,negative,negative
414490411,Thanks for the update (and apologies for not properly citing you earlier)! Could you add the citation to magenta/models/polyphony_rnn/README.md as well?,thanks update properly could add citation well,issue,positive,positive,neutral,neutral,positive,positive
414467565,"If you have some time, please take a look into the modifications as you have suggested.",time please take look,issue,negative,neutral,neutral,neutral,neutral,neutral
414372567,"I'm training a data set with max seq length of 150 for thedata set of 2000/300/300 sketches and I am getting nan cost after about 30k steps, anybody has any idea why is that?

Note: Im still able to generate some decent sketches with it",training data set length set getting nan cost anybody idea note still able generate decent,issue,negative,positive,positive,positive,positive,positive
414054480,"Latest version of magenta in docker gives me ""Illegal instruction"" for any model  run :(",latest version magenta docker illegal instruction model run,issue,negative,neutral,neutral,neutral,neutral,neutral
413338885,I have changed as you have suggested. Please take a look and let me know .,please take look let know,issue,negative,neutral,neutral,neutral,neutral,neutral
413017244,Pip package for release 0.3.11 is now available.,pip package release available,issue,negative,positive,positive,positive,positive,positive
412756017,"Hi, thanks for the question!

The dimensions of Z aren't actually anything specific. The latent space is a learned feature space and its dimensions are not constrained to have any specific meaning. However, the variational loss forces the space to be structured, which makes it possible to determine directions in this space that align to meaningful attributes. This is what the section of the paper on attribute vectors is discussing. 

I'd recommend you look at https://distill.pub/2017/aia if you want to learn a bit more about latent spaces.

Feel free to reopen if you have more questions.",hi thanks question actually anything specific latent space learned feature space constrained specific meaning however variational loss space structured possible determine space align meaningful section paper attribute recommend look want learn bit latent feel free reopen,issue,positive,positive,positive,positive,positive,positive
412656189,"This is addressed by #1251, but we still need to create a new version of the pip package.",still need create new version pip package,issue,negative,positive,positive,positive,positive,positive
412445089,"by the way, what is the loss of the last step of this model?",way loss last step model,issue,negative,neutral,neutral,neutral,neutral,neutral
412402064,Which checkpoint are you trying to use? I may have stripped out some of the training variables but I can fix that if needed.,trying use may stripped training fix,issue,negative,neutral,neutral,neutral,neutral,neutral
412355619,Full path worked. There were other issues though.. As pointed out in https://github.com/tensorflow/magenta/issues/853,full path worked though pointed,issue,negative,positive,positive,positive,positive,positive
412219246,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm order pas check please resolve problem pull request author add another comment bot run bot comment think anything,issue,positive,negative,negative,negative,negative,negative
410409452,"I have refactored the code as suggested. Please take a look, and let me know if any other changes are needed.",code please take look let know,issue,negative,neutral,neutral,neutral,neutral,neutral
409260462,GPU package is installed correctly. The problem is that the default batch_size is too big even for a 24G GPU.,package correctly problem default big even,issue,negative,neutral,neutral,neutral,neutral,neutral
409253682,"Are you using the GPU pip package?

On Tue, Jul 31, 2018 at 5:13 AM Howard Lau <notifications@github.com> wrote:

> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1246>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6A5xd2Msu-KsY-o6YRaR_oEuyQAqks5uMEnTgaJpZM4VoIxD>
> .
>
",pip package tue wrote thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
409194128,"Use bazel to build from the latest source, NO ERRORS.",use build latest source,issue,negative,positive,positive,positive,positive,positive
409164041,"Mac OS 10.13.6, python 3.5 same problem",mac o python problem,issue,negative,neutral,neutral,neutral,neutral,neutral
407919990,You need to run that command from within the magenta directory after cloning the github repo.,need run command within magenta directory,issue,negative,neutral,neutral,neutral,neutral,neutral
407500800,"Have you tried to use the full path instead of the relative path?

On Fri, Jul 20, 2018 at 7:56 AM Angad Singh <notifications@github.com>
wrote:

>
>    1.
>
>    I think the command given on the nsynth model readme has a typo. It
>    should be wavenet:train rather than wavenet/train.
>    2.
>
>    When I try training the model, I get the following error:
>
> INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>, ../../train/records/nsynth-train.tfrecord; Not a directory
> 	 [[Node: ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/device:CPU:0""](TFRecordReaderV2, input_producer/FIFOQueueV2)]]
>
> Any ideas why? The .tfrecord file is definitely present. Do I need to
> extract it or process it in someway?
>
>    1. Is there a way to continue training from a checkpoint? I want to
>    potentially fine-tune the model on some new data.
>
> I would be really appreciate any help here!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1234>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6Lsb2cIWMnHRyhJmHQaQald2V-u1ks5uIe-vgaJpZM4VYLDs>
> .
>
",tried use full path instead relative path singh wrote think command given model typo train rather try training model get following error error class directory node file definitely present need extract process someway way continue training want potentially model new data would really appreciate help thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
406217380,"Sure thing, sorry for the delay:

I ran these commands:
from os import system

# Number of iterations.
TRAIN_STEPS=10 #for testing

# Folder containing MIDI and/or MusicXML files. can have child folders.
INPUT_DIRECTORY='/home/jfonseca/side_projs/midi_proj/midi_collection'

# TFRecord file that will contain NoteSequence protocol buffers.
SEQUENCES_TFRECORD='/home/jfonseca/side_projs/midi_proj/note_sequences/notesequences.tfrecord'

# SequenceExamples are fed into the model during training and evaluation
SEQUENCES_EXAMPLES='/home/jfonseca/side_projs/midi_proj/note_sequences/sequence_examples/'

# Run dir
RUN_DIR= '/home/jfonseca/side_projs/midi_proj/logdir/run1'

# Create dataset
system(
""""""
convert_dir_to_note_sequences \
  --input_dir=%s \
  --output_file=%s \
  --recursive
"""""" % (INPUT_DIRECTORY, SEQUENCES_TFRECORD)
)

# Create SequenceExamples
system(
""""""
pianoroll_rnn_nade_create_dataset \
--input=%s \
--output_dir=%s \
--eval_ratio=0.10
"""""" % (SEQUENCES_TFRECORD, SEQUENCES_EXAMPLES)
)

# Train and Evaluate the Model
system(
""""""
pianoroll_rnn_nade_train \
--run_dir=%s \
--sequence_example_file=%seval_pianoroll_tracks.tfrecord \
--hparams=""batch_size=48,rnn_layer_sizes=[128]"" \
--num_training_steps=%s \
"""""" % (RUN_DIR, SEQUENCES_EXAMPLES, TRAIN_STEPS)
)


system(
""""""
pianoroll_rnn_nade_generate \
--run_dir=%s \
--output_dir=/home/jfonseca/midi_proj/generated \
--num_outputs=20 \
--num_steps=128 \
--primer_pitches=""[67,64,60]"" \
--hparams=""batch_size=48,rnn_layer_sizes=[128]""
"""""" % RUN_DIR
)
`

I was running each command one by one, the error occurred in the pianoroll_rnn_nade_generate:

`Traceback (most recent call last):
  File ""/home/jfonseca/miniconda3/envs/magenta/bin/pianoroll_rnn_nade_generate"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 251, in console_entry_point
    tf.app.run(main)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 247, in main
    run_with_flags(generator)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_generate.py"", line 210, in run_with_flags
    generated_sequence = generator.generate(primer_sequence, generator_options)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 196, in generate
    return self._generate(input_sequence, generator_options)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_sequence_generator.py"", line 121, in _generate
    total_steps, pianoroll_seq, **args)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_model.py"", line 98, in generate_pianoroll_sequence
    steps_per_iteration=steps_per_iteration)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 361, in _generate_events
    steps_per_iteration=steps_per_iteration)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/common/beam_search.py"", line 134, in beam_search
    beam_entries, generate_step_fn, branch_factor, first_iteration_num_steps)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/common/beam_search.py"", line 67, in _generate_branches
    all_sequences, all_states, all_scores)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 215, in _generate_step
    temperature)
  File ""/home/jfonseca/miniconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_model.py"", line 75, in _generate_step_for_batch
    return final_state, loglik[:, 0]
IndexError: too many indices for array`

Again, thank you for your help!",sure thing sorry delay ran o import system number testing folder child file contain protocol fed model training evaluation run create system recursive create system train evaluate model system system running command one one error recent call last file line module file line main file line run main file line main generator file line file line generate return file line file line file line file line file line file line temperature file line return many index array thank help,issue,positive,positive,positive,positive,positive,positive
406023486,Is there a longer stacktrace to tell us what line that error was raised at?,longer tell u line error raised,issue,negative,neutral,neutral,neutral,neutral,neutral
406003815,"Thanks! Got a new error when I did that though (basically copied and pasted the hparams part from train): IndexError: too many indices for array

Any idea what this could be?

",thanks got new error though basically copied pasted part train many index array idea could,issue,negative,positive,positive,positive,positive,positive
406001551,You need to pass the same --hparams flag into generate as you used in train.,need pas flag generate used train,issue,negative,neutral,neutral,neutral,neutral,neutral
403255391,"Is there a resolution to this, or does anyone know anything about it?

Seems to be the same error as 
https://github.com/bazelbuild/bazel/issues/3803 and https://github.com/tensorflow/magenta/issues/901 but both are redirected to look at other possible solutions with no errors and are unresolved but still get closed.

ERROR: E:/music/magenta/magenta/magenta/models/arbitrary_image_stylization/BUILD:33:1: PythonZipper magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_train.zip failed (Exit -1): zipper.exe failed: error executing command
  cd C:/users/paul/_bazel_paul/b626u53e/execroot/__main__
  SET PATH=D:\msys64\usr\bin;D:\msys64\bin;D:\Users\paul\Anaconda3\envs\tensorflow;D:\Users\paul\Anaconda3\envs\tensorflow\Library\mingw-w64\bin;D:\Users\paul\Anaconda3\envs\tensorflow\Library\usr\bin;D:\Users\paul\Anaconda3\envs\tensorflow\Library\bin;D:\Users\paul\Anaconda3\envs\tensorflow\Scripts;D:\Users\paul\Anaconda3\envs\tensorflow\bin;d:\Users\paul\Anaconda3;d:\Users\paul\Anaconda3\Library\mingw-w64\bin;d:\Users\paul\Anaconda3\Library\usr\bin;d:\Users\paul\Anaconda3\Library\bin;d:\Users\paul\Anaconda3\Scripts;D:\Users\paul\Anaconda3\Library\bin;C:\Program Files\Docker\Docker\Resources\bin;d:\Program Files\ImageMagick-7.0.7-Q16;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.1\libnvvp;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\ia32\compiler;C:\Program Files (x86)\Common Files\Intel\Shared Libraries\redist\intel64\compiler;C:\ProgramData\Oracle\Java\javapath;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\GtkSharp\2.12\bin;C:\Program Files (x86)\Skype\Phone\;D:\Program Files\nodejs\;D:\Program Files\PuTTY\;D:\ffmpeg\bin;d:\Program Files\Git\cmd;D:\Program Files (x86)\Yarn\bin;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\Program Files\dotnet\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\paul\AppData\Local\Microsoft\WindowsApps;C:\Users\paul\AppData\Roaming\npm;D:\ffmpeg\bin;d:\Program Files\Microsoft VS Code\bin;C:\Users\paul\AppData\Local\Yarn\bin;C:\Users\paul\AppData\Local\Microsoft\WindowsApps;
  external/bazel_tools/tools/zip/zipper/zipper.exe cC bazel-out/x64_windows-opt/bin/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_train.zip @bazel-out/x64_windows-opt/bin/magenta/models/arbitrary_image_stylization/arbitrary_image_stylization_train.zip-2.params

INFO: Elapsed time: 1.717s, Critical Path: 0.17s
INFO: 0 processes.
FAILED: Build did NOT complete successfully",resolution anyone know anything error look possible unresolved still get closed error exit error command set time critical path build complete successfully,issue,negative,positive,positive,positive,positive,positive
401819662,The script here helps me to export the model with an input: https://github.com/tensorflow/tensorflow/issues/9678,script export model input,issue,negative,neutral,neutral,neutral,neutral,neutral
401505044,"For py3 compatibility, I think you'll need to switch to six.iteritems",compatibility think need switch,issue,negative,neutral,neutral,neutral,neutral,neutral
401421434,"See discussion in #775. It should be possible, but I haven't tried it myself. Let us know if you get it working!",see discussion possible tried let u know get working,issue,negative,neutral,neutral,neutral,neutral,neutral
401355562,"Thanks @panmari for localizing the first occurrence of the issue. The problem is caused by `NaN` values in the weights of `Conv2D` layers. The reason why the network works on GPU is supposedly because GPU does not have a exception mechanism, so `NaN` values will be converted to zeros. On CPU, however, the `NaN` is preserved thorough computation.

My personal workaround of this issue is the following:
```python
for var in tf.global_variables():
    w = var.eval()
    w = np.nan_to_num(w)
    var.assign(w).eval()
```
This snippet should be placed every time you load the model into the session. Worked for `tensorflow==1.8.0`. Will make a pull request soon onto both [tensorflow/magenta](https://github.com/tensorflow/magenta) and [tensorflow/magenta-demos](https://github.com/tensorflow/magenta-demos) repositories.

A more correct solution should be replacing all the weights in the model according to the snippet above (so someone should upload the new weights onto [download.magenta.tensorflow.org/models/](download.magenta.tensorflow.org/models/) upstream).",thanks first occurrence issue problem nan reason network work supposedly exception mechanism nan converted however nan thorough computation personal issue following python snippet every time load model session worked make pull request soon onto correct solution model according snippet someone new onto upstream,issue,negative,positive,positive,positive,positive,positive
401186026,"Hi @yemeijuan 

Sketch-RNN only works with vector images, unfortunately png is a raster image format that it doesn't support.",hi work vector unfortunately raster image format support,issue,negative,negative,negative,negative,negative,negative
399986163,"I am having a similar issue with the Sketch RNN example. I've added the traceback below when running `sketch_rnn_train`, which looks similar to @Techagogy 's.

```
Traceback (most recent call last):
  File ""/home/areddy/anaconda3/envs/magenta/bin/sketch_rnn_train"", line 7, in <module>
    from magenta.models.sketch_rnn.sketch_rnn_train import console_entry_point
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/__init__.py"", line 34, in <module>
    import magenta.music.audio_io
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/music/audio_io.py"", line 20, in <module>
    import librosa
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/__init__.py"", line 12, in <module>
    from . import core
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/core/__init__.py"", line 104, in <module>
    from .time_frequency import *  # pylint: disable=wildcard-import
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/core/time_frequency.py"", line 10, in <module>
    from ..util.exceptions import ParameterError
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/util/__init__.py"", line 67, in <module>
    from .utils import *  # pylint: disable=wildcard-import
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/util/utils.py"", line 111, in <module>
    def valid_audio(y, mono=True):
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/librosa/cache.py"", line 49, in wrapper
    if self.cachedir is not None and self.level >= level:
  File ""/home/areddy/anaconda3/envs/magenta/lib/python2.7/site-packages/joblib/memory.py"", line 847, in cachedir
    DeprecationWarning, stacklevel=2)
TypeError: expected string or buffer
```

Not a particularly elegant solution, but I copy-pasted the files I needed from the directory in this repo and then installed `magenta-gpu`. There were some minor errors, but it looks like it's training now.",similar issue sketch example added running similar recent call last file line module import file line module import file line module import file line module import core file line module import file line module import file line module import file line module file line wrapper none level file line string buffer particularly elegant solution directory minor like training,issue,positive,positive,neutral,neutral,positive,positive
399953232,"I hava the same error,but I couldn't solve the problem after doing as you said",error could solve problem said,issue,negative,neutral,neutral,neutral,neutral,neutral
399679464,"Can i work on this ? and is the idea of porting the SeqGAN still hold. Because for generating texts we now also have other options like rankGAN, leakGAN, and a textGAN",work idea still hold generating also like,issue,negative,neutral,neutral,neutral,neutral,neutral
397947661,"Hello, I was wondering if you have fixed the model without creating the full training dataset? We want to run the model locally but now we still can't do it due to lack of MAPS dataset.
Hope to hear from you soon. Thank you.",hello wondering fixed model without full training want run model locally still ca due lack hope hear soon thank,issue,negative,positive,neutral,neutral,positive,positive
397303137,"It turns out that using smaller layer_sizes such as [128,128] solves the issue. Does anyone have any idea why this is the case? Perhaps lowering the learning rate can allow me to use larger layer_sizes? 

Thanks.",turn smaller issue anyone idea case perhaps lowering learning rate allow use thanks,issue,negative,positive,neutral,neutral,positive,positive
397299247,"Got to work by installing an older version of Magenta with :  
`pip install magenta==0.1.10` 

After that, I've uninstalled the TensorFlow dependency installed by the Magenta package with: 
`pip uninstall tensorflow`

And finally, I've installed the compatible version of TF for Magenta v0.1.10 with: 
`pip install tensorflow==1.0.1`

You should be able to run the notebook/demos after going through the steps above and get styled images. ",got work older version magenta pip install uninstalled dependency magenta package pip finally compatible version magenta pip install able run going get,issue,negative,positive,positive,positive,positive,positive
397073367,i initialized random.seed(123) in melody_rnn_generate.py but it is not effective and producing different outputs every time. is there any suggestion on where else should i fix the seed? ,effective different every time suggestion else fix seed,issue,negative,positive,positive,positive,positive,positive
396977429,"Would someone mind submitting a fix to this?

On Tue, Jun 12, 2018 at 6:28 PM ihavetoomanyquestions <
notifications@github.com> wrote:

> found the problem: after you create NoteSequences, you have to create
> SequenceExamples and feed it to the training script, otherwise it gives
> that error..
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1145#issuecomment-396784596>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6GD_p9UhMKt2MdvwiMnu1_48jOXjks5t8GrEgaJpZM4TZ2At>
> .
>
",would someone mind fix tue wrote found problem create create feed training script otherwise error thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
396851065,"One more thing:
after the training starts, it display one message: ""Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA""
It kind of stuck here, but the CPUs are all running at 100%, the system is not hang on or crash. Don't know why.

Is that message the reason cause my problem? Will it affect my training?",one thing training display one message binary use kind stuck running system crash know message reason cause problem affect training,issue,negative,positive,positive,positive,positive,positive
396784596,"found the problem: after you create NoteSequences, you have to create SequenceExamples and feed it to the training script, otherwise it gives that error..
",found problem create create feed training script otherwise error,issue,negative,neutral,neutral,neutral,neutral,neutral
396559361,@twobob did you find any solution? i am also having the same problem. i would appreciate if you can share your workaround if you found one!,find solution also problem would appreciate share found one,issue,positive,neutral,neutral,neutral,neutral,neutral
395968099,"@ml4046 
Hi! I have been busy with other stuff such as the background report for my thesis, but I managed to get the whole thing working, train a basic_rnn and use my own dataset. However, I am now trying to adapt the code to use an attention_rnn instead (a variant of the basic_rnn). I have two issues: 1. I get Nan loss during training for the attention_rnn and 2. The checkpoint that I have (from earlier in the training, before the error) does not work (shapes are different). What I did was simply change the make_rnn_cell part of the code to include attn_length=40, in order to apply the attention wrapper on the lstm cell. 

Anyway, have you experienced any issues similar to these with Magenta code? 

As always, thanks so much for the help.",hi busy stuff background report thesis get whole thing working train use however trying adapt code use instead variant two get nan loss training training error work different simply change part code include order apply attention wrapper cell anyway experienced similar magenta code always thanks much help,issue,negative,positive,positive,positive,positive,positive
395941755,"The list of Magenta models can be found [here](https://github.com/tensorflow/magenta/tree/master/magenta/models). I believe most (if not all) of them are meant for music/art synthesis.

[Here's a tutorial](https://hackernoon.com/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194) on using deep learning to classify audio by genre using convolutional neural networks.",list magenta found believe meant synthesis tutorial deep learning audio genre convolutional neural,issue,negative,neutral,neutral,neutral,neutral,neutral
395932663,"I'm having the same issue. 

**[Example Output]**
Completed.

INFO:tensorflow:Processed 2122 inputs total. Produced 0 outputs.
INFO:tensorflow:DAGPipeline_DrumsExtractor_eval_drum_track_lengths_in_bars:

INFO:tensorflow:DAGPipeline_DrumsExtractor_eval_drum_tracks_discarded_too_long: 0
INFO:tensorflow:DAGPipeline_DrumsExtractor_eval_drum_tracks_discarded_too_short: 0
INFO:tensorflow:DAGPipeline_DrumsExtractor_eval_drum_tracks_truncated: 0
INFO:tensorflow:DAGPipeline_DrumsExtractor_training_drum_track_lengths_in_bars:

INFO:tensorflow:DAGPipeline_DrumsExtractor_training_drum_tracks_discarded_too_long: 0
INFO:tensorflow:DAGPipeline_DrumsExtractor_training_drum_tracks_discarded_too_short: 0
INFO:tensorflow:DAGPipeline_DrumsExtractor_training_drum_tracks_truncated: 0
INFO:tensorflow:DAGPipeline_RandomPartition_eval_drum_tracks_count: 214
INFO:tensorflow:DAGPipeline_RandomPartition_training_drum_tracks_count: 1908",issue example output total produced,issue,negative,neutral,neutral,neutral,neutral,neutral
394526367,"It looks like tensorflow is now complaining about loading libcublas. This happened because you installed the magenta-gpu package, which has a dependency on tensorflow-gpu, which I suspect overwrote your local tensorflow package installation. Can you try installing just the 'magenta' package instead?",like loading package dependency suspect local package installation try package instead,issue,negative,neutral,neutral,neutral,neutral,neutral
394458228,"Hi Liu!

The checkpoint downloads are linked from the top of the Colab. Let me know
if you have any issues!

-Adam

On Mon, Jun 4, 2018 at 9:50 AM Liu Yihong <notifications@github.com> wrote:

> Hi there!
> When I'm playing with music_vae
> <https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae>,
> I found that the checkpoints files are only on the Colab
> <https://g.co/magenta/musicvae-colab>environment, not like other model
> with mag file download links. But I want to retrain the model based on
> existed checkpoints files, I'm just wondering if there's any chance to have
> a checkpoint file download link of music_vae?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1194>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6IxRqW1kZYRAdcTzAGmTy1wOtxxcks5t5WVrgaJpZM4UZb3i>
> .
>
",hi linked top let know mon wrote hi found like model mag file link want retrain model based wondering chance file link thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
394024138,"Just release pip package 0.3.8, which has the arbitrary image stylization commands built in.",release pip package arbitrary image stylization built,issue,negative,negative,neutral,neutral,negative,negative
393749918,"I did that and it works but I want to do some development, so need to do a windows install afaik from the docs. Which is what I've been trying to do.

>>Did you do auto install and do you have Linux/Mac or windows?

-> Title of issue is Windows 10 Ananconda Install - Bazel fails 
I'm following the instructions on https://github.com/tensorflow/magenta for setting up a development environment.

Using Windows 10 x64 pro latest update",work want development need install trying auto install title issue install following setting development environment pro latest update,issue,negative,positive,positive,positive,positive,positive
393748022,"Maybe try Docker with a preconfigured magenta image 

Also,
Did you do auto install and do you have Linux/Mac or windows?",maybe try docker magenta image also auto install,issue,negative,neutral,neutral,neutral,neutral,neutral
393672493,Thanks @bjaress! This issue should be fixed now. We'll release a new pip package shortly.,thanks issue fixed release new pip package shortly,issue,negative,positive,positive,positive,positive,positive
393612739,I've updated the tarball linked from the colab. Please reopen if you still have issues. Thanks for pointing this out!,linked please reopen still thanks pointing,issue,positive,positive,positive,positive,positive,positive
392978873,"Yes, it seems that the checkpoint tarball is out of date. I'll update it and then resolve this issue.",yes date update resolve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
392914023,"Yes, this checkpoint seems to work. Now I get an error a few lines down this is the same error, but this time for the *flat-trio_16bar* model. Could you provide the correct checkpoint for this model too?

Otherwise I would consider this issue solved. Thank you so much Adam. Perhaps this file should be added to the colab notebook.",yes work get error error time model could provide correct model otherwise would consider issue thank much perhaps file added notebook,issue,negative,positive,positive,positive,positive,positive
392872173,"Does this checkpoint work?

https://storage.googleapis.com/download.magenta.tensorflow.org/models/music_vae/checkpoints/trio_16bar_hierdec.ckpt.data-00000-of-00001
https://storage.googleapis.com/download.magenta.tensorflow.org/models/music_vae/checkpoints/trio_16bar_hierdec.ckpt.index

On Tue, May 29, 2018 at 9:48 AM Linford Goedschalk <notifications@github.com>
wrote:

> Hey Adam,
>
> Thank you for your response. I obtained the following from
> inspect_checkpoints:
>
> beta2_power (DT_FLOAT) []
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2138,4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2138,4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2138,4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
> core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
> core_decoder_0/decoder/output_projection/bias (DT_FLOAT) [90]
> core_decoder_0/decoder/output_projection/bias/Adam (DT_FLOAT) [90]
> core_decoder_0/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [90]
> core_decoder_0/decoder/output_projection/kernel (DT_FLOAT) [1024,90]
> core_decoder_0/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,90]
> core_decoder_0/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,90]
> core_decoder_0/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
> core_decoder_0/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
> core_decoder_0/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_0/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
> core_decoder_0/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
> core_decoder_0/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2138,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2138,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2138,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
> core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
> core_decoder_1/decoder/output_projection/bias (DT_FLOAT) [90]
> core_decoder_1/decoder/output_projection/bias/Adam (DT_FLOAT) [90]
> core_decoder_1/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [90]
> core_decoder_1/decoder/output_projection/kernel (DT_FLOAT) [1024,90]
> core_decoder_1/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,90]
> core_decoder_1/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,90]
> core_decoder_1/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
> core_decoder_1/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
> core_decoder_1/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_1/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
> core_decoder_1/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
> core_decoder_1/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2560,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2560,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2560,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
> core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
> core_decoder_2/decoder/output_projection/bias (DT_FLOAT) [512]
> core_decoder_2/decoder/output_projection/bias/Adam (DT_FLOAT) [512]
> core_decoder_2/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [512]
> core_decoder_2/decoder/output_projection/kernel (DT_FLOAT) [1024,512]
> core_decoder_2/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,512]
> core_decoder_2/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,512]
> core_decoder_2/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
> core_decoder_2/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
> core_decoder_2/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
> core_decoder_2/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
> core_decoder_2/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
> core_decoder_2/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2740,8192]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2740,8192]
> encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2740,8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2740,8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2740,8192]
> encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2740,8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [6144,8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [6144,8192]
> encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [6144,8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [6144,8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [6144,8192]
> encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [6144,8192]
> encoder/mu/bias (DT_FLOAT) [512]
> encoder/mu/bias/Adam (DT_FLOAT) [512]
> encoder/mu/bias/Adam_1 (DT_FLOAT) [512]
> encoder/mu/kernel (DT_FLOAT) [4096,512]
> encoder/mu/kernel/Adam (DT_FLOAT) [4096,512]
> encoder/mu/kernel/Adam_1 (DT_FLOAT) [4096,512]
> encoder/sigma/bias (DT_FLOAT) [512]
> encoder/sigma/bias/Adam (DT_FLOAT) [512]
> encoder/sigma/bias/Adam_1 (DT_FLOAT) [512]
> encoder/sigma/kernel (DT_FLOAT) [4096,512]
> encoder/sigma/kernel/Adam (DT_FLOAT) [4096,512]
> encoder/sigma/kernel/Adam_1 (DT_FLOAT) [4096,512]
> global_step (DT_INT64) []
> hierarchical_layer_0/e_to_initial_state/bias (DT_FLOAT) [4096]
> hierarchical_layer_0/e_to_initial_state/bias/Adam (DT_FLOAT) [4096]
> hierarchical_layer_0/e_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
> hierarchical_layer_0/e_to_initial_state/kernel (DT_FLOAT) [512,4096]
> hierarchical_layer_0/e_to_initial_state/kernel/Adam (DT_FLOAT) [512,4096]
> hierarchical_layer_0/e_to_initial_state/kernel/Adam_1 (DT_FLOAT) [512,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [1025,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [1025,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [1025,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
> hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]```
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1188#issuecomment-392848170>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6Fr4fz2AOTBjAhqSu8aw1sV4Qjknks5t3XvbgaJpZM4URr3a>
> .
>
",work tue may wrote hey thank response following reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
392848170,"Hey Adam,

Thank you for your response. I obtained the following from inspect_checkpoints:

```beta1_power (DT_FLOAT) []
beta2_power (DT_FLOAT) []
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2138,4096]
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2138,4096]
core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2138,4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
core_decoder_0/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
core_decoder_0/decoder/output_projection/bias (DT_FLOAT) [90]
core_decoder_0/decoder/output_projection/bias/Adam (DT_FLOAT) [90]
core_decoder_0/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [90]
core_decoder_0/decoder/output_projection/kernel (DT_FLOAT) [1024,90]
core_decoder_0/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,90]
core_decoder_0/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,90]
core_decoder_0/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
core_decoder_0/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
core_decoder_0/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_0/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
core_decoder_0/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
core_decoder_0/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2138,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2138,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2138,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
core_decoder_1/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
core_decoder_1/decoder/output_projection/bias (DT_FLOAT) [90]
core_decoder_1/decoder/output_projection/bias/Adam (DT_FLOAT) [90]
core_decoder_1/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [90]
core_decoder_1/decoder/output_projection/kernel (DT_FLOAT) [1024,90]
core_decoder_1/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,90]
core_decoder_1/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,90]
core_decoder_1/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
core_decoder_1/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
core_decoder_1/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_1/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
core_decoder_1/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
core_decoder_1/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2560,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2560,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2560,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
core_decoder_2/decoder/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]
core_decoder_2/decoder/output_projection/bias (DT_FLOAT) [512]
core_decoder_2/decoder/output_projection/bias/Adam (DT_FLOAT) [512]
core_decoder_2/decoder/output_projection/bias/Adam_1 (DT_FLOAT) [512]
core_decoder_2/decoder/output_projection/kernel (DT_FLOAT) [1024,512]
core_decoder_2/decoder/output_projection/kernel/Adam (DT_FLOAT) [1024,512]
core_decoder_2/decoder/output_projection/kernel/Adam_1 (DT_FLOAT) [1024,512]
core_decoder_2/decoder/z_to_initial_state/bias (DT_FLOAT) [4096]
core_decoder_2/decoder/z_to_initial_state/bias/Adam (DT_FLOAT) [4096]
core_decoder_2/decoder/z_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
core_decoder_2/decoder/z_to_initial_state/kernel (DT_FLOAT) [1024,4096]
core_decoder_2/decoder/z_to_initial_state/kernel/Adam (DT_FLOAT) [1024,4096]
core_decoder_2/decoder/z_to_initial_state/kernel/Adam_1 (DT_FLOAT) [1024,4096]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2740,8192]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2740,8192]
encoder/cell_0/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2740,8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [2740,8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [2740,8192]
encoder/cell_0/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2740,8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [6144,8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [6144,8192]
encoder/cell_1/bidirectional_rnn/bw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [6144,8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [6144,8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [6144,8192]
encoder/cell_1/bidirectional_rnn/fw/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [6144,8192]
encoder/mu/bias (DT_FLOAT) [512]
encoder/mu/bias/Adam (DT_FLOAT) [512]
encoder/mu/bias/Adam_1 (DT_FLOAT) [512]
encoder/mu/kernel (DT_FLOAT) [4096,512]
encoder/mu/kernel/Adam (DT_FLOAT) [4096,512]
encoder/mu/kernel/Adam_1 (DT_FLOAT) [4096,512]
encoder/sigma/bias (DT_FLOAT) [512]
encoder/sigma/bias/Adam (DT_FLOAT) [512]
encoder/sigma/bias/Adam_1 (DT_FLOAT) [512]
encoder/sigma/kernel (DT_FLOAT) [4096,512]
encoder/sigma/kernel/Adam (DT_FLOAT) [4096,512]
encoder/sigma/kernel/Adam_1 (DT_FLOAT) [4096,512]
global_step (DT_INT64) []
hierarchical_layer_0/e_to_initial_state/bias (DT_FLOAT) [4096]
hierarchical_layer_0/e_to_initial_state/bias/Adam (DT_FLOAT) [4096]
hierarchical_layer_0/e_to_initial_state/bias/Adam_1 (DT_FLOAT) [4096]
hierarchical_layer_0/e_to_initial_state/kernel (DT_FLOAT) [512,4096]
hierarchical_layer_0/e_to_initial_state/kernel/Adam (DT_FLOAT) [512,4096]
hierarchical_layer_0/e_to_initial_state/kernel/Adam_1 (DT_FLOAT) [512,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel (DT_FLOAT) [1025,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam (DT_FLOAT) [1025,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel/Adam_1 (DT_FLOAT) [1025,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias/Adam_1 (DT_FLOAT) [4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel (DT_FLOAT) [2048,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam (DT_FLOAT) [2048,4096]
hierarchical_layer_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel/Adam_1 (DT_FLOAT) [2048,4096]```",hey thank response following,issue,negative,neutral,neutral,neutral,neutral,neutral
392840898,"Hi Linford,

Can you use the inspect_checkpoints tool bundled with tensorflow to list
out the contents of your checkpoint and share those here?

-Adam

On Tue, May 29, 2018 at 8:10 AM Linford Goedschalk <notifications@github.com>
wrote:

> What I'm trying to do
>
> I am trying to run the code from the music-vae colab notebook
> <https://colab.research.google.com/notebooks/magenta/music_vae/music_vae.ipynb>
> on my own machine.
> What I did
>
> First I setup the Magenta environment as mentioned here
> <https://github.com/tensorflow/magenta/blob/master/README.md>.
>
> I copied the code from the colab notebook for the setup environment and
> '16-bar trio models' section to a .py file on my machine. (I commented the
> first few lines in the ' setup environment' part as this contains bash
> code. I also commented the from google.colab import files line as my IDE
> indicates this package does not exist and I could not find it anywhere to
> be installed either).
>
> I downloaded the checkpoints via a link in the colab notebook and changed
> the paths in the code accordingly so all files could be found (I have
> verified that these paths are correct).
>
> Lastly, I have changed the checkpoint_path_to_dir value in the
> TrainedModel function (from magenta.models.music_vae.trained_model).
> There was no file with the name *trio_16bar_hierdec* among the
> checkpoints I downloaded and so I changed the path
> *hiercat_trio_16bar_big* as this file is present among the checkpoints.
> What went wrong
>
> After running the code I get the error:
> tensorflow.python.framework.errors_impl.NotFoundError: Key
> core_decoder/core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias
> not found in checkpoint [[Node: save/RestoreV2 =
> RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ...,
> DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64],
> _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0,
> save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
>
> NotFoundError (see above for traceback): Key
> core_decoder/core_decoder_0/decoder/multi_rnn_cell/cell_0/lstm_cell/bias
> not found in checkpoint [[Node: save/RestoreV2 =
> RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ...,
> DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64],
> _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0,
> save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]
>
> I'm new to working with tensorflow checkpoints and so I have no idea how
> to resolve this *key not found* error. Could someone tell me how to
> resolve this issue?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1188>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6FXIdmQ5dfhGB1buAxPou-QMZW6xks5t3WTQgaJpZM4URr3a>
> .
>
",hi use tool list content share tue may wrote trying trying run code notebook machine first setup magenta environment copied code notebook setup environment trio section file machine first setup environment part bash code also import line ide package exist could find anywhere either via link notebook code accordingly could found correct lastly value function file name among path file present among went wrong running code get error key found node see key found node new working idea resolve key found error could someone tell resolve issue thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
391887817,"If I understand correctly what you're asking, reducing the temperature to a very low number (e.g, 0.0001) will return the argmax. However, I think it's likely you'll find the outputs are quite boring without some randomness.",understand correctly reducing temperature low number return however think likely find quite boring without randomness,issue,negative,negative,negative,negative,negative,negative
391578309,"I don't think that's the solution, If you browse the issue list other people seem to have issue with the same thing, but slightly different. Thanks for your help anyway.",think solution browse issue list people seem issue thing slightly different thanks help anyway,issue,positive,positive,neutral,neutral,positive,positive
391567159,"I'm sorry, I don't know well....
It's too irresponsible to answer that please delete and install it again. 
    ",sorry know well irresponsible answer please delete install,issue,negative,negative,negative,negative,negative,negative
391562512,ty! I was looking forward to having a play with Magenta development but it's a bit of a showstopper at the moment.,looking forward play magenta development bit moment,issue,negative,neutral,neutral,neutral,neutral,neutral
391560806,please wait a moment I'll try it on virtual machine,please wait moment try virtual machine,issue,negative,neutral,neutral,neutral,neutral,neutral
391497747,"I ended up running the python files without bazel, which was a significant pain but easier than trying to figure this out. Not sure how this might run with bazel. 
",ended running python without significant pain easier trying figure sure might run,issue,negative,positive,positive,positive,positive,positive
390971676,"@miraodasilva 
I had a good amount of pauses and no actions actually and I didn't modify the reward function. Maybe you can try modifying the music reward function? Or maybe it has to do with the note sequences you generated for training previously?

No problem at all",good amount actually modify reward function maybe try music reward function maybe note training previously problem,issue,positive,positive,positive,positive,positive,positive
390946415,"@ml4046 It's working and training successfully after some modifcations! The samples post-training actually sound quite good, but they are lacking pauses or continued notes (0s and 1s in their notation). This can be easily observed in the note probabilities pre and post RL. Did this happen to you as well by any chance?

Again, thank you so much for the help! ",working training successfully actually sound quite good continued notation easily note post happen well chance thank much help,issue,positive,positive,positive,positive,positive,positive
390860091,"same issue
I can run the demo of image_stylization in the docker, everything is fine:
`$ image_stylization_transform \
      --num_styles=<NUMBER_OF_STYLES> \
      --checkpoint=/path/to/model.ckpt \
      --input_image=/path/to/image.jpg \
      --which_styles=""[0,1,2,5,14]"" \
      --output_dir=/tmp/image_stylization/output \
      --output_basename=""stylized""`
but the terminal printed the ""command not found"" issue when running `arbitrary_image_stylization_with_weights`",issue run docker everything fine terminal printed command found issue running,issue,negative,positive,positive,positive,positive,positive
390852882,"@miraodasilva 

Yes I modified how values sampled from the replay buffer are fed into the session like you mentioned.",yes replay buffer fed session like,issue,positive,neutral,neutral,neutral,neutral,neutral
390752782,"So we need to compute the pitch_class mod 12 so that the pitch class range stays in the interval 0 - 11. I think the best approach here is to compute the MIDI pitch, and then take that mod 12.

Here's a simple way to compute the MIDI pitch, assuming C4 = 60:
```midi_pitch = (((octave + 1) * 12) + pitch_class) + alter```

Then just compute the pitch class:
```pitch_class = midi_pitch % 12```",need compute pitch class range stay interval think best approach compute pitch take simple way compute pitch assuming octave alter compute pitch class,issue,positive,positive,positive,positive,positive,positive
390470537,"@ml4046 It turns out that I was generating but without training (tuning) with RL at all. When I run the train function it gives me some errors which again have to do with the new form of LSTM states. Did you have to modify the training_step/train functions to accomodate the new form of LSTM States? I am removing all of the .flatten from the states and chaging the way they are concatenated when they are fed in batches during the training step. It is a bit of work but I suppose it is necessary to make it work. Let me know if you have a different solution for this.

Thank you for your time.",turn generating without training tuning run train function new form modify new form removing way fed training step bit work suppose necessary make work let know different solution thank time,issue,positive,positive,neutral,neutral,positive,positive
390190183,"@miraodasilva Awesome, that's a good question which I don't have a great answer to it either. I've read about editing it in a virtual environment (like you did) but I guess you could also clone it and edit from there?

Let me know if you've a good answer to that and glad I was able to help!",awesome good question great answer either read virtual environment like guess could also clone edit let know good answer glad able help,issue,positive,positive,positive,positive,positive,positive
389563990,"@ml4046 I got it to work! I am currently using the Basic RNN by the way, not the NoteRNN. It is generating proper MIDI outputs. By the way, I am actually editing the file in anaconda/envs/magenta...../rl_tuner.py and then running ""python rl_tuner.py"". Is there a better way to do this? I apologize if this is a pretty ridiculous question.

Thank you very much for the help.",got work currently basic way generating proper way actually file running python better way apologize pretty ridiculous question thank much help,issue,positive,positive,neutral,neutral,positive,positive
389336349,"@miraodasilva Yes, try creating a placeholder for specifying the batchsize and passing it in to your sessions. You'll need this when you sample from the replay buffer since when you first initialize your state, the batchsize is 1",yes try passing session need sample replay buffer since first initialize state,issue,negative,positive,positive,positive,positive,positive
389184340,"I believe I have fixed these errors by using:

def get_zero_state(self):
    """"""Gets an initial state of zeros of the appropriate size.

    Required size is based on the model's internal RNN cell.

    Returns:
      A matrix of batch_size x cell size zeros.
    """"""
    state_tuple= ()
    for layer_size in self.hparams.rnn_layer_sizes:
      tup = np.zeros((self.hparams.batch_size,layer_size))
      state = tf.contrib.rnn.LSTMStateTuple(tup,tup)
      state_tuple += (state)


    return state_tuple

However, now I get the following error:

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,38] vs. shape[1] = [128,512]

Because apparently the input of the dynamic rnn does not match the state. However, I fail to see how I could ever get them to match. Perhaps this has to do with the placeholder on batch size you mentioned earlier? Thanks.",believe fixed self initial state appropriate size size based model internal cell matrix cell size tup state tup tup state return however get following error see match shape shape apparently input dynamic match state however fail see could ever get match perhaps batch size thanks,issue,negative,positive,neutral,neutral,positive,positive
389127265,"This also happens during training in line 704, where again the state_value is fed into the feed_dict and the same error appears.",also training line fed error,issue,negative,neutral,neutral,neutral,neutral,neutral
389124945,"@ml4046  The issue is when I am passing the state_value as the initial state in the feed_dict. The state of the LSTM is a tuple of LSTMSTateTuples of Tensors, and therefore I get the error. The exact line of the error is 1789 I believe, where this happens:

softmax, self.q_network.state_value = self.session.run(
            [self.action_softmax, self.q_network.state_tensor],
            {self.q_network.melody_sequence: input_batch,
             self.q_network.initial_state: self.q_network.state_value, << PROBLEM
             self.q_network.lengths: lengths})

I don't understand how to solve it. If I try to use eval on the tensors it tells me that the session I am using is not the same as the Tensor's session. From my understanding, if I could  transform the state_value into a raw format instead of Tensor, the problem would be solved, but I can't seem to do this successfully.",issue passing initial state state therefore get error exact line error believe problem understand solve try use session tensor session understanding could transform raw format instead tensor problem would ca seem successfully,issue,negative,positive,positive,positive,positive,positive
388986375,"@miraodasilva 
It's hard to tell which line is causing this but the general idea is you're feeding in a tensor when you run your sessions from `session.run(...,feed_dict:{state:<some tf.Tensor>}).` You want to feed in the values instead (i.e. samples from the replays), not the Tensor itself.",hard tell line causing general idea feeding tensor run session state want feed instead tensor,issue,negative,negative,negative,negative,negative,negative
388771984,"@ml4046 
I converted the checkpoint to the right format successfully. However, now I get this error. Did you have this same error by any chance? Thank you very much. 

""TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(""MultiRNNCellZeroState_2/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros:0"", shape=(128, 512), dtype=float32) which was passed to the feed with key Tensor(""q_network/MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros:0"", shape=(128, 512), dtype=float32).""

",converted right format successfully however get error error chance thank much value feed object acceptable feed include python reference tensor object tensor feed key tensor,issue,positive,positive,positive,positive,positive,positive
388470952,"@miraodasilva No worries, from what I remember, you have to pass in a custom `note_rnn_hparams` when you initialize `rl_tuner` is because the initialization misses the flag that you're using a custom trained model so it will initialize from the default even if you specify a custom checkpoint directory.

As with using the `rl_tuner` for tuning the default `basic_rnn`, I haven't tested out the pre-config model since I only have been tuning my own 'basic_rnn' generated from `melody_rnn`",remember pas custom initialize flag custom trained model initialize default even specify custom directory tuning default tested model since tuning,issue,negative,neutral,neutral,neutral,neutral,neutral
388454505,"Do you mean the custom params that are in the melody_rnn code as the default config? Why can't I use the default ones from rl_tuner? 

Again, I apologize if I am asking stupid questions, but I am just getting started with TF. I really appreciate your help.",mean custom code default ca use default apologize stupid getting really appreciate help,issue,negative,negative,negative,negative,negative,negative
388441222,@miraodasilva I did so I just trained my own model with `melody_rnn` and tuned with `rl_tuner` which worked out for me (remember to pass custom hparams for the melody rnn when you initialize `rl_tuner`),trained model tuned worked remember pas custom melody initialize,issue,negative,neutral,neutral,neutral,neutral,neutral
388391287,"Okay, I think that worked! Did you also have the same trouble with the checkpoint file for the basic RNN after this?",think worked also trouble file basic,issue,negative,negative,neutral,neutral,negative,negative
388189651,"@miraodasilva Perhaps and regarding `.zero_state()`, you can create a placeholder for `batch_size` and pass that into `.zero_state() ` instead. ",perhaps regarding create pas instead,issue,negative,neutral,neutral,neutral,neutral,neutral
388163728,"@ml4046 To be clear, I am under the impression that the problem is that cell.state_size used to return an integer and now returns a tuple, and that's why the code does not work. In any case, the function to get_zero_state also does not work for the same reason (it returns ""np.zeros((self.batch_size, self.cell.state_size))""). In other words, it again seems to assume that the state_size is an integer. 

I apologize if I am completely misunderstanding, I am very new to Tensorflow. 

Thanks",clear impression problem used return integer code work case function also work reason assume integer apologize completely misunderstanding new thanks,issue,negative,positive,positive,positive,positive,positive
388158421,As per the link: Googlers do not need to sign a CLA.,per link need sign,issue,negative,neutral,neutral,neutral,neutral,neutral
388146064,Thank you very much for the response. Do you have any idea why this error exists in the first place? Is it a matter of the code being somewhat old? ,thank much response idea error first place matter code somewhat old,issue,negative,positive,positive,positive,positive,positive
388141529,"@miraodasilva The `NotFoundError` has to do with variable names initialized by RL_Tuner note matching the `.ckpt` file (where the weights are saved).

The issue with `TypeError` from using `basic_rnn` is with the placeholder (line 199) in `build_graph()` from `note_rnn_loader.py`. The idea is that we want a placeholder for the `MultiRNNCell` which is represented as multiple tuple specifying the size. However, we cannot simply just pass `[None, self.cell.state_size]` because `self.cell.state_size` is a tuple containing the `MultiCellRNN`'s RNN state sizes (represented as a tuple). 

Instead we need to initialize the MultiCellRNN with `zero_state`. Then, during the training sessions, we need to modify how we Q-network, Target etc. is reading in states when we run the model (e.g. line 697 in `rl_tuner.py`) such that we are feeding in tuples of samples. ",variable note matching file saved issue line idea want multiple size however simply pas none state size instead need initialize training session need modify target reading run model line feeding,issue,negative,neutral,neutral,neutral,neutral,neutral
388117990,I didn't really understand the exact solution to this @ml4046 . Did you end up solving the issue @hany-tawfik ? I'm having the same exact problem.,really understand exact solution end issue exact problem,issue,negative,positive,positive,positive,positive,positive
387782881,"I haven't created a script or a download link because the intention was
that users would create samples through the colab notebook:
g.co/magenta/musicvae-colab

All of the code you would need to sample and create MIDIs there, along with
checkpoints. I may also add a binary to the project when I get time.

Hope this solves your problem!

On Tue, May 8, 2018 at 9:25 PM Mafii <notifications@github.com> wrote:

> @adarob <https://github.com/adarob>
> I'm using my own checkpoint since there was no pretrained model given for
> MusicVAE.
> Could give any example upon generating mid fie from MusicVAE-Python ?
> Or show how to use music_vae.trained_model.TrainedModel correctly?
>
> (I tried running examples of MusicVAE through Magenta.js, but converting
> checkpoint into that format was another mess-up ;-(
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1164#issuecomment-387616177>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6IzPoZyuzHSc2_LGvEtfNJLaCJu7ks5twm-2gaJpZM4T0yNK>
> .
>
",script link intention would create notebook code would need sample create along may also add binary project get time hope problem tue may wrote since model given could give example upon generating mid fie show use correctly tried running converting format another reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
387616177,"@adarob 
I'm using my own checkpoint since there was no pretrained model given for MusicVAE.
Could you give any example upon generating mid file from MusicVAE-Python? Or demonstrate how to use music_vae.trained_model.TrainedModel correctly?

(I tried running examples of MusicVAE through Magenta.js, but converting checkpoint into that js-format was another mess-up ;-( ",since model given could give example upon generating mid file demonstrate use correctly tried running converting another,issue,negative,neutral,neutral,neutral,neutral,neutral
387082470,"Which checkpoint are you using or did you train your own?

Try using z[1], which doesn't have gaussian noise added.

On Mon, May 7, 2018, 3:59 AM Mafii <notifications@github.com> wrote:

> I found no script for generating under musci_vae model.
> I wrote one based on trained_model.TrainedModel class.
> The code is some like this
>
>  model = trained_model.TrainedModel(config, batch_size=1, checkpoint_path)
>  z = model.encode(input_sequence)
>  generated_sequences = model.decode(z[0], length=64, temperature=1)
> magenta.music.sequence_proto_to_midi_file(generated_sequences[0], midi_path)
>
> Then I found output had no relation with the input. Was there any thing
> wrong with my usage of Autoencoder?
> Thank you for your answer!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1164>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6GefmpDwYBKRCEPhgf_-IK4bIOrNks5twCkEgaJpZM4T0yNK>
> .
>
",train try noise added mon may wrote found script generating model wrote one based class code like model found output relation input thing wrong usage thank answer thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
386932543,"Allison, would you mind submitting a pull request with your fix? Thanks!

On Sun, May 6, 2018, 6:09 PM Allison Parrish <notifications@github.com>
wrote:

> I was having this problem as well (using the functions defined in the
> Jupyter notebook
> <https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb>).
> I fixed it by passing the max_len parameter to to_big_strokes() in the
> encode() function as defined in the sample notebook, i.e., replace
>
> strokes = to_big_strokes(input_strokes).tolist()
>
> with
>
> strokes = to_big_strokes(input_strokes, max_len=eval_model.hps.max_seq_len).tolist()
>
> The default value for this parameter is 250, which ends up in the
> resulting numpy array having the wrong dimensions for the operation that
> follows (unless your max_seq_len just happens to be 250).
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/948#issuecomment-386931886>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6A1mlUaAOlcTBT3SV3Xk_vGdqBtfks5tv56ygaJpZM4Qhc0X>
> .
>
",would mind pull request fix thanks sun may wrote problem well defined notebook fixed passing parameter encode function defined sample notebook replace default value parameter resulting array wrong operation unless thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
386931886,"I was having this problem as well (using the functions defined in [the Jupyter notebook](https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb)). I fixed it by passing the `max_len` parameter to `to_big_strokes()` in the `encode()` function as defined in the sample notebook, i.e., replace

```
strokes = to_big_strokes(input_strokes).tolist()
```

with

```
strokes = to_big_strokes(input_strokes, max_len=eval_model.hps.max_seq_len).tolist()
```

The default value for this parameter is 250, which ends up in the resulting numpy array having the wrong dimensions for the operation that follows (unless your max_seq_len just happens to be 250).",problem well defined notebook fixed passing parameter encode function defined sample notebook replace default value parameter resulting array wrong operation unless,issue,negative,negative,negative,negative,negative,negative
386710676,"A way to address this is to initialize `MultiRNNCell` with `zero_state` and create a placeholder to specify the `batch_size` since `zero_state` requires `batch_size`. Then, you'll have to specify this in every session. ",way address initialize create specify since specify every session,issue,negative,neutral,neutral,neutral,neutral,neutral
386709422,The main issue here is that `tf.placeholder` is reading in a tuple. The code is trying to set up the initial state such that `MultiRNNCell` has dynamic input size. Usually it is initialized with `zero_state` but requires you to specify a batch_size. You can alternatively create a placeholder to specify the batch_size and modify the code such that you are also passing in the batch_size during a session. ,main issue reading code trying set initial state dynamic input size usually specify alternatively create specify modify code also passing session,issue,positive,negative,neutral,neutral,negative,negative
386707307,You have to specify note_rnn_hparams in RLTuner so it correctly loads from the checkpoint file. After that it'll successfully initialize the Note RNN. ,specify correctly file successfully initialize note,issue,negative,positive,positive,positive,positive,positive
386508139,"I re-trained it just now and the tmp generated and my generate bat file is attached.
[pianoroll.zip](https://github.com/tensorflow/magenta/files/1973331/pianoroll.zip)
[tmp.zip](https://github.com/tensorflow/magenta/files/1973332/tmp.zip)
",generate bat file attached,issue,negative,neutral,neutral,neutral,neutral,neutral
386458884,I haven't changed max beta at all but I've used various numbers of free bits.  I'll address it one way or another when I make the checkpoints available.,beta used various free address one way another make available,issue,positive,positive,positive,positive,positive,positive
386424353,"I think it's worth adding something reasonable to these so that if someone
trains their own it will at least work. You don't need to add every
variation. The default is no free bits and max beta of 1,

On Thu, May 3, 2018 at 12:58 PM Ian Simon <notifications@github.com> wrote:

> *@iansimon* commented on this pull request.
>
> Should I add these to all of my configs? I kinda don't want to; for many
> of them I trained with multiple values of free_bits and I don't want to
> duplicate each config a bunch of times...
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/pull/1161#pullrequestreview-117407890>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6D6n-oMMzR5A0z3lJCBuHpXtoFFwks5tu2FXgaJpZM4TxhdG>
> .
>
",think worth something reasonable someone least work need add every variation default free beta may wrote pull request add want many trained multiple want duplicate bunch time thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
386376364,"Using the pip installation wasn't to get fix the bazel problem. However,
depending on what you're trying to do, you may be able to use it instead of
bazel. Are you trying to modify the code at all or just use the existing
library as-is?

On Wed, May 2, 2018 at 10:27 PM hayoha <notifications@github.com> wrote:

> I've already installed its own version of the protobuf library and tried
> pip install magenta.
> The installation completed but I still cannot use bazel to build anything.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1154#issuecomment-386194726>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6AVwS9iW-CXK1x681Y5LxEWVGKdRks5tupVMgaJpZM4Tvcdn>
> .
>
",pip installation get fix problem however depending trying may able use instead trying modify code use library wed may wrote already version library tried pip install magenta installation still use build anything reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
386194726,"I've already installed its own version of the protobuf library and tried pip install magenta.
The installation completed but I still cannot use bazel to build anything.",already version library tried pip install magenta installation still use build anything,issue,negative,neutral,neutral,neutral,neutral,neutral
386171235,"in note_rnn_loader.py:

print('var_dict: ', var_dict)
       if '/Adam' in var.name:
         # TODO(lukaszkaiser): investigate the problem here and remove this hack.
         pass
       elif self.note_rnn_type == 'basic_rnn':
+        print(""debuggggingg!!!!!!!!!!!!!!!!!!!***********"")
         var_dict[inner_name] = var
       else:
-        var_dict[self.checkpoint_scope + '/' + inner_name] = var
+        print(""debuggggingg!!!!!"")
+        scope = self.checkpoint_scope + '/' + inner_name
+        print(""scope: "", scope)
+        print(""var: "", var)
+        if scope == 'rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/bias':
+          var_dict['rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/B'] = var
+        elif scope == 'rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel':
+          var_dict['rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0'] = var",print investigate problem remove hack pas print else print scope print scope scope print scope scope,issue,negative,neutral,neutral,neutral,neutral,neutral
386120996,"Fixed by https://github.com/tensorflow/magenta-demos/pull/38
Thanks for bringing the issue to our attention!",fixed thanks issue attention,issue,negative,positive,positive,positive,positive,positive
386120907,"Can you send a list of variables in your checkpoint? You can print it out
with
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py

On Wed, May 2, 2018 at 11:56 AM ml4046 <notifications@github.com> wrote:

> Hi all,
>
> I trained my own melody_rnn (basic/attention_rnn) successfully and
> attempted to train with rl_tuner_train. However the
> 'rnn_model/fully_connected/bias' was not found in my checkpoint, giving
> this error:
>
>
> ////////////////////////////////////////////////////////////////////////////////////////////////////////////
> NotFoundError: Key rnn_model/fully_connected/bias not found in checkpoint
>
> ////////////////////////////////////////////////////////////////////////////////////////////////////////////
>
> I've looked at #597 <https://github.com/tensorflow/magenta/issues/597>
> already and seems like this is an issue with newer version of tensorflow?
> I'm currently running tensorflow 1.8.0
>
> Thanks
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1156>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6Ic9zoSPE4PqF6liHlA8CwjPw0yeks5tugFjgaJpZM4Tv-5a>
> .
>
",send list print wed may wrote hi trained successfully train however found giving error key found already like issue version currently running thanks thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
386085263,"You'll have to modify the .ipynb using an editor because there's an extra comma after ""import sys\n"":

   ""cell_type"": ""code"",
   ""execution_count"": 1,
   ""metadata"": {
    ""collapsed"": false
   },
   ""outputs"": [],
   ""source"": [
    ""import tensorflow as tf\n"",
    ""import numpy as np\n"",
    ""import sys\n"",

Should work after the modification",modify editor extra comma import code false source import import import work modification,issue,negative,negative,negative,negative,negative,negative
386073123,"Hi @Alihussain1, which tensorflow version are you using? I successfully trained my own melody_rnn (basic/attention_rnn) and tried to train using rl_tuner. I used the checkpoint from my own model but I'm getting:

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
NotFoundError: Key rnn_model/fully_connected/bias not found in checkpoint
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Is this an issue from checkpoint saving? I'm running tensor flow 1.8.0

Thanks much",hi version successfully trained tried train used model getting key found issue saving running tensor flow thanks much,issue,positive,positive,positive,positive,positive,positive
386057483,"You can ignore the py2 test failure, it's fixed in #1155.",ignore test failure fixed,issue,negative,negative,negative,negative,negative,negative
386055650,"It needs to install its own version of the protobuf library as well if you are using bazel. I'm not sure why you're getting a build interrupted error unless you're manually stopping it. There may be some hidden error that you're not seeing. Maybe try to enable verbosity in bazel?

Are you trying to do development or just want to use the package? If the latter, you can just do `pip install magenta`.",need install version library well sure getting build interrupted error unless manually stopping may hidden error seeing maybe try enable verbosity trying development want use package latter pip install magenta,issue,negative,positive,positive,positive,positive,positive
386054691,"@adarob Still the same error.
Everytime I ran bazel test or bazel build, it just:
Fetching https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-python-3.5.1.tar.gz; 112,193b 76s
and never finished this fetching process then showed ERROR: build interrupted

I've already installed protobuf-3.5.1. Nothing changed.
",still error ran test build fetching never finished fetching process error build interrupted already nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
386053994,"Oh sure! Yes I've been able to fix the problem... changing my computer LOL. 
Main problem was my CPU: I used an old HP to run MusicVAE and Tensorflow installation didn't go well. 
I needed Tensorflow 1.7 but my CPU didn't not support it. That was the problem. I changed PC to work and now I just work with it quietly. 
Anyway thank you for the previous advice :)",oh sure yes able fix problem computer main problem used old run installation go well support problem work work quietly anyway thank previous advice,issue,negative,positive,positive,positive,positive,positive
386052542,"@hayoha what error did you get after you install tf 1.8?

Also, you should try this: `bazel test ...:all`",error get install also try test,issue,negative,neutral,neutral,neutral,neutral,neutral
386050787,How long ago did you train the checkpoint? Would you be willing to send it to me so I can debug.,long ago train would willing send,issue,negative,positive,neutral,neutral,positive,positive
386050262,"@Gnefi have you been able to resolve this yet? If not, I can look into it today.",able resolve yet look today,issue,negative,positive,positive,positive,positive,positive
386022855,"I installed protobuf-3.5.2 and tensorflow-1.8.0 still got the same error
bazel test //magenta:all

ERROR: build interrupted
INFO: Elapsed time: 70.358s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: magenta/protobuf
ERROR: Couldn't start the build. Unable to run tests

Anyone can help me?",still got error test error build interrupted time build complete successfully loaded currently loading error could start build unable run anyone help,issue,negative,positive,neutral,neutral,positive,positive
386017586,"The command is simply parsed from the wheels project I listed.
Perhaps check out the page and see if any suit your scenario.

Basically it is saying the python isn't pointing at the right stuff, or the stuff isn't there.
One of those wheels should contain certainly something of use

",command simply project listed perhaps check page see suit scenario basically saying python pointing right stuff stuff one contain certainly something use,issue,negative,positive,positive,positive,positive,positive
385167357,"I apologize, I'm not able to reproduce it, now it works correctly again.",apologize able reproduce work correctly,issue,negative,positive,positive,positive,positive,positive
385110788,"I am not seeing this issue on https://g.co/magenta/musicvae-colab. Can you
reproduce there?

On Wed, Apr 25, 2018 at 2:32 AM RoderickvanderWeerdt <
notifications@github.com> wrote:

> For some reason the notebook is unable to import magenta.music during the
> Environment Setup, even though it worked previously. I have also tried
> running the original MusicVAE Colab notebook, which now also gives this
> error.
>
> Is this a common problem?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1149>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6FeOk4VrPShOCFtIWgsFmxjeNmYAks5tsEKugaJpZM4TjFUG>
> .
>
",seeing issue reproduce wed wrote reason notebook unable import environment setup even though worked previously also tried running original notebook also error common problem thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
384793807,"We don't currently support a Docker GPU container, but it shouldn't be too difficult to set up following the examples here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker

If you get it working, let us know if there are any tricks to get it to work correctly with the host GPU.",currently support docker container difficult set following get working let u know get work correctly host,issue,negative,negative,negative,negative,negative,negative
384657574,"I was having the same issue. I uninstalled libcudnn 7.1 (cuDNN 7.1) and installed the latest 7.0 version and it worked for me.

I am using cuda 9.0 and tensorflow-gpu 1.7.

You can download libcudnn packages from here but first you need to register as a developer:
https://developer.nvidia.com/rdp/cudnn-archive
Installation instructions here:
https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html",issue uninstalled latest version worked first need register developer installation,issue,negative,positive,positive,positive,positive,positive
383727613,"That command gives a 404 error:
```
HTTP error 404 while getting https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp27-cp27mu-linux_x86_64.whl
  Could not install requirement tensorflow==1.4.0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp27-cp27mu-linux_x86_64.whl because of error 404 Client Error: Not Found for ...
``` 
Installed by pip install tensorflow but to no avail: ImportError: No module named magenta.models.sketch_rnn.sketch_rnn_train
",command error error getting could install requirement error client error found pip install avail module,issue,negative,neutral,neutral,neutral,neutral,neutral
383404327,"Same issue here. I think it's an issue with the build, because in the build file we have

```
py_library(
    name = ""arbitrary_image_stylization_build_model"",
    srcs = [
        ""arbitrary_image_stylization_build_model.py"",
    ],
    srcs_version = ""PY2AND3"",
    deps = [
        ""//magenta/models/image_stylization:ops"",
        "":nza_model"",
        "":arbitrary_image_stylization_losses"",
        # tensorflow dep
    ],
)
```

Im on Mac OS, and I tried to build in two ways: 

1. Double-clicking the build file, which leads to: 

```
Akhils-MacBook-Air-4:~ akhiljalan$ /Users/akhiljalan/Programming/_wip/magenta-master/magenta/models/arbitrary_image_stylization/BUILD ; exit;
/Users/akhiljalan/Programming/_wip/magenta-master/magenta/models/arbitrary_image_stylization/BUILD: line 19: syntax error near unexpected token `newline'
/Users/akhiljalan/Programming/_wip/magenta-master/magenta/models/arbitrary_image_stylization/BUILD: line 19: `py_binary('
logout
Saving session...
...copying shared history...
...saving history...truncating history files...
...completed.

[Process completed]
```

2. Installing bazel and trying `bazel build BUILD`, which works fine but leads to the same issue as this one 

```
INFO: Analysed target //magenta/models/arbitrary_image_stylization:BUILD (1 packages loaded).
INFO: Found 1 target...
INFO: Elapsed time: 0.307s, Critical Path: 0.02s
INFO: Build completed successfully, 1 total action
```
",issue think issue build build file name mac o tried build two way build file exit line syntax error near unexpected token line saving session history saving history history process trying build build work fine issue one target build loaded found target time critical path build successfully total action,issue,negative,positive,positive,positive,positive,positive
383346322,"Well then given that seemingly nothing actually installed perhaps
from this page https://github.com/lakshayg/tensorflow-build
one could
pip install https://github.com/lakshayg/tensorflow-build/raw/master/tensorflow-1.4.0-cp27-cp27mu-linux_x86_64.whl
then maybe?  That is a custom linux build that supports python 2.7 on TF 1.4.0 and Ubuntu 16.04

alternately https://github.com/mind/wheels/releases/tag/tf1.4.1-cpu
any use?",well given seemingly nothing actually perhaps page one could pip install maybe custom build python alternately use,issue,negative,neutral,neutral,neutral,neutral,neutral
383343074,"Still experiencing this issue with the latest versions of TF and Magenta:

magenta-0.3.7 
tensorflow-1.7.0
cuda=9.0
cudnn=7.0.5

This occurs whether running the program in Docker or in Conda. It occurs on both the CPU and GPU. I'm using Ubuntu 16.04.",still issue latest magenta whether running program docker,issue,negative,positive,positive,positive,positive,positive
383320777,"That gives no output at all. 
```
which python
/home/qni/miniconda2/bin/python
```
Someone somewhere said relogging was beneficial in something related to this but I think I installed jupyter with pip without a restart.",output python someone somewhere said beneficial something related think pip without restart,issue,negative,neutral,neutral,neutral,neutral,neutral
383317134,"I'm just saying it sounds like you might have two pythons.
Can't you just

`sudo updatedb; locate Tensorflow | sort -n`
or `locate tensorflow`
at the command prompt and find where - if at all - it put it?
",saying like might two ca locate sort locate command prompt find put,issue,negative,neutral,neutral,neutral,neutral,neutral
382365831,"It doesn't find any packages, including scipy. Tensorflow supposedly got
installed with Magenta, which can be source activated, so those packages
shouldn't have to be installed again.

Python 2.7, Intel cpu.

On 18 Apr. 2018 13:10, ""_"" <notifications@github.com> wrote:

> You don't say what python or CPU type so I'll just guess
> Using https://www.tensorflow.org/install/install_linux#the_url_
> of_the_tensorflow_python_package
> and https://www.tensorflow.org/install/install_linux
> I would guess try
> pip install https://storage.googleapis.com/tensorflow/linux/cpu/
> tensorflow-1.7.0-cp34-cp34m-linux_x86_64.whl
>
> Sorry - Windows here, can't test
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1144#issuecomment-382351074>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGCB2mZ9RPnGDsIw3kTnYaZIKARysWQtks5tpx87gaJpZM4TYslY>
> .
>
",find supposedly got magenta source python wrote say python type guess would guess try pip install sorry ca test thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
382351074,"You don't say what python or CPU type so I'll just guess
Using https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package
and https://www.tensorflow.org/install/install_linux
I would guess try
pip3 install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.7.0-cp34-cp34m-linux_x86_64.whl

Sorry - Windows here, can't test  - if you used a virtual env, activate it first I guess",say python type guess would guess try pip install sorry ca test used virtual activate first guess,issue,negative,negative,negative,negative,negative,negative
382343703,"`melody_rnn_generate  --config=attention_rnn --bundle_file=<Somewhere> --output_dir=<SomewhereElse> --num_outputs=1 --num_steps=128 --primer_melody=""[60]""`

A simple way to use the system is just:
the improv_rnn_generate thingy (i'm on windows so I end up with horrid %VARS%)
`
improv_rnn_generate.py --config='chord_pitches_improv' --bundle_file=%BUNDLE_PATH% --output_dir=r:/tmp/improv_rnn/generated --num_outputs=2 --primer_melody=""[60]"" --backing_chords=""Am F C G Am E Am F C G Dm E"" --render_chords`

gives:

> INFO:tensorflow:Beam search yields sequence with log-likelihood: -176.666260
> INFO:tensorflow:Beam search yields sequence with log-likelihood: -114.263802
> INFO:tensorflow:Wrote 2 MIDI files to r:/tmp/improv_rnn/generated

and two midi files with the chords and lead line sets with the minor 3rd C as a priming point

Hope it helps
other things you asked
https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#basic
https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#lookback
https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#attention",somewhere simple way use system thingy end horrid beam search sequence beam search sequence wrote two lead line minor priming point hope,issue,negative,negative,neutral,neutral,negative,negative
381719006,"Oh, I see the confusion, we haven't documented how to create an inference dataset without creating the full training dataset. We should fix that.

In the mean time, you can see an example of how to do this from our colab notebook, which you can run from your browser: https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/magenta/onsets_frames_transcription/onsets_frames_transcription.ipynb",oh see confusion create inference without full training fix mean time see example notebook run browser,issue,negative,positive,neutral,neutral,positive,positive
381718070,"I'm not sure what the current state of the MAPS dataset is, but if you're just interested in using the model for inference, you can use our pre-trained checkpoint as described here: https://github.com/tensorflow/magenta/tree/master/magenta/models/onsets_frames_transcription#pre-trained",sure current state interested model inference use,issue,positive,positive,positive,positive,positive,positive
381414067,"Hello, sorry for bumping up this post. I also want to experiment with refining a pre-trained net and, thus, would like to know it the issue with checkpoints compatibility has been solved.",hello sorry bumping post also want experiment refining net thus would like know issue compatibility,issue,negative,negative,negative,negative,negative,negative
380250094,"We used the GM1 definition here: https://www.midi.org/specifications/item/gm-level-1-sound-set

```
40 | Electric Snare
41 | Low Floor Tom
42 | Closed Hi Hat
43 | High Floor Tom
44 | Pedal Hi-Hat
45 | Low Tom
46 | Open Hi-Hat
47 | Low-Mid Tom
48 | Hi-Mid Tom
49 | Crash Cymbal 1
50 | High Tom
```

The mapping was chosen based on drum ""function"" and should be fairly reasonable, but note that there are bound to be potential disagreements when mapping 47 drum sounds onto 9.",used definition electric snare low floor closed hi hat high floor pedal low open crash cymbal high chosen based drum function fairly reasonable note bound potential drum onto,issue,negative,positive,neutral,neutral,positive,positive
380171867,"If I may bother you to hold my hand for another moment, I assume the answer is a little more involved than to plug in 
extracted_seqs, _ = mm.extract_pianoroll_sequences( /tmp/notesequences.tfrecord)
yeah?",may bother hold hand another moment assume answer little involved plug yeah,issue,negative,negative,negative,negative,negative,negative
380167978,"Ha no worries.

On Apr 10, 2018 9:35 AM, ""HandsomeDevilv112"" <notifications@github.com>
wrote:

I was just about to edit my comment. I'm a little undercaffinated.

—
You are receiving this because you commented.

Reply to this email directly, view it on GitHub
<https://github.com/tensorflow/magenta/issues/1141#issuecomment-380166458>,
or mute the thread
<https://github.com/notifications/unsubscribe-auth/ABCa6KW3I6dJUWepKSAwCvLsmGNamt4-ks5tnN9fgaJpZM4TN46C>
.
",ha wrote edit comment little reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
380164777,"You don't run pianoroll_rnn_nade_sequence_generator.py directly but it gets
called via pianoroll_rnn_nade_generate. The change that would be required
to fix the issue is in pianoroll_rnn_nade_sequence_generator.py, however.

On Tue, Apr 10, 2018 at 9:24 AM HandsomeDevilv112 <notifications@github.com>
wrote:

> No need to apologize! I'm just happy to have made it this far.
> ah, I didn't see a step where I should run
> pianoroll_rnn_nade_sequence_generator.py
>
> The instructions I did catch were:
> *building your dataset (convert_dir_to_note_sequences)
> *sequence examples (pianoroll_rnn_nade_create_dataset)
> *train (pianoroll_rnn_nade_train)
> *generate (pianoroll_rnn_nade_generate)
>
> I'll give that a spin
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1141#issuecomment-380162806>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6E32HioyG9-mdIgYPeg4NDhOJZgiks5tnNzMgaJpZM4TN46C>
> .
>
",run directly via change would fix issue however tue wrote need apologize happy made far ah see step run catch building sequence train generate give spin reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
380162806,"No need to apologize! I'm just happy to have made it this far. 
ah, I didn't see a step where I should run pianoroll_rnn_nade_sequence_generator.py

The instructions I did catch were:
*building your dataset (convert_dir_to_note_sequences)
*sequence examples (pianoroll_rnn_nade_create_dataset)
*train (pianoroll_rnn_nade_train)
*generate (pianoroll_rnn_nade_generate) 

I'll give that a spin",need apologize happy made far ah see step run catch building sequence train generate give spin,issue,positive,positive,positive,positive,positive,positive
380145333,"Sorry you're facing this issue!

Looking back at the code, it appears that we are not correctly handling the case when no priming sequence is provided. 

I believe we basically need a conditional to give an empty PianoRoll if the NoteSequence is empty here:
https://github.com/tensorflow/magenta/blob/48a199085e303eeae7c36068f050696209b856bb/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_sequence_generator.py#L88

This should be easy to fix, but I don't have time at the moment. You can either fix it yourself, wait until I can get to it (later this week?), or try giving it a primer sequence.",sorry facing issue looking back code correctly handling case priming sequence provided believe basically need conditional give empty empty easy fix time moment either fix wait get later week try giving primer sequence,issue,negative,negative,neutral,neutral,negative,negative
379486428,"I have the most recent version. Is it 1.7.0 right? 
Anyway this is the report.

pip show tensorflow
Name: tensorflow
Version: 1.7.0
Summary: TensorFlow helps the tensors flow
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /home/generale/anaconda3/envs/magenta/lib/python2.7/site-packages
Requires: protobuf, astor, backports.weakref, wheel, mock, enum34, gast, termcolor, absl-py, tensorboard, six, grpcio, numpy
",recent version right anyway report pip show name version summary flow author license apache location astor wheel mock gast six,issue,negative,positive,positive,positive,positive,positive
379485455,Can you try doing `pip install -u tensorflow`. You may not have the most recent version.,try pip install may recent version,issue,negative,neutral,neutral,neutral,neutral,neutral
378731246,"Hi!

In the paper, the loss function is a combination of gaussian and discrete pdf (for pen strokes, and end-of-drawing etc), so it can be negative.

Thks",hi paper loss function combination discrete pen negative,issue,negative,negative,negative,negative,negative,negative
378675502,"@hardmaru why reconstruction loss will be negative? I think it just a normal distribution pdf , how it will be greater than one , and make reconstruction loss become negative? Did I something wrong? Thk ",reconstruction loss negative think normal distribution greater one make reconstruction loss become negative something wrong,issue,negative,negative,neutral,neutral,negative,negative
376261022,"Hi Hubert. Sorry but MusicVAE doesn't currently have automatic path expansion enabled, so you can't use ""~"" in your path. I'm going to fix it, but for now you can just use the full path.",hi sorry currently automatic path expansion ca use path going fix use full path,issue,negative,negative,neutral,neutral,negative,negative
375077239,"yes thats what seems to be the case, i would also prefer not having to dig into the build process :) 

thanks for the fast response !  i also grabbed the source but when i executed the code via
pyhton ./arbitrary_image_stylization_evaluate.py ..  it failed to load the 'from magenta.models.arbitrary_image_stylization' part, it seems that the magenta module code is somehow not loaded in the env.  i've tried the provided docker container which should already have magenta installed, do you have any quick pointers what could be the mistake im making ? thanks again !",yes thats case would also prefer dig build process thanks fast response also source executed code via load part magenta module code somehow loaded tried provided docker container already magenta quick could mistake making thanks,issue,positive,positive,positive,positive,positive,positive
375014701,"It just needs to land as a module. The only thing I'm doing it grabbing the source from GitHub! :)

I believe this all stems from the use of Bazel to build Python apps, which otherwise would be quite happy including packages via setuptools `find_packages`. I could dig into the Bazel requirements, but I imagine whoever setup this build configuration for magenta would know instantly what to do to make sure this package landed in the distribution.",need land module thing source believe use build python otherwise would quite happy via could dig imagine whoever setup build configuration magenta would know instantly make sure package landed distribution,issue,positive,positive,positive,positive,positive,positive
375000579,@gar1t it would be awesome if you could share what additions/changes are needed in the Bazel build configs in order to include arbitrary_image_stylization as a binary in the pip package.  ,would awesome could share build order include binary pip package,issue,positive,positive,positive,positive,positive,positive
374786427,"It's fixed in 0.3.7.


On Tue, Mar 20, 2018 at 10:52 PM Brian McMahon <notifications@github.com>
wrote:

> Closed #1118 <https://github.com/tensorflow/magenta/issues/1118>.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1118#event-1532162334>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6CmqwV-DQur7-5DsFKUaEpMPSVmfks5tgYgRgaJpZM4SyttD>
> .
>
",fixed tue mar wrote closed reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
374784296,"I'm using 0.3.6 of the magenta and magenta-gpu pip packages, although I believe I had been using this version while I was having the issue earlier.  ",magenta pip although believe version issue,issue,negative,neutral,neutral,neutral,neutral,neutral
374777722,"Ah yes. Which version of magenta's pip package do you have installed? That
should have been fixed already.


On Tue, Mar 20, 2018 at 10:20 PM Brian McMahon <notifications@github.com>
wrote:

> It appears I spoke too soon as setting --master="""" actually solved the
> problem. I passed specifically:
>
> music_vae_train --config=cat-mel_2bar_small --run_dir=/tmp/music_vae/
> --mode=train --examples_path=/tmp/notesequences.tfrecord --master=""""
>
> And now it appears to train without a hitch.
>
> Thanks!
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1118#issuecomment-374776896>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6GGjgmKSapKQYkpxDmLusMpgG04Kks5tgYCygaJpZM4SyttD>
> .
>
",ah yes version magenta pip package fixed already tue mar wrote spoke soon setting actually problem specifically train without hitch thanks reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
374776896,"It appears I spoke too soon as setting --master="""" actually solved the problem.  I passed specifically:

`music_vae_train --config=cat-mel_2bar_small --run_dir=/tmp/music_vae/ --mode=train --examples_path=/tmp/notesequences.tfrecord --master=""""`

And now it appears to train without a hitch.

Thanks!",spoke soon setting actually problem specifically train without hitch thanks,issue,negative,positive,neutral,neutral,positive,positive
374773239,"Sorry for the confusing error message, but this means that it isn't finding
any files that match your input path.


On Tue, Mar 20, 2018 at 9:54 PM Brian McMahon <notifications@github.com>
wrote:

> I am having trouble running music_vae_train on an AWS p2.xlarge instance.
> When passing the following directly from the model readme:
>
> music_vae_train --config=cat-mel_2bar_small --run_dir=/tmp/music_vae/
> --mode=train --examples_path=/tmp/notesequences.tfrecord
>
> I get the following error:
>
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/h5py/__init__.py:36:
> FutureWarning: Conversion of the second argument of issubdtype fromfloatto
> np.floatingis deprecated. In future, it will be treated asnp.float64 ==
> np.dtype(float).type`.
> from ._conv import register_converters as _register_converters
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #2
> <https://github.com/tensorflow/magenta/pull/2>
> (fname, cnt))
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #3
> <https://github.com/tensorflow/magenta/pull/3>
> (fname, cnt))
> INFO:tensorflow:Reading examples from: /tmp/notesequences.tfrecord
> 2018-03-20 21:09:58.072001: I
> tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports
> instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2018-03-20 21:09:58.261392: I
> tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA
> node read from SysFS had negative value (-1), but there must be at least
> one NUMA node, so returning NUMA node zero
> 2018-03-20 21:09:58.261775: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with
> properties:
> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
> pciBusID: 0000:00:1e.0
> totalMemory: 11.17GiB freeMemory: 11.10GiB
> 2018-03-20 21:09:58.261809: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu
> devices: 0
> 2018-03-20 21:10:00.061698: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow
> device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory)
> -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0,
> compute capability: 3.7)
> INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder,
> CategoricalLstmDecoder, and hparams:
> {'grad_clip': 1.0, 'z_size': 256, 'free_bits': 0.0, 'max_seq_len': 32,
> 'sampling_schedule': 'constant', 'grad_norm_clip_to_zero': 10000,
> 'learning_rate': 0.001, 'conditional': True, 'use_cudnn': False,
> 'min_learning_rate': 1e-05, 'batch_size': 512, 'dec_rnn_size': [256, 256],
> 'decay_rate': 0.9999, 'beta_rate': 0.0, 'sampling_rate': 0.0,
> 'enc_rnn_size': [512], 'max_beta': 1.0, 'dropout_keep_prob': 1.0,
> 'clip_mode': 'global_norm'}
> INFO:tensorflow:
> Encoder Cells (bidirectional):
> units: [512]
>
> INFO:tensorflow:
> Decoder Cells:
> units: [256, 256]
>
> WARNING:tensorflow:From
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/lstm_models.py:535:
> softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is
> deprecated and will be removed in a future version.
> Instructions for updating:
>
> Future major versions of TensorFlow will allow gradients to flow
> into the labels input on backprop by default.
>
> See tf.nn.softmax_cross_entropy_with_logits_v2.
>
> INFO:tensorflow:Create CheckpointSaverHook.
> INFO:tensorflow:Graph was finalized.
> 2018-03-20 21:10:13.154010: E
> tensorflow/core/common_runtime/session.cc:69] Not found: No session factory
> registered for the given session options: {target: ""local"" config: }
> Registered factories are {DIRECT_SESSION, GRPC_SESSION}.
> Traceback (most recent call last):
> File ""/home/ubuntu/anaconda3/envs/magenta/bin/music_vae_train"", line 11,
> in
> sys.exit(console_entry_point())
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 324, in console_entry_point
> tf.app.run(main)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"",
> line 126, in run
> _sys.exit(main(argv))
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 320, in main
> run(configs.CONFIG_MAP)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 302, in run
> task=FLAGS.task)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 211, in train
> is_chief=is_chief)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/training.py"",
> line 541, in train
> max_wait_secs=max_wait_secs) as session:
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 384, in MonitoredTrainingSession
> stop_grace_period_secs=stop_grace_period_secs)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 795, in *init*
> stop_grace_period_secs=stop_grace_period_secs)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 518, in *init*
> self._sess = _RecoverableSession(self._coordinated_creator)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 981, in *init*
> _WrappedSession.*init*(self, self._create_session())
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 986, in _create_session
> return self._sess_creator.create_session()
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 675, in create_session
> self.tf_sess = self._session_creator.create_session()
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 446, in create_session
> init_fn=self._scaffold.init_fn)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"",
> line 275, in prepare_session
> config=config)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"",
> line 180, in _restore_checkpoint
> sess = session.Session(self._target, graph=self._graph, config=config)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 1522, in *init*
> super(Session, self).*init*(target, graph, config=config)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 638, in *init*
> self._session = tf_session.TF_NewDeprecatedSession(opts, status)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"",
> line 516, in *exit*
> c_api.TF_GetCode(self.status.status))
> tensorflow.python.framework.errors_impl.NotFoundError: No session factory
> registered for the given session options: {target: ""local"" config: }
> Registered factories are {DIRECT_SESSION, GRPC_SESSION}.
> `
> When adding a --master="""" I get the following:
>
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/h5py/__init__.py:36:
> FutureWarning: Conversion of the second argument of issubdtype fromfloatto
> np.floatingis deprecated. In future, it will be treated asnp.float64 ==
> np.dtype(float).type`.
> from ._conv import register_converters as _register_converters
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #2
> <https://github.com/tensorflow/magenta/pull/2>
> (fname, cnt))
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #3
> <https://github.com/tensorflow/magenta/pull/3>
> (fname, cnt))
> INFO:tensorflow:Reading examples from: /tmp/notesequences.tfrecord
> 2018-03-20 21:15:19.489714: I
> tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports
> instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2018-03-20 21:15:19.587392: I
> tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA
> node read from SysFS had negative value (-1), but there must be at least
> one NUMA node, so returning NUMA node zero
> 2018-03-20 21:15:19.587762: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with
> properties:
> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
> pciBusID: 0000:00:1e.0
> totalMemory: 11.17GiB freeMemory: 11.10GiB
> 2018-03-20 21:15:19.587799: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu
> devices: 0
> 2018-03-20 21:15:19.885465: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow
> device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory)
> -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0,
> compute capability: 3.7)
> INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder,
> CategoricalLstmDecoder, and hparams:
> {'grad_clip': 1.0, 'z_size': 256, 'free_bits': 0.0, 'max_seq_len': 32,
> 'sampling_schedule': 'constant', 'grad_norm_clip_to_zero': 10000,
> 'learning_rate': 0.001, 'conditional': True, 'use_cudnn': False,
> 'min_learning_rate': 1e-05, 'batch_size': 512, 'dec_rnn_size': [256, 256],
> 'decay_rate': 0.9999, 'beta_rate': 0.0, 'sampling_rate': 0.0,
> 'enc_rnn_size': [512], 'max_beta': 1.0, 'dropout_keep_prob': 1.0,
> 'clip_mode': 'global_norm'}
> INFO:tensorflow:
> Encoder Cells (bidirectional):
> units: [512]
>
> INFO:tensorflow:
> Decoder Cells:
> units: [256, 256]
>
> WARNING:tensorflow:From
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/lstm_models.py:535:
> softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is
> deprecated and will be removed in a future version.
> Instructions for updating:
>
> Future major versions of TensorFlow will allow gradients to flow
> into the labels input on backprop by default.
>
> See tf.nn.softmax_cross_entropy_with_logits_v2.
>
> INFO:tensorflow:Create CheckpointSaverHook.
> INFO:tensorflow:Graph was finalized.
> 2018-03-20 21:15:32.846152: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu
> devices: 0
> 2018-03-20 21:15:32.846364: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow
> device (/job:localhost/replica:0/task:0/device:GPU:0 with 339 MB memory) ->
> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute
> capability: 3.7)
> INFO:tensorflow:Running local_init_op.
> INFO:tensorflow:Done running local_init_op.
> 2018-03-20 21:15:48.419446: W tensorflow/core/framework/op_kernel.cc:1202]
> OP_REQUIRES failed at iterator_ops.cc:814 : Invalid argument: buffer_size
> must be greater than zero.
> [[Node: ShuffleAndRepeatDataset =
> ShuffleAndRepeatDataset[output_shapes=[[]],
> output_types=[DT_STRING]](TensorSliceDataset,
> ShuffleAndRepeatDataset/buffer_size, ShuffleAndRepeatDataset/seed,
> ShuffleAndRepeatDataset/seed2, ShuffleAndRepeatDataset/count)]]
> Traceback (most recent call last):
> File ""/home/ubuntu/anaconda3/envs/magenta/bin/music_vae_train"", line 11,
> in
> sys.exit(console_entry_point())
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 324, in console_entry_point
> tf.app.run(main)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"",
> line 126, in run
> _sys.exit(main(argv))
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 320, in main
> run(configs.CONFIG_MAP)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 302, in run
> task=FLAGS.task)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/music_vae_train.py"",
> line 211, in train
> is_chief=is_chief)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/training.py"",
> line 544, in train
> loss = session.run(train_op)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 546, in run
> run_metadata=run_metadata)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 1022, in run
> run_metadata=run_metadata)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 1113, in run
> raise six.reraise(*original_exc_info)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 1098, in run
> return self._sess.run(*args, **kwargs)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 1170, in run
> run_metadata=run_metadata)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"",
> line 950, in run
> return self._sess.run(*args, **kwargs)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 905, in run
> run_metadata_ptr)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 1137, in _run
> feed_dict_tensor, options, run_metadata)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 1355, in _do_run
> options, run_metadata)
> File
> ""/home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.py"",
> line 1374, in _do_call
> raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.InvalidArgumentError: buffer_size
> must be greater than zero.
> [[Node: ShuffleAndRepeatDataset =
> ShuffleAndRepeatDataset[output_shapes=[[]],
> output_types=[DT_STRING]](TensorSliceDataset,
> ShuffleAndRepeatDataset/buffer_size, ShuffleAndRepeatDataset/seed,
> ShuffleAndRepeatDataset/seed2, ShuffleAndRepeatDataset/count)]]
> [[Node: OneShotIterator = OneShotIteratorcontainer="""",
> dataset_factory=_make_dataset_5408f458[], output_shapes=[[?,?,90],
> [?,?,90], [?,?,?], [?]], output_types=[DT_BOOL, DT_BOOL, DT_BOOL,
> DT_INT32], shared_name="""",
> _device=""/job:localhost/replica:0/task:0/device:CPU:0""]]
> [[Node: IteratorGetNext/_235 = _Recvclient_terminated=false,
> recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"",
> send_device=""/job:localhost/replica:0/task:0/device:CPU:0"",
> send_device_incarnation=1, tensor_name=""edge_5_IteratorGetNext"",
> tensor_type=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:GPU:0""
> ]]
> `
> and with --master=grpc://:1111 it hangs at:
>
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/h5py/__init__.py:36:
> FutureWarning: Conversion of the second argument of issubdtype fromfloatto
> np.floatingis deprecated. In future, it will be treated asnp.float64 ==
> np.dtype(float).type`.
> from ._conv import register_converters as _register_converters
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #2
> <https://github.com/tensorflow/magenta/pull/2>
> (fname, cnt))
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/matplotlib/
> *init*.py:1057: UserWarning: Duplicate key in file
> ""/home/ubuntu/.config/matplotlib/matplotlibrc"", line #3
> <https://github.com/tensorflow/magenta/pull/3>
> (fname, cnt))
> INFO:tensorflow:Reading examples from: /tmp/notesequences.tfrecord
> 2018-03-20 21:17:47.658643: I
> tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports
> instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2018-03-20 21:17:47.755925: I
> tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA
> node read from SysFS had negative value (-1), but there must be at least
> one NUMA node, so returning NUMA node zero
> 2018-03-20 21:17:47.756284: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with
> properties:
> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
> pciBusID: 0000:00:1e.0
> totalMemory: 11.17GiB freeMemory: 11.10GiB
> 2018-03-20 21:17:47.756317: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu
> devices: 0
> 2018-03-20 21:17:48.053155: I
> tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow
> device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory)
> -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0,
> compute capability: 3.7)
> INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder,
> CategoricalLstmDecoder, and hparams:
> {'grad_clip': 1.0, 'z_size': 256, 'free_bits': 0.0, 'max_seq_len': 32,
> 'sampling_schedule': 'constant', 'grad_norm_clip_to_zero': 10000,
> 'learning_rate': 0.001, 'conditional': True, 'use_cudnn': False,
> 'min_learning_rate': 1e-05, 'batch_size': 512, 'dec_rnn_size': [256, 256],
> 'decay_rate': 0.9999, 'beta_rate': 0.0, 'sampling_rate': 0.0,
> 'enc_rnn_size': [512], 'max_beta': 1.0, 'dropout_keep_prob': 1.0,
> 'clip_mode': 'global_norm'}
> INFO:tensorflow:
> Encoder Cells (bidirectional):
> units: [512]
>
> INFO:tensorflow:
> Decoder Cells:
> units: [256, 256]
>
> WARNING:tensorflow:From
> /home/ubuntu/anaconda3/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae/lstm_models.py:535:
> softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is
> deprecated and will be removed in a future version.
> Instructions for updating:
>
> Future major versions of TensorFlow will allow gradients to flow
> into the labels input on backprop by default.
>
> See tf.nn.softmax_cross_entropy_with_logits_v2.
>
> INFO:tensorflow:Create CheckpointSaverHook.
> INFO:tensorflow:Graph was finalized.
> INFO:tensorflow:An error was raised while a session was being created.
> This may be due to a preemption of a connected worker or parameter server.
> A new session will be created. Error: OS Error
> INFO:tensorflow:Graph was finalized.
> INFO:tensorflow:An error was raised while a session was being created.
> This may be due to a preemption of a connected worker or parameter server.
> A new session will be created. Error: OS Error
> INFO:tensorflow:Graph was finalized.
> `
> With --hparams=batch_size=32,learning_rate=0.0005 i get the same error as
> above.
>
> I have been able to run the train on my Ubuntu 17.10 desktop without an
> issue.
>
> Any guidance would be sincerely appreciated!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1118>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6GI2lzZaPSmQ7W_Ej30gqp4pyFexks5tgXqpgaJpZM4SyttD>
> .
>
",sorry error message finding match input path tue mar wrote trouble running instance passing following directly model get following error conversion second argument future float import duplicate key file line duplicate key file line reading binary use successful node read negative value must least one node node zero found device name major minor visible device memory physical device name bus id compute capability building model true false bidirectional warning removed future version future major allow flow input default see create graph found session factory registered given session target local registered recent call last file line file line main file line run main file line main run file line run file line train file line train session file line file line file line file line self file line return file line file line file line file line sess file line super session self target graph file line status file line exit session factory registered given session target local registered get following conversion second argument future float import duplicate key file line duplicate key file line reading binary use successful node read negative value must least one node node zero found device name major minor visible device memory physical device name bus id compute capability building model true false bidirectional warning removed future version future major allow flow input default see create graph visible device memory physical device name bus id compute capability running done running invalid argument must greater zero node recent call last file line file line main file line run main file line main run file line run file line train file line train loss file line run file line run file line run raise file line run return file line run file line run return file line run file line file line file line raise type message must greater zero node node node conversion second argument future float import duplicate key file line duplicate key file line reading binary use successful node read negative value must least one node node zero found device name major minor visible device memory physical device name bus id compute capability building model true false bidirectional warning removed future version future major allow flow input default see create graph error raised session may due connected worker parameter server new session error o error graph error raised session may due connected worker parameter server new session error o error graph get error able run train without issue guidance would sincerely thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
374275042,"As far as I can tell, the problem was with our test infra, not the tests themselves. Should be fine to merge.",far tell problem test infra fine merge,issue,negative,positive,positive,positive,positive,positive
373929236,@adarob The tests do not pass but only insiders have the access rights to see why.  Can you please let me know what went wrong?,pas access see please let know went wrong,issue,negative,negative,negative,negative,negative,negative
373924978,"Just a quick question @hardmaru : does it also do the necessary pre-processing that is mentioned https://github.com/googlecreativelab/quickdraw-dataset

1.  Align the drawing to the top-left corner, to have minimum values of 0.
2. Uniformly scale the drawing, to have a maximum value of 255.
3. Resample all strokes with a 1 pixel spacing.
4. Simplify all strokes using the Ramer–Douglas–Peucker algorithm with an epsilon value of 2.0.

Thank you very much in advance. ",quick question also necessary align drawing corner minimum uniformly scale drawing maximum value resample spacing simplify algorithm epsilon value thank much advance,issue,positive,positive,positive,positive,positive,positive
373485835,"Thanks. I will correct this in the code.


On Thu, Mar 15, 2018 at 6:49 PM Tom Duncalf <notifications@github.com>
wrote:

> Never mind, I found the solution (it was to add --master="""" to the
> training command). Thanks!
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/997#issuecomment-373484274>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6IYESdWXKx0d-MZI3acQppBn0fqfks5teretgaJpZM4RPmWk>
> .
>
",thanks correct code mar wrote never mind found solution add training command thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
373484274,"Never mind, I found the solution (it was to add `--master=""""` to the training command). Thanks!",never mind found solution add training command thanks,issue,negative,positive,positive,positive,positive,positive
373484136,"Hi @adarob, thanks for the quick reply! I actually was just about to reply myself saying I found that solution via https://stackoverflow.com/questions/41809130/tensorflow-slim-training-loop-crashing-no-session-factory-registered and it does indeed work :)

Thanks again!
Tom",hi thanks quick reply actually reply saying found solution via indeed work thanks,issue,positive,positive,positive,positive,positive,positive
373483329,"Hi @MarkWuNLP, could you elaborate on your solution please? I've got the same issue (https://github.com/tensorflow/magenta/issues/1110) but am not sure what your solution means :)

Thanks!",hi could elaborate solution please got issue sure solution thanks,issue,positive,positive,positive,positive,positive,positive
373205336,"We have to use it for now because dl.multinomial is not in any other
version. I will switch it once the new version is released.

On Thu, Mar 15, 2018 at 7:39 AM, Kyle Phillips <notifications@github.com>
wrote:

> all of this looks good except I don't think its a good idea to use ""deeplearn"":
> ""next"" this is will continue to always pull in there latest unstable
> version.
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/pull/1108#issuecomment-373198708>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6H6zDqZHgAU6sNtVjX1k9Vkl_Zhiks5teZwNgaJpZM4SrKN2>
> .
>
",use version switch new version mar kyle wrote good except think good idea use next continue always pull latest unstable version state reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
373198708,"all of this looks good except I don't think its a good idea to use `""deeplearn"": ""next""` this is will continue to always pull in there latest unstable version. ",good except think good idea use next continue always pull latest unstable version,issue,positive,positive,positive,positive,positive,positive
372654255,"It's really strange. I encountered this error as well. However, when I change the eval radio to 40% there's no error and then I change it back to 10% and it works too. I am so confused what happened. 
",really strange error well however change radio error change back work confused,issue,negative,negative,negative,negative,negative,negative
372512766,"It looks like sometimes when you run the train command you have hparams that specify a size of [64,64] and sometimes there isn't an hparam, so it goes with the default of [128,128]. I suspect there is a checkpoint in your rundir that was created with a graph that is a different size than what you are trying to run now. I would try using a different rundir or deleting the current contents of the rundir and starting again.",like sometimes run train command specify size sometimes go default suspect graph different size trying run would try different current content starting,issue,negative,neutral,neutral,neutral,neutral,neutral
372468387,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to `go/cla#troubleshoot`.
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look help look pull request need sign contributor license agreement memo please visit sign fixed please reply verify already individual possible different address commit check data verify set git corporate company point contact authorized participate ask added group authorized know point contact direct project maintainer used register authorized contributor must used git commit check data verify set git used register authorized contributor must also attached account,issue,positive,positive,neutral,neutral,positive,positive
372062992,Just testing whether or not requiring tornado version < 5.0 avoids the kokoro failure.,testing whether tornado version failure,issue,negative,negative,negative,negative,negative,negative
371922600,"@ElegantColor  - 

my python is a bit light on - but I believe there maybe some steps needed to preprocess model.  
Would be nice if Magenta team could shed some light on parameters needed....

https://github.com/tf-coreml/tf-coreml/blob/master/examples/inception_v1_preprocessing_steps.ipynb

```python 

Inception V1 Example
In this notebook we will go through the process of converting the Inception V1 model to a Neural Network Classifier CoreML model that directly predicts the class label of the input image. We will highlight the importance of setting the image preprocessing parameters correctly to get the right results. Lets get started!
Lets first download the inception V1 frozen TF graph (the .pb file)
In [ ]:
# Download the model and class label package
import os
import urllib
import tarfile
def download_file_and_unzip(url, dir_path='.'):
    """"""Download the frozen TensorFlow model and unzip it.
    url - The URL address of the frozen file
    dir_path - local directory
    """"""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    k = url.rfind('/')
    fname = url[k+1:]
    fpath = os.path.join(dir_path, fname)

    if not os.path.exists(fpath):
        urllib.urlretrieve(url, fpath)
    tar = tarfile.open(fpath)
    tar.extractall(dir_path)
    tar.close()

inception_v1_url = 'https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz'
download_file_and_unzip(inception_v1_url)
For conversion to CoreML, **we need to find the input and output tensor names in the TF graph**. This will also be required to run the TF graph for numerical accuracy check. Lets load the TF graph def and try to find the names
In [ ]:
# Load the TF graph definition
import tensorflow as tf
tf_model_path = './inception_v1_2016_08_28_frozen.pb'
with open(tf_model_path, 'rb') as f:
    serialized = f.read()
tf.reset_default_graph()
original_gdef = tf.GraphDef()
original_gdef.ParseFromString(serialized)

# Lets get some details about a few ops in the beginning and the end of the graph
with tf.Graph().as_default() as g:
    tf.import_graph_def(original_gdef, name='')
    ops = g.get_operations()
    N = len(ops)
    for i in [0,1,2,N-3,N-2,N-1]:
        print('\n\nop id {} : op type: ""{}""'.format(str(i), ops[i].type));
        print('input(s):'),
        for x in ops[i].inputs:
            print(""name = {}, shape: {}, "".format(x.name, x.get_shape())),
        print('\noutput(s):'),
        for x in ops[i].outputs:
            print(""name = {}, shape: {},"".format(x.name, x.get_shape())),
The output of the Placeholder op is the input (""input:0"") and the output of the Softmax op towards the end of the graph is the output (""InceptionV1/Logits/Predictions/Softmax:0""). Lets convert to mlmodel now.
In [ ]:
import tfcoreml
# Supply a dictionary of input tensors' name and shape (with batch axis)
input_tensor_shapes = {""input:0"":[1,224,224,3]} # batch size is 1
#providing the image_input_names argument converts the input into an image for CoreML
image_input_name = ['input:0']
# Output CoreML model path
coreml_model_file = './inception_v1.mlmodel'
# The TF model's ouput tensor name
output_tensor_names = ['InceptionV1/Logits/Predictions/Softmax:0']
# class label file: providing this will make a ""Classifier"" CoreML model
class_labels = 'imagenet_slim_labels.txt'

# Call the converter. This may take a while
coreml_model = tfcoreml.convert(
        tf_model_path=tf_model_path,
        mlmodel_path=coreml_model_file,
        input_name_shape_dict=input_tensor_shapes,
        output_feature_names=output_tensor_names,
        image_input_names = image_input_name,
        class_labels = class_labels)
Lets load an image for testing. We will get predictions on this image using the TF model and the corresponding mlmodel.
In [ ]:
# Now we're ready to test out the CoreML model with a real image!
# Load an image
import numpy as np
import PIL
import requests
from io import BytesIO
from matplotlib.pyplot import imshow
# This is an image of a golden retriever from Wikipedia
img_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'
response = requests.get(img_url)
%matplotlib inline
img = PIL.Image.open(BytesIO(response.content))
imshow(np.asarray(img))
In [ ]:
# for getting CoreML predictions we directly pass in the PIL image after resizing
import coremltools
img = img.resize([224,224], PIL.Image.ANTIALIAS)
coreml_inputs = {'input__0': img}
coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)
coreml_pred_dict = coreml_output['InceptionV1__Logits__Predictions__Softmax__0']
coreml_predicted_class_label = coreml_output['classLabel']

#for getting TF prediction we get the numpy array of the image
img_np = np.array(img).astype(np.float32)
print 'image shape:', img_np.shape
print 'first few values: ', img_np.flatten()[0:4], 'max value: ', np.amax(img_np)
img_tf = np.expand_dims(img_np, axis = 0) #now shape is [1,224,224,3] as required by TF

# Evaluate TF and get the highest label 
tf_input_name = 'input:0'
tf_output_name = 'InceptionV1/Logits/Predictions/Softmax:0'
with tf.Session(graph = g) as sess:
    tf_out = sess.run(tf_output_name, 
                      feed_dict={tf_input_name: img_tf})
tf_out = tf_out.flatten()    
idx = np.argmax(tf_out)
label_file = 'imagenet_slim_labels.txt' 
with open(label_file) as f:
    labels = f.readlines()
    
#print predictions   
print('\n')
print(""CoreML prediction class = {}, probabiltiy = {}"".format(coreml_predicted_class_label,
                                            str(coreml_pred_dict[coreml_predicted_class_label])))  
print(""TF prediction class = {}, probability = {}"".format(labels[idx],
                                            str(tf_out[idx])))
Both the predictions match, this means that the conversion was correct. However, the class label seems incorrect. What could be the reason? The answer is that we did not preprocess the image correctly before passing it to the neural network!! This is always a crucial step when using neural networks on images.
How do we know what preprocessing to apply? This can be tricky to find sometimes. The approach is to find the source of the pre-trained model and check for the preprocessing that the author of the model used while training and evaluation. In this case, the TF model comes from the SLIM library so we find the preprocessing steps here
We see that the image pixels have to be scaled to lie in the interval [-1,1]. Lets do that and get the TF predictions again!
In [ ]:
img_tf = (2.0/255.0) * img_tf - 1
with tf.Session(graph = g) as sess:
    tf_out = sess.run(tf_output_name, 
                      feed_dict={tf_input_name: img_tf})
tf_out = tf_out.flatten()    
idx = np.argmax(tf_out)
print(""TF prediction class = {}, probability = {}"".format(labels[idx],
                                            str(tf_out[idx])))
Much better now! The model is predicting a dog as the highest class.
What about CoreML? CoreML automatically handles the image preprocessing, when the input is of type image, so we do not have to change the input that we were passing in earlier. For the mlmodel we converted, lets see what the image biases and scale have been set to
In [ ]:
# Get image pre-processing parameters of a saved CoreML model
from coremltools.proto import FeatureTypes_pb2 as _FeatureTypes_pb2


spec = coremltools.models.utils.load_spec(coreml_model_file)
if spec.WhichOneof('Type') == 'neuralNetworkClassifier':
  nn = spec.neuralNetworkClassifier
if spec.WhichOneof('Type') == 'neuralNetwork':
  nn = spec.neuralNetwork  
if spec.WhichOneof('Type') == 'neuralNetworkRegressor':
  nn = spec.neuralNetworkRegressor

preprocessing = nn.preprocessing[0].scaler
print 'channel scale: ', preprocessing.channelScale
print 'blue bias: ', preprocessing.blueBias
print 'green bias: ', preprocessing.greenBias
print 'red bias: ', preprocessing.redBias

inp = spec.description.input[0]
if inp.type.WhichOneof('Type') == 'imageType':
  colorspace = _FeatureTypes_pb2.ImageFeatureType.ColorSpace.Name(inp.type.imageType.colorSpace)
  print 'colorspace: ', colorspace
As suspected, they are not correct. Lets convert the model again and set them correctly this time. Note that the channel scale is multiplied first and then the bias is added.
In [ ]:
# Call the converter. This may take a while
coreml_model = tfcoreml.convert(
        tf_model_path=tf_model_path,
        mlmodel_path=coreml_model_file,
        input_name_shape_dict=input_tensor_shapes,
        output_feature_names=output_tensor_names,
        image_input_names = image_input_name,
        class_labels = class_labels,
        red_bias = -1,
        green_bias = -1,
        blue_bias = -1,
        image_scale = 2.0/255.0)
In [ ]:
# Call CoreML predict again
coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)
coreml_pred_dict = coreml_output['InceptionV1__Logits__Predictions__Softmax__0']
coreml_predicted_class_label = coreml_output['classLabel']
print(""CoreML prediction class = {}, probability = {}"".format(coreml_predicted_class_label,
                                            str(coreml_pred_dict[coreml_predicted_class_label])))
Yes, now its matching the TF output and is correct!!
Note that predictions with the default CoreML predict call (when the flag useCPUOnly=True is skipped) may vary slightly since it uses a lower precision optimized path that runs faster.
```



https://github.com/tf-coreml/tf-coreml/blob/master/examples/style_transfer_example.ipynb
```python 

Style Transfer Network
In this notebook we will go through the process of converting and evaluating the style transfer model, the one linked in the readme page, to CoreML. This model takes in an image and a style index (one of 26 possible styles) and outputs the stylized image.
We first download the TF model (.pb file)
In [ ]:
# Download the model 
import os
import urllib
import zipfile
def download_file_and_unzip(url, dir_path='.'):
    """"""Download the frozen TensorFlow model and unzip it.
    url - The URL address of the frozen file
    dir_path - local directory
    """"""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    k = url.rfind('/')
    fname = url[k+1:]
    fpath = os.path.join(dir_path, fname)

    if not os.path.exists(fpath):
        urllib.urlretrieve(url, fpath)
    zip_ref = zipfile.ZipFile(fpath, 'r')
    zip_ref.extractall(dir_path)
    zip_ref.close()    

inception_v1_url = 'https://storage.googleapis.com/download.tensorflow.org/models/stylize_v1.zip'
download_file_and_unzip(inception_v1_url)
For conversion to CoreML, we need to find the input and output tensor names in the TF graph. This will also be required to run the TF graph for numerical accuracy check. Lets load the TF graph def and try to find the names. Inputs are generally the tensors that are outputs of the ""Placeholder"" op.
In [ ]:
# Load the TF graph definition
import tensorflow as tf
tf_model_path = './stylize_quantized.pb'
with open(tf_model_path, 'rb') as f:
    serialized = f.read()
tf.reset_default_graph()
original_gdef = tf.GraphDef()
original_gdef.ParseFromString(serialized)

# Lets get some details about a few ops in the beginning and the end of the graph
with tf.Graph().as_default() as g:
    tf.import_graph_def(original_gdef, name='')
    ops = g.get_operations()
    N = len(ops)
    for i in range(N):
        if ops[i].type == 'Placeholder':
            for x in ops[i].outputs:
                print(""output name = {}, shape: {},"".format(x.name, x.get_shape())),
                print('\n')
There are two inputs: the image input named ""input:0"" and the style index input named ""style_num:0"". For finding the output lets print some info of the last few ops
In [ ]:
with tf.Graph().as_default() as g:
    tf.import_graph_def(original_gdef, name='')
    ops = g.get_operations()
    N = len(ops)
    for i in range(N-10,N):
        print('\n\nop id {} : op type: ""{}""'.format(str(i), ops[i].type));
        print('input(s):'),
        for x in ops[i].inputs:
            print(""name = {}, shape: {}, "".format(x.name, x.get_shape())),
        print('\noutput(s):'),
        for x in ops[i].outputs:
            print(""name = {}, shape: {},"".format(x.name, x.get_shape())),
Generally some knowledge about the network may be required to correctly determine the output. In this case the output of the ""Sigmoid"" op is the normalized image (between 0-1) which goes into the ""Mul"" op followed by the ""Squeeze"" op. The final output we are interested in is the tensor ""Squeeze:0"" which is the RGB image with values between 0-255.
Now lets convert the model to CoreML. In this particular model, the TF graph can take an image of any size (it will produce the output image of the same size). However, CoreML requires us to specify the exact size of all its inputs. Hence we choose a fixed size for our image. Lets say 256.
In [ ]:
import tfcoreml
mlmodel = tfcoreml.convert(
        tf_model_path = tf_model_path,
        mlmodel_path = './stylize.mlmodel',
        output_feature_names = ['Squeeze:0'],
        input_name_shape_dict = {'input:0':[1,256,256,3], 'style_num:0':[26]})
We see that the CoreML model expects two inputs: 'style_num__0' which is a multiarray and a sequence of length 26 and 'input__0' which is a multiarray corresponding to the image input and of shape (3,256,256). It produces a multiarray output called 'Squeeze__0'
Lets now grab an image and using coremltools see what the coreml model predicts.
In [ ]:
import numpy as np
import PIL
import requests
from io import BytesIO
from matplotlib.pyplot import imshow
# This is an image of a golden retriever from Wikipedia
img_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'
response = requests.get(img_url)
%matplotlib inline
img = PIL.Image.open(BytesIO(response.content))
img = img.resize([256,256], PIL.Image.ANTIALIAS)
img_np = np.asarray(img).astype(np.float32)
print img_np.shape, img_np.flatten()[:5]
imshow(img_np/255.0)
In [ ]:
# Transpose the image since CoreML requires C,H,W format (3,256,256)
coreml_image_input = np.transpose(img_np, (2,0,1))

# The style index is a one-hot vector: a vector of zeros of length 26, with 1 in the index whose style we want
index = np.zeros((26)).astype(np.float32)
index[0] = 1 #Lets say we want to get style 0

# CoreML Multi array interpreation is (Seq, Batch, C,H,W). Hence the style index input, which is a sequence,
# must be of shape (26,1,1,1,1)
coreml_style_index = index[:,np.newaxis,np.newaxis,np.newaxis,np.newaxis]

coreml_input = {'input__0': coreml_image_input, 'style_num__0': coreml_style_index}
coreml_out = mlmodel.predict(coreml_input, useCPUOnly = True)['Squeeze__0']
print coreml_out.shape, coreml_out.flatten()[:5]
In [ ]:
#Transpose back for visualization with imshow
coreml_out = np.transpose(np.squeeze(coreml_out), (1,2,0))
imshow(coreml_out/255.0)
That looks cool! Lets try another style.
In [ ]:
index = np.zeros((26)).astype(np.float32)
index[10] = 1 
coreml_style_index = index[:,np.newaxis,np.newaxis,np.newaxis,np.newaxis]
coreml_input = {'input__0': coreml_image_input, 'style_num__0': coreml_style_index}
coreml_out = mlmodel.predict(coreml_input, useCPUOnly = True)['Squeeze__0']
coreml_out = np.transpose(np.squeeze(coreml_out), (1,2,0))
imshow(coreml_out/255.0)
Lets also try to evaluate the same image and style with the TF model to check that the conversion was correct (we should get similar output)
In [ ]:
tf_img = np.expand_dims(img_np,axis=0)
tf_input_name_image = 'input:0'
tf_input_name_style_index = 'style_num:0'
feed_dict = {tf_input_name_image: tf_img, tf_input_name_style_index: index}
tf_output_name = 'Squeeze:0'
with tf.Session(graph = g) as sess:
    tf_out = sess.run(tf_output_name, 
                      feed_dict=feed_dict)
imshow(tf_out/255.0)
```",python bit light believe maybe model would nice magenta team could shed light python inception example notebook go process converting inception model neural network classifier model directly class label input image highlight importance setting image correctly get right get first inception frozen graph file model class label package import o import import frozen model address frozen file local directory tar conversion need find input output tensor graph also run graph numerical accuracy check load graph try find load graph definition import open get beginning end graph print id type print print name shape print print name shape output input input output towards end graph output convert import supply dictionary input name shape batch axis input batch size providing argument input image output model path model tensor name class label file providing make classifier model call converter may take load image testing get image model corresponding ready test model real image load image import import import io import import image golden retriever response getting directly pas image import getting prediction get array image print shape print value axis shape evaluate get highest label graph sess open print print print prediction class print prediction class probability match conversion correct however class label incorrect could reason answer image correctly passing neural network always crucial step neural know apply tricky find sometimes approach find source model check author model used training evaluation case model come slim library find see image scaled lie interval get graph sess print prediction class probability much better model dog highest class automatically image input type image change input passing converted see image scale set get image saved model import spec print scale print bias print bias print bias print suspected correct convert model set correctly time note channel scale first bias added call converter may take call predict print prediction class probability yes matching output correct note default predict call flag may vary slightly since lower precision path faster python style transfer network notebook go process converting style transfer model one linked page model image style index one possible image first model file model import o import import frozen model address frozen file local directory conversion need find input output tensor graph also run graph numerical accuracy check load graph try find generally load graph definition import open get beginning end graph range print output name shape print two image input input style index input finding output print last range print id type print print name shape print print name shape generally knowledge network may correctly determine output case output sigmoid image go squeeze final output interested tensor squeeze image convert model particular model graph take image size produce output image size however u specify exact size hence choose fixed size image say import see model two sequence length corresponding image input shape output grab image see model import import import io import import image golden retriever response print transpose image since format style index vector vector length index whose style want index index say want get style array batch hence style index input sequence must shape index true print transpose back visualization cool try another style index index index true also try evaluate image style model check conversion correct get similar output index graph sess,issue,positive,positive,positive,positive,positive,positive
371920933,"digging deeper  from examples - @aseemw looks like he has a way to fix this
```python
Inception V1 Example
In this notebook we will go through the process of converting the Inception V1 model to a Neural Network Classifier CoreML model that directly predicts the class label of the input image. We will highlight the importance of setting the image preprocessing parameters correctly to get the right results. Lets get started!
Lets first download the inception V1 frozen TF graph (the .pb file)
In [ ]:
# Download the model and class label package
import os
import urllib
import tarfile
def download_file_and_unzip(url, dir_path='.'):
    """"""Download the frozen TensorFlow model and unzip it.
    url - The URL address of the frozen file
    dir_path - local directory
    """"""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    k = url.rfind('/')
    fname = url[k+1:]
    fpath = os.path.join(dir_path, fname)

    if not os.path.exists(fpath):
        urllib.urlretrieve(url, fpath)
    tar = tarfile.open(fpath)
    tar.extractall(dir_path)
    tar.close()

inception_v1_url = 'https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz'
download_file_and_unzip(inception_v1_url)
For conversion to CoreML, we need to find the input and output tensor names in the TF graph. This will also be required to run the TF graph for numerical accuracy check. Lets load the TF graph def and try to find the names
In [ ]:
# Load the TF graph definition
import tensorflow as tf
tf_model_path = './inception_v1_2016_08_28_frozen.pb'
with open(tf_model_path, 'rb') as f:
    serialized = f.read()
tf.reset_default_graph()
original_gdef = tf.GraphDef()
original_gdef.ParseFromString(serialized)

**# Lets get some details about a few ops in the beginning and the end of the graph**
with tf.Graph().as_default() as g:
    tf.import_graph_def(original_gdef, name='')
    ops = g.get_operations()
    N = len(ops)
    for i in [0,1,2,N-3,N-2,N-1]:
        print('\n\nop id {} : op type: ""{}""'.format(str(i), ops[i].type));
        print('input(s):'),
        for x in ops[i].inputs:
            print(""name = {}, shape: {}, "".format(x.name, x.get_shape())),
        print('\noutput(s):'),
        for x in ops[i].outputs:
            print(""name = {}, shape: {},"".format(x.name, x.get_shape())),
The output of the Placeholder op is the input (""input:0"") and the output of the Softmax op towards the end of the graph is the output (""InceptionV1/Logits/Predictions/Softmax:0""). Lets convert to mlmodel now.
In [ ]:
import tfcoreml
# Supply a dictionary of input tensors' name and shape (with batch axis)
input_tensor_shapes = {""input:0"":[1,224,224,3]} # batch size is 1
#providing the image_input_names argument converts the input into an image for CoreML
image_input_name = ['input:0']
# Output CoreML model path
coreml_model_file = './inception_v1.mlmodel'
# The TF model's ouput tensor name
output_tensor_names = ['InceptionV1/Logits/Predictions/Softmax:0']
# class label file: providing this will make a ""Classifier"" CoreML model
class_labels = 'imagenet_slim_labels.txt'

# Call the converter. This may take a while
coreml_model = tfcoreml.convert(
        tf_model_path=tf_model_path,
        mlmodel_path=coreml_model_file,
        input_name_shape_dict=input_tensor_shapes,
        output_feature_names=output_tensor_names,
        image_input_names = image_input_name,
        class_labels = class_labels)
Lets load an image for testing. We will get predictions on this image using the TF model and the corresponding mlmodel.
In [ ]:
# Now we're ready to test out the CoreML model with a real image!
# Load an image
import numpy as np
import PIL
import requests
from io import BytesIO
from matplotlib.pyplot import imshow
# This is an image of a golden retriever from Wikipedia
img_url = 'https://upload.wikimedia.org/wikipedia/commons/9/93/Golden_Retriever_Carlos_%2810581910556%29.jpg'
response = requests.get(img_url)
%matplotlib inline
img = PIL.Image.open(BytesIO(response.content))
imshow(np.asarray(img))
In [ ]:
# for getting CoreML predictions we directly pass in the PIL image after resizing
import coremltools
img = img.resize([224,224], PIL.Image.ANTIALIAS)
coreml_inputs = {'input__0': img}
coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)
coreml_pred_dict = coreml_output['InceptionV1__Logits__Predictions__Softmax__0']
coreml_predicted_class_label = coreml_output['classLabel']

#for getting TF prediction we get the numpy array of the image
img_np = np.array(img).astype(np.float32)
print 'image shape:', img_np.shape
print 'first few values: ', img_np.flatten()[0:4], 'max value: ', np.amax(img_np)
img_tf = np.expand_dims(img_np, axis = 0) #now shape is [1,224,224,3] as required by TF

# Evaluate TF and get the highest label 
tf_input_name = 'input:0'
tf_output_name = 'InceptionV1/Logits/Predictions/Softmax:0'
with tf.Session(graph = g) as sess:
    tf_out = sess.run(tf_output_name, 
                      feed_dict={tf_input_name: img_tf})
tf_out = tf_out.flatten()    
idx = np.argmax(tf_out)
label_file = 'imagenet_slim_labels.txt' 
with open(label_file) as f:
    labels = f.readlines()
    
#print predictions   
print('\n')
print(""CoreML prediction class = {}, probabiltiy = {}"".format(coreml_predicted_class_label,
                                            str(coreml_pred_dict[coreml_predicted_class_label])))  
print(""TF prediction class = {}, probability = {}"".format(labels[idx],
                                            str(tf_out[idx])))
Both the predictions match, this means that the conversion was correct. However, the class label seems incorrect. What could be the reason? The answer is that we did not preprocess the image correctly before passing it to the neural network!! This is always a crucial step when using neural networks on images.
How do we know what preprocessing to apply? This can be tricky to find sometimes. The approach is to find the source of the pre-trained model and check for the preprocessing that the author of the model used while training and evaluation. In this case, the TF model comes from the SLIM library so we find the preprocessing steps here
We see that the image pixels have to be scaled to lie in the interval [-1,1]. Lets do that and get the TF predictions again!
In [ ]:
img_tf = (2.0/255.0) * img_tf - 1
with tf.Session(graph = g) as sess:
    tf_out = sess.run(tf_output_name, 
                      feed_dict={tf_input_name: img_tf})
tf_out = tf_out.flatten()    
idx = np.argmax(tf_out)
print(""TF prediction class = {}, probability = {}"".format(labels[idx],
                                            str(tf_out[idx])))
Much better now! The model is predicting a dog as the highest class.
What about CoreML? CoreML automatically handles the image preprocessing, when the input is of type image, so we do not have to change the input that we were passing in earlier. For the mlmodel we converted, lets see what the image biases and scale have been set to
In [ ]:
# Get image pre-processing parameters of a saved CoreML model
from coremltools.proto import FeatureTypes_pb2 as _FeatureTypes_pb2


spec = coremltools.models.utils.load_spec(coreml_model_file)
if spec.WhichOneof('Type') == 'neuralNetworkClassifier':
  nn = spec.neuralNetworkClassifier
if spec.WhichOneof('Type') == 'neuralNetwork':
  nn = spec.neuralNetwork  
if spec.WhichOneof('Type') == 'neuralNetworkRegressor':
  nn = spec.neuralNetworkRegressor

preprocessing = nn.preprocessing[0].scaler
print 'channel scale: ', preprocessing.channelScale
print 'blue bias: ', preprocessing.blueBias
print 'green bias: ', preprocessing.greenBias
print 'red bias: ', preprocessing.redBias

inp = spec.description.input[0]
if inp.type.WhichOneof('Type') == 'imageType':
  colorspace = _FeatureTypes_pb2.ImageFeatureType.ColorSpace.Name(inp.type.imageType.colorSpace)
  print 'colorspace: ', colorspace
As suspected, they are not correct. Lets convert the model again and set them correctly this time. Note that the channel scale is multiplied first and then the bias is added.
In [ ]:
# Call the converter. This may take a while
coreml_model = tfcoreml.convert(
        tf_model_path=tf_model_path,
        mlmodel_path=coreml_model_file,
        input_name_shape_dict=input_tensor_shapes,
        output_feature_names=output_tensor_names,
        image_input_names = image_input_name,
        class_labels = class_labels,
        red_bias = -1,
        green_bias = -1,
        blue_bias = -1,
        image_scale = 2.0/255.0)
In [ ]:
# Call CoreML predict again
coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)
coreml_pred_dict = coreml_output['InceptionV1__Logits__Predictions__Softmax__0']
coreml_predicted_class_label = coreml_output['classLabel']
print(""CoreML prediction class = {}, probability = {}"".format(coreml_predicted_class_label,
                                            str(coreml_pred_dict[coreml_predicted_class_label])))
Yes, now its matching the TF output and is correct!!
Note that predictions with the default CoreML predict call (when the flag useCPUOnly=True is skipped) may vary slightly since it uses a lower precision optimized path that runs faster.
```",digging like way fix python inception example notebook go process converting inception model neural network classifier model directly class label input image highlight importance setting image correctly get right get first inception frozen graph file model class label package import o import import frozen model address frozen file local directory tar conversion need find input output tensor graph also run graph numerical accuracy check load graph try find load graph definition import open get beginning end graph print id type print print name shape print print name shape output input input output towards end graph output convert import supply dictionary input name shape batch axis input batch size providing argument input image output model path model tensor name class label file providing make classifier model call converter may take load image testing get image model corresponding ready test model real image load image import import import io import import image golden retriever response getting directly pas image import getting prediction get array image print shape print value axis shape evaluate get highest label graph sess open print print print prediction class print prediction class probability match conversion correct however class label incorrect could reason answer image correctly passing neural network always crucial step neural know apply tricky find sometimes approach find source model check author model used training evaluation case model come slim library find see image scaled lie interval get graph sess print prediction class probability much better model dog highest class automatically image input type image change input passing converted see image scale set get image saved model import spec print scale print bias print bias print bias print suspected correct convert model set correctly time note channel scale first bias added call converter may take call predict print prediction class probability yes matching output correct note default predict call flag may vary slightly since lower precision path faster,issue,positive,positive,positive,positive,positive,positive
371916338,@adarob - did you ever hear of someone freezing the magenta graph? It would be nice to pick this up again some day - but stuck.,ever hear someone freezing magenta graph would nice pick day stuck,issue,negative,positive,positive,positive,positive,positive
371499412,"I am facing the same problem, any idea how to solve it?
@johndpope @Calvin-Shen ",facing problem idea solve,issue,negative,neutral,neutral,neutral,neutral,neutral
371342918,@JunShern take a look at the [unpack_bundle](https://github.com/tensorflow/magenta/blob/master/magenta/scripts/unpack_bundle.py) script. You can extract the regular tensorflow checkpoint file from the .mag file using that.,take look script extract regular file file,issue,negative,neutral,neutral,neutral,neutral,neutral
371223551,"@PeterChenYijie, yes we do support Python 3. I'll update the README to make that a little more clear.",yes support python update make little clear,issue,positive,negative,neutral,neutral,negative,negative
371115655,"Yeah, thanks very much for your kindly reply. @superMDguy @cghawthorne",yeah thanks much kindly reply,issue,positive,positive,positive,positive,positive,positive
371085889,"Hi,I want to know if it can be  compatible with py3. Because my envs is based on py3 ",hi want know compatible based,issue,negative,neutral,neutral,neutral,neutral,neutral
370971474,"That's correct, it adds support for ABC files to the NoteSequence converter. I'll update the README to mention this.",correct support converter update mention,issue,negative,neutral,neutral,neutral,neutral,neutral
370970839,"@timoisik the problem is that all of the sequences were discarded for various reasons. The output has some diagnostic info about that. Here are the relevant lines:

```
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melodies_discarded_too_short: 180
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_polyphonic_tracks_discarded: 297
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_short: 10638
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_polyphonic_tracks_discarded: 18665
```

For training the melody model, I don't think the tracks you're using will work. They look like polyphonic piano words. You'll want something that has tracks with monophonic lines.",problem various output diagnostic relevant training melody model think work look like polyphonic piano want something monophonic,issue,negative,positive,positive,positive,positive,positive
370884111,I can confirm that it works. I suspect it's just a matter of plugging it into the Bazel release machinery gizmo and... voilà!,confirm work suspect matter plugging release machinery,issue,negative,neutral,neutral,neutral,neutral,neutral
370870389,"No particularly good reason, just not something we've gotten around to.

@fredbertsch @golnazg is this something you'd be interested in doing?

We'd also be happy to accept a PR. :-)",particularly good reason something gotten around something interested also happy accept,issue,positive,positive,positive,positive,positive,positive
370746106,"There’s some code I wrote in the distant past, used to convert simple SVG
paths to stroke-3 format. It uses the “svg” python library.

https://github.com/hardmaru/sketch-rnn/blob/master/utils.py

Please note that this code snippet is written just for your reference, to
give you as a starting point, and I don’t support it anymore in any
capacity whatsoever.

On Tue, Mar 6, 2018 at 7:57 PM Akilesh B <notifications@github.com> wrote:

> Could you please point to appropriate references for converting new
> collection of svgs into the format that sketch rnn expects. That is,
> conversion of any new svg into desired format by following the simplified
> line drawings procedure mentioned here (
> https://github.com/googlecreativelab/quickdraw-dataset)
>
> Thanks,
> Akilesh
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1088>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGBoHnJ3fqU1Gh8VJ_fqL3DmPc4hRJghks5tbmuFgaJpZM4SegKx>
> .
>
",code wrote distant past used convert simple format python library please note code snippet written reference give starting point support capacity whatsoever tue mar wrote could please point appropriate converting new collection format sketch conversion new desired format following simplified line procedure thanks thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
370649541,"Hi, 

I found the problem. There was a ._loop.wav in my source folder, created by my mac and copied in my Ubuntu computer. 
I just removed it via rm ._loop.wav and everything is OK. 

",hi found problem source folder mac copied computer removed via everything,issue,negative,neutral,neutral,neutral,neutral,neutral
369719680,I can't figure out if there is still something I need to do here or if it just needs approval?,ca figure still something need need approval,issue,negative,neutral,neutral,neutral,neutral,neutral
369700304,"We don't check it in in `dist/` and we only host on CDN / NPM, but I would defer to @hapticdata on this since he's more familiar with the OSS JS world :)",check host would defer since familiar world,issue,negative,positive,positive,positive,positive,positive
369683774,"Some library authors prefer not to publish their generated bundle file to their repo; but the majority do include it just to keep it as simple and convenient for end-users as possible. 
If you would prefer to put it up on a CDN and link to it in a readme, I think that is fine as well.",library prefer publish bundle file majority include keep simple convenient possible would prefer put link think fine well,issue,negative,positive,positive,positive,positive,positive
369346675,"Hey Adam,

Here are some examples of the value of the interfaces. If you use the protobuffs internally but accept plain-objects matching the shape, the music-vae interface will look something like this with simple serialized data:

```ts
import { MusicVAE } from '@magenta/music-vae';

const noteSequence: INoteSequence = {
  notes: [
    {pitch: 36, startTime: 0 },
    {pitch: 42, startTime: 2 },
    {pitch: 42, startTime: 6},
    {pitch: 36, startTime: 8},
    {pitch: 42, startTime: 10}, 
    {pitch: 36, startTime: 12}, 
    {pitch: 42, startTime: 14},
    {pitch: 36, startTime: 16}, 
    {pitch: 36, startTime: 24}, 
    {pitch: 36, startTime: 28}, 
    {pitch: 42, startTime: 30}
  ]
};

new MusicVAE(checkPointURL)
  .initialize()
  .then((vae)=> vae.interpolate(noteSequence, 10))
  .then(output=> // do something );
```

If you are requiring them to be instances of NoteSequence and Note it will likely require the user to import 2 libraries (and is also more likely to result in 2 different versions of magenta.js being loaded in):

```ts
import { MusicVAE } from '@magenta/music-vae';
import { NoteSequence, Note } from '@magenta/core';

const noteSequence: NoteSequence = new NoteSequence({
  notes: [
    new Note({pitch: 36, startTime: 0 }), 
    new Note({pitch: 42, startTime: 2 }),
    new Note({pitch: 42, startTime: 6}),
    new Note({pitch: 36, startTime: 8}),
    new Note({pitch: 42, startTime: 10}),
    new Note({pitch: 36, startTime: 12}), 
    new Note({pitch: 42, startTime: 14}),
    new Note({pitch: 36, startTime: 16}),
    new Note({pitch: 36, startTime: 24}), 
    new Note({pitch: 36, startTime: 28}), 
    new Note({pitch: 42, startTime: 30})
  ]
});

new MusicVAE(checkPointURL)
  .initialize()
  .then((vae)=> vae.interpolate(noteSequence, 10))
  .then(output=> // do something );
```

Also if the user is writing vanilla js, they will need 2 script tags and will need to reference 2 global objects and this will result in 2 copies of magenta.js (one loaded globally for the `NoteSequence` and `Note` class and one bundled internally to `musicvae`:

```js
const NoteSequence = window.magenta.NoteSequence;
const Note = window.magenta.Note;
const vae = new musicvae.MusicVAE(checkpointURL);
```",hey value use internally accept matching shape interface look something like simple data import pitch pitch pitch pitch pitch pitch pitch pitch pitch pitch pitch new something note likely require user import also likely result different loaded import import note new new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new note pitch new something also user writing vanilla need script need reference global result one loaded globally note class one internally note new,issue,positive,positive,neutral,neutral,positive,positive
369076717,"Thanks for the feedback @hapticdata!

1. Switched to music-vae. For some reason I thought you'd said before the hyphen was a no-no but maybe that was for something different.
2. Note[] is going to be replaced by our NoteSequence proto once @cghawthorne has it checked in (probably tomorrow) anyways.",thanks feedback switched reason thought said hyphen maybe something different note going proto checked probably tomorrow anyways,issue,negative,positive,neutral,neutral,positive,positive
369069908,"I would recommend against using underscores in the package name, it is very uncommon for npm, snake case is very uncommon for JS. An npm user would expect `@magenta/musicvae` or `@magenta/music-vae`; lowercase and hyphen separated are the conventions.

I would consider keeping `Note` exclusively for internal use and using pure js arrays (or plain objects) instead:

```js
[
  [36, 0], [42, 2], [36, 4], [42, 6],
  [36, 8], [42, 10], [36, 12], [42, 14],
  [36, 16], [36, 24], [36, 28], [42, 30]
]
```
or
```js
[
  {pitch: 36, start: 0 }, {pitch: 42, start: 2 }, {pitch: 42, start: 6},
  {pitch: 36, start: 8}, {pitch: 42, start: 10}, {pitch: 36, start: 12}, {pitch: 42, start: 14},
  {pitch: 36, start: 16}, {pitch: 36, start: 24}, {pitch: 36, start: 28}, {pitch: 42, start: 30}
]
```
over

```js
[
  new Note(36, 0), new Note(42, 2), new Note(36, 4), new Note(42, 6),
  new Note(36, 8), new Note(42, 10), new Note(36, 12), new Note(42, 14),
  new Note(36, 16), new Note(36, 24), new Note(36, 28), new Note(42, 30)
]
```

it is very convenient that this would allow the input and output to remain serializable and these structures can be enforced in typescript with `type` or `interface`.",would recommend package name uncommon snake case uncommon user would expect hyphen would consider keeping note exclusively internal use pure plain instead pitch start pitch start pitch start pitch start pitch start pitch start pitch start pitch start pitch start pitch start pitch start new note new note new note new note new note new note new note new note new note new note new note new note convenient would allow input output remain enforced typescript type interface,issue,positive,positive,positive,positive,positive,positive
368491735,"I have encountered the same problem (using it with docker). My `eval_melodies.tfrecord` and `training_melodies.tfrecord` files are empty:

`-rw-r--r-- 1 root root 0 Feb 26 12:10 eval_melodies.tfrecord`
`-rw-r--r-- 1 root root 0 Feb 26 12:10 training_melodies.tfrecord`

I did run the following command to create note sequences first:

```
convert_dir_to_note_sequences \
--input_dir=$INPUT_DIRECTORY \
--output_file=$SEQUENCES_TFRECORD \
--recursive
```

which gives me the following output (I used 40 midi files downloaded from the web):

```
INFO:tensorflow:Converting files in '/midi-files/'.
INFO:tensorflow:0 files converted.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus90_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bor_ps1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se8_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus22_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bor_ps2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/appass_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus10_3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_hammerklavier_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_hammerklavier_4_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus90_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_les_adieux_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/appass_3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp6_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus22_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/appass_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus22_3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bor_ps6_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus22_4_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_hammerklavier_3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_les_adieux_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bach_846_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se5_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus10_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_opus10_1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp5_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bach_847_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bor_ps3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_hammerklavier_2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se4_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp4_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se7_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_esp2_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se1_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/beethoven_les_adieux_3_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/alb_se6_format0.mid.
INFO:tensorflow:Converted MIDI file /midi-files/bach_850_format0.mid.
```

The generated `notesequences.tfrecord` file is not empty: 

`-rw-r--r-- 1 root root 3706900 Feb 26 12:09 notesequences.tfrecord`

Than I did run the command to create the sequence examples:

```
melody_rnn_create_dataset \
--config=lookback_rnn \
--input=/tmp/notesequences.tfrecord \
--output_dir=/tmp/melody_rnn/sequence_examples \
--eval_ratio=0.10
```

Which gives me the following output:

```
INFO:tensorflow:

Completed.

INFO:tensorflow:Processed 40 inputs total. Produced 0 outputs.
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melodies_discarded_too_few_pitches: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melodies_discarded_too_long: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melodies_discarded_too_short: 180
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melodies_truncated: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_melody_lengths_in_bars:

INFO:tensorflow:DAGPipeline_MelodyExtractor_eval_polyphonic_tracks_discarded: 297
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_few_pitches: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_long: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_discarded_too_short: 10638
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melodies_truncated: 0
INFO:tensorflow:DAGPipeline_MelodyExtractor_training_melody_lengths_in_bars:

INFO:tensorflow:DAGPipeline_MelodyExtractor_training_polyphonic_tracks_discarded: 18665
INFO:tensorflow:DAGPipeline_RandomPartition_eval_melodies_count: 1
INFO:tensorflow:DAGPipeline_RandomPartition_training_melodies_count: 39
```

I see, that it produced 0 outputs. But what is the problem here? Are 40 midi files not enough? Or did i miss something else? 

Thanks for your help. ",problem docker empty root root root root run following command create note first recursive following output used web converting converted converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file converted file file empty root root run command create sequence following output total produced see produced problem enough miss something else thanks help,issue,negative,positive,neutral,neutral,positive,positive
368117864,"[for the standalone build](https://github.com/adarob/magenta/blob/c163c91078a3594b97b9a6d3d43747d725eb763c/magenta/models/music_vae/js/package.json#L8) I highly recommend changing `--standalone music-vae` to `--standalone musicvae`.
Using a hyphen would require the user to access it as `new window[""music-vae""].MusicVAE()` as opposed to just `new musicvae.MusicVAE()`.

Also, because [deeplearn](https://github.com/adarob/magenta/blob/c163c91078a3594b97b9a6d3d43747d725eb763c/magenta/models/music_vae/js/package.json#L25) would be a required dependency to install this via npm/yarn it should be a `dependency` and not a `devDependency`

Similarly [http-server](https://github.com/adarob/magenta/blob/c163c91078a3594b97b9a6d3d43747d725eb763c/magenta/models/music_vae/js/package.json#L30) should be a `devDependency` and not a `dependency` because it is only necessary for viewing the example, not as part of a build.",build highly recommend hyphen would require user access new window opposed new also would dependency install via dependency similarly dependency necessary example part build,issue,negative,positive,neutral,neutral,positive,positive
367762849,"Hmm, sorry not sure what the problem is then. I'd suggest asking over on the audioread github project because they'll have a better idea of how to debug this: https://github.com/beetbox/audioread",sorry sure problem suggest project better idea,issue,negative,positive,positive,positive,positive,positive
367532853,"Thank for your response. 
I installed Gstreamer, Ffmpeg and Mad, but it still doesn't work. 
I installed them via conda directly to my magenta env. ",thank response mad still work via directly magenta,issue,negative,negative,negative,negative,negative,negative
367528654,"That seems to be caused by the lack of a backend for audioread. This page has a list of supported backends: https://github.com/beetbox/audioread

I'd try installing one of those and see if that gets it to work.",lack page list try one see work,issue,negative,neutral,neutral,neutral,neutral,neutral
367526619,The padding happens inside the convolution function: https://github.com/tensorflow/magenta/blob/master/magenta/models/nsynth/wavenet/masked.py#L148,padding inside convolution function,issue,negative,neutral,neutral,neutral,neutral,neutral
367525394,"Sorry, but multi-gpu training is not currently supported externally. See #625 ",sorry training currently externally see,issue,negative,negative,negative,negative,negative,negative
367524873,Sorry for the long delay. The clash comes from an internal vs. external data reader. The best way to load the model is actually to redefine the graph with model code as you can see here: https://github.com/tensorflow/magenta/blob/master/magenta/models/nsynth/wavenet/fastgen.py#L53,sorry long delay clash come internal external data reader best way load model actually redefine graph model code see,issue,negative,positive,neutral,neutral,positive,positive
367459616,Hey I just updated the branch to reflect the latest commits in master. Kind of forgot that I had this pull request open haha. Do I need to do something or will you merge it now?,hey branch reflect latest master kind forgot pull request open need something merge,issue,positive,positive,positive,positive,positive,positive
366570676,"I'm running into a very similar error in an experiment I'm doing with custom data on polyphony_rnn:
```
polyphony_rnn_train --run_dir=./polyphony_rnn/logdir/run1 --sequence_example_file=./polyphony_rnn/sequence_examples/eval_poly_tracks.tfrecord --hparams=""batch_size=64,rnn_layer_sizes=[64,64]"" --num_training_steps=20000 --eval
INFO:tensorflow:hparams = {'rnn_layer_sizes': [64, 64], 'learning_rate': 0.001, 'clip_norm': 5, 'batch_size': 64, 'dropout_keep_prob': 0.5}
INFO:tensorflow:Train dir: ./polyphony_rnn/logdir/run1/train
INFO:tensorflow:Eval dir: ./polyphony_rnn/logdir/run1/eval
INFO:tensorflow:Counting records in ./polyphony_rnn/sequence_examples/eval_poly_tracks.tfrecord.
INFO:tensorflow:Total records: 54
INFO:tensorflow:[<tf.Tensor 'ParseSingleSequenceExample/ParseSingleSequenceExample:0' shape=(?, 259) dtype=float32>, <tf.Tensor 'ParseSingleSequenceExample/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>, <tf.Tensor 'strided_slice:0' shape=() dtype=int32>]
Traceback (most recent call last):
  File ""/Users/ianconway/anaconda/envs/magenta/bin/polyphony_rnn_train"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Users/ianconway/anaconda/envs/magenta/lib/python2.7/site-packages/magenta/models/polyphony_rnn/polyphony_rnn_train.py"", line 113, in console_entry_point
    tf.app.run(main)
  File ""/Users/ianconway/anaconda/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/Users/ianconway/anaconda/envs/magenta/lib/python2.7/site-packages/magenta/models/polyphony_rnn/polyphony_rnn_train.py"", line 103, in main
    events_rnn_train.run_eval(build_graph_fn, train_dir, eval_dir, num_batches)
  File ""/Users/ianconway/anaconda/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_train.py"", line 114, in run_eval
    EvalLoggingTensorHook(logging_dict, every_n_iter=num_batches),
  File ""/Users/ianconway/anaconda/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 209, in __init__
    raise ValueError(""invalid every_n_iter=%s."" % every_n_iter)
ValueError: invalid every_n_iter=0.
```

At first I had issues because the script which prepares the tf_records expects the files be above/below a given minimum/maximum length. After I wrote a script to split my midi files into appropriately sized chunks, I was left with only about 65 files. Before on an experiment where I was using more examples, I did not get this error. Just a hunch, but I think it may have to do with the number of midi files being too small, even though you have enough data. Maybe consider splitting the files and see if that helps. If I figure out a solution on my end I will post it.
",running similar error experiment custom data train counting total recent call last file line module file line main file line run main file line main file line file line raise invalid invalid first script given length wrote script split appropriately sized left experiment get error hunch think may number small even though enough data maybe consider splitting see figure solution end post,issue,negative,positive,neutral,neutral,positive,positive
366475981,"Update: I noticed that in magenta/magenta/models/polyphony_rnn/polyphony_rnn_create_dataset.py
the pipline instance hardcodes the max steps to 512:
`pipeline_instance = get_pipeline(
      min_steps=80,  # 5 measures
      max_steps=512,
      eval_ratio=FLAGS.eval_ratio,
      config=polyphony_model.default_configs['polyphony'])`
It would be useful if instead the min and max could be evaluated from the flags, unless there's some reason not to due this that I'm unaware of.

I'm closing the issue because it worked once I wrote a script to split my midi files.",update instance would useful instead min could unless reason due unaware issue worked wrote script split,issue,negative,positive,neutral,neutral,positive,positive
366123640,"It looks like it's a parser for [abc notation](http://abcnotation.com/), which is kind of like MIDI, but simpler and much more readable.",like parser notation kind like simpler much readable,issue,positive,positive,positive,positive,positive,positive
365862428,"Oops, premature send there.

I expect things to be consistent between the colab and the GitHub repo by
the end of next week. Sorry for the inconvenience!

On Thu, Feb 15, 2018, 12:53 AM Adam Roberts <adarob@google.com> wrote:

> Hello everyone! Apologies for the issues you are running into. The code is
> still in a bit of flux as I am integrating several new features related to
> a paper we recently submitted. I expect that things will be running
> smoothly again
>
> On Mon, Feb 12, 2018, 11:51 PM Inhyuk <notifications@github.com> wrote:
>
>> @ccassion <https://github.com/ccassion> Thanks for comment.
>> but It still gives an error.
>>
>> If I run after changing *CONFIG_MAP* to *config_map*, it gives an error
>> like below.
>> '''
>> Traceback (most recent call last):
>> File ""music_vae_train.py"", line 327, in
>> console_entry_point()
>> File ""music_vae_train.py"", line 323, in console_entry_point
>> tf.app.run(main)
>> File
>> ""/home/inhyuk/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"",
>> line 48, in run
>> _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>> File ""music_vae_train.py"", line 319, in main
>> run(configs.config_map)
>> File ""music_vae_train.py"", line 300, in run
>> task=FLAGS.task)
>> File ""music_vae_train.py"", line 146, in train
>> config.data_converter.is_training = True
>> AttributeError: 'Config' object has no attribute 'data_converter'
>> '''
>>
>> —
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tensorflow/magenta/issues/1023#issuecomment-365178150>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/ABCa6FyFLyhj1c-9wbZ2WBIuwf_fo48pks5tUT8SgaJpZM4Rj-2q>
>> .
>>
>
",premature send expect consistent end next week sorry inconvenience wrote hello everyone running code still bit flux several new related paper recently expect running smoothly mon wrote thanks comment still error run error like recent call last file line file line main file line run main file line main run file line run file line train true object attribute reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
365862131,"Hello everyone! Apologies for the issues you are running into. The code is
still in a bit of flux as I am integrating several new features related to
a paper we recently submitted. I expect that things will be running
smoothly again

On Mon, Feb 12, 2018, 11:51 PM Inhyuk <notifications@github.com> wrote:

> @ccassion <https://github.com/ccassion> Thanks for comment.
> but It still gives an error.
>
> If I run after changing *CONFIG_MAP* to *config_map*, it gives an error
> like below.
> '''
> Traceback (most recent call last):
> File ""music_vae_train.py"", line 327, in
> console_entry_point()
> File ""music_vae_train.py"", line 323, in console_entry_point
> tf.app.run(main)
> File
> ""/home/inhyuk/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"",
> line 48, in run
> _sys.exit(main(_sys.argv[:1] + flags_passthrough))
> File ""music_vae_train.py"", line 319, in main
> run(configs.config_map)
> File ""music_vae_train.py"", line 300, in run
> task=FLAGS.task)
> File ""music_vae_train.py"", line 146, in train
> config.data_converter.is_training = True
> AttributeError: 'Config' object has no attribute 'data_converter'
> '''
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/1023#issuecomment-365178150>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6FyFLyhj1c-9wbZ2WBIuwf_fo48pks5tUT8SgaJpZM4Rj-2q>
> .
>
",hello everyone running code still bit flux several new related paper recently expect running smoothly mon wrote thanks comment still error run error like recent call last file line file line main file line run main file line main run file line run file line train true object attribute reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
365438647,"It contains a test notesequence that used to be used in a unit test. It looks like it's no longer used anywhere, so we should probably just delete it.",test used used unit test like longer used anywhere probably delete,issue,negative,neutral,neutral,neutral,neutral,neutral
365178150,"@ccassion Thanks for comment.
but It still gives an error.

If I run after changing **CONFIG_MAP** to **config_map**, it gives an error like below.
```
Traceback (most recent call last):
  File ""music_vae_train.py"", line 327, in <module>
    console_entry_point()
  File ""music_vae_train.py"", line 323, in console_entry_point
    tf.app.run(main)
  File ""/home/inhyuk/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""music_vae_train.py"", line 319, in main
    run(configs.config_map)
  File ""music_vae_train.py"", line 300, in run
    task=FLAGS.task)
  File ""music_vae_train.py"", line 146, in train
    config.data_converter.is_training = True
AttributeError: 'Config' object has no attribute 'data_converter'
```
",thanks comment still error run error like recent call last file line module file line main file line run main file line main run file line run file line train true object attribute,issue,negative,positive,positive,positive,positive,positive
365147278,"@InhyukYee My colleague was able to pinpoint my issue that may help you as well.

The files on git and colab *may be* different than pip.

So, **CONFIG_MAP** is actually **config_map** in configs.py of the pip package version. It was changed on here: https://github.com/tensorflow/magenta/commit/b3e51fef5eb9f4875e12a9cb503e2e44d8d3c441#diff-9567b92253dc476296d67b51104b512e but I don't think the push was made to pip install version (?).

Anyhow, changing my configs call to (lower case) **config_map** worked for me.

Hope this resolves your issue and closes this.",colleague able pinpoint issue may help well git may different pip actually pip package version think push made pip install version anyhow call lower case worked hope issue,issue,positive,positive,positive,positive,positive,positive
365106378,"No. I haven't solved yet.
but I am running music_vae in miniconda library now.

The path is like as below.
```
~/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/music_vae
```

I tried to run both of Ubuntu 16.04 and MacOS High Sierra, but they give same error.",yet running library path like tried run high sierra give error,issue,negative,positive,positive,positive,positive,positive
365032769,"I came across this issue myself yesterday and was not able to fix it. 
I was attempting to run the MusicVAE google colab code on my local machine.

I'm using Python 3.5 on MacOS High Sierra.
",came across issue yesterday able fix run code local machine python high sierra,issue,negative,positive,positive,positive,positive,positive
365017536,Sorry for the delay. Were you able to solve this issue?,sorry delay able solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
364759433,"Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.
- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address commit check data verify set git company point contact authorized participate may need contact point contact company ask added group authorized know point contact direct project maintainer used register authorized contributor must used git commit order pas check please resolve problem pull request author add another comment bot run bot comment think anything,issue,positive,positive,positive,positive,positive,positive
364607621,Closing to make a change because I don't know how to edit the PR contents,make change know edit content,issue,negative,neutral,neutral,neutral,neutral,neutral
360669154,"I do all what you mentioned except for the 'midi'.
so please let me know how to start to study 'midi', is there any book or
program? or website?
I want to make pop music, is that with midi?

On Thu, Jan 25, 2018 at 8:34 PM, The Evil Man <notifications@github.com>
wrote:

> @terraxoxo <https://github.com/terraxoxo> understand midi, sheet music,
> harmony/counterpoint(for me those two are the same) and that will do for
> most of the western music... i guess
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-360657756>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhLztPVPcWJo8wUdCteAf-vmoTqijks5tOSu9gaJpZM4K3IsG>
> .
>
",except please let know start study book program want make pop music evil man wrote understand sheet music two western music guess reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
360657756,"@terraxoxo understand midi, sheet music, harmony/counterpoint(for me those two are the same) and that will do for most of the western music... i guess 
",understand sheet music two western music guess,issue,negative,neutral,neutral,neutral,neutral,neutral
360486240,"dear all, to be honest, I don't know how and where to start. MIDI studying
will be first? I only did until now ORGANIC instrument and vocal. so just
let me know real basic level to start computer music. and please let me
know the program which have to be ready.! thanks! xoxo

On Wed, Jan 24, 2018 at 8:11 AM, Jiri Prajzner <notifications@github.com>
wrote:

> @Zenanimator <https://github.com/zenanimator> i suggest you start with
> regular pentatonic but add little oscillation on its tones (i'd do a bend
> or a vibrato/tremolo on guitar to achieve that) to simulate microtones
> (intervals between tones that are smaller than a semitone). if i used a
> synth, i'd decide on a waveform (square, saw etc.) and then shifted the
> phase a bit. my opinion is that you can use midi as long as there's a fine
> grain resolution in order to achieve either one of the described methods.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-360127188>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhJGf2YMJLLbLgLRkzw54MTosD15vks5tNyvqgaJpZM4K3IsG>
> .
>
",dear honest know start first organic instrument vocal let know real basic level start computer music please let know program thanks wed wrote suggest start regular pentatonic add little oscillation bend guitar achieve simulate smaller semitone used decide square saw phase bit opinion use long fine grain resolution order achieve either one reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
360330109,Sorry for letting the image get so stale. I've just updated it to our latest release. Hopefully that resolves your problems!,sorry image get stale latest release hopefully,issue,negative,negative,negative,negative,negative,negative
360183064,"It looks like it's failing because `to_tensors` is returning a single value but the code is written to expect two values, is this unrelated?",like failing single value code written expect two unrelated,issue,negative,negative,neutral,neutral,negative,negative
360127188,"@Zenanimator i suggest you start with regular pentatonic but add little oscillation on its tones (i'd do a bend or a vibrato/tremolo on guitar to achieve that) to simulate microtones (intervals between tones that are smaller than a semitone). if i used a synth, i'd decide on a waveform (square, saw etc.) and then shifted the phase a bit. my opinion is that you can use midi as long as there's a fine grain resolution in order to achieve either one of the described methods.",suggest start regular pentatonic add little oscillation bend guitar achieve simulate smaller semitone used decide square saw phase bit opinion use long fine grain resolution order achieve either one,issue,negative,positive,neutral,neutral,positive,positive
360102074,"@terraxoxo I called up a friend of mine who's an experienced (now retired) recording engineer and musician about some concerns I was having about these recommendations to use MIDI. The thing about midi is is its going to trash all the subtlety in your music. Asian music (and here I'm including the sitar, which you say you also play) are absolutely reliant on microtonal variation... midi isn't going to capture any of that. I'm thinking someone might have to train a network to do some kind of Fourier pattern recognition on the waveform data itself...but I'm just guessing here. Melodyne does some of this and may be useful. Here's my friend's (more experienced) concurrence:

""I agree. MIDI is now a thirty-something year old data format that is not well suited to microtonal systems. 
""It seems that Celemony supports a wide range of alternate tunings, but does not include a specific Korean scale. It may allow the import of custom scale tunings. It does perform an esoteric FFT analysis on the audio to derive pitch/timing data for display but leaves the audio file untouched (until you edit…). I haven’t explored the alt-tuning capabillities in detail.""
",friend mine experienced retired recording engineer musician use thing going trash subtlety music music sitar say also play absolutely reliant variation going capture thinking someone might train network kind pattern recognition data guessing may useful friend experienced concurrence agree year old data format well wide range alternate include specific scale may allow import custom scale perform esoteric analysis audio derive data display leaf audio file untouched detail,issue,positive,positive,positive,positive,positive,positive
359887174,"Thanks for the fix in train_util.py! However, it looks like there's also a change to a README.md that has already been committed in a different PR. Can you remove that change so this PR is just for train_util.py?",thanks fix however like also change already different remove change,issue,positive,positive,neutral,neutral,positive,positive
359854138,"Hi @terraxoxo, we are certainly interested in all types of music, but as other have pointed out, machine learning is a data-based science and we unfortunately currently lack sufficient amounts of non-western music in the data format we need. If someone were able to build a collection in either MIDI or MusicXML format, we would love to collaborate on building appropriate models for it! Thanks for reaching out, an please let us know if you'd like to discuss more.",hi certainly interested music pointed machine learning science unfortunately currently lack sufficient music data format need someone able build collection either format would love collaborate building appropriate thanks reaching please let u know like discus,issue,positive,positive,positive,positive,positive,positive
359728931,"So there's good news and bad news.

:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.

:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.

*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*

<!-- need_author_consent -->",good news bad news good news everyone need sign pull request submitter commit done everything good confused bad news one someone pull request submitter need confirm project please confirm pull request note project maintainer terminal state meaning commit status change state confirm consent commit author merge pull request appropriate,issue,positive,positive,positive,positive,positive,positive
359703389,"oh, thank you very much zen animator. ha. do you like zen?
I am really interested in AI or other technologies also, virtual reality. I
am looking for someone who are interested in them, but i have no knowledge
even MIDI, i din't know that all these day's music are made by computer?
ha! so now am going to study it and make music with the midi. if anybody
know midi music even for pop music program, please let me know whatever.
best wishes, xoxo

On Tue, Jan 23, 2018 at 12:43 AM, Zenanimator <notifications@github.com>
wrote:

> :) Annyeonghaseyo. I hope someone steps up to help you for although I
> recognize the tremendous value of a collaboration between the classical
> Asian (Korean) musical arts and modern neural net research into sound
> structures, I am almost completely ignorant of the technologies required to
> do that research. I am studying cognitive science and philosophy (and am an
> amateur musician) but I'm still years away from really being able to offer
> any real help. I do truly wish you all the best and hope someone can help.
> If I come across anyone in my research contacts looking to expand their
> research in this direction I will refer them to you.
>
> On Sun, Jan 21, 2018 at 1:43 PM, terraxoxo <notifications@github.com>
> wrote:
>
> > yes, ha! thank you, yes, work with me, explorer something, ! ha.
> >
> > On Sun, Jan 21, 2018 at 1:03 AM, Zenanimator <notifications@github.com>
> > wrote:
> >
> > > *@terraxoxo <https://github.com/terraxoxo>*
> > > Are you the master gayageum player Han TeRra?? This is indeed a
> research
> > > opportunity! - I wish I knew enough about Magenta and neural nets to
> help
> > > you - please somebody work with this artist, this would be a phenomenal
> > > creative exchange!
> > >
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tensorflow/magenta/issues/402#
> issuecomment-359226379
> > >,
> > > or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/AWeUhN6w_
> > iqjG4Dakk5pS5jxXgdllsBrks5tMtNBgaJpZM4K3IsG>
> > > .
> > >
> >
> > —
> > You are receiving this because you commented.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tensorflow/magenta/issues/402#issuecomment-359283523
> >,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-
> auth/Ah_2bMwMQHnBKgoZnhCMKa-DSNSBy-RBks5tM69ngaJpZM4K3IsG>
> > .
>
> >
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-359682618>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhNIpCcHepxlDTWmXTSSgoed6mulRks5tNXFwgaJpZM4K3IsG>
> .
>
",oh thank much animator ha like really interested ai also virtual reality looking someone interested knowledge even di know day music made computer ha going study make music anybody know music even pop music program please let know whatever best tue wrote hope someone help although recognize tremendous value collaboration classical musical modern neural net research sound almost completely ignorant research cognitive science philosophy amateur musician still away really able offer real help truly wish best hope someone help come across anyone research looking expand research direction refer sun wrote yes ha thank yes work explorer something ha sun wrote master player han indeed research opportunity wish knew enough magenta neural help please somebody work artist would phenomenal creative exchange reply directly view mute thread reply directly view mute thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
359682618,":) Annyeonghaseyo. I hope someone steps up to help you for although I
recognize the tremendous value of a collaboration between the classical
Asian (Korean) musical arts and modern neural net research into sound
structures, I am almost completely ignorant of the technologies required to
do that research. I am studying cognitive science and philosophy (and am an
amateur musician) but I'm still years away from really being able to offer
any real help. I do truly wish you all the best and hope someone can help.
If I come across anyone in my research contacts looking to expand their
research in this direction I will refer them to you.

On Sun, Jan 21, 2018 at 1:43 PM, terraxoxo <notifications@github.com> wrote:

> yes, ha! thank you, yes, work with me, explorer something, ! ha.
>
> On Sun, Jan 21, 2018 at 1:03 AM, Zenanimator <notifications@github.com>
> wrote:
>
> > *@terraxoxo <https://github.com/terraxoxo>*
> > Are you the master gayageum player Han TeRra?? This is indeed a research
> > opportunity! - I wish I knew enough about Magenta and neural nets to help
> > you - please somebody work with this artist, this would be a phenomenal
> > creative exchange!
> >
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tensorflow/magenta/issues/402#issuecomment-359226379
> >,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/AWeUhN6w_
> iqjG4Dakk5pS5jxXgdllsBrks5tMtNBgaJpZM4K3IsG>
> > .
> >
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-359283523>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/Ah_2bMwMQHnBKgoZnhCMKa-DSNSBy-RBks5tM69ngaJpZM4K3IsG>
> .
>
",hope someone help although recognize tremendous value collaboration classical musical modern neural net research sound almost completely ignorant research cognitive science philosophy amateur musician still away really able offer real help truly wish best hope someone help come across anyone research looking expand research direction refer sun wrote yes ha thank yes work explorer something ha sun wrote master player han indeed research opportunity wish knew enough magenta neural help please somebody work artist would phenomenal creative exchange reply directly view mute thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
359291379,"The image on docker hub is 8 months old and does not seem to contain the `nsynth_generate` script. Perhaps you can build your own image based on the latest source with the Dockerfile provided in this repo instead?

`docker build -t magenta https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/tools/docker/Dockerfile`",image docker hub old seem contain script perhaps build image based latest source provided instead docker build magenta,issue,negative,positive,positive,positive,positive,positive
359283523,"yes, ha! thank you, yes, work with me, explorer something, ! ha.

On Sun, Jan 21, 2018 at 1:03 AM, Zenanimator <notifications@github.com>
wrote:

> *@terraxoxo <https://github.com/terraxoxo>*
> Are you the master gayageum player Han TeRra?? This is indeed a research
> opportunity! - I wish I knew enough about Magenta and neural nets to help
> you - please somebody work with this artist, this would be a phenomenal
> creative exchange!
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-359226379>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhN6w_iqjG4Dakk5pS5jxXgdllsBrks5tMtNBgaJpZM4K3IsG>
> .
>
",yes ha thank yes work explorer something ha sun wrote master player han indeed research opportunity wish knew enough magenta neural help please somebody work artist would phenomenal creative exchange reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
359226379,"**@terraxoxo** 
Are you the master gayageum player Han TeRra?? This is indeed a research opportunity! - I wish I knew enough about Magenta and neural nets to help you - please somebody work with this artist, this would be a phenomenal creative exchange!",master player han indeed research opportunity wish knew enough magenta neural help please somebody work artist would phenomenal creative exchange,issue,positive,positive,positive,positive,positive,positive
359114674,"related - https://github.com/tensorflow/magenta/issues/715
I gave up on this after failing to freeze the graph - interested to see if this can be progressed. 
I think there maybe a problem with certain operations.
Presumably if you're freezing graph - you're trying to run on mobile? 
if so - are you targeting ios or android?


_TF graph must be cycle free (cycles are generally created due to control flow ops like if, while, map, etc.)_",related gave failing freeze graph interested see think maybe problem certain presumably freezing graph trying run mobile android graph must cycle free generally due control flow like map,issue,positive,positive,positive,positive,positive,positive
359114024,"TF graph must be cycle free (cycles are generally created due to control flow ops like if, while, map, etc.)


Supported Ops
List of TensorFlow ops that are supported currently (see tfcoreml/_ops_to_layers.py):

Add
ArgMax
AvgPool
BatchNormWithGlobalNormalization
BatchToSpaceND*
BiasAdd
ConcatV2, Concat
Const
Conv2D
Conv2DBackpropInput
DepthwiseConv2dNative
Elu
Exp
ExtractImagePatches
Fill*
FloorMod*
FusedBatchNorm
Gather*
Greater*
GreaterEqual*
Identity
Log
LogicalAnd*
LRN
MatMul
Max*
Maximum
MaxPool
Mean*
Min*
Minimum
MirrorPad
Mul
Neg
OneHot
Pad
Placeholder
Prod*
RandomUniform*
RealDiv
Reciprocal
Relu
Relu6
Reshape*
ResizeNearestNeighbor
Rsqrt
Shape
Sigmoid
Slice
Softmax
SpaceToBatchND*
Square
SquaredDifference
StridedSlice
Sub
Sum*
Tanh
Transpose*",graph must cycle free generally due control flow like map list currently see add fill gather greater identity log maximum mean min minimum pad prod reciprocal reshape shape sigmoid slice square sub sum tanh transpose,issue,positive,positive,neutral,neutral,positive,positive
358874161,"From what I'm looking at, you're using Anacoda, if so run
`conda create -n py36 python=3.6 anaconda`
since you're getting a 

> ""RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6

error. If this doesn't work try searching for ways to update your version of python because it seems that you have conda 3.6 but for one reason or another you're getting a runtime warning.
In my personal opinion (I don't know your situation) I would just get jupyter notebook and just install 3.6. To start, run
`brew install python3`
and then run
`pip3 install jupyter`
(something like that).
While you're fixing this issue run
`brew doctor`
to find any problems, if you want to.",looking run create anaconda since getting version module match version error work try searching way update version python one reason another getting warning personal opinion know situation would get notebook install start run brew install python run pip install something like fixing issue run brew doctor find want,issue,negative,neutral,neutral,neutral,neutral,neutral
356396190,"Oh, we should already be on pretty_midi 0.2.8, which has the fix. Have you synced your whole git repo?",oh already fix whole git,issue,negative,positive,positive,positive,positive,positive
356395255,"Ah, that was a bug in pretty_midi that has since been fixed. I'll need to update our pretty_midi version.",ah bug since fixed need update version,issue,negative,positive,neutral,neutral,positive,positive
356208391,"TensorFlow version 1.4.0
Python version: Python 3.5.4 |Continuum Analytics
Bazel version (if compiling from source): 0.90

Is it OK to run “convert_dir_to_note_sequences”?
I tried to run “python 2to3” and i got the same error message
@cghawthorne  Thanks!",version python version python analytics version source run tried run python got error message thanks,issue,negative,positive,positive,positive,positive,positive
356200283,"<img width=""958"" alt=""screen shot 2018-01-09 at 3 10 28 pm"" src=""https://user-images.githubusercontent.com/23095057/34709000-5e343fd6-f550-11e7-8c37-3ff00535be23.png"">
<img width=""882"" alt=""screen shot 2018-01-09 at 3 11 04 pm"" src=""https://user-images.githubusercontent.com/23095057/34709001-5e70cac8-f550-11e7-8c62-0e18a7f4b8d7.png"">
",screen shot screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
356045983,"On the [MAPS page](http://www.tsi.telecom-paristech.fr/aao/en/2010/07/08/maps-database-a-piano-database-for-multipitch-estimation-and-automatic-transcription-of-music/), there's a [download link](http://service.tsi.telecom-paristech.fr/cgi-bin/user-service/subscribe.cgi?ident=maps&form=&license=1). If it asks for a login/password, I think you can just hit cancel and it will work anyway.",page link think hit cancel work anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
355730406,"protobuf-python-3.2.0.tar.gz => protobuf-python-3.4.0.tar.gz
bazel test //magenta:all  successful  !
Then I  tried to convert midi file to NoteSequences according to magenta/scripts/README.md

(tensorflow_theano_20180103) c:\bazel\0.90>ls magenta/my_train_dir
1.mid

(tensorflow_theano_20180103) c:\bazel\0.90>bazel run //magenta/scripts:convert_dir_to_note_sequences -- --input_dir=C:/bazel/0.90/magenta/my_train_dir --output_file=C:/bazel/0.90/magenta/my_train_dir/notesequences.tfrecord --recursive
INFO: Analysed target //magenta/scripts:convert_dir_to_note_sequences (0 packages loaded).
INFO: Found 1 target...
Target //magenta/scripts:convert_dir_to_note_sequences up-to-date:
  C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/execroot/__main__/bazel-out/x64_windows-fastbuild/bin/magenta/scripts/convert_dir_to_note_sequences.exe
  C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/execroot/__main__/bazel-out/x64_windows-fastbuild/bin/magenta/scripts/convert_dir_to_note_sequences.zip
INFO: Elapsed time: 1.369s, Critical Path: 0.03s
INFO: Build completed successfully, 1 total action

INFO: Running command line: C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/execroot/__main__/bazel-out/x64_windows-fastbuild/bin/magenta/scripts/convert_dir_to_note_sequences.exe '--input_dir=C:/bazel/0.90/magenta/my_train_dir' '--output_file=C:/bazel/0.90/magenta/my_train_dir/notesequences.tfrecord' --recursive
Traceback (most recent call last):
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\__main__\magenta\scripts\convert_dir_to_note_sequences.py"", line 34, in <module>
    from magenta.music import midi_io
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\__main__\magenta\music\midi_io.py"", line 29, in <module>
    import pretty_midi
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\pretty_midi\__init__.py"", line 138, in <module>
    from .pretty_midi import *
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\pretty_midi\pretty_midi.py"", line 13, in <module>
    from .instrument import Instrument
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\pretty_midi\instrument.py"", line 13, in <module>
    from .containers import PitchBend
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\pretty_midi\containers.py"", line 5, in <module>
    from .utilities import key_number_to_key_name
  File ""\\?\C:\Users\GOF\AppData\Local\Temp\Bazel.runfiles_yau5u79k\runfiles\pretty_midi\utilities.py"", line 84
    ur'^(?P<key>[ABCDEFGabcdefg])'
                                 ^
SyntaxError: invalid syntax
ERROR: Non-zero return code '1' from command: Process exited with status 1

@cghawthorne  Thanks!",test successful tried convert file according run recursive target loaded found target target time critical path build successfully total action running command line recursive recent call last file line module import file line module import file line module import file line module import instrument file line module import file line module import file line key invalid syntax error return code command process status thanks,issue,positive,positive,positive,positive,positive,positive
355708723,@falaktheoptimist any luck getting sketch rnn to work in keras?,luck getting sketch work,issue,negative,neutral,neutral,neutral,neutral,neutral
355644523,"Oh, one thing I just noticed is that you're not using an up to date copy of the Magenta repo. Our most recent version uses `protobuf-python-3.4.0.tar.gz`. Can you try syncing your repo and trying again?",oh one thing date copy magenta recent version try trying,issue,negative,neutral,neutral,neutral,neutral,neutral
355468460,"Whatever i use the vpn or not , i got the same error checksum
![image](https://user-images.githubusercontent.com/34936990/34595155-9a4ebfa2-f210-11e7-8818-9f07afadf24c.png)
",whatever use got error image,issue,negative,neutral,neutral,neutral,neutral,neutral
355390342,"@RuchirB, because of the way our protobuf code is generated, you can't run the python files directly from the repo. You'll need to either install our pip package or use our development environment: https://github.com/tensorflow/magenta#development-environment",way code ca run python directly need either install pip package use development environment,issue,negative,positive,neutral,neutral,positive,positive
355192684,"Yes I agree.  Changing to False will make more midi files usable.

There is also an ` ignore_polyphonic_notes` option here, which means exactly the opposite to the `skip_polyphony` in music_vae. One of them should be changed perhaps...

https://github.com/tensorflow/magenta/blob/de1c8e8f66ee08d3776433863cbdf51d56c332f7/magenta/music/melodies_lib.py#L239
  ",yes agree false make usable also option exactly opposite one perhaps,issue,positive,negative,negative,negative,negative,negative
355077167,"OK, it looks like the the protobuf library you're downloading has a checksum that's different than expected. I can't reproduce this problem on either my mac or linux environments. I don't have a Windows environment handy to test, but that shouldn't affect the checksum of the downloaded file. I suspect that there's maybe a problem with the download, like a proxy that's giving you a different file or an error page. I'd try downloading that URL (https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-python-3.2.0.tar.gz) using `wget`, `curl`, or a similar tool on the commandline and see what result you get, or just take a look at `C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/external/protobuf/protobuf-python-3.2.0.tar.gz` and see if the file looks like an error message.",like library different ca reproduce problem either mac environment handy test affect file suspect maybe problem like proxy giving different file error page try curl similar tool see result get take look see file like error message,issue,negative,positive,positive,positive,positive,positive
354971654,"Have I written custom code : No
OS Platform and Distribution : Windows10 64bit
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): r1.4
Python version: 2.7.12
Bazel version (if compiling from source): 0.90
GCC/Compiler version (if compiling from source): 4.6.3

Here""s my WORKSPACE:
#######################################################
new_http_archive(
    name = ""pretty_midi"",
    build_file = ""pretty_midi.BUILD"",
    sha256 = ""8326c9c87d5efc91670a5881581eb192b095a1c93afd5fddc91b2232af8e9b9b"",
    strip_prefix = ""pretty-midi-0.2.6/pretty_midi"",
    url = ""https://github.com/craffel/pretty-midi/archive/0.2.6.tar.gz"",
)

http_archive(
    name = ""protobuf"",
    sha256 = ""3f833c1c367f53803f5f849181af4a4edb20f8dd1fbdced19b5a2d52ee43ed54"",
    strip_prefix = ""protobuf-3.2.0"",
    url = ""https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-python-3.2.0.tar.gz"",
)
new_http_archive(
    name = ""six_archive"",
    build_file = ""six.BUILD"",
    sha256 = ""105f8d68616f8248e24bf0e9372ef04d3cc10104f1980f54d57b2ce73a5ad56a"",
    strip_prefix = ""six-1.10.0"",
    url = ""https://pypi.python.org/packages/source/s/six/six-1.10.0.tar.gz#md5=34eed507548117b2ab523ab14b2f8b55"",
)

bind(
    name = ""six"",
    actual = ""@six_archive//:six"",
)

bind(
    name = ""python_headers"",
    actual = ""//util/python:python_headers"",
)

new_http_archive(
    name = ""mido"",
    build_file = ""mido.BUILD"",
    sha256 = ""7844ff77ab12469504c46e9aa035722a2829e7c72b8b6241c78d356895e88114"",
    strip_prefix = ""mido-1.1.17/mido"",
    url = ""https://github.com/olemb/mido/archive/1.1.17.tar.gz"",
)
#######################################################
Here's the error messages:
c:\bazel\0.90>bazel.exe test //magenta:all
ERROR: C:/bazel/0.90/magenta/BUILD:21:1: error loading package 'magenta/protobuf': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading [https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-python-3.2.0.tar.gz] to C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/external/protobuf/protobuf-python-3.2.0.tar.gz: Checksum was c574e2b2178ffe66599274e8cfa11ecf83799a7992be30f0b68fb33ea0a0f1af but wanted 3f833c1c367f53803f5f849181af4a4edb20f8dd1fbdced19b5a2d52ee43ed54 and referenced by '//magenta:magenta'
ERROR: Analysis of target '//magenta:magenta' failed; build aborted: error loading package 'magenta/protobuf': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading [https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-python-3.2.0.tar.gz] to C:/users/gof/appdata/local/temp/_bazel_gof/m5nvlktk/external/protobuf/protobuf-python-3.2.0.tar.gz: Checksum was c574e2b2178ffe66599274e8cfa11ecf83799a7992be30f0b68fb33ea0a0f1af but wanted 3f833c1c367f53803f5f849181af4a4edb20f8dd1fbdced19b5a2d52ee43ed54
INFO: Elapsed time: 312.693s
FAILED: Build did NOT complete successfully (7 packages loaded)
    currently loading: magenta/protobuf
ERROR: Couldn't start the build. Unable to run tests

@cghawthorne  Thank you!",written custom code o platform distribution bit source binary source version use command python version version source version source name sha name sha name sha bind name six actual six bind name actual name sha error test error error loading package error reading extension file package error error analysis target magenta build aborted error loading package error reading extension file package error time build complete successfully loaded currently loading error could start build unable run thank,issue,negative,positive,neutral,neutral,positive,positive
354936261,"Ah. The ""issue"" is here: https://github.com/tensorflow/magenta/blob/de1c8e8f66ee08d3776433863cbdf51d56c332f7/magenta/models/music_vae/configs.py#L50

Do you think it makes more sense for this to be False by default?",ah issue think sense false default,issue,negative,negative,negative,negative,negative,negative
354922856,"@adarob Thank you for your reply. Michael and I are in the same research group. 

We followed your suggestion and found that the data Michael used is empty after the pre-processing in music_vae_train. The dataset we used is Nottingham dataset [https://github.com/jukedeck/nottingham-dataset], which is a polyphonic piano data set. We found that if we put the raw data to music_vae (config = cat-mel2bar-small), it will return 0 melody segment. After we extract its melody by ourselves (extract notes played by right hand), the music_vae_train works.

We are checking the data pre-processor of music_vae_train. 

Another question I want to ask is the speed of data pre-process. When we train music_vae with the data set lakh (http://colinraffel.com/projects/lmd/#get), we found that the training speed of music_vae is 1 step per minute.   


  
  ",thank reply research group suggestion found data used empty used polyphonic piano data set found put raw data return melody segment extract melody extract right hand work data another question want ask speed data train data set found training speed step per minute,issue,positive,negative,neutral,neutral,negative,negative
354921597,"Thank you for your reply. I fixed the bug by setting master=""""  instead of local/master",thank reply fixed bug setting instead,issue,negative,positive,neutral,neutral,positive,positive
354845567,I'm not sure why you would be getting that error. Can you trying installing the latest version of Bazel and see if that works?,sure would getting error trying latest version see work,issue,negative,positive,positive,positive,positive,positive
354842197,"@MichaelMa2014, have you been able to resolve this issue? @MarkWuNLP, are you seeing a similar issue?",able resolve issue seeing similar issue,issue,negative,positive,positive,positive,positive,positive
354842091,"That should be enough to train, assuming most of them meet the
requirements, which is that they have segments with overlapping parts in
all 3 of the following categories: drums (channel 9), melody (program
number 0-31), bass (program number 32-39).
The ""melody"" and ""bass"" sections can be polyphonic, but the model will
ignore all but the highest-pitched lines.

-Adam

On Sat, Dec 30, 2017 at 5:12 AM, MarkWuNLP <notifications@github.com> wrote:

> Hi Adam,
> @adarob <https://github.com/adarob> How much data does music_vae_train
> need if I use the cat-trio_16bar_big setting? I am not sure whether 0.2
> million midi files are enough for this model.
> Another question: does the music_vae model have some special requirements
> for the provided data? For example, melody_rnn requires midi files that do
> not have polyphonic notes. Does music_vae model have similar requirements?
> I am looking for your reply. Thank you in advance.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/985#issuecomment-354545564>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6CdtiSJFJ50t2L0fGsnDS57hKfc2ks5tFjaigaJpZM4RGmv1>
> .
>
",enough train assuming meet following channel melody program number bass program number melody bass polyphonic model ignore sat wrote hi much data need use setting sure whether million enough model another question model special provided data example polyphonic model similar looking reply thank advance reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
354839120,"Hi. I'm not sure why you are getting this error message. Are you running
with bazel? Have you tried using the pip package?

On Sat, Dec 30, 2017 at 5:30 AM, MarkWuNLP <notifications@github.com> wrote:

> Hi,
> When I run music_vae_train.py, I encountered the following issue. It seems
> that music_vae_train does not support python3 right now? Any solution?
>
> ""C:\Program Files\Anaconda3\python.exe"" C:/Users/RinnaMSRA/
> PycharmProjects/musicgeneration/magenta-master/magenta-master/magenta/
> models/music_vae/music_vae_train.py --config=cat-trio_16bar_big
> --run_dir=D:\data\music\log_vae --mode=train
> --examples_path=D:\data\music\nottingham_xml.tfrecord
> 2017-12-30 11:58:03.812382: I C:\tf_jenkins\home\workspace\
> rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:137]
> Your CPU supports instructions that this TensorFlow binary was not compiled
> to use: AVX AVX2
> 2017-12-30 11:58:04.583557: I C:\tf_jenkins\home\workspace\
> rel-win\M\windows-gpu\PY\35\tensorflow\core\common_
> runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
> pciBusID: ff8e:00:00.0
> totalMemory: 11.15GiB freeMemory: 10.97GiB
> 2017-12-30 11:58:04.583942: I C:\tf_jenkins\home\workspace\
> rel-win\M\windows-gpu\PY\35\tensorflow\core\common_
> runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device
> (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: ff8e:00:00.0,
> compute capability: 3.7)
> 2017-12-30 11:58:33.431348: E C:\tf_jenkins\home\workspace\
> rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\session.cc:69]
> Not found: No session factory registered for the given session options:
> {target: ""local"" config: } Registered factories are {DIRECT_SESSION,
> GRPC_SESSION}.
> Traceback (most recent call last):
> File ""C:/Users/RinnaMSRA/PycharmProjects/musicgeneration/magenta-
> master/magenta-master/magenta/models/music_vae/music_vae_train.py"", line
> 294, in
> console_entry_point()
> File ""C:/Users/RinnaMSRA/PycharmProjects/musicgeneration/magenta-
> master/magenta-master/magenta/models/music_vae/music_vae_train.py"", line
> 290, in console_entry_point
> tf.app.run(main)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"",
> line 48, in run
> _sys.exit(main(_sys.argv[:1] + flags_passthrough))
> File ""C:/Users/RinnaMSRA/PycharmProjects/musicgeneration/magenta-
> master/magenta-master/magenta/models/music_vae/music_vae_train.py"", line
> 286, in main
> run(configs.config_map)
> File ""C:/Users/RinnaMSRA/PycharmProjects/musicgeneration/magenta-
> master/magenta-master/magenta/models/music_vae/music_vae_train.py"", line
> 282, in run
> task=FLAGS.task)
> File ""C:/Users/RinnaMSRA/PycharmProjects/musicgeneration/magenta-
> master/magenta-master/magenta/models/music_vae/music_vae_train.py"", line
> 176, in train
> is_chief=is_chief)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\
> training\python\training\training.py"", line 535, in train
> config=config) as session:
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 368, in MonitoredTrainingSession
> stop_grace_period_secs=stop_grace_period_secs)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 673, in *init*
> stop_grace_period_secs=stop_grace_period_secs)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 493, in *init*
> self._sess = _RecoverableSession(self._coordinated_creator)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 851, in *init*
> _WrappedSession.*init*(self, self._create_session())
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 856, in _create_session
> return self._sess_creator.create_session()
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 554, in create_session
> self.tf_sess = self._session_creator.create_session()
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\
> training\monitored_session.py"", line 428, in create_session
> init_fn=self._scaffold.init_fn)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\training\session_manager.py"",
> line 273, in prepare_session
> config=config)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\training\session_manager.py"",
> line 178, in _restore_checkpoint
> sess = session.Session(self._target, graph=self._graph, config=config)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"",
> line 1482, in *init*
> super(Session, self).*init*(target, graph, config=config)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"",
> line 622, in *init*
> self._session = tf_session.TF_NewDeprecatedSession(opts, status)
> File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"",
> line 473, in *exit*
> c_api.TF_GetCode(self.status.status))
> tensorflow.python.framework.errors_impl.NotFoundError: No session factory
> registered for the given session options: {target: ""local"" config: }
> Registered factories are {DIRECT_SESSION, GRPC_SESSION}.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/997>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6GCd-GVRkDChj3ZbkIp9XsMviiTkks5tFjrugaJpZM4RPmWk>
> .
>
",hi sure getting error message running tried pip package sat wrote hi run following issue support python right solution binary use found device name major minor device device name bus id compute capability found session factory registered given session target local registered recent call last file line file line main file line run main file line main run file line run file line train file line train session file line file line file line file line self file line return file line file line file line file line sess file line super session self target graph file line status file line exit session factory registered given session target local registered thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
354677438,"It's possible that the hparams used when training / saving bundle / generating with attention_rnn were different. Are you sure you used the same values during all steps? Otherwise it should work if you used attention_rnn all throughout. Perhaps different systems or pc builds set diffrrent ""default"" hparams values? In that case, manually enter the same hparams used on machine B as machine A.",possible used training saving bundle generating different sure used otherwise work used throughout perhaps different set default case manually enter used machine machine,issue,negative,positive,positive,positive,positive,positive
354545564,"Hi Adam,
   @adarob  How much data does music_vae_train need if I use the cat-trio_16bar_big setting? I am not sure whether 0.2 million midi files are enough for this model. 
   Another question: does the music_vae model have some special requirements for the provided data? For example, melody_rnn requires midi files that do not have polyphonic notes. Does music_vae model have similar requirements?
   I am looking for your reply. Thank you in advance. ",hi much data need use setting sure whether million enough model another question model special provided data example polyphonic model similar looking reply thank advance,issue,positive,positive,positive,positive,positive,positive
354250417,"Also to mention my hypotheses are monophonic vs polyphonic midis, aside from the normal flags used",also mention hypothesis monophonic polyphonic aside normal used,issue,negative,positive,positive,positive,positive,positive
353222202,"Because of the way our protobuf files are generated, you cannot run the python files directly from the repo. You'll need to either install our pip package or set up the Magenta dev environment as documented here: https://github.com/tensorflow/magenta#development-environment",way run python directly need either install pip package set magenta dev environment,issue,negative,positive,neutral,neutral,positive,positive
353221933,You probably won't be able to run both training and evaluation on the GPU on the same machine. I'd recommend running the eval job on just CPU. You can do this by running `export CUDA_VISIBLE_DEVICES=''` before starting the eval job.,probably wo able run training evaluation machine recommend running job running export starting job,issue,negative,positive,positive,positive,positive,positive
352895795,"I had the same issue, I managed to solve that by running **pip install django-pipeline**",issue solve running pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
352826725,"Hi Michael!

It sounds like there might not be enough examples for it to fill a batch.
If you run it in eval mode, it will report how many training examples it is
able to extract.
Which config are you using and what is your dataset?

-Adam

On Tue, Dec 19, 2017 at 12:35 AM, Michael Ma <notifications@github.com>
wrote:

> music_vae_train gets stuck after saying ""Shuffle buffer filled"". I can
> see that it takes all the memory on a GPU card and also 100% of one CPU
> core but it has been this way for more than 24 hours now. I am still trying
> to figure out whether it's a bug and any help is welcome!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/985>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6HPjEFYjJujqWuDOWEF_oq5BzCaCks5tB3VmgaJpZM4RGmv1>
> .
>
",hi like might enough fill batch run mode report many training able extract tue wrote stuck saying shuffle buffer filled see memory card also one core way still trying figure whether bug help welcome thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
351251639,"You can check if it is using your gpu with `nvidia-smi` in a separate terminal. It should post logging events, but you may need to add a `--alsologtostderr` flag at the end of the command.",check separate terminal post logging may need add flag end command,issue,negative,neutral,neutral,neutral,neutral,neutral
349698312,"somebody has created this tensorflow to coreml converter.
https://github.com/tf-coreml/tf-coreml

I don't have time to test this - but it would nice to see magenta working on ios - so going to re-open this.  @adarob - it seems like the converter can accommodate frozen and non -frozen pb files. 
My remaining problem is simply to find the appropriate variable name for the input to match up.


```python

import tfcoreml as tf_converter
tf_converter.convert(tf_model_path = 'my_model.pb',
                     mlmodel_path = 'my_model.mlmodel',
                     output_feature_names = ['softmax:0'])					
When input shapes are not fully specified in the frozen .pb file:

import tfcoreml as tf_converter
tf_converter.convert(tf_model_path = 'my_model.pb',
                     mlmodel_path = 'my_model.mlmodel',
                     output_feature_names = ['softmax:0'],
                     input_name_shape_dict = {'input:0' : [1, 227, 227, 3]}) /// <- this input name is unknown to me
```",somebody converter time test would nice see magenta working going like converter accommodate frozen non problem simply find appropriate variable name input match python import input fully frozen file import input name unknown,issue,negative,positive,positive,positive,positive,positive
349489346,"That's right. I tried adding checkpoint file but it doesn't work. Thank you for your help!

Regards,
Yan",right tried file work thank help yan,issue,positive,positive,positive,positive,positive,positive
349486880,"One step towards a fix is that after unpacking the bundle but before training you should create a file called ""checkpoint"" in improv_rnn/run6/train that looks like:

```
model_checkpoint_path: ""model.ckpt""
all_model_checkpoint_paths: ""model.ckpt""
```

But there seems to be some kind of checkpoint incompatibility with what's in the bundle; in fact even if you create a new bundle then unpack it and train you'll get variable name errors.  I'm looking into it now...",one step towards fix bundle training create file like kind incompatibility bundle fact even create new bundle unpack train get variable name looking,issue,positive,positive,positive,positive,positive,positive
348603583,"OK, I found it it was an issue with the 

--hparams=""batch_size=XX,rnn_layer_sizes=[XX,XX]"" 

It has to match the training command.  Should be noted in the info.",found issue match training command noted,issue,negative,neutral,neutral,neutral,neutral,neutral
348459069,"I am facing this issue while trying out this  [demo](https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Image_Stylization.ipynb) .
model.transform returns NaN for all the values
",facing issue trying nan,issue,negative,neutral,neutral,neutral,neutral,neutral
348274966,"Hi @hardmaru 

Sorry for bothering you again.

I am trying to create a deterministic regressor for the next point of a sketch given a sequence of 16 points. My loss function is composed of two parts. The first (loss_1) takes into account the MSE of true position and predicted position. Second part (loss_2) is a categorical cross entropy that accounts for the length 3 array of possible pen states. As an initial attempt, I am using different weights (1,10,100) to deal with the unbalanced number of possible states in the data. As the training goes on, I see that loss_2 is decaying, but still much greater than loss_1 (~80x) and does not seem to be getting any close to loss_1 in the future. See the figure enclosed.

![image](https://user-images.githubusercontent.com/7592099/33447182-a468f766-d5e9-11e7-8d69-ba97d6e5af3c.png)

Is this a behavior that you would expect? I'd appreciate if you could give me any advice and I'd be happy to provide you more information about the model etc.",hi sorry trying create deterministic regressor next point sketch given sequence loss function composed two first account true position position second part categorical cross entropy length array possible pen initial attempt different deal unbalanced number possible data training go see still much greater seem getting close future see figure image behavior would expect appreciate could give advice happy provide information model,issue,positive,positive,positive,positive,positive,positive
347779027,"Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.
- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git company point contact authorized participate may need contact point contact company ask added group authorized know point contact direct project maintainer order pas check please resolve problem pull request author add another comment bot run,issue,positive,positive,positive,positive,positive,positive
347580227,"Hi @hardmaru. Thanks for you comment.

However, I am still confused. In the document you sent, I found `We suggest you build a dataset where the maximum sequence length is less than 250`. Does that mean that `Ns=250`?

Anyways, I am having trouble to set the size of the sequence used as input for training. Do the sequences always have to start with at the beginning of a drawing and finishes at the end of a drawing?

**EDIT:** I think I understood the meaning of `Ns`. This is the length of the _s-th_ sketch. Therefore, if `Ns < Nmax=250`, you pad the sequence `S` up to length `Nmax` by appending `(0,0,0,0,1)` to the sequence. Is that correct?",hi thanks comment however still confused document sent found suggest build maximum sequence length le mean anyways trouble set size sequence used input training always start beginning drawing end drawing edit think understood meaning length sketch therefore pad sequence length sequence correct,issue,negative,negative,negative,negative,negative,negative
347457093,"Update on the issue.

SEQUENCES_TFRECORD=data/improv_rnn/jazz_xml2/training_lead_sheets.tfrecord
RUNDIR=improv_rnn/run6

improv_rnn_train \
--config=chord_pitches_improv \
--run_dir=${RUNDIR} \
--sequence_example_file=${SEQUENCES_TFRECORD} \
--hparams=""batch_size=128,rnn_layer_sizes=[256, 256, 256]"" \
--num_training_steps=10

command: ls improv_rnn/run6/train
output: 
checkpoint
events.out.tfevents.1511859596.DESKTOP-VTMLC08
graph.pbtxt
model.ckpt
model.ckpt.meta
model.ckpt-1.data-00000-of-00001
model.ckpt-1.index
model.ckpt-1.meta

Many thanks. 
Yan
",update issue command output many thanks yan,issue,negative,positive,positive,positive,positive,positive
347361906,"Hi!

Please take a look at this document:

https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn

""Each example in the dataset is stored as list of coordinate offsets: ∆x, ∆y, and a binary value representing whether the pen is lifted away from the paper. This format, we refer to as stroke-3, is described in this paper. Note that the data format described in the paper has 5 elements (stroke-5 format), and this conversion is done automatically inside the DataLoader. Below is an example sketch of a turtle using this format:""

Hope that helps!",hi please take look document example list binary value whether pen away paper format refer paper note data format paper format conversion done automatically inside example sketch turtle format hope,issue,positive,neutral,neutral,neutral,neutral,neutral
346980433,"I was playing around with a variant on Performance RNN that handles multiple instruments.  Code is [here](https://github.com/iansimon/magenta/tree/midi_rnn) but not sure it's in a great state; that said, it should be fairly straightforward to modify the Performance RNN representation to handle instrument change events.

Of course, stuffing all instruments into a single stream might very well not be the best way to handle multiple instrument generation...",around variant performance multiple code sure great state said fairly straightforward modify performance representation handle instrument change course stuffing single stream might well best way handle multiple instrument generation,issue,positive,positive,positive,positive,positive,positive
346867371,"I understand that I can change piano to another instrument, but I'm asking if the music models could use multiple instruments at once.",understand change piano another instrument music could use multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
346607674,"if you want to generate midi files with more instruments,maybe you should edit the code by yourself,becaulse  I traced the code ""melody_rnn_generate"" and know that beforing generating midi file,you should refer a certain instrument. and so as other model in my opinion.",want generate maybe edit code code know generating file refer certain instrument model opinion,issue,negative,positive,positive,positive,positive,positive
345807369,This should only happen if there's a problem with your local pip installation. Have you tried doing `pip install -U pip`?,happen problem local pip installation tried pip install pip,issue,negative,neutral,neutral,neutral,neutral,neutral
345160446,"@hardmaru I used the model you provided , did not make any other changes , just replaced the .npz",used model provided make,issue,negative,neutral,neutral,neutral,neutral,neutral
345157627,"@hardmaru Thanks a lot! But I do not know how to look the size of the rnn ,and how to make changes",thanks lot know look size make,issue,negative,positive,positive,positive,positive,positive
345139932,"Check that the size of the rnn in your notebook matches the rnn that you
had trained.

On Thu, Nov 16, 2017 at 6:34 PM yemeijuan <notifications@github.com> wrote:

> I have trained sketch-rnn model with airplane.full.npz. The information
> about the airplane.full.npz is as follows:
> [image: image]
> <https://user-images.githubusercontent.com/33479160/32926474-5e42e0a6-cb82-11e7-95b6-1f451df69b15.png>
> But when I test it, An error has occurred:
> [image: image]
> <https://user-images.githubusercontent.com/33479160/32926528-b54892c4-cb82-11e7-925e-5be6db1262a8.png>
> Please tell me how to solve it. Thanks a lot!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/948>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGBoHm6AJaXBRjSm52S7_8xCRjzeFswaks5s3PDIgaJpZM4Qhc0X>
> .
>
",check size notebook trained wrote trained model information image image test error image image please tell solve thanks lot thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
345108950,"I'm new to Magenta, but I might be able to help a little (at least, as you say, point you in the right direction). If we look at Melody RNN for example (https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn), we can see from the README that to train a new model, you are supposed to supply a --config flag. This config flag is then passed on to the config_from_flags() function in melody_rnn_config_flags.py, which returns a config object which contains information such as the encoder decoder and the number of layers and units per layer. It looks like you can see examples of the default configs in melody_rnn_model.py: `default_configs = {
    'basic_rnn': MelodyRnnConfig(
        magenta.protobuf.generator_pb2.GeneratorDetails(
            id='basic_rnn',
            description='Melody RNN with one-hot encoding.'),
        magenta.music.OneHotEventSequenceEncoderDecoder(
            magenta.music.MelodyOneHotEncoding(
                min_note=DEFAULT_MIN_NOTE,
                max_note=DEFAULT_MAX_NOTE)),
        tf.contrib.training.HParams(
            batch_size=128,
            rnn_layer_sizes=[128, 128],
            dropout_keep_prob=0.5,
            clip_norm=5,
            learning_rate=0.001)),

    'lookback_rnn': MelodyRnnConfig(
        magenta.protobuf.generator_pb2.GeneratorDetails(
            id='lookback_rnn',
            description='Melody RNN with lookback encoding.'),
        magenta.music.LookbackEventSequenceEncoderDecoder(
            magenta.music.MelodyOneHotEncoding(
                min_note=DEFAULT_MIN_NOTE,
                max_note=DEFAULT_MAX_NOTE)),
        tf.contrib.training.HParams(
            batch_size=128,
            rnn_layer_sizes=[128, 128],
            dropout_keep_prob=0.5,
            clip_norm=5,
            learning_rate=0.001)),

    'attention_rnn': MelodyRnnConfig(
        magenta.protobuf.generator_pb2.GeneratorDetails(
            id='attention_rnn',
            description='Melody RNN with lookback encoding and attention.'),
        magenta.music.KeyMelodyEncoderDecoder(
            min_note=DEFAULT_MIN_NOTE,
            max_note=DEFAULT_MAX_NOTE),
        tf.contrib.training.HParams(
            batch_size=128,
            rnn_layer_sizes=[128, 128],
            dropout_keep_prob=0.5,
            attn_length=40,
            clip_norm=3,
            learning_rate=0.001))
}`
The documentation only specifies how to work with the default configurations, but  it probably isn't that hard to create your own, or even hack up the existing defaults if you have a development environment. 
From there, I think the config file is passed to  events_rnn_graph.build_graph() which returns a  graph which is then sent to  events_rnn_train.run_training(). 
If anyone out there see's an error in what I've said, or knows a better way to change the architecture, please let me know, I'm interested in this as well. 
Note: I had another look at the repo; it seems most of the music related projects are pretty similar to what I've discribed here, but sketch_rnn defines the network params and hyper params right in the model.py file.
",new magenta might able help little least say point right direction look melody example see train new model supposed supply flag flag function object information number per layer like see default attention documentation work default probably hard create even hack development environment think file graph sent anyone see error said better way change architecture please let know interested well note another look music related pretty similar network hyper right file,issue,positive,positive,positive,positive,positive,positive
344778849,"@iansimon Hi Ian, I am encountering the same issue and tried the method you suggested. However, it seems that the model is still training from the begining, i.e. it doesn't mention about restoring saved checkpoint as I will expect. Also, I noticed that runing performance_rnn_train, .index and .data files will be saved besides .meta and .ckpt files. I am not sure whether I will need those other two files while restoring checkpoint. Thank you! 

Below is the output when runing  performance_rnn_train as you suggested,  
INFO:tensorflow:Train dir: performance_rnn/run2\train
INFO:tensorflow:Starting training loop...
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 1 into performance_rnn/run2\train\model.ckpt.

while I am expecting something like this:
INFO:tensorflow:Restoring parameters from performance_rnn/run3\train\model.ckpt

",hi issue tried method however model still training mention saved expect also saved besides sure whether need two thank output train starting training loop create saving something like,issue,positive,positive,positive,positive,positive,positive
344504780,"If I'm understanding you correctly, you used some midi files as training data and then took the primer melody from the same training data, and were surprised to find that the melody generated by the model was not identical to the original training data?
If I've understood you correctly, this is expected behavior of the software; the models are not intended to simply repeat the training data, but instead to generalize and create new music in a style similar to the training data. 
Hope that helps.",understanding correctly used training data took primer melody training data find melody model identical original training data understood correctly behavior intended simply repeat training data instead generalize create new music style similar training data hope,issue,positive,positive,positive,positive,positive,positive
343790257,"Hi Noon van der Silk,

There is going to be a trade off between the reconstruction loss and the KL
loss.

What numbers did you ultimately get for the reconstruction loss and KL
loss? And can you use the trained model to generate meaningful sketches?
How large is your dataset?

If you want to have a better KL loss, sooner in training, I would recommend
try setting kl_decay_rate to 0.9990. In addition, setting kl_weight to 1.0
will lower the KL loss.

On Sun, Nov 12, 2017 at 2:23 PM Noon van der Silk <notifications@github.com>
wrote:

> i'm playing around with a custom dataset in sketch rnn
>
> i've set it up in (basically) the stroke-3 format; expect in my case i'm
> not using dx dy, but just simply x, y
>
> i'm keeping the pen-state as a single boolean
>
> however, before progress very far my network cost goes negative and after
> that no improvement in KL is seen:
>
> [image: image]
> <https://user-images.githubusercontent.com/129525/32704079-f602b61e-c853-11e7-927b-6f559415585e.png>
>
> these are the hparams:
>
> ...
> INFO:tensorflow:sketch-rnn
> INFO:tensorflow:Hyperparams:
> INFO:tensorflow:grad_clip = 1.0
> INFO:tensorflow:conditional = True
> INFO:tensorflow:min_learning_rate = 1e-05
> INFO:tensorflow:num_mixture = 20
> INFO:tensorflow:is_training = True
> INFO:tensorflow:input_dropout_prob = 0.9
> INFO:tensorflow:kl_decay_rate = 0.99995
> INFO:tensorflow:kl_tolerance = 0.2
> INFO:tensorflow:random_scale_factor = 0.15
> INFO:tensorflow:decay_rate = 0.9999
> INFO:tensorflow:use_recurrent_dropout = True
> INFO:tensorflow:num_steps = 10000000
> INFO:tensorflow:use_output_dropout = False
> INFO:tensorflow:max_seq_len = 250
> INFO:tensorflow:z_size = 128
> INFO:tensorflow:augment_stroke_prob = 0.0
> INFO:tensorflow:learning_rate = 0.001
> INFO:tensorflow:batch_size = 100
> INFO:tensorflow:enc_model = layer_norm
> INFO:tensorflow:use_input_dropout = False
> INFO:tensorflow:dec_model = hyper
> INFO:tensorflow:enc_rnn_size = 256
> INFO:tensorflow:output_dropout_prob = 0.9
> INFO:tensorflow:save_every = 500
> INFO:tensorflow:kl_weight = 0.5
> INFO:tensorflow:data_set = ['choreo-alt-data.npz']
> INFO:tensorflow:kl_weight_start = 0.01
> INFO:tensorflow:dec_rnn_size = 2048
> INFO:tensorflow:recurrent_dropout_prob = 0.9
> INFO:tensorflow:Loading data files.
> INFO:tensorflow:Loaded 172490/5505/5505 from choreo-alt-data.npz
> INFO:tensorflow:Dataset combined: 183500 (172490/5505/5505), avg len 234
> INFO:tensorflow:model_params.max_seq_len 234.
> total images <= max_seq_len is 172490
> total images <= max_seq_len is 5505
> total images <= max_seq_len is 5505
> INFO:tensorflow:normalizing_scale_factor 0.1818.
> INFO:tensorflow:Model using gpu.
> INFO:tensorflow:Input dropout mode = False.
> INFO:tensorflow:Output dropout mode = False.
> INFO:tensorflow:Recurrent dropout mode = True.
> INFO:tensorflow:Model using gpu.
> INFO:tensorflow:Input dropout mode = 0.
> INFO:tensorflow:Output dropout mode = 0.
> INFO:tensorflow:Recurrent dropout mode = 0.
>
> any thoughts?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/945>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGBoHtlEOVctqSChOXLyfiMdayFZwBRdks5s12_EgaJpZM4QbEe0>
> .
>
",hi noon van silk going trade reconstruction loss loss ultimately get reconstruction loss loss use trained model generate meaningful large want better loss sooner training would recommend try setting addition setting lower loss sun noon van silk wrote around custom sketch set basically format expect case simply keeping single however progress far network cost go negative improvement seen image image conditional true true true false false hyper loading data loaded combined total total total model input dropout mode false output dropout mode false recurrent dropout mode true model input dropout mode output dropout mode recurrent dropout mode thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
343706121,"Curious about this as well. The last response specifically. 

Since it seems he is using the correct config model type.",curious well last response specifically since correct model type,issue,positive,negative,neutral,neutral,negative,negative
342853857,"Hi

KL loss should be positive and the reconstruction loss iusually becomes negative so it is normal.

For an example of how to load a trained TensorFlow model, please take a look at this IPython Notebook example:

https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb
",hi loss positive reconstruction loss becomes negative normal example load trained model please take look notebook example,issue,negative,positive,neutral,neutral,positive,positive
341815588,"This is because we translate the data into its onehot representation before we save it to disk. In hindsight, we probably should have saved the onehot translation until right before the data goes into the network. If you have thoughts on how to update the code to do this, we'd be open to a pull request.",translate data representation save disk hindsight probably saved translation right data go network update code open pull request,issue,positive,positive,positive,positive,positive,positive
341595943,"Kokoro error seems to be spurious, so will merge anyway.",error spurious merge anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
340964105,"@Calvin-Shen Here is an example of a corrupted midi file. It drained all my memory.
```
>>> import pretty_midi as pm
>>> pm.PrettyMIDI(""30073.mid"")
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/v-chenxm/.local/lib/python3.5/site-packages/pretty_midi/pretty_midi.py"", line 84, in __init__
    ' it is likely corrupt'.format(max_tick)))
ValueError: MIDI file has a largest tick of 4295008119, it is likely corrupt
```",example corrupted file drained memory import recent call last file line module file line likely file tick likely corrupt,issue,negative,negative,neutral,neutral,negative,negative
340788581,"@jveres How did you solve your problem? 
@iansimon I just trained a SINGLE style model (the style being starrynight) using the image_stylization_train.py code, following the instructions on README, for 40k iterations. However, my results are very weird.
![starrynight_step40k_fulltraining_picabo_0](https://user-images.githubusercontent.com/32304564/32230672-9df162ca-be4b-11e7-9a2f-c81d5b7b756d.png)
![starrynight_step40k_fulltraining_guerrillero_0](https://user-images.githubusercontent.com/32304564/32230676-a1c856e2-be4b-11e7-9a51-d4984eee372a.png)

These are the results of applying the trained model on the evaluation image : Picabo_lava.jpg and guerrillero.jpg respectively",solve problem trained single style model style code following however weird trained model evaluation image respectively,issue,negative,negative,negative,negative,negative,negative
340786490,"@xiesiyuan Could you please let us know how you fixed the bug? I am having similar trouble
",could please let u know fixed bug similar trouble,issue,negative,negative,neutral,neutral,negative,negative
340606205,"It will never go away entirely, but 1600 steps is almost certainly not enough.  For our pretrained models (on ~1400 classical pieces) we trained for many tens of thousands of steps.

Also, when you synthesize the generated MIDI, you may want to use a synth where notes eventually decay to zero.  This doesn't actually solve the problem, but makes it less unpleasant.",never go away entirely almost certainly enough classical trained many also synthesize may want use eventually decay zero actually solve problem le unpleasant,issue,negative,negative,neutral,neutral,negative,negative
340027556,That looks like a problem with your tensorflow installation. I'd suggest reinstalling TensorFlow and perhaps trying the non-GPU version of TensorFlow.,like problem installation suggest perhaps trying version,issue,negative,neutral,neutral,neutral,neutral,neutral
340013606,@Calvin  Hey dude thanks for the communication!  That's literally all we need to learn!  Google should hire you now that you've proven to be more dedicated to building a community over here than the guy who said his job is to build a community over here. (Doug Eck please be more to your word and actually come up on here and build a community instead of leaving the people alone to ask questions to a void which then prevents the possibility of a community ever appearing).  ,hey dude thanks communication literally need learn hire proven building community guy said job build community please word actually come build community instead leaving people alone ask void possibility community ever,issue,negative,positive,neutral,neutral,positive,positive
339912321,"@493238731 Thanks for the notes. I agree that 0.99 or 0.999 value and moving the statement to the new location as you suggested are better due to the float32 issue. My last run failed probably because of the float32 issue. I am rerunning with what you suggested.

I do think that the input x to the mu_law function is in [-1, 1], because the [µ-law formula](https://en.wikipedia.org/wiki/%CE%9C-law_algorithm) requires that. ",thanks agree value moving statement new location better due float issue last run probably float issue think input function formula,issue,positive,positive,positive,positive,positive,positive
339909468,"@jasondesante yesterday,I run the performance_rnn_train script, and even 20000 iteration.The loss was always keeping about 4.0 or so,and the accuracy was about 0.05 or so.However to my surprise when I saw it again at 4.00 p.m today,the loss has dropped about 0.05 and the accuracy was about 97%,and the iteration counts was about 75000 at that time,it takes me nearly a whole day to do that.
maybe the instruction is not wrong.
Hope my experience can help you~ best wishes!!!",yesterday run script even loss always keeping accuracy surprise saw today loss accuracy iteration time nearly whole day maybe instruction wrong hope experience help best,issue,positive,positive,positive,positive,positive,positive
339848828,"@Invisibility Your code maybe wrong? You should run `out = tf.clip_by_value(x, -1, 0.999999999)` between `out = tf.sign(out) * tf.log(1 + mu * tf.abs(out)) / np.log(1 + mu)` and `out = tf.floor(out * 128)`.Because the `x` is in [0, 2^16 -1] not in [-1, 1].In addition, the`0.999999999` is too big to treated as `1.` in `tf.float32/np.float32` mode, you can change it using 0.99, 0.999 etc.",invisibility code maybe wrong run mu mu addition big mode change,issue,negative,negative,negative,negative,negative,negative
339845469,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.
In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm order pas check please resolve problem pull request author add another comment bot run,issue,positive,negative,negative,negative,negative,negative
339806977,This change probably will resolve issue #904 ,change probably resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
339794720,"Thank you @493238731. I am rerunning the training, and it seems to run further than before. 

Based on the suggestion in #853, I updated the function in utils.py as follows:

    def mu_law(x, mu=255, int8=False):
      """"""A TF implementation of Mu-Law encoding.

      Args:
        x: The audio samples to encode.
        mu: The Mu to use in our Mu-Law.
        int8: Use int8 encoding.

      Returns:
        out: The Mu-Law encoded int8 data.
      """"""
      out = tf.clip_by_value(x, -1, 0.999999999)
      out = tf.sign(out) * tf.log(1 + mu * tf.abs(out)) / np.log(1 + mu)
      out = tf.floor(out * 128)
      if int8:
        out = tf.cast(out, tf.int8)
      return out
",thank training run based suggestion function implementation audio encode mu mu use use mu mu return,issue,negative,neutral,neutral,neutral,neutral,neutral
339732278,"@Calvin-Shen  Sorry I haven't found a solution yet.  I have spent less time playing with this stuff now that I've realized it isn't as inviting of a community as I once thought.  The criticism I've seen from people that actually know what they're doing is that Magenta doesn't have enough documentation, and I understand what they're saying because I am clueless.

I've realized Magenta is only for people that already have years of experience and know a lot of what to do.  If you are learning through reading websites and courses because of this.....it seems like you will still get no help here. 

I watched a lot of videos from a guy called ""Doug Eck"" who apparently works on Magenta....and he would say that they need more musicians and normal people popping in to give feedback and get involved, and that the people on the google brain team are always in the forums answering questions.  I don't know if that's a lie or just his intentions that didn't come true but I feel disappointed by the disconnect between the intentions and the reality of this project.

I simply want to learn!  If I'm here alone in the forums just venting my feelings to myself it is a very discouraging thing because I know how much farther along I would be if someone had just shared some simple information.

TLDR, No and I'm frustrated",sorry found solution yet spent le time stuff inviting community thought criticism seen people actually know magenta enough documentation understand saying magenta people already experience know lot learning reading like still get help watched lot guy apparently work magenta would say need normal people give feedback get involved people brain team always know lie come true feel disappointed disconnect reality project simply want learn alone discouraging thing know much farther along would someone simple information,issue,negative,negative,neutral,neutral,negative,negative
339563423,"Based on @zhang-jian observation that train_op isn't the right operation, and the code in baseline model (baseline/train.py and baseline/models/ae.py), I made the following change in wavenet/train.py:

Instead of:

      train_op = opt.minimize(
          loss,
          global_step=global_step,
          name=""train"",
          colocate_gradients_with_ops=True)

I change it to:

      train_op = slim.learning.create_train_op(
          loss,
          opt,
          global_step=global_step,
          colocate_gradients_with_ops=True)

This appears to make loss output not the same as global step. 

However, my training was still not successful (forgot whether it has NaN or the loss not converging). It may be because I didn't have enough GPU memory to run with 32 worker replicas and 32 total_batch_size as mentioned in the parameter descriptions.",based observation right operation code model made following change instead loss train change loss opt make loss output global step however training still successful forgot whether nan loss converging may enough memory run worker parameter,issue,negative,positive,positive,positive,positive,positive
339563206,"@jasondesante can you run train script and train --eval script at the same time?  I can't do this, otherwise it will make a lot of errors~",run train script train script time ca otherwise make lot,issue,negative,neutral,neutral,neutral,neutral,neutral
339562840,"I just facing the same problem like you~, do you have solution yet? @jasondesante ",facing problem like solution yet,issue,negative,neutral,neutral,neutral,neutral,neutral
339542973,"Just scale the audio into [-1,1) instead of [-1, 1] can avoid the NaN loss. @493238731 ",scale audio instead avoid nan loss,issue,negative,neutral,neutral,neutral,neutral,neutral
339542571,@auzxb Can you show how to solve the `NaN loss` bug more detail? Thanks,show solve nan loss bug detail thanks,issue,negative,positive,positive,positive,positive,positive
339539903,"I meet the same problem.And the loss always is NaN in the tensorboard, after 50k step using default params.
Maybe it uses batch_size = 1 in default params to train unstable?",meet loss always nan step default maybe default train unstable,issue,negative,neutral,neutral,neutral,neutral,neutral
339396185,I'd suggest taking a look at [Performance RNN](https://github.com/tensorflow/magenta/tree/master/magenta/models/performance_rnn). It can generate polyphonic music with expressive timing and dynamics. You might also be interested in our [web demo](https://magenta.tensorflow.org/performance-rnn-browser) of that model.,suggest taking look performance generate polyphonic music expressive timing dynamic might also interested web model,issue,positive,positive,positive,positive,positive,positive
338325456,"pardon for half-baked request; 
issue is fixed by removing "".name"" on line 250 of image_utils.py:
    image = scipy.misc.imread(f)",pardon request issue fixed removing line image,issue,negative,positive,neutral,neutral,positive,positive
338001660,"You can add a program argument to the to_sequence call here: https://github.com/tensorflow/magenta/blob/master/magenta/models/melody_rnn/melody_rnn_sequence_generator.py#L128

However, I'd recommend just loading the midi into a DAW (e.g., GarageBand) and modifying it that way.",add program argument call however recommend loading daw way,issue,negative,neutral,neutral,neutral,neutral,neutral
337915010,"I trained a model myself and just used the ckpt with editing the parameters of the model to match my trained model and it worked, that was a long time ago I don't know if this is fixed now or not",trained model used model match trained model worked long time ago know fixed,issue,negative,positive,neutral,neutral,positive,positive
337107282,Yes it seems this is a memory issue. Could you please try using only part of your dataset and see if the issue still exists? Sometimes one corrupted file can eat up all the memory and it happened to me before. ,yes memory issue could please try part see issue still sometimes one corrupted file eat memory,issue,positive,neutral,neutral,neutral,neutral,neutral
336807476,I just use your updated code. I hope you help me to solve the problem.  Thank you~ @adarob @MichaelMa2014 @cghawthorne ,use code hope help solve problem thank,issue,positive,neutral,neutral,neutral,neutral,neutral
336328678,@Calvin-Shen Please use `sudo dmesg` to check why your OS killed your process.,please use check o process,issue,negative,neutral,neutral,neutral,neutral,neutral
336320908,"it still exists some proble when converting midi files to .tfrecord file. it seems having no memory problem ,but it still killed my progress with not converting complete files.  I don't know whtat causes this problem. @MichaelMa2014 @cghawthorne @adarob 
![wechatimg1901507856234_ pic](https://user-images.githubusercontent.com/23095057/31525684-b419ecee-aff4-11e7-912e-4d1e26eebd9c.jpg)
",still converting file memory problem still progress converting complete know problem pic,issue,negative,positive,neutral,neutral,positive,positive
335700032,It seems really solving the problem that memory can not be released in time when generating .tfrecord file from midi files. thanks a lot @MichaelMa2014 @cghawthorne ,really problem memory time generating file thanks lot,issue,negative,positive,positive,positive,positive,positive
335699291,"okay,thanks for your attention~
The training commands are like this:
melody_rnn_train --config=attention_rnn --run_dir=/home/kunsound/Desktop/run --sequence_example_file=/home/kunsound/Desktop/sequence-example/training_melodies.tfrecord --hparams=""batch_size=64,rnn_layer_sizes=[64,64]"" --num_training_steps=100000

And the save bundle file command is like this:
melody_rnn_generate --config=attention_rnn --run_dir=/home/kunsound/Desktop/run  --hparams=""batch_size=64,rnn_layer_sizes=[64,64]"" --bundle_file=/home/kunsound/Desktop/MyAttention.mag --save_generator_bundle",thanks training like save bundle file command like,issue,positive,positive,positive,positive,positive,positive
335537919,Can you include the commands you used to train and save the bundle file?,include used train save bundle file,issue,negative,neutral,neutral,neutral,neutral,neutral
335328242,The .mag file was trained by myself using the attention_rnn config at A computer.   Then I transfer the gernerated .mag file From A computer to B computer to gernerate midi file.  Facing the problem above.   @cghawthorne ,file trained computer transfer file computer computer file facing problem,issue,negative,neutral,neutral,neutral,neutral,neutral
335235650,Here's an example of loading a trained Performance RNN model in Javascript: https://magenta.tensorflow.org/performance-rnn-browser,example loading trained performance model,issue,negative,neutral,neutral,neutral,neutral,neutral
335102000,"I made some changes to the code handling the mutate.
It seems to solve the issue but it was done just by some trial and error.
Looks like there are some unwanted side effects as well. 
When running loop mode after a mutate, there is an additional delay
in the sequence for some unknown reason.
I hope someone with a better understanding of the code can improve that.

```
        if self._mutate.is_set():
          # new_start_time = response_start_time + response_duration
          new_start_time = tick_time
          new_end_time = new_start_time + response_duration
          response_sequence = self._generate(
              response_sequence,
              response_start_time,
              new_start_time,
              new_end_time)
          # If it took too long to generate, push response to next tick.
          if (time.time() - tick_time) >= tick_duration / 4:
            push_ticks = (
                (time.time() - tick_time) // tick_duration + 1)
            push_ticks = push_ticks
            # new_start_time += push_ticks * tick_duration
            response_sequence = adjust_sequence_times(
                response_sequence, push_ticks * tick_duration)
            tf.logging.warn(
                'Response too late. Pushing back %d ticks.', push_ticks)
          response_start_time = new_start_time
          self._mutate.clear()
```",made code handling mutate solve issue done trial error like unwanted side effect well running loop mode mutate additional delay sequence unknown reason hope someone better understanding code improve took long generate push response next tick late pushing back,issue,positive,positive,neutral,neutral,positive,positive
334014925,"This is probably because multiple TensorFlow instances can't use the same GPU at the same time. You could try disabling GPU usage on the second instance by setting the `CUDA_VISIBLE_DEVICES` environment variable before starting it.

```
CUDA_VISIBLE_DEVICES=-1
```",probably multiple ca use time could try usage second instance setting environment variable starting,issue,negative,neutral,neutral,neutral,neutral,neutral
332907658,"Where did generate.mag come from? Are you sure it came from an attention_rnn config? If it came from a different config, that would explain the error message.",come sure came came different would explain error message,issue,negative,positive,positive,positive,positive,positive
332902368,I think this is a problem with protobuf compiling on Windows (looks like they've had a problem similar to this at least once [before](https://github.com/google/protobuf/issues/87). I'd post this error message on their issue tracker and see if they know what's happening: https://github.com/google/protobuf/issues,think problem like problem similar least post error message issue tracker see know happening,issue,negative,negative,negative,negative,negative,negative
332799735,Any updates @xiesiyuan ? I'm getting a similar amount of distortion from training and transforming right out of the box.,getting similar amount distortion training transforming right box,issue,negative,positive,positive,positive,positive,positive
332746203,"Forgive me bad English~ :),  i faced your problem before,  the tutorial have writen how to generated trianing set and the evaluation set like that:""melody_rnn_create_dataset \
--config=<one of 'basic_rnn', 'lookback_rnn', or 'attention_rnn'> \
--input=/tmp/notesequences.tfrecord \
--output_dir=/tmp/melody_rnn/sequence_examples \
--eval_ratio=0.10""
focus on the last param  ""--eval_ration""  it means training set :  evaluation set = 9 : 1,so you should have 10 midi file in your floder at least.  this is my personal view.",forgive bad faced problem tutorial set evaluation set like one focus last param training set evaluation set file least personal view,issue,negative,negative,negative,negative,negative,negative
332681064,Found the solution internally. Thanks.,found solution internally thanks,issue,positive,positive,positive,positive,positive,positive
332305909,"Hmm, I'm not sure what would cause that other than a corrupt midi file. Can you try using the example midi file from the Magenta repo and see if that works? https://github.com/tensorflow/magenta/raw/master/magenta/testdata/example.mid",sure would cause corrupt file try example file magenta see work,issue,negative,neutral,neutral,neutral,neutral,neutral
332297506,Can you include the output of the commands you used to generate the datasets? They should include some debugging information about what was included and why. Exactly how the dataset is generated varies for each model.,include output used generate include information included exactly model,issue,negative,positive,positive,positive,positive,positive
332296830,"Hmm, I'm not really sure. You could try using a non-Ananconda Python build or maybe ask on the Anaconda issue tracker.",really sure could try python build maybe ask anaconda issue tracker,issue,negative,positive,positive,positive,positive,positive
332072723,"@cghawthorne Hi, I'm not able to remove mkl on Windows, since nomkl is not available on Windows. If I remove mkl completely, the error will ask for numpy to be installed. if I type `conda install numpy` mkl will be installed along with numpy.",hi able remove since available remove completely error ask type install along,issue,negative,positive,positive,positive,positive,positive
332055988,"Thank you for the review! It certainly easy to mistake point.
I added the comment to the each test method. And attached the notifications to each line that modified.

Are these enough or too much?",thank review certainly easy mistake point added comment test method attached line enough much,issue,positive,positive,positive,positive,positive,positive
332046158,"That appears to be an issue with the MKL library on Windows. I'm not familiar with exactly what the issue is, but you could try uninstalling MKL with the instructions here: https://docs.anaconda.com/mkl-optimizations/",issue library familiar exactly issue could try,issue,negative,positive,positive,positive,positive,positive
331943150,Thanks for the fix! Can you add some comments around the lines you changed explaining why they are necessary? I want to make sure we don't accidentally break it in the future if we forget why the change was made.,thanks fix add around explaining necessary want make sure accidentally break future forget change made,issue,negative,positive,positive,positive,positive,positive
331941918,"One other thing that may help with this is using the `magenta-gpu` pip package, which depends on `tensorflow-gpu`. The `magenta` package just depends on `tensorflow`, which is the CPU version.

After installing the GPU-enabled version of tensorflow, the CUDA_VISIBLE_DEVICES variable should work as expected.",one thing may help pip package magenta package version version variable work,issue,negative,neutral,neutral,neutral,neutral,neutral
331888891,"@mbs6176966 Hi, I've tried your suggestion, but now an error comes up:

![untitled](https://user-images.githubusercontent.com/31815007/30811990-4ce09f48-a23c-11e7-9518-c8b5fcb49807.png)

And the error code is:

`Intel MKL FATAL ERROR: Cannot load mkl_intel_thread.dll.`",hi tried suggestion error come untitled error code fatal error load,issue,negative,neutral,neutral,neutral,neutral,neutral
331839007,"@mbs6176966 that's exactly what I did what did I write make you assume otherwise?  First sentence was literally I made a dataset, which is a .tfrecord file.  training data is made from a dataset. a dataset is midi files turned into a stream of information the models like to eat.  I should have written ""training data for the different models"" in the second sentence but it was obvious what I was talking about because I refer to the training_melodies and evaluation files in that same sentence.  

So back to the original question :)",exactly write make assume otherwise first sentence literally made file training data made turned stream information like eat written training data different second sentence obvious talking refer evaluation sentence back original question,issue,positive,positive,positive,positive,positive,positive
331813686,"run the python file melody_rnn_generate.py  in melody_rnn attached the args  ""--config .....""",run python file attached,issue,negative,neutral,neutral,neutral,neutral,neutral
331812892,"ok~,have nerver encountered this problem! but  run the python file may help.     just like ""python /Users/calvin/Desktop/magenta-master/magenta/models/melody_rnn/melody_rnn_generate.py -config='basic_rnn' --bundle_file=/Users/calvin/Desktop/mag/basic_rnn.mag  --output_dir=/Users/calvin/Desktop/  --num_outputs=1 --num_steps=128 --primer_melody=""[60]"" """,nerver problem run python file may help like python,issue,negative,neutral,neutral,neutral,neutral,neutral
331810188,"@mbs6176966 Thanks for the guidance, but a new error comes up:

`'melody_rnn_generate' is not recognized as an internal or external command,
operable program or batch file.`

![capture](https://user-images.githubusercontent.com/31815007/30798824-7e49b850-a20d-11e7-9e74-794981bd6e68.PNG)
",thanks guidance new error come internal external command operable program batch capture,issue,negative,positive,neutral,neutral,positive,positive
331808008,"have you been in magenta environment? run the command like:""source activate magenta""  in your terminal. you should not run the python.",magenta environment run command like source activate magenta terminal run python,issue,negative,neutral,neutral,neutral,neutral,neutral
331806536,"any efficient solution for this proble? i have increased my RAM from 8G to 32G,but still haven't solve the problem of training big .tfrecord file.",efficient solution ram still solve problem training big file,issue,negative,neutral,neutral,neutral,neutral,neutral
331806307,"Hi, I tried typing them all in one line, but the same error still shows up...

![capture](https://user-images.githubusercontent.com/31815007/30798134-ff8d8e08-a20a-11e7-827d-9c9d4c74bb70.PNG)
",hi tried one line error still capture,issue,negative,neutral,neutral,neutral,neutral,neutral
331804971,"you should type all command in one line,don't copy and paste,try this way!!! not using ""\\""  ",type command one line copy paste try way,issue,negative,neutral,neutral,neutral,neutral,neutral
331790991,"it due  to all the memeory is occupied,any advice to solve this problem?thanks",due advice solve problem thanks,issue,negative,positive,neutral,neutral,positive,positive
331790367,"first you should read readme.md file seriously,  you should turn this midi file to .tfrecord file. and then generated notesequence from .tfrecord file. the notesequence  is the training set to build your model.",first read file seriously turn file file file training set build model,issue,negative,negative,neutral,neutral,negative,negative
331790236,"@mbs6176966 
I tried typing the whole thing out, but I still get an error...
![capture](https://user-images.githubusercontent.com/31815007/30795321-89e6b144-a1ff-11e7-820d-4d9d73d09801.PNG)
",tried whole thing still get error capture,issue,negative,positive,positive,positive,positive,positive
331787694,"have you install tensorflow-GPU,you can't install tensorflow-CPU，task will take precedence using tensorflow-CPU，so you should uninstall tensorflow-cpu first if you have both version.",install ca install take precedence first version,issue,negative,positive,positive,positive,positive,positive
331787137,"I encountered the same problem, with 8g RAM generated 2.9G size of .tfrecord file,instead of using 8G RAM by using 32G RAM generate only 4 G size of .tfrecord file。anyone  could tell me the efficient solution.",problem ram size file instead ram ram generate size could tell efficient solution,issue,negative,neutral,neutral,neutral,neutral,neutral
331762772,[`pipelines`](https://github.com/tensorflow/magenta/tree/master/magenta/pipelines) folder does not include the `__init__.py`. So it may affect to this problem.,folder include may affect problem,issue,negative,neutral,neutral,neutral,neutral,neutral
331684269,"I'm on Ubuntu, and I fixed a similar error with: `sudo apt install libjack-dev libasound-dev`. There is a note on the python-rtmidi page [about this requirement](https://python-rtmidi.readthedocs.io/en/latest/installation.html#linux).",fixed similar error apt install note page requirement,issue,negative,positive,positive,positive,positive,positive
331303469,"another thing is the loss numbers in tensorboard say one thing and in actual terminal, when you look at the numbers in the eval window, it ALWAYS shows perplexity = 0 loss = 0 accuracy = 0.  Every single time I've ever run it, it has showed 0 for everything in terminal.  In tensorboard the numbers are always numbers and not 0.  That's definitely some sort of bug!",another thing loss say one thing actual terminal look window always perplexity loss accuracy every single time ever run everything terminal always definitely sort bug,issue,negative,negative,neutral,neutral,negative,negative
331301136,"its at 1800 steps and loss is still at 5....I started up eval when I got up and it seems that eval is also going up.  Do I need to wait until 20,000 steps until I can judge it?  Is this now too big of a dataset?  Too large too small, what is just right?  I have literally no clue what to do next.



I think maybe its just the midi files and the model wants midi files formatted a certain way and if I prepare the midis the way it wants maybe it will perform properly.  That's the only thing I can think about, but there's no way of knowing because all I'm doing is running these terminal scripts, and not bringing me closer to any sort of understanding.  

Please help me I actually want to get into this stuff but it's almost impossible with the lack of information, lack of people discussing these common things in forums.  Even though I want to put all my time into learning this is it just too much?  Only for the people who already know what they're doing and I should just go away?  

",loss still got also going need wait judge big large small right literally clue next think maybe model certain way prepare way maybe perform properly thing think way knowing running terminal closer sort understanding please help actually want get stuff almost impossible lack information lack people common even though want put time learning much people already know go away,issue,negative,negative,neutral,neutral,negative,negative
331296274,"Another thing is how could I stop training early if eval goes up from the very beginning that would suggest the model is the most trained when it is at 0, which suggests the entire thing is a waste of time or broken?  I seriously will understand things if they make sense.",another thing could stop training early go beginning would suggest model trained entire thing waste time broken seriously understand make sense,issue,negative,negative,negative,negative,negative,negative
331295864,"I am training with a larger dataset (26mb of midi = 74mb notestream = 8gb performance_rnn training data)

I figured that would be a lot larger dataset because the last one was only 1 gb of performance_rnn training data.  

This time after 12 hours of training, the training set is still at loss 5.....basically the exact same spot it was at when it started.......

I have to be missing something here because I feel like I'm following all the instructions and all I get is problems and things breaking.  Every single time I've done this the loss has gone down, except for now.  



Not sure why you closed the issue, this is most definitely an open issue!!  Should I open a new one or is it possible to re open this?  I need help thanks.",training training data figured would lot last one training data time training training set still loss basically exact spot missing something feel like following get breaking every single time done loss gone except sure closed issue definitely open issue open new one possible open need help thanks,issue,positive,positive,neutral,neutral,positive,positive
331259947,"I haven't see that error before, but it looks like an issue with bazel on windows. I'd suggest reporting it on the Bazel project issue tracker: https://github.com/bazelbuild/bazel/issues",see error like issue suggest project issue tracker,issue,negative,neutral,neutral,neutral,neutral,neutral
331259096,"@ghostPath Yeah, after I uninstalled everything and reinstalled them numerous times haha.

Thanks!",yeah uninstalled everything numerous time thanks,issue,positive,positive,neutral,neutral,positive,positive
331244401,"This could happen if your model is overfitting to your training data, which can happen for a variety of reasons including a training set that is too small, a training set that is from a different distribution than the test set, or a model that is too powerful.

I'd suggest training a model with more data or possibly just stopping training early.",could happen model training data happen variety training set small training set different distribution test set model powerful suggest training model data possibly stopping training early,issue,negative,positive,neutral,neutral,positive,positive
331218759,"This seems reasonable to me. I know we've gotten a number of complaints about this script using up too much memory.

Another option would be to not let the queue of items to convert grow beyond a certain size. This would retain whatever benefits there are to multithreading without causing memory issues.

@adarob since you wrote the threaded version, what do you think?",reasonable know gotten number script much memory another option would let queue convert grow beyond certain size would retain whatever without causing memory since wrote threaded version think,issue,negative,positive,positive,positive,positive,positive
330161811,"now says   File ""demo.py"", line 16
    convert_midi_dir_to_note_sequences \
SyntaxError: can't assign to operator
",file line ca assign operator,issue,negative,neutral,neutral,neutral,neutral,neutral
329321739,Looks like there are still some lingering py3 issues. I'm going to submit this now and investigate those as a separate PR.,like still going submit investigate separate,issue,negative,neutral,neutral,neutral,neutral,neutral
329228923,"Yeah, getting SeqGAN in Magenta would be great!",yeah getting magenta would great,issue,positive,positive,positive,positive,positive,positive
329064607,"@cghawthorne SeqGAN has been used for the purposes of text generation here- https://github.com/codekansas/seqgan-text-tensorflow

Should we port this model so it works well with Magenta?",used text generation port model work well magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
328981676,"Not sure why the kokoro build failed, and re-adding the label doesn't seem to trigger it to run again, so I'm just going to bypass the check.",sure build label seem trigger run going bypass check,issue,negative,positive,positive,positive,positive,positive
328326053,"Same problem here! I'm using Windows 10, downloaded Python 3.6 Miniconda, and entered the following code:
`conda create -n magenta python=3 jupyter` followed by
`activate magenta`, since source does not work.

I then proceeded to enter: `pip install magenta`, and got the exact same error.",problem python following code create magenta activate magenta since source work enter pip install magenta got exact error,issue,negative,positive,positive,positive,positive,positive
328207461,Thanks for filing this issue. I have noticed this as well but I haven't had time to look into it. Hopefully I will be able to look into it soon unless someone else wants to figure it out first :),thanks filing issue well time look hopefully able look soon unless someone else figure first,issue,positive,positive,positive,positive,positive,positive
327947821,"I realize that the Python 3 support is actually really buggy right now, so I'll close this",realize python support actually really buggy right close,issue,negative,positive,positive,positive,positive,positive
327856111,"Try running `bazel shutdown` and trying again. If you ran bazel before switching to the magenta environment, it may have cached the wrong python path.",try running shutdown trying ran switching magenta environment may wrong python path,issue,negative,negative,negative,negative,negative,negative
327355879,"@cghawthorne  I have tried that script, and I use conda environment.
![0502664ca9b1979e44955c5408b51257](https://user-images.githubusercontent.com/5909556/30091629-2a1a08c2-92ed-11e7-97ad-c8fb9022081c.jpg)
![b1c5f509201c5c19e34e3092d6d6f2fd](https://user-images.githubusercontent.com/5909556/30091638-364cdbf6-92ed-11e7-8002-bc36ee5ba00a.jpg)

",tried script use environment,issue,negative,neutral,neutral,neutral,neutral,neutral
327263358,Can you provide some more details about the rest of your setup process? Were you using our automated install script or doing things manually? Did you use a conda environment?,provide rest setup process install script manually use environment,issue,negative,neutral,neutral,neutral,neutral,neutral
327242746,"Thanks for the interest, here's a short gist that I used to make the figures in the paper. https://gist.github.com/jesseengel/e223622e255bd5b8c9130407397a0494",thanks interest short gist used make paper,issue,positive,positive,neutral,neutral,positive,positive
327239853,"This seems reasonable to me, but I'd appreciate another review. @iansimon could you take a look?",reasonable appreciate another review could take look,issue,negative,positive,positive,positive,positive,positive
327171652,"I've added a 50gb swap file simply to see if it would solve the issue. I left it on overnight and woke up to see that the program was frozen, but not killed. I also don't think that using less data is the solution",added swap file simply see would solve issue left overnight woke see program frozen also think le data solution,issue,negative,neutral,neutral,neutral,neutral,neutral
326850724,"Send me your pip install magenta logs Maybe I can help

On Mon, Sep 4, 2017 at 4:05 AM, Dmytro Voloshyn <notifications@github.com>
wrote:

> @chestnut3108 <https://github.com/chestnut3108> what was the solution? I
> faced similar error
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/852#issuecomment-326835640>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AQCeUwHT2rkWtsAn61F78szoJ5OJd5H1ks5seymYgaJpZM4PDX9Z>
> .
>
",send pip install magenta maybe help mon wrote chestnut solution faced similar error reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
326835640,@chestnut3108 what was the solution? I faced similar error,chestnut solution faced similar error,issue,negative,neutral,neutral,neutral,neutral,neutral
326635311,"This looks fine for this commit. For a more intelligent approach to transposing, I would recommend the following logic:

- If transposition adds flats to the key signature, continue adding flats until no more flats can be added.
- If transposition adds sharps to the key signature, continue adding sharps until no more sharps can be added.

Examples:

- Key of C major, Trumpet in Bb. Transposing will move the trumpet to the key of D major, which adds two sharps.
- Key of F# major, Trumpet in Bb. Transposing will move the trumpet to the key of Ab major, because there is no key signature for G# major. I checked this logic using Sibelius, and it appears to be the same as the process I described.
",fine commit intelligent approach would recommend following logic transposition key signature continue added transposition sharp key signature continue sharp sharp added key major trumpet move trumpet key major two sharp key major trumpet move trumpet key major key signature major checked logic process,issue,positive,positive,neutral,neutral,positive,positive
325803676,@fredbertsch ping on this review please. The Kokoro error appears to be unrelated to this CL.,ping review please error unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
325747747,Thanks for looking into this. Would you be willing to submit a small PR with your fixes?,thanks looking would willing submit small,issue,negative,positive,neutral,neutral,positive,positive
325622263,"I fix the bug！
The audio samples are represented as floating point values in the range [-1,1].
Audio point values will be quantized to [0,256] using the mu_law method.
Howerve, the range of [0,255] is expected for tf.nn.sparse_softmax_cross_entropy_with_logits method.
Thus, scale the audio into [-1,1) will avoid the above bug.

```
def mu_law(x, mu=255, int8=False):
  """"""A TF implementation of Mu-Law encoding.

  Args:
    x: The audio samples to encode.
    mu: The Mu to use in our Mu-Law.
    int8: Use int8 encoding.

  Returns:
    out: The Mu-Law encoded int8 data.
  """"""
  out = tf.sign(x) * tf.log(1 + mu * tf.abs(x)) / np.log(1 + mu)
  out = tf.floor(out * 128)
  if int8:
    out = tf.cast(out, tf.int8)
  return out
```
",fix audio floating point range audio point method range method thus scale audio avoid bug implementation audio encode mu mu use use mu mu return,issue,negative,neutral,neutral,neutral,neutral,neutral
325578943,"I modifed the code and solve the problem(#loss value = #global step). However, I got a nan loss after few steps of trainning with the default parameters.
```
train_op = slim.learning.create_train_op(total_loss = total_loss,
optimizer = opt,
global_step = global_step,
colocate_gradients_with_ops=True)
```",code solve problem loss value global step however got nan loss default opt,issue,negative,neutral,neutral,neutral,neutral,neutral
325083010,"Doesn't [this test](https://github.com/tensorflow/magenta/blob/93f7c72092b3f1532485a7cb1709caca2136b35e/magenta/music/musicxml_parser_test.py#L306) cover this scenario, or is there a new case that needs to be handled? 

The test takes a Clarinet in Bb scale as input and makes sure it is transposed properly to sounding pitch. Look at the [transpose tag](https://github.com/tensorflow/magenta/blob/93f7c72092b3f1532485a7cb1709caca2136b35e/magenta/music/testdata/clarinet_scale.xml#L121) in the test file. Notice that the first pitch in the MusicXML file is G4, but the test compares this to F4 (the sounding pitch), which passes. Specifically, the test compares the flute and clarinet scale files and makes sure they are equal. Their sounding pitches are equal, but the written pitches are different.

The `el_capitan.xml` file is a conductor's score, and contains several transposing instruments of different transposition levels (Bb Clarinet, Eb Alto Sax, Horn in F), as well as a key change. If a use case isn't covered, it can probably be written against this file.

Note that if the `<transpose>` tag is missing or only includes a `<diatonic>` element, then the code will not perform transposition. According to the [MusicXML schema](http://usermanuals.musicxml.com/MusicXML/MusicXML.htm#CT-MusicXML-transpose.htm#kanchor3032), `<chromatic>` is required; `<diatonic>` is optional.",test cover scenario new case need handled test clarinet scale input sure properly sounding pitch look transpose tag test file notice first pitch file test sounding pitch specifically test flute clarinet scale sure equal sounding equal written different file conductor score several different transposition clarinet alto sax horn well key change use case covered probably written file note transpose tag missing diatonic element code perform transposition according schema chromatic diatonic optional,issue,positive,positive,neutral,neutral,positive,positive
325081742,"@jsawruk if you have time, would appreciate your input on this one too.",time would appreciate input one,issue,negative,neutral,neutral,neutral,neutral,neutral
325024214,This blog article: https://magenta.tensorflow.org/nsynth-fastgen and associated notebook show how you can do that: https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/NSynth.ipynb,article associated notebook show,issue,negative,neutral,neutral,neutral,neutral,neutral
324226237,"Thanks! it works!
upgrading magenta works for me",thanks work magenta work,issue,negative,positive,positive,positive,positive,positive
324135332,I think this is because the previous version of the pip package didn't include the density options for performance rnn. We just released a new package yesterday. Can you try upgrading and see if it works?,think previous version pip package include density performance new package yesterday try see work,issue,negative,negative,neutral,neutral,negative,negative
324091431,"Thanks to @umbanhowar, the majority of our code base is now Python 3 compatible! Closing this bug now, and we can track any remaining incompatibilities with separate bugs. ",thanks majority code base python compatible bug track separate,issue,negative,negative,negative,negative,negative,negative
324087169,"Yeah, sorry about the log visibility thing. It's something we're working on fixing. I think the py3 presubmit failed due to a kokoro server restart. I re-added the label to see if that will reschedule it. If not, we can just override that check and submit anyway, after @jesseengel approves the PR.",yeah sorry log visibility thing something working fixing think presubmit due server restart label see reschedule override check submit anyway,issue,negative,negative,negative,negative,negative,negative
324076599,Looks like a relatively easy fix: https://stackoverflow.com/questions/436198/what-is-an-alternative-to-execfile-in-python-3,like relatively easy fix,issue,positive,positive,positive,positive,positive,positive
323750498,"Looks like you need to install the development files for JACK.

If you're using Ubuntu this can be done via `sudo apt-get install libjack-dev`.",like need install development jack done via install,issue,negative,neutral,neutral,neutral,neutral,neutral
323507957,"I think you have a space after you equals sign. It should work if you get rid of the whitespaces.

`--source_path= /Users/tatecarson/Desktop/Kea \`
-->
`--source_path=/Users/tatecarson/Desktop/Kea \`
",think space sign work get rid,issue,negative,neutral,neutral,neutral,neutral,neutral
323498576,"```
(magenta) tate-2:~ tatecarson$ nsynth_generate \
> --checkpoint_path= /Users/tatecarson/Documents/tensorflow/magenta/pre-trained/wavenet-ckpt/model.ckpt-200000.data-00000-of-00001 \
> --source_path= /Users/tatecarson/Desktop/Kea \
> --save_path= /private/tmp/nsynth  \
> --batch_size=4
source path is /Users/tatecarson
Traceback (most recent call last):
  File ""/Users/tatecarson/miniconda2/envs/magenta/bin/nsynth_generate"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Users/tatecarson/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/nsynth_generate.py"", line 92, in console_entry_point
    tf.app.run(main)
  File ""/Users/tatecarson/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/Users/tatecarson/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/nsynth_generate.py"", line 60, in main
    raise RuntimeError(""Folder must contain .wav or .npy files."")
RuntimeError: Folder must contain .wav or .npy files.
(magenta) tate-2:~ tatecarson$ 
```

See `source path is /Users/tatecarson` . Why does that not = `--source_path= /Users/tatecarson/Desktop/Kea` ? ",magenta source path recent call last file line module file line main file line run main file line main raise folder must contain folder must contain magenta see source path,issue,negative,positive,neutral,neutral,positive,positive
323482303,"That's odd, these are the relevant lines of code from nsynth_generate.py. It explicitly is looking for files ending in "".wav"" so you can make sure that's the case. you could also try throwing in a print statement to see if it's picking up the files properly.

```python
    files = tf.gfile.ListDirectory(source_path)
    exts = [os.path.splitext(f)[1] for f in files]
    if "".wav"" in exts:
      postfix = "".wav""
    elif "".npy"" in exts:
      postfix = "".npy""
    else:
      raise RuntimeError(""Folder must contain .wav or .npy files."")
```",odd relevant code explicitly looking ending make sure case could also try throwing print statement see properly python postfix postfix else raise folder must contain,issue,negative,positive,positive,positive,positive,positive
321680477,"You should be able to use this script to extract a checkpoint from one of our bundle files: https://github.com/tensorflow/magenta/blob/master/magenta/scripts/unpack_bundle.py

And then run performance_rnn_train pointing --run_dir at wherever the extracted checkpoint lives.",able use script extract one bundle run pointing wherever extracted,issue,negative,positive,positive,positive,positive,positive
321678625,"If you're using the pip package, you should just run the performance_rnn_create_dataset in your bin/ directory.  The source repository has some functionality not yet included in the pip package.",pip package run directory source repository functionality yet included pip package,issue,negative,neutral,neutral,neutral,neutral,neutral
320537368,Version 4.0 of music21 which can be used for Magenta MusicXML parsing was released today and it is the last version to support Python 2.  The master branch of music21 is now Python 3 only.  I'd very much like to keep up connecting Magenta and music21!,version music used magenta today last version support python master branch music python much like keep magenta music,issue,positive,positive,neutral,neutral,positive,positive
320467385,"I'm having a similar problem with the Mac installer (from running `bash /tmp/magenta-install.sh`) which also failed due to a problem with python-rtmidi installation.  

I'll try the docker installation instead.",similar problem mac installer running bash also due problem installation try docker installation instead,issue,negative,negative,neutral,neutral,negative,negative
320062580,I fixed a bad email address in my .gitconfig.  You can ignore the CLA message. ,fixed bad address ignore message,issue,negative,negative,negative,negative,negative,negative
319307642,"Thank you so much! @cghawthorne 
I made it by installing the magenta pip package ~",thank much made magenta pip package,issue,negative,positive,positive,positive,positive,positive
319295585,Ok sure.. We're making an attempt. Will share if we get some good results.,sure making attempt share get good,issue,positive,positive,positive,positive,positive,positive
319190424,It looks like there's a previous checkpoint in your run_dir that is from a model created with different hparams. I'd try deleting any previous checkpoints in that directory and starting training again.,like previous model different try previous directory starting training,issue,negative,negative,neutral,neutral,negative,negative
319188999,"@QianhuiWu, to import sketch_rnn_train, you'll either need to install the magenta pip package and import it as a system library, or you'll need to use our [development environment](https://github.com/tensorflow/magenta#development-environment) and set up a new target for your test.py in the `BUILD` file and build it with [bazel](https://bazel.build/).",import either need install magenta pip package import system library need use development environment set new target build file build,issue,negative,positive,positive,positive,positive,positive
318941844,"The loss function for the decoder is somewhat non standard, so you may encounter some challenges if you want to implement in a high level framework such as Keras, but I think it should be possible.

If you manage to write the model in Keras in the future, please let us know so we can refer your implementation to Keras users or other interested parties.",loss function somewhat non standard may encounter want implement high level framework think possible manage write model future please let u know refer implementation interested,issue,negative,positive,neutral,neutral,positive,positive
318914897,"You should be able to see some results (i.e. it should draw something that look like crabs if you trained on crab.npz), after 10-20K steps. We set the default number of steps close to infinity to allow us to control manually when we want to stop training, by looking at the TensorBoard graphs and the various reported losses. In practice once the validation loss curves stop decreasing we stop the training.

The convergence depends on the data, and also the regularization scheme used, and size of the network, so can vary between 50K-500K steps even.",able see draw something look like trained set default number close infinity allow u control manually want stop training looking various practice validation loss stop decreasing stop training convergence data also regularization scheme used size network vary even,issue,negative,positive,positive,positive,positive,positive
318913360,"Hi @alexis-jacq @hardmaru 
Thanks for the tips @hardmaru. We're trying out something similar- creating similar model using keras. How many epochs did you end up training upto? Because the default number of steps 1e7 seems abnormally high. Also, at what number of steps does total convergence start?",hi thanks trying something similar model many end training default number abnormally high also number total convergence start,issue,positive,positive,positive,positive,positive,positive
318451057,"Oh, I mention this in my demos post but forgot to do so here, on the ai jam ableton page, the link for the for the simplified js version is pointing to the wrong place. 
I believe it should be 
https://github.com/tensorflow/magenta-demos/tree/master/ai-jam-js 
instead of
https://github.com/tensorflow/magenta-demos/blob/master/demos/ai-jam-js",oh mention demo post forgot ai jam page link simplified version pointing wrong place believe instead,issue,negative,negative,negative,negative,negative,negative
318450661,"It's all good! I should have posted to the main directory in the first place, but I was really inspired by the ai jam demo. 
I'll give that a crack and get back to you. 
I'll go ahead and close this for the moment. I'll reopen if I fall completely off the rails. 
Thanks!",good posted main directory first place really inspired ai jam give crack get back go ahead close moment reopen fall completely thanks,issue,positive,positive,positive,positive,positive,positive
318442013,"Hi, and apologies for missing your message over on magenta-demos.
It would be great to have something like this in the AI jam demo, but it
currently doesn't support this.

For now, the easiest way to do it would be to use the drums_rnn
command-line generation script.

You can use a command similar to the one found here:
https://github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn#generate-a-drum-track

You would replace the `--primer_drums` flag with the `--primer_midi` flag,
passing it the path to your MIDI file.

Let us know if you have any more questions!

On Thu, Jul 27, 2017 at 11:01 AM, HandsomeDevilv112 <
notifications@github.com> wrote:

> So, one of the demos described in the Magenta documentation is an
> ""Interactive Musical Improvisation with Magenta"" (https://github.com/
> tensorflow/magenta-demos/tree/master/ai-jam-ableton /)
>
> If it works the way I think it does, it receives midi input from a
> keyboard, and then can output a drum beat to match your input. Would/could
> you be able to generate a midi through use of magenta/models/melody_rnn/,(skipping
> the keyboard entirely) and then use the ai jam to create a drum track/beat
> based on that input?
>
> Or can this be done with the drums_rnn model?
>
> My apologies if I missed something in documentation
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/800>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6Ai4VmDijZwSteONLf9gHngRJ6Giks5sSNB6gaJpZM4Oloqf>
> .
>
",hi missing message would great something like ai jam currently support easiest way would use generation script use command similar one found would replace flag flag passing path file let u know wrote one demo magenta documentation interactive musical improvisation magenta work way think input keyboard output drum beat match input able generate use skipping keyboard entirely use ai jam create drum based input done model something documentation thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
318148672,"Also, something in ‘magenta’ wanted me to revert from numpy 0.20.3 to umpy 0.19.2

Error: 

File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/dask/dataframe/core.py"", line 38, in <module>
    pd.computation.expressions.set_use_numexpr(False)
AttributeError: 'module' object has no attribute 'computation'

In [2]: print pandas.__version__
0.20.3

In [3]: quit
David-Laxers-MacBook-Pro:magenta davidlaxer$ conda install pandas=0.19.2

> On Jul 26, 2017, at 9:23 AM, David Laxer <davidl@softintel.com> wrote:
> 
> Python indicates the bazel command is an ‘ordinary string’.
> 
> $ bazel run //magenta/models/melody_rnn:melody_rnn_train -- --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=/Users/davidlaxer/magenta/magenta/testdata/notesequences.tfrecord --hparams=""batch_size=10,rnn_layer_sizes=[64,64]"" **--save_summaries_secs=10000 --save_interval_secs=10000** --num_training_steps=20000
> 
> Open a new issue?
> 
> <Screen Shot 2017-07-26 at 9.22.49 AM.png>
>> On Jul 25, 2017, at 5:24 PM, cghawthorne <notifications@github.com <mailto:notifications@github.com>> wrote:
>> 
>> @dbl001 <https://github.com/dbl001> that looks like a different error caused by copy/pasting unicode characters into your command. If you continue to have the problem, please open a new bug.
>> 
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/83#issuecomment-317911015>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i28Vih4QzyyHt7PMkP3B4m4iCmkMNks5sRodIgaJpZM4JFpzp>.
>> 
> 

",also something magenta revert error file line module false object attribute print quit magenta install wrote python command ordinary string run open new issue screen shot wrote like different error command continue problem please open new bug reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
318106700,"Python indicates the bazel command is an ‘ordinary string’.

$ bazel run //magenta/models/melody_rnn:melody_rnn_train -- --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=/Users/davidlaxer/magenta/magenta/testdata/notesequences.tfrecord --hparams=""batch_size=10,rnn_layer_sizes=[64,64]"" **--save_summaries_secs=10000 --save_interval_secs=10000** --num_training_steps=20000

Open a new issue?


> On Jul 25, 2017, at 5:24 PM, cghawthorne <notifications@github.com> wrote:
> 
> @dbl001 <https://github.com/dbl001> that looks like a different error caused by copy/pasting unicode characters into your command. If you continue to have the problem, please open a new bug.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/83#issuecomment-317911015>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i28Vih4QzyyHt7PMkP3B4m4iCmkMNks5sRodIgaJpZM4JFpzp>.
> 

",python command ordinary string run open new issue wrote like different error command continue problem please open new bug reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
317911015,"@dbl001 that looks like a different error caused by copy/pasting unicode characters into your command. If you continue to have the problem, please open a new bug.",like different error command continue problem please open new bug,issue,negative,positive,neutral,neutral,positive,positive
317900755,"I think you're trying to run the wrong target. Instead of `//magenta:convert_midi_dir_to_note_sequences`, use `//magenta/scripts:convert_dir_to_note_sequences`.",think trying run wrong target instead use,issue,negative,negative,negative,negative,negative,negative
317892060,"I encountered similar issue. The command line I used was:

> bazel run //magenta/models/nsynth/wavenet:train -- --train_path=/ml/data/nsynth/tfrecord/nsynth-train.tfrecord --logdir=/ml/tensorflow/magenta/log

The commit number is https://github.com/tensorflow/magenta/commit/935438f18f020b31e6438889dbcfbd922595e9f7.

The train_path file was downloaded from http://download.magenta.tensorflow.org/datasets/nsynth/nsynth-train.tfrecord.

I am using ubuntu 14.04, with a python 2.7.6 virtual environment and the following packages:

    audioread==2.1.5
    backports.weakref==1.0rc1
    bleach==1.5.0
    Cython==0.26
    decorator==4.1.2
    funcsigs==1.0.2
    html5lib==0.9999999
    joblib==0.11
    librosa==0.5.1
    Markdown==2.2.0
    mock==2.0.0
    numpy==1.13.1
    pbr==3.1.1
    protobuf==3.3.0
    resampy==0.1.5
    scikit-learn==0.18.2
    scipy==0.19.1
    six==1.10.0
    tensorflow==1.2.1
    tensorflow-tensorboard==0.1.2
    Werkzeug==0.12.2

I compiled my tensorflow package with CUDA 8.0 and CUDNN 6.0. My GPU is TITAN X (Pascal).",similar issue command line used run train commit number file python virtual environment following package,issue,negative,neutral,neutral,neutral,neutral,neutral
317209593,I have this exact same problem. I'd love to see a workaround soon!,exact problem love see soon,issue,negative,positive,positive,positive,positive,positive
317097131,The small number of data works fine!,small number data work fine,issue,negative,positive,neutral,neutral,positive,positive
317021317,"According to your method has solved the problem,thanks!",according method problem thanks,issue,negative,positive,positive,positive,positive,positive
317018173,"Update: I didn't touch anything, but it seems to have ""decided"" to start working... now it's using gpus. However, it would be helpful if I could specify which one(s) to use in the configuration without modifying magenta source or exporting CUDA_VISIBLE_DEVICES. Does anyone know if this is possible?",update touch anything decided start working however would helpful could specify one use configuration without magenta source anyone know possible,issue,negative,neutral,neutral,neutral,neutral,neutral
317008398,"Looks like you're missing dependencies for python_rtmidi

Make sure you have the dependencies installed
Linux: ALSA, JACK
OS X: CoreMIDI, JACK
Windows: MultiMedia (MM)

This link has the name of the packages that you can download -
http://python-rtmidi.readthedocs.io/en/latest/installation.html

The commands you'll most likely need to use as stated above are:
sudo apt-get install libasound-dev
sudo apt-get install libjack-dev",like missing make sure jack o jack link name likely need use stated install install,issue,negative,positive,neutral,neutral,positive,positive
316910548,"Is this the same issue?
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe0 in position 132: invalid continuation byte

```
$ bazel run //magenta/models/melody_rnn:melody_rnn_train -- --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=/Users/davidlaxer/magenta/magenta/testdata/notesequences.tfrecord --hparams=""batch_size=10,rnn_layer_sizes=[64,64]"" **--save_summaries_secs=10000 --save_interval_secs=10000** --num_training_steps=20000 
Killed non-responsive server process (pid=65119)
.
INFO: Found 1 target...
Target //magenta/models/melody_rnn:melody_rnn_train up-to-date:
  bazel-bin/magenta/models/melody_rnn/melody_rnn_train
INFO: Elapsed time: 9.400s, Critical Path: 0.65s

INFO: Running command line: bazel-bin/magenta/models/melody_rnn/melody_rnn_train '--config=attention_rnn' '--run_dir=/tmp/melody_rnn/logdir/run1' '--sequence_example_file=/Users/davidlaxer/magenta/magenta/testdata/notesequences.tfrecord' '--hparams=batch_size=10,rnn_layer_sizes=[64,64]' '**--save_summaries_secs=10000' '--save_interval_secs=10000**' '--num_training_steps=20000'
INFO:tensorflow:hparams = {'rnn_layer_sizes': [64, 64], 'attn_length': 40, 'dropout_keep_prob': 0.5, 'batch_size': 10, 'clip_norm': 3, 'learning_rate': 0.001}
INFO:tensorflow:Counting records in /Users/davidlaxer/magenta/magenta/testdata/notesequences.tfrecord.
INFO:tensorflow:Total records: 46
INFO:tensorflow:[<tf.Tensor 'random_shuffle_queue_Dequeue:0' shape=(?, 74) dtype=float32>, <tf.Tensor 'random_shuffle_queue_Dequeue:1' shape=(?,) dtype=int64>, <tf.Tensor 'random_shuffle_queue_Dequeue:2' shape=() dtype=int32>]
INFO:tensorflow:Train dir: /tmp/melody_rnn/logdir/run1/train
INFO:tensorflow:Starting training loop...
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Error reported to Coordinator: <type 'exceptions.UnicodeDecodeError'>, 'utf8' codec can't decode byte 0xe0 in position 132: invalid continuation byte
INFO:tensorflow:Saving checkpoints for 0 into /tmp/melody_rnn/logdir/run1/train/model.ckpt.
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 112, in <module>
    console_entry_point()
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 108, in console_entry_point
    tf.app.run(main)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 104, in main
    checkpoints_to_keep=FLAGS.num_checkpoints)
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/shared/events_rnn_train.py"", line 71, in run_training
    save_summaries_steps=summary_frequency)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/training.py"", line 530, in train
    loss = session.run(train_op)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 521, in __exit__
    self._close_internal(exception_type)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 556, in _close_internal
    self._sess.close()
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 791, in close
    self._sess.close()
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 888, in close
    ignore_live_threads=True)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 238, in _run
    enqueue_callable()
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1063, in _single_operation_run
    target_list_as_strings, status, None)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 465, in raise_exception_on_not_ok_status
    compat.as_text(pywrap_tensorflow.TF_Message(status)),
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/util/compat.py"", line 84, in as_text
    return bytes_or_text.decode(encoding)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe0 in position 132: invalid continuation byte
ERROR: Non-zero return code '1' from command: Process exited with status 1.
```",issue ca decode position invalid continuation run server process found target target time critical path running command line counting total train starting training loop create error type ca decode position invalid continuation saving recent call last file line module file line main file line run main file line main file line file line train loss file line file line file line close file line close file line join file line file line status none file line file line status file line return file line decode return input true ca decode position invalid continuation error return code command process status,issue,negative,positive,neutral,neutral,positive,positive
316704245,"Thanks for the help! I was missing the ALSA library. 

Here's the commands on CentOS:
`sudo yum install alsa-lib-devel alsa-utils`",thanks help missing library install,issue,positive,neutral,neutral,neutral,neutral,neutral
316628107,"Make sure you have the dependencies installed 
Linux: ALSA, JACK
OS X: CoreMIDI, JACK
Windows: MultiMedia (MM)

This link has the name of the packages that you can download  - 
http://python-rtmidi.readthedocs.io/en/latest/installation.html

The commands you'll most likely need to use as stated above are:
```sudo apt-get install libasound-dev```
```sudo apt-get install libjack-dev```",make sure jack o jack link name likely need use stated install install,issue,negative,positive,positive,positive,positive,positive
316531447,"Perhaps melody_rnn:melody_rnn_generate is looking for an existing trained model.
I tried this:
$ bazel run //magenta/models/melody_rnn:melody_rnn_train -- --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=./magenta/testdata/notesequences.tfrecord --hparams=""batch_size=64,rnn_layer_sizes=[64,64]"" --num_training_steps=20000 --eval
INFO: Found 1 target...
Target //magenta/models/melody_rnn:melody_rnn_train up-to-date:
  bazel-bin/magenta/models/melody_rnn/melody_rnn_train
INFO: Elapsed time: 0.398s, Critical Path: 0.00s

INFO: Running command line: bazel-bin/magenta/models/melody_rnn/melody_rnn_train '--config=attention_rnn' '--run_dir=/tmp/melody_rnn/logdir/run1' '--sequence_example_file=./magenta/testdata/notesequences.tfrecord' '--hparams=batch_size=64,rnn_layer_sizes=[64,64]' '--num_training_steps=20000' --eval
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 112, in <module>
    console_entry_point()
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 108, in console_entry_point
    tf.app.run(main)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_train.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_train.py"", line 76, in main
    os.path.expanduser(FLAGS.sequence_example_file))
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 334, in get_matching_files
    compat.as_bytes(single_filename), status)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: ./magenta/testdata
ERROR: Non-zero return code '1' from command: Process exited with status 1",perhaps looking trained model tried run found target target time critical path running command line recent call last file line module file line main file line run main file line main file line status file line file line status error return code command process status,issue,negative,positive,neutral,neutral,positive,positive
316449955,"No news right now, but this is something that we definitely want to move forward on, especially since IPython now supports only Python 3.",news right something definitely want move forward especially since python,issue,negative,positive,neutral,neutral,positive,positive
316447209,"Yeah, we should probably add that. It hasn't been a problem because we depend on tensorflow, which depends on numpy, but we should list our dependency explicitly.",yeah probably add problem depend list dependency explicitly,issue,negative,neutral,neutral,neutral,neutral,neutral
315943141,"I think you need to install the ALSA library development files first. In Debian / Ubuntu you could fix it with:
```
sudo apt-get install libasound2-dev
```
But you'll need to find the equivalent command for the CentOS package manager.",think need install library development first could fix install need find equivalent command package manager,issue,negative,positive,positive,positive,positive,positive
315815988,"Indeed, I was pointing to the directory that contains the models, not to the specific .mag file.
Thank you!",indeed pointing directory specific file thank,issue,negative,neutral,neutral,neutral,neutral,neutral
315808290,Does converting a fewer number of files help? Can you increase the amount of RAM on the machine you're using?,converting number help increase amount ram machine,issue,positive,neutral,neutral,neutral,neutral,neutral
315807732,"It looks like you might not be setting BUNDLE_PATH to point to the bundle
file you want to use. If you think you have set it, you can try typing the
command 'echo $BUNDLE_FILE' and see if it prints out the correct path.

-Adam

On Sat, Jul 15, 2017 at 7:48 AM, David Martínez de Lecea <
notifications@github.com> wrote:

> I am getting a tensorflow.python.framework.errors_impl.FailedPreconditionError
> error whenever I try to generate a melody following the tutorial. The same
> thing happens regardless of which of the three pre-trained models.
> Anybody can give me a hint of where the problem might be, please?
> melody_rnn_generate \
>
> --config=${CONFIG}
> --bundle_file=${BUNDLE_PATH}
> --output_dir=/tmp/melody_rnn/generated
> --num_outputs=10
> --num_steps=128
> --primer_melody=""[60]""
> Traceback (most recent call last):
> File ""/usr/local/bin/melody_rnn_generate"", line 11, in
> sys.exit(console_entry_point())
> File ""/usr/local/lib/python2.7/dist-packages/magenta/models/
> melody_rnn/melody_rnn_generate.py"", line 250, in console_entry_point
> tf.app.run(main)
> File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"",
> line 48, in run
> _sys.exit(main(_sys.argv[:1] + flags_passthrough))
> File ""/usr/local/lib/python2.7/dist-packages/magenta/models/
> melody_rnn/melody_rnn_generate.py"", line 223, in main
> bundle = get_bundle()
> File ""/usr/local/lib/python2.7/dist-packages/magenta/models/
> melody_rnn/melody_rnn_generate.py"", line 127, in get_bundle
> return magenta.music.read_bundle_file(bundle_file)
> File ""/usr/local/lib/python2.7/dist-packages/magenta/music/sequence_generator_bundle.py"",
> line 34, in read_bundle_file
> bundle.ParseFromString(f.read())
> File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"",
> line 125, in read
> pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
> File ""/usr/lib/python2.7/contextlib.py"", line 24, in *exit*
> self.gen.next()
> File ""/usr/local/lib/python2.7/dist-packages/tensorflow/
> python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_
> status
> pywrap_tensorflow.TF_GetCode(status))
> tensorflow.python.framework.errors_impl.FailedPreconditionError:
> /home/ubuntu/workspace/magenta/magenta-models
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/778>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6NcbSakzd0H1LNL_0g2XmL1dQTvZks5sONEpgaJpZM4OZCNW>
> .
>
",like might setting point bundle file want use think set try command see correct path sat de wrote getting error whenever try generate melody following tutorial thing regardless three anybody give hint problem might please recent call last file line file line main file line run main file line main bundle file line return file line file line read length status file line exit file line status status thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
315805891,"Because this is a build failure with protobuf, I'm going to close this issue so it can be tracked in https://github.com/google/protobuf/issues/3373",build failure going close issue tracked,issue,negative,negative,negative,negative,negative,negative
315801426,"Unfortunately, bazel does not have an install command: https://docs.bazel.build/versions/master/bazel-user-manual.html

The closest thing would probably be to use our [build script](https://github.com/tensorflow/magenta/blob/master/magenta/tools/build.sh).",unfortunately install command thing would probably use build script,issue,negative,negative,negative,negative,negative,negative
315570418,"I also see the same issue in my macOS.

After running `bazel test //magenta/... --test_verbose_timeout_warnings`, I get this terminal [dump](https://gist.github.com/wayne-chen/c508cbaa8dbb08f6b48e077c5bd9a1c4#DUMP) with its associated [test.log](https://gist.github.com/wayne-chen/c508cbaa8dbb08f6b48e077c5bd9a1c4#file-test-log) file.

I'm running macOS 10.12.6 with bazel 0.5.2.",also see issue running test get terminal dump associated file running,issue,negative,neutral,neutral,neutral,neutral,neutral
315437484,"No it does not.
It just output which file it converted!
`INFO:tensorflow:Converted MIDI file lmd_full/0/00032fb2047d3cdd0394b89349d858b4.mid.`",output file converted converted file,issue,negative,neutral,neutral,neutral,neutral,neutral
315407501,"Hmm, the default setup for convert_dir_to_note_sequences shouldn't use too much memory (I would expect usage to increase if you used `--num_threads=4`, for example). Does the script produce any other output before getting killed? What happens if you try to convert a smaller number of midis?",default setup use much memory would expect usage increase used example script produce output getting try convert smaller number,issue,negative,positive,neutral,neutral,positive,positive
315191222,This is likely caused by having an out of date version of TensorFlow. Can you check that you have the latest TensorFlow package installed and try again?,likely date version check latest package try,issue,negative,positive,positive,positive,positive,positive
315178678,"We don't currently have a pre-built Magenta image with gpu support. However, it should be fairly easy to build one. Just modify the [Dockerfile](https://github.com/tensorflow/magenta/blob/master/magenta/tools/docker/Dockerfile) to depend on `tensorflow/tensorflow:N.N.N-devel-gpu` instead of the version without `-gpu`, and that should work.",currently magenta image support however fairly easy build one modify depend instead version without work,issue,positive,positive,positive,positive,positive,positive
314449107,"It's a little bit awkward right now, but you have to pass a `Performance` object (not a list) to `performance_log_likelihood`.  And there's no easy way to create one from a list of events, you'll need to create an empty `Performance` and then append each event in turn.",little bit awkward right pas performance object list easy way create one list need create empty performance append event turn,issue,positive,negative,neutral,neutral,negative,negative
314308947,"@adarob That seems to have indeed been the case! Thank you very much. I realize I was getting the AI Duet site in the browser as well. 

Now, after a reboot, I am getting the AI Jam site and all seems to be functional. I don't know what caused the issue (perhaps because I was playing with the AI Duet demo just before?) and can't reproduce it, so I will close it.",indeed case thank much realize getting ai duet site browser well getting ai jam site functional know issue perhaps ai duet ca reproduce close,issue,positive,positive,positive,positive,positive,positive
314180763,"Hi, it looks like you might be serving the AI Duet site somehow? That POST
request (""POST /predict?duration=3.320453514739228 HTTP/1.1"" 405"") would
only come from ai-duet not ai-jam.

On Sun, Jul 9, 2017 at 4:12 PM, achimkoh <notifications@github.com> wrote:

> ai-jam-js: https://github.com/tensorflow/magenta/tree/master/demos/ai-
> jam-js
>
> Also, it doesn't return any generated notes, nor the keyboard shortcuts
> seem to work. Any suggestions are appreciated.
>
> OS: macOS Sierra 10.12.4
> Flask (0.12.2)
> magenta (0.2.4)
>
> I installed Magenta using the following command (as per the readme) in
> conda 4.3.21:
>
> curl https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/tools/magenta-install.sh > /tmp/magenta-install.sh
> bash /tmp/magenta-install.sh
>
> The demo script output:
>
> $ source activate magenta
> (magenta) $ sh RUN_DEMO.sh
> File http://download.magenta.tensorflow.org/models/attention_rnn.mag already present
> File http://download.magenta.tensorflow.org/models/performance.mag already present
> File http://download.magenta.tensorflow.org/models/pianoroll_rnn_nade.mag already present
> File http://download.magenta.tensorflow.org/models/drum_kit_rnn.mag already present
>  * Running on http://127.0.0.1:8080/ (Press CTRL+C to quit)
> WARNING:tensorflow:No input port specified. Capture disabled.
> INFO:tensorflow:Opening 'magenta_clock' as a virtual MIDI port for output.
> INFO:tensorflow:Restoring parameters from /var/folders/7f/643bllcn4pn1g_wf1fnkmwd80000gn/T/tmpOfwkH0/model.ckpt
> INFO:tensorflow:Restoring parameters from /var/folders/7f/643bllcn4pn1g_wf1fnkmwd80000gn/T/tmpWo89rQ/model.ckpt
> Loaded 'attention_rnn' generator bundle from file './attention_rnn.mag'.
> Loaded 'drum_kit' generator bundle from file './drum_kit_rnn.mag'.
> INFO:tensorflow:Opening 'magenta_drums_in' as a virtual MIDI port for input.
> INFO:tensorflow:Opening 'magenta_out' as a virtual MIDI port for output.
>
> Instructions:
> Start playing  when you want to begin the call phrase.
> When you want to end the call phrase, stop playing and wait one clock tick.
> Once the response completes, the interface will wait for you to begin playing again to start a new call phrase.
>
> To end the interaction, press CTRL-C.
> INFO:tensorflow:State: Idle
> INFO:tensorflow:State: Idle
> INFO:tensorflow:State: Idle
> INFO:tensorflow:Restoring parameters from /var/folders/7f/643bllcn4pn1g_wf1fnkmwd80000gn/T/tmpK6LEqi/model.ckpt
> INFO:tensorflow:State: Idle
> Loaded 'rnn-nade_attn' generator bundle from file './pianoroll_rnn_nade.mag'.
> INFO:tensorflow:State: Idle
> INFO:tensorflow:Restoring parameters from /var/folders/7f/643bllcn4pn1g_wf1fnkmwd80000gn/T/tmpvg5Rt6/model.ckpt
> Loaded 'performance' generator bundle from file './performance.mag'.
> INFO:tensorflow:Opening 'magenta_piano_in' as a virtual MIDI port for input.
> INFO:tensorflow:Opening 'magenta_out' as a virtual MIDI port for output.
>
> Instructions:
> Start playing  when you want to begin the call phrase.
> When you want to end the call phrase, stop playing and wait one clock tick.
> Once the response completes, the interface will wait for you to begin playing again to start a new call phrase.
>
> To end the interaction, press CTRL-C.
> INFO:tensorflow:State: Idle
> INFO:tensorflow:State: Idle
> INFO:tensorflow:State: Idle
> 127.0.0.1 - - [09/Jul/2017 18:58:59] ""POST /predict?duration=3.320453514739228 HTTP/1.1"" 405 -
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/771>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6DtRJBRjZYqwLych4C3XgUQzbOz1ks5sMV5fgaJpZM4OSOA_>
> .
>
",hi like might serving ai duet site somehow post request post would come sun wrote also return keyboard seem work o sierra flask magenta magenta following command per curl bash script output source activate magenta magenta sh file already present file already present file already present file already present running press quit warning input port capture disabled opening virtual port output loaded generator bundle file loaded generator bundle file opening virtual port input opening virtual port output start want begin call phrase want end call phrase stop wait one clock tick response interface wait begin start new call phrase end interaction press state idle state idle state idle state idle loaded generator bundle file state idle loaded generator bundle file opening virtual port input opening virtual port output start want begin call phrase want end call phrase stop wait one clock tick response interface wait begin start new call phrase end interaction press state idle state idle state idle post thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
313256858,"Hmm, I'm not seeing that error on my Mac using Bazel 0.5.2-homebrew. You could try updating to that version to see if it makes a difference.

Also make sure that you've synced the magenta repository to the latest commit.

It may also be worth trying the following:
```
bazel clean
bazel shutdown
```

And then retrying the test command.",seeing error mac could try version see difference also make sure magenta repository latest commit may also worth trying following clean shutdown test command,issue,positive,positive,positive,positive,positive,positive
313255398,"Hi @orgicus. Sorry to hear that your .bash_profile was overwritten. This part of the installation process is done by the miniconda installer, so I would suggest filing a bug report on their issue tracker: https://github.com/conda/conda/issues

For getting Magenta working, could you try following the manual installation instructions and see if that works?",hi sorry hear part installation process done installer would suggest filing bug report issue tracker getting magenta working could try following manual installation see work,issue,negative,negative,negative,negative,negative,negative
313250013,"@neelkadia can you please file a new issue? I suspect your problem is not related to the issue in this bug. When you create a new issue, please include the errors in one of the log files from the output.",please file new issue suspect problem related issue bug create new issue please include one log output,issue,negative,positive,neutral,neutral,positive,positive
312311661,"Jordan, ""one-hot"" (https://en.wikipedia.org/wiki/One-hot) is actually the intended term there.
Thanks for checking though!",jordan actually intended term thanks though,issue,negative,positive,neutral,neutral,positive,positive
311826615,@gbernal Now [bash on Windows does not support GPU](https://github.com/Microsoft/BashOnWindows/issues/829).  We have to wait Magenta supports Python3 or bash on Windows supports GPU!,bash support wait magenta python bash,issue,negative,neutral,neutral,neutral,neutral,neutral
311787211,"thanks for the advice. I'm still having some issues. I'm now having this issue https://stackoverflow.com/questions/42013316/after-building-tensorflow-from-source-seeing-libcudart-so-and-libcudnn-errors 
Do you install windows cuDNN  or linux cuDNN? ",thanks advice still issue install,issue,negative,positive,positive,positive,positive,positive
311739244,"Hi @pcuellar 

In sketch_rnn_train.py, in line 75, I see something different than what you are seeing:

https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py#L75

Recently, the HParams object has been updated to use tf's HParams and update has been changed to parse_json a week or two ago. Maybe you need to run the latest version.

If the latest packaged version doesn't include the latest code, we will need to release and update the packages so that they do.

Thanks

",hi line see something different seeing recently object use update week two ago maybe need run latest version latest version include latest code need release update thanks,issue,negative,positive,positive,positive,positive,positive
311509682,"I have seen this as well but haven't had time to look into it yet. Thanks
for creating the issue.

On Tue, Jun 27, 2017 at 3:53 PM Yesh <notifications@github.com> wrote:

> When I run bazel test //magenta/... all tests pass except for the
> midi_hub_test in /magenta/interfaces/midi which times out.
>
> Console output:
> `
> TIMEOUT: //magenta/interfaces/midi:midi_hub_test (see
> /home/s/.cache/bazel/_bazel_s/5be385002debe164746de4f288331729/execroot/magenta-dev/bazel-out/local-opt/testlogs/magenta/interfaces/midi/midi_hub_test/test.log).
>
> Executed 40 out of 40 tests: 39 tests pass and 1 fails locally.
> `
>
> After checking the test.log file I get this output, which looks like a
> failed redirection with the exec command.
>
> exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
>
> As this is the first issue with this test, I'm sure there is some local
> setup that I'm missing or have wrong. I'm running Ubuntu 16.04 with bazel
> 0.5.1
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/759>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6CE4Q0peTaNv9CMiUvZJAUO4H3Tdks5sIYfQgaJpZM4OHSmZ>
> .
>
",seen well time look yet thanks issue tue wrote run test pas except time console output see executed pas locally file get output like redirection command pager exit first issue test sure local setup missing wrong running thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
311437249,"Let's do that later, that's another step that I also want to make sure everyone approves of.",let later another step also want make sure everyone,issue,negative,positive,positive,positive,positive,positive
311218258,"You can use [bash on Windows](https://msdn.microsoft.com/ja-jp/commandline/wsl/about). My platform is Windows 10 and executes the Magenta by bash on Windows. 
I hope the short instruction on my repository helps you.

[icoxfog417/magenta_session#install](https://github.com/icoxfog417/magenta_session#install)
",use bash platform magenta bash hope short instruction repository install,issue,negative,neutral,neutral,neutral,neutral,neutral
311178651,"Ah.. I came here looking for the answer to this questions.. Is everyone running some form of Linux?

",ah came looking answer everyone running form,issue,negative,neutral,neutral,neutral,neutral,neutral
311133529,Thanks @folex! Can you sign the CLA so we can merge your code?,thanks sign merge code,issue,negative,positive,positive,positive,positive,positive
310991735,"Hey, no idea off the top of my head, but it might be a good idea to include more details about how you generated ```escher_style_images.tfrecord```.",hey idea top head might good idea include,issue,positive,positive,positive,positive,positive,positive
310279842,"yes, I know the indian music also. I play also sitar.

On Wed, Jun 21, 2017 at 3:16 PM, The Evil Man <notifications@github.com>
wrote:

> @avinash040 <https://github.com/avinash040> midi is based on twelve tone
> but for example I heard that Indian music even use notes between two
> semitones. xD
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-309974395>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhPphfrkgYwEYl6s1lqqS-iqE2SKAks5sGLVPgaJpZM4K3IsG>
> .
>
",yes know music also play also sitar wed evil man wrote based twelve tone example music even use two reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
310279437,"contact!


On Tue, May 16, 2017 at 7:28 PM, The Evil Man <notifications@github.com>
wrote:

> @terraxoxo <https://github.com/terraxoxo> Do u have Skype or something?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-301741090>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhCsF6_-ljpFs9IhpSOEZaSUSgd_cks5r6XplgaJpZM4K3IsG>
> .
>
",contact tue may evil man wrote something reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
310279019,"@DefinitlyEvil 
Yes, I have skype, haha. I will let you know by email. but hope you can do self-introduce to me....! 
",yes let know hope,issue,positive,neutral,neutral,neutral,neutral,neutral
310214325,"Run

`pip uninstall tensorflow` to get rid of the original version and then run `pip install tensorflow==1.0.1`",run pip get rid original version run pip install,issue,negative,positive,positive,positive,positive,positive
309974395,"@avinash040 midi is based on twelve tone but for example I heard that Indian music even use notes between two semitones. xD 
",based twelve tone example music even use two,issue,negative,neutral,neutral,neutral,neutral,neutral
309960331,"@terraxoxo You could probably create a MIDI dataset by converting your existing music files into MIDI. There are software tools that let you do this. However, they are not very accurate. Ableton lets you convert live audio into MIDI (doesn't really work well when harmony is involved)",could probably create converting music let however accurate convert live audio really work well harmony involved,issue,positive,positive,positive,positive,positive,positive
309655422,Should be resolved with Issue #734. Let me know if any problems still.,resolved issue let know still,issue,negative,neutral,neutral,neutral,neutral,neutral
309576435,"I edited rl_tuner_ops.basic_rnn_hparams() function with the parameters which I used in training the model and used "" bazel run magenta/models/rl_tuner:rl_tuner_train "" 
and this returns the right hparams 
I think my issue is because (state_is_tuple=True)  in events_rnn_graph 
maybe the code was implemented for (state_is_tuple=False) only but I'm not sure 
I wanted to get another opinion to make sure that this is the problem and if so how can i fix it",function used training model used run right think issue maybe code sure get another opinion make sure problem fix,issue,negative,positive,positive,positive,positive,positive
309507776,"Hi!

If you don't care about total convergence, training on a single class in
QuickDraw for half a day on a TITAN-X is enough.

Tips for faster training at the expense of quality:

-anneal KL faster: use 0.9999 rather than 0.99995
-use learning rate at 0.0001 and not anneal below this rate to 0.00001, at
the higher risk of NaNs
-turn off dropout, train faster but risk overfitting too soon

Good luck with the implementation

On Mon, Jun 19, 2017 at 8:16 AM Alexis David Jacq <notifications@github.com>
wrote:

> Hello, thanks for this amazing algorithm!
>
> I am writing a Pytorch version of sketch-rnn, and I would like to know
> what is the average time of training with a simple laptop's GPU. (using the
> same default hyperparameters, and only training to generate samples from
> the cat.npz dataset)
>
> Also, what is approximatively the minimal number of epoch in order to get
> recognizable drawing generations?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/742>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGBoHjpv3fDn0KLkDEJAvBE4Opp3ENA5ks5sFpDpgaJpZM4N-YZD>
> .
>
",hi care total convergence training single class half day enough faster training expense quality faster use rather learning rate anneal rate higher risk dropout train faster risk soon good luck implementation mon wrote hello thanks amazing algorithm writing version would like know average time training simple default training generate also approximatively minimal number epoch order get recognizable drawing thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
309416907,"sudo bazel test //magenta/...
Password:
Extracting Bazel installation...
.........
INFO: Found 136 targets and 39 test targets...
INFO: From Compiling external/protobuf/src/google/protobuf/util/time_util.cc [for host]:
external/protobuf/src/google/protobuf/util/time_util.cc:52:18: warning: unused variable 'kMicrosPerMillisecond' [-Wunused-const-variable]
static const int kMicrosPerMillisecond = 1000;
                 ^
external/protobuf/src/google/protobuf/util/time_util.cc:56:19: warning: unused variable 'kTimestampFormat' [-Wunused-const-variable]
static const char kTimestampFormat[] = ""%E4Y-%m-%dT%H:%M:%S"";
                  ^
2 warnings generated.
INFO: From Compiling external/protobuf/src/google/protobuf/compiler/js/embed.cc [for host]:
external/protobuf/src/google/protobuf/compiler/js/embed.cc:37:12: warning: unused variable 'output_file' [-Wunused-const-variable]
const char output_file[] = ""well_known_types_embed.cc"";
           ^
1 warning generated.
INFO: From Linking external/protobuf/libprotobuf.a [for host]:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/gzip_stream.o has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/util/internal/error_listener.o has no symbols
INFO: From Linking external/protobuf/libprotobuf_lite.a [for host]:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/atomicops_internals_x86_gcc.o has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: file: bazel-out/host/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/atomicops_internals_x86_msvc.o has no symbols
FAIL: //magenta/common:concurrency_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/common/concurrency_test/test.log).
FAIL: //magenta/models/improv_rnn:improv_rnn_create_dataset_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/improv_rnn/improv_rnn_create_dataset_test/test.log).
FAIL: //magenta/common:state_util_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/common/state_util_test/test.log).
FAIL: //magenta/models/melody_rnn:melody_rnn_create_dataset_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/melody_rnn/melody_rnn_create_dataset_test/test.log).
FAIL: //magenta/models/shared:events_rnn_graph_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/shared/events_rnn_graph_test/test.log).
FAIL: //magenta/models/polyphony_rnn:polyphony_encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/polyphony_rnn/polyphony_encoder_decoder_test/test.log).
FAIL: //magenta/models/polyphony_rnn:polyphony_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/polyphony_rnn/polyphony_lib_test/test.log).
FAIL: //magenta/models/polyphony_rnn:polyphony_rnn_create_dataset_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/polyphony_rnn/polyphony_rnn_create_dataset_test/test.log).
FAIL: //magenta/models/drums_rnn:drums_rnn_create_dataset_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/drums_rnn/drums_rnn_create_dataset_test/test.log).
FAIL: //magenta/models/pianoroll_rnn_nade:pianoroll_rnn_nade_create_dataset_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_create_dataset_test/test.log).
FAIL: //magenta/scripts:convert_dir_to_note_sequences_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/scripts/convert_dir_to_note_sequences_test/test.log).
FAIL: //magenta/models/rl_tuner:rl_tuner_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/rl_tuner/rl_tuner_test/test.log).
INFO: From Compiling external/protobuf/src/google/protobuf/util/time_util.cc:
external/protobuf/src/google/protobuf/util/time_util.cc:52:18: warning: unused variable 'kMicrosPerMillisecond' [-Wunused-const-variable]
static const int kMicrosPerMillisecond = 1000;
                 ^
external/protobuf/src/google/protobuf/util/time_util.cc:56:19: warning: unused variable 'kTimestampFormat' [-Wunused-const-variable]
static const char kTimestampFormat[] = ""%E4Y-%m-%dT%H:%M:%S"";
                  ^
2 warnings generated.
FAIL: //magenta/interfaces/midi:midi_hub_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/interfaces/midi/midi_hub_test/test.log).
FAIL: //magenta/pipelines:statistics_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/statistics_test/test.log).
FAIL: //magenta/pipelines:pipelines_common_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/pipelines_common_test/test.log).
FAIL: //magenta/pipelines:pipeline_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/pipeline_test/test.log).
FAIL: //magenta/pipelines:melody_pipelines_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/melody_pipelines_test/test.log).
FAIL: //magenta/pipelines:lead_sheet_pipelines_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/lead_sheet_pipelines_test/test.log).
FAIL: //magenta/pipelines:drum_pipelines_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/drum_pipelines_test/test.log).
FAIL: //magenta/pipelines:dag_pipeline_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/dag_pipeline_test/test.log).
FAIL: //magenta/pipelines:chord_pipelines_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/pipelines/chord_pipelines_test/test.log).
FAIL: //magenta/music:sequences_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/sequences_lib_test/test.log).
FAIL: //magenta/music:sequence_generator_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/sequence_generator_test/test.log).
FAIL: //magenta/music:pianoroll_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/pianoroll_lib_test/test.log).
FAIL: //magenta/music:note_sequence_io_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/note_sequence_io_test/test.log).
FAIL: //magenta/music:musicxml_parser_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/musicxml_parser_test/test.log).
FAIL: //magenta/music:pianoroll_encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/pianoroll_encoder_decoder_test/test.log).
FAIL: //magenta/music:midi_io_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/midi_io_test/test.log).
FAIL: //magenta/music:melody_encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/melody_encoder_decoder_test/test.log).
FAIL: //magenta/music:musicnet_io_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/musicnet_io_test/test.log).
FAIL: //magenta/music:melodies_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/melodies_lib_test/test.log).
FAIL: //magenta/music:lead_sheets_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/lead_sheets_lib_test/test.log).
FAIL: //magenta/music:events_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/events_lib_test/test.log).
FAIL: //magenta/music:drums_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/drums_lib_test/test.log).
FAIL: //magenta/music:drums_encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/drums_encoder_decoder_test/test.log).
FAIL: //magenta/music:chords_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/chords_lib_test/test.log).
FAIL: //magenta/music:chords_encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/chords_encoder_decoder_test/test.log).
FAIL: //magenta/music:encoder_decoder_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/encoder_decoder_test/test.log).
FAIL: //magenta/music:chord_symbols_lib_test (see /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/music/chord_symbols_lib_test/test.log).
INFO: Elapsed time: 79.245s, Critical Path: 10.22s
//magenta/common:concurrency_test                                        FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/common/concurrency_test/test.log
//magenta/common:state_util_test                                         FAILED in 0.5s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/common/state_util_test/test.log
//magenta/interfaces/midi:midi_hub_test                                  FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/interfaces/midi/midi_hub_test/test.log
//magenta/models/drums_rnn:drums_rnn_create_dataset_test                 FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/drums_rnn/drums_rnn_create_dataset_test/test.log
//magenta/models/improv_rnn:improv_rnn_create_dataset_test               FAILED in 0.1s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/improv_rnn/improv_rnn_create_dataset_test/test.log
//magenta/models/melody_rnn:melody_rnn_create_dataset_test               FAILED in 0.1s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/melody_rnn/melody_rnn_create_dataset_test/test.log
//magenta/models/pianoroll_rnn_nade:pianoroll_rnn_nade_create_dataset_test FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/pianoroll_rnn_nade/pianoroll_rnn_nade_create_dataset_test/test.log
//magenta/models/polyphony_rnn:polyphony_encoder_decoder_test            FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/polyphony_rnn/polyphony_encoder_decoder_test/test.log
//magenta/models/polyphony_rnn:polyphony_lib_test                        FAILED in 0.2s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlogs/magenta/models/polyphony_rnn/polyphony_lib_test/test.log
//magenta/models/polyphony_rnn:polyphony_rnn_create_dataset_test         FAILED in 0.1s
  /private/var/tmp/_bazel_root/f7b8a482e96a40315508e7c5aab958fc/execroot/magenta/bazel-out/darwin_x86_64-opt/testlog",test password installation found test host warning unused variable static warning unused variable static char host warning unused variable char warning linking host file file linking host file file fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see warning unused variable static warning unused variable static char fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see fail see time critical path,issue,negative,negative,negative,negative,negative,negative
309234561,"Few more quick nits:

* You can change the link to the blog post to `magenta.tensorflow.org/nsynth-fastgen`
* Maybe add a link to download the wavenet checkpoint `http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar`

Besides that, LGTM
",quick change link post maybe add link besides,issue,negative,positive,positive,positive,positive,positive
308896209,"I'm suffering from the same with:

```
rl_tuner_train \
  --run_dir=$RUN_DIR \
  --note_rnn_checkpoint_dir=$CKPT_DIR \
  --note_rnn_hparams=""{'batch_size':16,'rnn_layer_sizes':[768,768]}"" \
  --note_rnn_type=basic_rnn \
  --training_steps=10000 \
  --exploration_steps=5000 \
  --output_every_nth=50
```

I've tracked what values are being passed at ` File ""~/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1499, in placeholder shape = tensor_shape.as_shape(shape)`. After running the command above they are (in order):
1. `[None, None, 38]`
2. `[None]`
3. `[None, (LSTMStateTuple(c=512, h=512), LSTMStateTuple(c=512, h=512))]`

The last one causes the error.

What I've also found is that `note_rnn_hparams` argument is ignored in `rl_tuner_train.py`:
```
hparams = (rl_tuner_ops.basic_rnn_hparams()
             if FLAGS.note_rnn_type == 'basic_rnn'
             else rl_tuner_ops.default_hparams())
```
Where `rl_tuner_ops.basic_rnn_hparams()` returns hardcoded value:
```
return tf.contrib.training.HParams(batch_size=128,
                                     rnn_layer_sizes=[512, 512],
                                     one_hot_length=NUM_CLASSES)
```",suffering tracked file line shape shape running command order none none none none last one error also found argument else value return,issue,negative,neutral,neutral,neutral,neutral,neutral
308874176,"it looks like @francescodelduchetto folded this change into his PR (https://github.com/tensorflow/magenta/pull/735/commits/965ed258cb937b3bb6c13292665b6746d4dcc427), which is now merged, so I think this one is no longer needed! ",like folded change think one longer,issue,negative,neutral,neutral,neutral,neutral,neutral
308798301,"Sorry for the extremely long delay on this. We had to change a bunch of the code to incorporate the new sampler. If you want to update this for the new code and think it'd be useful I'd be happy to take a look. However, using a TitanX I was able to create encodings and generate from a 3 minute song, so I'm not sure what practical use cases this would really be addressing. We also switched to using librosa for loading, but didn't do the normalization trick, so maybe you could create a new smaller PR for that.

",sorry extremely long delay change bunch code incorporate new sampler want update new code think useful happy take look however able create generate minute song sure practical use would really also switched loading normalization trick maybe could create new smaller,issue,positive,positive,positive,positive,positive,positive
308540705,Thanks for the catch. We recently merged with TF's native HParams from the magenta HParams class,thanks catch recently native magenta class,issue,negative,positive,neutral,neutral,positive,positive
308485745,"Good catch. Could you submit a PR to fix?

On Jun 14, 2017 5:58 PM, ""francescodelduchetto"" <notifications@github.com>
wrote:

> When running the command for training
> $ sketch_rnn_train --log_root=models/ --data_dir=datasets/
> --hparams=""data_set=[theMonaLisa.npz]""
>
> I get the following error:
>
>
> INFO:tensorflow:sketch-rnn
> INFO:tensorflow:Hyperparams:
> Traceback (most recent call last):
>   File ""/home/frahp/miniconda2/bin/sketch_rnn_train"", line 11, in <module>
>     sys.exit(console_entry_point())
>   File ""/home/frahp/miniconda2/lib/python2.7/site-packages/magenta/models/sketch_rnn/sketch_rnn_train.py"", line 476, in console_entry_point
>     tf.app.run(main)
>   File ""/home/frahp/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""/home/frahp/miniconda2/lib/python2.7/site-packages/magenta/models/sketch_rnn/sketch_rnn_train.py"", line 472, in main
>     trainer(model_params)
>   File ""/home/frahp/miniconda2/lib/python2.7/site-packages/magenta/models/sketch_rnn/sketch_rnn_train.py"", line 437, in trainer
>     for key, val in model_params.keyvals.iteritems():
> AttributeError: 'HParams' object has no attribute 'keyvals'
>
> In *sketch_rnn_train.py"", line 437* the line for key, val in
> model_params.keyvals.iteritems(): should be for key, val in
> model_params.values().iteritems(): right?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/734>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6CVVgUomGapt6TGHDCmoI441gMZfks5sEAMWgaJpZM4N6GFS>
> .
>
",good catch could submit fix wrote running command training get following error recent call last file line module file line main file line run main file line main trainer file line trainer key object attribute line line key key right thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
308129973,"so digging into source code for Summarise_Graph - it seems that the code is simply looking for ""Placeholder"" ops.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/summarize_graph_main.cc#L129

",digging source code code simply looking,issue,negative,neutral,neutral,neutral,neutral,neutral
307583602,"It is relatively straightforward to apply for speech in theory, however in practice it computationally expensive to train new models, ex. see #625 ",relatively straightforward apply speech theory however practice expensive train new ex see,issue,negative,positive,neutral,neutral,positive,positive
307583385,"Sorry for taking so long to reply. Unfortunately, it seems that the OSS version of TF requires different setup for distributed training than we have internally. This makes it hard for us to test and setup, so sorry for the challenge and confusion.
 
I think you're on the right track in terms of needing to set up a clusterspec and server. A good example is the [inception](https://github.com/tensorflow/models/blob/master/inception/inception/inception_distributed_train.py) [imagenet](https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py) code if you want to pursue this further. Slim.learning.train works well for distributed training internally, but I can't point you to an exact usage externally yet. Apologies, again. If you would like to get this working we of course would welcome the contribution. Given that it takes so much compute to train a model (32 K80's for 10 days) the training script serves more illustrative than practical purpose at the moment.

If you want to make your own sounds with NSynth, we are [just releasing](https://github.com/tensorflow/magenta/pull/669) fast sampler code to make that easy. 
",sorry taking long reply unfortunately version different setup distributed training internally hard u test setup sorry challenge confusion think right track needing set server good example inception code want pursue work well distributed training internally ca point exact usage externally yet would like get working course would welcome contribution given much compute train model day training script illustrative practical purpose moment want make fast sampler code make easy,issue,positive,positive,neutral,neutral,positive,positive
307462456,"This shouldn't affect the duration of individual notes, but the start/end times of generated sequences.  Are you observing any difference in note durations?",affect duration individual time observing difference note,issue,negative,neutral,neutral,neutral,neutral,neutral
307461544,Will this PR make quantization less accurate?  It seems that it reduces the duration of all the notes by one step.,make quantization le accurate duration one step,issue,negative,positive,positive,positive,positive,positive
307263239,"conversely - 
bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=/Users/jp/Downloads/inception5h/**tensorflow_inception_graph.pb**
**Found 1 possible inputs: (name=input, type=float(1), shape=[])**
No variables spotted.
**Found 3 possible outputs: (name=output, op=Identity) (name=output1, op=Identity) (name=output2, op=Identity)**
Found 13462015 (13.46M) const parameters, 0 (0) variable parameters, and 0 control_edges
370 nodes assigned to device '/cpu:0'Op types used: 142 Const, 64 BiasAdd, 61 Relu, 59 Conv2D, 13 MaxPool, 9 Concat, 5 Reshape, 5 MatMul, 3 Softmax, 3 Identity, 3 AvgPool, 2 LRN, 1 Placeholder
To use with tensorflow/tools/benchmark:benchmark_model try these arguments:
bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=/Users/jp/Downloads/inception5h/tensorflow_inception_graph.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape= --output_layer=output,output1,output2",conversely found possible spotted found possible found variable assigned device used reshape identity use try run output output,issue,negative,neutral,neutral,neutral,neutral,neutral
307262456,"I'm afraid after running the scripts to dump out the checkpoint file
 bazel run magenta/scripts:unpack_bundle -- \
--bundle_path '/Users/jp/Documents/tensorflowWorkspace/magenta/attention_rnn.mag' --checkpoint_path '/Users/jp/Documents/tensorflowWorkspace/magenta/attention_rnn.mag.chkpt'

spits out -> **attention_rnn.pb**


then building 
bazel build tensorflow/tools/graph_transforms:summarize_graph
and running  
 
bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=**attention_rnn.pb**
**No inputs spotted.**
**No variables spotted.**
**No outputs spotted.**
Found 5201907 (5.20M) const parameters, 0 (0) variable parameters, and 14 control_edges
Op types used: 43 Const, 14 Assign, 14 RestoreSlice, 1 NoOp
To use with tensorflow/tools/benchmark:benchmark_model try these arguments:
bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=attention_rnn.pb --show_flops --input_layer= --input_layer_type= --input_layer_shape= --output_layer=

not sure how to progress this. can the magenta mag files be used for inference?
",afraid running dump file run building build running spotted spotted spotted found variable used assign noop use try run sure progress magenta mag used inference,issue,negative,negative,neutral,neutral,negative,negative
307250739,"I didn't mean to do it in this PR, but I am about to push a new version, so might as well.",mean push new version might well,issue,negative,negative,neutral,neutral,negative,negative
307186963,"John, it sounds like we should be doing the freezing when we create the
.mag files.

Do you want to make a PR to add that functionality? We can then re-release
the .mag files pre-frozen.

On Thu, Jun 8, 2017 at 7:14 AM John Pope <notifications@github.com> wrote:

> thus far
>
> import tensorflow as tf
> from tensorflow.python.tools import freeze_graph
> from PIL import Image
> import numpy as np
> print ""start..""
> freeze_graph.freeze_graph('attention_rnn.pb',"""",True,
> 'attention_rnn.chkpt',
> 'mul',
> 'save_1/restore_all','save_1/Const:0',
> 'attention_rnn_frozen.pb',
> True,"""")
>
> print ""end...""
>
> start..
> Traceback (most recent call last):
> File ""gen_freeze_graph.py"", line 11, in
> True,"""")
> File
> ""/usr/local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"",
> line 179, in freeze_graph
> variable_names_blacklist)
> File
> ""/usr/local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"",
> line 87, in freeze_graph_with_def_protos
> _ = importer.import_graph_def(input_graph_def, name="""")
> File
> ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"",
> line 391, in import_graph_def
> node, 'Input tensor %r %s' % (input_name, te)))
> ValueError: graph_def is invalid at node u'save_1/Assign': Input tensor
> 'RNN/AttentionCellWrapper/Attention/AttnV:0' Cannot convert a tensor of
> type float32 to an input of type float32_ref.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/715#issuecomment-307116386>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6H-JaYeD8HCLO1btqrDWUq4VqpT1ks5sCAGrgaJpZM4N0EK3>
> .
>
",like freezing create want make add functionality pope wrote thus far import import import image import print start true true print end start recent call last file line true file line file line file line node tensor te invalid node input tensor convert tensor type float input type thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
307185646,"Removed .DS_Store files. We could decide to move the demos later on. For now, we have them outside of the magenta directory.",removed could decide move demo later outside magenta directory,issue,negative,neutral,neutral,neutral,neutral,neutral
307116386,"thus far

```python
import tensorflow as tf
from tensorflow.python.tools import freeze_graph
from PIL import Image
import numpy as np
print ""start..""
freeze_graph.freeze_graph('attention_rnn.pb',"""",True,
                'attention_rnn.chkpt',
                'mul',
                'save_1/restore_all','save_1/Const:0',
                'attention_rnn_frozen.pb',
                True,"""")

print ""end...""




Traceback (most recent call last):
  File ""gen_freeze_graph.py"", line 11, in <module>
    True,"""")
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"", line 179, in freeze_graph
    variable_names_blacklist)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"", line 87, in freeze_graph_with_def_protos
    _ = importer.import_graph_def(input_graph_def, name="""")
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 391, in import_graph_def
    node, 'Input tensor %r %s' % (input_name, te)))
ValueError: graph_def is invalid at node u'save_1/Assign': Input tensor 'RNN/AttentionCellWrapper/Attention/AttnV:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
```",thus far python import import import image import print start true true print end recent call last file line module true file line file line file line node tensor te invalid node input tensor convert tensor type float input type,issue,positive,positive,positive,positive,positive,positive
306878206,"rl_tuner_train
Retrieving checkpoint of Note RNN from Magenta download server.
WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x118524050>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x118524dd0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x119697110>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
WARNING:tensorflow:ERROR! No such primer file exists! ./testdata/primer.mid
2017-06-07 14:07:58.519449: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-07 14:07:58.519468: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-07 14:07:58.519484: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-07 14:07:58.519489: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-07 14:07:58.519493: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
WARNING:tensorflow:Can't find checkpoint file, using /Users/jpope/note_rnn.ckpt
Traceback (most recent call last):
  File ""/usr/local/bin/rl_tuner_train"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner_train.py"", line 137, in console_entry_point
    tf.app.run(main)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner_train.py"", line 115, in main
    algorithm=FLAGS.algorithm)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 236, in __init__
    self.initialize_internal_models_graph_session()
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 300, in initialize_internal_models_graph_session
    self.q_network.initialize_and_restore(self.session)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 142, in initialize_and_restore
    self.restore_vars_from_checkpoint(self.checkpoint_dir)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 284, in restore_vars_from_checkpoint
    saver.restore(self.session, checkpoint_file)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1548, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 789, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 997, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1132, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1152, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Tensor name ""rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel"" not found in checkpoint files /Users/jpope/note_rnn.ckpt
	 [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]

Caused by op u'save_1/RestoreV2_3', defined at:
  File ""/usr/local/bin/rl_tuner_train"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner_train.py"", line 137, in console_entry_point
    tf.app.run(main)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner_train.py"", line 115, in main
    algorithm=FLAGS.algorithm)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 236, in __init__
    self.initialize_internal_models_graph_session()
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 300, in initialize_internal_models_graph_session
    self.q_network.initialize_and_restore(self.session)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 142, in initialize_and_restore
    self.restore_vars_from_checkpoint(self.checkpoint_dir)
  File ""/usr/local/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 274, in restore_vars_from_checkpoint
    saver = tf.train.Saver(var_list=var_dict)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1139, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1170, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 691, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 247, in restore_op
    [spec.tensor.dtype])[0])
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 640, in restore_v2
    dtypes=dtypes, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1269, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Tensor name ""rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel"" not found in checkpoint files /Users/jpope/note_rnn.ckpt
	 [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]
",note magenta server warning object state soon use warning error primer file warning object state soon use warning error primer file warning object state soon use warning error primer file library use available machine could speed library use available machine could speed library use available machine could speed library use available machine could speed library use available machine could speed warning ca find file recent call last file line module file line main file line run main file line main file line file line file line file line file line restore file line run file line file line file line raise type message tensor name found node defined file line module file line main file line run main file line main file line file line file line file line saver file line file line build file line build reshape file line file line file line file line file line file line see tensor name found node,issue,negative,positive,positive,positive,positive,positive
306876338,"Retrieving checkpoint of Note RNN from Magenta download server.
INFO:tensorflow:Initializing q network
INFO:tensorflow:Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope q_network
WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x1187bee50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
INFO:tensorflow:Initializing target q network
INFO:tensorflow:Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope target_q_network
WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x1199ca9d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
INFO:tensorflow:Initializing reward network
INFO:tensorflow:Using custom hparams
INFO:tensorflow:Initializing melody RNN graph for scope reward_rnn
WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x119a4d9d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
INFO:tensorflow:Q network cell: <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x1187beb90>
INFO:tensorflow:Adding RL graph variables
INFO:tensorflow:Adding reward computation portion of the graph
INFO:tensorflow:Adding taking action portion of graph
INFO:tensorflow:Add estimating future rewards portion of graph
INFO:tensorflow:Adding q value prediction portion of graph
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights_0/gradients instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases:0 is illegal; using q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases_0 instead.
INFO:tensorflow:Summary name q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases:0/gradients is illegal; using q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases_0/gradients instead.
INFO:tensorflow:Summary name q_network/fully_connected/weights:0 is illegal; using q_network/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name q_network/fully_connected/weights:0/gradients is illegal; using q_network/fully_connected/weights_0/gradients instead.
INFO:tensorflow:Summary name q_network/fully_connected/bias:0 is illegal; using q_network/fully_connected/bias_0 instead.
INFO:tensorflow:Summary name q_network/fully_connected/bias:0/gradients is illegal; using q_network/fully_connected/bias_0/gradients instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/weights_0 instead.
INFO:tensorflow:Summary name target_q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases:0 is illegal; using target_q_network/rnn/multi_rnn_cell/cell_0/lstm_cell/biases_0 instead.
INFO:tensorflow:Summary name target_q_network/fully_connected/weights:0 is illegal; using target_q_network/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name target_q_network/fully_connected/bias:0 is illegal; using target_q_network/fully_connected/bias_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/lstm_cell/weights:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/lstm_cell/weights_0 instead.
INFO:tensorflow:Summary name reward_rnn/rnn/multi_rnn_cell/cell_0/lstm_cell/biases:0 is illegal; using reward_rnn/rnn/multi_rnn_cell/cell_0/lstm_cell/biases_0 instead.
INFO:tensorflow:Summary name reward_rnn/fully_connected/weights:0 is illegal; using reward_rnn/fully_connected/weights_0 instead.
INFO:tensorflow:Summary name reward_rnn/fully_connected/bias:0 is illegal; using reward_rnn/fully_connected/bias_0 instead.
INFO:tensorflow:Adding target network update portion of graph
INFO:tensorflow:Restoring variables from checkpoint
INFO:tensorflow:Checkpoint dir: /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner
WARNING:tensorflow:Can't find checkpoint file, using /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner/note_rnn.ckpt
INFO:tensorflow:Checkpoint file: /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner/note_rnn.ckpt
INFO:tensorflow:Restoring parameters from /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner/note_rnn.ckpt
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-7-8910b466ad1e> in <module>()
      4                           reward_scaler=REWARD_SCALER,
      5                           output_every_nth=OUTPUT_EVERY_NTH,
----> 6                           num_notes_in_melody=NUM_NOTES_IN_COMPOSITION)

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.pyc in __init__(self, output_dir, dqn_hparams, reward_mode, reward_scaler, exploration_mode, priming_mode, stochastic_observations, algorithm, note_rnn_checkpoint_dir, note_rnn_checkpoint_file, note_rnn_type, note_rnn_hparams, num_notes_in_melody, input_size, num_actions, midi_primer, save_name, output_every_nth, training_file_list, summary_writer, initialize_immediately)
    234 
    235     if initialize_immediately:
--> 236       self.initialize_internal_models_graph_session()
    237 
    238   def initialize_internal_models_graph_session(self,

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.pyc in initialize_internal_models_graph_session(self, restore_from_checkpoint)
    298       # Initialize internal networks.
    299       if restore_from_checkpoint:
--> 300         self.q_network.initialize_and_restore(self.session)
    301         self.target_q_network.initialize_and_restore(self.session)
    302         self.reward_rnn.initialize_and_restore(self.session)

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.pyc in initialize_and_restore(self, session)
    140     """"""
    141     self.session = session
--> 142     self.restore_vars_from_checkpoint(self.checkpoint_dir)
    143 
    144   def initialize_new(self, session=None):

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.pyc in restore_vars_from_checkpoint(self, checkpoint_dir)
    282     tf.logging.info('Checkpoint file: %s', checkpoint_file)
    283 
--> 284     saver.restore(self.session, checkpoint_file)
    285 
    286   def load_primer(self):

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1455     logging.info(""Restoring parameters from %s"", save_path)
   1456     sess.run(self.saver_def.restore_op_name,
-> 1457              {self.saver_def.filename_tensor_name: save_path})
   1458 
   1459   @staticmethod

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    776     try:
    777       result = self._run(None, fetches, feed_dict, options_ptr,
--> 778                          run_metadata_ptr)
    779       if run_metadata:
    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    980     if final_fetches or final_targets:
    981       results = self._do_run(handle, final_targets, final_fetches,
--> 982                              feed_dict_string, options, run_metadata)
    983     else:
    984       results = []

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1030     if handle is None:
   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1032                            target_list, options, run_metadata)
   1033     else:
   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1050         except KeyError:
   1051           pass
-> 1052       raise type(e)(node_def, op, message)
   1053 
   1054   def _extend_graph(self):

NotFoundError: Tensor name ""rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/weights"" not found in checkpoint files /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner/note_rnn.ckpt
	 [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save_1/Const_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]

Caused by op u'save_1/RestoreV2_3', defined at:
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-7-8910b466ad1e>"", line 6, in <module>
    num_notes_in_melody=NUM_NOTES_IN_COMPOSITION)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 236, in __init__
    self.initialize_internal_models_graph_session()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/rl_tuner.py"", line 300, in initialize_internal_models_graph_session
    self.q_network.initialize_and_restore(self.session)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 142, in initialize_and_restore
    self.restore_vars_from_checkpoint(self.checkpoint_dir)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/rl_tuner/note_rnn_loader.py"", line 274, in restore_vars_from_checkpoint
    saver = tf.train.Saver(var_list=var_dict)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1056, in __init__
    self.build()
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1086, in build
    restore_sequentially=self._restore_sequentially)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 691, in build
    restore_sequentially, reshape)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 247, in restore_op
    [spec.tensor.dtype])[0])
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 669, in restore_v2
    dtypes=dtypes, name=name)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/jpope/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Tensor name ""rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/weights"" not found in checkpoint files /Users/jpope/Documents/gitWorkspace/magenta/magenta/models/rl_tuner/note_rnn.ckpt
	 [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save_1/Const_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]
",note magenta server network custom melody graph scope warning object state soon use target network custom melody graph scope warning object state soon use reward network custom melody graph scope warning object state soon use network cell object graph reward computation portion graph taking action portion graph add future portion graph value prediction portion graph summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead summary name illegal instead target network update portion graph warning ca find file file recent call last bade module self algorithm self self initialize internal self session session self self file self restore self sess run self try result none self handle handle else self handle handle none return else return handle self except pas raise type message self tensor name found node defined file line loader file line code file line module file line file line start file line start super self file line start file line return file line file line file line file line return file line dispatcher return stream file line handler stream file line file line code file line return super self file line file line code result file line file bade line module file line file line file line file line saver file line file line build file line build reshape file line file line file line file line file line file line see tensor name found node,issue,negative,negative,negative,negative,negative,negative
306337416,I think you should be able to add it to rl_tuner_test.py fairly easily.,think able add fairly easily,issue,negative,positive,positive,positive,positive,positive
306250600,"@gautam1858 the simplest workaround is to just manually edit the `model_config.json` file for the model you're using (by default, they'll save under /tmp/sketch_rnn/models). Just replace `""data_set"": [""foo.npz""],` with `""data_set"": ""foo.npz"",`.

(You could also install the latest Magenta from source, but that's more work.)",manually edit file model default save replace could also install latest magenta source work,issue,negative,positive,positive,positive,positive,positive
305749445,"UPDATE:

Basically, in the var_dict that we create for the tf Saver, 
`rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/weights` is actually `rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0`

and
`rnn_model/rnn/multi_rnn_cell/cell_0/lstm_cell/biases` is actually
`rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/B`

My temporary workaround was to modify the dictionary before it gets passed into the Saver",update basically create saver actually actually temporary modify dictionary saver,issue,negative,neutral,neutral,neutral,neutral,neutral
305662507,"Yes, I believe an updated pip package would fix this.",yes believe pip package would fix,issue,negative,neutral,neutral,neutral,neutral,neutral
305641066,"@hardmaru if we just release a new pip package, will that fix this?",release new pip package fix,issue,negative,positive,positive,positive,positive,positive
304957681,"The improv RNN model needs to train on ""lead sheets"" which have both chords and melody.  The dataset you're using contains only MIDI files, which have no chord information.

If your MIDI files contain ""chords"" as notes and you want to modify the code, you can try calling sequences_lib.infer_chords_for_sequence somewhere in the input pipeline, but it's just going to be guessing the chords and might choke on some inputs.",model need train lead melody chord information contain want modify code try calling somewhere input pipeline going guessing might choke,issue,negative,neutral,neutral,neutral,neutral,neutral
304945861,That could be caused by running out of memory. I'd take a look at what kinds of errors show up if you run the `dmesg` command. You may need to allocate more memory for your container.,could running memory take look show run command may need allocate memory container,issue,negative,neutral,neutral,neutral,neutral,neutral
304856922,"cghawthorne,

Much appreciated! I don't know if that was the core problem or not but after sleeping on it and fiddling with a few characters I got it to work. Thank you!
",much know core problem sleeping fiddling got work thank,issue,negative,positive,positive,positive,positive,positive
304795516,"I could narrow it down to a problem with the second convolutional layer - all goes black there when running on the CPU. Here's the snippet from `magenta/models/image_stylization/model.py`: 

```python
with tf.variable_scope('transformer', reuse=reuse):
    with slim.arg_scope(
        [slim.conv2d],
        activation_fn=tf.nn.relu,
        normalizer_fn=normalizer_fn,
        normalizer_params=normalizer_params,
        weights_initializer=tf.random_normal_initializer(0.0, 0.01),
        biases_initializer=tf.constant_initializer(0.0)):
      with tf.variable_scope('contract'):
        h = _conv2d(input_, 9, 1, 32, 'conv1')
        # h is identical on CPU and GPU
        h = _conv2d(h, 3, 2, 64, 'conv2')
        # h is all black on CPU, GPU works as intended.
        h = _conv2d(h, 3, 2, 128, 'conv3')
```

@fchollet might know more about what changed from 1.0.1 to 1.1.0 regarding convolutions on CPU. They added some cpu-specific logic to `tensorflow/python/layers/convolutional.py`. 
But the bug might also be related to batch normalization or anything else that happens between the two layers.",could narrow problem second convolutional layer go black running snippet python identical black work intended might know regarding added logic bug might also related batch normalization anything else two,issue,negative,negative,negative,negative,negative,negative
304568370,"looks like you're trying to load a model after making changes to your graph (i.e. the shapes in your graph don't match up with the shapes in the graph that you saved). alternatively, maybe you changed some of the names.",like trying load model making graph graph match graph saved alternatively maybe,issue,positive,neutral,neutral,neutral,neutral,neutral
304520327,"@psoulos Thank you so much. Had the same problem today and searched for hours. 
Can anybody explain what causes this or how to support the new tensorflow version? ",thank much problem today anybody explain support new version,issue,negative,positive,positive,positive,positive,positive
304418474,"THANKS man,, you catch me... i need to find another way of copy pasting commands and i didn't saw the INFO: ... too much warnings, lines, errors in the terminal... the hparams of the generate  command was a total mess!",thanks man catch need find another way copy pasting saw much terminal generate command total mess,issue,negative,positive,neutral,neutral,positive,positive
304415508,"Taking a closer look at the commands you're running, it looks like some of the quote marks in your melody_rnn_generate command have been replaced with unicode quote characters (perhaps by pasting into a document editing application?). This prevented the hparams from being parsed correctly.

You can verify how the hparams argument is being parsed by looking for output like this when you run the command:
```
INFO:tensorflow:hparams = {'rnn_layer_sizes': [64, 64], 'attn_length': 40,
'dropout_keep_prob': 0.5, 'batch_size': 64, 'decay_rate': 0.97, 'clip_norm': 3,
'initial_learning_rate': 0.001, 'decay_steps': 1000, 'skip_first_n_losses': 0}
```",taking closer look running like quote command quote perhaps pasting document application correctly verify argument looking output like run command,issue,negative,neutral,neutral,neutral,neutral,neutral
304414171,"thanks for the suggestions.... is what i already found as possible problems for this error...

but these are the commands i used:

Train and Evaluate the Model - OK
melody_rnn_train --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=/tmp/melody_rnn/sequence_examples_attention/training_melodies.tfrecord --hparams=""{'batch_size':64,'rnn_layer_sizes':[64,64]}"" --num_training_steps=100

Generate Melodies FAIL
melody_rnn_generate --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --output_dir=/Users/racso/Documents/MAGENTA/MagentaMidis —num_outputs=1 —num_steps=128 --hparams=""{'batch_size’:64,’rnn_layer_sizes':[64,64]}"" --primer_melody=""[60]”

 --hparams are the same, no? or i miss something else...?

and each time i execute the melody_rnn_train i have change the run_dir or even erased all the run*s

",thanks already found possible error used train evaluate model generate fail miss something else time execute change even erased run,issue,negative,negative,neutral,neutral,negative,negative
304413639,"It looks like the hyperparameters you used for training are different than what you're using for generation. Are you use the --hparams arguments are the same for those two commands? Also, is there a chance that there are checkpoint files from a previous run using different parameters in your run_dir?",like used training different generation use two also chance previous run different,issue,positive,negative,neutral,neutral,negative,negative
304409234,I think the ZeroDivisionError problem should be fixed by #675. We can look at the filename case change in #686.,think problem fixed look case change,issue,negative,positive,neutral,neutral,positive,positive
304402586,"Hi @Voxmanns. I think the problem is with this part of your command:

```
--config=</Users/Nathaniel/Documents/Music/Magenta/RNN/basic_rnn.mag>
```

It shouldn't have the angle brackets and it should reference the name of a config, not a bundle file. It should look something like:

```
--config=basic_rnn
```",hi think problem part command angle reference name bundle file look something like,issue,negative,neutral,neutral,neutral,neutral,neutral
304331304,"Yeah, I'm not sure why the site is down or if it will come back at some point (the error page indicates that it is ""temporarily"" unavailable). I included the archive.org link, which should work even if the site is down, but perhaps that should be made more prominent.",yeah sure site come back point error page temporarily unavailable included link work even site perhaps made prominent,issue,negative,positive,positive,positive,positive,positive
304189408,"I see, there was originally two sets in the research code to do more things, but that isn't needed anymore.  Will remove, thanks.",see originally two research code remove thanks,issue,negative,positive,positive,positive,positive,positive
304184684,"We plan to release the JavaScript demo in the near future. Please keep an
eye out for it :-)

On Thu, May 25, 2017 at 8:32 PM jaimezwalker <notifications@github.com>
wrote:

> I've searched across internet but all I find is quick draw
> <https://quickdraw.withgoogle.com/> which is drawing and recognize the
> drawing. Where can I find the demo of machine continue drawing rain drops
> after I draw a cloud? Thanks!!!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/688>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGBoHu4JQwNCGWalXr5P1wpXV61hqOtlks5r9kfpgaJpZM4NnIs0>
> .
>
",plan release near future please keep eye may wrote across find quick draw drawing recognize drawing find machine continue drawing rain draw cloud thanks thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
304176738,"it does fix it for me; but it still seems very odd to have the two if statements with exactly the same condition

as it is, you may as well just delete the first one; it contributes nothing.",fix still odd two exactly condition may well delete first one nothing,issue,negative,positive,positive,positive,positive,positive
304166702,"Sorry, I didn't know the pull request function. I have done that just now. #685
",sorry know pull request function done,issue,negative,negative,negative,negative,negative,negative
304165962,"Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.

---

- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
- If you signed the CLA as a corporation, please let us know the company's name.

<!-- need_sender_cla -->",thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git corporation please let u know company name,issue,positive,positive,positive,positive,positive,positive
304159412,"Hi @silky, I have resolved this issue. Can you take a look when you have the chance? Let us know if any issue. Thanks.",hi silky resolved issue take look chance let u know issue thanks,issue,positive,positive,positive,positive,positive,positive
304159230,"@dribnet this should be resolved now, can you help give it a go? let me know if any more issues. the multi-dateset is also in.",resolved help give go let know also,issue,positive,neutral,neutral,neutral,neutral,neutral
304156876,"We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.

<!-- need_author_cla -->",found contributor license agreement sender pull request unable find commit author maybe used different address git used sign login double check someone else need sign well confirm,issue,positive,negative,negative,negative,negative,negative
304092881,"Just fyi, `<forward>` has the duration in the text of a child element, not as an attribute:
[MusicXML forward documentation](http://usermanuals.musicxml.com/MusicXML/MusicXML.htm#EL-MusicXML-duration.htm)

Example: 
```
<forward>
<duration>16</duration>
</forward>
```",forward duration text child element attribute forward documentation example forward duration,issue,negative,neutral,neutral,neutral,neutral,neutral
304073356,"Sounds reasonable. Maybe `ableton-jam`, or `ableton-ai-jam`, or `live-ai-jam`, to make it more clear? @cghawthorne , should this be inside or outside the main magenta folder? The jam does have a dependency on having the pip package installed, but doesn't need to include anything in the pip package itself.",reasonable maybe make clear inside outside main magenta folder jam dependency pip package need include anything pip package,issue,negative,positive,positive,positive,positive,positive
304069815,I also think we should consider renaming NIPS_2016 to something like ai-jam,also think consider something like,issue,negative,neutral,neutral,neutral,neutral,neutral
304054678,"Thanks. Would you be willing to submit a pull request to correct this?

On Wed, May 24, 2017 at 11:17 PM 12gjang <notifications@github.com> wrote:

> Hello,
> I am training melody_rnn using various music datasets.
> In some datasets, they have a midi file that contains capital letter
> extension like 'music.MID'.
> But convert_dir_to_note_sequence can't read them.
>
> INFO:tensorflow:Unable to find a converter for file
> /Users/user/Desktop/magenta2/train_midi/test/example.MID
>
> I suggest modifying comparing method to does not distinguish capital and
> small letter in file extension at line 84 of
> /scripts/convert_dir_to_note_sequences.py file
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/677>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6LoYtuPN3U85k4Arl7DW55hUlWLYks5r9R0RgaJpZM4NmAZC>
> .
>
",thanks would willing submit pull request correct wed may wrote hello training various music file capital letter extension like ca read unable find converter file suggest method distinguish capital small letter file extension line file thread reply directly view mute thread,issue,positive,negative,neutral,neutral,negative,negative
303928331,"Yeah, the sketch_rnn notebook calls sketch_rnn_train.load_dataset(), which is where I had set `eval_model_params.is_training = 1` in #666. Evidently this breaks deserialization, maybe because TF is looking for 2 RNNs instead of just 1. In any case, setting this back to `eval_model_params.is_training = 0` fixes the problem for me.

I'll leave this open for now since the current code base will have the same problem for everyone else. I think the solution might be a fix to #661 that is different from #666.",yeah notebook set evidently maybe looking instead case setting back problem leave open since current code base problem everyone else think solution might fix different,issue,negative,negative,neutral,neutral,negative,negative
303926228,"OK, I've found that reverting my change in #666 fixes it. Will keep looking.",found change keep looking,issue,negative,neutral,neutral,neutral,neutral,neutral
303885888,"Hi @dribnet 

Thanks for the modification! I think the multi-dataset idea is great! Before I was just manually concatenating them to create a new .npz file.

I tested your code and there isn't any current issue.  However, we are planning on migrating from our HParams class to the tf.HParams class (https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/training/HParams) later on, and it seems for tf.HParams, it has trouble setting what was originally a single-valued parameter to a list.

One solution is to sacrifice backwards compatibility, and ask you to also modify ""get_default_hparams"" so that by default, data_set is a list, and assume that the model_config json files also store this as a list.

After doing so, I'll update the sketch_rnn.zip so that the JSON model_config files also conform to the new standard, and will merge the pull request and update the zip file on http://download.magenta.tensorflow.org/ at the same time.

Let us know what you think later.",hi thanks modification think idea great manually create new file tested code current issue however class class later trouble setting originally parameter list one solution sacrifice backwards compatibility ask also modify default list assume also store list update also conform new standard merge pull request update zip file time let u know think later,issue,positive,positive,positive,positive,positive,positive
303885110,"It definitely makes sense to add a whole measure rest if the `<forward>` is the only element in that measure. I am just wondering if it makes sense to add rest for any `<forward>` element. I don't think it would make sense to generalize, because the model might learn too many rests. I will just insert rests for the whole measure rest case.",definitely sense add whole measure rest forward element measure wondering sense add rest forward element think would make sense generalize model might learn many insert whole measure rest case,issue,negative,positive,positive,positive,positive,positive
303884313,"@dribnet kindly patched this issue, let me know if you still have a problem later.

https://github.com/tensorflow/magenta/pull/666",kindly issue let know still problem later,issue,negative,positive,positive,positive,positive,positive
303876880,"The file was created in MuseScore, and when you open the file with that program, it interprets it as an empty measure.

I think adding a rest to what would otherwise be an empty measure is a reasonable solution.",file open file program empty measure think rest would otherwise empty measure reasonable solution,issue,negative,neutral,neutral,neutral,neutral,neutral
303876564,"This is an unusual file. Finale and Sibelius imported the `<forward duration='16' />` by simply omitting the measures, giving a fractured score layout. Dorico inserted a whole measure rest in those measures. My plan is to insert a rest when encountering a `<forward>` in some cases. It might be ok to do in all cases; I need to think about this more.",unusual file finale forward simply giving score layout inserted whole measure rest plan insert rest forward might need think,issue,negative,positive,positive,positive,positive,positive
303875386,I'll investigate it in a few days. Thanks for your initial analysis.,investigate day thanks initial analysis,issue,negative,positive,neutral,neutral,positive,positive
303872853,"The root bug is in #674. For now, we should have a way of detecting this error and skipping the file.",root bug way error skipping file,issue,negative,neutral,neutral,neutral,neutral,neutral
303846418,Actually it looks like this is a symptom of a bug in the musicxml parser that sometimes leads to having a 0 in the numerator of the time signature. Ultimately we should fix that and remove this catch.,actually like symptom bug parser sometimes numerator time signature ultimately fix remove catch,issue,negative,neutral,neutral,neutral,neutral,neutral
303845172,"Here is the repository: https://github.com/herougo/magenta/
I mainly changed this file: https://github.com/herougo/magenta/blob/master/magenta/models/rl_tuner/rl_tuner.py. I added a reward function called ""reward_other"" at the bottom. I explicitly defined the chord progression to be C F G C and rewarded when notes match the current chord. Currently, the harmony rewards are commented out. But they were uncommented and given higher rewards for the Youtube video. 

I also experimented with other rewards such as penalizing high values of the total melody distance (summed absolute distances between consecutive notes). As a result, there were less leaps. I also penalized when the distance (interval) between the lowest note and highest note is too big.

Thanks for your interest!",repository mainly file added reward function bottom explicitly defined chord progression match current chord currently harmony uncommented given higher video also experimented high total melody distance summed absolute consecutive result le also distance interval note highest note big thanks interest,issue,positive,positive,positive,positive,positive,positive
303840228,Thanks for pointing this out. I will fix it shortly by modifying it as you did.,thanks pointing fix shortly,issue,negative,positive,neutral,neutral,positive,positive
303839230,"Very nice! Could you provide some more details? Did you add the chord
harmonies yourself?

On Tue, May 23, 2017 at 7:39 PM herougo <notifications@github.com> wrote:

> I experimented with the RL tuning algorithm. Here are some preliminary
> results: https://www.youtube.com/watch?v=6O6Aatj9sfY.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/608#issuecomment-303601745>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6Nf05vti1vWV0tyKsx-XgL_D7lLdks5r85hTgaJpZM4NK88W>
> .
>
",nice could provide add chord tue may wrote experimented tuning algorithm preliminary thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
303601745,I experimented with the RL tuning algorithm. Here are some preliminary results: https://www.youtube.com/watch?v=6O6Aatj9sfY.,experimented tuning algorithm preliminary,issue,negative,neutral,neutral,neutral,neutral,neutral
303316590,"Grand, cheers for clarifying.

On Mon, 22 May 2017, 21:45 Jesse Engel, <notifications@github.com> wrote:

> Closed #646 <https://github.com/tensorflow/magenta/issues/646>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/646#event-1092530485>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ADXIc9EGAHmNC7ufMzUIafxMqGwLgkmxks5r8fP2gaJpZM4NeE8k>
> .
>
",grand mon may wrote closed thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
303217695,"Sorry it doesn't work for what you want. In terms of creating new samples, we should have code to allow for creating your own samples into the repo soon. ",sorry work want new code allow soon,issue,negative,negative,negative,negative,negative,negative
303216540,"Sorry you're having trouble with the plugin. I'm not sure why it would require 9.7.2 besides being made with the most recent version of live. I know it's not exactly what you're asking, but if you do have 9.6 you should be able to upgrade to the most recent version of live for free https://www.ableton.com/en/help/article/latest-live-version/.",sorry trouble sure would require besides made recent version live know exactly able upgrade recent version live free,issue,negative,positive,positive,positive,positive,positive
303215149,"Hi James, 

That's not a mistake, different instruments have different amounts of pitches and velocities available to them. As it says on the dataset page:

""Some instruments are not capable of producing all 88 pitches in this range, resulting in an average of 65.4 pitches per instrument. Furthermore, the commercial sample packs occasionally contain duplicate sounds across multiple velocities, leaving an average of 4.75 unique velocities per pitch.""

If a sound had no variation across velocity, we only included the highest velocity, which is 127 as MIDI is 7-bit.",hi mistake different different available page capable range resulting average per instrument furthermore commercial sample occasionally contain duplicate across multiple leaving average unique per pitch sound variation across velocity included highest velocity,issue,negative,positive,neutral,neutral,positive,positive
302772099,Sorry about that. We hadn't yet updated the pip package to include sketch_rnn. It should be available now if you upgrade to the latest version (pip install -U magenta).,sorry yet pip package include available upgrade latest version pip install magenta,issue,negative,positive,positive,positive,positive,positive
302767412,@somah1411 it looks like you're running something called `dual learning/src/train.py`. Is this code from Magenta or something else?,like running something dual code magenta something else,issue,negative,neutral,neutral,neutral,neutral,neutral
302752696,The skip_first_n_losses bug should have been fixed by #551. Are you still having problems? Are you using the latest pip package?,bug fixed still latest pip package,issue,negative,positive,positive,positive,positive,positive
302137795,It appears some instruments only have one velocity (127 - the max). Another example is `organ_electronic_110`. I don't think this is explicitly stated in the documentation here (but could be wrong!): https://magenta.tensorflow.org/datasets/nsynth. I was expecting 5 velocities per note where some are duplicates.,one velocity another example think explicitly stated documentation could wrong per note,issue,negative,negative,negative,negative,negative,negative
300639326,"To clarify, I do not mean popularity prediction rating. That is a much more difficult and fuzzy task. I'm referring to a model which can distinguish between obviously bad music and real music (binary classification). For example, random notes would be bad and a Mozart sonata would be good. Generative adversarial networks could be one approach. One could also view ""pleasant music"" as coming from a particular probability distribution and bad melodies are anomalies.

I'm actually working on a repository (https://github.com/herougo/MusicGenerationWithML) which uses a music rating prediction model as rewards for a reinforcement learning algorithm. It's currently in progress, but I found some interesting features. ",clarify mean popularity prediction rating much difficult fuzzy task model distinguish obviously bad music real music binary classification example random would bad sonata would good generative could one approach one could also view pleasant music coming particular probability distribution bad actually working repository music rating prediction model reinforcement learning algorithm currently progress found interesting,issue,negative,negative,neutral,neutral,negative,negative
300537056,"fyi - I have an inception + swift + docker container talking together. 
 https://github.com/nubbel/swift-tensorflow/

I couldn't see any service layer inside magenta proto files / so haven't explored further with this. 
@adarob - was there any progress here?",inception swift docker container talking together could see service layer inside magenta proto progress,issue,positive,neutral,neutral,neutral,neutral,neutral
300476885,"wow, sounds like a hard task. it feels like you're talking more about popularity prediction rating.  ",wow like hard task like talking popularity prediction rating,issue,positive,negative,neutral,neutral,negative,negative
300108845,"Yes, it works with the older version, thanks!",yes work older version thanks,issue,positive,positive,positive,positive,positive,positive
300063719,"hi @lakeinchina @guanjhensu 

What do you set for  `init_fn `?

Do you still use 
```
saver = tf.train.Saver(slim.get_variables('vgg_16'))

def init_fn(session):
      saver.restore(session, vgg.checkpoint_file())
```

Thanks a million",hi set still use saver session session thanks million,issue,negative,positive,positive,positive,positive,positive
300025110,This isn't fixed until we push a new pip package.,fixed push new pip package,issue,negative,positive,positive,positive,positive,positive
300022263,Where would the unit test go?,would unit test go,issue,negative,neutral,neutral,neutral,neutral,neutral
300013641,"It looks like mido has changed things a bit. Can you try installing the older version to see if it works:

pip install mido==1.1.17 --force-reinstall",like bit try older version see work pip install,issue,negative,positive,positive,positive,positive,positive
299922706,Good catch! Could you write a unit test to verify the fix?,good catch could write unit test verify fix,issue,negative,positive,positive,positive,positive,positive
299753729,The author email is incorrect so I will close this and create a new pull request with a correct email.,author incorrect close create new pull request correct,issue,negative,positive,positive,positive,positive,positive
299513665,"Ah, good catch. I'll take a look at that.",ah good catch take look,issue,negative,positive,positive,positive,positive,positive
299414198,"The hparams parsing issue fixing documented in #592 is only applied to the training and also needs applied on the generation part.
I did it and I can now generate.",issue fixing applied training also need applied generation part generate,issue,negative,neutral,neutral,neutral,neutral,neutral
299293344,"I actually had tried that, using this generation command instead:

```
python ${MAGENTA_PATH}/models/polyphony_rnn/polyphony_rnn_generate.py  --run_dir=${1}/run${2} --output_dir=${1}/generated --num_outputs=${3} --num_steps=128 \
--hparams=""{'batch_size':64,'rnn_layer_sizes':[64,64]}""\
--primer_pitches=${4} \
--condition_on_primer=true \
--inject_primer_during_generation=false
```
It yields exactly the same result. (Including the display of 'rnn_layer_sizes': [256, 256, 256])",actually tried generation command instead python exactly result display,issue,negative,positive,positive,positive,positive,positive
299288742,"Yes, that's the issue. You need to specify the same layer sizes via the hparams flag when you generate as when you trained.",yes issue need specify layer size via flag generate trained,issue,negative,neutral,neutral,neutral,neutral,neutral
299276717,"Sure thing!
I've been using some shell scripts to execute those commands, hence the ${n}, I guess the actual values are not relevant.

Training command:
`python ${MAGENTA_PATH}/models/polyphony_rnn/polyphony_rnn_train.py --run_dir=${1}/run${3} --sequence_example_file=${1}/tfSequences/training_poly_tracks.tfrecord --hparams=""{'batch_size':64,'rnn_layer_sizes':[64,64],'initial_learning_rate':0.0001}"" --num_training_steps=${4}`

Generation command:
```
python ${MAGENTA_PATH}/models/polyphony_rnn/polyphony_rnn_generate.py  --run_dir=${1}/run${2} --output_dir=${1}/generated --num_outputs=${3} --num_steps=128 \
--primer_pitches=${4} \
--condition_on_primer=true \
--inject_primer_during_generation=false
```

Generation traceback:

> INFO:tensorflow:hparams = {'rnn_layer_sizes': [256, 256, 256], 'decay_rate': 0.95, 'dropout_keep_prob': 1.0, 'batch_size': 1, 'decay_steps': 1000, 'clip_norm': 5, 'initial_learning_rate': 0.001, 'skip_first_n_losses': 10}
> WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fddfb80e690>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
> WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fddfb80e5d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
> WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fde05c6dd50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.
> INFO:tensorflow:Checkpoint used: ./2017_05_04//run1/train/model.ckpt-3122
> INFO:tensorflow:Restoring parameters from ./2017_05_04//run1/train/model.ckpt-3122
> 2017-05-04 20:47:29.315896: W tensorflow/core/framework/op_kernel.cc:1152] Not found: Key rnn/multi_rnn_cell/cell_2/basic_lstm_cell/weights not found in checkpoint
> 2017-05-04 20:47:29.320142: W tensorflow/core/framework/op_kernel.cc:1152] Not found: Key rnn/multi_rnn_cell/cell_2/basic_lstm_cell/biases not found in checkpoint
> Traceback (most recent call last):
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 265, in <module>
>     console_entry_point()
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 261, in console_entry_point
>     tf.app.run(main)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 257, in main
>     run_with_flags(generator)
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 227, in run_with_flags
>     generated_sequence = generator.generate(primer_sequence, generator_options)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 203, in generate
>     self.initialize()
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 149, in initialize
>     self._model.initialize_with_checkpoint(checkpoint_file)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/model.py"", line 63, in initialize_with_checkpoint
>     saver.restore(self._session, checkpoint_file)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1545, in restore
>     {self.saver_def.filename_tensor_name: save_path})
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 786, in run
>     run_metadata_ptr)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 994, in _run
>     feed_dict_string, options, run_metadata)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1044, in _do_run
>     target_list, options, run_metadata)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1064, in _do_call
>     raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.NotFoundError: Key rnn/multi_rnn_cell/cell_2/basic_lstm_cell/weights not found in checkpoint
> 	 [[Node: save/RestoreV2_7 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_7/tensor_names, save/RestoreV2_7/shape_and_slices)]]
> 
> Caused by op u'save/RestoreV2_7', defined at:
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 265, in <module>
>     console_entry_point()
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 261, in console_entry_point
>     tf.app.run(main)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 257, in main
>     run_with_flags(generator)
>   File ""/home/pierre/HumtapGit/magenta/magenta//models/polyphony_rnn/polyphony_rnn_generate.py"", line 227, in run_with_flags
>     generated_sequence = generator.generate(primer_sequence, generator_options)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 203, in generate
>     self.initialize()
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 149, in initialize
>     self._model.initialize_with_checkpoint(checkpoint_file)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/magenta/music/model.py"", line 60, in initialize_with_checkpoint
>     saver = tf.train.Saver()
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1139, in __init__
>     self.build()
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1170, in build
>     restore_sequentially=self._restore_sequentially)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 691, in build
>     restore_sequentially, reshape)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 407, in _AddRestoreOps
>     tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 247, in restore_op
>     [spec.tensor.dtype])[0])
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 669, in restore_v2
>     dtypes=dtypes, name=name)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
>     op_def=op_def)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
>     original_op=self._default_original_op, op_def=op_def)
>   File ""/home/pierre/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
>     self._traceback = _extract_stack()
> 
> NotFoundError (see above for traceback): Key rnn/multi_rnn_cell/cell_2/basic_lstm_cell/weights not found in checkpoint
> 	 [[Node: save/RestoreV2_7 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_7/tensor_names, save/RestoreV2_7/shape_and_slices)]]

I notice that at the beginning of the traceback of the generation part, it displays 'rnn_layer_sizes': [256, 256, 256] (while the training was actually done with size [64, 64]). Is it relevant?",sure thing shell execute hence guess actual relevant training command python generation command python generation warning object state soon use warning object state soon use warning object state soon use used found key found found key found recent call last file line module file line main file line run main file line main generator file line file line generate file line initialize file line file line restore file line run file line file line file line raise type message key found node defined file line module file line main file line run main file line main generator file line file line generate file line initialize file line saver file line file line build file line build reshape file line file line file line file line file line file line see key found node notice beginning generation part training actually done size relevant,issue,negative,positive,positive,positive,positive,positive
299257600,Can you include the commands you were using to train and generate? Also might as well include the traceback just to be sure.,include train generate also might well include sure,issue,positive,positive,positive,positive,positive,positive
299042114,"Ahaa. Solved the issue. It turns out that my text editor had decided to trick me.
Notice that one of the quotation marks differs from the other.
--primer_melody=“[60]""
",issue turn text editor decided trick notice one quotation,issue,negative,neutral,neutral,neutral,neutral,neutral
299031965,"After starting from scratch and reinstalling my VM I am back at my initial problem: The melody_rnn_generate doesn't generate melodies for me. I can use it to generate a bundle file just fine, which I did after training a network with 1000 steps and tried to feed it as input, but still nothing.

melody_rnn_generate \
--config=attention_rnn \
--bundle_file=/tmp/generatedbundle.mag \
--output_dir=/tmp/generated_midi \
--num_outputs=1 \
--num_steps=128 \
--primer_melody=“[60]"" 

There is no output or error message, just like it was stuck in a loop. Any ideas?
",starting scratch back initial problem generate use generate bundle file fine training network tried feed input still nothing output error message like stuck loop,issue,negative,positive,positive,positive,positive,positive
298974954,"Did a fresh install of the whole VM. 
Ran the script on the new machine, encountered it again. 
Changed the config and regenerated the dataset, got some other error.
Double checked my paths for the script.
Did an rm -rf for my /tmp/melody_rnn/logdir/

Applying these steps in no particular order fixed it for me.
(I have no idea which one of them was to blame).",fresh install whole ran script new machine got error double checked script particular order fixed idea one blame,issue,negative,positive,positive,positive,positive,positive
298711745,"Closed, because I decided to start from scratch.",closed decided start scratch,issue,negative,negative,neutral,neutral,negative,negative
298572216,"I believe the reason why we haven't seen generation implemented is because the wavenet code that google has developed for generating wavenet is so much faster than any open sourced code currently available. They would essentially be handing over one of their best AI technologies for speech synthesis over to their competitors.
Best option would probably be to implement fast-wavenet based generation but the code is very convoluted.
See:
https://github.com/ibab/tensorflow-wavenet",believe reason seen generation code generating much faster open code currently available would essentially one best ai speech synthesis best option would probably implement based generation code convoluted see,issue,positive,positive,positive,positive,positive,positive
298477544,It looks like the global step is being reported as the loss. Can you give the command line call that you used to produce this output and magenta commit number?,like global step loss give command line call used produce output magenta commit number,issue,negative,neutral,neutral,neutral,neutral,neutral
298414823,"Hi,
I think your issue is the spaces around the ""="". There shouldn't be any on either side.
-Adam",hi think issue around either side,issue,negative,neutral,neutral,neutral,neutral,neutral
298164011,@cghawthorne what would be the purpose of the text generation model? I'm interested in working on this. ,would purpose text generation model interested working,issue,negative,positive,positive,positive,positive,positive
298102548,"There is some code to reward the use of notes within the current key and for playing the tonic at times that make sense: https://github.com/tensorflow/magenta/blob/master/magenta/models/rl_tuner/rl_tuner.py#L1148

It would definitely be interesting to extend these rewards to include ideas like harmonic progression. If you want to try this out, we'd love to hear your results!",code reward use within current key tonic time make sense would definitely interesting extend include like harmonic progression want try love hear,issue,positive,positive,positive,positive,positive,positive
298099769,"The comment from @jsleep is correct. At this point, if you want to you nsynth, you'll need to use the dev environment. We hope to make nsynth easier to use in the future.",comment correct point want need use dev environment hope make easier use future,issue,positive,neutral,neutral,neutral,neutral,neutral
298093798,"Sorry about that, we accidentally moved some old blog posts to a new URL structure. We've pushed a change to fix this, so the original links should work again: https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn/
",sorry accidentally old new structure change fix original link work,issue,negative,positive,neutral,neutral,positive,positive
298090031,"I'm assuming that NSynth hasn't been released with the latest pip package
which is probably what was installed when you did the automatic
installation. If you want to use NSynth right now you will probably need to
follow the instructions for setting up the dev environment. I'm sure
they'll be releasing NSynth with the next pip package release once they
have tools to do more than just train and save audio embeddings with NSynth.

On Apr 28, 2017 12:31 PM, ""dinamix"" <notifications@github.com> wrote:

> Upon further inspection it seems like in my magenta models folder from my
> miniconda directory:
>
> ~/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models
>
> There is no nsynth directory. Is the nsynth code only available in the dev
> version. As mentioned, I used the automated build to make magenta.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/611#issuecomment-298087179>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AGPOikK53hhUjloF4YXt9jydsXT8Dxx6ks5r0j6dgaJpZM4NL39L>
> .
>
",assuming latest pip package probably automatic installation want use right probably need follow setting dev environment sure next pip package release train save audio wrote upon inspection like magenta folder directory directory code available dev version used build make magenta thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
298087179,"Upon further inspection it seems like in my magenta models folder from my miniconda directory:

~/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models

There is no nsynth directory. Is the nsynth code only available in the dev version. As mentioned, I used the automated build to make magenta.",upon inspection like magenta folder directory directory code available dev version used build make magenta,issue,negative,positive,positive,positive,positive,positive
297576749,I think this is a question about the nsynth code. @adarob or @jesseengel could you take a look?,think question code could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
297473636,"Magenta does not currently have any text generation models, but that's something we're interested in and would welcome pull requests for!",magenta currently text generation something interested would welcome pull,issue,positive,positive,positive,positive,positive,positive
296759172,"I am running into this issue as well. To perform image stylization on CPU, it is necessary to install tensorflow 1.0.1 instead of tensorflow 1.1.0",running issue well perform image stylization necessary install instead,issue,negative,neutral,neutral,neutral,neutral,neutral
296410126,yes! this resolves my issues :) thanks so much for your help!,yes thanks much help,issue,positive,positive,positive,positive,positive,positive
296352871,"Perhaps this, since it's a bit different from the original implementation should be moved out to a separate method?",perhaps since bit different original implementation separate method,issue,negative,positive,positive,positive,positive,positive
296250856,You're right i trained melody_rnn for 100 iterations and loaded it into rl_tumer to test it and it worked without any problems ,right trained loaded test worked without,issue,negative,positive,positive,positive,positive,positive
296144036,Perhaps it could be resolved using sigmoid output with every pitch/note encoded as multi-class labels. That way we could keep the 16th note resolution which helps inform the RNN of rhythmic patterns,perhaps could resolved sigmoid output every way could keep th note resolution inform rhythmic,issue,negative,neutral,neutral,neutral,neutral,neutral
296143467,"Would be interesting to create a embedding<->midi autoencoder
If we have midi notes we could probably find such a correlation 
@visualex 
the embeddings are learned, see autoencoders, so it is possible that the note isn't represented by the embeddings in an intuitive way allowing for reconstruction",would interesting create could probably find correlation learned see possible note intuitive way reconstruction,issue,positive,positive,positive,positive,positive,positive
296039772,"I have a problem like this ,too.
It happens on restoring variables from checkpoint, maybe the codes needs the old version tensor flow to run
saver.restore(self.session, checkpoint_file) does not have a correct result",problem like maybe need old version tensor flow run correct result,issue,negative,positive,neutral,neutral,positive,positive
295010604,"has anyone got a wave embedding we can take a look at? 
generating midi is what comes first to my mind",anyone got wave take look generating come first mind,issue,negative,positive,positive,positive,positive,positive
295004527,"I also have this question. the NSynth README describes how to train, and how to save embeddings, but not how to generate audio from those embeddings (unless I am missing something). Could someone shed some light on this process? Thanks!",also question train save generate audio unless missing something could someone shed light process thanks,issue,positive,positive,positive,positive,positive,positive
293434794,"My bad, it was building a target that wasn't there in NSynth. This should be fixed now.",bad building target fixed,issue,negative,negative,negative,negative,negative,negative
293045412,This should have been fixed by #551. Can you verify that you're using the latest release of Magenta?,fixed verify latest release magenta,issue,negative,positive,positive,positive,positive,positive
293004591,Looks like an issue with the nsynth BUILD file.,like issue build file,issue,negative,neutral,neutral,neutral,neutral,neutral
293003234,The Dockerfile used to build the container is available here: https://github.com/tensorflow/magenta/tree/master/magenta/tools/docker,used build container available,issue,negative,positive,positive,positive,positive,positive
292875113,"- You can use MSCOCO image data instead of ImageNet.
- Just rewrite build imagenet data file in github about inception net. ",use image data instead rewrite build data file inception net,issue,negative,neutral,neutral,neutral,neutral,neutral
292819447,"Sure, I know this repository and I used it. But there is no way to know before running the container which version of tensorflow is used and how the container is built.",sure know repository used way know running container version used container built,issue,negative,positive,positive,positive,positive,positive
292800088,"Download a pre-made docker instance for magenta.
https://hub.docker.com/r/tensorflow/magenta/

you'll need to install docker.",docker instance magenta need install docker,issue,negative,neutral,neutral,neutral,neutral,neutral
292784538,"You can use this repository.

[tensorflow/magenta](https://hub.docker.com/r/tensorflow/magenta/tags/)

Following is my application's docker file that uses above magenta container.

[icoxfog417/magenta_session](https://github.com/icoxfog417/magenta_session/blob/master/Dockerfile)
",use repository following application docker file magenta container,issue,negative,neutral,neutral,neutral,neutral,neutral
291925593,I think python may be getting its import path confused between the pip package and the python files in your current directory. Can you try changing to another directory outside of your magenta build directory so that python will use the files from the pip package?,think python may getting import path confused pip package python current directory try another directory outside magenta build directory python use pip package,issue,negative,negative,negative,negative,negative,negative
290298947,"I am also having the problem of hparams taking no effect. Mac OSx. I used the provided script to install everything. No matter what my --hparams is defined to be, I am getting a log that prints:
INFO:tensorflow:hparams = {'rnn_layer_sizes': [256, 256, 256], 'decay_rate': 0.95, 'dropout_keep_prob': 0.5, 'batch_size': 64, 'decay_steps': 1000, 'clip_norm': 5, 'initial_learning_rate': 0.001, 'skip_first_n_losses': 10}

And training runs forever... even if I tell it to run 1 training step
",also problem taking effect mac used provided script install everything matter defined getting log training forever even tell run training step,issue,negative,neutral,neutral,neutral,neutral,neutral
290152858,You need to specify a valid config option. The `...` in the docs is meant as an example. The docs on the melody model provide some more concrete examples: https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn,need specify valid option meant example melody model provide concrete,issue,negative,positive,positive,positive,positive,positive
290040309,"for the use of gpu : 
you can replace code in the image_stylization_transform.py :
```python
with tf.Graph().as_default(), tf.Session() as sess:
```
(line 86 and line 105) by
``` python 
device_t='/gpu:0'
g = tf.Graph()
soft_config = tf.ConfigProto(allow_soft_placement=True)
soft_config.gpu_options.allow_growth = True
with g.as_default(), g.device(device_t), \
        tf.Session(config=soft_config) as sess:
```
If it does not work, that's probably because you are using Anaconda and the tensorflow version installed by default in the environment **magenta**  does not support GPU. 
In this case, you need to reinstall tensorflow (make sure that cuda, cudnn are already well installed.)
enter the environment **magenta** by
`source activate magenta`
and then
`pip uninstall tensorflow`
if python 2.7 : 
`pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linu/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl`
if python 3.x :
please check [https://www.tensorflow.org/install/install_linux#installing_with_anaconda](url) for installing tensorflow by Anaconda with GPU support.
it works for me : 
```I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:

name: GeForce GTX 1080

major: 6 minor: 1 memoryClockRate (GHz) 1.7335

pciBusID 0000:03:00.0

Total memory: 7.92GiB

Free memory: 7.62GiB

I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 

I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 

I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)
```
hope that will help.",use replace code python sess line line python true sess work probably anaconda version default environment magenta support case need reinstall make sure already well enter environment magenta source activate magenta pip python pip install upgrade python please check anaconda support work found device name major minor total memory free memory device device name bus id hope help,issue,positive,positive,positive,positive,positive,positive
289846321,"Different issu, but …

$ bazel version
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:50:12 2017 (1489668612)
Build timestamp: 1489668612
Build timestamp as int: 1489668612

$ bazel run //magenta/models/melody_rnn:melody_rnn_generate -- --config=...
INFO: Found 1 target...
Target //magenta/models/melody_rnn:melody_rnn_generate up-to-date:
  bazel-bin/magenta/models/melody_rnn/melody_rnn_generate
INFO: Elapsed time: 1.651s, Critical Path: 0.68s

INFO: Running command line: bazel-bin/magenta/models/melody_rnn/melody_rnn_generate '--config=...'
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_generate.py"", line 246, in <module>
    console_entry_point()
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_generate.py"", line 242, in console_entry_point
    tf.app.run(main)
  File ""/Users/davidlaxer/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_generate.py"", line 223, in main
    config = melody_rnn_config_flags.config_from_flags()
  File ""/private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/execroot/magenta/bazel-out/local-opt/bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/__main__/magenta/models/melody_rnn/melody_rnn_config_flags.py"", line 136, in config_from_flags
    melody_rnn_model.default_configs.keys(), FLAGS.config))
magenta.models.melody_rnn.melody_rnn_config_flags.MelodyRnnConfigFlagsException: `--config` must be one of ['basic_rnn', 'attention_rnn', 'lookback_rnn']. Got ....
ERROR: Non-zero return code '1' from command: Process exited with status 1.
David-Laxers-MacBook-Pro:magenta davidlaxer$ 


> On Mar 28, 2017, at 10:25 AM, cghawthorne <notifications@github.com> wrote:
> 
> Closed #578 <https://github.com/tensorflow/magenta/issues/578> via #579 <https://github.com/tensorflow/magenta/pull/579>.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/578#event-1018989689>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i29PhduUk8IJ5BWSedTTIUBHADy0Wks5rqUKWgaJpZM4Mr5ML>.
> 

",different version build label build target build time mar build build run found target target time critical path running command line recent call last file line module file line main file line run main file line main file line must one got error return code command process status magenta mar wrote closed via reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
289836286,Hi @dbl001. We require Bazel 0.4.5 to use the dev environment. I'll update the readme to reflect this.,hi require use dev environment update reflect,issue,negative,neutral,neutral,neutral,neutral,neutral
289486129,Should now be fixed on master with pull request #573.  Thanks @astromme!,fixed master pull request thanks,issue,negative,positive,positive,positive,positive,positive
289345701,Thanks @spammy123.  I can confirm that patch will fix the problem.,thanks confirm patch fix problem,issue,negative,positive,positive,positive,positive,positive
288801160,Updated to handle non-note events. Can you take another look?,handle take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
288334618,"@xiesiyuan Hi,can you show us how to fix that bug?thank you~",hi show u fix bug thank,issue,negative,neutral,neutral,neutral,neutral,neutral
288251258,"Hey! Also good to hear from you, miss you guys. Can you take another look with the updated code?",hey also good hear miss take another look code,issue,negative,positive,positive,positive,positive,positive
288014132,"@xiesiyuan  Hi, Can you share how did you fix that bug?",hi share fix bug,issue,negative,neutral,neutral,neutral,neutral,neutral
287974136,Thanks a lot. It solves the big size problem!,thanks lot big size problem,issue,negative,positive,neutral,neutral,positive,positive
287843296,"This should be fixed by #565. You can try it out in our development environment, or we'll cut a new pip package soon.",fixed try development environment cut new pip package soon,issue,negative,positive,positive,positive,positive,positive
287839155,"Can you try downloading the latest version of bazel? When you posted, bazel 0.4.5 was only available as a release candidate.",try latest version posted available release candidate,issue,negative,positive,positive,positive,positive,positive
287838578,"The problem seems to be that the command isn't seeing anything for the `--input` flag. Looking at the command you pasted, it looks like the first dash is actually a unicode em-dash (0x2014) instead of just a normal dash (0x2d). I'm guessing you maybe pasted it into some sort of editor that turned the two dashes into an em-dash? Can you try typing the command manually instead of doing any pasting?",problem command seeing anything input flag looking command pasted like first dash actually instead normal dash guessing maybe pasted sort editor turned two try command manually instead pasting,issue,negative,positive,positive,positive,positive,positive
287824323,"This pull request appears to be empty, so I'm going to close it.",pull request empty going close,issue,negative,negative,neutral,neutral,negative,negative
287692827,"This code is real-time now, however, you need to fix 2 bugs before that.",code however need fix,issue,negative,neutral,neutral,neutral,neutral,neutral
287692545,"If you really want to train your owm model, you need to change some code for fixing some bug exists in this version. 

By the way, this code is forbidden for any commercial use without the author's permission.",really want train model need change code fixing bug version way code forbidden commercial use without author permission,issue,negative,positive,neutral,neutral,positive,positive
287590761,"Just for a test,I have a model trained,but the result is terrible.So I wanna see other's model for sure if it's my problem. ",test model trained result wan na see model sure problem,issue,negative,positive,positive,positive,positive,positive
287539672,"Thanks,
I modified the code based on comments.
Please check.",thanks code based please check,issue,positive,positive,positive,positive,positive,positive
287483360,Unfortunately this just masks the issue.  Pull request #563 should address the root cause.,unfortunately issue pull request address root cause,issue,negative,negative,negative,negative,negative,negative
287422398,This approach seems reasonable to me. @iansimon can you take a look too?,approach reasonable take look,issue,negative,positive,positive,positive,positive,positive
287418576,It looks like we aren't computing log likelihood for the priming portion of the sequence that's passed into evaluate_log_likelihood. @iansimon what was the intention here? Should we be calculating the likelihood of the priming sequence or skipping it during likelihood calculations?,like log likelihood priming portion sequence intention calculating likelihood priming sequence skipping likelihood,issue,negative,neutral,neutral,neutral,neutral,neutral
287411997,It looks like you're using a fairly old version of the code. Can you try syncing to head and trying again?,like fairly old version code try head trying,issue,negative,positive,neutral,neutral,positive,positive
287411548,Can you include the exact command you're running and the output it produces?,include exact command running output,issue,negative,positive,positive,positive,positive,positive
287407755,Magenta currently requires Python 2.7. I'd suggest setting up a 2.7 environment (you can use conda to do this without changing your system python version) and trying the installation again.,magenta currently python suggest setting environment use without system python version trying installation,issue,negative,neutral,neutral,neutral,neutral,neutral
287274481,"ok, i've read it. I guess the reason it can't find the package is that I am using Python 3.5, and i installed all requirements but still no luck. :'( 
",read guess reason ca find package python still luck,issue,negative,neutral,neutral,neutral,neutral,neutral
287262368,"modify image_stylization_train.py
```python
from tensorflow.contrib.framework.python.ops import variables

savertransformer = tf.train.Saver(variables.get_variables(""transformer""))
# Run training
slim.learning.train(
    train_op=train_op,
    logdir=os.path.expanduser(FLAGS.train_dir),
    master=FLAGS.master,
    is_chief=FLAGS.task == 0,
    number_of_steps=FLAGS.train_steps,
    init_fn=init_fn,
    saver=savertransformer,
    save_summaries_secs=FLAGS.save_summaries_secs,
    save_interval_secs=FLAGS.save_interval_secs)
```
 That will only save the transformer network,~20mb.
but I do not know where the remaining 13mb comes from.",modify python import transformer run training save transformer network know come,issue,negative,neutral,neutral,neutral,neutral,neutral
287231822,"I don't think you'll be able to run the MIDI interface on AWS. There may be a way to get it to run without a local soundcard, but I'm not sure how to set up all the components to work that way. I'd suggest either running it locally or just using the generation scripts rather than an interactive environment.

If you want an easy way to play around with an interactive Magenta environment, I'd also suggest you check out AI Duet: https://aiexperiments.withgoogle.com/ai-duet",think able run interface may way get run without local sure set work way suggest either running locally generation rather interactive environment want easy way play around interactive magenta environment also suggest check ai duet,issue,positive,positive,positive,positive,positive,positive
287225767,"Yes, please see our installation instructions here: https://github.com/tensorflow/magenta#python-pip",yes please see installation,issue,positive,neutral,neutral,neutral,neutral,neutral
287188791,"We've released version 0.1.10 of our pip package, which should solve these problems. We've also updated our development environment to fix the bazel import problems we were having (as long as you have Bazel 0.4.5). Can you try installing the latest version and see if you still have issues?",version pip package solve also development environment fix import long try latest version see still,issue,negative,positive,positive,positive,positive,positive
287188522,@DefinitlyEvil can you try installing the newly released 0.1.10 version of our pip package and see if you continue to have errors?,try newly version pip package see continue,issue,negative,positive,positive,positive,positive,positive
287188333,"We just released version 0.1.10 of the pip package, which should solve these problems.",version pip package solve,issue,negative,neutral,neutral,neutral,neutral,neutral
287104756,"Thanks for your comment! 
But is there any way to drop vgg out of the checkpoint?",thanks comment way drop,issue,negative,positive,positive,positive,positive,positive
286626235,"In previous code, if ""skip_first_n_losses"" is nonzero, the size was changed by slicing ""logits"" and ""labels"". This caused the size of ""labels_flat"" and the size of ""mask_flat"" to be different and an error occurred.
In this pull request, I did not slice ""logits"" and ""labels"". And solved it by filling in the first ""skip_first_n_losses"" of ""mask"" with 0.",previous code nonzero size slicing size size different error pull request slice filling first mask,issue,negative,positive,neutral,neutral,positive,positive
286621293,"Thanks for the quick response.  I installed bazel 0.4.5 but I'm still getting 7 failed tests which are   ValueError: Attempted relative import in non-package

I'm using tensorflow 1.0.1, bazel 0.4.5, and python 2.7.13 on Mac OS X.",thanks quick response still getting relative import python mac o,issue,negative,positive,positive,positive,positive,positive
286556167,"From my testing, the pull request https://github.com/tensorflow/magenta/pull/551 eliminates the skip_first_n_losses error. However, the hparams no effect problem is still yet to be solved.",testing pull request error however effect problem still yet,issue,negative,neutral,neutral,neutral,neutral,neutral
286358886,yes is there any news on magenta support python 3?,yes news magenta support python,issue,positive,neutral,neutral,neutral,neutral,neutral
286308486,"Similar issue with https://github.com/tensorflow/magenta/issues/549
This error can be avoided by changing the code in polyphony_model.py skip_first_n_losses to 0, though this isn't a good way to fix the issue.

It will be great if anyone can explain what skip_first_n_losses actually works? And why setting it 0 will fix this exception? Thanks.",similar issue error code though good way fix issue great anyone explain actually work setting fix exception thanks,issue,positive,positive,positive,positive,positive,positive
286245088,"I'm running into this as well.  I think this is related to https://github.com/tensorflow/magenta/issues/525

By default the polyphony model has `skip_first_n_losses` set to 10.  

I tried passing the hyperparms as a flag, (e.g.: `--hparams=""{'batch_size': 100, 'skip_first_n_losses':0}""` but I still get different parameters being printed when I call the train method, e.g.:
```
INFO:tensorflow:hparams = {'rnn_layer_sizes': [256, 256, 256], 'decay_rate': 0.95, 'dropout_keep_prob': 0.5, 'batch_size': 64, 'decay_steps': 1000, 'clip_norm': 5, 'initial_learning_rate': 0.001, 'skip_first_n_losses': 10...
```

So it seems there might be two potential issues, 1 as described in https://github.com/tensorflow/magenta/issues/525 w/ nonzero `skip_first_n_losses`, and another w/ setting `hparams` on the polyphony CLI interface for training.

It looks like `melody_rnn` uses the tf.app config FLAGs to read the hparams, and default to the magenta common params, and then parse any given params (see here: `magenta/magenta/models/melody_rnn/melody_rnn_config_flags.py`), but there is no code yet to do that in the polyphony rnn model.  A quick hack to at least get started with the model is to just change the default value for `skip_first_n_losses` to 0 in the file `magenta/models/polyphony_rnn/polyphony_model.py`.",running well think related default polyphony model set tried passing flag still get different printed call train method might two potential nonzero another setting polyphony interface training like read default magenta common parse given see code yet polyphony model quick hack least get model change default value file,issue,positive,negative,neutral,neutral,negative,negative
286174707,"@neovaldivia the MIDI interface instructions assume you are using a local machine with a local display. If you're running vmpk remotely, you'll need to set up some sort of tunneling for both X and sound.",interface assume local machine local display running remotely need set sort tunneling sound,issue,negative,positive,neutral,neutral,positive,positive
286002317,"@terraxoxo Sorry I can't give my name(privacy ;) ) but I can explain more. See, the machine (neural network) is completely blank and don't know anything about music. When you throw them with some midi files within specific era, it will learn from patterns from it but no one can explain how it works because everything are just weights. So it might or might not be able to learn the harmonies hidden inside a piece. I was planning to train it with Bach's French suite, but I ran into errors. 
",sorry ca give name privacy explain see machine neural network completely blank know anything music throw within specific era learn one explain work everything might might able learn hidden inside piece train bach suite ran,issue,negative,negative,neutral,neutral,negative,negative
285957559,"Hi,,, Evill?
Thank you for message...but I don't understand exactly what you are
saying..? can you give me more informations..? thank you very much. ^^ and
can you let me know your name..? terra, xoxo.

On Sun, Mar 12, 2017 at 8:32 PM, The Evil Man <notifications@github.com>
wrote:

> @terraxoxo <https://github.com/terraxoxo> I am in a music college
> majoring music composing haha, but I am a self-taught programmer as well.
> You can do anything with this library I think. You could throw them midi
> files and they can imitate the exact type of music, as for asian music,
> just throw them asian music midi files.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/402#issuecomment-285938544>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AWeUhMXjdqqNwEjkKDPJKzo45DDNo8I-ks5rk9fBgaJpZM4K3IsG>
> .
>
",hi thank message understand exactly saying give thank much let know name sun mar evil man wrote music college music programmer well anything library think could throw imitate exact type music music throw music reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
285938544,"@terraxoxo I am in a music college majoring music composing haha, but I am a self-taught programmer as well. You can do anything with this library I think. You could throw them midi files and they can imitate the exact type of music, as for asian music, just throw them asian music midi files. 
",music college music programmer well anything library think could throw imitate exact type music music throw music,issue,negative,positive,positive,positive,positive,positive
285910749,"This has been fixed, it was a python version issue",fixed python version issue,issue,negative,positive,neutral,neutral,positive,positive
285897969,"Excuse me, can you explain how you solved this problem cause I meet the same problem now",excuse explain problem cause meet problem,issue,negative,negative,neutral,neutral,negative,negative
285892408,"I have similar issue when trying to start interactive magenta_midi session with **polyphony_rnn** model.

Edit: After reading #123 I see there is no way this could work now, but I leave the comment here for the stack trace which could still be helpful.

Command: `magenta_midi   --input_port=""Impulse:Impulse MIDI 1 20:0""   --output_port=""FLUID Synth (4378):Synth input port (4378:0) 129:0""   --bundle_files=/tmp/polyphony_rnn.mag`

Output: 
```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 950M
major: 5 minor: 0 memoryClockRate (GHz) 0.928
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.57GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0)
Loaded 'polyphony' generator bundle from file '/tmp/polyphony_rnn.mag'.

Instructions:
Start playing  when you want to begin the call phrase.
When you want to end the call phrase, stop playing and wait one clock tick.
Once the response completes, the interface will wait for you to begin playing again to start a new call phrase.

To end the interaction, press CTRL-C.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArray is deprecated. It will cease to work in GraphDef version 16. Use TensorArrayV2.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArraySize is deprecated. It will cease to work in GraphDef version 16. Use TensorArraySizeV2.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArrayScatter is deprecated. It will cease to work in GraphDef version 16. Use TensorArrayScatterV2.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArrayRead is deprecated. It will cease to work in GraphDef version 16. Use TensorArrayReadV2.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArrayWrite is deprecated. It will cease to work in GraphDef version 16. Use TensorArrayWriteV2.
W tensorflow/core/framework/op_def_util.cc:332] Op TensorArrayGather is deprecated. It will cease to work in GraphDef version 16. Use TensorArrayGatherV2.
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/interfaces/midi/midi_interaction.py"", line 447, in run
    response_start_time + response_duration)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/interfaces/midi/midi_interaction.py"", line 338, in _generate
    adjust_sequence_times(input_sequence, -zero_time), generator_options)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/music/sequence_generator.py"", line 204, in generate
    return self._generate(input_sequence, generator_options)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/polyphony_rnn/polyphony_sequence_generator.py"", line 172, in _generate
    len(poly_seq) + rnn_steps_to_gen, poly_seq, **args)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/polyphony_rnn/polyphony_model.py"", line 54, in generate_polyphonic_sequence
    modify_events_callback=modify_events_callback)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 409, in _generate_events
    control_events, modify_events_callback)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 343, in _beam_search
    final_state, temperature)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 214, in _generate_branches
    all_event_sequences, all_inputs, all_final_state, temperature)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 153, in _generate_step
    temperature)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/shared/events_rnn_model.py"", line 111, in _generate_step_for_batch
    event_sequences, softmax)
  File ""/home/lukas/libs/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/music/encoder_decoder.py"", line 291, in evaluate_log_likelihood
    loglik += np.log(softmax[i][position][index])
IndexError: index 4 is out of bounds for axis 0 with size 4
```",similar issue trying start interactive session model edit reading see way could work leave comment stack trace could still helpful command impulse impulse fluid input port output successfully library locally successfully library locally successfully library locally successfully library locally successfully library locally successful node read negative value must least one node node zero found device name major minor total memory free memory device device name bus id loaded generator bundle file start want begin call phrase want end call phrase stop wait one clock tick response interface wait begin start new call phrase end interaction press cease work version use cease work version use cease work version use cease work version use cease work version use cease work version use exception thread recent call last file line file line run file line file line generate return file line file line file line file line temperature file line temperature file line temperature file line file line position index index axis size,issue,positive,positive,positive,positive,positive,positive
285799734,"I ran into the same problem, and it turns out the #535 fix was incomplete. This patch fixes it for the dict based styles:

```
--- a/magenta/models/image_stylization/ops.py
+++ b/magenta/models/image_stylization/ops.py
@@ -103,10 +103,10 @@ def conditional_instance_norm(inputs,
     beta, gamma = None, None
     if center:
       beta = _label_conditioned_variable(
-          'beta', tf.zeros_initializer, labels, num_categories)
+          'beta', tf.zeros_initializer(), labels, num_categories)
     if scale:
       gamma = _label_conditioned_variable(
```",ran problem turn fix incomplete patch based beta gamma none none center beta scale gamma,issue,negative,negative,neutral,neutral,negative,negative
285411756,"Thanks to work from the Bazel team, we now have a workaround (#547). It requires Bazel 0.4.5, which is not yet released, but if you want to try it out, you can download a release candidate. I'll submit the CL once the release is officially available.",thanks work team yet want try release candidate submit release officially available,issue,negative,positive,positive,positive,positive,positive
285251593,"I found that problem right now!!Because if you install the magenta right now,the version of tensorflow is 1.00(default), But the code is using tensorflow0.12 ,So we must `pip uninstall tensorflow`and `pip install tensorflow==0.12.0`;That 's all

If you still wanna use tensorflow1.0,try this 

> ;In the short-term (before 1.0 final happens) concat_v2 will be the function to use. Once 1.0 final happens, concat_v2() will be renamed to concat() and then what used to be concat() will cease to exist.

 https://github.com/tensorflow/tensorflow/issues/6345
",found problem right install magenta right version default code must pip pip install still wan na use try final function use final used cease exist,issue,negative,positive,neutral,neutral,positive,positive
285250344,"Traceback (most recent call last):
  File ""/Users/DOVAN/anaconda2/envs/magenta/bin/image_stylization_transform"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py"", line 144, in console_entry_point
    tf.app.run(main)
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py"", line 135, in main
    _multiple_images(image, which_styles, output_dir)
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py"", line 88, in _multiple_images
    tf.concat_v2([input_image for _ in range(len(which_styles))], 0),
AttributeError: 'module' object has no attribute 'concat_v2'

When I try to do this:
(magenta) DOVANtekiMacBook-Pro:/ DOVAN$ sudo image_stylization_transform       --num_styles=10       --checkpoint=/Users/DOVAN/Downloads/multistyle-pastiche-generator-monet.ckpt       --input_image=/Users/DOVAN/Desktop/photo.jpg       —which_styles=""{0:0.1,1:0.1,2:0.1,3:0.1,4:0.1,5:0.1,6:0.1,7:0.1,8:0.1,9:0.1}
""       --output_dir=/Users/DOVAN/Desktop/       --output_basename=""stylized""


It appear a new error :AttributeError: 'module' object has no attribute 'concat_v2'
 How to slove it~",recent call last file line module file line main file line run main file line main image file line range object attribute try magenta appear new error object attribute,issue,negative,positive,positive,positive,positive,positive
285243981,"I have search many information about this,but It still no work~ Can you tell me what this error means particularly? 'NoneType' object has no attribute 'startswith'.  Sincerely~",search many information still tell error particularly object attribute,issue,negative,positive,positive,positive,positive,positive
284915021,"@nikhilweee I installed magenta with `pip install magenta`, and I found that on this [pypi site](https://pypi.python.org/pypi/magenta) the update date is ""2017-01-27"", so the pip version doesn't include the latest fix. But at this moment I don't know how to manully install the latest version, how do you install magenta?",magenta pip install magenta found site update date pip version include latest fix moment know install latest version install magenta,issue,negative,positive,positive,positive,positive,positive
284814701,@EncodeTS: But what does pip have to do with it? I have the magenta repo cloned locally and also Tensorflow was installed via a URL. Neither of these depend on pip. Am I missing something here?,pip magenta locally also via neither depend pip missing something,issue,negative,negative,neutral,neutral,negative,negative
284464564,"I do have Tensorflow installed: 
```
Python 2.7.13 |Continuum Analytics, Inc.| (default, Dec 20 2016, 23:05:08)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://anaconda.org
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))
Hello, TensorFlow!
>>>
```

No problems when running this. ",python analytics default compatible apple type help copyright license information anaconda brought continuum analytics please check import hello sess print hello hello running,issue,positive,neutral,neutral,neutral,neutral,neutral
284463036,"It looks like you don't have TensorFlow installed. There are instructions to do so in the README.
Let us know if you still have issues after that.",like let u know still,issue,negative,neutral,neutral,neutral,neutral,neutral
284429365,"That looks to me like a different error, where the `path` module in `posixpath.py` is somehow `None`.",like different error path module somehow none,issue,negative,neutral,neutral,neutral,neutral,neutral
284368034,"Traceback (most recent call last):
  File ""/Users/DOVAN/anaconda2/envs/magenta/bin/image_stylization_transform"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py"", line 144, in console_entry_point
    tf.app.run(main)
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/image_stylization/image_stylization_transform.py"", line 127, in main
    os.path.expanduser(FLAGS.input_image)), 0)
  File ""/Users/DOVAN/anaconda2/envs/magenta/lib/python2.7/posixpath.py"", line 254, in expanduser
    if not path.startswith('~'):
AttributeError: 'NoneType' object has no attribute 'startswith'


I have try tensorflow0.12.0 and tensorflow 1.0,it still no work~",recent call last file line module file line main file line run main file line main file line object attribute try still,issue,negative,positive,neutral,neutral,positive,positive
284214230,"@nikhilweee 
I found that the pip version isn't the latest version, maybe we should manually install it...",found pip version latest version maybe manually install,issue,negative,positive,positive,positive,positive,positive
284162304,"Hi!
You can hear the melody generated by this option(primer_melody=""[60,60,-1,60,59,60,60,60,-2,60,64,-2,62,-2,60,-2]"") in soundcloud.
https://soundcloud.com/ig4osq8tqokz/dilatedcnnmagentademo",hi hear melody option,issue,negative,neutral,neutral,neutral,neutral,neutral
284141564,"I'm facing the same issue even after #535 
I'm using tensorflow 1.0.0 for gpu installed via pip.
Any leads would be appreciated.",facing issue even via pip would,issue,negative,neutral,neutral,neutral,neutral,neutral
283791186,"Is there any chance you're accidentally referencing a directory with a checkpoint that was trained with a different network size? This is the important error from the stacktrace:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [128,40] rhs shape= [64,40]
```

It seems to imply that the network you've constructed doesn't match the checkpoint you're trying to restore.",chance accidentally directory trained different network size important error assign match imply network match trying restore,issue,negative,positive,positive,positive,positive,positive
283789823,"Hi @YoshikawaMasashi, this looks really interesting! Do you have any example outputs of this model?",hi really interesting example model,issue,negative,positive,positive,positive,positive,positive
283467253,"In case anyone else runs into this before its fixed, I was able to get around this issue w/ the most recent magenta installed via pip by uninstalling tensorflow 1.0 and instead installing tensorflow 0.12. :

```bash
pip install magenta
pip uninstall tensorflow
#pip uininstall tensorflow-gpu # uncomment if using gpu
pip install tensorflow==0.12.0
#pip install tensorflow-gpu==0.12.0 # uncomment if using gpu
```
",case anyone else fixed able get around issue recent magenta via pip instead bash pip install magenta pip pip pip install pip install,issue,negative,positive,positive,positive,positive,positive
283417350,"@mattetti in the [dev environment setup instructions](https://github.com/tensorflow/magenta#development-environment), we suggest looking at dependency list in setup.py for what to install. That should cover intervaltree, but you're right that we're currently missing IPython form that list. We'll get that fixed.",dev environment setup suggest looking dependency list install cover right currently missing form list get fixed,issue,negative,positive,neutral,neutral,positive,positive
283413079,"We've been using http://www.akaipro.com/product/mpk-mini-mkii in the office and for some of our demos, and it's worked well for us.",office demo worked well u,issue,negative,neutral,neutral,neutral,neutral,neutral
283214147,"Just to update from the email thread:

I chatted with @kchodorow earlier today, and there's not a good workaround that doesn't involve modifying dependencies. The problem should be solved in Bazel 0.5, which should hopefully be released in a week or so.

@PeterMitrano you could try going back to cbee9fa, but you'll also need to make sure you're using a version of TensorFlow earlier than 1.0.",update thread today good involve problem hopefully week could try going back also need make sure version,issue,positive,positive,positive,positive,positive,positive
283208565,"can confirm, works for me. tested with [this code](https://gist.github.com/PeterMitrano/5575de94ae96edbc50e99dca84870e2e)",confirm work tested code,issue,negative,neutral,neutral,neutral,neutral,neutral
282877268,"Yes, you are correct. Unfortunately we need to figure out a solution to #529 before we cut a new release. I'm hoping that will be very soon.",yes correct unfortunately need figure solution cut new release soon,issue,negative,negative,negative,negative,negative,negative
282645094,"I tried to agree to the CLA (Google Individual Contributor License Agreement), but at that time I got an error message ""You must be an owner of the contributors group in order to submit this CLA"".
What is the contributors group?
And how can I submit this CLA?",tried agree individual contributor license agreement time got error message must owner group order submit group submit,issue,negative,neutral,neutral,neutral,neutral,neutral
282643524,"http://www.akaipro.com/product/lpk25

This one is good.
Wait till you see it on sale for 40 - 50 dollars.",one good wait till see sale,issue,negative,positive,positive,positive,positive,positive
282523986,"@arijit17 That would be once all of Magenta's source code has been translated to Python 3, which is probably not at the top of the priority list. ",would magenta source code python probably top priority list,issue,negative,positive,positive,positive,positive,positive
282431485,"Sorry for the long delay Rishab!

I'd look at how our current models work to see if it would be as easy as adding the GAN as an option during training. That would enable us to keep using all of the generation APIs and interfaces.",sorry long delay look current work see would easy gan option training would enable u keep generation,issue,negative,negative,neutral,neutral,negative,negative
281428857,"Hi @Lizzard13, I'm not very familiar with this part of the code, but are I believe it that particular test is for the compressed version of MusicXML (http://www.musicxml.com/tutorial/compressed-mxl-files/). Please re-open if I'm wrong. Thanks!",hi familiar part code believe particular test compressed version please wrong thanks,issue,negative,positive,neutral,neutral,positive,positive
280939599,"Also, is there a commit/version I can go back to that will allow me to use magenta without this issue?",also go back allow use magenta without issue,issue,negative,neutral,neutral,neutral,neutral,neutral
280939275,"This seems to be a blocking issue for not just unit tests. I get this same error when trying to use one of the generators:

    bazel-bin/magenta/models/melody_rnn/melody_rnn_generate --config=lookback_rnn --bundle_file=${PWD}/bundles/lookback_rnn.mag --output_dir=${PWD}/generated --primer_melody=""[60]""",blocking issue unit get error trying use one,issue,negative,neutral,neutral,neutral,neutral,neutral
280389246,"@brisker there are a few things you could try:
- revert your git repo to cbee9fa (before the changes to use the new TensorFlow API) and use a version of TensorFlow older than 1.0
- locally build and install a Magenta pip package with your changes. the problems occur only when using the bazel wrappers around scripts and tests. building the pip package will let you run things outside of the bazel environment
- If you don't need to change any of the core Magenta libraries, you could just install our pip package and develop your changes outside of the repo.

Sorry for these problems, we're working to get them resolved as soon as possible.",could try revert git use new use version older locally build install magenta pip package occur around building pip package let run outside environment need change core magenta could install pip package develop outside sorry working get resolved soon possible,issue,negative,negative,neutral,neutral,negative,negative
280388194,"Hey Bob, you'll need to update your TensorFlow installation to the new 1.0 release. It has some API changes, and the latest git revision reflects those. Note that unfortunately this is also causing some (inaccurate) test failures. See #529 for details. If the test failures are causing you problems, you could also just reset your git repo to cbee9fa, which was before the API changes.",hey bob need update installation new release latest git revision note unfortunately also causing inaccurate test see test causing could also reset git,issue,negative,positive,neutral,neutral,positive,positive
280211898,"@cghawthorne 
So right now, I can do nothing?
Without testing pass, I can not run the demos and scripts?",right nothing without testing pas run demo,issue,negative,positive,positive,positive,positive,positive
280181019,"I believe this particular problem has been fixed by #527, so I'll go ahead and close this bug. However, I suspect you'll now see an error related to importing 'parser'. I'm tracking that in #529.",believe particular problem fixed go ahead close bug however suspect see error related,issue,negative,positive,neutral,neutral,positive,positive
280002808,"@cghawthorne
I have rewrote my error and my environment is Ubuntu14.04,titan x gpu, cuda 7.5 , bazel 0.4.4 and cudnn5.0. 
I install the development version of magenta and the process of my installing is:
1. install bazel
2. install tensorflow
3. git clone https://github.com/tensorflow/magenta.git
4. cd magenta
5. bazel test //magenta/...
and after step 5, the error occurs.
Is this because of the version of tensorflow?
My tensorflow is 1.0 rc2. What version of tensorflow does magenta prefer?",error environment install development version magenta process install install git clone magenta test step error version version magenta prefer,issue,negative,neutral,neutral,neutral,neutral,neutral
279794996,"Can you give some more details about your environment? What version of magenta do you have installed, are you in the development environment? In what context are you trying to import magenta.protobuf?",give environment version magenta development environment context trying import,issue,negative,neutral,neutral,neutral,neutral,neutral
279793941,"Based on the anaconda bug tracker, this may be caused by a conflict with other python package management setups: https://github.com/ContinuumIO/anaconda-issues/issues/416 Could you try out the solutions mentioned in that thread?",based anaconda bug tracker may conflict python package management could try thread,issue,negative,neutral,neutral,neutral,neutral,neutral
279619450,"**open the file**  ""/home/jcc/.cache/bazel/_bazel_jcc/ed5599de3378c6e0a5a71ebe1650713e/external/protobuf/**protobuf.bzl**""
than, **relpace** **HOST_CFG** to '**host**' ,   notice the '**host**' with **' '**,  and **run test again** just fine for me solve this problem    
",open file host notice host run test fine solve problem,issue,negative,positive,positive,positive,positive,positive
279543359,"I think the example in the documentation assumes that the first four notes of ""Twinkle Twinkle, Little Star"" are eighth notes. The example you gave looks correct if you want them to be quarter notes instead. I'd suggest trying both and seeing what kind of output you get either way.",think example documentation first four twinkle twinkle little star eighth example gave correct want quarter instead suggest trying seeing kind output get either way,issue,positive,positive,positive,positive,positive,positive
279511348,"Ah, thank you @cghawthorne, I haven't used docstrings much and didn't know that. Sorry for adding noise.",ah thank used much know sorry noise,issue,negative,negative,negative,negative,negative,negative
279506080,"In this case, the `r` indicates that the following string is a raw string: https://docs.python.org/2.7/reference/lexical_analysis.html#string-literals

We tend to do this for our docstrings in case the string contains code or command line snippets.",case following string raw string tend case string code command line,issue,negative,negative,negative,negative,negative,negative
279499763,They're something my editor did automatically. I figured might as well keep them since the attributes are now in a predictable order.,something editor automatically figured might well keep since predictable order,issue,negative,negative,negative,negative,negative,negative
279157997,"@nathanielatom 
Ubuntu 14.04 Python2.7 bazel 0.4.4, error when test magenta:
jcc@jcc:~/magenta$ bazel test //magenta:all
ERROR: /home/jcc/.cache/bazel/_bazel_jcc/ed5599de3378c6e0a5a71ebe1650713e/external/protobuf/protobuf.bzl:91:19: name 'HOST_CFG' is not defined.
ERROR: /home/jcc/magenta/magenta/BUILD:21:1: error loading package 'magenta/protobuf': Extension 'protobuf.bzl' has errors and referenced by '//magenta:magenta'.
ERROR: Analysis of target '//magenta:magenta' failed; build aborted.
INFO: Elapsed time: 0.155s
ERROR: Couldn't start the build. Unable to run tests.
Could you please give some advice?",python error test magenta test error name defined error error loading package extension magenta error analysis target magenta build aborted time error could start build unable run could please give advice,issue,negative,negative,negative,negative,negative,negative
278176369,"Removed the superfluous references to `rnn_cell`. I hadn't noticed that ugliness became unnecessary.

I also fixed up a doc reference to `RnnCell`, which AFAICT should have been `RNNCell`.",removed superfluous ugliness unnecessary also fixed doc reference,issue,negative,negative,negative,negative,negative,negative
276450112,"OK, we'll probably wait until then so we can make sure our pip package is in a good state.",probably wait make sure pip package good state,issue,positive,positive,positive,positive,positive,positive
276243813,Do you know if it will be available on pypi at some point? We prefer if we can set things up so that `pip install magenta` just works.,know available point prefer set pip install magenta work,issue,negative,positive,positive,positive,positive,positive
276242962,"Sorry, I was actually wrong in my previous reply. 1.0.0rc0 is actually available as a pip package, but you would need to use one of the URLs listed here:
https://www.tensorflow.org/versions/r1.0/get_started/os_setup#pip_installation",sorry actually wrong previous reply actually available pip package would need use one listed,issue,negative,negative,negative,negative,negative,negative
276242081,"Yes, we need to be able to depend on a pip package listed in our setup.py: https://github.com/tensorflow/magenta/blob/master/magenta/tools/pip/setup.py#L31",yes need able depend pip package listed,issue,negative,positive,positive,positive,positive,positive
276241683,rc0 won't be available as a pip package. Next release that will be available as a pip package will be 1.0. Do you need pip package to have these changes?,wo available pip package next release available pip package need pip package,issue,negative,positive,positive,positive,positive,positive
276241459,"It looks like the latest release that has a pip package is 0.12.1. Do you know when 1.0.0-rc0 will be available as a pip package?

https://pypi.python.org/pypi/tensorflow",like latest release pip package know available pip package,issue,negative,positive,positive,positive,positive,positive
274290210,"Hey @adarob ,
I would like to take up this issue. I am currently reading the papers and implementations. Any suggestions for getting started?",hey would like take issue currently reading getting,issue,negative,neutral,neutral,neutral,neutral,neutral
273414931,I also want to know how to apply for realtime webcam,also want know apply,issue,negative,neutral,neutral,neutral,neutral,neutral
272852003,Does it mean once we have it Magenta will work on Windows 10 as well?,mean magenta work well,issue,negative,negative,negative,negative,negative,negative
270657959,@ZuzooVn you need to use ```git rebase``` instead of ```git merge``` to get rid of those **merge** commits,need use git rebase instead git merge get rid merge,issue,negative,neutral,neutral,neutral,neutral,neutral
270611833,"Currently Tensorflow for Windows is available only for Python 3.5, and Python 2.7 is not supported even when compiling from source (see e.g. [cmake instructions](https://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake)).
Thus, Windows support relies critically on the support for Python3 (see PR #461).",currently available python python even source see thus support critically support python see,issue,positive,positive,positive,positive,positive,positive
270262127,"Our build environment uses bazel, so you can't run the tests directly. To run the tests, you'll need to first install the [development environment](https://github.com/tensorflow/magenta/blob/master/README.md#development-environment) and then run ```bazel test //magenta/models/drums_rnn:drums_rnn_create_dataset_test```.",build environment ca run directly run need first install development environment run test,issue,negative,positive,positive,positive,positive,positive
269102275,"> It looks like your most recent error is from not passing the VGG checkpoint.

When I pass VGG and everything, I got the initial error. Currently I cannot finetune (with or without passing vgg checkpoint) on docker image.
",like recent error passing pas everything got initial error currently without passing docker image,issue,negative,neutral,neutral,neutral,neutral,neutral
269094556,"It looks like your most recent error is from not passing the VGG checkpoint.

Finetuning is very much like training, but instead of starting from scratch it starts with the weights of a pretrained model.  It still needs to use imagenet images as training data.",like recent error passing much like training instead starting scratch model still need use training data,issue,negative,positive,neutral,neutral,positive,positive
268890759,"@hanzorama , I still want to add this feature, but I think it might be worth rethinking a bit now that a lot of the code has changed significantly. We can also simplify things quite a bit now. You'll definitely need to merge with master or start a new branch.

I'm happy to take this on if you don't have time, but if you want to do it, it's all yours!
 
Here is a basic plan:
1. Add a small class that takes a dictionary mapping a string name to a cc number or None and returns an updated version of that dictionary. The class has a method that will enter a user feedback loop that prints the current mapping and allows the user to enter a number to update one of the values or quit. I know you already have something like this now, but I just want to simplify and clean it up a bit.

2. In magenta_midi, iterate through FLAGS, selecting those that end in _control_number and adding them to a dictionary. Before initializing the interaction, optionally pass this dictionary into the remap class based on user input (another flag? or maybe tell the user to press 'c' to map control changes or enter to start the interaction). After remapping, pass these values into the interaction and continue as usual.

Let me know if you have any Q's.",still want add feature think might worth bit lot code significantly also simplify quite bit definitely need merge master start new branch happy take time want basic plan add small class dictionary string name number none version dictionary class method enter user feedback loop current user enter number update one quit know already something like want simplify clean bit iterate end dictionary interaction optionally pas dictionary remap class based user input another flag maybe tell user press map control enter start interaction pas interaction continue usual let know,issue,positive,positive,positive,positive,positive,positive
268756591,"```
root@92a258e36b5c:/magenta-data# image_stylization_finetune \
>       --checkpoint=/magenta-data/multistyle-pastiche-generator-monet.ckpt \
>       --train_dir=/magenta-data/train/style/images_4 \
>       --style_dataset_file=/magenta-data/train/style/style_images_4.tfrecord \
>       --num_styles=4 \
>       --imagenet_data_dir=/imagenet_data
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_utils.py:136 in imagenet_inputs.: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.image. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py:344 in __init__.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.
Traceback (most recent call last):
  File ""/usr/local/bin/image_stylization_finetune"", line 11, in <module>
    sys.exit(console_entry_point())
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py"", line 166, in console_entry_point
    tf.app.run(main)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py"", line 162, in main
    save_interval_secs=FLAGS.save_interval_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 766, in train
    master, start_standard_services=False, config=session_config) as sess:
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 974, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 802, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 963, in managed_session
    start_standard_services=start_standard_services)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 720, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 235, in prepare_session
    init_fn(sess)
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py"", line 144, in init_fn
    init_fn_vgg(session)
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py"", line 134, in init_fn_vgg
    saver_vgg.restore(session, vgg.checkpoint_file())
  File ""/usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/vgg.py"", line 38, in checkpoint_file
    return os.path.expanduser(FLAGS.vgg_checkpoint)
  File ""/usr/lib/python2.7/posixpath.py"", line 261, in expanduser
    if not path.startswith('~'):
AttributeError: 'NoneType' object has no attribute 'startswith'
```
@iansimon Could you take a look ?
",root warning removed please switch note node name instead tag automatically summary based scope also argument warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning removed please switch interface behavior rename recent call last file line module file line main file line run main file line main file line train master sess file line return file line file line stop file line join file line file line file line sess file line session file line session file line return file line object attribute could take look,issue,negative,positive,positive,positive,positive,positive
268755260,"I want to finetune..

This is what I am using:

```
image_stylization_finetune \
      --checkpoint=/magenta-data/multistyle-pastiche-generator-monet.ckpt \
      --train_dir=/magenta-data/train/style/images_4 \
      --style_dataset_file=/magenta-data/train/style/style_images_4.tfrecord \
      --num_styles=4 \
      --vgg_checkpoint=/magenta-data/train/vgg_16.ckpt \
      --imagenet_data_dir=/imagenet_data
```

This is the example on readme.md:

```
image_stylization_finetune \
      --checkpoint=/path/to/model.ckpt \
      --train_dir=/tmp/image_stylization/run2/train
      --style_dataset_file=/tmp/image_stylization/style_images.tfrecord \
      --num_styles=<NUMBER_OF_STYLES> \
      --vgg_checkpoint=/path/to/vgg_16.ckpt \
      --imagenet_data_dir=/path/to/imagenet-2012-tfrecord
```

How should I call finetune ?

Where can I read to understand why we need imagenet data as a whole when I am just finetuning ? Maybe then I have a better understanding of the process..",want example call read understand need data whole maybe better understanding process,issue,negative,positive,positive,positive,positive,positive
268701382,"It looks like you're running image_stylization_finetune, but passing the VGG checkpoint as the stylization checkpoint.  If you want to finetune you'll want to pass one of our pretrained model checkpoints (http://download.magenta.tensorflow.org/models/multistyle-pastiche-generator-monet.ckpt) or (http://download.magenta.tensorflow.org/models/multistyle-pastiche-generator-varied.ckpt).

If you want to train a model from scratch, use image_stylization_train instead of image_stylization_finetune.",like running passing stylization want want pas one model want train model scratch use instead,issue,positive,neutral,neutral,neutral,neutral,neutral
268638490,"@iansimon  I did pull the latest and it solved the initial problem with the string.

Although it starts, training my own network still fails soon after with no obvious error. Below is the console output, almost entirely with warnings.

Maybe some kind of time-out functionality I am not aware of ?

Edit1: I get the train files (including a file ""model.ckpt-0.data-00000-of-00001""), but running the finetune command again does not resume. 

Edit2: Put below console output into ""code""
```
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_utils.py:136 in imagenet_inputs.: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.image. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/models/image_stylization/image_stylization_finetune.py:122 in main.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py:344 in __init__.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.

Killed
```",pull latest initial problem string although training network still soon obvious error console output almost entirely maybe kind functionality aware edit get train file running command resume edit put console output code warning removed please switch note node name instead tag automatically summary based scope also argument warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning main removed please switch note node name instead tag automatically summary based scope also passing tensor list scalar summary longer warning removed please switch interface behavior rename,issue,negative,positive,positive,positive,positive,positive
268470479,"I have long since switched to VMWare and ran full version of Ubuntu 16.10. I will reinstall and test with the latest version of docker for windows and magenta image and let you know.

",long since switched ran full version reinstall test latest version docker magenta image let know,issue,negative,positive,positive,positive,positive,positive
268057817,right now I just do `bazel test //magenta/... ` I think we could put a travis CI script for free ... the time is not as long as tensorflow's one to require a custom CI server. ,right test think could put travis script free time long one require custom server,issue,positive,positive,positive,positive,positive,positive
268028272,"We do have some CI tooling that we use internally, but nothing external yet. At some point, we would like to switch to a system similar to what Tensorflow is using.",tooling use internally nothing external yet point would like switch system similar,issue,negative,neutral,neutral,neutral,neutral,neutral
267215362,"I think this is fixed by #441. You can either try building from source or waiting until we cut a new pip package version, which should be in the next few days. Please reopen if one of these methods doesn't work.",think fixed either try building source waiting cut new pip package version next day please reopen one work,issue,negative,positive,neutral,neutral,positive,positive
266907508,Hey Hans. I'd still like to get this in. Can you make the remaining fixes?,hey still like get make,issue,negative,neutral,neutral,neutral,neutral,neutral
266860321,"When you pull the Docker image, it's only refreshed to our latest Magenta release. We haven't yet cut a new release that includes the fix, so you won't see it in the Docker image.

The fastest way to test out the fix would be to use a development environment and use the Magenta source at HEAD.

Otherwise, you can wait until we cut our next release, which should be soon.",pull docker image latest magenta release yet cut new release fix wo see docker image way test fix would use development environment use magenta source head otherwise wait cut next release soon,issue,negative,positive,positive,positive,positive,positive
266618435,It seems the Docker image at https://hub.docker.com/r/tensorflow/magenta/tags/ is not refreshed with each new pull. Correct?,docker image new pull correct,issue,negative,positive,positive,positive,positive,positive
266504212,"This should be fixed when we cut a new pip package. For now, to use the musicxml converter, you'll probably need to build from the dev environment. We plan on releasing a new pip package soon.",fixed cut new pip package use converter probably need build dev environment plan new pip package soon,issue,negative,positive,positive,positive,positive,positive
266267520,"What about style index?

[0]->Roy Lichtenstein, Bicentennial Print (1975).
[1]->Ernst Ludwig Kirchner, Boy with Sweets (1918).
[2]->Paul Signac, Cassis, Cap Lombard, Opus 196 (1889).




",style index bicentennial print boy cassis cap lombard opus,issue,negative,neutral,neutral,neutral,neutral,neutral
266242785,"The one script seems not working, convert_midi_dir_to_note_sequences it works, but covert_dir_to_note_sequences not working. And convert musicmxl seems not working either. ",one script working work working convert working either,issue,negative,neutral,neutral,neutral,neutral,neutral
265905934,This should now be fixed by #445 but let me know if your results still look incorrect.,fixed let know still look incorrect,issue,negative,positive,neutral,neutral,positive,positive
265760200,"@cghawthorne thanks again for your feedback. I've used `del` to delete any notes in `primer_sequence` if the `exclude_primer_midi` flag is set to `True`. Notes are determined to be in `primer_sequence` if `note.start_time` is `<` `start_time`, where `start_time` is the starting point of newly generated notes (`start_time = last_end_time + _steps_to_seconds(1, qpm)`).",thanks feedback used delete flag set true determined starting point newly,issue,positive,positive,positive,positive,positive,positive
265675845,Hi. I encountered the same problem. The output results are just like yours. Can I know how you fix the problem? ,hi problem output like know fix problem,issue,negative,neutral,neutral,neutral,neutral,neutral
265674032,"I modified the code in image_utils.py like this: 
add `from tensorflow.python.ops import control_flow_ops as control_flow_ops` at the beginning 
and replace `tf.control_flow_ops` with  `control_flow_ops`. It works for me. 
",code like add import beginning replace work,issue,negative,neutral,neutral,neutral,neutral,neutral
265627866,"ahah! I used the command `dmesg` and it  showd numbers of wrong information about `out of memory in ub `.you are right.thank you so much! seems that i need a new machine,lol 🙈",used command wrong information memory much need new machine,issue,negative,negative,neutral,neutral,negative,negative
265583166,"I suspect the main problem is that your environment doesn't have enough RAM. If you check the output of `dmesg`, you'll probably see something related to the process being killed due to running out of memory. I'd suggest getting a machine with at least 2GB of RAM, though the exact amount used will depend on how you configure the training.",suspect main problem environment enough ram check output probably see something related process due running memory suggest getting machine least ram though exact amount used depend configure training,issue,negative,negative,neutral,neutral,negative,negative
265363269,"OK，I checked and the file ""training_melodies.tfrecord"" does exist and has file size(means it's not 0kb and has data in it). However,I don't know how to read the "".tfrecord"" file.so I can't figure out whether it is correct.I searched on the internet and found the below python code to read data in tfrecord file.
`readtfrecordfile.py`
```
import tensorflow as tf
import os
current_path = os.getcwd()
input_file = os.path.join(current_path, ""training_melodies.tfrecord"")
for serialized_example in tf.python_io.tf_record_iterator(input_file):
        example = tf.train.Example()
        example.ParseFromString(serialized_example)
        feature = example.features.feature[""feature""].float_list.value
        label = example.features.feature[""label""].float_list.value
        print(""Feature: {}, label: {}"".format(feature, label))
```
When I run it, the output are multi lines `Feature: [], label: []`.Is this correct?Does it mean there are no training data in training_melodies.tfrecord or I didn't use the right way to read the data in tfrecord file?

What's more,I use the vps which bought from Bandwagon Host.Here is the environment:
CPU:2x Intel Xeon
RAM:512MB
OS:Ubuntu 16.04 64bit with Python2.7
Disk storage:11GB available

Are there any problems about the environment?Looking forward your reply.Thank you very much!
@cghawthorne ",checked file exist file size data however know read ca figure whether found python code read data file import import o example feature feature label label print feature label feature label run output feature label correct mean training data use right way read data file use bought environment ram o bit python disk storage available environment looking forward much,issue,negative,positive,positive,positive,positive,positive
265282016,"One other thing to double check, has the file `/tmp/melody_rnn/sequence_examples/training_melodies.tfrecord` been correctly created with training data in it?

Also, what environment are you running this in? Is there any possibility some other part of the system is killing the process, maybe for exceeding quota or something?",one thing double check file correctly training data also environment running possibility part system killing process maybe exceeding quota something,issue,negative,neutral,neutral,neutral,neutral,neutral
265258160,I can't seem to replicate this.  Are you using the latest docker image?  Try doing `docker pull tensorflow/magenta` to update to the latest version.,ca seem replicate latest docker image try docker pull update latest version,issue,negative,positive,positive,positive,positive,positive
265061293,"Here is my trainthemodel.sh：

```
melody_rnn_train \
--config=attention_rnn \
--run_dir=/tmp/melody_rnn/logdir/run1 \
--sequence_example_file=/tmp/melody_rnn/sequence_examples/training_melodies.tfrecord \
--hparams=""{'batch_size':64,'rnn_layer_sizes':[64,64]}"" \
--num_training_steps=20000
```

I just copied it according to the tutorial. Although it always shows ""balabala(Is the number a PID?) Killed"", It did create the folder ""/tmp/melody_rnn/logdir/run1/train"" and it contents four files: 
checkpoint                               graph.pbtxt   model.ckpt-0.meta
events.out.tfevents.1480998996.tianwang  model.ckpt-0

@cghawthorne ",copied according tutorial although always number create folder content four,issue,negative,neutral,neutral,neutral,neutral,neutral
264995101,"I went ahead and corrected a few minor lint fixes. Just have one more comment about a method name change, and then I think we're ready to submit.",went ahead corrected minor lint one comment method name change think ready submit,issue,negative,positive,neutral,neutral,positive,positive
264992428,"We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.

<!-- need_author_consent -->",found contributor license agreement sender pull request commit best tell someone else case please add pull request confirm mistaken author reply confirm,issue,positive,positive,positive,positive,positive,positive
264957842,"Sounds good. For now, I'll close this. I'm hoping with some pip package changes we can automate more of the installation process in the future.",good close pip package installation process future,issue,negative,positive,positive,positive,positive,positive
264956693,"I'm somewhat indifferent, but in general I guess I prefer having fewer installation methods to support.",somewhat indifferent general guess prefer installation support,issue,negative,positive,neutral,neutral,positive,positive
264840581,"hey, I meet the same problem like yours. However, every time I tried to run my code, it always had this wrong massage:

_INFO:tensorflow:hparams = {'rnn_layer_sizes': [128, 128], 'attn_length': 40, 'dropout_keep_prob': 0.5, 'batch_size': 128, 'decay_rate': 0.97, 'clip_norm': 3, 'initial_learning_rate': 0.001, 'decay_steps': 1000, 'skip_first_n_losses': 0}
INFO:tensorflow:Train dir: /tmp/melody_rnn/logdir/run1/train
INFO:tensorflow:Starting training loop...
INFO:tensorflow:global_step/sec: 0
**trainthemodel.sh: line 6: 13536 Killed**                  melody_rnn_train --config=attention_rnn --run_dir=/tmp/melody_rnn/logdir/run1 --sequence_example_file=/tmp/melody_rnn/sequence_examples/training_melodies.tfrecord --hparams=""{'batch_size':64,'rnn_layer_sizes':[64,64]}"" --num_training_steps=20000_

I think this isn't correct. Does anyone know how to solve it?",hey meet problem like however every time tried run code always wrong massage train starting training loop line think correct anyone know solve,issue,negative,negative,negative,negative,negative,negative
264826879,"This should have a very high priority, as _TensorFlow supports **only** 64-bit Python 3.5 on Windows._([link](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#pip-installation-on-windows)).",high priority python link,issue,negative,positive,positive,positive,positive,positive
264826089,"I believe it is the same with the paper appendix (pages 14-24): https://arxiv.org/abs/1610.07629


Roy Lichtenstein, Bicentennial Print (1975). 
Ernst Ludwig Kirchner, Boy with Sweets (1918). 
Paul Signac, Cassis, Cap Lombard, Opus 196 (1889). 
Paul Klee, Colors from a Distance (1932). 
Frederic Edwin Church, Cotopaxi (1855). 
Jamini Roy, Crucifixion. 
Henri de Toulouse-Lautrec, Divan Japonais (1893). 
Egon Schiele, Edith with Striped Dress, Sitting (1915). 
Georges Rouault, Head of a Clown (ca. 1907-1908). 
William Hoare, Henry Hoare, ”The Magnificent”, of Stourhead (about 1750-1760). 
Giorgio de Chirico, Horses on the seashore (1927/1928). 
Vincent van Gogh, Landscape at Saint-Remy (Enclosed Field with Peasant) ´ (1889). 
Nicolas Poussin, Landscape with a Calm (1650-1651). 
Bernardino Fungai, Madonna and Child with Two Hermit Saints (early 1480s). 
Max Hermann Maxy, Portrait of a Friend (1926). 
Juan Gris, Portrait of Pablo Picasso (1912). 
Severini Gino, Ritmo plastico del 14 luglio (1913). 
Richard Diebenkorn, Seawall (1957). 
Alice Bailly, Self-Portrait (1917). 
Grayson Perry, The Annunciation of the Virgin Deal (2012). 
William Glackens, The Green Boathouse (ca. 1922). 
Edvard Munch, The Scream (1910). 
Vincent van Gogh, The Starry Night (1889). 
Pieter Bruegel the Elder, The Tower of Babel (1563). 
Wolfgang Lettl, The Trial (1981). 
Douglas Coupland, Thomson No. 5 (Yellow Sunset) (2011). 
Claude Monet, Three Fishing Boats (1886). 
John Ruskin, Trees in a Lane (1847). 
Giuseppe Cades, Tullia about to Ride over the Body of Her Father in Her Chariot (about 1770-1775). 
Berthe Morisot, Under the Orange Tree (1889). 
Giulio Romano (Giulio Pippi), Victory, Janus, Chronos and Gaea (about 1532-1534). 
Wassily Kandinsky, White Zig Zags (1922). ",believe paper appendix bicentennial print boy cassis cap lombard opus color distance church crucifixion de divan striped dress sitting head clown ca henry magnificent de seashore vincent van landscape field peasant landscape calm child two hermit early portrait friend gris portrait pablo perry annunciation virgin deal green boathouse ca munch scream vincent van starry night elder tower trial yellow sunset three fishing ruskin lane ride body father chariot orange tree victory white zig,issue,positive,positive,positive,positive,positive,positive
264663765,"Issue Resolved.

Thank You!
> On Dec 2, 2016, at 11:06 AM, cghawthorne <notifications@github.com> wrote:
> 
> It looks like you're using the MacPorts version of gcc. We recommend using the version from xcode:
> 
> $ which gcc
> /usr/bin/gcc
> $ gcc --version
> Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
> Apple LLVM version 7.0.2 (clang-700.1.81)
> Target: x86_64-apple-darwin15.6.0
> Thread model: posix
> http://www.bazel.io/versions/master/docs/install.html#install-with-installer-1 <http://www.bazel.io/versions/master/docs/install.html#install-with-installer-1>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/435#issuecomment-264535410>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i29xs-GBG9yMTqiHobX7JxB9va6dAks5rEGwfgaJpZM4LCyOm>.
> 

",issue resolved thank wrote like version recommend version version apple version target thread model thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
264535410,"It looks like you're using the MacPorts version of gcc. We recommend using the version from xcode:

```
$ which gcc
/usr/bin/gcc
$ gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 7.0.2 (clang-700.1.81)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
```

http://www.bazel.io/versions/master/docs/install.html#install-with-installer-1",like version recommend version version apple version target thread model,issue,positive,neutral,neutral,neutral,neutral,neutral
264523854,"Would you recommend running Magenta on the Google Cloud Platform instead of on a Mac?
Does Magenta require/utilize Google TPUs?

> On Dec 2, 2016, at 10:13 AM, David Laxer <davidl@softintel.com> wrote:
> 
> XCode Version 8.0 (8A218a)
> 
> David-Laxers-MacBook-Pro:magenta davidlaxer$ bazel clean
> INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
> David-Laxers-MacBook-Pro:magenta davidlaxer$ gcc --version
> gcc (MacPorts gcc5 5.4.0_0) 5.4.0
> Copyright (C) 2015 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.  There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
> 
> David-Laxers-MacBook-Pro:magenta davidlaxer$ bazel test //magenta:all
> WARNING: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
> INFO: Found 2 targets and 0 test targets...
> ERROR: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/BUILD:71:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
> gcc: error: unrecognized command line option '-Wthread-safety'
> gcc: error: unrecognized command line option '-Wself-assign'
> INFO: Elapsed time: 9.644s, Critical Path: 2.90s
> ERROR: No test targets were found, yet testing was requested.
> David-Laxers-MacBook-Pro:magenta davidlaxer$ 
> 
> 
>> On Dec 2, 2016, at 9:57 AM, Douglas Eck <notifications@github.com <mailto:notifications@github.com>> wrote:
>> 
>> does it help to run ""bazel clean"" and try again?
>> What xcode version are you on? I don't have my mac here but I think ""gcc
>> --version"" will tell you something.
>> 
>> On Fri, Dec 2, 2016 at 9:17 AM, dbl <notifications@github.com <mailto:notifications@github.com>> wrote:
>> 
>> > OS X 10.11.6
>> > Mac ports
>> >
>> > MacBook-Pro:magenta davidlaxer$ which gcc
>> > /opt/local/bin/gcc
>> > MacBook-Pro:magenta davidlaxer$ gcc --version
>> > gcc (MacPorts gcc5 5.4.0_0) 5.4.0
>> > Copyright (C) 2015 Free Software Foundation, Inc.
>> > This is free software; see the source for copying conditions. There is NO
>> > warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>> >
>> > MacBook-Pro:magenta davidlaxer$ python --version
>> > Python 2.7.10 :: Anaconda 2.3.0 (x86_64)
>> >
>> > MacBook-Pro:magenta davidlaxer$ bazel test //magenta:all
>> > ..
>> > WARNING: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
>> > b1/external/protobuf/WORKSPACE:1: Workspace name in
>> > /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE
>> > (@*main*) does not match the name given in the repository's definition (
>> > @protobuf <https://github.com/protobuf <https://github.com/protobuf>>); this will cause a build error
>> > in future versions.
>> > INFO: Found 2 targets and 0 test targets...
>> > ERROR: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
>> > b1/external/protobuf/BUILD:71:1: C++ compilation of rule
>> > '@protobuf//:protobuf_lite' failed: cc_wrapper.sh failed: error executing
>> > command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE
>> > '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign
>> > -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 41
>> > argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException:
>> > Process exited with status 1.
>> > gcc: error: unrecognized command line option '-Wthread-safety'
>> > gcc: error: unrecognized command line option '-Wself-assign'
>> > INFO: Elapsed time: 10.207s, Critical Path: 1.48s
>> > ERROR: No test targets were found, yet testing was requested.
>> > D
>> >
>> > —
>> > You are receiving this because you are subscribed to this thread.
>> > Reply to this email directly, view it on GitHub
>> > <https://github.com/tensorflow/magenta/issues/435 <https://github.com/tensorflow/magenta/issues/435>>, or mute the thread
>> > <https://github.com/notifications/unsubscribe-auth/APQ6Qt5EMU5WS3ESjWpWW_AEGsOw2LFKks5rEFKxgaJpZM4LCyOm <https://github.com/notifications/unsubscribe-auth/APQ6Qt5EMU5WS3ESjWpWW_AEGsOw2LFKks5rEFKxgaJpZM4LCyOm>>
>> > .
>> >
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/435#issuecomment-264518487>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i2zTfj6otjbvXyi0W-SLkKyYLhd7Sks5rEFv9gaJpZM4LCyOm>.
>> 
> 

",would recommend running magenta cloud platform instead mac magenta wrote version aa magenta clean starting clean may take consider clean several magenta version copyright free foundation free see source warranty even fitness particular purpose magenta test warning name match name given repository definition cause build error future found test error compilation rule error command argument process status error unrecognized command line option error unrecognized command line option time critical path error test found yet testing magenta wrote help run clean try version mac think version tell something wrote o mac magenta magenta version copyright free foundation free see source warranty even fitness particular purpose magenta python version python anaconda magenta test warning name main match name given repository definition cause build error future found test error compilation rule error command argument process status error unrecognized command line option error unrecognized command line option time critical path error test found yet testing thread reply directly view mute thread thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
264522460,"XCode Version 8.0 (8A218a)

David-Laxers-MacBook-Pro:magenta davidlaxer$ bazel clean
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
David-Laxers-MacBook-Pro:magenta davidlaxer$ gcc --version
gcc (MacPorts gcc5 5.4.0_0) 5.4.0
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

David-Laxers-MacBook-Pro:magenta davidlaxer$ bazel test //magenta:all
WARNING: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 2 targets and 0 test targets...
ERROR: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/BUILD:71:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error: unrecognized command line option '-Wthread-safety'
gcc: error: unrecognized command line option '-Wself-assign'
INFO: Elapsed time: 9.644s, Critical Path: 2.90s
ERROR: No test targets were found, yet testing was requested.
David-Laxers-MacBook-Pro:magenta davidlaxer$ 


> On Dec 2, 2016, at 9:57 AM, Douglas Eck <notifications@github.com> wrote:
> 
> does it help to run ""bazel clean"" and try again?
> What xcode version are you on? I don't have my mac here but I think ""gcc
> --version"" will tell you something.
> 
> On Fri, Dec 2, 2016 at 9:17 AM, dbl <notifications@github.com> wrote:
> 
> > OS X 10.11.6
> > Mac ports
> >
> > MacBook-Pro:magenta davidlaxer$ which gcc
> > /opt/local/bin/gcc
> > MacBook-Pro:magenta davidlaxer$ gcc --version
> > gcc (MacPorts gcc5 5.4.0_0) 5.4.0
> > Copyright (C) 2015 Free Software Foundation, Inc.
> > This is free software; see the source for copying conditions. There is NO
> > warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
> >
> > MacBook-Pro:magenta davidlaxer$ python --version
> > Python 2.7.10 :: Anaconda 2.3.0 (x86_64)
> >
> > MacBook-Pro:magenta davidlaxer$ bazel test //magenta:all
> > ..
> > WARNING: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
> > b1/external/protobuf/WORKSPACE:1: Workspace name in
> > /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE
> > (@*main*) does not match the name given in the repository's definition (
> > @protobuf <https://github.com/protobuf>); this will cause a build error
> > in future versions.
> > INFO: Found 2 targets and 0 test targets...
> > ERROR: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
> > b1/external/protobuf/BUILD:71:1: C++ compilation of rule
> > '@protobuf//:protobuf_lite' failed: cc_wrapper.sh failed: error executing
> > command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE
> > '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign
> > -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 41
> > argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException:
> > Process exited with status 1.
> > gcc: error: unrecognized command line option '-Wthread-safety'
> > gcc: error: unrecognized command line option '-Wself-assign'
> > INFO: Elapsed time: 10.207s, Critical Path: 1.48s
> > ERROR: No test targets were found, yet testing was requested.
> > D
> >
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/tensorflow/magenta/issues/435>, or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/APQ6Qt5EMU5WS3ESjWpWW_AEGsOw2LFKks5rEFKxgaJpZM4LCyOm>
> > .
> >
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub <https://github.com/tensorflow/magenta/issues/435#issuecomment-264518487>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AC9i2zTfj6otjbvXyi0W-SLkKyYLhd7Sks5rEFv9gaJpZM4LCyOm>.
> 

",version aa magenta clean starting clean may take consider clean several magenta version copyright free foundation free see source warranty even fitness particular purpose magenta test warning name match name given repository definition cause build error future found test error compilation rule error command argument process status error unrecognized command line option error unrecognized command line option time critical path error test found yet testing magenta wrote help run clean try version mac think version tell something wrote o mac magenta magenta version copyright free foundation free see source warranty even fitness particular purpose magenta python version python anaconda magenta test warning name main match name given repository definition cause build error future found test error compilation rule error command argument process status error unrecognized command line option error unrecognized command line option time critical path error test found yet testing thread reply directly view mute thread thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
264518487,"does it help to run ""bazel clean"" and try again?
What xcode version are you on? I don't have my mac here but I think ""gcc
--version"" will tell you something.

On Fri, Dec 2, 2016 at 9:17 AM, dbl <notifications@github.com> wrote:

> OS X 10.11.6
> Mac ports
>
> MacBook-Pro:magenta davidlaxer$ which gcc
> /opt/local/bin/gcc
> MacBook-Pro:magenta davidlaxer$ gcc --version
> gcc (MacPorts gcc5 5.4.0_0) 5.4.0
> Copyright (C) 2015 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions. There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>
> MacBook-Pro:magenta davidlaxer$ python --version
> Python 2.7.10 :: Anaconda 2.3.0 (x86_64)
>
> MacBook-Pro:magenta davidlaxer$ bazel test //magenta:all
> ..
> WARNING: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
> b1/external/protobuf/WORKSPACE:1: Workspace name in
> /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2b1/external/protobuf/WORKSPACE
> (@*main*) does not match the name given in the repository's definition (
> @protobuf <https://github.com/protobuf>); this will cause a build error
> in future versions.
> INFO: Found 2 targets and 0 test targets...
> ERROR: /private/var/tmp/_bazel_davidlaxer/182280691ad889ad33cd20c0640dc2
> b1/external/protobuf/BUILD:71:1: C++ compilation of rule
> '@protobuf//:protobuf_lite' failed: cc_wrapper.sh failed: error executing
> command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE
> '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign
> -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 41
> argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException:
> Process exited with status 1.
> gcc: error: unrecognized command line option '-Wthread-safety'
> gcc: error: unrecognized command line option '-Wself-assign'
> INFO: Elapsed time: 10.207s, Critical Path: 1.48s
> ERROR: No test targets were found, yet testing was requested.
> D
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/435>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/APQ6Qt5EMU5WS3ESjWpWW_AEGsOw2LFKks5rEFKxgaJpZM4LCyOm>
> .
>
",help run clean try version mac think version tell something wrote o mac magenta magenta version copyright free foundation free see source warranty even fitness particular purpose magenta python version python anaconda magenta test warning name main match name given repository definition cause build error future found test error compilation rule error command argument process status error unrecognized command line option error unrecognized command line option time critical path error test found yet testing thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
263953748,"Wow, that was a fast fix! Thanks!",wow fast fix thanks,issue,positive,positive,positive,positive,positive,positive
263625772,"@chrispesto, #416 should fix your issue, but please let me know if it doesn't.",fix issue please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
263408062,"It sounds like Adam has this sorted out, but it looks like your
checkpointed model was created with a LSTMCell, whereas RL Tuner is
expecting a BasicLSTMCell for basic_rnn. It should be a simple change to
delete the word ""Basic"" and get it working if you just want to try it out.

P.S., for easy debugging: the way RL Tuner loads things from a checkpoint
is by creating a dict that maps the string names of variables in the
checkpoint to the variables it creates in its graph. You can check this
dict using the get_variable_name_dict function in note_rnn_loader.



On Sat, Nov 26, 2016 at 9:52 PM, Chris Pesto <notifications@github.com>
wrote:

> @cghawthorne <https://github.com/cghawthorne> I don't have a great
> understanding of how this all works, but it looks like it might already be
> incompatible for basic_rnn somehow.
>
> I tried running //magenta/models/rl_tuner:rl_tuner_train with
> --note_rnn_type='basic_rnn' using a checkpoint file (train/model.ckpt-20)
> I generated with //magenta/models/melody_rnn:melody_rnn_train.
>
> It tells me Tensor name ""rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0""
> not found. My basic_rnn checkpoint has entries like
> RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias����, while the
> pretrained version that rl_tuner downloads has entries like
> rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0, which it's looking for.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/373#issuecomment-263099108>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEGEZpmfyEAGXDrWFtT0scRVpRFo34XPks5rCPBfgaJpZM4KuJyR>
> .
>
",like sorted like model whereas tuner simple change delete word basic get working want try easy way tuner string graph check function sat wrote great understanding work like might already incompatible somehow tried running file tensor name found like version like looking reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
263345032,Yes I believe it is ready for another round of review.,yes believe ready another round review,issue,positive,neutral,neutral,neutral,neutral,neutral
263343076,"Hey @jsawruk, not sure where this ended up with the last round of commits. Is it ready for review again at this point?",hey sure ended last round ready review point,issue,positive,positive,positive,positive,positive,positive
263341818,"I'm a little reluctant to switch to the version on conda-forge. It's community-maintained, so it's not always up to date (right now, it's on 0.11.0rc2, but the current version is 0.11.0), and I believe it doesn't have GPU support.

@iansimon what do you think?",little reluctant switch version always date right current version believe support think,issue,negative,positive,neutral,neutral,positive,positive
263131258,"To clarify, my PR fixes basic_rnn only. We will have it checked in on
Monday.

On Nov 27, 2016 8:22 AM, ""Adam Roberts"" <adarob@google.com> wrote:

> I already have a PR out (assigned to @cghawthorne) that will fix this.
>
> On Nov 26, 2016 6:52 PM, ""Chris Pesto"" <notifications@github.com> wrote:
>
>> @cghawthorne <https://github.com/cghawthorne> I don't have a great
>> understanding of how this all works, but it looks like it might already be
>> incompatible for basic_rnn somehow.
>>
>> I tried running //magenta/models/rl_tuner:rl_tuner_train with
>> --note_rnn_type='basic_rnn' using a checkpoint file (train/model.ckpt-20)
>> I generated with //magenta/models/melody_rnn:melody_rnn_train.
>>
>> It tells me Tensor name ""rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0""
>> not found. My basic_rnn checkpoint has entries like
>> RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias����, while the
>> pretrained version that rl_tuner downloads has entries like
>> rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0, which it's looking for.
>>
>> —
>> You are receiving this because you are subscribed to this thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/tensorflow/magenta/issues/373#issuecomment-263099108>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/ABCa6IK_FRY3QEOcDm0TuzMUbCTqXTIvks5rCPBbgaJpZM4KuJyR>
>> .
>>
>
",clarify checked wrote already assigned fix wrote great understanding work like might already incompatible somehow tried running file tensor name found like version like looking thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
263131194,"I already have a PR out (assigned to @cghawthorne) that will fix this.

On Nov 26, 2016 6:52 PM, ""Chris Pesto"" <notifications@github.com> wrote:

> @cghawthorne <https://github.com/cghawthorne> I don't have a great
> understanding of how this all works, but it looks like it might already be
> incompatible for basic_rnn somehow.
>
> I tried running //magenta/models/rl_tuner:rl_tuner_train with
> --note_rnn_type='basic_rnn' using a checkpoint file (train/model.ckpt-20)
> I generated with //magenta/models/melody_rnn:melody_rnn_train.
>
> It tells me Tensor name ""rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0""
> not found. My basic_rnn checkpoint has entries like
> RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias����, while the
> pretrained version that rl_tuner downloads has entries like
> rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0, which it's looking for.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/magenta/issues/373#issuecomment-263099108>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABCa6IK_FRY3QEOcDm0TuzMUbCTqXTIvks5rCPBbgaJpZM4KuJyR>
> .
>
",already assigned fix wrote great understanding work like might already incompatible somehow tried running file tensor name found like version like looking thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
263099108,"@cghawthorne I don't have a great understanding of how this all works, but it looks like it might already be incompatible for basic_rnn somehow.

I tried running `//magenta/models/rl_tuner:rl_tuner_train` with `--note_rnn_type='basic_rnn'` using a checkpoint file (`train/model.ckpt-20`) I generated with `//magenta/models/melody_rnn:melody_rnn_train`.

It tells me `Tensor name ""rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0"" not found`. My basic_rnn checkpoint has entries like `RNN/MultiRNNCell/Cell0/BasicLSTMCell/Linear/Bias`, while the pretrained version that rl_tuner downloads has entries like `rnn_model/RNN/MultiRNNCell/Cell0/LSTMCell/W_0`, which it's looking for.",great understanding work like might already incompatible somehow tried running file tensor name found like version like looking,issue,positive,positive,positive,positive,positive,positive
262098304,"thank you. yes I already recorded hundreds of music recording. And there are also live recordings in the famous hall as like carnegie hall. As well as, singing too.
If magenta can overcome these kinds of music, the magenta will be able to play any kinds of music on the planet. I can swear because my original ambition was to become a pianist when I was early young age.",thank yes already music recording also live famous hall like hall well singing magenta overcome music magenta able play music planet swear original ambition become pianist early young age,issue,positive,positive,positive,positive,positive,positive
262095654,"Yeah, it sounds like the challenge will be finding a large enough dataset of symbolic data in a format that Magenta can understand. The training will work best if you have on the order of hundreds or thousands of songs to train from.",yeah like challenge finding large enough symbolic data format magenta understand training work best order train,issue,positive,positive,positive,positive,positive,positive
262094448,"thank you @cghawthorne.
MIDI is computer music. I don't figure out what kind of MIDI music you mean. 
I can give you some music sample:[https://soundcloud.com/poly-music-co/jajinmori](url)
and Music XML is new to me. In fact, almost all professional performers have no interest in these technology things. Usually composers might have some interest, though,.
I can deal with Finale or Sibelius program and if it needed, I might try learning the MusicXML. [https://en.wikipedia.org/wiki/MusicXML](url)

I am assuming, the Asian music will be really excited with new technology, and it must challengeable to do something with. One of reasons is the music cannot be written for their real substance, and many of institute as like IRCAM in France had given up to digitalize for some music. 

I attach an Asian notation sample: [http://www.rutadeseda.org/corea/musica/notacion8.html](url)

thanks!",thank computer music figure kind music mean give music sample music new fact almost professional interest technology usually might interest though deal finale program might try learning assuming music really excited new technology must challengeable something one music written real substance many institute like given digitalize music attach notation sample thanks,issue,positive,positive,positive,positive,positive,positive
262073375,"Yes, we're definitely interested in pentatonic music. Our existing models should be able to work with pentatonic music, though it's hard to know for sure without trying. Do you have a corpus of pentatonic music in either MIDI or MusicXML format you could use to train a model? It would be very interesting to see how well it does.",yes definitely interested pentatonic music able work pentatonic music though hard know sure without trying corpus pentatonic music either format could use train model would interesting see well,issue,positive,positive,positive,positive,positive,positive
262072934,"I agree, this would be an excellent project!",agree would excellent project,issue,positive,positive,positive,positive,positive,positive
261261245,"@cghawthorne thanks for your feedback. Please let me know how this looks! 
",thanks feedback please let know,issue,positive,positive,positive,positive,positive,positive
261189453,"I would need a bit more exact reference data to evaluate my changes made in the code before I could make a PR.
",would need bit exact reference data evaluate made code could make,issue,negative,positive,positive,positive,positive,positive
261082350,"Those looks great!  Thanks for doing this!  Do you want to submit a pull request for your fix?
",great thanks want submit pull request fix,issue,positive,positive,positive,positive,positive,positive
261075966,"I've fixed the training code so now it produces much better results.
After ~500 iterations:

![screen shot 2016-11-16 at 22 16 38](https://cloud.githubusercontent.com/assets/6890818/20366367/0ef7b686-ac4b-11e6-9e95-8d59c9971a60.png)
",fixed training code much better screen shot,issue,negative,positive,positive,positive,positive,positive
261027643,"Ah sorry, that was caused by #377 that combined the musicxml and midi parser scripts and updated the documentation accordingly. We need to cut a new pip package with the new command. In the mean time, you can proceed using convert_midi_dir_to_note_sequences.
",ah sorry combined parser documentation accordingly need cut new pip package new command mean time proceed,issue,negative,negative,negative,negative,negative,negative
261027567,"@jsawruk is your thumbs-up on my previous comment a confirmation that you are in fact interested, or did you try parsing chord symbols and it seemed to work?
",previous comment confirmation fact interested try chord work,issue,negative,positive,neutral,neutral,positive,positive
261022904,"@jellysquider it looks like you're including some unicode quote characters on your command line to set the CONFIG value. Try this for setting the CONFIG value:

```
CONFIG=lookback_rnn
```
",like quote command line set value try setting value,issue,positive,neutral,neutral,neutral,neutral,neutral
260859248,"okay, I entered the absolute path and it worked.
Thanks and sorry about that.
",absolute path worked thanks sorry,issue,negative,negative,neutral,neutral,negative,negative
260858121,"```
(magenta) Gabrielas-Mac-Pro:magenta govi$ BUNDLE_PATH=//miniconda2/envs/magenta/magenta/models/melody_rnn/lookback_rnn.mag
(magenta) Gabrielas-Mac-Pro:magenta govi$ CONFIG=‘lookback_rnn’
(magenta) Gabrielas-Mac-Pro:magenta govi$ bazel-bin/magenta/models/melody_rnn/melody_rnn_generate 
--config=${CONFIG} \ 
--bundle_file=${BUNDLE_PATH} \ 
--output_dir=//miniconda2/generated \ 
--num_outputs=10 \ 
--num_steps=128 \ 
--primer_melody=""[60]""
```

> Traceback (most recent call last):
>   File ""/Users/govi/miniconda2/envs/magenta/bazel-bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/**main**/magenta/models/melody_rnn/melody_rnn_generate.py"", line 260, in <module>
>     console_entry_point()
>   File ""/Users/govi/miniconda2/envs/magenta/bazel-bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/**main**/magenta/models/melody_rnn/melody_rnn_generate.py"", line 256, in console_entry_point
>     tf.app.run(main)
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""/Users/govi/miniconda2/envs/magenta/bazel-bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/**main**/magenta/models/melody_rnn/melody_rnn_generate.py"", line 239, in main
>     config = melody_rnn_config_flags.config_from_flags()
>   File ""/Users/govi/miniconda2/envs/magenta/bazel-bin/magenta/models/melody_rnn/melody_rnn_generate.runfiles/**main**/magenta/models/melody_rnn/melody_rnn_config_flags.py"", line 136, in config_from_flags
>     melody_rnn_model.default_configs.keys(), FLAGS.config))
> magenta.models.melody_rnn.melody_rnn_config_flags.MelodyRnnConfigFlagsException: `--config` must be one of ['basic_rnn', 'attention_rnn', 'lookback_rnn']. Got ‘lookback_rnn’.
",magenta magenta magenta magenta magenta magenta recent call last file main line module file main line main file line run main file main line main file main line must one got,issue,negative,positive,positive,positive,positive,positive
260856776,"hey, thanks a lot for writing it. I think it should be written like this on the[ main page](https://github.com/tensorflow/magenta) too.

I got issue described in #350 :(
",hey thanks lot writing think written like main page got issue,issue,positive,positive,positive,positive,positive,positive
260815331,"@jellysquider From the error message, it looks like the bundle file doesn't exist at the path you supplied (`/miniconda/envs/magenta/models/melody_rnn/basic_rnn.mag`). Can you check where that file is saved and try again?

Also, if you continue to have this problem, can you open a new issue? I'd like to keep this issue dedicated to discussing @brannondorsey's ideas around priming sequences.
",error message like bundle file exist path check file saved try also continue problem open new issue like keep issue around priming,issue,negative,positive,neutral,neutral,positive,positive
260739138,"I'll try to get you some benchmarks next week as I am at a conference this week.
",try get next week conference week,issue,negative,neutral,neutral,neutral,neutral,neutral
260655942,"Realized my implementation needs to account for situations where the output is a different length from the primer MIDI. Will be working on this!
",implementation need account output different length primer working,issue,negative,neutral,neutral,neutral,neutral,neutral
260648026,"I guess the model size problem could be solved by stripping `VGG16` from the final checkpoint?
",guess model size problem could stripping final,issue,negative,neutral,neutral,neutral,neutral,neutral
260618401,"Checking my output by evaluating a single style model after a few hundreds of iterations describes the ""black images"" notation better: it seems they are in the internal format of `[0, 1)`. 
Regarding hyperparameters, I've only changed `batch_size` to `3`.
![screen shot 2016-11-15 at 12 25 57](https://cloud.githubusercontent.com/assets/6890818/20304147/13f9cd1c-ab2f-11e6-9523-43e275d584f8.png)
",output single style model black notation better internal format regarding screen shot,issue,negative,positive,neutral,neutral,positive,positive
260493146,"Should add a unit test to verify.
",add unit test verify,issue,negative,neutral,neutral,neutral,neutral,neutral
260452404,"sounds awesome. I built an desktop osx app and was looking at HMM hidden markov models to spew out midi - but would love to upgrade it with some real smarts.
The swift grpc project is making head way here - https://github.com/grpc/grpc-swift/issues/6
so just need to glue it all together.

https://github.com/tensorflow/magenta/blob/00bfe59fd038e2df17db3db7ef6377ee49d5dc33/magenta/protobuf/music.proto

 but um, frankly without a grpc service + documentation (independent of swift) /notes  - then it's a kind of a black hole.  Which is ok - but just would be good to share workings.
",awesome built looking hidden spew would love upgrade real swift project making head way need glue together um frankly without service documentation independent swift kind black hole would good share,issue,positive,positive,positive,positive,positive,positive
260444350,"Yes, very similar to that. You should also add the other flags in that example command:

```
BUNDLE_PATH=//miniconda2/envs/magenta/magenta/models/melody_rnn/lookback_rnn.mag

CONFIG=‘lookback_rnn’

bazel run //magenta/models/melody_rnn:melody_rnn_generate --
--config=${CONFIG} \
--bundle_file=${BUNDLE_PATH} \
--output_dir=/tmp/melody_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""
```
",yes similar also add example command run,issue,negative,neutral,neutral,neutral,neutral,neutral
260417885,"Hi John. Which parts of Magenta are you looking to open up to Swift? We
have some plans around building a gRPC interface for musical sequence
generation. If that's what you had in mind, we should definitely coordinate.

On Mon, Nov 7, 2016 at 10:29 AM, John Pope notifications@github.com wrote:

> until tensorflow has a native swift wrapper - the grpc will allow apps or
> server side micro services to interact with it. tensorflow/tensorflow#19
> https://github.com/tensorflow/tensorflow/issues/19
> It's kind of pioneering work - and any pointers by @adarob
> https://github.com/adarob would be most appreciated.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/358#issuecomment-258920133,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABCa6CNpzz3HISuhO6JFlX1lGU93SZwtks5q724lgaJpZM4KqTe4
> .
",hi magenta looking open swift around building interface musical sequence generation mind definitely mon pope wrote native swift wrapper allow server side micro interact kind work would reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
260412400,"Hello, 
I encountered this issue after running

```
melody_rnn_generate \
  --bundle_file=//magenta/models/lookback_rnn.mag \
  --output_dir=//miniconda2/generated \
  --num_outputs=10 \
  --num_steps=128 \
  --primer_melody=""[60]""
```

I got: 

> File ""/Users/govi/miniconda2/envs/magenta/bin/melody_rnn_generate"", line 11, in <module>
>     sys.exit(console_entry_point())
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 256, in console_entry_point
>     tf.app.run(main)
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 239, in main
>     config = melody_rnn_config_flags.config_from_flags()
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_config_flags.py"", line 111, in config_from_flags
>     'Exactly one of `--config` or `--melody_encoder_decoder` must be '
> magenta.models.melody_rnn.melody_rnn_config_flags.MelodyRnnConfigFlagsException: Exactly one of `--config` or `--melody_encoder_decoder` must be supplied.

I described similar issue in [#296](https://github.com/tensorflow/magenta/issues/296#issuecomment-260358733)
",hello issue running got file line module file line main file line run main file line main file line one must exactly one must similar issue,issue,negative,positive,positive,positive,positive,positive
260411848,"You'll need to add a checkpoint or bundle file path to your command. You can find links to pre-trained bundle files and an example command using the `--bundle_file` flag here: https://github.com/tensorflow/magenta/tree/master/magenta/models/melody_rnn#pre-trained
",need add bundle file path command find link bundle example command flag,issue,negative,neutral,neutral,neutral,neutral,neutral
260358733,"Hello,

I just spend the whole night installing and re-installing environments and I finally found this issue; I think it is the bug of the 0.1.6 version since a couple of days ago 0.1.4 worked for me perfectly. 

Anyhow, when trying to generate magenta using pre-trained model:

```
(magenta) Gabrielas-Mac-Pro:~ govi$ melody_rnn_generate \
> --config=basic_rnn \
> --bundle_file=//miniconda/envs/magenta/models/melody_rnn/basic_rnn.mag \
> --output_dir=//miniconda/generated \
> --num_outputs=10 \
> --num_steps=128 \
> --primer_melody=""[60]""
```

I get the following:

> Traceback (most recent call last):
>   File ""/Users/govi/miniconda2/envs/magenta/bin/melody_rnn_generate"", line 11, in <module>
>     sys.exit(console_entry_point())
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 256, in console_entry_point
>     tf.app.run(main)
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 245, in main
>     bundle=get_bundle())
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/models/melody_rnn/melody_rnn_generate.py"", line 129, in get_bundle
>     return magenta.music.read_bundle_file(bundle_file)
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/magenta/music/sequence_generator_bundle.py"", line 34, in read_bundle_file
>     bundle.ParseFromString(f.read())
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 101, in read
>     compat.as_bytes(self.**name), status)
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/contextlib.py"", line 24, in __exit**
>     self.gen.next()
>   File ""/Users/govi/miniconda2/envs/magenta/lib/python2.7/site-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
>     pywrap_tensorflow.TF_GetCode(status))
> tensorflow.python.framework.errors.NotFoundError: //miniconda/envs/magenta/models/melody_rnn/basic_rnn.mag

At first I thought that the Development Environment I established earlier was interfering with it since I got the same problem after the`bazel test` and when `building pip package` from magenta, but after de-installing everything and installing everything from scratch, it didn't work either. I even tried to download 0.1.4 version of magenta, but when I do `pip install magenta` obviously it generates new file `melody_rnn_generate.py` which I think might cause the problem.
",hello spend whole night finally found issue think bug version since couple day ago worked perfectly anyhow trying generate magenta model magenta get following recent call last file line module file line main file line run main file line main file line return file line file line read self name status file line file line status first thought development environment established interfering since got problem test building pip package magenta everything everything scratch work either even tried version magenta pip install magenta obviously new file think might cause problem,issue,negative,positive,positive,positive,positive,positive
260049063,"The current model wasn't well optimized for speed. We agree that it's too
slow.

Do you have some benchmark results? I'd love to see how we're doing.

On Fri, Nov 11, 2016 at 9:25 AM Kevin LaMar notifications@github.com
wrote:

> I really appreciate the work you guys have done on magenta here in
> including image stylization, which I am passionately interested in and
> would love to use cloudML to do some stuff in the future with it since this
> is already using TensorFlow.
> 
> However this project https://github.com/jcjohnson/fast-neural-style is a
> lot faster for me using cutorch taking advantage of my nvidia gpu.
> 
> If we could have parity over here I think that would be ideal!
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/379, or mute the thread
> https://github.com/notifications/unsubscribe-auth/APkejNzKCN6qUcHnJbasLVg172BRfLaGks5q9KT7gaJpZM4Kv9jb
> .
",current model well speed agree slow love see wrote really appreciate work done magenta image stylization passionately interested would love use stuff future since already however project lot faster taking advantage could parity think would ideal thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
260024293,"@cghawthorne I'd like more info about different reward implementations. For example, I would like to relax the rule on staying within the given key so that a composition could modulate to a nearby key. For example, if the piece starts in C, it should be able to borrow notes from the neighboring keys of G and F. I assume that making it easier to use different reward functions would enable me to create my own rules, so I am interested in helping with this.
",like different reward example would like relax rule within given key composition could modulate nearby key example piece able borrow neighboring assume making easier use different reward would enable create interested helping,issue,positive,positive,positive,positive,positive,positive
259787556,"We also have to add the following test case in addition to st_anne.xml. 
1. Measure 1 does not have a time signature defined at all. See for example Messiaen's Quartet for the End of Time, Movement 6 ""Danse de la fureur"". In that particular example, the inserted time signature for the first measure would be 17/16.

Please see attached MusicXML as an example.

[unmetered_example.xml.zip](https://github.com/tensorflow/magenta/files/585966/unmetered_example.xml.zip)
",also add following test case addition measure time signature defined see example quartet end time movement de la particular example inserted time signature first measure would please see attached example,issue,negative,positive,positive,positive,positive,positive
259773265,"It sounds like @natashamjaques won't have time for this in the immediate future, so if anyone else would like to take a look, that would be great!
",like wo time immediate future anyone else would like take look would great,issue,positive,positive,positive,positive,positive,positive
259764509,"I've changed the algorithm slightly after looking at the st_anne.xml example. Instead of computing the new time signature when parsing the next measure, compute it after parsing the current measure. This occurs within the Part class. As a result, there is no longer any need to keep track of the previous measure. The other details remain the same.
",algorithm slightly looking example instead new time signature next measure compute current measure within part class result longer need keep track previous measure remain,issue,negative,negative,neutral,neutral,negative,negative
259616937,"I would like to help in the issue
",would like help issue,issue,positive,neutral,neutral,neutral,neutral,neutral
259576591,"@cghawthorne Success!

Got rid of bazel test in Dockerfile for now so I was able to build again, the new version of the pip package seemed to have resolved the issue.

Appreciate your help! 
",success got rid test able build new version pip package resolved issue appreciate help,issue,positive,positive,positive,positive,positive,positive
259574711,"My experience with `tensorflow-devel-gpu` has been relatively smooth thus far it's based from nvidia-docker / `nvidia/cuda:8.0-cudnn5-devel`. I'm not quite sure how to extract test.log as it's the build which fails and it seems the file is stored in a random tmp directory name. 

Will try to build on a different machine, possibly try to skip this test all together as it's only the style transfer I'm interested in. Will post an update shorty. 
",experience relatively smooth thus far based quite sure extract build file random directory name try build different machine possibly try skip test together style transfer interested post update,issue,positive,positive,positive,positive,positive,positive
259573079,"Hmm, not sure why that one would be failing. Can you include the test.log from the failing test?

If you're wanting to use the GPU, I would definitely recommend using the pip package with a locally installed tensorflow setup. Getting the GPU to work in a Docker container can be tricky (though it should be possible).
",sure one would failing include failing test wanting use would definitely recommend pip package locally setup getting work docker container tricky though possible,issue,negative,positive,positive,positive,positive,positive
259572022,"Apologies I missed the relevant error line:

``` javascript
//magenta/interfaces/midi:midi_hub_test                                  FAILED in 21.5s
  /root/.cache/bazel/_bazel_root/cb5f479c6a7afa91f510d7ce625f6aa5/execroot/magenta/bazel-out/local-opt/testlogs/magenta/interfaces/midi/midi_hub_test/test.log

Executed 30 out of 30 tests: 29 tests pass and 1 fails locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
The command '/bin/sh -c bazel build //magenta/... && bazel test //magenta/...' returned a non-zero code: 3
```

I'm building the image myself is because it's based from `tensorflow/tensorflow:0.11.0rc1-devel` and I'd like to be able to base it from `tensorflow/tensorflow:0.11.0rc1-devel-gpu` later on. 
",relevant error line executed pas locally whose size big use command line option see command build test returned code building image based like able base later,issue,negative,positive,neutral,neutral,positive,positive
259571219,"Can you include a bit more of the output to show which test is failing?

Is there a reason you need to build a new Docker image? If you're wanting to do more than just run a few example commands, I'd recommend installing the pip package locally: https://github.com/tensorflow/magenta#python-pip
",include bit output show test failing reason need build new docker image wanting run example recommend pip package locally,issue,negative,positive,neutral,neutral,positive,positive
259569117,"@cghawthorne Dockfile build now fails with the following error:

``` javascript
Executed 30 out of 30 tests: 29 tests pass and 1 fails locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
The command '/bin/sh -c bazel build //magenta/... && bazel test //magenta/...' returned a non-zero code: 3
```

(Rebuilding again to make sure none of the dependencies failed to download)

Build still fails unfortunately... I'm on Ubuntu 14.04
",build following error executed pas locally whose size big use command line option see command build test returned code make sure none build still unfortunately,issue,negative,neutral,neutral,neutral,neutral,neutral
259567369,"Closing due to lack of updates. Please reopen if you're still having problems.
",due lack please reopen still,issue,negative,negative,negative,negative,negative,negative
259564435,"Thanks @cghawthorne does tensorflow/magenta pull from the repo or should I attempt a manual install?

About the list of styles, one of the reasons I'm trying to look them up is because it will be hard for me attempt to train new models if I don't know which styles are included in the pre-trained models or compare my own results. 

Will take a look look at Dockerfile and rebuild in the meantime
",thanks pull attempt manual install list one trying look hard attempt train new know included compare take look look rebuild,issue,negative,positive,neutral,neutral,positive,positive
259562384,"@1N50MN14 I'm not sure if this is relevant, but we just released a new version of the pip package (0.1.6). Can you try upgrading and see if that fixes it?
",sure relevant new version pip package try see,issue,negative,positive,positive,positive,positive,positive
259494752,"I removed the `import magenta as mg` line.

The `RL_CODE_PATH` was so it could work without the pip package. I removed that line in this PR because this should be able to use the code directly.
",removed import magenta line could work without pip package removed line able use code directly,issue,negative,positive,positive,positive,positive,positive
259218078,"Sounds like a good plan!

The st_anne.xml file I'm adding in #356 might be a good test file to use for this change because it has some partial measures in it.
",like good plan file might good test file use change partial,issue,positive,positive,positive,positive,positive,positive
259209797,"The numpy views are a problem, though I think with the way the iterators are currently used, they won't cause issues (though I could be wrong there).

The main problem is that the time class translation searches over data that it has already changed. So for example: it replaces all instances of .5 (seconds) with 1 (class), and then later replaces 1 (seconds) with 4 (class), then 4 (seconds) with 8 (class), then 8 (seconds) with 10 (class). Which means that all instances of .5 seconds get turned into 8 seconds. Exactly how this bug manifests depends on what class values also show up as duration values in a class index larger than the original one.
",problem though think way currently used wo cause though could wrong main problem time class translation data already example class later class class class get turned exactly bug class also show duration class index original one,issue,negative,positive,neutral,neutral,positive,positive
259209051,"Great, I'm a bit swamped this week but should be able to get on this and hopefully make a PR by early next week.
",great bit week able get hopefully make early next week,issue,positive,positive,positive,positive,positive,positive
259168132,"Here's a proposed solution:
- When beginning a new measure, check if there is a previous measure. 
- If there is, find the sum of its durations in voice 1 (since voice 1 is always present)
- Build a time signature as proper fraction in lowest terms (ex: 3/8 instead of 1.5/4)
- If the time signature is different from the current global time signature (in the parser state):
  - Insert the new time signature into the previous measure at the beginning. Time signatures cannot be inserted in the middle of a measure
  - Update the global time signature in the parser state.

Three examples/test cases:
1. First measure, full measure of 4/4. The MusicXML contains time signature info describing this measure as 4/4 (this sets the global time signature to 4/4). 
   - The total duration = 1024, and divisions = 256, which gives a time signature of 4/4. 
   - Because 4/4 = 4/4, no action is taken. 
   - These computations occur in measure 2 because that is the only way to ensure we have exited the measure.
2. First measure, pickup measure of 1 beat, but the MusicXML contains time signature info of 4/4. This sets the global time signature to 4/4.
   - When entering measure two, compute the total duration of the previous measure (measure 1).
   - Total duration = 256, divisions = 256. Computed time signature = 1/4.
   - 1/4 != 4/4. Insert a 1/4 time signature in the first measure. Update the global time signature to 1/4.
   - When entering measure three, compute the total duration of the previous measure (measure 2).
   - Total duration = 1024, divisions = 256. Computed time signature = 4/4
   - 4/4 != 1/4. Insert a 4/4 time signature in the second measure. Update the global time signature to 4/4.
3. First measure, pickup measure of 3 eighth notes (1.5 quarter notes). The MusicXML indicates a time signature of 4/4, setting the global time signature to 4/4.
   - Same as 2 above, but now the computed time signature = 3/8.
   - When in measure 2, insert the 3/8 time signature into measure 1 and update the global time signature
   - When in measure 3, 3/8 != 4/4, so insert the time signature change into measure 2 and update the global time signature to 4/4.
",solution beginning new measure check previous measure find sum voice since voice always present build time signature proper fraction ex instead time signature different current global time signature parser state insert new time signature previous measure beginning time inserted middle measure update global time signature parser state three first measure full measure time signature measure global time signature total duration time signature action taken occur measure way ensure measure first measure pickup measure beat time signature global time signature entering measure two compute total duration previous measure measure total duration time signature insert time signature first measure update global time signature entering measure three compute total duration previous measure measure total duration time signature insert time signature second measure update global time signature first measure pickup measure eighth quarter time signature setting global time signature time signature measure insert time signature measure update global time signature measure insert time signature change measure update global time signature,issue,positive,positive,neutral,neutral,positive,positive
259027227,"Yep that looks like it would be bad news - views are deceptive! Thanks @cghawthorne for fixing it
",yep like would bad news deceptive thanks fixing,issue,negative,negative,negative,negative,negative,negative
258975520,"I am currently investigating this exact idea (though not specifically pertaining to Magenta, I have found it to be a tremendous starting point) as an independent research project at university. I am currently running tests on the pre-trained models provided with the recently published ""call and response"" MIDI interface. These preliminary tests involve attempting to get the program(s) to recognize simple and rudimentary patterns used in music, such as arpeggios or scales.

If at all possible, I would like to request the training data used for the pre-trained models, as I would like to investigate the possible effect of priming for each of them. The paper, _Generating Sequences with Recurrent Neural Networks_ by Graves ([link](https://arxiv.org/abs/1308.0850)) points to the possible affect on stylistic generation that priming can have. It is possible for the training data to be specifically chosen to represent a specific style, and have that style replicated in generation, as shown in the paper by Graves above, and in _A First Look at Music Composition using LSTM Recurrent Neural Networks_ by Eck and Schmidhuber ([link](http://people.idsia.ch/~juergen/blues/IDSIA-07-02.pdf)), who in their paper found that LSTMs were capable of replicating a ""bebop jazz"" style when trained on chords for a similar style. 

Obviously priming cannot be the only solution to this, and it certainly would not be the most efficient solution. Re-training the machine each time one wants to replicate a different artistic style seems rather costly. However if priming yields promising results, it could be used to develop more efficient machines and ones which present a much better focus on stylistic generation. This is the goal of the aforementioned tests involving basic patterns.

These are of course the opinions of a first-year undergraduate with limited applicable experience in the fields of deep learning, generative models, and music theory, so this can all be taken with a significantly sized grain of salt. Any insight that the more experienced among this project's contributors have would be greatly appreciated. 
",currently investigating exact idea though specifically pertaining magenta found tremendous starting point independent research project university currently running provided recently call response interface preliminary involve get program recognize simple rudimentary used music scale possible would like request training data used would like investigate possible effect priming paper recurrent neural link possible affect stylistic generation priming possible training data specifically chosen represent specific style style replicated generation shown paper first look music composition recurrent neural link paper found capable bebop jazz style trained similar style obviously priming solution certainly would efficient solution machine time one replicate different artistic style rather costly however priming promising could used develop efficient present much better focus stylistic generation goal basic course undergraduate limited applicable experience deep learning generative music theory taken significantly sized grain salt insight experienced among project would greatly,issue,positive,positive,positive,positive,positive,positive
258920133,"until  tensorflow has a native swift wrapper - the grpc will allow apps or server side micro services to interact with it. https://github.com/tensorflow/tensorflow/issues/19
It's kind of pioneering work - and any pointers by @adarob  would be most appreciated.
",native swift wrapper allow server side micro interact kind work would,issue,positive,positive,positive,positive,positive,positive
258909676,"@adarob has looking into using Magenta via grpc before.

I'm curious what your goal is for having the proto files generated outside the repo or pip package. Are you wanting to add support for manipulating NoteSequence protos via another programming language, or did you have something else in mind?
",looking magenta via curious goal proto outside pip package wanting add support via another language something else mind,issue,positive,negative,neutral,neutral,negative,negative
258713739,"@cghawthorne thanks for the feedback! I've opened a PR for this. Let me know if there's anything else I can help out with. https://github.com/tensorflow/magenta/pull/359
",thanks feedback let know anything else help,issue,positive,positive,positive,positive,positive,positive
258623257,"Do you guys have any gists you can share to get the proto files to talk to magenta?
",share get proto talk magenta,issue,negative,neutral,neutral,neutral,neutral,neutral
258579196,"I think that's doable because we know the cumulative duration within a single measure. For example, I generated a MusicXML file in 4/4 with a 1 beat pickup. In measure 0, it set divisions to 256 and had a note of duration 256. In measure 1, divisions continued as 256, and the whole note had a duration of 1024. (Please see attached example file).

This demonstrates that any partial measure would just be the maximum of the sum of the note durations across all voices with that measure (some voices may only appear partially within a given measure). In the above example, if the durations summed to 512, then a 2/4 TimeSignature would be inserted. 

MusicXML does not enforce that the durations fit within a measure, so we can expand this if a measure overflows, i.e. there are 5 beats in a measure of 4/4.
[pickup_bar.xml.zip](https://github.com/tensorflow/magenta/files/572919/pickup_bar.xml.zip)
",think doable know cumulative duration within single measure example file beat pickup measure set note duration measure continued whole note duration please see attached example file partial measure would maximum sum note across measure may appear partially within given measure example summed would inserted enforce fit within measure expand measure measure,issue,positive,positive,neutral,neutral,positive,positive
258491914,"@johndpope, we build new Docker images with each major release. The Docker image contains a full development environment, so you could certainly update to the latest git commit within the image, but unless you moved the git repo to a persistent volume, your updates would disappear when your session ended.

If you'd like to experiment with the latest changes from master, I'd recommend setting up a local development environment: https://github.com/tensorflow/magenta#development-environment

Also, you're right that we require Bazel 0.3.1 for now. There's a bug in 0.3.2 that breaks out build that we're hoping will be resolved soon. You can follow updates here: https://github.com/bazelbuild/bazel/issues/1997
",build new docker major release docker image full development environment could certainly update latest git commit within image unless git persistent volume would disappear session ended like experiment latest master recommend setting local development environment also right require bug build resolved soon follow,issue,positive,positive,positive,positive,positive,positive
258487585,"Thanks for catching this. Could you investigate and add a unit test to verify the fix?
",thanks catching could investigate add unit test verify fix,issue,negative,positive,positive,positive,positive,positive
258422576,"I'm eager to test this out in Docker

It seems Dockerfile is hard coded to a specific commit on magenta (MAGENTA_MASTER_REF) and tensorflow. Is it not possible to have it fetch latest code from master?
I tried rebuilding container from scratch - drafted here (including other midi dependencies)
https://gist.github.com/johndpope/2d3a90c8d70b22732ad75b6ebec60187

but eventually fails with 
/magenta/magenta/music/BUILD:44:1: no such package '@music21//': File ""LICENSE"" linked from ""LICENSE"" does not exist and referenced by '//magenta/music:chord_symbols_lib'.
ERROR: Analysis of target '//magenta/music:chord_symbols_lib_test' failed; build aborted.

ok from some digging it seems like this is from a requirement of bazel 0.3.1
",eager test docker hard specific commit magenta possible fetch latest code master tried container scratch eventually package file license linked license exist error analysis target build aborted digging like requirement,issue,negative,positive,neutral,neutral,positive,positive
258300819,"Yeah, I think we should figure out some way of making that automatic so users don't have to specify the config when they're loading a bundle.
",yeah think figure way making automatic specify loading bundle,issue,negative,neutral,neutral,neutral,neutral,neutral
258274924,"Thanks for catching this! We forgot to update the example command with the --config parameter. I'll fix that shortly.
",thanks catching forgot update example command parameter fix shortly,issue,negative,positive,positive,positive,positive,positive
258260814,"this has a hard git commit in dockerfile that I think is causing problems with updated code.

 https://github.com/cghawthorne/magenta/blob/246e8ea3483fc90dcd3c5c4347ca0bcb64156e1a/magenta/tools/docker/Dockerfile
",hard git commit think causing code,issue,negative,negative,negative,negative,negative,negative
258255039,"I had this comment in a PR, so I will put it here as well:

One other thing to think about in a potential future PR is incorporating parts of [Modelling Symbolic Music: Beyond the Piano Roll, C. Walder](https://arxiv.org/abs/1606.01368). See the [samples](http://users.cecs.anu.edu.au/~christian.walder/). As far as I can tell, he uses a groundtruth rhythm which includes time signature and every note duration, and resamples the pitch values conditional on that. The model sounds really good IMO and it seems like this kind of model (and/or the reverse - predict durations given pitches) could be a fun addition for Magenta as a quick proxy to ""style""
",comment put well one thing think potential future symbolic music beyond piano roll see far tell rhythm time signature every note duration pitch conditional model really good like kind model reverse predict given could fun addition magenta quick proxy style,issue,positive,positive,positive,positive,positive,positive
258254778,"Looks good to me - this seems like plenty for a first pass. This is great!
",good like plenty first pas great,issue,positive,positive,positive,positive,positive,positive
258232663,"Thanks for fixing this, as well as demonstrating a different way to do unit testing.
",thanks fixing well different way unit testing,issue,positive,positive,neutral,neutral,positive,positive
258213990,"@kastnerkyle 555a2b7 implements the time class change you suggested. Can you take a look and see if that matches with what you were thinking?

Are there any other changes you think should happen before this initial checkin?
",time class change take look see thinking think happen initial,issue,negative,neutral,neutral,neutral,neutral,neutral
258032526,"I didn't like how the rebase went, so I deleted the branch, rebranched off of master, and created a new branch. I guess I need to create a new pull request now.
",like rebase went branch master new branch guess need create new pull request,issue,positive,positive,positive,positive,positive,positive
258032191,"Looks like the pull request was closed before it could be merged. Were you planning on making a different pull request?
",like pull request closed could making different pull request,issue,negative,negative,neutral,neutral,negative,negative
258025885,"Can you rebase your change onto master so it has only the last commit?

Or alternatively, resync with magenta/master and create a new branch that has only the commit to add the file.
",rebase change onto master last commit alternatively create new branch commit add file,issue,positive,positive,neutral,neutral,positive,positive
258024872,"Cool. Can you do a new pull request for that?
",cool new pull request,issue,negative,positive,positive,positive,positive,positive
258024422,"Oops, forgot to check it in. It's now on the musicxml branch, commit 0eb36d5.
",forgot check branch commit,issue,negative,neutral,neutral,neutral,neutral,neutral
258009953,"Hey Jeremy, I think this is looking pretty good! We might need some followup changes, but I think it's in a good shape to check in now!
",hey think looking pretty good might need think good shape check,issue,positive,positive,positive,positive,positive,positive
257734699,"I think we can leave it at 11.0rc2. The only problem is with the docker image, and I was able to rely on the 11.0rc1 docker image, and then let our pip package end up installing 11.0rc2. So I think it all works out.

Hopefully the Bazel problem gets fixed soon.
",think leave problem docker image able rely docker image let pip package end think work hopefully problem fixed soon,issue,negative,positive,positive,positive,positive,positive
257641402,"How about a flag (e.g. `--primer_midi_track 1`) to specify which track to extract melodies from and use the first track if this flag is not specified?
",flag specify track extract use first track flag,issue,negative,positive,positive,positive,positive,positive
257639663,"melody extractor will accept polyphonic tracks in its default mode. it looks like the problem here is that the generator is asserting that there is no more than 1 melody extracted. ""assert len(extracted_melodies) <= 1""

An easy fix would be to remove the assertion and just pick the first melody to generate from. Maybe also display a warning that there are other melodies which will not be used.
",melody extractor accept polyphonic default mode like problem generator melody extracted assert easy fix would remove assertion pick first melody generate maybe also display warning used,issue,negative,positive,positive,positive,positive,positive
257634678,"Done. I link to the directory rather than a specific script since there's a few options.
",done link directory rather specific script since,issue,negative,neutral,neutral,neutral,neutral,neutral
257629055,"So it turns out email reply doesn't reply to the commit comment directly...

¯\_(ツ)_/¯
",turn reply reply commit comment directly,issue,negative,positive,neutral,neutral,positive,positive
257456053,"This is a little hacky, so let me know if you have thoughts about a better way to do it.
",little hacky let know better way,issue,negative,positive,positive,positive,positive,positive
257450868,"I was just doing some manual testing and noticed some potential issues with parsing. Some of these should probably be added as unit tests.
- flute_scale.mxl has a key_signature of C added at time -1.0
- el_capitan.xml has a key signature of C at time -1.0 too, and it also has some duplicate key signatures. I'm wondering if the duplicate key signatures are due to the transposing parts? Should everything be transposed to 1 key signature before writing? Here's the current key signature output:

```
key_signatures {
  time: 0.0
  key: B_FLAT
}
key_signatures {
  time: -1.0
  key: C
}
key_signatures {
  time: 81.0
  key: E_FLAT
}
key_signatures {
  time: 81.0
  key: F
}
key_signatures {
  time: 0.0
  key: D_FLAT
}
key_signatures {
  time: 81.0
  key: C
}
key_signatures {
  time: 81.0
  key: B_FLAT
}
```
- Not a bug, but worth verifying in a unit test: I compared how our music21-based parser and your parser handled clarinet_scale, and it turns out the music21-based parser got it wrong (it didn't transpose) and yours got it right! Thanks for figuring out all the tricky transposition stuff.

For testing this, I just used some code that looked like this:

```
import magenta.music as mm
mxml = mm.note_sequence_io.note_sequence_record_iterator('/tmp/jmusicxml.tfrecord')
mxml.next()
```

Note that when protobufs are printed out, they don't include default values or 0s. So if a time_signature happens at time 0, it will print out without a time value. Similarly, because the key signature enum has C as 0, key signatures with a value of C will print out without a key.
",manual testing potential probably added unit added time key signature time also duplicate key wondering duplicate key due everything key signature writing current key signature output time key time key time key time key time key time key time key bug worth unit test parser parser handled turn parser got wrong transpose got right thanks tricky transposition stuff testing used code like import note printed include default time print without time value similarly key signature key value print without key,issue,negative,positive,neutral,neutral,positive,positive
257421556,"Thanks for digging into this! Your understanding seems correct to me. @danabo (who originally wrote the melody extractor), can you take a look at this too and see if this is correct?

Also adding @adarob and @elliotwaite who have worked on this code before.

Also, do any of you have thoughts on whether we should change this logic? Or just improve the error message?
",thanks digging understanding correct originally wrote melody extractor take look see correct also worked code also whether change logic improve error message,issue,negative,positive,positive,positive,positive,positive
257406138,"That is probably the best approach. The list of valid durations can always
increase later if people are running into a surprising number of unknown
durations.

On Mon, Oct 31, 2016 at 4:06 PM, cghawthorne notifications@github.com
wrote:

> ## _@cghawthorne_ commented on this pull request.
> 
> In magenta/models/polyphonic_rnn/polyphonic_rnn_lib.py
> https://github.com/tensorflow/magenta/pull/314:
> 
> > -            # Put silences back
> > -            new_down[new_down == -i] = 0.
> > -            # Edge case... shouldn't come up in general
> > -            new_down[new_down < 0.] = 1.
> >   +
> > -            new_ps_list.append(new_up)
> > -            new_ds_list.append(ds)
> >   +
> > -            new_ps_list.append(new_down)
> > -            new_ds_list.append(ds)
> > -        all_ds = np.concatenate(new_ds_list)
> > -        all_ps = np.concatenate(new_ps_list)
> >   +
> > -      self._min_time_data = np.min(all_ds)
> > -      self._max_time_data = np.max(all_ds)
> > -      self.time_classes = list(np.unique(all_ds.ravel()))
> 
> What about this as an approach: hard code a set of acceptable durations
> (possibly the one you already have for bach) and just skip any input that
> has a duration not in that set. This should work with any kind of input and
> won't cause problems if training and eval sets have different sets of
> durations.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/314, or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABfbHasw2yw5N5mEGLKPPY6CzhZ7EiuQks5q5ko3gaJpZM4Kj-0t
> .
",probably best approach list valid always increase later people running surprising number unknown mon wrote pull request put back edge case come general list approach hard code set acceptable possibly one already bach skip input duration set work kind input wo cause training different reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
257404106,"that sounds good to me

On Mon, Oct 31, 2016 at 3:57 PM, cghawthorne notifications@github.com
wrote:

> ## _@cghawthorne_ commented on this pull request.
> 
> In magenta/models/polyphonic_rnn/polyphonic_rnn_lib.py
> https://github.com/tensorflow/magenta/pull/314:
> 
> > +
> > +def ndim(x):
> > -  return len(shape(x))
> >   +
> >   +
> >   +# TODO: How can I correct this for shared / tied weights?
> >   +def print_network(params):
> > -  n_params = sum([np.prod(shape(p)) for p in params])
> > -  tf.logging.info('Total number of parameters: %fM' % (n_params / float(1E6)))
> >   +
> >   +
> >   +def dot(a, b):
> > -  # Generalized dot for nd sequences, assumes last axis is projection
> > -  # b must be rank 2
> > -  # rediculously hacky string parsing... wowie
> > -  a_tup = shape(a)
> 
> Chatted with @craffel https://github.com/craffel offline. I've updated
> the shape and ndims methods, but I'll leave the dot method as is until
> there's an official implementation.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/314, or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABfbHeRd_69zINxaf1RjswqkAsXCw9o2ks5q5kg7gaJpZM4Kj-0t
> .
",good mon wrote pull request return shape correct tied sum shape number float dot generalized dot last axis projection must rank hacky string shape shape leave dot method official implementation reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
257336509,"One other thing to think about in a potential future PR is incorporating parts of [Modelling Symbolic Music: Beyond the Piano Roll, C. Walder](https://arxiv.org/abs/1606.01368). See the [samples](http://users.cecs.anu.edu.au/~christian.walder/). As far as I can tell, he uses a groundtruth rhythm which includes time signature and every note duration, and resamples the pitch values conditional on that. This could potentially be incorporated simply by modifying the mask and sampling code for this polyphonic model, though a better version would just avoid parameterizing the softmax for duration at all. In general, that model sounds really good IMO and it seems like this kind of model (and/or the reverse - predict durations given pitches) could be a fun addition for Magenta
",one thing think potential future symbolic music beyond piano roll see far tell rhythm time signature every note duration pitch conditional could potentially incorporated simply mask sampling code polyphonic model though better version would avoid duration general model really good like kind model reverse predict given could fun addition magenta,issue,positive,positive,positive,positive,positive,positive
257335182,"Cool! I tried to leave comments on the parts that seem most relevant - you did an awesome job wrapping this. The main parts seem ok, and most (all) of my comments could be addressed in future PRs. Most are related to user interface in sampling, if you even end up using my functions for sampling -> MIDI. There are probably better ones in Magenta
",cool tried leave seem relevant awesome job wrapping main seem could future related user interface sampling even end sampling probably better magenta,issue,positive,positive,positive,positive,positive,positive
257188716,"Hi @cghawthorne ,

I've spent a few hours this afternoon getting a the Magenta dev environment setup and poking around the code base. It seems to me that the assertion error [here](https://github.com/tensorflow/magenta/blob/e1a4eebbac6cbce8a58beefc5152030a4af7a05a/magenta/models/melody_rnn/melody_rnn_sequence_generator.py#L95) (mentioned above) is not actually ""because at least one track needs to be monophonic"", **but rather** there cannot be more than one track that has an extractable monophonic melody. 

I've tested this theory by running `melody_rnn_generate` on a MIDI file that I have constructed with two monophonic tracks. When I do this I get the above assertion error: `assert len(extracted_melodies) <= 1`. However, if I remove one of these two tracks (thus setting the length of `evaluated_melodies` to 1 instead of 2), I get no error and a midi file is generated correctly. I've tested this with multiple midi files and it consistently fails whenever there is more than one track with a monophonic melody (which does seem to be what the assert is testing for) present in the file. 

I've made what appear to be the necessary changes to 1) provide an error message to the user as to why their `melody_rnn_generate` command is failing if they are trying to prime from a midi file with more than one track, and 2) updates the melody_rnn/README to notify users of this current limitation. You can preview these changes in [this commit](https://github.com/brannondorsey/magenta/commit/2181af5238714bb92d6e1996fb952ea1fd01c965).

I have yet to submit a PR because I want to confirm that my observations are correct, especially as they contradict your description of the error.

If this seems good let me know and I will submit the PR from [this branch](https://github.com/brannondorsey/magenta/tree/issue-296), otherwise maybe you could provide some further insight?

Thanks!
",hi spent afternoon getting magenta dev environment setup poking around code base assertion error actually least one track need monophonic rather one track extractable monophonic melody tested theory running file two monophonic get assertion error assert however remove one two thus setting length instead get error file correctly tested multiple consistently whenever one track monophonic melody seem assert testing present file made appear necessary provide error message user command failing trying prime file one track notify current limitation preview commit yet submit want confirm correct especially contradict description error good let know submit branch otherwise maybe could provide insight thanks,issue,negative,negative,neutral,neutral,negative,negative
257060411,"@kastnerkyle feel free to review if you'd like!
",feel free review like,issue,positive,positive,positive,positive,positive,positive
257046707,"Ah, ok great, thanks! I'll see if I can devote a bit of time in the coming days to dig in and perhaps submit a PR.  
",ah great thanks see devote bit time coming day dig perhaps submit,issue,positive,positive,positive,positive,positive,positive
257046133,"Hi Brannon,

The file doesn't need to be monophonic, but it does need to have at least 1 track that is monophonic so our melody extractor can find something that looks like a melody. There's a bit more information about how this works here: https://github.com/tensorflow/magenta/blob/master/magenta/music/melodies_lib.py#L522

We'd be happy to accept a pull request with better docs or improved error messages!
",hi file need monophonic need least track monophonic melody extractor find something like melody bit information work happy accept pull request better error,issue,positive,positive,positive,positive,positive,positive
257045407,"This should be relatively easy to do by adding a flag to melody_rnn_generate.py that results in removing notes in generated_sequence that start before the calculated start_time in the generate_section request.

It might be a little bit before one of us can get to this, but we'd be happy to accept a pull request!
",relatively easy flag removing start calculated request might little bit one u get happy accept pull request,issue,positive,positive,positive,positive,positive,positive
256378000,"I believe this latest commit addresses all issues raised so far. I have implemented the note.numerator and note.denominator support (@douglaseck's TODO)
",believe latest commit raised far support,issue,positive,positive,positive,positive,positive,positive
256089784,"I would also like to see a feature along the lines of this. I believe as of now you would have to generate a midi file much longer than the primer file and then manually (or via scripting) remove the primer portion. The ability to give a primer of an entire file and then have Magenta generate a completely different track similar to/based on the primer is something I find myself really wanting to be able to do.
",would also like see feature along believe would generate file much longer primer file manually via remove primer portion ability give primer entire file magenta generate completely different track similar primer something find really wanting able,issue,positive,positive,positive,positive,positive,positive
255458150,"I updated this to use the GeneratorOptions to pass beam search parameters.

However, there's an issue with batch size.  If at all possible, I'd really like to require that beam size and batch size are the same; the code will be a lot messier otherwise.  Unfortunately batch size is currently fixed by the graph itself, and it looks nontrivial to remove this.  (It's also fixed at 1 in our existing bundles.)
",use pas beam search however issue batch size possible really like require beam size batch size code lot otherwise unfortunately batch size currently fixed graph remove also fixed,issue,negative,negative,neutral,neutral,negative,negative
255285166,"@cghawthorne 

Yes, I would love to do this either tomorrow or Saturday. ( I just got a new job and lost a lot of time to freely program :grinning: )

I can replicate the full output then. 

Ya, I'm wondering if my theory was right. I would be proud if I could guess that bit. :+1: 
",yes would love either tomorrow got new job lost lot time freely program grinning replicate full output ya wondering theory right would could guess bit,issue,positive,positive,positive,positive,positive,positive
255244285,"Discussed offline. The changes are supposed to be backwards compatible, so this should just handle itself.
",supposed backwards compatible handle,issue,negative,neutral,neutral,neutral,neutral,neutral
255183370,"I looked into this a little more. The only way I know to fix this completely with Bazel would be to use a bazel.rc template that is filled out by a configure script, similar to what Tensorflow does: https://github.com/tensorflow/tensorflow/blob/master/tools/bazel.rc.template

A configure script seems a little heavy for Magenta, but there are a couple ways to make this work a little better:
- Make sure you do a `bazel shutdown` after changing conda/virtualenv environments. This will force bazel to re-evaluate the location of the python interpreter.
- Instead of using bazel, use our new pip package to install the Magenta scripts. We released this just last week and updated the main README file with instructions on how to use it.
",little way know fix completely would use template filled configure script similar configure script little heavy magenta couple way make work little better make sure shutdown force location python interpreter instead use new pip package install magenta last week main file use,issue,positive,positive,neutral,neutral,positive,positive
254958040,"@iansimon: Thanks for fixing the lint errors. I have been extremely busy at work and was hoping to work more on this code at the Classical Music Hack Day at MIT this coming weekend.
",thanks fixing lint extremely busy work work code classical music hack day coming weekend,issue,negative,positive,positive,positive,positive,positive
254957610,"I fixed many of the lint errors, mainly just ones that required no understanding of the code.  There are still several that remain, largely missing/malformed docstring sections.  There's also a CURRENT_DIVISIONS variable in musicxml_parser.py that is commented out in some places but not others.
",fixed many lint mainly understanding code still several remain largely also variable,issue,negative,positive,positive,positive,positive,positive
254580348,"In addition to the readme, you might want to put example usage at the top of melody_rnn_create_dataset.py, melody_rnn_train.py, and melody_rnn_generate.py showing how to run these scripts.
",addition might want put example usage top showing run,issue,negative,positive,positive,positive,positive,positive
254388257,"Looks good. It actually improves readability, nice.
",good actually readability nice,issue,positive,positive,positive,positive,positive,positive
254288065,"There seems to be a missing file el_capitan.xml being referred to in your tests.  Did you forget to check this in?
",missing file forget check,issue,negative,negative,negative,negative,negative,negative
254050417,"Hi,
Can anyone take up this issue??
",hi anyone take issue,issue,negative,neutral,neutral,neutral,neutral,neutral
253596901,"The metronome remains constant without joining the thread, just the clicks
are audible or not. I'll add midi clock support to that later tonight which
will require a continuous metronome.

also re:Link...I also think Link only works for Ableton to send clock
information. When receiving I think it has to be in external mode so then
it relies on midi clock or midi timecode anyway. But I have to revisit that
to be sure

On Thu, Oct 13, 2016 at 11:07 AM, Adam Roberts notifications@github.com
wrote:

> Is this change essentially equivalent to stopping and restarting the
> metronome with the same start_time? That was how I was handling this for
> now.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/273#issuecomment-253591859,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AP7D9XjFS382Q_ZvtC5CU-j0CU5NJ2qoks5qznNEgaJpZM4KVfrE
> .
",metronome remains constant without joining thread audible add clock support later tonight require continuous metronome also link also think link work send clock information think external mode clock anyway revisit sure wrote change essentially equivalent stopping metronome handling thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
253591859,"Is this change essentially equivalent to stopping and restarting the metronome with the same start_time? That was how I was handling this for now.
",change essentially equivalent stopping metronome handling,issue,negative,neutral,neutral,neutral,neutral,neutral
253562864,"I agree that Link is a nice way to talk between devices, but it gets a bit
tricky because it is doing some time conversion of its own between wall
time and sample based time. One of my main concerns is how tempo changes
are currently handled internally within magenta (which is ""not at all"")
independent of any sync mechanism. How the tempo is passed to and from the
hub based on the wall clock was decided under the assumption that magenta
would always be the master and not have update-able tempo during capture or
playback. So Link might be able to inform that there is a tempo change
externally, but how it would be handled is the question. And while
midi-clock messages to slaves are less resolute and more jitter prone, it
communicates well with any MIDI capable software and hardware devices. So I
am totally into using sync tools like Link but think there are some other
fundamental timing considerations to adjust to really make it useful.

On Thu, Oct 13, 2016 at 8:36 AM, Jesse Engel notifications@github.com
wrote:

> This feature doesn't hurt, but fwiw, I think syncing with pulse messages
> is real messy, best handled by protocols such as Link (
> https://github.com/Ableton/link). For us, it seems like the easiest
> option is to have start/stop events controlled by events sent from the host
> software rather than trying to sync a host to some metronome of our own.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/273#issuecomment-253550720,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AP7D9U_ivVabuINPNjaoOIPfeXKExe4yks5qzlAYgaJpZM4KVfrE
> .
",agree link nice way talk bit tricky time conversion wall time sample based time one main tempo currently handled internally within magenta independent sync mechanism tempo hub based wall clock decided assumption magenta would always master tempo capture playback link might able inform tempo change externally would handled question le resolute jitter prone well capable hardware totally sync like link think fundamental timing adjust really make useful wrote feature hurt think pulse real messy best handled link u like easiest option sent host rather trying sync host metronome thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
253550720,"This feature doesn't hurt, but fwiw, I think syncing with pulse messages is real messy, best handled by protocols such as Link (https://github.com/Ableton/link). For us, it seems like the easiest option is to have start/stop events controlled by events sent from the host software rather than trying to sync a host to some metronome of our own. 
",feature hurt think pulse real messy best handled link u like easiest option sent host rather trying sync host metronome,issue,positive,positive,positive,positive,positive,positive
253007062,"@vmeade I'm having trouble reproducing this problem. Can you paste the full output of that command?  In particular, I'm interested in what Bazel says for the ""Running command line"" output. Here's what it looks like for me:

```
# bazel run //magenta/models/basic_rnn:basic_rnn_generate -- \
> --bundle_file=/magenta-models/basic_rnn.mag \
> --output_dir=/magenta-data \
> --num_outputs=10 \
> --num_steps=128 \
> --primer_melody=""[60]""
INFO: Reading 'startup' options from /root/.bazelrc: --batch
WARNING: /root/.cache/bazel/_bazel_root/cb5f479c6a7afa91f510d7ce625f6aa5/external/protobuf/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/cb5f479c6a7afa91f510d7ce625f6aa5/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 1 target...
Target //magenta/models/basic_rnn:basic_rnn_generate up-to-date:
  bazel-bin/magenta/models/basic_rnn/basic_rnn_generate
INFO: Elapsed time: 3.384s, Critical Path: 0.39s

INFO: Running command line: bazel-bin/magenta/models/basic_rnn/basic_rnn_generate '--bundle_file=/magenta-models/basic_rnn.mag' '--output_dir=/magenta-data' '--num_outputs=10' '--num_steps=128' '--primer_melody=[60]'
INFO:tensorflow:Wrote 10 MIDI files to /magenta-data

```
",trouble problem paste full output command particular interested running command line output like run reading batch warning name match name given repository definition cause build error future found target target time critical path running command line wrote,issue,negative,positive,neutral,neutral,positive,positive
252984622,"Will do

> On Oct 10, 2016, at 1:28 PM, Adam Roberts notifications@github.com wrote:
> 
> @hanzorama, agreed that we should add a count-off at some point. Feel free to do it if you have time! I've added clarification about the beats per bar. Thanks.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",wrote agreed add point feel free time added clarification per bar thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
252736868,"@hanzorama, agreed that we should add a count-off at some point. Feel free to do it if you have time! I've added clarification about the beats per bar. Thanks. 
",agreed add point feel free time added clarification per bar thanks,issue,positive,positive,positive,positive,positive,positive
252448164,"@x267wu 
Thanks, I'm on Windows. I'll look at the code when I have time and see if i can figure out why the path gets written to /tmp/, I'm sure it's within the bundle_file. It's the only place where there could be this variation. Plus I think magenta was intended through it's stack to primarily run on apple computers so it would make sense the programs would utilize a standard feature of the apple operating system.
",thanks look code time see figure path written sure within place could variation plus think magenta intended stack primarily run apple would make sense would utilize standard feature apple operating system,issue,positive,positive,positive,positive,positive,positive
252362393,"You can open the /tmp folder on a Mac by typing `open /tmp` in the terminal,
hope that helps!
",open folder mac open terminal hope,issue,negative,neutral,neutral,neutral,neutral,neutral
252355856,"@jesseengel, I accidentally merged this prematurely. Please review and we will revert if needed.
",accidentally prematurely please review revert,issue,negative,neutral,neutral,neutral,neutral,neutral
251765810,"@iansimon: I am getting a pylint error that I don't know how to resolve. 

Bad option value 'g-import-not-at-top' (bad-option-value)

Please compare with the code here:
https://github.com/tensorflow/magenta/blob/master/magenta/music/midi_io.py#L21
",getting error know resolve bad option value please compare code,issue,negative,negative,negative,negative,negative,negative
251477239,"@iansimon: Thanks. I'm linting the code right now using that pylint configuration. Not done yet, but soon. Then I will address remaining issues raised by @cghawthorne.
",thanks code right configuration done yet soon address raised,issue,negative,positive,positive,positive,positive,positive
250999803,"I'll close this. After 5 consecutive cleans and rebuilds, all the tests passed. There is no sane reason for this, and I am certain no definitive solution exists to deal with Bazel. 
",close consecutive sane reason certain definitive solution deal,issue,positive,positive,positive,positive,positive,positive
250872185,"Closing due to lack of activity. Please reopen if you're still having problems.
",due lack activity please reopen still,issue,negative,negative,negative,negative,negative,negative
250867780,"I recommend running pylint on your code.  You can even get something close to Google's linter configuration, described in this StackOverflow answer: http://stackoverflow.com/questions/29597618/is-there-a-tool-to-lint-python-based-on-the-google-style-guide

Basically, install pylint, download that googlecl-pylint.rc file, then run:

`pylint --rcfile=/path/to/googlecl-pylint.rc <your files>`
",recommend running code even get something close linter configuration answer basically install file run,issue,negative,neutral,neutral,neutral,neutral,neutral
250662526,"I signed it. Maybe the email address is not matching up with my gmail address. I put in my github username in the CLA
",maybe address matching address put,issue,negative,neutral,neutral,neutral,neutral,neutral
250625139,"@unboundmusic, please sign the CLA or I will need to create a separate PR to get this fix in. Thanks!
",please sign need create separate get fix thanks,issue,positive,positive,positive,positive,positive,positive
250379936,"Added the above change @cghawthorne thanks for the note.
",added change thanks note,issue,negative,positive,positive,positive,positive,positive
250319334,"I wasn't running the bazel test correctly, so I tried it in interactive Python. Once I ran the bazel test correctly, I was able to resolve the issue; the bazel tests now pass on my system.
",running test correctly tried interactive python ran test correctly able resolve issue pas system,issue,negative,positive,positive,positive,positive,positive
250312649,"Are you having issues when running bazel test, or only in interactive python?  When working on libraries for core magenta, we recommend testing via bazel.
",running test interactive python working core magenta recommend testing via,issue,negative,neutral,neutral,neutral,neutral,neutral
250182160,"I'm still getting errors. I checked out the master branch at commit 0056294, which includes #223. When I try to import using python, I get this error:

```
>>> from magenta.protobuf import music_pb2
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""magenta/__init__.py"", line 26, in <module>
    import magenta.music.melodies_lib
ImportError: No module named music.melodies_lib
```

This does include the new /music directory, and the BUILD file there looks correct.
",still getting checked master branch commit try import python get error import recent call last file line module file line module import module include new directory build file correct,issue,negative,positive,neutral,neutral,positive,positive
250125472,"Sure, I'm new to Docker, is there anything significant about the /magenta-data folder itself? There's a warning that calls it out here, I can edit this as well to be more generic:

> WARNING: only data saved in /magenta-data will persist across Docker sessions.
",sure new docker anything significant folder warning edit well generic warning data saved persist across docker session,issue,negative,positive,positive,positive,positive,positive
250042597,"I think you're running into a merge conflict with #223. We recently moved a bunch of our modules that used to be in /lib to /music. You'll probably also want your musicxml code to be in /music now.
",think running merge conflict recently bunch used probably also want code,issue,negative,neutral,neutral,neutral,neutral,neutral
250012201,"In process of updating my code. I just rebased against master, and am now getting this error when running the unit tests:

```
Traceback (most recent call last):
  File ""musicxml_parser_test.py"", line 20, in <module>
    from musicxml_reader import *
  File ""/Users/jsawruk/magenta/magenta/music/musicxml_reader.py"", line 29, in <module>
    from magenta.protobuf import music_pb2
ImportError: No module named magenta.protobuf
```

What changed?
",process code master getting error running unit recent call last file line module import file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
249977549,"Hey @elburz, feel free to submit a pull request if you have thoughts on how to make the documentation more clear. I'd suggest we leave the non-Docker documentation using /tmp because most systems won't have a /magenta-data directory (and probably wouldn't want to make one).
",hey feel free submit pull request make documentation clear suggest leave documentation wo directory probably would want make one,issue,positive,positive,positive,positive,positive,positive
249925965,"@jsawruk: sorry about the confusion here.  It looks like we're not able to map your GitHub username to the email address used in your commits.  Could you add your *@jwpepper.com email address [to your GitHub account](https://help.github.com/articles/adding-an-email-address-to-your-github-account/)?  That should take care of this.
",sorry confusion like able map address used could add address account take care,issue,negative,neutral,neutral,neutral,neutral,neutral
249853471,"The issue is your output_dir variable should match the 2nd half of your docker path assignment, not the first. The first is the path on your local machine, and the 2nd path is the corresponding path in the docker session. So you should do this to correspond with that docker run command :

`output_dir=/magenta-data`
",issue variable match half docker path assignment first first path local machine path corresponding path docker session correspond docker run command,issue,negative,positive,neutral,neutral,positive,positive
249831091,"![untitled](https://cloud.githubusercontent.com/assets/22435073/18870406/505e71ea-8465-11e6-8b3c-efbf203a27b3.jpg)

a view of the chaos... i see the folders but can not access them?
",untitled view chaos see access,issue,negative,neutral,neutral,neutral,neutral,neutral
249828616,"Basically I know this happened because one time I misspelled a path for the output_div and docker created the folder set (with the misspelling) on my harddrive 

I think the

 docker run -it -p 6006:6006 **C:/magenta:/magenta-data** tensorflow

**output_dir=/c/Users/Vincent/notebooks**

might be it but i'll have to check tomorrow.
",basically know one time path docker folder set misspelling think docker run might check tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
249791790,"Great. Please close this issue if it's solved.
",great please close issue,issue,positive,positive,positive,positive,positive,positive
249789665,"Wow, I see ten midi's within the container by

cd /magenta-data/lookback_rnn/generated

ls

You definitely solved it, congrats and thank you!
",wow see ten within container definitely thank,issue,positive,positive,neutral,neutral,positive,positive
249785905,"Also noticed you can just skip the step because the download should already be there. So you can change this

BUNDLE_PATH=<absolute path of basic_rnn.mag>

bazel run //magenta/models/basic_rnn:basic_rnn_generate -- \
--bundle_file=${BUNDLE_PATH} \
--output_dir=/tmp/basic_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""

And instead just point to the bundle_file in the flags like:

bazel run //magenta/models/basic_rnn:basic_rnn_generate -- \
--bundle_file=/magenta-models/basic_rnn.mag \
--output_dir=/tmp/basic_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""
",also skip step already change absolute path run instead point like run,issue,negative,positive,positive,positive,positive,positive
249785400,"We'll get you there! If you've got your shared folder working then I think it might be a case of updating the output path in the bazel commands. 

An easy way to test to make sure your shared folder is working is to go into the docker session, navigate to your folder with `cd /magenta-data` and do a `mkdir test` you should see a folder named test pop up on the windows side in the shared folder.
",get got folder working think might case output path easy way test make sure folder working go docker session navigate folder test see folder test pop side folder,issue,positive,positive,positive,positive,positive,positive
249784868,"Unfortunately not. I think it's something to do with the nature of a Windows 7 Path that Magenta recognizes but doesn't compute...

I'm just reading your message now... okay I'm going try this. 

This I'm thinking I'm understanding, this would explain the missing link between the Docker folder and my local machine. I'll see if I can configure it right and get success.

I didn't believe I had the knowledge power to set this up but I'm literally 95% of the way through, so if I get this to work I'll be happy and proud.
",unfortunately think something nature path magenta compute reading message going try thinking understanding would explain missing link docker folder local machine see configure right get success believe knowledge power set literally way get work happy,issue,positive,positive,positive,positive,positive,positive
249783971,"I just ran one of the other examples and think I know where you're stuck on this one. On the default example on the front page, they took this piece of code

`bazel run //magenta/models/lookback_rnn:lookback_rnn_generate -- \
--bundle_file=/magenta-models/lookback_rnn.mag \
--output_dir=/magenta-data/lookback_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""
`

And the person who wrote it made the `--output_dir=` match the directory in the earlier steps when you launched the instance with `docker run -it -p 6006:6006 -v /tmp/magenta:/magenta-data tensorflow/magenta`. So you see when you ran the container, you made the shared folder `:/magenta-data`.

In the examples on the other pages, the `--output_dir=` is still set to tmp like in this example from the basic_rnn realm

`bazel run //magenta/models/basic_rnn:basic_rnn_generate -- \
--bundle_file=${BUNDLE_PATH} \
--output_dir=/tmp/basic_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""`

So you'd want to change the `/tmp/basic_rnn/generated` to be `/magenta-data/basic_rnn/generated` or whatever you designated the shared folder as when you boot the container. 
",ran one think know stuck one default example front page took piece code run person wrote made match directory instance docker run see ran container made folder still set like example realm run want change whatever folder boot container,issue,negative,neutral,neutral,neutral,neutral,neutral
249783403,"Did you download the file basic_rnn.mag and put it on the machine? It's one of the steps listed on this page under Pre-Trained. You can download it and put it in the shared folder you designated, then use the `BUNDLE_PATH=<path_here.mag>` to point at the downloaded file.

https://github.com/tensorflow/magenta/tree/master/magenta/models/basic_rnn
",file put machine one listed page put folder use point file,issue,negative,neutral,neutral,neutral,neutral,neutral
249781165,"Were you able to find it based on the other discussion? 

https://github.com/tensorflow/magenta/issues/221
",able find based discussion,issue,negative,positive,positive,positive,positive,positive
249669175,"@elburz
Ya, I'm going to try 
docker run -it -p 6006:6006 -v C:/magenta:/magenta-data tensorflow/magenta

bazel run //magenta/models/lookback_rnn:lookback_rnn_generate -- \
--bundle_file=/magenta-models/lookback_rnn.mag \
--output_dir=/magenta-data/lookback_rnn/generated \
--num_outputs=10 \
--num_steps=128 \
--primer_melody=""[60]""

If it works I'll share the piece.

@douglaseck 
Ya, I can understand. I just was captivated by the whole early stages of the movement of these things and wound up getting this far working through docker,msys,bazel,tensorflow, and then magenta.
",ya going try docker run run work share piece ya understand whole early movement wound getting far working docker magenta,issue,negative,positive,positive,positive,positive,positive
249663789,"I'm unaware of how to access /tmp on a Windows. I did quick tests on a Mac and used my home folder `~/magenta:/magenta-data` . So you may want to do something similar but for Windows, like `C:/magenta:/magenta-data`
",unaware access quick mac used home folder may want something similar like,issue,negative,positive,positive,positive,positive,positive
249663773,"I'm not sure where the temp directory is created in Windows.  Any Windows
users able to help?

In general TensorFlow life is easier on Linux and Mac OSX.

On Mon, Sep 26, 2016 at 11:55 AM, vmeade notifications@github.com wrote:

> Do I need to create the folder /tmp/magenta prior to running the
> lookback_rnn in order for Docker to find this folder?
> 
> The folder currently doesn't exist on my computer or it is extremely
> hidden.
> I'm not sure if running in Windows will have an effect about any of this?
> 
> Thanks for the help so far.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/221#issuecomment-249663025,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/APQ6QhWtO5qh37MDe1rBO-O1JaiFRuTYks5quBUUgaJpZM4KG0U0
> .
",sure temp directory able help general life easier mac mon wrote need create folder prior running order docker find folder folder currently exist computer extremely hidden sure running effect thanks help far thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
249663025,"Do I need to create the folder /tmp/magenta prior to running the lookback_rnn in order for Docker to find this folder?

The folder currently doesn't exist on my computer or it is extremely hidden.
I'm not sure if running in Windows will have an effect about any of this?

Thanks for the help so far.
",need create folder prior running order docker find folder folder currently exist computer extremely hidden sure running effect thanks help far,issue,positive,positive,positive,positive,positive,positive
249661801,"When you run the Docker script, this part ""/tmp/magenta:/magenta-data"" assigned a folder on your local system at /tmp/magenta to the folder on the Docker container /magenta-data. By default I believe the midi files are written to /magenta-data, so you'd just need to go on your local machine to /tmp/magenta, or wherever you specified that folder to be.
",run docker script part assigned folder local system folder docker container default believe written need go local machine wherever folder,issue,negative,neutral,neutral,neutral,neutral,neutral
249660382,"Hi @cghawthorne.

In the end of computing the lookback_rnn example I get ""INFO:tensorflow:Wrote 10 MIDI files to /magenta-data/lookback_rnn/generated""

I thought the files would be written onto my computer, but couldn't find them. I then looked to see if they were in a directory in Docker and that's why I was trying to copy them from there but I may have had a misunderstanding.

Do you know where the location of these MIDIs are? 

I ran the ""cp file.mid /magenta-data""

but got ""cp: cannot stat 'file.mid': No such file or directory""

I apologize for being a beginner if I have done something wrong because many things aren't obvious to me. 
",hi end example get wrote thought would written onto computer could find see directory docker trying copy may misunderstanding know location ran got file directory apologize beginner done something wrong many obvious,issue,negative,neutral,neutral,neutral,neutral,neutral
249648640,"Hi @vmeade. If you start docker using the command listed in our readme, then the folder /magenta-data within the Docker container will be mapped to /tmp/magenta on your host machine.

```
docker run -it -p 6006:6006 -v /tmp/magenta:/magenta-data tensorflow/magenta
```

So, to copy a file to the host machine from within Docker, you would just run `cp file.mid /magenta-data`.
",hi start docker command listed folder within docker container host machine docker run copy file host machine within docker would run,issue,negative,neutral,neutral,neutral,neutral,neutral
249268021,"I updated the contact info email address on the CLA to match the email address on my Github account. Hopefully this resolves the issue.
",contact address match address account hopefully issue,issue,negative,neutral,neutral,neutral,neutral,neutral
249266823,"@jsawruk the cla bot still doesn't seem happy. Can you try replying using the github web interface?
",bot still seem happy try web interface,issue,positive,positive,positive,positive,positive,positive
249257594,"I signed it!

On Thu, Sep 15, 2016 at 3:56 PM, googlebot notifications@github.com wrote:

> Thanks for your pull request. It looks like this may be your first
> contribution to a Google open source project. Before we can look at your
> pull request, you'll need to sign a Contributor License Agreement (CLA).
> 
> 📝 _Please visit https://cla.developers.google.com/
> https://cla.developers.google.com/ to sign._
> 
> Once you've signed, please reply here (e.g. I signed it!) and we'll
> 
> ## verify. Thanks.
> - If you've already signed a CLA, it's possible we don't have your
>   GitHub username or you're using a different email address. Check your
>   existing CLA data https://cla.developers.google.com/clas and verify
>   that your email is set on your git commits
>   https://help.github.com/articles/setting-your-email-in-git/.
> - If you signed the CLA as a corporation, please let us know the
>   company's name.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/214#issuecomment-247435189,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAZxWQclQSKQz5a6tlNA4FwAtj84Zpu2ks5qqaLdgaJpZM4J-R_e
> .
",wrote thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo visit please reply verify thanks already possible different address check data verify set git corporation please let u know company name thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
249211036,"Probably just changing from `/usr/bin/python` to `/usr/bin/env python` everywhere should do the trick.
",probably python everywhere trick,issue,negative,neutral,neutral,neutral,neutral,neutral
247455644,"I'll take a look also.

-Ian

On Thu, Sep 15, 2016 at 2:02 PM cghawthorne notifications@github.com
wrote:

> Yup, I can definitely look at it. Wouldn't mind a second pair of eyes,
> though.
> 
> @jsawruk https://github.com/jsawruk we'll start the review once the CLA
> is signed. Thanks again for your work on this!
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/214#issuecomment-247454618,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABTHb6_coRvnUz7DefMLSn9WPol1tVzlks5qqbJwgaJpZM4J-R_e
> .
",take look also wrote definitely look would mind second pair though start review thanks work reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
247454618,"Yup, I can definitely look at it. Wouldn't mind a second pair of eyes, though.

@jsawruk we'll start the review once the CLA is signed. Thanks again for your work on this!
",definitely look would mind second pair though start review thanks work,issue,positive,positive,neutral,neutral,positive,positive
246743385,"Thanks @unboundmusic! Please let us know when you sign the CLA so we can merge in your fix.
",thanks please let u know sign merge fix,issue,positive,positive,positive,positive,positive,positive
245791331,"Thanks Adam,

The problem has solved!
The import error has disappeared after rebuilding my binaries as follows.

```
bazel build //magenta/models/${RNN_TYPE}:${RNN_TYPE}_train    # This line is added

./bazel-bin/magenta/models/$RNN_TYPE/${RNN_TYPE}_train --run_dir=$RUN_DIR --sequence_example_file=$TRAIN_DATA --hparams=$HPARAMS --num_training_steps=$NUM_TRAINING_STEPS &
```

It was my bad.
Thanks for your help ;)

Makoto
",thanks problem import error build line added bad thanks help,issue,negative,negative,neutral,neutral,negative,negative
245622554,"Can you share the command you are giving that leads to these errors? Have you rebuilt your binaries with bazel build?
",share command giving rebuilt build,issue,positive,neutral,neutral,neutral,neutral,neutral
245004170,"@Mistobaan do you have some pointers on what that change would look like?
",change would look like,issue,negative,neutral,neutral,neutral,neutral,neutral
244462203,"Closing due to inactivity. Please reopen if you are still having this problem.
",due inactivity please reopen still problem,issue,negative,negative,negative,negative,negative,negative
244427107,"Good call. Updating to the latest version (r0.10) seems to have ditched the error. Thanks!
",good call latest version error thanks,issue,negative,positive,positive,positive,positive,positive
244278693,"I'm using it internally to make it equivalent to the MR version.

On Thu, Sep 1, 2016 at 9:08 PM, Daniel Abolafia notifications@github.com
wrote:

> Is this change being used anywhere?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/191#issuecomment-244278429,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABCa6DR-iU6GnwuEk33M6J77BWz-LX_Dks5ql6ErgaJpZM4JzOjy
> .
",internally make equivalent version wrote change used anywhere thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
243881550,"Hi Travis. From my experience, this is usually caused by the length of the
melody you extracted. You can limit this with the max_steps_truncate
argument in extract_melodies. Try something like 512.

On Wed, Aug 31, 2016 at 12:26 PM, Travis Briggs notifications@github.com
wrote:

> Within 33 seconds of starting training, I ran into:
> https://gist.github.com/audiodude/a31a489ac4cad20a67319d039abcf497
> 
> It says it's out of memory, but I'm not sure what the ""chunks"" are or how
> it's reporting the memory being used. Is this related to the number of MIDI
> files I fed into it (~2700)?
> 
> Thanks!
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/185, or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABCa6AzkDe3_qIEoCtL6kKe1Oqz5fa20ks5qldV8gaJpZM4Jx-Qq
> .
",hi travis experience usually length melody extracted limit argument try something like wed travis wrote within starting training ran memory sure memory used related number fed thanks thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
243879677,"Do you know if you're using tensorflow with GPU usage enabled? You might not have enough space on your GPU, or it may be in use for something else. Can you try running with CPU-only tensorflow and see if you get the same error?
",know usage might enough space may use something else try running see get error,issue,negative,neutral,neutral,neutral,neutral,neutral
243638650,"Thank you for your reply! It's very helpful to me, and I'll try another piece.
",thank reply helpful try another piece,issue,positive,neutral,neutral,neutral,neutral,neutral
243564048,"Also, Neoanarika, since you are on Windows change the file paths to drive:/... and change forward slashes to back slashes and see if that works.
",also since change file drive change forward back see work,issue,negative,neutral,neutral,neutral,neutral,neutral
243563587,"So allow relative path? I'm not sure where the base path would be, but sure that is reasonable.
",allow relative path sure base path would sure reasonable,issue,positive,positive,neutral,neutral,positive,positive
243558322,"When I ran the melody extractor with my change over your mid files I got this output:
INFO:tensorflow:Processed 2 inputs total. Produced 0 outputs.
INFO:tensorflow:DAGPipeline_Quantizer_sequences_discarded_because_multiple_time_signatures: 2

The reason for discarding the sequences is now displayed.
",ran melody extractor change mid got output total produced reason displayed,issue,negative,neutral,neutral,neutral,neutral,neutral
243555477,"npuichigo, both mid files you shared contain multiple time signatures. The Bach piece switches time sig frequently. The HP piece has a 4/4 and 6/8 time sig both at time zero for some reason. Since some models use information about where notes are in the bar, we wanted to avoid complicating things and we discard MIDIs with multiple time signatures.

I'll add a message that counts how many samples are discarded because of multiple time signatures so this is clear in the future. Sorry for the inconvenience. 
",mid contain multiple time bach piece time sig frequently piece time sig time zero reason since use information bar avoid discard multiple time add message many multiple time clear future sorry inconvenience,issue,negative,positive,neutral,neutral,positive,positive
243551350,"Hi @Neoanarika. Can you paste the entire sequence of commands and outputs that you see in your Magenta session? The only way you should get an error like that is if your --output_file flag does not contain a directory.

@danabo, do you think we should change the code in convert_midi_dir_to_note_sequences.py to support supplying an output_file without a directory path?
",hi paste entire sequence see magenta session way get error like flag contain directory think change code support without directory path,issue,negative,neutral,neutral,neutral,neutral,neutral
243549255,"Hi @jeffehobbs. What version of tensorflow do you have installed when you see this error?
",hi version see error,issue,negative,neutral,neutral,neutral,neutral,neutral
243548402,"@danabo do you know what's happening with the input pipeline here?
",know happening input pipeline,issue,negative,neutral,neutral,neutral,neutral,neutral
243547115,"Agreed that this will become more important as Magenta develops more complex models. We'll definitely keep it in mind!
",agreed become important magenta complex definitely keep mind,issue,positive,positive,neutral,neutral,positive,positive
242046720,"Thanks for sharing all this!

Is there someway I personally can contribute to as well? Some tasks still to be done? Some guidelines etc? I am trying to get started with some small contributions to open source. 
",thanks someway personally contribute well still done trying get small open source,issue,positive,negative,neutral,neutral,negative,negative
241958658,"No you didn't miss any documentation. It was idiomatic English, and you
understood it completely. :-) It's not easy to do polyphonic prediction,
but with some care perhaps we can make it happen without too much
refactoring on everyone's part.

On Tue, Aug 23, 2016 at 9:21 PM, Prakhar Shukla notifications@github.com
wrote:

> Thanks so much for sharing the information. This explains a lot.
> 
> One question however, what did you mean by (read ""not horribly painful"").
> Although I think I understand, what it meant to convey was that the problem
> at hand wasn't too easy, is there some documentation that I missed out
> completely?
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/123#issuecomment-241953674,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/APQ6QmHxIiJVur32dF-9EQqPdm8Ujpy-ks5qi8bKgaJpZM4JY3B_
> .
",miss documentation idiomatic understood completely easy polyphonic prediction care perhaps make happen without much everyone part tue wrote thanks much information lot one question however mean read horribly painful although think understand meant convey problem hand easy documentation completely reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
241956933,"Usually to solve these kinds of fundamental problems, you are working at
the level of Tensorflow itself. I cannot think of any easy way to get the
flexibility (at least I) needed for this task without dropping down to that
level. Hopefully the rest of my internship (til September 2.) will focus on
getting some code cleanup and trying to integrate with the existing Magenta
API. The model itself is not terribly complicated, but there are some
tricky things data-wise I think, especially handling other people's files
and getting different voices out.

Plus, my code still has little scars and stubs from all my failed
ideas/models :p It's not messy exactly, more like wounded in (research)
battle.

On Tue, Aug 23, 2016 at 9:21 PM, Prakhar Shukla notifications@github.com
wrote:

> Thanks so much for sharing the information. This explains a lot.
> 
> One question however, what did you mean by (read ""not horribly painful"").
> Although I think I understand, what it meant to convey was that the problem
> at hand wasn't too easy, is there some documentation that I missed out
> completely?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/123#issuecomment-241953674,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABfbHaAZqpUBEzuJ9xLfnccpFCPyHA2Oks5qi8bLgaJpZM4JY3B_
> .
",usually solve fundamental working level think easy way get flexibility least task without dropping level hopefully rest internship til focus getting code cleanup trying integrate magenta model terribly complicated tricky think especially handling people getting different plus code still little messy exactly like wounded research battle tue wrote thanks much information lot one question however mean read horribly painful although think understand meant convey problem hand easy documentation completely reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
241953674,"Thanks so much for sharing the information. This explains a lot. 

One question however, what did you mean by `(read ""not horribly painful"")`. Although I think I understand, what it meant to convey was that the problem at hand wasn't too easy, is there some documentation that I missed out completely?
",thanks much information lot one question however mean read horribly painful although think understand meant convey problem hand easy documentation completely,issue,negative,negative,neutral,neutral,negative,negative
241947713,"Magenta intern @kastnerkyle has done some nice polyphonic work. But it's not ready for release.  Messy code, Kyle? :-) In general the reason why is that it's a lot harder than monophonic prediction. With monophonic prediction, you can sample from a single softmax, but once you add multiple notes (and worse, maybe 1,2,3,4,5 .. however many at one time) the possible combinations of what could happen at any timestep explodes.  One answer is to do conditional prediction. For example, hard limit to K voices and predict them conditionally (voice 1 is predicted, then voice 2 conditional on voice 1, . . . and so forth).  Or even predict the number of notes at a given timestep, then predict them.  I don't think there's a single right way to do this and I hope we can make it easy (read ""not horribly painful"") to try different things.  Really these sorts of decisions are the bread-and-butter of machine learning. What are you modeling? Where are the assumptions? The ""right"" answer is probably always to model the joint distribution of everything. But often that's intractable, and making it tractable by introducing factorizations like conditional prediction, is part of the fun of ML.
",magenta intern done nice polyphonic work ready release messy code kyle general reason lot harder monophonic prediction monophonic prediction sample single add multiple worse maybe however many one time possible could happen one answer conditional prediction example hard limit predict conditionally voice voice conditional voice forth even predict number given predict think single right way hope make easy read horribly painful try different really machine learning modeling right answer probably always model joint distribution everything often intractable making tractable like conditional prediction part fun,issue,positive,positive,neutral,neutral,positive,positive
241894337,"Hey guys sorry for bothering everyone here again. I'd like to ask why are we ignoring the polyphonic music while training? is there a specific reason (as in we should train it in something we aren't able to generate back yet?)

Because I looked around the code a bit to find a flag whose default is set to ignore polyphonic music. I have this amazing collection of polyphonic music that I'd like to train on, just for a bit of fun.
",hey sorry everyone like ask polyphonic music training specific reason train something able generate back yet around code bit find flag whose default set ignore polyphonic music amazing collection polyphonic music like train bit fun,issue,positive,positive,positive,positive,positive,positive
241480623,"Yes, I think there was a problem with my Anaconda configuration. I just tested it again right now and it is working. Thanks.
",yes think problem anaconda configuration tested right working thanks,issue,negative,positive,positive,positive,positive,positive
241479359,"Can you paste the errors you're getting now? Is it the same syntax error? If so, that would indicate that Python 3 is still being used.

Bazel clears some environment variables before running tests to attempt to get a hermetic build/test environment. It's possible that's messing up your anaconda installation. Would it be possible to install Python 2.7 as your system default Python?
",paste getting syntax error would indicate python still used environment running attempt get hermetic environment possible messing anaconda installation would possible install python system default python,issue,negative,neutral,neutral,neutral,neutral,neutral
241126831,"I'm still getting these errors even in Python 2.7. I set up an Anaconda environment following these instructions: https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#anaconda-installation

I then did `bazel clean` before re-running the tests. I get the exact same errors as before, including the error in the log file.

My python version is: Python 2.7.12 :: Continuum Analytics, Inc.
",still getting even python set anaconda environment following clean get exact error log file python version python continuum analytics,issue,negative,positive,positive,positive,positive,positive
241095358,"Ok thanks. Since Tensorflow is on both Python 2 and Python 3, I installed Tensorflow using Python 3 and just assumed Magenta would work on that. I didn't realize Magenta only worked on Python 2. 
",thanks since python python python assumed magenta would work realize magenta worked python,issue,negative,positive,positive,positive,positive,positive
241094780,"Oh, sorry, I didn't notice in your first post that you're using Python 3. Unfortunately, we currently only support Python 2. I'll update our docs to reflect that.
",oh sorry notice first post python unfortunately currently support python update reflect,issue,negative,negative,neutral,neutral,negative,negative
241093087,"Bazel version:

```
bazel version
Build label: 0.3.1-homebrew
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Aug 4 09:58:27 2016 (1470304707)
Build timestamp: 1470304707
Build timestamp as int: 1470304707
```

Output of one of the failed test logs:

```
cat /private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/__main__/magenta/scripts/convert_midi_dir_to_note_sequences_test.py"", line 23, in <module>
    from magenta.scripts import convert_midi_dir_to_note_sequences
  File ""/private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/__main__/magenta/scripts/convert_midi_dir_to_note_sequences.py"", line 30, in <module>
    from magenta.lib import midi_io
  File ""/private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/__main__/magenta/lib/midi_io.py"", line 29, in <module>
    import pretty_midi
  File ""/private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/pretty_midi/__init__.py"", line 1, in <module>
    from .pretty_midi import *
  File ""/private/var/tmp/_bazel_jsawruk/e6e065222e08ffdd42d29a3881482d1d/execroot/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/pretty_midi/pretty_midi.py"", line 938
    'Set Tempo': lambda(e): (1 * 256 * 256),
                       ^
SyntaxError: invalid syntax
```
",version version build label build target build time build build output one test cat pager exit recent call last file line module import file line module import file line module import file line module import file line tempo lambda invalid syntax,issue,negative,neutral,neutral,neutral,neutral,neutral
241091003,"Can you post the contents of one of those failed test logs?

Also, what do you see when you run 'bazel version'?
",post content one test also see run version,issue,negative,neutral,neutral,neutral,neutral,neutral
240761508,"Thanks Dan! I'll look at this this weekend and get back to you with any comments and edits. Much appreciated.
",thanks dan look weekend get back much,issue,negative,positive,positive,positive,positive,positive
240276528,"This pull request includes the review of [Boulanger-Lewandowski 2012](http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf), with a focus on the RNN-RBM architecture and its applications to generating polyphonic music. I'm looking forward to hearing feedback on the review. Thank you. 
",pull request review focus architecture generating polyphonic music looking forward hearing feedback review thank,issue,negative,neutral,neutral,neutral,neutral,neutral
239805019,"Sounds like you're not in a [Bazel workspace](http://bazel.io/docs/build-ref.html#workspace). You need to `cd` into the magenta directory after cloning the repository.
",like need magenta directory repository,issue,negative,neutral,neutral,neutral,neutral,neutral
239693064,"That sounds fantastic. We would welcome that Dan.
",fantastic would welcome dan,issue,positive,positive,positive,positive,positive,positive
239668741,"While creating the tfrecord files and datasets, messages are printed out respectively as follows:

> zhangyuchao@node1-cluster:~/tf_workspace/magenta$./dataset_processing.sh
> INFO: Found 1 target...
> Target //magenta/scripts:convert_midi_dir_to_note_sequences up-to-date:
>   bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences
> INFO: Elapsed time: 0.119s, Critical Path: 0.00s
> INFO: Running command line: bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences '--midi_dir=/home/disk1/zhangyuchao/tf_workspace/magenta/midi_directory' '--output_file=/home/disk1/zhangyuchao/tf_workspace/magenta/tmp/notesequences.tfrecord' --recursive
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
> INFO:tensorflow:Converting MIDI files in '/home/disk1/zhangyuchao/tf_workspace/magenta/midi_directory/'.
> INFO:tensorflow:Converted 1 MIDI files in '/home/disk1/zhangyuchao/tf_workspace/magenta/midi_directory/'.
> INFO:tensorflow:Could not parse 0 MIDI files.
> 
> zhangyuchao@node1-cluster:~/tf_workspace/magenta$ ./attention_rnn_create_dataset.sh
> INFO: Found 1 target...
> Target //magenta/models/attention_rnn:attention_rnn_create_dataset up-to-date:
>   bazel-bin/magenta/models/attention_rnn/attention_rnn_create_dataset
> INFO: Elapsed time: 0.103s, Critical Path: 0.00s
> INFO: Running command line: bazel-bin/magenta/models/attention_rnn/attention_rnn_create_dataset '--input=/home/disk1/zhangyuchao/tf_workspace/magenta/tmp/notesequences.tfrecord' '--output_dir=/home/disk1/zhangyuchao/tf_workspace/magenta/tmp/attention_rnn/sequence_examples' '--eval_ratio=0.10'
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
> INFO:tensorflow:
> Completed.
> INFO:tensorflow:Processed 1 inputs total. Produced 0 outputs.

Maybe you can try these two MIDI files of mine.
[MIDI.zip](https://github.com/tensorflow/magenta/files/417001/MIDI.zip)

Thanks a lot!
",printed respectively found target target time critical path running command line recursive successfully library locally successfully library locally successfully library locally successfully library locally successfully library locally converting converted could parse found target target time critical path running command line successfully library locally successfully library locally successfully library locally successfully library locally successfully library locally total produced maybe try two mine thanks lot,issue,positive,positive,positive,positive,positive,positive
239667947,"I've seen the ""extraction mechanism"" give strange outputs, to nothing. Unfortunately I'm away from my workstation, but can share the complete log with the latest pull. Both while creating the tfrecord files and then datasets?
",seen extraction mechanism give strange nothing unfortunately away share complete log latest pull,issue,negative,positive,neutral,neutral,positive,positive
239667064,"Thanks for your reminding, but the README.md in basic_rnn says:

> This model takes monophonic melodies, meaning one note plays at a time. Use basic_rnn_create_dataset.py to extract monophonic melodies from NoteSequence protos made from your MIDI files. The script will look at each instrument track and extract a melody line if it is at least 7 measures long, and at least 5 unique pitches (with octave equivalence). If multiple notes play at the same time, one note is kept.

Does that mean polyphonic input is okay? And monophonic melodies can be extracted from original polyphonic input? 
",thanks model monophonic meaning one note time use extract monophonic made script look instrument track extract melody line least long least unique octave equivalence multiple play time one note kept mean polyphonic input monophonic extracted original polyphonic input,issue,positive,negative,neutral,neutral,negative,negative
239665763,"Are you sure the input sequences are not polyphonic? I'm also encountering similar issue, however if you're working on the latest pull, you'll notice that it does spit the reason out in more verbose explanations.
",sure input polyphonic also similar issue however working latest pull notice spit reason verbose,issue,negative,positive,positive,positive,positive,positive
239597246,"I find my bazel is 0.2.0-homebrew. When I `brew upgrade bazel` and upgrade the bazel to 0.3.1-homebrew.  It works~
",find brew upgrade upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
239239929,"I'm logging a warning that will tell what the bad time signature is.
",logging warning tell bad time signature,issue,negative,negative,negative,negative,negative,negative
239214758,"LGTM.

It might also be useful to record steps_per_bar_float in a histogram statistic so users can figure out what the offending time signature is (or change their steps per beat). Or you can have counters for every time signature.
",might also useful record histogram statistic figure time signature change per beat every time signature,issue,negative,positive,positive,positive,positive,positive
239210742,"Yeah, it sounds like a git credential problem.  For future ref, they could try using the Skylark git rules ([`@bazel_tools//tools/build_defs/repo:gitrepositories.bzl`](https://github.com/bazelbuild/bazel/tree/master/tools/build_defs/repo)) which would use the system git instead of the somewhat funky jGit library or download it manually and reference it as a `local_repository`.
",yeah like git credential problem future ref could try skylark git would use system git instead somewhat funky library manually reference,issue,negative,neutral,neutral,neutral,neutral,neutral
238975824,"LGTM, but can you sync with master to get rid of merge conflicts?
",sync master get rid merge,issue,negative,neutral,neutral,neutral,neutral,neutral
238892493,"I'd like to contribute to the code as well, if that's possible. 
",like contribute code well possible,issue,positive,neutral,neutral,neutral,neutral,neutral
238725559,"Wow I should have caught that when I changed it. Thanks for fixing :)
",wow caught thanks fixing,issue,positive,positive,positive,positive,positive,positive
238718155,"I see the issue. Will fix shortly.
",see issue fix shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
238716218,"Yes I can confirm, that with the commit ffec2883b66d3818380d4f53cc9794b7276556ca, still doesn't works with the same error as said above. Thanks for such a prompt response.
",yes confirm commit still work error said thanks prompt response,issue,positive,positive,positive,positive,positive,positive
238712169,"Hi, it looks like you might be using the wrong (maybe old) flags.  The usage example shows:

  $ ./bazel-bin/magenta/models/basic_rnn/basic_rnn_create_dataset \
    --input=/tmp/note_sequences.tfrecord \
    --output_dir=/tmp/basic_rnn \
    --eval_ratio=0.10

Can you try again with output_dir instead of train_output and close this issue if it works? Thanks.
",hi like might wrong maybe old usage example try instead close issue work thanks,issue,negative,negative,neutral,neutral,negative,negative
238711001,"I'm going to close this issue out since we no longer support TensorFlow 0.10. Please open a new issue if problems persist after you upgrade.
",going close issue since longer support please open new issue persist upgrade,issue,positive,positive,neutral,neutral,positive,positive
238710534,"This should be fixed by https://github.com/tensorflow/magenta/pull/148, which was merged in this morning. Are you still having the issue after doing a pull?
",fixed morning still issue pull,issue,negative,positive,neutral,neutral,positive,positive
238637680,"I saw someone have a similar problem at the hackathon. For them, running 'bazel clean' and then trying to build again fixed things. They were also having some networking issues, so I suspect they maybe didn't have the protobuf repo fully downloaded.
",saw someone similar problem running clean trying build fixed also suspect maybe fully,issue,negative,positive,positive,positive,positive,positive
238631813,"SGTM. Maybe it's reasonable to add a check to see if those functions exist
to preserve compatibility for a version or two..

On Tue, Aug 9, 2016 at 1:37 PM, Adam Roberts notifications@github.com
wrote:

> Thanks. I'm going to discuss with the team how best to roll this out since
> it is not backwards compatible.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/148#issuecomment-238630191,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABBIPmxfKyNY-jdUS9wuWKdudqcEgh8lks5qeLrsgaJpZM4JftCk
> .
",maybe reasonable add check see exist preserve compatibility version two tue wrote thanks going discus team best roll since backwards compatible thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
238630191,"Thanks. I'm going to discuss with the team how best to roll this out since it is not backwards compatible.
",thanks going discus team best roll since backwards compatible,issue,positive,positive,positive,positive,positive,positive
238597770,"Yes, this is unfortunate since it will break 0.9 users. Can you also include an update to the installation instructions to say that 0.10 or greater is required?
",yes unfortunate since break also include update installation say greater,issue,negative,neutral,neutral,neutral,neutral,neutral
238454034,"I still need to add the sequence.tempos check
",still need add check,issue,negative,neutral,neutral,neutral,neutral,neutral
238374030,"Makes sense -- I could see an argument for doing it either way, but yes, I've modified to point at the next note.

An aside: I think the previous (and current) code has ""-1"" and ""1"" reversed from what one would expect (i.e., ""result = 1 if ....... %2 else -1"" seems backwards from what you described above). But it doesn't really matter as long as all the examples are consistent :) Should we swap them or leave it alone?  
",sense could see argument either way yes point next note aside think previous current code reversed one would expect result else backwards really matter long consistent swap leave alone,issue,negative,positive,neutral,neutral,positive,positive
238358306,"Great, this is a good thing to know about ;) No need to apologize!

> On Aug 8, 2016, at 10:16 AM, Adam Roberts notifications@github.com wrote:
> 
> FYI: https://google.github.io/styleguide/pyguide.html https://google.github.io/styleguide/pyguide.html
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub https://github.com/tensorflow/magenta/pull/143#issuecomment-238305450, or mute the thread https://github.com/notifications/unsubscribe-auth/AP7D9eZ5AZV_vbGavmMnsfTWlQAnVGoRks5qd2RjgaJpZM4JeVp4.
",great good thing know need apologize wrote thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
238338081,"Actually, I think it should be ""n = len(melody)"" for both. It shifts the binary clock forward one to give the correct signal for what the next note should be, instead of signalling what the time position of the last note was. For example, the bar binary counter should be -1.0 for the first 15 inputs, but change to 1.0 for the 16th input, so that it will signal the start of a new bar for generating the 17th step.

For example, instead of n = len(melody) - 1:
1: [0, 0, 0, 0, 0]
2: [1, 0, 0, 0, 0]
3: [0, 1, 0, 0, 0]
4: [1, 1, 0, 0, 0]
5: [0, 0, 1, 0, 0]
6: [1, 0, 1, 0, 0]
7: [0, 1, 1, 0, 0]
8: [1, 1, 1, 0, 0]
9: [0, 0, 0, 1, 0]
10: [1, 0, 0, 1, 0]
11: [0, 1, 0, 1, 0]
12: [1, 1, 0, 1, 0]
13: [0, 0, 1, 1, 0]
14: [1, 0, 1, 1, 0]
15: [0, 1, 1, 1, 0]
16: [1, 1, 1, 1, 0]
17: [0, 0, 0, 0, 1]
18: [1, 0, 0, 0, 1]
19: [0, 1, 0, 0, 1]
20: [1, 1, 0, 0, 1]
21: [0, 0, 1, 0, 1]
22: [1, 0, 1, 0, 1]
23: [0, 1, 1, 0, 1]
24: [1, 1, 1, 0, 1]
25: [0, 0, 0, 1, 1]
26: [1, 0, 0, 1, 1]
27: [0, 1, 0, 1, 1]
28: [1, 1, 0, 1, 1]
29: [0, 0, 1, 1, 1]
30: [1, 0, 1, 1, 1]
31: [0, 1, 1, 1, 1]
32: [1, 1, 1, 1, 1]

It should be n = len(melody), since the input is for predicting the next note:
1: [1, 0, 0, 0, 0]
2: [0, 1, 0, 0, 0]
3: [1, 1, 0, 0, 0]
4: [0, 0, 1, 0, 0]
5: [1, 0, 1, 0, 0]
6: [0, 1, 1, 0, 0]
7: [1, 1, 1, 0, 0]
8: [0, 0, 0, 1, 0]
9: [1, 0, 0, 1, 0]
10: [0, 1, 0, 1, 0]
11: [1, 1, 0, 1, 0]
12: [0, 0, 1, 1, 0]
13: [1, 0, 1, 1, 0]
14: [0, 1, 1, 1, 0]
15: [1, 1, 1, 1, 0]
16: [0, 0, 0, 0, 1]
17: [1, 0, 0, 0, 1]
18: [0, 1, 0, 0, 1]
19: [1, 1, 0, 0, 1]
20: [0, 0, 1, 0, 1]
21: [1, 0, 1, 0, 1]
22: [0, 1, 1, 0, 1]
23: [1, 1, 1, 0, 1]
24: [0, 0, 0, 1, 1]
25: [1, 0, 0, 1, 1]
26: [0, 1, 0, 1, 1]
27: [1, 1, 0, 1, 1]
28: [0, 0, 1, 1, 1]
29: [1, 0, 1, 1, 1]
30: [0, 1, 1, 1, 1]
31: [1, 1, 1, 1, 1]
32: [0, 0, 0, 0, 0]

It's counter intuitive since you're feeding in information about the previous note, but the time clock is the signal for the next note, but I think it's the right strategy. Thanks for finding that inconsistency between lookback_rnn and attention_rnn.

Other than that, the change looks good to me.
",actually think melody binary clock forward one give correct signal next note instead time position last note example bar binary counter first change th input signal start new bar generating th step example instead melody melody since input next note counter intuitive since feeding information previous note time clock signal next note think right strategy thanks finding inconsistency change good,issue,positive,positive,positive,positive,positive,positive
238139684,"@cghawthorne Now it works. Test are all passed. Thanks~
I tested on Python 2.7.10, Bazel 0.3.1
Hope other people works.
",work test tested python hope people work,issue,negative,neutral,neutral,neutral,neutral,neutral
238055334,"I signed the CLA.

On Sat, Aug 6, 2016 at 1:54 PM, cghawthorne notifications@github.com
wrote:

> @elliotwaite https://github.com/elliotwaite can you take a look at this?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/146#issuecomment-238048208,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABBIPlwQl576Og7KVrXNBixW1W8ZunZ1ks5qdPSOgaJpZM4JeXMv
> .
",sat wrote take look thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
238047757,"Oh thanks, good catch! Thanks for fixing it even though that wasn't your PR. :-)
",oh thanks good catch thanks fixing even though,issue,positive,positive,positive,positive,positive,positive
238043683,"For folks still having build errors, Bazel 0.3.1 was released recently and seems to clear up some issues. Can you give it a try and see if you're still getting errors? https://github.com/bazelbuild/bazel/releases
",still build recently clear give try see still getting,issue,negative,positive,positive,positive,positive,positive
238022948,"I guess the problem was due to bazel installation and environment setting. I reinstalled every environment on a clean ubuntu from scratch, and got it all working. 
I'll close this thread. 
",guess problem due installation environment setting every environment clean scratch got working close thread,issue,negative,positive,positive,positive,positive,positive
238004552,"I also tried different settings from scratch using virtualenv. 
(python3.5)
They all come up with the same error.
I've been googling a lot, but haven't been quite successful.. 
",also tried different scratch python come error lot quite successful,issue,negative,positive,positive,positive,positive,positive
237816407,"Hi, also having similar problem running the initial test. 
(python 2.7.12 / tensorflow 0.9.0 / OSX 10.11.6)

Executing the following code from the instruction, 
bazel test //magenta/...

I get these error messages. : 

```
WARNING: /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 45 targets and 10 test targets...
FAIL: //magenta/lib:note_sequence_io_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log).
FAIL: //magenta/pipelines:pipeline_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/pipelines/pipeline_test/test.log).
FAIL: //magenta/scripts:convert_midi_dir_to_note_sequences_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log).
INFO: Elapsed time: 1.181s, Critical Path: 0.76s
//magenta/lib:melodies_lib_test                                 (cached) PASSED in 1.1s
//magenta/lib:midi_io_test                                      (cached) PASSED in 2.1s
//magenta/lib:sequences_lib_test                                (cached) PASSED in 1.0s
//magenta/models/shared:melody_rnn_create_dataset_test          (cached) PASSED in 1.0s
//magenta/pipelines:dag_pipeline_test                           (cached) PASSED in 1.0s
//magenta/pipelines:pipelines_common_test                       (cached) PASSED in 1.0s
//magenta/pipelines:statistics_test                             (cached) PASSED in 1.0s
//magenta/lib:note_sequence_io_test                                      FAILED in 0.6s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log
//magenta/pipelines:pipeline_test                                        FAILED in 0.7s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/pipelines/pipeline_test/test.log
//magenta/scripts:convert_midi_dir_to_note_sequences_test                FAILED in 0.8s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log

Executed 3 out of 10 tests: 7 tests pass and 3 fail locally.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
```

Could anyone give me an advice?

With the suggested option, here are the error messages. 

```
WARNING: /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 45 targets and 10 test targets...
FAIL: //magenta/lib:note_sequence_io_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log).
FAIL: //magenta/pipelines:pipeline_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/pipelines/pipeline_test/test.log).
FAIL: //magenta/scripts:convert_midi_dir_to_note_sequences_test (see /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log).
INFO: Elapsed time: 1.193s, Critical Path: 0.74s
//magenta/lib:melodies_lib_test                                 (cached) PASSED in 1.1s
  WARNING: //magenta/lib:melodies_lib_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/lib:midi_io_test                                      (cached) PASSED in 2.1s
  WARNING: //magenta/lib:midi_io_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/lib:sequences_lib_test                                (cached) PASSED in 1.0s
  WARNING: //magenta/lib:sequences_lib_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/models/shared:melody_rnn_create_dataset_test          (cached) PASSED in 1.0s
  WARNING: //magenta/models/shared:melody_rnn_create_dataset_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/pipelines:dag_pipeline_test                           (cached) PASSED in 1.0s
  WARNING: //magenta/pipelines:dag_pipeline_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/pipelines:pipelines_common_test                       (cached) PASSED in 1.0s
  WARNING: //magenta/pipelines:pipelines_common_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/pipelines:statistics_test                             (cached) PASSED in 1.0s
  WARNING: //magenta/pipelines:statistics_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
//magenta/lib:note_sequence_io_test                                      FAILED in 0.6s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log
//magenta/pipelines:pipeline_test                                        FAILED in 0.7s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/pipelines/pipeline_test/test.log
//magenta/scripts:convert_midi_dir_to_note_sequences_test                FAILED in 0.7s
  /private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log

Executed 3 out of 10 tests: 7 tests pass and 3 fail locally.
```

And here are the 3 test.log files. 

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
.E.
======================================================================
ERROR: testNoteSequenceRecordWriterAndIterator (__main__.NoteSequenceIoTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/bin/magenta/lib/note_sequence_io_test.runfiles/__main__/magenta/lib/note_sequence_io_test.py"", line 52, in testNoteSequenceRecordWriterAndIterator
    writer.write(sequence)
AttributeError: 'NoneType' object has no attribute 'write'

----------------------------------------------------------------------
Ran 3 tests in 0.010s

FAILED (errors=1)
```

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/__main__/magenta/scripts/convert_midi_dir_to_note_sequences_test.py"", line 23, in <module>
    from magenta.scripts import convert_midi_dir_to_note_sequences
  File ""/private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences_test.runfiles/__main__/magenta/scripts/convert_midi_dir_to_note_sequences.py"", line 40, in <module>
    tf.app.flags.DEFINE_bool('recursive', False,
AttributeError: 'module' object has no attribute 'DEFINE_bool'
```

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
EE.........
======================================================================
ERROR: testFileIteratorNotRecursive (__main__.PipelineTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/bin/magenta/pipelines/pipeline_test.runfiles/__main__/magenta/pipelines/pipeline_test.py"", line 89, in testFileIteratorNotRecursive
    tf.gfile.MakeDirs(os.path.dirname(abs_path))
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/default/_gfile.py"", line 294, in MakeDirs
    os.makedirs(path, mode)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 17] File exists: '/var/folders/ft/pglvm7vd2z314vmrkkrqgsc40000gn/T/pipeline_test/tmpXijx5Y'

======================================================================
ERROR: testFileIteratorRecursive (__main__.PipelineTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_kaka/d3542784be43f5a4052aba9655d0cf38/magenta/bazel-out/local-opt/bin/magenta/pipelines/pipeline_test.runfiles/__main__/magenta/pipelines/pipeline_test.py"", line 65, in testFileIteratorRecursive
    tf.gfile.MakeDirs(os.path.dirname(abs_path))
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/default/_gfile.py"", line 294, in MakeDirs
    os.makedirs(path, mode)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py"", line 157, in makedirs
    mkdir(name, mode)
OSError: [Errno 17] File exists: '/var/folders/ft/pglvm7vd2z314vmrkkrqgsc40000gn/T/pipeline_test/tmpviHWZd'

----------------------------------------------------------------------
Ran 11 tests in 0.042s

FAILED (errors=2)
```
",hi also similar problem running initial test python following code instruction test get error warning name match name given repository definition cause build error future found test fail see fail see fail see time critical path executed pas fail locally whose size big use command line option see could anyone give advice option error warning name match name given repository definition cause build error future found test fail see fail see fail see time critical path warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small warning test execution time excluding execution overhead outside range moderate consider setting short small executed pas fail locally pager exit error recent call last file line sequence object attribute ran pager exit recent call last file line module import file line module false object attribute pager exit error recent call last file line file line path mode file line name mode file error recent call last file line file line path mode file line name mode file ran,issue,negative,negative,negative,negative,negative,negative
237767671,"I signed it!

> On Aug 4, 2016, at 11:29 PM, googlebot notifications@github.com wrote:
> 
> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).
> 
> 📝 Please visit https://cla.developers.google.com/ https://cla.developers.google.com/ to sign.
> 
> Once you've signed, please reply here (e.g. I signed it!) and we'll verify. Thanks.
> 
> If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address. Check your existing CLA data https://cla.developers.google.com/clas and verify that your email is set on your git commits https://help.github.com/articles/setting-your-email-in-git/.
> If you signed the CLA as a corporation, please let us know the company's name.
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub https://github.com/tensorflow/magenta/pull/136#issuecomment-237767208, or mute the thread https://github.com/notifications/unsubscribe-auth/AP7D9cpb-42roO7h_JwLSWgHT7SC6QETks5qcthigaJpZM4JdZJf.
",wrote thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git corporation please let u know company name thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
237725346,"Regarding the original issue, the *_create_dataset.py scripts will now log how many melodies they extract from how many inputs. Additionally extra information is logged such as why melodies were discarded and statistics about melody lengths.
",regarding original issue log many extract many additionally extra information logged statistic melody,issue,negative,positive,positive,positive,positive,positive
237725038,"#115 is fixed. To update this PR, add a `log` flag to this file where tf.logging.set_verbosity is called: https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_create_dataset.py#L95
",fixed update add log flag file,issue,negative,positive,neutral,neutral,positive,positive
237546362,"I signed it

————————
jonasfehr.ch

Furesøvej 161
2830 Virum

+45 52 777 432

> Den 4. aug. 2016 kl. 14.57 skrev googlebot notifications@github.com:
> 
> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).
> 
> 📝 Please visit https://cla.developers.google.com/ to sign.
> 
> Once you've signed, please reply here (e.g. I signed it!) and we'll verify. Thanks.
> 
> If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address. Check your existing CLA data and verify that your email is set on your git commits.
> If you signed the CLA as a corporation, please let us know the company's name.
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",den thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo please visit sign please reply verify thanks already possible different address check data verify set git corporation please let u know company name thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
237123004,"@danabo Good idea making bpm a float. Looks great. I tested it and it works well.
",good idea making float great tested work well,issue,positive,positive,positive,positive,positive,positive
237110547,"@danabo  Good work getting it going. Do you want me to test your code. I had issues with the code dying if bpm was set in the command line 14

I think the issue is at 

https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_sequence_generator.py#L91
",good work getting going want test code code dying set command line think issue,issue,negative,positive,positive,positive,positive,positive
237110196,"Sounds great Daniel. I will close my PR.

On Tue, Aug 2, 2016 at 4:51 PM, Daniel Abolafia notifications@github.com
wrote:

> I created a PR that will fix both issues - bpm flag and no primer is
> allowed. This was a bit more complicated than I was anticipated, so I
> thought it would be easier if I fix both in one PR.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/121#issuecomment-237086157,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AFWI7uVCi4dohMVGwU0DuhKvgmwpwpQyks5qb9f9gaJpZM4JYluI
> .
",great close tue wrote fix flag primer bit complicated thought would easier fix one thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
237087868,"All tests pass. I manually verified that each rnn generator works with --primer_midi, --primer_melody, and no primer given. And I verified that the --bpm flag sets the output bpm when --primer_melody or no primer is given, but not when --primer_midi is given.
",pas manually generator work primer given flag output primer given given,issue,negative,neutral,neutral,neutral,neutral,neutral
237086157,"I created a PR that will fix both issues - bpm flag and no primer is allowed. This was a bit more complicated than I was anticipated, so I thought it would be easier if I fix both in one PR.
",fix flag primer bit complicated thought would easier fix one,issue,negative,negative,negative,negative,negative,negative
236967967,"Do we want to use the correct MIDI terms? ""MIDI keyboard"" is oddly specific. I'm not all that familiar with MIDI, but ""MIDI Instrument"" is (I think) a device that can both send and receive messages.
",want use correct keyboard oddly specific familiar instrument think device send receive,issue,negative,positive,positive,positive,positive,positive
236607520,"It turned out that it is due to the corruption of tensorflow installation.  Previously it had been successfully installed, but somehow it cannot work any more, then I reinstalled tensorflow and the problem just disappear.
Thanks very much!!
",turned due corruption installation previously successfully somehow work problem disappear thanks much,issue,negative,positive,positive,positive,positive,positive
236504396,"@danabo I am testing a solution to this. Seems to work, have sent a pull request at https://github.com/tensorflow/magenta/pull/124 
",testing solution work sent pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
236504192,"@danabo . Too bad the hparams method was fairly easy. I will look into changing the constructor.
",bad method fairly easy look constructor,issue,negative,negative,negative,negative,negative,negative
236495613,"I think bpm should not be a hyperparameter. Ultimately, a hyperparameter affects what type of model you have, and what it learns. My rule of thumb is that parameters which affect the Tensorflow graph and get saved into checkpoints are hyperparameters. bpm is a parameter about how to convert the model's output into something a human can listen to, and more importantly it depends on the given sample, and not intrinsic to the model itself. Though temperature doesn't affect training it does affect the generated output, but I would accept temperature as an hparam or just a flag.
",think ultimately type model rule thumb affect graph get saved parameter convert model output something human listen importantly given sample intrinsic model though temperature affect training affect output would accept temperature flag,issue,positive,positive,positive,positive,positive,positive
236494654,"Hmm I am still not sure what is producing the error code.

Can you do two things?
Run the binary without bazel (just run the command that bazel prints in the INFO statement). Just to be sure this is not related to bazel.

bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences '--midi_dir=/home/oatmeal/HiMusic/MIDI/Dance' '--output_file=/home/oatmeal/HiMusic/Output/Dance_sequences.tfrecord' --recursive --alsologtostderr

Second thing is to see if importing tensorflow works. From doing a bit of googling this sounds like an issue with your tensorflow install. You can just delete everything in convert_midi_dir_to_note_sequences.py and replace it with one line: ""import tensorflow as tf""
Build and run the binary again.
",still sure error code two run binary without run command statement sure related recursive second thing see work bit like issue install delete everything replace one line import build run binary,issue,positive,positive,positive,positive,positive,positive
236428112,"I also have some problem on running test. There are 2 fail on 8 test item.

```
INFO: Found 39 targets and 8 test targets...
FAIL: //magenta/lib:midi_io_test (see /private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/testlogs/magenta/lib/midi_io_test/test.log).
FAIL: //magenta/scripts:convert_midi_dir_to_note_sequences_test (see /private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log).
INFO: Elapsed time: 8.243s, Critical Path: 2.52s
//magenta/lib:melodies_lib_test                                 (cached) PASSED in 2.2s
//magenta/lib:note_sequence_io_test                             (cached) PASSED in 1.8s
//magenta/lib:sequences_lib_test                                (cached) PASSED in 1.3s
//magenta/models/shared:melody_rnn_create_dataset_test          (cached) PASSED in 2.4s
//magenta/pipelines:pipeline_test                               (cached) PASSED in 3.4s
//magenta/pipelines:pipelines_common_test                       (cached) PASSED in 3.2s
//magenta/lib:midi_io_test                                               FAILED in 0.2s
  /private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/testlogs/magenta/lib/midi_io_test/test.log
//magenta/scripts:convert_midi_dir_to_note_sequences_test                FAILED in 1.7s
  /private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log

Executed 2 out of 8 tests: 6 tests pass and 2 fail locally.
```

Both log has comment as 'ImportError: No module named midi'.

```
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/bin/magenta/lib/midi_io_test.runfiles/magenta/lib/midi_io_test.py"", line 21, in <module>
    import pretty_midi
  File ""/private/var/tmp/_bazel_kwangin/001031a49558f53b54e889be1a87c437/magenta/bazel-out/local_darwin-opt/bin/magenta/lib/midi_io_test.runfiles/external/pretty_midi/pretty_midi.py"", line 6, in <module>
    import midi
ImportError: No module named midi
```

Does anyone know about this?
",also problem running test fail test item found test fail see fail see time critical path executed pas fail locally log comment module recent call last file line module import file line module import module anyone know,issue,negative,negative,negative,negative,negative,negative
236419940,"Outputs are the same after adding the flag.

WARNING: /home/oatmeal/.cache/bazel/_bazel_oatmeal/c3300a0566708e561674ab71c996c139/external/protobuf/WORKSPACE:1: Workspace name in /home/oatmeal/.cache/bazel/_bazel_oatmeal/c3300a0566708e561674ab71c996c139/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 1 target...
Target //magenta/scripts:convert_midi_dir_to_note_sequences up-to-date:
  bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences
INFO: Elapsed time: 0.264s, Critical Path: 0.00s

INFO: Running command line: bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences '--midi_dir=/home/oatmeal/HiMusic/MIDI/Dance' '--output_file=/home/oatmeal/HiMusic/Output/Dance_sequences.tfrecord' --recursive --alsologtostderr
ERROR: Non-zero return code '245' from command: Process exited with status 245.
",flag warning name match name given repository definition cause build error future found target target time critical path running command line recursive error return code command process status,issue,negative,neutral,neutral,neutral,neutral,neutral
236387025,"@danabo 

I see that hparams is one of the passed variables in the constructor you mentioned, in your opinion, should I try what Elliote did:

>   hparams = ast.literal_eval(FLAGS.hparams if FLAGS.hparams else '{}')
>   hparams['temperature'] = FLAGS.temperature

the code is at:

https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_generate.py#L73-L74

and make the FLAGS.bpm into an hparam, or change the constructor which may effect other calls to the function.

I just tested the hparams method and it works fine. I am not very used to python so I don't think I will try messing with constructors. By the way I do get an error at very low bpm < 14, will have to figure that out.
",see one constructor opinion try else code make change constructor may effect function tested method work fine used python think try messing way get error low figure,issue,negative,positive,positive,positive,positive,positive
236377453,"Ah good observation. bpm is not passed into the generator, but is recalculated here
https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_sequence_generator.py#L97

I think it would be reasonable to pass in bpm into the constructor here
https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_sequence_generator.py#L31
",ah good observation generator think would reasonable pas constructor,issue,negative,positive,positive,positive,positive,positive
236376687,"Can you run with the --alsologtostderr flag and share the output?

So it would be
bazel run //magenta/scripts:convert_midi_dir_to_note_sequences -- \
--midi_dir=$MIDI_DIRECTORY \
--output_file=$SEQUENCES_TFRECORD \
--recursive \
--alsologtostderr
",run flag share output would run recursive,issue,negative,neutral,neutral,neutral,neutral,neutral
236376304,"@danabo having a hard time figuring out how bpm gets from the new code 

https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_generate.py#L138

to the sequence generator. Does not seem to be passed as a simple variable at

https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_generate.py#L167
",hard time new code sequence generator seem simple variable,issue,negative,negative,neutral,neutral,negative,negative
236376080,"Should be a small change, so early next week seems reasonable.
",small change early next week reasonable,issue,negative,positive,neutral,neutral,positive,positive
236335389,"Sounds good. Any idea of your time frame for the fix?  
",good idea time frame fix,issue,negative,positive,positive,positive,positive,positive
236305072,"I didn't know that we allowed no primer to be given previously, but you are right. This is the code that picked a random primer:
https://github.com/tensorflow/magenta/blob/4c0050aee5f2bac3f95041a42074cfb6054071c2/magenta/models/shared/melody_rnn_generate.py#L101

We can add this option back in.
",know primer given previously right code picked random primer add option back,issue,negative,negative,neutral,neutral,negative,negative
236301612,"@cghawthorne @danabo I think I will wait with my PR until this issue is cleaned up 

https://github.com/tensorflow/magenta/issues/121

The latest change seems to have messed up the auto random note if no primer supplied.
",think wait issue latest change auto random note primer,issue,negative,neutral,neutral,neutral,neutral,neutral
236278093,"I am just going to close this PR until I have tested it. I see the changes that are needed.
",going close tested see,issue,negative,neutral,neutral,neutral,neutral,neutral
236252035,"This code has changed. It should actually be pretty simple to add a bpm flag in the new code. Please sync your branch to upstream master.

This is where the bpm is set in the new code:
https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_generate.py#L138
You can have the bpm flag override the bpm value computed here if its a positive value. I don't think we need the ability to set bpm to 0, so you can make that the default instead of -1.
",code actually pretty simple add flag new code please sync branch upstream master set new code flag override value positive value think need ability set make default instead,issue,positive,positive,positive,positive,positive,positive
236112358,"@cghawthorne I have tested it and it works. If bpm is not in the command line then the default behaviour occurs. If bpm is less than or equal to zero then the default behaviour also occurs. If bpm is in the command line and is greater than zero then it controls the output bpm if a primer midi is involved or not.
",tested work command line default behaviour le equal zero default behaviour also command line greater zero output primer involved,issue,negative,positive,positive,positive,positive,positive
236004294,"Not quite. The actual logging statements were removed.
",quite actual logging removed,issue,negative,neutral,neutral,neutral,neutral,neutral
235995591,"Hi @oatmeal3000, I think you're using an outdated set of instructions. We've changed the locations of some of our build targets recently. Please sync your git repo and try again. The up to date instructions can be seen here: https://github.com/tensorflow/magenta
",hi oatmeal think outdated set build recently please sync git try date seen,issue,negative,negative,negative,negative,negative,negative
235793468,"LGTM.
We will have to remember to do this for every binary. Pretty annoying.
",remember every binary pretty annoying,issue,negative,negative,negative,negative,negative,negative
235793152,"Thanks for making this change. I made one small comment in the code. Please address it and I will merge your PR.
",thanks making change made one small comment code please address merge,issue,positive,negative,neutral,neutral,negative,negative
235792239,"I don't think we changed anything about the model architectures themselves.
Its possible that the melody dataset being created is different.

On Wed, Jul 27, 2016 at 7:08 PM, Jeremy Ellis notifications@github.com
wrote:

> Last week my starting loss was about 40,000 this week my loss values are
> about 1.6 ?
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/115#issuecomment-235780035,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAP99v-bBMIr8EXiuTz8JuLttRJ7rdJ_ks5qaA8fgaJpZM4JWv5J
> .
",think anything model possible melody different wed wrote last week starting loss week loss reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
235791774,"I signed it!

On Wed, Jul 27, 2016 at 8:26 PM, googlebot notifications@github.com wrote:

> Thanks for your pull request. It looks like this may be your first
> contribution to a Google open source project. Before we can look at your
> pull request, you'll need to sign a Contributor License Agreement (CLA).
> 
> 📝 _Please visit https://cla.developers.google.com/
> https://cla.developers.google.com/ to sign._
> 
> Once you've signed, please reply here (e.g. I signed it!) and we'll
> 
> ## verify. Thanks.
> - If you've already signed a CLA, it's possible we don't have your
>   GitHub username or you're using a different email address. Check your
>   existing CLA data https://cla.developers.google.com/clas and verify
>   that your email is set on your git commits
>   https://help.github.com/articles/setting-your-email-in-git/.
> - If you signed the CLA as a corporation, please let us know the
>   company's name.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/117#issuecomment-235790966,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AFWI7mtcEsKBB9SvVmZA0BfJTqG0eJ0tks5qaCF8gaJpZM4JW1Yi
> .
",wed wrote thanks pull request like may first contribution open source project look pull request need sign contributor license agreement memo visit please reply verify thanks already possible different address check data verify set git corporation please let u know company name thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
235780035,"Last week my starting loss was about 40,000 this week my loss values are about 1.6 ? 
",last week starting loss week loss,issue,negative,neutral,neutral,neutral,neutral,neutral
235765585,"The melody info logging went away in monday's change as well. We will bring
it back soon. Sit tight.

On Wed, Jul 27, 2016 at 5:06 PM, Jeremy Ellis notifications@github.com
wrote:

> Anyone else having this issue?
> 
> Everything seems to work fine except my output used to give me some
> indication about the midi files that have been processed,
> 
> I used to see something like:
> 
> INFO: found 9 melodies in 3 sequences.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/115, or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAP99i5KyDNnIBrNzTGWM07VpXtKty-pks5qZ_KAgaJpZM4JWv5J
> .
",melody logging went away change well bring back soon sit tight wed wrote anyone else issue everything work fine except output used give indication used see something like found thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
235764764,"Just looked at Tensorboard and I must still have something wrong. The loss is a straight line.
",must still something wrong loss straight line,issue,negative,negative,negative,negative,negative,negative
235745449,"@zuoxingdong it looks like the only file in that directory is notesequences.tfrecord. The convert_midi_dir_to_note_sequences is meant to take in a directory of midi files and produce a tfrecord file that contains notesequences representing the data in the midi files. If you try again with a directory that contains midi files, it should work. Let me know if you have any other problems!
",like file directory meant take directory produce file data try directory work let know,issue,negative,neutral,neutral,neutral,neutral,neutral
235744385,"@cghawthorne  I've tried with Bazel 0.2.3, now it is working fine. Thanks for the advice, and this issue might be ok to close.  
",tried working fine thanks advice issue might close,issue,positive,positive,positive,positive,positive,positive
235743427,"@cghawthorne  Sorry for the late reply. I've re-clone the latest repo and try again, got the following message

```
INFO: Found 1 target...
Target //magenta/scripts:convert_midi_dir_to_note_sequences up-to-date:
  bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences
INFO: Elapsed time: 0.157s, Critical Path: 0.00s

INFO: Running command line: bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences '--midi_dir=midi_data/midis' '--output_file=midi_data/midis/notesequences.tfrecord' --recursive
INFO:tensorflow:Converting MIDI files in 'midi_data/midis/'.
WARNING:tensorflow:Could not parse MIDI file midi_data/midis/notesequences.tfrecord. It will be skipped. Error was: Midi decoding error <type 'exceptions.TypeError'>: Bad header in MIDI file.
INFO:tensorflow:Converted 0 MIDI files in 'midi_data/midis/'.
INFO:tensorflow:Could not parse 1 MIDI files.
INFO:tensorflow:Wrote 0 NoteSequence protos to 'midi_data/midis/notesequences.tfrecord'

```

Unfortunately no file is created. But I found if running commend `bazel build //magenta/scripts:convert_midi_dir_to_note_sequences` first and then run `./bazel-bin/............` would be successfully generating TFRecord file. 
",sorry late reply latest try got following message found target target time critical path running command line recursive converting warning could parse file error error type bad header file converted could parse wrote unfortunately file found running commend build first run would successfully generating file,issue,negative,negative,neutral,neutral,negative,negative
235706666,"Glad to hear things are working for you now, @hpssjellis. We'll try to do better with sending out announcements when we change data generation instructions.

@zuoxingdong are you still having problems?
",glad hear working try better sending change data generation still,issue,positive,positive,positive,positive,positive,positive
235704897,"Yes the flags changed again. Sorry for breaking things. We are in the middle of making some changes to how datasets are created.
",yes sorry breaking middle making,issue,negative,negative,negative,negative,negative,negative
235702998,"@hpssjellis it should just show up on stdout:

```
$ bazel run //magenta/scripts:convert_midi_dir_to_note_sequences -- --midi_dir=$MIDI_DIRECTORY --output_file=$SEQUENCES_TFRECORD --recursive
...
INFO:tensorflow:Converted 2 MIDI files in '/tmp/midis/'.
INFO:tensorflow:Coult not parse 3 MIDI files.
INFO:tensorflow:Wrote 2 NoteSequence protos to '/tmp/notesequences.tfrecord'

```
",show run recursive converted parse wrote,issue,negative,neutral,neutral,neutral,neutral,neutral
235696076,"@cghawthorne where are the new log files being saved? I have noticed the output information telling me how many midi files have been processed is not showing anymore.
",new log saved output information telling many showing,issue,negative,positive,positive,positive,positive,positive
235665926,"Aaaargh.

The instructions changed at 
https://github.com/tensorflow/magenta/tree/master/magenta/models/basic_rnn

The new line is

DATASET_DIR=/tmp/basic_rnn/sequence_examples

I now do not get the below errors. Wish a notice would go out in magenta discus when the basic steps have changed

https://groups.google.com/a/tensorflow.org/forum/#!forum/magenta-discuss

Ignore the following comments.

Still getting similar errors in the basic_rnn_create_dataset everything else seems to be fine. If I run Magenta from a few commits back everything is fine on my machine.

> INFO: Running command line: bazel-bin/magenta/models/basic_rnn/basic_rnn_create_dataset '--input=/tmp/notesequences.tfrecord' '--train_output=/tmp/basic_rnn/sequence_examples/training_melodies.tfrecord' '--eval_output=/tmp/basic_rnn/sequence_examples/eval_melodies.tfrecord' '--eval_ratio=0'
> Traceback (most recent call last):
>   File ""/home/ben/.cache/bazel/_bazel_ben/8c0953a859c6a7cebfcbd426d9e6c4a2/magenta/bazel-out/local-opt/bin/magenta/models/basic_rnn/basic_rnn_create_dataset.runfiles/__main__/magenta/models/basic_rnn/basic_rnn_create_dataset.py"", line 41, in <module>
>     tf.app.run()
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
>     sys.exit(main(sys.argv))
>   File ""/home/ben/.cache/bazel/_bazel_ben/8c0953a859c6a7cebfcbd426d9e6c4a2/magenta/bazel-out/local-opt/bin/magenta/models/basic_rnn/basic_rnn_create_dataset.runfiles/__main__/magenta/models/basic_rnn/basic_rnn_create_dataset.py"", line 37, in main
>     basic_rnn_encoder_decoder.MelodyEncoderDecoder())
>   File ""/home/ben/.cache/bazel/_bazel_ben/8c0953a859c6a7cebfcbd426d9e6c4a2/magenta/bazel-out/local-opt/bin/magenta/models/basic_rnn/basic_rnn_create_dataset.runfiles/__main__/magenta/models/shared/melody_rnn_create_dataset.py"", line 121, in run_from_flags
>     FLAGS.output_dir)
>   File ""/home/ben/.cache/bazel/_bazel_ben/8c0953a859c6a7cebfcbd426d9e6c4a2/magenta/bazel-out/local-opt/bin/magenta/models/basic_rnn/basic_rnn_create_dataset.runfiles/__main__/magenta/pipelines/pipeline.py"", line 196, in run_pipeline_serial
>     if not tf.gfile.Exists(output_dir):
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/gfile.py"", line 252, in Exists
>     return os.path.exists(path)
>   File ""/home/ben/virtual-tf/lib/python2.7/genericpath.py"", line 26, in exists
>     os.stat(path)
> TypeError: coercing to Unicode: need string or buffer, NoneType found
> ERROR: Non-zero return code '1' from command: Process exited with status 1.
",new line get wish notice would go magenta discus basic ignore following still getting similar everything else fine run magenta back everything fine machine running command line recent call last file line module file line run main file line main file line file line file line return path file line path need string buffer found error return code command process status,issue,negative,positive,positive,positive,positive,positive
235646500,"I just added some better logging to our midi conversion code in #112. Can the folks in this thread that were having import errors do a git pull and try again? I'd like to see what kind of error messages you're getting.
",added better logging conversion code thread import git pull try like see kind error getting,issue,positive,positive,positive,positive,positive,positive
235641374,"We don't directly include pretty_midi in our repo. Instead, we reference it in our WORKSPACE file[1]. This allows Bazel to download the repo whenever a python build target depends on it. Bazel also takes care of setting up the runfiles directory for that python target such that it can reference the pretty_midi repo.

For an example of how to do this, check out the build target for midi_io[2]. If you want to add your own targets that have a dependency on midi_io or pretty_midi within the repo, you'll need to define BUILD targets so that Bazel can manage the dependencies for you. You can find more information about how Bazel works at http://bazel.io.

1: https://github.com/tensorflow/magenta/blob/master/WORKSPACE
2: https://github.com/tensorflow/magenta/blob/master/magenta/lib/BUILD#L50
",directly include instead reference file whenever python build target also care setting directory python target reference example check build target want add dependency within need define build manage find information work,issue,positive,positive,neutral,neutral,positive,positive
235630403,"I am having similar issues with midi files. Here is a pretty_midi repo

https://github.com/craffel/pretty-midi

Not sure how to build pretty_midi  so that tensorflow is aware of it. 
",similar sure build aware,issue,negative,positive,positive,positive,positive,positive
235353254,"Sorry, my laptop died recently and I'm just getting going again on a new one.  Did not get it solved, with MacPorts, however with the new laptop I'm trying HomeBrew instead, and got the tests to pass.
",sorry recently getting going new one get however new trying instead got pas,issue,negative,negative,neutral,neutral,negative,negative
235185543,"You were right. Changing min_bars and min_unique_pitches solved the problem of the ""example.mid"" not getting loaded. 

> def extract_melodies(sequence, steps_per_beat=4, min_bars=1, min_unique_pitches=1):

P.S. I had to use yesterdays Magenta, the present repository has some issues that don't work on my computer.
",right problem getting loaded sequence use magenta present repository work computer,issue,negative,positive,positive,positive,positive,positive
235168264,"hey @danabo how do we get magenta/tensorflow to show debug errors. Is it something we request in the command line?

I want to see this output

tf.logging.debug( 'MonophonicMelody was discarded because it is too short.')
",hey get show something request command line want see output short,issue,negative,neutral,neutral,neutral,neutral,neutral
235117943,"We do filter out short melodies and melodies with few pitches.

There is not currently a command line flag to modify these settings, but you can change them in the code:
https://github.com/tensorflow/magenta/blob/master/magenta/models/shared/melody_rnn_create_dataset.py#L96

Try setting min_bars=0 and min_unique_pitches=0
",filter short currently command line flag modify change code try setting,issue,negative,neutral,neutral,neutral,neutral,neutral
234950038,"I am having the same issue as @zuoxingdong.

My setup:
- OS X 10.11
- Python and bazel installed via homebrew
- Tensor flow installed inside a virtualenv (named ""all"")
- up to date magenta (commit d9bd761)

Here I activate the virtualenv and run the convert midi script using the midi file posted above:

```
$ source ~/all/bin/activate

(all)$ ./bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences \
--midi_dir=/tmp/tester \
--output_file=/tmp/tester/noteSequences.tfrecord

/Users/ruaridh/dev/music/magenta/bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences.runfiles/pretty_midi/pretty_midi.py:87: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file. Tempo, Key or Time Signature may be wrong.
RuntimeWarning)
ERROR:tensorflow:Midi decoding error <type 'exceptions.TypeError'>: Bad header in MIDI file.

(all)$ 
```

I'm having this error for every midi file I've tried.
The output file does seem to be generated, however it doesn't work in the next stage of creating the dataset. Apparently it can't be read (`IOError: Could not open /tmp/tester/noteSequences.tfrecord.`).

Also importing pretty_midi doesn't seem to work:

```
>>> import pretty_midi
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named pretty_midi
```
",issue setup o python via tensor flow inside date magenta commit activate run convert script file posted source tempo key time signature change found valid type type file tempo key time signature may wrong error error type bad header file error every file tried output file seem however work next stage apparently ca read could open also seem work import recent call last file line module module,issue,negative,negative,negative,negative,negative,negative
234788945,"I think I have the train data path incorrect. Closing this now.
",think train data path incorrect,issue,negative,neutral,neutral,neutral,neutral,neutral
234788892,"Can someone try deleting the example_complex.mid file and just doing a run with the simple example.mid file. For me it does not find any melodies? I can however run other midi files. I think magenta is now ignoring any monophonic midi files with any issues in it's header, including the example.mid file. I have however got some other monophonic midi files working. Most complex files work.
",someone try file run simple file find however run think magenta monophonic header file however got monophonic working complex work,issue,negative,negative,negative,negative,negative,negative
234757086,"If I revert Magenta back about 10 days everything works again. I get more sensible responses when I run multiple midi files

INFO:tensorflow:Extracted 9 melodies from 1 sequences.
Extracted 9 melodies from 1 sequences.
Found 11 sequences
Extracted 14 melodies for training.
Extracted 2 melodies for evaluation.
Dataset files: ['/tmp/training_melodies.tfrecord']
",revert magenta back day everything work get sensible run multiple extracted extracted found extracted training extracted evaluation,issue,negative,neutral,neutral,neutral,neutral,neutral
234721170,"I am having similar issues but did not see this thread until after starting my new thread at https://github.com/tensorflow/magenta/issues/107

I have a fresh installation and can't run any new mid files. The only file that runs is the example_complex.mid

I got the  /tmp/test.file2 file that @douglaseck suggested trying. I don't think the issue is the ability to generate a midi file, I think a code bug is just ignoring doing it.
",similar see thread starting new thread fresh installation ca run new mid file got file trying think issue ability generate file think code bug,issue,positive,positive,neutral,neutral,positive,positive
234718930,"Actually I think only the complex midi files are being read and the simple midi files are being ignored.
",actually think complex read simple,issue,negative,negative,neutral,neutral,negative,negative
234382399,"@adarob, to make the graph more efficient by not adding the division op to the graph when not needed.
",make graph efficient division graph,issue,negative,neutral,neutral,neutral,neutral,neutral
234331796,"I just tried the same commands as @douglaseck above and got the same results (a populated tfrecord file). Have you done a 'git pull' recently?

The pretty_midi and midi modules are downloaded by bazel at compilation time, and bazel takes care of setting up the python import paths to be able to reference them when you run bazel targets. So you should be using the same versions as we are.
",tried got file done pull recently compilation time care setting python import able reference run,issue,negative,positive,positive,positive,positive,positive
234322969,"@zuoxingdong can you try installing bazel 0.2.3? I've also had some problems where bazel test with 0.3.0 overwrites the environment variable pointing to my virtualenv.

Another thing to try would be running the tests directly out of bazel-bin/ and see if that works.
",try also test environment variable pointing another thing try would running directly see work,issue,negative,positive,neutral,neutral,positive,positive
234321834,"Nope, ran some training iterations last night, this seems to be resolved.
",nope ran training last night resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
234319966,"I think the pull request in #103 will fix this for you.
",think pull request fix,issue,negative,neutral,neutral,neutral,neutral,neutral
234318913,"@afuhrtrumpet sounds like #102 got resolved. Are you still having problems with this issue?
",like got resolved still issue,issue,negative,neutral,neutral,neutral,neutral,neutral
234317653,"@act65 your issue sounds like something different. Can you open a separate bug?

@nathanielatom do the tests work if you first do a 'bazel build' on the test target and then run the test directly? The result of bazel build should include the bazel-bin/ location of the test file.

If that works, the issue is that bazel strips out a lot of environment variables when it runs things, in an effort to keep a hermetic build/test environment. We're kind of working around things by relying on an external tensorflow installation.

In the short term, you could just run things directly, instead of using bazel build/test. Longer term, we're working on ways to depend directly on tensorflow and have it correctly autodetect whether your system can support a GPU. Some more details here: https://github.com/tensorflow/tensorflow/issues/2873
",act issue like something different open separate bug work first build test target run test directly result build include location test file work issue lot environment effort keep hermetic environment kind working around external installation short term could run directly instead longer term working way depend directly correctly whether system support,issue,positive,positive,positive,positive,positive,positive
234144977,"Problem solved. I used Tensorflow 0.7.1. Seems version >= 0.9 is perfectly OK. 
",problem used version perfectly,issue,negative,positive,positive,positive,positive,positive
234066465,"same on OSX El Capitan

`WARNING: /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/external/protobuf/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.
INFO: Found 30 targets and 5 test targets...
FAIL: //magenta/lib:sequence_to_melodies_test (see /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/sequence_to_melodies_test/test.log).
FAIL: //magenta/lib:note_sequence_io_test (see /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log).
FAIL: //magenta/lib:melodies_lib_test (see /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/melodies_lib_test/test.log).
FAIL: //magenta/scripts:convert_midi_dir_to_note_sequences_test (see /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log).
FAIL: //magenta/lib:midi_io_test (see /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/midi_io_test/test.log).
INFO: Elapsed time: 5.088s, Critical Path: 1.41s
//magenta/lib:melodies_lib_test                                          FAILED in 0.7s
  /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/melodies_lib_test/test.log
//magenta/lib:midi_io_test                                               FAILED in 0.9s
  /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/midi_io_test/test.log
//magenta/lib:note_sequence_io_test                                      FAILED in 0.7s
  /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/note_sequence_io_test/test.log
//magenta/lib:sequence_to_melodies_test                                  FAILED in 0.7s
  /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/lib/sequence_to_melodies_test/test.log
//magenta/scripts:convert_midi_dir_to_note_sequences_test                FAILED in 0.9s
  /private/var/tmp/_bazel_benjamingenchel/1c269da31038396025e7f6c0675c28b2/execroot/magenta/bazel-out/local-opt/testlogs/magenta/scripts/convert_midi_dir_to_note_sequences_test/test.log`
",el capitan warning name match name given repository definition cause build error future found test fail see fail see fail see fail see fail see time critical path,issue,negative,negative,negative,negative,negative,negative
233979228,"@douglaseck 

When I enter IPython terminal under virtual environment of TensorFlow and run `import pretty_midi` and `import midi`

It returns `No module named pretty_midi/midi`

Does it mean that I should install these packages independently, since I am using Anaconda and when run `conda install pretty_midi` it does not find such a package to install.  
",enter terminal virtual environment run import import module mean install independently since anaconda run install find package install,issue,negative,negative,negative,negative,negative,negative
233849505,"Turns out I upgraded to the newest magenta and still had an old build under models:basic_rnn that I was trying to run.
",turn magenta still old build trying run,issue,negative,positive,neutral,neutral,positive,positive
233811269,"I'm not able to reproduce this.

I copied that 1.mid into /tmp/tester and ran this:

bazel run //magenta/scripts:convert_midi_dir_to_note_sequences --
--midi_dir=/tmp/tester --output_file=/tmp/test.file2
INFO: Running command line:
bazel-bin/magenta/scripts/convert_midi_dir_to_note_sequences
'--midi_dir=/tmp/tester' '--output_file=/tmp/test.file2'
/usr/local/google/home/deck/.cache/bazel/_bazel_deck/57b4fd5929bc61a3e836ee5f75cccde4/magenta/bazel-out/local-opt/bin/magenta/scripts/convert_midi_dir_to_note_sequences.runfiles/pretty_midi/pretty_midi.py:87:
RuntimeWarning: Tempo, Key or Time signature change events found on
non-zero tracks.  This is not a valid type 0 or type 1 MIDI file. Tempo,
Key or Time Signature may be wrong.
  RuntimeWarning)

I get a RuntimeWarning about the MIDI file, but that's not a problem. The
output file is stil created

ls -l /tmp/test.file2
-rw-r--r-- 1 deck eng 31414 Jul 19 18:01 /tmp/test.file2

What versions of pretty_midi and py_midi are you running?

import pretty_midi
pretty_midi.**version**
Out[9]: '0.2-pre'

What version of py_midi are you running:
import midi
midi.**file**
Out[8]:
'/usr/local/lib/python2.7/dist-packages/midi-0.2.3-py2.7.egg/midi/**init**.pyc'

On Tue, Jul 19, 2016 at 5:34 PM, Xingdong Zuo notifications@github.com
wrote:

> 1.mid.zip https://github.com/tensorflow/magenta/files/372681/1.mid.zip
> 
> It can be imported and played with onlinesequencer.net
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/104#issuecomment-233806923,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/APQ6QlwTBmXHCsQheMoEIyEG4nPIGDGgks5qXW0qgaJpZM4JQR1t
> .
",able reproduce copied ran run running command line tempo key time signature change found valid type type file tempo key time signature may wrong get file problem output file deck running import version version running import file tue wrote reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
233799713,"Can you attach the MIDI file?

On Tue, Jul 19, 2016 at 4:22 PM, Xingdong Zuo notifications@github.com
wrote:

> By following the tutorial, when converting midi files to note sequences,
> it encounters following error
> 
> ERROR:tensorflow:Midi decoding error <type 'exceptions.TypeError'>: Bad
> header in MIDI file
> 
> when running
> 
> bazel run //magenta/scripts:convert_midi_dir_to_note_sequences -- \
> --midi_dir=$MIDI_DIRECTORY \
> --output_file=$SEQUENCES_TFRECORD \
> --recursive
> 
> No tfrecord file generated.
> 
> I've tried many different midi files from midiworld website, the same
> error remains. So I guess it might not be the problem with midi files.
> 
> Environment:
> Bazel 0.30
> TensorFlow 0.9 under virtual environment
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/104, or mute the thread
> https://github.com/notifications/unsubscribe-auth/APQ6QogxwTMHrUhv47q36pa3y2c6P37Gks5qXVwdgaJpZM4JQR1t
> .
",attach file tue wrote following tutorial converting note following error error error type bad header file running run recursive file tried many different error remains guess might problem environment virtual environment thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
233709163,"Alex, I'm having trouble reproducing this error. Can you make sure you're synced to the latest updates. And if that doesn't help, what OS and Python version are you using?
",trouble error make sure latest help o python version,issue,negative,positive,positive,positive,positive,positive
233627741,"I'm not sure if this was related to how bazel is installed on my machine, but I need to use absolute and not relative paths for all the references and writing to tfrecord files. All works fine when I do!
",sure related machine need use absolute relative writing work fine,issue,negative,positive,positive,positive,positive,positive
233539232,"I think I was confusing the output. However I can't run the current version of basic_rnn_train due to #102 at the moment to verify this.
",think output however ca run current version due moment verify,issue,negative,negative,neutral,neutral,negative,negative
233228962,"Well done danabo. I think this enhancement can be closed since I see that it is in operation with the April 15, 2016 changes to magenta.
",well done think enhancement closed since see operation magenta,issue,negative,negative,neutral,neutral,negative,negative
233201721,"@cinjon I ran 

```
wget $CUDNN_URL
tar -xzf cudnn-*-osx-x64-v*.tgz
sudo mv cuda/include/cudnn.h /Developer/NVIDIA/CUDA-7.5/include/
sudo mv cuda/lib/libcudnn* /Developer/NVIDIA/CUDA-7.5/lib
sudo ln -s /Developer/NVIDIA/CUDA-7.5/lib/libcudnn* /usr/local/cuda/lib/
```

and my environment contains 

```
export CUDA_HOME=""/usr/local/cuda""
export DYLD_LIBRARY_PATH=""$DYLD_LIBRARY_PATH:$CUDA_HOME/lib""
```

and `ls /usr/local/cuda/lib | grep ""libcudart.7.5""` gives `libcudart.7.5.dylib`.

Tensorflow 0.9 itself works great with GPU.
",ran tar environment export export work great,issue,positive,positive,positive,positive,positive,positive
233200977,"@act65 try `condo install --channel https://conda.anaconda.org/conda-forge protobuf=3.0.0b2.post2`.
",act try install channel,issue,negative,neutral,neutral,neutral,neutral,neutral
233200146,"I ""fixed"" what may be the same problem by changing the symbolic link in /usr/bin to point to my Anaconda version:
$ which python
/home/denis/anaconda2/bin/python
sudo ln -s ./usr/bin/python /home/denis/anaconda2/bin/python

""fixed"" is in quotes because messing with the system python link seems bad, but tensorflow is all I'm using it for right now, so it's a risk I can take.
I'm guessing something in bazel needs to not point directly to /usr/bin/python?
",fixed may problem symbolic link point anaconda version python fixed messing system python link bad right risk take guessing something need point directly,issue,negative,negative,neutral,neutral,negative,negative
233168649,"Hey,
mine doesnt work either. Mac OSX 10.11, Anaconda 3.5, Bazel 0.3, Tensorflow 0.9. And just cloned this repo.

```
$ bazel test //magenta/...
ERROR: package contains errors: magenta/magenta/protobuf.
ERROR: error loading package 'magenta/magenta/protobuf': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': error loading package 'external': The repository named 'protobuf' could not be resolved.
INFO: Elapsed time: 0.226s
ERROR: Couldn't start the build. Unable to run tests.
```

Cant be bothered going back to python 2.7, will just wait for fix/help.
",hey mine doesnt work either mac anaconda test error package error error loading package error reading extension file package error loading package repository could resolved time error could start build unable run cant going back python wait,issue,negative,negative,negative,negative,negative,negative
233145021,"@afuhrtrumpet I encountered something similar. I believe that you are confusing the output of convert_midi_dir_to_note_sequences.py. with that of basic_rnn_create_dataset.py

So first create a /tmp/notesequences.tfrecord with convert_midi_dir_to_note_sequences.py, and then create a /tmp/basic_rnn/sequence_examples/training_melodies.tfrecord with basic_rnn_create_dataset.py

It's training_melodies.tfrecord that you want to pass to --sequence_example_file
",something similar believe output first create create want pas,issue,positive,positive,positive,positive,positive,positive
233099661,"I was able to reproduce the error earlier. Since then, I updated my TensorFlow install to 0.9.0 and we made changed to Magenta. Now when I create the dataset and run training it doesn't crash. Seems the issue may have been magically fixed.

Can you make sure you are running tensorflow 0.9.0 and pull in recent Magenta changes, and then try again?
",able reproduce error since install made magenta create run training crash issue may magically fixed make sure running pull recent magenta try,issue,negative,positive,positive,positive,positive,positive
232701497,"When you go into a python shell, can you import tensorflow?
",go python shell import,issue,negative,neutral,neutral,neutral,neutral,neutral
232700952,"@nathanielatom, I've usually seen that error when libcudart.7.5 wasn't copied to the correct cuda installation. Would you mind following the installation instructions one more time just to make sure that isn't it?
",usually seen error copied correct installation would mind following installation one time make sure,issue,negative,positive,neutral,neutral,positive,positive
232678094,"@cinjon  For each log, there is only one error

`ImportError: No module named tensorflow`

The TensorFlow 0.9 is installed via Anaconda approach mentioned on TF official website, and created a conda virtual environment called tensorflow, it is a bit strange because I've already has run `source activate tensorflow` before `bazel test //magenta:all`. 

By the way, bazel is installed within root environment, is it required to be separately installed within virtual environment where tensorflow located in ? But bazel is not a package with Anaconda, so this seems not to be the reason

There is an additional error 
`WARNING: /.../c45d77cbbbf828100c725e9c54fd2fa6/external/protobuf/WORKSPACE:1: Workspace name in /.../c45d77cbbbf828100c725e9c54fd2fa6/external/protobuf/WORKSPACE (@__main__) does not match the name given in the repository's definition (@protobuf); this will cause a build error in future versions.`
",log one error module via anaconda approach official virtual environment bit strange already run source activate test way within root environment separately within virtual environment package anaconda reason additional error warning name match name given repository definition cause build error future,issue,negative,negative,neutral,neutral,negative,negative
232674476,"@yunge, thanks for the request. We currently don't have the bandwidth to do this as we're busy working on other features, but we would gladly accept a PR that solves this.
",thanks request currently busy working would gladly accept,issue,positive,positive,positive,positive,positive,positive
232674075,"@YoshikawaMasashi, this is pretty hard for us to diagnose. Have you had any further success?
",pretty hard u diagnose success,issue,positive,positive,neutral,neutral,positive,positive
232673510,"Hi there endofzero. Thanks for posting this. If you wanted to make a PR for this, that would be super helpful. I'm going to close it an issue though.
",hi thanks posting make would super helpful going close issue though,issue,positive,positive,positive,positive,positive,positive
232673092,"Ah ok. Do you mind posting those logs please? I don't have a 16.04 distribution handy so it's hard for me to reproduce this.
",ah mind posting please distribution handy hard reproduce,issue,negative,positive,positive,positive,positive,positive
232629550,"@cinjon  Hi, it helped for the bazel installation, since it was failed to install bazel. And now there is this new problem when `bazel test //magenta:all`
",hi installation since install new problem test,issue,negative,positive,positive,positive,positive,positive
232519483,"Here is a fix:
https://github.com/danabo/magenta/blob/basic_rnn_checkpoint_fix/magenta/models/basic_rnn/basic_rnn_train.py

This code worked for me. When training is resumed global step is loaded from the checkpoint. Let me know if this fixes your issue.
",fix code worked training global step loaded let know issue,issue,negative,neutral,neutral,neutral,neutral,neutral
232301500,"Hey Dan

I posted a partial solution thanks for the starting code.

Jeremy Ellis

twitter @rocksetta
website http://rocksetta.com
On Jul 11, 2016 11:16 AM, ""Daniel Abolafia"" notifications@github.com
wrote:

> I posted in your thread what the change should look like.
> 
> https://groups.google.com/a/tensorflow.org/forum/#!topic/magenta-discuss/riVSW-dKJ3k
> 
> If you would like to fix it in your fork you are welcome to make a PR.
> Otherwise I will take care of it.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/issues/62#issuecomment-231818668,
> or mute the thread
> https://github.com/notifications/unsubscribe/AFWI7mTid2nDkNZJz70uNTMldI5rkE1Nks5qUohxgaJpZM4I9bYb
> .
",hey dan posted partial solution thanks starting code twitter wrote posted thread change look like would like fix fork welcome make otherwise take care thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
232106844,"Thanks @danabo 

Not yet perfect, still starting from zero checkpoint. See comment at

https://groups.google.com/a/tensorflow.org/forum/#!topic/magenta-discuss/riVSW-dKJ3k
",thanks yet perfect still starting zero see comment,issue,positive,positive,positive,positive,positive,positive
232087453,"Ok - I think I can relicense to apache 2.0 . Can we confirm that is
possible?

If not we can just point to Ishaan's code and pull this file.
On Jul 12, 2016 7:34 AM, ""fredbertsch"" notifications@github.com wrote:

> Closed #92 https://github.com/tensorflow/magenta/pull/92.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/92#event-720225878, or mute
> the thread
> https://github.com/notifications/unsubscribe/ABfbHe53-6ULI5qyONd9OpgLx0RtHstaks5qU6YIgaJpZM4JKIBi
> .
",think relicense apache confirm possible point code pull file wrote closed thread reply directly view mute thread,issue,negative,neutral,neutral,neutral,neutral,neutral
232066677,"Unfortunately, Google is requiring us to use a unform license in this repo. We're looking into finding an alternative.
",unfortunately u use unform license looking finding alternative,issue,negative,negative,negative,negative,negative,negative
231879972,"It looks like the error is occurring because a checkpoint file cannot be found in the specified experiment_run_dir. When you call basic_rnn_generate, the code looks for a checkpoint file in the 'train' subdirectory within the specified --experiment_run_dir. For example, if --experiment_run_dir=/tmp/basic_rnn/run1, the code looks for a checkpoint file in /tmp/basic_rnn/run1/train/. Does that location contain a checkpoint file for your trained model? Your --experiment_run_dir flag should point to the same --experiment_run_dir used when calling basic_rnn_train.
",like error file found call code file within example code file location contain file trained model flag point used calling,issue,negative,neutral,neutral,neutral,neutral,neutral
231829149,"I did not. I was looking at diving deeper into the source of the issue later.
",looking diving source issue later,issue,negative,neutral,neutral,neutral,neutral,neutral
231818668,"I posted in your thread what the change should look like.
https://groups.google.com/a/tensorflow.org/forum/#!topic/magenta-discuss/riVSW-dKJ3k

If you would like to fix it in your fork you are welcome to make a PR. Otherwise I will take care of it.
",posted thread change look like would like fix fork welcome make otherwise take care,issue,positive,positive,positive,positive,positive,positive
231167473,"So I have a repository setup at https://github.com/hpssjellis/magenta to address this issue. All I want to get working is for tensorflow to check if a RUN1 folder has already been made. If the folder exists then continue the training from the last checkpoint. 
",repository setup address issue want get working check run folder already made folder continue training last,issue,negative,neutral,neutral,neutral,neutral,neutral
230977742,"I'll have to make the test more lenient. Converting over to TFLearn should fix this (if I understand correctly that it automates boilerplate model testing). 
",make test lenient converting fix understand correctly model testing,issue,negative,positive,positive,positive,positive,positive
230932838,"I believe I'm having a similar issue when running the tests. I'm on:

OS X 10.11.5, Anaconda Python 2.7.11, Bazel 0.2.3, Tensorflow 0.9 with GPU, Cuda 7.5, CuDNN 5.1 RC

the error I get is:

`Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/__main__/magenta/lib/midi_io_test.py"", line 27, in <module>
    import tensorflow as tf
  File ""/Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 48, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)`
`ImportError: dlopen(/Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib
  Referenced from: /Users/Atom/.anaconda/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found`

which seems to be caused by missing environment variables that point to the GPU libraries (https://github.com/tensorflow/tensorflow/issues/2278).

Indeed, when I added `import os; print os.environ` to one of the tested python files, the resulting dictionary did not contain `DYLD_LIBRARY_PATH`. Why is the environment different? Is there a way to keep / include a user's environment variables?

For reference here's the printed `os.environ` from the test:

`{'PYTHON_RUNFILES': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles', 'TZ': 'UTC', 'PYTHONPATH': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/protobuf/python:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/__main__:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/midi:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/pretty_midi:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/protobuf:/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/six_archive', 'VERSIONER_PYTHON_VERSION': '2.7', 'TEST_TIMEOUT': '300', 'XML_OUTPUT_FILE': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/testlogs/magenta/midi_io_test/test.xml', 'JAVA_RUNFILES': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles', 'VERSIONER_PYTHON_PREFER_32_BIT': 'no', 'TEST_WORKSPACE': '__main__', 'TEST_SRCDIR': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles', '__CF_USER_TEXT_ENCODING': '0x1F6:0x0:0x0', 'SHLVL': '1', 'PWD': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/bazel-out/local-opt/bin/magenta/midi_io_test.runfiles/__main__', '_': 'magenta/midi_io_test', 'TEST_SIZE': 'medium', 'TEST_TMPDIR': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/_tmp/midi_io_test_6', 'PATH': '.:/usr/local/cuda/bin:/Users/Atom/.anaconda/bin:/Library/TeX/Distributions/TeXLive-2014-Basic.texdist/Contents/Programs/x86_64:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/usr/local/sbin:/opt/X11/bin:/usr/local/git/bin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin', 'GTEST_TMP_DIR': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta/_tmp/midi_io_test_6', 'OLDPWD': '/private/var/tmp/_bazel_Atom/cc11e662fbaa4b129c6842f2a973b85f/magenta', 'TMPDIR': '/var/folders/h0/j056qfyd7_s0_n1hj2z_716h0000gp/T/'}`

and from a regular ipython session:

`{'LESS': '-R', 'LC_CTYPE': 'en_CA.UTF-8', 'TERM_PROGRAM_VERSION': '361.1', 'LOGNAME': 'Atom', 'USER': 'Atom', 'PATH': '/usr/local/cuda/bin:/Users/Atom/.anaconda/bin:/Library/TeX/Distributions/TeXLive-2014-Basic.texdist/Contents/Programs/x86_64:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/usr/local/sbin:/opt/X11/bin:/usr/local/git/bin:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin', 'HOME': '/Users/Atom', 'DISPLAY': '/private/tmp/com.apple.launchd.Tc0rYXUYhi/org.macosforge.xquartz:0', 'TERM_PROGRAM': 'Apple_Terminal', 'LANG': 'en_CA.UTF-8', 'TERM': 'xterm-256color', 'Apple_PubSub_Socket_Render': '/private/tmp/com.apple.launchd.y4UoBj0q7B/Render', 'SHLVL': '2', 'XPC_FLAGS': '0x0', '_': '/Users/Atom/.anaconda/python.app/Contents/MacOS/python', 'TERM_SESSION_ID': '9C37E199-5885-47D0-90FC-5599E0F31044', 'XPC_SERVICE_NAME': '0', 'CUDA_HOME': '/usr/local/cuda', 'PYTHONPATH': '/Users/Atom/Dropbox/Aercoustics/ModCalcTools/Aelpy Library/source:', 'SSH_AUTH_SOCK': '/private/tmp/com.apple.launchd.dBG4xDDrvt/Listeners', 'DYLD_LIBRARY_PATH': ':/usr/local/cuda/lib', 'SHELL': '/bin/zsh', 'TMPDIR': '/var/folders/h0/j056qfyd7_s0_n1hj2z_716h0000gp/T/', 'LSCOLORS': 'Gxfxcxdxbxegedabagacad', 'PYTHONEXECUTABLE': '/Users/Atom/.anaconda/bin/python', '__CF_USER_TEXT_ENCODING': '0x1F6:0x0:0x0', 'PWD': '/Users/Atom/Dropbox/Year4/ECE521/Reference/tensorflow/magenta', 'PAGER': 'less'}`
",believe similar issue running o anaconda python error get recent call last file line module import file line module import file line module import file line module file line description library loaded reason image found missing environment point indeed added import o print one tested python resulting dictionary contain environment different way keep include user environment reference printed test regular session,issue,negative,negative,neutral,neutral,negative,negative
230858708,"Audacious has a built-in MIDI plugin, so you can try that. All you need to do is add a soundfont file in the settings.
",audacious try need add file,issue,negative,neutral,neutral,neutral,neutral,neutral
230816320,"Hello! Thanks for waiting. I was out of town on holiday...

This looks great. We're running Python 2.7.6 internally, but we definitely want to support Python 3 as well. We're working on setting up Python 3 tests, for example. 

Meanwhile, this is a great step in the right direction. LGTM.
",hello thanks waiting town holiday great running python internally definitely want support python well working setting python example meanwhile great step right direction,issue,positive,positive,positive,positive,positive,positive
230731331,"If that can't be opened with VLC, chances are it is, indeed, malformed. I would suggest to use another file. 
",ca indeed malformed would suggest use another file,issue,negative,neutral,neutral,neutral,neutral,neutral
230326085,"you should try these two commands:

```
wget https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg 
sudo apt-key add apt-key.pub.gpg
```

and then follow the installation tutorial. 
",try two add follow installation tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
230325959,"Hi! I didn't see any info on project README about which Python version is supported. I'm using Python 3.5 and encountered ImportError while importing StringIO and fixed it with this commit.
",hi see project python version python fixed commit,issue,negative,positive,neutral,neutral,positive,positive
229694529,"@fredbertsch Sure! Recreated this at PR #76 with correctly signed CLA. Feel free to close this one.
",sure correctly feel free close one,issue,positive,positive,positive,positive,positive,positive
229683747,"Yeah, we're going to need an account that can sign the CLA. Can you recreate the PR?
",yeah going need account sign recreate,issue,negative,neutral,neutral,neutral,neutral,neutral
229538348,"@danabo Sorry, I am a Git/OpenSource newbie. I resolved the conflicts but when I pushed the changes with SourceTree my email address was missing. :-( That's why it is not passing the CLA. Should I close this PR and open a new one?
",sorry resolved address missing passing close open new one,issue,negative,negative,negative,negative,negative,negative
229439100,"Resolve conflicts and I'll merge your PR. convert_sequences_to_melodies.py appears twice in the readme, can you update the name in both places? Thank you :)
",resolve merge twice update name thank,issue,positive,neutral,neutral,neutral,neutral,neutral
229426940,"Thanks for the improvements! We'll try to do this on the .md files for future models as well. 
",thanks try future well,issue,positive,positive,neutral,neutral,positive,positive
229403235,"You are correct. Googlebot gets confused by personal + google.com email
addresses sometimes.. No harm in ACKing the agreement:-)

On Jun 29, 2016 6:50 AM, ""Bryon Gloden, CISSP®"" notifications@github.com
wrote:

> @googlebot https://github.com/googlebot I am confused. I remember
> reading Googlers didn't need to sign the CLA
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/67#issuecomment-229361531,
> or mute the thread
> https://github.com/notifications/unsubscribe/APQ6QuJ68sghpYmy-thEJI0drR-JBed8ks5qQng2gaJpZM4JAnsd
> .
",correct confused personal sometimes harm agreement registered wrote confused remember reading need sign thread reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
229361531,"@googlebot I am confused. I remember reading Googlers didn't need to sign the CLA
",confused remember reading need sign,issue,negative,negative,negative,negative,negative,negative
228064382,"Good question, @lucianthorr. We're happy to take either one, but we're currently able to move faster on PRs. We're still figuring out how to tie our internal code to this repo, and we don't have a complete story about issues yet. Expect to hear more as we learn how to do this smoothly. 
",good question happy take either one currently able move faster still tie internal code complete story yet expect hear learn smoothly,issue,positive,positive,positive,positive,positive,positive
227806496,"Fred, thanks for the response and this style guide is great help.  I wasn't
sure if small edits like that should be suggested via pull request or
opening an issue.
I'm happy to help however I can and look forward to playing more with
Magenta soon.
-Jason

On Wed, Jun 22, 2016 at 12:09 PM, fredbertsch notifications@github.com
wrote:

> We'd like to have Magenta work with either Python 2.7+ or 3. Internally at
> Google, we tend to use 2.7 unless we deliberately try 3. Our style guide
> https://google.github.io/styleguide/pyguide.html#Exceptions even
> requests
> the as syntax.
> 
> I'd be happy to accept your pull request if you send it again.
> 
> -Fred (another Magenta engineer)
> 
> On Wed, Jun 22, 2016 at 8:11 AM Jason Aylward notifications@github.com
> wrote:
> 
> > I realized that what I thought was an error was really a discrepancy
> > between Python 2 and Python 3.
> > 
> > On Wed, Jun 22, 2016 at 10:53 AM, Bryon Gloden, CISSP® <
> > notifications@github.com> wrote:
> > 
> > > Greetings @lucianthorr https://github.com/lucianthorr! I see this
> > > issue
> > > was closed an hour ago. Was your code merged (accepted) somewhere else?
> > > 
> > > —
> > > You are receiving this because you were mentioned.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/tensorflow/magenta/pull/61#issuecomment-227769492
> > > ,
> > > or mute the thread
> > > <
> > 
> > https://github.com/notifications/unsubscribe/AFokMdJF4ZBrRcJZT64sS81-IKoXdwfYks5qOUxTgaJpZM4I7VoM
> > 
> > > .
> > 
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub
> > https://github.com/tensorflow/magenta/pull/61#issuecomment-227775566,
> > or mute the thread
> > <
> > https://github.com/notifications/unsubscribe/APkejIHXE7ebGQwVOr29EXIBI-Sd8Lpnks5qOVC-gaJpZM4I7VoM
> > 
> > .
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/61#issuecomment-227793929,
> or mute the thread
> https://github.com/notifications/unsubscribe/AFokMcLPdyH_vkxhCcjLOJYUuLV6R1buks5qOV4fgaJpZM4I7VoM
> .
",thanks response style guide great help sure small like via pull request opening issue happy help however look forward magenta soon wed wrote like magenta work either python internally tend use unless deliberately try style guide even syntax happy accept pull request send another magenta engineer wed wrote thought error really discrepancy python python wed registered wrote see issue closed hour ago code accepted somewhere else reply directly view mute thread thread reply directly view mute thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
227793929,"We'd like to have Magenta work with either Python 2.7+ or 3. Internally at
Google, we tend to use 2.7 unless we deliberately try 3. Our style guide
https://google.github.io/styleguide/pyguide.html#Exceptions even requests
the as syntax.

I'd be happy to accept your pull request if you send it again.

-Fred (another Magenta engineer)

On Wed, Jun 22, 2016 at 8:11 AM Jason Aylward notifications@github.com
wrote:

> I realized that what I thought was an error was really a discrepancy
> between Python 2 and Python 3.
> 
> On Wed, Jun 22, 2016 at 10:53 AM, Bryon Gloden, CISSP® <
> notifications@github.com> wrote:
> 
> > Greetings @lucianthorr https://github.com/lucianthorr! I see this
> > issue
> > was closed an hour ago. Was your code merged (accepted) somewhere else?
> > 
> > —
> > You are receiving this because you were mentioned.
> > Reply to this email directly, view it on GitHub
> > https://github.com/tensorflow/magenta/pull/61#issuecomment-227769492,
> > or mute the thread
> > <
> > https://github.com/notifications/unsubscribe/AFokMdJF4ZBrRcJZT64sS81-IKoXdwfYks5qOUxTgaJpZM4I7VoM
> > 
> > .
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/61#issuecomment-227775566,
> or mute the thread
> https://github.com/notifications/unsubscribe/APkejIHXE7ebGQwVOr29EXIBI-Sd8Lpnks5qOVC-gaJpZM4I7VoM
> .
",like magenta work either python internally tend use unless deliberately try style guide even syntax happy accept pull request send another magenta engineer wed wrote thought error really discrepancy python python wed registered wrote see issue closed hour ago code accepted somewhere else reply directly view mute thread thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
227775566,"I realized that what I thought was an error was really a discrepancy
between Python 2 and Python 3.

On Wed, Jun 22, 2016 at 10:53 AM, Bryon Gloden, CISSP® <
notifications@github.com> wrote:

> Greetings @lucianthorr https://github.com/lucianthorr! I see this issue
> was closed an hour ago. Was your code merged (accepted) somewhere else?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/61#issuecomment-227769492,
> or mute the thread
> https://github.com/notifications/unsubscribe/AFokMdJF4ZBrRcJZT64sS81-IKoXdwfYks5qOUxTgaJpZM4I7VoM
> .
",thought error really discrepancy python python wed registered wrote see issue closed hour ago code accepted somewhere else reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
227769492,"Greetings @lucianthorr! I see this issue was closed an hour ago. Was your code merged (accepted) somewhere else?
",see issue closed hour ago code accepted somewhere else,issue,negative,negative,neutral,neutral,negative,negative
227302870,"Thanks both of you! Upgrading my system python to 2.7.11 made all the tests pass!
",thanks system python made pas,issue,negative,positive,positive,positive,positive,positive
227287093,"I finally got things to work with python 2.7.  The secret sauce for me was to completely remove python 3, reinstall python 2 from scratch ensuring the brew postinstall worked, then do 

```
brew unlink python && brew link --overwrite python
pip install --upgrade pip
pip install --upgrade setuptools
```

After that I followed the tensorflow setup instructions, and everything worked!

Hopefully that helps others. 
",finally got work python secret sauce completely remove python reinstall python scratch brew worked brew unlink python brew link overwrite python pip install upgrade pip pip install upgrade setup everything worked hopefully,issue,negative,negative,negative,negative,negative,negative
227205543,"I ran into similar issues and assumed it was PEBKAC.  FWIW I could not get it to go with magenta either. 
",ran similar assumed could get go magenta either,issue,negative,neutral,neutral,neutral,neutral,neutral
227107884,"I tried to do this, but rnn training don't keep running.

I don't always get this issue.

When I used a certain midi file, I get this error.
And when I set 'rnn_raler_sizes' high (example:100), I get this error.
",tried training keep running always get issue used certain file get error set high example get error,issue,negative,positive,positive,positive,positive,positive
227025588,"I think you just have to let it keep running and it will continue through the rest of the steps.
",think let keep running continue rest,issue,negative,neutral,neutral,neutral,neutral,neutral
226967619,"I'm running into the same error, `can't import tensorflow`

If you type `python` then `import tensorflow as tf` and get this error, then I think this is an issue with setting up tensorflow for use in your python environment, and doesn't necessarily have a thing to do with magenta, except for the fact that magenta depends on this working in some way.

I tried installing tensorflow for python 2.7/osx with pip, but got the error ""tensorflow-0.9.0rc0-py2-none-any.whl is not a supported wheel on this platform."". I've now solved this by updating my python from 2.7.10 to 2.7.11! My bazel tests are now passing.

Before thinking to update python, I tried using the python 3/osx tensorflow package, and encountered the same error, ""can't import tensorflow"". Surely magenta supports python 3, the problem is making `python` be python 3 and not 2.7. I tried aliasing python to python3, but that didn't work. Creating a symlink could work, but I'm going to let others explore that right now: https://www.google.com/search?q=change+default+python+to+python3

I also tried tensorflows docker image but python isn't even setup inside their docker container, perhaps it should, but at that point I stopped and focused on other methods. 
",running error ca import type python import get error think issue setting use python environment necessarily thing magenta except fact magenta working way tried python pip got error wheel python passing thinking update python tried python package error ca import surely magenta python problem making python python tried python python work could work going let explore right also tried docker image python even setup inside docker container perhaps point stopped,issue,negative,positive,positive,positive,positive,positive
226186839,"I think I fixed it

needs this line in the Docs

replace 

bazel run //magenta:convert_sequences_to_melodies -- \

with

bazel run //magenta/models:basic_rnn_create_dataset -- \
",think fixed need line replace run run,issue,negative,positive,neutral,neutral,positive,positive
225731336,"Thanks for bringing this issue to our attention! Fixed.
",thanks issue attention fixed,issue,negative,positive,positive,positive,positive,positive
225371353,"@terrytangyuan you're quite right, thanks! 

I wasn't using latest. For reference, I updated using:
`(tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py2-none-any.whl
`
and then:
`(tensorflow)$ sudo pip install --upgrade $TF_BINARY_URL
`
...this is in osx using anaconda distribution.
",quite right thanks latest reference export pip install upgrade anaconda distribution,issue,negative,positive,positive,positive,positive,positive
225371039,"@davidplans Check to see if you are using the most recent version?
",check see recent version,issue,negative,neutral,neutral,neutral,neutral,neutral
225252960,"Not a typo. The preceding 'r' makes it a raw string, so that back slashes do not need to be escaped.
",typo preceding raw string back need,issue,negative,negative,negative,negative,negative,negative
225247452,"Thought I had checked that link. Thanks for catching that! This change has merge conflicts, so I fixed it in another pull request.
",thought checked link thanks catching change merge fixed another pull request,issue,negative,positive,positive,positive,positive,positive
225237986,"Hi mgfrantz. If you'd like to get a copy of the repo, just follow the clone instructions in the README. Thanks!
",hi like get copy follow clone thanks,issue,positive,positive,positive,positive,positive,positive
225049003,"I'll discuss these changes with Magenta's PR person and follow up on the CL. 
",discus magenta person follow,issue,negative,neutral,neutral,neutral,neutral,neutral
223768101,"Thanks @shagunsodhani, but I needed to go ahead and make this change. Please sign the CLA so we can use your change next time.
",thanks go ahead make change please sign use change next time,issue,positive,positive,neutral,neutral,positive,positive
223650017,"LGTM, but it looks like your commits came from another account? It looks like it's you, though, so I don't care.
",like came another account like though care,issue,positive,neutral,neutral,neutral,neutral,neutral
223441245,"Thanks for the fix! I may have already checked in the same fix, but it's
much appreciated (not sure what order things went in).

On Thu, Jun 2, 2016 at 2:32 PM, fredbertsch notifications@github.com
wrote:

> Thanks so much for the fix.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/tensorflow/magenta/pull/6#issuecomment-223429019, or mute
> the thread
> https://github.com/notifications/unsubscribe/APQ6Qq4qqKjyLCgrEmVE1IXZSHiv5vzFks5qH0vTgaJpZM4IrzsG
> .
",thanks fix may already checked fix much sure order went wrote thanks much fix thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
222036867,"Add the license text to the build and proto files. (This is tricky on my phone, so I'll look closer tomorrow.)
",add license text build proto tricky phone look closer tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
220447287,"Discussed with the rest of the team. Let's put this under https://github.com/tensorflow/models instead. They're happy to have quirky, specialized models there, and it'd be nice to have models in one place.
",rest team let put instead happy quirky specialized nice one place,issue,positive,positive,positive,positive,positive,positive
220392454,"No, not everything is going under Magenta's GitHub. An easy counterexample are new ops. Those need to go under tensorflow. Tensorflow already has a home for models. We need to decide if the costs of having two homes for TF models is worth it.
",everything going magenta easy new need go already home need decide two worth,issue,positive,positive,positive,positive,positive,positive
220370438,"1) I thought we were putting everything under Magenta team's directory. Ask
Doug about this.

2) I was copying the structure of our internal code, which seems to be
divided up by project and model type. But yes I agree lets organize by
problem space.

On Thu, May 19, 2016 at 7:13 AM, fredbertsch notifications@github.com
wrote:

> Question: Does this fit better in tensorflow/models instead of
> tensorflow/magenta? (I think I like it here better, but I want a record of
> the conversation about it.)
> 
> 2nd question: Why is it important that the models be RNN models? Can't we
> call it melody_models instead?
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly or view it on GitHub
> https://github.com/tensorflow/magenta/pull/2#issuecomment-220336780
",thought everything magenta team directory ask structure internal code divided project model type yes agree organize problem space may wrote question fit better instead think like better want record conversation question important ca call instead thread reply directly view,issue,positive,positive,positive,positive,positive,positive
220336780,"Question: Does this fit better in tensorflow/models instead of tensorflow/magenta? (I think I like it here better, but I want a record of the conversation about it.)

2nd question: Why is it important that the models be RNN models? Can't we call it melody_models instead? 
",question fit better instead think like better want record conversation question important ca call instead,issue,positive,positive,positive,positive,positive,positive
