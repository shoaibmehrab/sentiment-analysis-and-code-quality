id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1977816920,"C:\Users\josh\faceswap>""C:\Users\josh\Miniconda3\scripts\activate.bat""   && conda activate ""faceswap""   && python ""C:\Users\josh\faceswap/faceswap.py"" gui
Setting Faceswap backend to NVIDIA
02/29/2024 10:44:58 INFO     Log level set to: INFO
02/29/2024 10:45:04 ERROR    Got Exception on main handler:
Traceback (most recent call last):
  File ""C:\Users\josh\faceswap\lib\cli\launcher.py"", line 223, in execute_script
    script = self._import_script()
  File ""C:\Users\josh\faceswap\lib\cli\launcher.py"", line 53, in _import_script
    module = import_module(mod)
  File ""C:\Users\josh\miniconda3\envs\faceswap\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1050, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1027, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 1006, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 688, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 883, in exec_module
  File ""<frozen importlib._bootstrap>"", line 241, in _call_with_frames_removed
  File ""C:\Users\josh\faceswap\scripts\gui.py"", line 9, in <module>
    from lib.gui import (TaskBar, CliOptions, CommandNotebook, ConsoleOut, DisplayNotebook,
  File ""C:\Users\josh\faceswap\lib\gui\__init__.py"", line 4, in <module>
    from lib.gui.command import CommandNotebook
  File ""C:\Users\josh\faceswap\lib\gui\command.py"", line 9, in <module>
    from .control_helper import ControlPanel
  File ""C:\Users\josh\faceswap\lib\gui\control_helper.py"", line 15, in <module>
    from .custom_widgets import ContextMenu, MultiOption, ToggledFrame, Tooltip
  File ""C:\Users\josh\faceswap\lib\gui\custom_widgets.py"", line 14, in <module>
    from .utils import get_config
  File ""C:\Users\josh\faceswap\lib\gui\utils\__init__.py"", line 4, in <module>
    from .config import get_config, initialize_config, PATHCACHE
  File ""C:\Users\josh\faceswap\lib\gui\utils\config.py"", line 12, in <module>
    from lib.gui._config import Config as UserConfig
  File ""C:\Users\josh\faceswap\lib\gui\_config.py"", line 8, in <module>
    from matplotlib import font_manager
  File ""C:\Users\josh\miniconda3\envs\faceswap\lib\site-packages\matplotlib\__init__.py"", line 161, in <module>
    from . import _api, _version, cbook, _docstring, rcsetup
  File ""C:\Users\josh\miniconda3\envs\faceswap\lib\site-packages\matplotlib\rcsetup.py"", line 27, in <module>
    from matplotlib.colors import Colormap, is_color_like
  File ""C:\Users\josh\miniconda3\envs\faceswap\lib\site-packages\matplotlib\colors.py"", line 52, in <module>
    from PIL import Image
  File ""C:\Users\josh\miniconda3\envs\faceswap\lib\site-packages\PIL\Image.py"", line 100, in <module>
    from . import _imaging as core
ImportError: DLL load failed while importing _imaging: The specified module could not be found.
02/29/2024 10:45:04 CRITICAL An unexpected crash has occurred. Crash report written to 'C:\Users\josh\faceswap\crash_report.2024.02.29.104500909341.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting

(faceswap) C:\Users\josh\faceswap>ls
CODE_OF_CONDUCT.md  __pycache__                               docs                       locales       tools
Dockerfile.cpu      _config.yml                               faceswap.py                plugins       tools.py
Dockerfile.gpu      config                                    faceswap_gui.log           requirements  update_deps.py
INSTALL.md          crash_report.2024.02.29.104006270120.log  faceswap_gui.log.1         scripts
LICENSE             crash_report.2024.02.29.104030719334.log  faceswap_setup.log         setup.cfg
README.md           crash_report.2024.02.29.104242856258.log  faceswap_win_launcher.bat  setup.py
USAGE.md            crash_report.2024.02.29.104500909341.log  lib                        tests

(faceswap) C:\Users\josh\faceswap>ls requirements
_requirements_base.txt          requirements_cpu.txt       requirements_nvidia.txt
requirements_apple_silicon.txt  requirements_directml.txt  requirements_rocm.txt

(faceswap) C:\Users\josh\faceswap>cat requirements/requirements_nvidia.txt
-r _requirements_base.txt
# Exclude badly numbered Python2 version of nvidia-ml-py
nvidia-ml-py>=11.525,<300
pynvx==1.0.0 ; sys_platform == ""darwin""
tensorflow>=2.10.0,<2.11.0

(faceswap) C:\Users\josh\faceswap>cat requirements/_requirements_base.txt
tqdm>=4.65
psutil>=5.9.0
numexpr>=2.8.4
numpy>=1.25.0
opencv-python>=4.7.0.0
pillow>=9.4.0,<10.0.0
scikit-learn>=1.2.2
fastcluster>=1.2.6
matplotlib>=3.7.1
imageio>=2.26.0
imageio-ffmpeg>=0.4.8
ffmpy>=0.3.0
pywin32>=228 ; sys_platform == ""win32""

(faceswap) C:\Users\josh\faceswap>pip install pillow
Requirement already satisfied: pillow in c:\users\josh\miniconda3\envs\faceswap\lib\site-packages (9.3.0)

(faceswap) C:\Users\josh\faceswap>pip install pillow==9.4.0
Collecting pillow==9.4.0
  Downloading Pillow-9.4.0-cp310-cp310-win_amd64.whl.metadata (9.4 kB)
Downloading Pillow-9.4.0-cp310-cp310-win_amd64.whl (2.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 12.1 MB/s eta 0:00:00
Installing collected packages: pillow
  Attempting uninstall: pillow
    Found existing installation: Pillow 9.3.0
    Uninstalling Pillow-9.3.0:
      Successfully uninstalled Pillow-9.3.0
Successfully installed pillow-9.4.0
",activate python setting log level set error got exception main handler recent call last file line script file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import image file line module import core load module could found critical unexpected crash crash report written log must provide file seeking assistance please verify running latest version log license log log log cat exclude badly python version cat pillow win pip install pillow requirement already satisfied pillow pip install eta collected pillow pillow found installation pillow successfully uninstalled successfully,issue,negative,positive,positive,positive,positive,positive
1977791613,"No. it's the correct version of Pillow...

This is a system issue, in some way (a required file missing on your PC, or a conflict of some kind).

In the first instance, try this to see if it resolves it:
https://forum.faceswap.dev/app.php/faqpage#f1r1",correct version pillow system issue way file missing conflict kind first instance try see,issue,negative,positive,positive,positive,positive,positive
1964068051,"Never going to happen, I'm afraid. FS is rolling release, so installer always picks up the latest code... Packaging libs + models + applications on a point release basis is too much work.",never going happen afraid rolling release installer always latest code point release basis much work,issue,negative,positive,neutral,neutral,positive,positive
1925157867,"i tried the `bash ./faceswap_setup_x64.sh`
bug got 
```
ERROR   This install script should not be run with root privileges. Please
ERROR   run as a normal user.
```",tried bash bug got error install script run root please error run normal user,issue,negative,positive,positive,positive,positive,positive
1924192139,"json alignments have not been used in faceswap  for years. Literally, years.

As stated earlier in this thread. Read the guides linked in the faceswap forum as they are kept up to date.

**Installation**
- Windows Installation Guide:: https://faceswap.dev/forum/viewtopic.php?f=4&t=20
- Linux Installation Guide: https://forum.faceswap.dev/viewtopic.php?f=4&t=68
- macOS Installation Guide: https://forum.faceswap.dev/viewtopic.php?t=2748

**Usage**
- Extraction Guide : https://forum.faceswap.dev/viewtopic.php?f=25&t=27
- Training Guide: https://forum.faceswap.dev/viewtopic.php?f=27&t=146
- Convert Guide: https://forum.faceswap.dev/viewtopic.php?f=24&t=1083",used literally stated thread read linked forum kept date installation installation guide installation guide installation guide usage extraction guide training guide convert guide,issue,negative,neutral,neutral,neutral,neutral,neutral
1924186012,"It seems in the latest version, the ""alignments.json"" file is replaced by ""alignments.fsa"" file ? is it correct for my judgement ?",latest version file file correct,issue,negative,positive,positive,positive,positive,positive
1921212397,"The error and the solution is right in your message :/

If you want more support use our [Discord](https://discord.gg/FC54sYg) or our [Forum](https://faceswap.dev/forum). This is not the place for support on trivial issues.",error solution right message want support use discord forum place support trivial,issue,negative,positive,positive,positive,positive,positive
1920323156,"This makes no difference to me.

Either you know what you are doing with Python and can troubleshoot issues yourself, in which case by all means, install how you see fit.

Otherwise, you do not know how to troubleshoot these issues yourself and need help. In these instances we will **only** provide support if you use our installers.

It is too much of a burden to support anyone's and everyone's esoteric custom installation methods.

There is an installer for Linux at the link I posted above.",difference either know python case install see fit otherwise know need help provide support use much burden support anyone everyone esoteric custom installation installer link posted,issue,positive,positive,positive,positive,positive,positive
1920319565,"Use the installer.

We do not support custom install paths.

https://github.com/deepfakes/faceswap/releases",use installer support custom install,issue,negative,neutral,neutral,neutral,neutral,neutral
1920318872,"install python=3.10.13, but 
```
python faceswap.py gui
Setting Faceswap backend to NVIDIA
02/01/2024 09:34:35 INFO     Log level set to: INFO
02/01/2024 09:34:37 ERROR    No display detected. GUI mode has been disabled.
```",install python setting log level set error display mode disabled,issue,negative,negative,negative,negative,negative,negative
1919035571,Your Python version is too old. Use the installer in releases and you will not have this problem.,python version old use installer problem,issue,negative,positive,neutral,neutral,positive,positive
1918822542,"python faceswap.py gui
First time configuration. Please select the required backend
1: CPU, 2: DIRECTML, 3: NVIDIA, 4: APPLE SILICON, 5: ROCM: 3
Faceswap config written to: /data/xu/faceswap/config/.faceswap
Setting Faceswap backend to NVIDIA
Traceback (most recent call last):
  File ""/data/xu/faceswap/faceswap.py"", line 12, in <module>
    from lib.cli import args as cli_args  # pylint:disable=wrong-import-position
  File ""/data/xu/faceswap/lib/cli/args.py"", line 18, in <module>
    from .actions import (DirFullPaths, DirOrFileFullPaths, DirOrFilesFullPaths, FileFullPaths,
  File ""/data/xu/faceswap/lib/cli/actions.py"", line 49, in <module>
    class FileFullPaths(_FullPaths):
  File ""/data/xufaceswap/lib/cli/actions.py"", line 72, in FileFullPaths
    def __init__(self, *args, filetypes: str | None = None, **kwargs) -> None:
TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'",python first time configuration please select apple silicon written setting recent call last file line module import file line module import file line module class file line self none none none unsupported operand type,issue,negative,positive,neutral,neutral,positive,positive
1914739514,"This is not a support forum.

Please use our [Discord](https://discord.gg/FC54sYg) or our [Forum](https://faceswap.dev/forum)",support forum please use discord forum,issue,negative,neutral,neutral,neutral,neutral,neutral
1904043315,"Thank you very much this explains everything I wanted to know. This also means I will keep faceswap installed for as long as I use it no reverting back to a clean state (aka. backup) as I did before.

Have a nice day!",thank much everything know also keep long use back clean state aka backup nice day,issue,positive,positive,positive,positive,positive,positive
1903905372,"To the initial question 'How isolated is the installer?' the answer is 'very'

My general approach is that no application should take more permissions than they require. For that reason, if you run the installer in either Linux or macOS, then you will notice that at no point are you asked for the root password, yet everything works successfully.

This isn't so true of Windows, because Windows is Windows. Whilst the Windows installer also does not install anything system wide, an Admin confirmation window will still pop when running the installer (I was going to attempt to remove this, but I will soon be pushing WSL2 builds for Windows which *do* require admin access to manage WSL2... there is no way around that).

The installers, regardless of OS do the same thing:
- Install MiniConda3 (locally in userdata folder)
- Setup a MiniConda3 environment (because of above, this can *only* be local)
- Install all requirements (*including* Cuda) into the local environment.

Whilst faceswap itself keeps everything contained in the faceswap folder and MiniConda3 keeps everything contained in the MiniConda3 folder, the libs we rely on will have their own caching mechanism (matplotlib, keras, tensorflow etc. etc.). We can have no control over this. However, they *will* be stored somewhere in the user folder, as the application simply does not have privileges above user level.

As an aside, you should look into using Conda to manage you Cuda installs. It makes using multiple Cuda versions very simple (just create a new virtual environment for different Cuda versions) and, again, you do not need to elevate Cuda's permissions beyond what it requires.

The reason we recommend removing global Cuda is that it *can* conflict. Whilst I set as many mechanisms as I can not to break out of the environment we create, it *can* happen because, after all  `Admin` > `User` in terms privileges. So it is possible that global Cuda can override the locally installed Cuda",initial question isolated installer answer general approach application take require reason run installer either notice point root password yet everything work successfully true whilst installer also install anything system wide confirmation window still pop running installer going attempt remove soon pushing require access manage way around regardless o thing install locally folder setup environment local install local environment whilst everything folder everything folder rely mechanism control however somewhere user folder application simply user level aside look manage multiple simple create new virtual environment different need elevate beyond reason recommend removing global conflict whilst set many break environment create happen user possible global override locally,issue,positive,positive,neutral,neutral,positive,positive
1889259318,"I don't have an Apple device for testing.

However, looking at your install logs, it looks like you had a connection issue at the end of the installation process, so the final packages did not get installed.

Glad you got it working though.",apple device testing however looking install like connection issue end installation process final get glad got working though,issue,positive,positive,positive,positive,positive,positive
1888669213,Seems to work when building [manually](https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#macos-apple-silicon-install-guide) and using `python3.10 setup.py` and `python3.10 faceswap.py gui` commands,work building manually python python,issue,negative,neutral,neutral,neutral,neutral,neutral
1888651481,I tried `python faceswap.py gui` and got `ModuleNotFoundError: No module named 'numpy'` so no solution from forums I found work,tried python got module solution found work,issue,negative,neutral,neutral,neutral,neutral,neutral
1888641714,"I saw other users complaining about packages not being installed with official installer script, so maybe that's the problem

I have no idea where to run `pip install tensorflow-metal` or if is it even a correct command :/

<details>
<summary>Full installation logs</summary>

```
                         001
                        11 10  010
               @@@@      10
            @@@@@@@@         00     1
          @@@@@@@@@@  1  1            0
        @@@@@@@@    0000 01111
       @@@@@@@@@@    01  110 01  1
      @@@@@@@@@@@@ 111    010    0
      @@@@@@@@@@@@@@@@  10    0
      @@@@@@@@@@@@@   0010   1
      @@@@@@@@@  @@@   100         1
      @@@@@@@ .@@@@  10       1
       #@@@@@@@@@@@  001       0
         @@@@@@@@@@@  ,
         @@@@@@@@  @@@@@
        @@@@@@@@ @@@@@@@@    _
       @@@@@@@@@,@@@@@@@@  / _|
       %@@@@@@@@@@@@@@@@@ | |_  ___
           @@@@@@@@@@@@@@ |  _|/ __|
            @@@@@@@@@@@@  | |  \__ \
             @@@@@@@@@@(  |_|  |___/
                @@@@@@
                 @@@@

================ Welcome to the macOS Faceswap Installer ================
INFO    To get setup we need to gather some information about where you would
INFO    like Faceswap and Conda to be installed.
INFO    To accept the default values just hit the 'ENTER' key for each option.
INFO    You will have an opportunity to review your responses prior to
INFO    commencing the install.

INFO    IMPORTANT: Make sure that the user 'hloth' has full permissions for
INFO    all of the destinations that you select.
Press 'ENTER' to continue with the setup...

================================= CONDA =================================
INFO    Faceswap uses Conda as it handles the installation of all
INFO    prerequisites.

INFO    If you have an existing Conda install then enter the location here,
INFO    otherwise Miniconda3 will be installed in the given location.
Please specify a location for Conda. [default: '/Users/hloth/miniconda3']:

INFO    The Conda executable can be added to your PATH. This makes it easier
INFO    to run Conda commands directly. If you already have a pre-existing
INFO    Conda install then you should probably not enable this, otherwise this
INFO    should be fine.
Add Conda executable to path? [YES/no]:

INFO    Faceswap will be installed inside a Conda Environment. If an
INFO    environment already exists with the name specified then it will be
INFO    deleted.
Please specify a name for the Faceswap Conda Environmnet [default: 'faceswap']:

================================ FACESWAP ================================
INFO    Faceswap will be installed in the given location. If a folder exists
INFO    at the location you specify, then it will be deleted.
Please specify a location for Faceswap [default: '/Users/hloth/faceswap']:

INFO    Faceswap can be run on Apple Silicon (M1, M2 etc.), compatible NVIDIA
INFO    gpus, or on CPU. You should make sure that any drivers are up to
INFO    date. Please select the version of Faceswap you wish to install.
Select:	1: Apple Silicon
	2: NVIDIA
	3: CPU
[default: 1]:

======================= POST INSTALLATION ACTIONS =======================
INFO    Launching Faceswap requires activating your Conda Environment and then
INFO    running Faceswap. The installer can simplify this by creating an
INFO    Application Launcher file and placing it on your desktop to launch
INFO    straight into the Faceswap GUI
Create FaceswapGUI Launcher? [YES/no]:

========================= Review install options =========================
INFO    Please review the selected installation options before proceeding:

        - MiniConda3 will be installed in '/Users/hloth/miniconda3'
        - MiniConda3 will be added to your PATH
        - Conda Environment 'faceswap' will be created.
        - Faceswap will be installed in '/Users/hloth/faceswap'
        - Installing for 'apple_silicon'
        - An Application Launcher will be created
Do you wish to continue? [yes/NO]: yes
INFO    Downloading Miniconda3...

################################################################################################################################################################### 100.0%
INFO    Installing Miniconda3...

PREFIX=/Users/hloth/miniconda3
Unpacking payload ...

Installing base environment...


Downloading and Extracting Packages:


Downloading and Extracting Packages:

Preparing transaction: done
Executing transaction: \
done
installation finished.
INFO    Adding Miniconda3 to PATH...

no change     /Users/hloth/miniconda3/condabin/conda
no change     /Users/hloth/miniconda3/bin/conda
no change     /Users/hloth/miniconda3/bin/conda-env
no change     /Users/hloth/miniconda3/bin/activate
no change     /Users/hloth/miniconda3/bin/deactivate
no change     /Users/hloth/miniconda3/etc/profile.d/conda.sh
no change     /Users/hloth/miniconda3/etc/fish/conf.d/conda.fish
no change     /Users/hloth/miniconda3/shell/condabin/Conda.psm1
modified      /Users/hloth/miniconda3/shell/condabin/conda-hook.ps1
no change     /Users/hloth/miniconda3/lib/python3.11/site-packages/xontrib/conda.xsh
no change     /Users/hloth/miniconda3/etc/profile.d/conda.csh
modified      /Users/hloth/.bash_profile
no change     /Users/hloth/.zshrc

==> For changes to take effect, close and re-open your current shell. <==

INFO    Creating Conda Virtual Environment...

Channels:
 - defaults
Platform: osx-arm64
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /Users/hloth/miniconda3/envs/faceswap

  added / updated specs:
    - python=3.10


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    pip-23.3.1                 |  py310hca03da5_0         2.7 MB
    python-3.10.13             |       hb885b13_0        13.0 MB
    setuptools-68.2.2          |  py310hca03da5_0         942 KB
    tzdata-2023d               |       h04d1e81_0         117 KB
    wheel-0.41.2               |  py310hca03da5_0         107 KB
    ------------------------------------------------------------
                                           Total:        16.8 MB

The following NEW packages will be INSTALLED:

  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h620ffc9_4
  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2023.12.12-hca03da5_0
  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_0
  ncurses            pkgs/main/osx-arm64::ncurses-6.4-h313beb8_0
  openssl            pkgs/main/osx-arm64::openssl-3.0.12-h1a28f6b_0
  pip                pkgs/main/osx-arm64::pip-23.3.1-py310hca03da5_0
  python             pkgs/main/osx-arm64::python-3.10.13-hb885b13_0
  readline           pkgs/main/osx-arm64::readline-8.2-h1a28f6b_0
  setuptools         pkgs/main/osx-arm64::setuptools-68.2.2-py310hca03da5_0
  sqlite             pkgs/main/osx-arm64::sqlite-3.41.2-h80987f9_0
  tk                 pkgs/main/osx-arm64::tk-8.6.12-hb8d0fd4_0
  tzdata             pkgs/main/noarch::tzdata-2023d-h04d1e81_0
  wheel              pkgs/main/osx-arm64::wheel-0.41.2-py310hca03da5_0
  xz                 pkgs/main/osx-arm64::xz-5.4.5-h80987f9_0
  zlib               pkgs/main/osx-arm64::zlib-1.2.13-h5a0b063_0


Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
INFO    Downloading Faceswap...

Cloning into '/Users/hloth/faceswap'...
remote: Enumerating objects: 1294, done.
remote: Counting objects: 100% (1294/1294), done.
remote: Compressing objects: 100% (1086/1086), done.
remote: Total 1294 (delta 624), reused 515 (delta 186), pack-reused 0
Receiving objects: 100% (1294/1294), 88.60 MiB | 20.92 MiB/s, done.
Resolving deltas: 100% (624/624), done.
INFO    Setting up Faceswap...
/Users/hloth/faceswap/setup.py:18: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
  from pkg_resources import parse_requirements
INFO     Running without root/admin privileges
INFO     The tool provides tips for installation and installs required python packages
INFO     Setup in Darwin 22.6.0
INFO     Installed Python: 3.10.13 64bit
INFO     Running in Conda
INFO     Running in a Virtual Environment
INFO     Encoding: UTF-8
INFO     Installed pip: 23.3.1
INFO     Faceswap config written to: /Users/hloth/faceswap/config/.faceswap
INFO     Adding conda required package 'libblas' for backend 'apple_silicon')
INFO     Installing Required Python Packages. This may take some time...
INFO     Installing pexpect>=4.8.0
INFO     Installing Required Conda Packages. This may take some time...
INFO     Installing git
   perl-5.34.0          | 14.0 MB   | ███████████████████████████████████ | 100%
   git-2.40.1           | 8.8 MB    | ███████████████████████████████████ | 100%
   gettext-0.21.0       | 3.1 MB    | ███████████████████████████████████ | 100%
   libcurl-8.5.0        | 356 KB    | ███████████████████████████████████ | 100%
   llvm-openmp-14.0.6   | 253 KB    | ███████████████████████████████████ | 100%
   expat-2.5.0          | 144 KB    | ███████████████████████████████████ | 100%
   gdbm-1.18            | 141 KB    | ███████████████████████████████████ | 100%
   curl-8.5.0           | 79 KB     | ███████████████████████████████████ | 100%
INFO     Installing libblas
   libopenblas-0.3.25   | 2.8 MB    | ███████████████████████████████████ | 100%
   openssl-3.2.0        | 2.7 MB    | ███████████████████████████████████ | 100%
   libgfortran5-13.2.0  | 972 KB    | ███████████████████████████████████ | 100%
   llvm-openmp-17.0.6   | 268 KB    | ███████████████████████████████████ | 100%
   libgfortran-5.0.0    | 108 KB    | ███████████████████████████████████ | 100%
   libblas-3.9.0        | 14 KB     | ███████████████████████████████████ | 100%
INFO     Installing tqdm>=4.65
   tqdm-4.65.0          | 133 KB    | ███████████████████████████████████ | 100%
INFO     Installing psutil>=5.9.0
   psutil-5.9.0         | 345 KB    | ███████████████████████████████████ | 100%
INFO     Installing numexpr>=2.8.4
   numpy-base-1.26.3    | 5.8 MB    | ███████████████████████████████████ | 100%
   numexpr-2.8.7        | 126 KB    | ███████████████████████████████████ | 100%
   numpy-1.26.3         | 11 KB     | ███████████████████████████████████ | 100%
   blas-1.0             | 10 KB     | ███████████████████████████████████ | 100%
INFO     Installing numpy>=1.25.0
INFO     Installing opencv-python>=4.7.0.0
INFO     opencv-python>=4.7.0.0 not available in Conda. Installing with pip
INFO     Installing opencv-python>=4.7.0.0
   opencv_python-4.9.0.8| 35.4 MB   | ███████████████████████████████████ | 100%
INFO     Installing pillow<10.0.0,>=9.4.0
   pillow-9.4.0         | 669 KB    | ███████████████████████████████████ | 100%
   freetype-2.12.1      | 570 KB    | ███████████████████████████████████ | 100%
   libtiff-4.5.1        | 496 KB    | ███████████████████████████████████ | 100%
   libwebp-base-1.3.2   | 297 KB    | ███████████████████████████████████ | 100%
   libpng-1.6.39        | 283 KB    | ███████████████████████████████████ | 100%
   lcms2-2.12           | 273 KB    | ███████████████████████████████████ | 100%
   jpeg-9e              | 248 KB    | ███████████████████████████████████ | 100%
   lerc-3.0             | 115 KB    | ███████████████████████████████████ | 100%
   libwebp-1.3.2        | 86 KB     | ███████████████████████████████████ | 100%
   giflib-5.2.1         | 78 KB     | ███████████████████████████████████ | 100%
   libdeflate-1.17      | 55 KB     | ███████████████████████████████████ | 100%
INFO     Installing scikit-learn>=1.2.2
   scipy-1.11.4         | 19.5 MB   | ███████████████████████████████████ | 100%
   scikit-learn-1.3.0   | 7.7 MB    | ███████████████████████████████████ | 100%
   joblib-1.2.0         | 394 KB    | ███████████████████████████████████ | 100%
   threadpoolctl-2.2.0  | 16 KB     | ███████████████████████████████████ | 100%
INFO     Installing fastcluster>=1.2.6
   fastcluster-1.2.6    | 39 KB     | ███████████████████████████████████ | 100%
INFO     Installing matplotlib>=3.7.1
   matplotlib-base-3.8. | 6.8 MB    | ███████████████████████████████████ | 100%
   tornado-6.3.3        | 645 KB    | ███████████████████████████████████ | 100%
   fonttools-4.25.0     | 632 KB    | ███████████████████████████████████ | 100%
   libbrotlienc-1.0.9   | 256 KB    | ███████████████████████████████████ | 100%
   contourpy-1.2.0      | 238 KB    | ███████████████████████████████████ | 100%
   python-dateutil-2.8. | 233 KB    | ███████████████████████████████████ | 100%
   pyparsing-3.0.9      | 151 KB    | ███████████████████████████████████ | 100%
   packaging-23.1       | 78 KB     | ███████████████████████████████████ | 100%
   libbrotlicommon-1.0. | 70 KB     | ███████████████████████████████████ | 100%
   kiwisolver-1.4.4     | 61 KB     | ███████████████████████████████████ | 100%
   libbrotlidec-1.0.9   | 27 KB     | ███████████████████████████████████ | 100%
   brotli-1.0.9         | 18 KB     | ███████████████████████████████████ | 100%
   six-1.16.0           | 18 KB     | ███████████████████████████████████ | 100%
   brotli-bin-1.0.9     | 17 KB     | ███████████████████████████████████ | 100%
   munkres-1.1.4        | 13 KB     | ███████████████████████████████████ | 100%
   cycler-0.11.0        | 12 KB     | ███████████████████████████████████ | 100%
   matplotlib-3.8.0     | 9 KB      | ███████████████████████████████████ | 100%
INFO     Installing imageio>=2.26.0
   imageio-2.31.4       | 482 KB    | ███████████████████████████████████ | 100%
INFO     Installing imageio-ffmpeg>=0.4.8
INFO     Installing ffmpy>=0.3.0
   ffmpeg-4.3.2         | 46.6 MB   | ███████████████████████████████████ | 100%
   x264-1!161.3030      | 2.0 MB    | ███████████████████████████████████ | 100%
   gnutls-3.6.13        | 2.0 MB    | ███████████████████████████████████ | 100%
   openh264-2.1.1       | 1.3 MB    | ███████████████████████████████████ | 100%
   nettle-3.6           | 1.2 MB    | ███████████████████████████████████ | 100%
   gmp-6.2.1            | 557 KB    | ███████████████████████████████████ | 100%
   lame-3.100           | 516 KB    | ███████████████████████████████████ | 100%
   ffmpy-0.3.0          | 10 KB     | ███████████████████████████████████ | 100%
INFO     Installing tensorflow-macos>=2.10.0,<2.11.0
INFO     tensorflow-macos>=2.10.0,<2.11.0 not available in Conda. Installing with pip
INFO     Installing tensorflow-macos>=2.10.0,<2.11.0
   tensorflow_macos-2.10| 211.5 MB  | ███████████████████████████████████ | 100%
   google_pasta-0.2.0   | 57.5 kB   | ███████████████████████████████████ | 100%
   Keras_Preprocessing-1| 42.6 kB   | ███████████████████████████████████ | 100%
   opt_einsum-3.3.0     | 65.5 kB   | ███████████████████████████████████ | 100%
   protobuf-3.19.6      | 162.6 kB  | ███████████████████████████████████ | 100%
   tensorboard-2.10.1   | 5.9 MB    | ███████████████████████████████████ | 100%
   tensorflow_estimator-| 438.7 kB  | ███████████████████████████████████ | 100%
   keras-2.10.0         | 1.7 MB    | ███████████████████████████████████ | 100%
   tensorboard_plugin_wi| 781.3 kB  | ███████████████████████████████████ | 100%
   pyasn1_modules-0.3.0 | 181.3 kB  | ███████████████████████████████████ | 100%
   oauthlib-3.2.2       | 130.2 kB  | ███████████████████████████████████ | 100%
   grpcio-1.60.0        | 20.6 MB   | ███████████████████████████████████ | 100%
   google_auth-2.26.2   | 226.7 kB  | ███████████████████████████████████ | 100%
   certifi-2023.11.17   | 61.6 kB   | ███████████████████████████████████ | 100%
   urllib3-2.1.0        | 84.9 kB   | ███████████████████████████████████ | 100%
INFO     Installing tensorflow-deps>=2.10.0,<2.11.0
   python-3.10.13       | 11.1 MB   | ███████████████████████████████████ | 100%
   numpy-1.23.2         | 5.9 MB    | ███████████████████████████████████ | 100%
   hdf5-1.12.1          | 5.3 MB    | ███████████████████████████████████ | 100%
   tk-8.6.13            | 3.0 MB    | ███████████████████████████████████ | 100%
   grpcio-1.46.3        | 2.2 MB    | ███████████████████████████████████ | 100%
   libprotobuf-3.19.6   | 2.0 MB    | ███████████████████████████████████ | 100%
   h5py-3.6.0           | 1.0 MB    | ███████████████████████████████████ | 100%
   libsqlite-3.44.2     | 796 KB    | ███████████████████████████████████ | 100%
   protobuf-3.19.6      | 303 KB    | ███████████████████████████████████ | 100%
   zlib-1.2.13          | 78 KB     | ███████████████████████████████████ | 100%
   libzlib-1.2.13       | 47 KB     | ███████████████████████████████████ | 100%
   liblapack-3.9.0      | 14 KB     | ███████████████████████████████████ | 100%
   libcblas-3.9.0       | 14 KB     | ███████████████████████████████████ | 100%
   python_abi-3.10      | 6 KB      | ███████████████████████████████████ | 100%
   tensorflow-deps-2.10 | 2 KB      | ███████████████████████████████████ | 100%
INFO     Installing tensorflow-metal<0.7.0,>=0.6.0
INFO     tensorflow-metal<0.7.0,>=0.6.0 not available in Conda. Installing with pip
INFO     Installing tensorflow-metal<0.7.0,>=0.6.0
WARNING  Couldn't install tensorflow-metal<0.7.0,>=0.6.0 with pip. Please install this package manually
INFO     Installing decorator
INFO     decorator not available in Conda. Installing with pip
INFO     Installing decorator
WARNING  Couldn't install decorator with pip. Please install this package manually
INFO     Installing cloudpickle
INFO     cloudpickle not available in Conda. Installing with pip
INFO     Installing cloudpickle
WARNING  Couldn't install cloudpickle with pip. Please install this package manually
ERROR    Some packages failed to install. This may be a temporary error which might be fixed by re-running this script. Otherwise please install these packages manually.
INFO    Faceswap installation is complete!
INFO    You should close the terminal before proceeding
INFO    You can launch Faceswap from the icon on your desktop
```

</p>
</details>",saw official installer script maybe problem idea run pip install even correct command summary full installation welcome installer get setup need gather information would like accept default hit key option opportunity review prior install important make sure user full select press continue setup installation install enter location otherwise given location please specify location default executable added path easier run directly already install probably enable otherwise fine add executable path inside environment environment already name please specify name default given location folder location specify please specify location default run apple silicon compatible make sure date please select version wish install select apple silicon default post installation environment running installer simplify application launcher file launch straight create launcher review install please review selected installation proceeding added path environment application launcher wish continue yes base environment transaction done transaction done installation finished path change change change change change change change change change change change take effect close current shell virtual environment platform package working done environment working done package plan environment location added spec following package build total following new pip python wheel transaction working done transaction working done transaction working done remote done remote counting done remote done remote total delta delta mib done done setting see import running without tool installation python setup python bit running running virtual environment pip written package python may take time may take time git available pip pillow available pip available pip warning could install pip please install package manually decorator decorator available pip decorator warning could install decorator pip please install package manually available pip warning could install pip please install package manually error install may temporary error might fixed script otherwise please install manually installation complete close terminal proceeding launch icon,issue,positive,positive,positive,positive,positive,positive
1888619217,I tried reinstalling tensorflow but I'm not familiar with Python and pip so I'm not sure if it reinstalled correctly. Either way it did not work after installing tensorflow-gpu,tried familiar python pip sure correctly either way work,issue,negative,positive,positive,positive,positive,positive
1868210920,"Thanks for response.

Then, Can I train model for general person face swap?
Please let me know How Can I make trained model.

Thanks!",thanks response train model general person face swap please let know make trained model thanks,issue,positive,positive,positive,positive,positive,positive
1867639665,"No there is not. Faceswap models can only be trained on 2 specific identities so providing pre-trained models would be of limited use.

It is fine to use Faceswap for commercial purposes (assuming you are just talking about the output). Any use of the code in a product is covered by [our license](https://github.com/deepfakes/faceswap/blob/master/LICENSE)",trained specific providing would limited use fine use commercial assuming talking output use code product covered license,issue,negative,positive,neutral,neutral,positive,positive
1866814129,"This isn't a bug. This is you choosing to install an unsupported version of Python and then complaining when the app won't run in the unsupported version of Python.

Use the installer and/or learn how virtual environments work and you won't have this problem.",bug choosing install unsupported version python wo run unsupported version python use installer learn virtual work wo problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1862656315,"Manually installing Cuda is rarely the correct course of action.... Most likely this issue is caused by system conflicts.

See here:
https://forum.faceswap.dev/app.php/faqpage?sid=7fc24223c108f5c54472b7a1db812bec#f1r1


And if it doesn't solve your issue, then see here for the information that needs to be provided when reporting an issue:
https://forum.faceswap.dev/app.php/rules#rule-4a
https://forum.faceswap.dev/app.php/rules#rule-4b
",manually rarely correct course action likely issue system see solve issue see information need provided issue,issue,negative,positive,positive,positive,positive,positive
1862471232,"> Need to manually install cuda

May I know what's your means of manually install cuda? I have the same issue with you",need manually install may know manually install issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1838650386,"This is an issue with Faceswap talking to DirectX to get information about your GPU. Specifically it is failing to obtain information about available VRAM.

This is, unfortunately, most likely an issue within your setup (possible driver issue?). You can try following these steps to remedy:

https://forum.faceswap.dev/app.php/faqpage#f1r1
",issue talking get information specifically failing obtain information available unfortunately likely issue within setup possible driver issue try following remedy,issue,negative,positive,neutral,neutral,positive,positive
1831934853,"The jobs are explicitly excluded as per the notes in https://github.com/deepfakes/faceswap/blob/master/.github/workflows/pytest.yml

```yaml
# These backends will fail as GPU drivers not available
if: matrix.backend != 'rocm' && matrix.backend != 'nvidia' && matrix.backend != 'directml'
run: |
  FACESWAP_BACKEND=""${{ matrix.backend }}"" py.test -v tests/;
- name: End to End Tests
# These backends will fail as GPU drivers not available
# macOS fails on first extract test with 'died with <Signals.SIGSEGV: 11>'
if: matrix.backend != 'rocm' && matrix.backend != 'nvidia' && matrix.backend != 'directml' && matrix.os != 'macos-latest'        
```

If you are serious about improving the coverage of tests within the faceswap process, rather than just looking to shill another project, then we would very much welcome PRs that introduce more unit-tests, or look to resolve the above noted issues.

Please open a new issue/PR if you wish to contribute. This issue is closed as the problem disclosed is already known and documented.",explicitly per fail available run name end end fail available first extract test serious improving coverage within process rather looking shill another project would much welcome introduce look resolve noted please open new wish contribute issue closed problem disclosed already known,issue,negative,positive,neutral,neutral,positive,positive
1779555034,"> *Note: For general usage questions and help, please use either our [FaceSwap Forum](https://faceswap.dev/forum) 
or [FaceSwap Discord server](https://discord.gg/FC54sYg). General usage questions are liable to be closed without
response.*
",note general usage help please use either forum discord server general usage liable closed without response,issue,negative,negative,neutral,neutral,negative,negative
1774242657,This looks like an issue with DirectML communicating with your GPU. Make sure your drivers are up to date.,like issue communicating make sure date,issue,positive,positive,positive,positive,positive,positive
1774241897,"There is no way near enough information here to even begin to understand your problem.

Either way, the Github issues are for bugs in code, and not for general usage support. For that use our [Discord](https://discord.gg/FC54sYg) or our [Forum](https://forum.faceswap.dev/index.php)",way near enough information even begin understand problem either way code general usage support use discord forum,issue,negative,positive,neutral,neutral,positive,positive
1774240870,"You do not give enough information here about the version of Faceswap you are using. I have to take a guess an assume ROCm.

Either way (and assuming that you are using ROCm) then the issue is clearly stated in your error report:
The supported AMDGPU versions are gfx1030, gfx900, gfx906, gfx908, gfx90a

You would need to take this up with the ROCm developers.",give enough information version take guess assume either way assuming issue clearly stated error report would need take,issue,negative,positive,neutral,neutral,positive,positive
1774239999,"Then you are doing something wrong. 

You do not provide anyway near enough information to diagnose the issue. This is also an issue with your setup and not with faceswap.

See here for more remedial methods:
https://forum.faceswap.dev/app.php/faqpage?sid=c6e8313d10e2337cd3f53f966ec88875#f1r1",something wrong provide anyway near enough information diagnose issue also issue setup see remedial,issue,negative,negative,negative,negative,negative,negative
1774239499,"This is an out of memory error, as clearly stated in the error report. Get a bigger GPU or use a smaller model, or follow one of these remedial steps:

https://forum.faceswap.dev/app.php/faqpage?sid=c6e8313d10e2337cd3f53f966ec88875#f3r9

Either way, this is not a bug.",memory error clearly stated error report get bigger use smaller model follow one remedial either way bug,issue,negative,positive,neutral,neutral,positive,positive
1774238944,"This is not a bug. You do not have enough VRAM to continue, as stated clearly, along with remedial steps, in your screengrab",bug enough continue stated clearly along remedial,issue,negative,positive,neutral,neutral,positive,positive
1722905274,"This is not a support forum, it is for issues with the code. If you require support please use our [forum](https://forum.faceswap.dev/) or our [Discord](https://discord.gg/FC54sYg)",support forum code require support please use forum discord,issue,positive,neutral,neutral,neutral,neutral,neutral
1722903043,ok thx.....Can you please give me any tips on how to start open source contributions and how to read large codebases. I tried to find answers online but didnt get any satisfactory answers?,please give start open source read large tried find didnt get satisfactory,issue,negative,positive,positive,positive,positive,positive
1722900440,"Install a new version of Python or, even easier, use our installer in https://github.com/deepfakes/faceswap/releases/latest as it handles all of this for you",install new version python even easier use installer,issue,negative,positive,positive,positive,positive,positive
1722892273,"You are using the wrong minimum Python version.

Minimum is 3.10",wrong minimum python version minimum,issue,negative,negative,negative,negative,negative,negative
1722780563,"please use just.... (_EXCLUDE_DEVICES  = []) or (_EXCLUDE_DEVICES: List[int] = []) instead. I am new to open source so please pardon if its now the right way to contribute... for the second (from typing import List).
Please tell me if it works or not.",please use list instead new open source please pardon right way contribute second import list please tell work,issue,positive,positive,positive,positive,positive,positive
1694405133,"Please, please, please read our faqs and the forums rather than using github as you personal support platform.
https://forum.faceswap.dev/app.php/faqpage?sid=9d5c723510161f1f6c556b1054a6f7ff
",please please please read rather personal support platform,issue,positive,neutral,neutral,neutral,neutral,neutral
1692968708,"> It's most likely an internet connection issue. You can just download and install miniconda separately from here:
> 
> https://docs.conda.io/en/latest/miniconda.html
> 
> Also, you are best of posting (and searching) for these kind of problems on our website: https://forum.faceswap.dev/index.php?sid=5dd29bc3fc8162a0b2107f78c4a01923 as support is provided there.
> 
> Github issues is more for software bugs/improvements

thanks，i don't know why,but when i install the conda in the website,it just work,on my win10 equipment don't need to do this.but on my win11 equipment,i have to do,it is not the connection issues,because i can install the whole miniconda on your exe.but i cannot use your exe to add to local.greatly thanks",likely connection issue install separately also best posting searching kind support provided know install work win equipment need win equipment connection install whole use add thanks,issue,positive,positive,positive,positive,positive,positive
1692946559,"It's most likely an internet connection issue. You can just download and install miniconda separately from here: 

https://docs.conda.io/en/latest/miniconda.html

Also, you are best of posting (and searching) for these kind of problems on our website: https://forum.faceswap.dev/index.php?sid=5dd29bc3fc8162a0b2107f78c4a01923 as support is provided there.

Github issues is more for software bugs/improvements",likely connection issue install separately also best posting searching kind support provided,issue,positive,positive,positive,positive,positive,positive
1690824876,"Even on a modern, high powered x86_64 processor, training would take so long as to not be worth it. You really need a GPU (Nvidia or AMD) with at least 4GB of VRAM to even start thinking about training a model.

This is not a limitation of Faceswap, it's just the way that Machine Learning works. Faceswap models are quite large so it is not feasible to train them without a GPU.",even modern high powered processor training would take long worth really need least even start thinking training model limitation way machine learning work quite large feasible train without,issue,negative,positive,positive,positive,positive,positive
1690822092,"> Because you need a decently powered GPU, which the Orange Pi Zero does not have, and Tensorflow requires an x86_64 processor (or an Apple M1/2 processor), whilst the Orange Pi Zero has an Arm64 processor.

thanks,so if i choose cpu to train,it still cannot work successfully,right?what i have to do is to use my own computer?",need decently powered orange pi zero processor apple processor whilst orange pi zero arm processor thanks choose train still work successfully right use computer,issue,positive,positive,positive,positive,positive,positive
1690820565,"Because you need a decently powered GPU, which the Orange Pi Zero does not have, and Tensorflow requires an x86_64 processor (or an Apple M1/2 processor), whilst the Orange Pi Zero has an Arm64 processor.
",need decently powered orange pi zero processor apple processor whilst orange pi zero arm processor,issue,negative,positive,positive,positive,positive,positive
1690815927,"Please provide the file `faceswap_setup.log` from your faceswap folder.

And if you are actually running this on an orange pi zero, then you have zero chance of getting this to work.",please provide file folder actually running orange pi zero zero chance getting work,issue,positive,neutral,neutral,neutral,neutral,neutral
1667461373,"You are having some kind of connection error connecting to git. This could be a proxy or port issue, but I can't really help you beyond that as it is outside of the scope of the project.

You will need to try to solve the issue with your connection:
https://www.google.com/search?q=fatal%253A+unable+to+access+Recv+failure%253A+Connection+was+reset

Alternatively you can try a manual install:
https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#manual-install",kind connection error git could proxy port issue ca really help beyond outside scope project need try solve issue connection alternatively try manual install,issue,positive,positive,positive,positive,positive,positive
1667071998,"**Is it related to the Python 3.11 I installed in advance**  Here is the complete error code

```
(check) MiniConda installed: conda 23.7.2
(check) CPU Supports AVX Instructions
(check) CPU Supports SSE4 Instructions
(check) Completed check for installed applications
(check) Setting up for: nvidia

Miniconda3 installed.
Initializing Conda...
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done
# All requested packages already installed.
Creating Conda Virtual Environment...
Removing existing Conda Virtual Environment...
Remove all packages in environment C:\Users\Administrator\MiniConda3\envs\faceswap:
Deleting stale Conda Virtual Environment files...
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\bin\ffi.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\bin\libbz2.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\bin\liblzma.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\bin\libssl-3-x64.dll.conda_trash
Remove folder: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\bin\
Remove folder: C:\Users\Administrator\Miniconda3\envs\faceswap\Library\
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\msvcp140.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\vcruntime140.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\vcruntime140_1.dll.conda_trash
Delete file: C:\Users\Administrator\Miniconda3\envs\faceswap\zlib.dll.conda_trash
Remove folder: C:\Users\Administrator\Miniconda3\envs\faceswap\
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done
## Package Plan ##
  environment location: C:\Users\Administrator\MiniConda3\envs\faceswap
  added / updated specs:
    - python=3.10
The following NEW packages will be INSTALLED:
  bzip2              pkgs/main/win-64::bzip2-1.0.8-he774522_0 
  ca-certificates    pkgs/main/win-64::ca-certificates-2023.05.30-haa95532_0 
  libffi             pkgs/main/win-64::libffi-3.4.4-hd77b12b_0 
  openssl            pkgs/main/win-64::openssl-3.0.10-h2bbff1b_0 
  pip                pkgs/main/win-64::pip-23.2.1-py310haa95532_0 
  python             pkgs/main/win-64::python-3.10.12-he1021f5_0 
  setuptools         pkgs/main/win-64::setuptools-68.0.0-py310haa95532_0 
  sqlite             pkgs/main/win-64::sqlite-3.41.2-h2bbff1b_0 
  tk                 pkgs/main/win-64::tk-8.6.12-h2bbff1b_0 
  tzdata             pkgs/main/noarch::tzdata-2023c-h04d1e81_0 
  vc                 pkgs/main/win-64::vc-14.2-h21ff451_1 
  vs2015_runtime     pkgs/main/win-64::vs2015_runtime-14.27.29016-h5e58377_2 
  wheel              pkgs/main/win-64::wheel-0.38.4-py310haa95532_0 
  xz                 pkgs/main/win-64::xz-5.4.2-h8cc25b3_0 
  zlib               pkgs/main/win-64::zlib-1.2.13-h8cc25b3_0 
Downloading and Extracting Packages
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
#
# To activate this environment, use
#
#     $ conda activate faceswap
#
# To deactivate an active environment, use
#
#     $ conda deactivate
Installing Git...
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done
## Package Plan ##
  environment location: C:\Users\Administrator\MiniConda3\envs\faceswap
  added / updated specs:
    - git
The following NEW packages will be INSTALLED:
  git                pkgs/main/win-64::git-2.40.1-haa95532_1 
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
Downloading Faceswap...
Cloning into 'C:\Users\Administrator\faceswap'...
fatal: unable to access 'https://github.com/deepfakes/faceswap.git/': Recv failure: Connection was reset
Error Downloading Faceswap
Install Aborted
```",related python advance complete error code check check check check check check setting package working done environment working done already virtual environment removing virtual environment remove environment stale virtual environment delete file delete file delete file delete file remove folder remove folder delete file delete file delete file delete file remove folder package working done environment working done package plan environment location added spec following new pip python wheel transaction working done transaction working done transaction working done activate environment use activate deactivate active environment use deactivate git package working done environment working done package plan environment location added spec git following new git transaction working done transaction working done transaction working done fatal unable access failure connection reset error install aborted,issue,negative,negative,negative,negative,negative,negative
1666885866,"I need the full error text. Right click on the text window in the installer, hit ""copy"" and paste here",need full error text right click text window installer hit copy paste,issue,negative,positive,positive,positive,positive,positive
1664259157,"Yes.

However, this area is for issues and bugs with the software, it is not a support forum.

Please see our FAQs at:
https://forum.faceswap.dev/app.php/faqpage?sid=896912e96449945d0960adc4c964e05b

and guides at:
https://forum.faceswap.dev/app.php/tag/Guide",yes however area support forum please see,issue,positive,neutral,neutral,neutral,neutral,neutral
1661155157,"@torzdf 
I personally do **NOT** like **conda**, although many years ago, I advocated it.
I noticed in [setup.py](https://github.com/deepfakes/faceswap/blob/master/setup.py), we absolutely can work without **conda**, which is also my preference. 

Anyway, Thank you for your prompt reply.... I'll try to figure it out by myself. 
",personally like although many ago absolutely work without also preference anyway thank prompt reply try figure,issue,positive,positive,positive,positive,positive,positive
1661141750,"Most likely a broken virtual environment. Unfortunately troubleshooting non-standard installs is beyond the scope of this project. The general advice I give is [this](https://forum.faceswap.dev/app.php/faqpage#f1r1), as it solves 99% of problems:
https://forum.faceswap.dev/app.php/faqpage#f1r1


fwiw, running your *exact* command results in this on a successful install:
```
(faceswap) $  python faceswap.py extract -i ./data -o ./output
Setting Faceswap backend to NVIDIA
08/01/2023 22:39:13 INFO     Log level set to: INFO
08/01/2023 22:39:14 INFO     Loading Detect from S3Fd plugin...
08/01/2023 22:39:14 INFO     Loading Align from Fan plugin...
08/01/2023 22:39:14 INFO     Loading Mask from Components plugin...
08/01/2023 22:39:14 INFO     Loading Mask from Extended plugin...
08/01/2023 22:39:14 WARNING  Not enough free VRAM for parallel processing. Switching to serial
08/01/2023 22:39:14 INFO     Reset batch sizes due to available VRAM: Detect: 1
08/01/2023 22:39:14 INFO     Starting, this may take a while...
08/01/2023 22:39:14 INFO     Output Directory: /mnt/Data/git/faceswap/output
08/01/2023 22:39:14 ERROR    The location '/mnt/Data/git/faceswap/data' does not exist
```",likely broken virtual environment unfortunately beyond scope project general advice give running exact command successful install python extract setting log level set loading detect loading align fan loading mask loading mask extended warning enough free parallel switching serial reset batch size due available detect starting may take output directory error location exist,issue,negative,positive,neutral,neutral,positive,positive
1661104761,"@torzdf 
Thank you... I found out a dirty way to handle this particular **tensorflow**, but not a generalized solution.

Thank you anyway... ",thank found dirty way handle particular generalized solution thank anyway,issue,positive,negative,negative,negative,negative,negative
1661089489,"Sure.

But you're talking about a manually installed Tensorflow wheel which is not officially supported by Faceswap, so it's kinda edge case. If you have got to the point that you can get Faceswap to run with an unsupported version of Tensorflow, then you're probably at the point where you can also code around this issue, no?

You're welcome to PR a solution that catches and handles any matching manually installed wheels though.",sure talking manually wheel officially edge case got point get run unsupported version probably point also code around issue welcome solution matching manually though,issue,positive,positive,positive,positive,positive,positive
1642746463,"Zero context. Zero information. Completely ignores the issue requirements.

Bad install. Cleanup and install properly.

https://forum.faceswap.dev/app.php/faqpage#f1r1",zero context zero information completely issue bad install cleanup install properly,issue,negative,negative,negative,negative,negative,negative
1637055092,Closing as should be fixed by python update + new install script,fixed python update new install script,issue,negative,positive,positive,positive,positive,positive
1622072656,"tf probability has been removed as a requirement, so this issue should no longer occur",probability removed requirement issue longer occur,issue,negative,neutral,neutral,neutral,neutral,neutral
1621896359,"yep, that worked. removed the dll from system32 and ran the conda install steps above and training kicked in nicely.

also since the upgrade i see a noticable speed increase. getting ~15% higher EG/s ",yep worked removed system ran install training nicely also since upgrade see speed increase getting higher,issue,positive,positive,positive,positive,positive,positive
1621789816,"Yeah. This seems like an issue on some Windows systems. I did a clean Nvidia install on a clean WIndows 11 machine, and it ran fine, so can't recreate.

For others who hit the issue, you could try the following, and let me know if it resolves your issue? If it does, I will look to build this into the install process.

Start > Anaconda prompt (cmd)
```
conda activate faceswap
conda install -c conda-forge -y zlib-wapi
```
Close the window when it has finished installing and relaunch faceswap",yeah like issue clean install clean machine ran fine ca recreate hit issue could try following let know issue look build install process start anaconda prompt activate install close window finished relaunch,issue,positive,positive,positive,positive,positive,positive
1621784963,"I installed the missing dll manually to my system32... not sure if it is the proper fix but now everything works with latest release.
",missing manually system sure proper fix everything work latest release,issue,negative,positive,positive,positive,positive,positive
1620731400,"zlibwapi is part of cuDNN as far as I'm aware.  Given the error you put in the first error message, and now this issue, I would say your system is most likely in a mess, which may not be easily fixable.

In the meantime, please provide the following:
https://forum.faceswap.dev/app.php/rules?sid=f366e01a18f86fa4adb034a10af65bd9#rule-4b",part far aware given error put first error message issue would say system likely mess may easily fixable please provide following,issue,negative,positive,positive,positive,positive,positive
1620649264,"Followed steps on forum to scrub system of all faceswap/conda/python and got latest installer. Fixed running faceswap.

However now get runtime issue: Could not locate zlibwapi.dll. Please make sure it is in your library path!",forum scrub system got latest installer fixed running however get issue could locate please make sure library path,issue,positive,positive,positive,positive,positive,positive
1615152040,"Unsupported Python version.
Unsupported command line switches.
See install guide here:
https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#linux-and-windows-install-guide

There was an ordering bug which I have just fixed.

If still issues, please post the exact steps to reproduce.",unsupported python version unsupported command line see install guide bug fixed still please post exact reproduce,issue,negative,positive,positive,positive,positive,positive
1609702278,"You will need to remove your environment and re-install Faceswap as per the updated instructions here: https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#macos-apple-silicon-install-guide

The lowest supported version of Python has been updated to 3.10",need remove environment per version python,issue,negative,neutral,neutral,neutral,neutral,neutral
1595710576,Merging as codepage issue is not recreatable and config is now explicitly saved and loaded in utf-8,issue explicitly saved loaded,issue,negative,neutral,neutral,neutral,neutral,neutral
1593148829,"No need. It's possible to add it to the batch file that starts Faceswap, so it'll apply only to the command prompt. I haven't really tested that though, but it may work. That may mean changing the way the installer is creating the batch file a tiny bit... 

Somehow, that doesn't even work... But forcing UTF-8 in the entire system does. I don't think it's that much of a hassle to enable though... Just hidden somewhat well. But since this is just 1 checkmark that needs to be enabled, it shouldn't be _too_ annoying...",need possible add batch file apply command prompt really tested though may work may mean way installer batch file tiny bit somehow even work forcing entire system think much hassle enable though hidden somewhat well since need annoying,issue,negative,negative,negative,negative,negative,negative
1593009336,"So, is this something a user needs to do for locales to work in the .ini files? If so, then I think we'll need to scrap locales for ini files. It's annoying, but it becomes a support headache.",something user need work think need scrap annoying becomes support headache,issue,negative,negative,negative,negative,negative,negative
1591236646,"I've discovered something rather too weird...

Linux encodings will ALWAYS be UTF-8(and I bet you can change it). But Windows is special. It can come up with whatever code page it wants. But UTF-8 _probably_ won't be one of them. But we can fix that.

The reason not so many people know about it is because Microsoft is hiding such unknown or ""beta"" settings deep in the legacy menus(from Windows XP era, or maybe even older)

""So, I'm getting UnicodeDecodeError's when using your locale. What's wrong?""

Because Faceswap fails to generate config files. And the reason behind that is the wrong encoding.
Sure, the recent update forced UTF-8 encoding, but Windows doesn't seem to comply... How do we fix this?

- Run ""Run"" by pressing ""Win + R"" and then type ""intl.cpl"" in there, which will throw us in the legacy Region settings.

- Then we need to find ""Administrative"" and press ""Change system locale"" there.

- On the next window, you'll see a checkmark saying ""Beta: Use Unicode ITF-8 for worldwide language support"" and you'll need to click that and then apply the settings.

- Reboot the system afterwards.

Or...
We can force the Command Prompt's code page to change.

- Open the Command Prompt

- type ""chcp 65001""

- Run Faceswap.

Why is the encoding **not** UTF-8 in Windows? No one really knows... But at least we found the fix.

(_god i've spent so much time working on a fix..._)",discovered something rather weird always bet change special come whatever code page wo one fix reason many people know unknown beta deep legacy era maybe even older getting locale wrong generate reason behind wrong sure recent update forced seem comply fix run run pressing win type throw u legacy region need find administrative press change system locale next window see saying beta use language support need click apply system afterwards force command prompt code page change open command prompt type run one really least found fix spent much time working fix,issue,negative,negative,neutral,neutral,negative,negative
1580447929,"TBH, I'm not sure why tf-probability would be looking to access tf.contrib. Annoyingly, we only import it for 1 function, but the code we use from there is quite involved, which is why I haven't just manually brought the module in. I may revisit this at some point.",sure would looking access annoyingly import function code use quite involved manually brought module may revisit point,issue,negative,negative,negative,negative,negative,negative
1580434169,"I installed using anaconda virtual environment and git (both cuda and cudaa have been installed), but some packages were missing during the installation process. I used pip for installation. During this period, there were some package version conflicts that were fortunately resolved. I will follow your prompts to solve the problem. Thank you for answering my question during your busy schedule.",anaconda virtual environment git missing installation process used pip installation period package version fortunately resolved follow solve problem thank question busy schedule,issue,negative,positive,positive,positive,positive,positive
1580401750,"First thing I would suggest is to update Faceswap. There was an issue with locales not displaying correctly in Windows, which I fixed yesterday. This may solve your issue.
",first thing would suggest update issue correctly fixed yesterday may solve issue,issue,negative,positive,positive,positive,positive,positive
1580395573,"Ok, this is a weird issue that I haven't seen before, and is related to tensorflow-probability rather than tensorflow itself. Most likely a version conflict somewhere.

How did you install Faceswap? The quickest and easiest fix I can suggest is to remove your environment and re-install through the installer.",weird issue seen related rather likely version conflict somewhere install easiest fix suggest remove environment installer,issue,negative,negative,negative,negative,negative,negative
1579966629,"@torzdf Brother, looking forward to your reply",brother looking forward reply,issue,negative,neutral,neutral,neutral,neutral,neutral
1577747636,"@torzdf   https://github.com/long369486562/faceswap/tree/zh-cn-locales/locales
I'm not sure I'm doing it right, but can make the code you see to implement",sure right make code see implement,issue,negative,positive,positive,positive,positive,positive
1576650022,"Sure, have a look here:
https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request

It may seem intimidating at first, but it really isn't too difficult. Once done, I can checkout and review the code, and we can merge your translations in to the main project, which would be very useful for Chinese users (and you would become a contributor)",sure look may seem first really difficult done review code merge main project would useful would become contributor,issue,negative,positive,positive,positive,positive,positive
1575904493,"@torzdf Sorry, I can only simply use GITHUB, I don't fully understand what you mean, can you elaborate on that?",sorry simply use fully understand mean elaborate,issue,negative,negative,neutral,neutral,negative,negative
1575895849,"> @andentze @torzdf Can you give some tips on how to solve the problem I raised?

Raise it as a PR and I can take a look",give solve problem raised raise take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1575894332,@andentze @torzdf Can you give some tips on how to solve the problem I raised?,give solve problem raised,issue,negative,neutral,neutral,neutral,neutral,neutral
1508188062,"the complete error reporting as follow：
``
Setting Faceswap backend to DIRECTML
Traceback (most recent call last):
  File ""H:\profess_L\faceswap\faceswap.py"", line 6, in <module>
    from lib.cli import args as cli_args
  File ""H:\profess_L\faceswap\lib\cli\args.py"", line 24, in <module>
    _GPUS = GPUStats().cli_devices
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 489, in __init__
    super().__init__(log=log)
  File ""H:\profess_L\faceswap\lib\gpu_stats\_base.py"", line 96, in __init__
    self._initialize()
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 545, in _initialize
    self._devices = self._get_devices()
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 528, in _get_devices
    adapters = Adapters(log_func=self._log)
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 315, in __init__
    self._devices = self._process_adapters()
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 468, in _process_adapters
    is_d3d12 = self._test_d3d12(adapter)
  File ""H:\profess_L\faceswap\lib\gpu_stats\directml.py"", line 428, in _test_d3d12
    success = factory_func(adapter,
OSError: exception: access violation writing 0x00007FFD6187A3E4
``",complete error setting recent call last file line module import file line module file line super file line file line file line file line file line adapter file line success adapter exception access violation writing,issue,negative,positive,positive,positive,positive,positive
1501651411,"This already exists. It's the ""Extract Every N"" option.

You should follow the guides as it covers all this kind of stuff:
https://forum.faceswap.dev/app.php/tag/Guide?sid=af4d6d7c7bf7ccb54f305193d0d84ee7",already extract every option follow kind stuff,issue,positive,positive,positive,positive,positive,positive
1498971735,"Unfortunately we don not directly support Colab, especially since Google blocks the use of our software on Colab.",unfortunately directly support especially since use,issue,negative,positive,neutral,neutral,positive,positive
1498970519,"Yes. For a while now.

2.8-2.10 are currently supported (this will change in future)",yes currently change future,issue,negative,neutral,neutral,neutral,neutral,neutral
1498970054,Not sure what you are asking. The latest installer will always install the latest code.,sure latest installer always install latest code,issue,negative,positive,positive,positive,positive,positive
1498969405,Not sure what you are proposing here. This appears to be a statement rather than a specific issue.,sure statement rather specific issue,issue,negative,positive,positive,positive,positive,positive
1498968648,"> How would I apply this? I followed the directions on Patreon, but couldn't find the "".cache"" folder after ""mask"" to extract the zipped file. Would I have to extract in the ""pycache"" folder?
> 
> And is it automatically applied in Faceswap or do I need to uploaded it or select an option for it? TIA!

No need to add anything to the .cache folder. Patreons got this mask well ahead of time as a perk for membership, but it has long been rolled into the main Faceswap branch. Probably best to delete any files you added to .cache, in case I have made any model updates since then (I honestly can't remember).

You can select the mask either in extract or the mask tool (bisenet-fp). You can configure how the mask works (what it masks) in Settings > Extract > Mask > Bisenet-FP.

You can select the bisenet-fp mask for training in Settings > Train > Loss > Mask Type",would apply could find folder mask extract file would extract folder automatically applied need select option need add anything folder got mask well ahead time perk membership long rolled main branch probably best delete added case made model since honestly ca remember select mask either extract mask tool configure mask work extract mask select mask training train loss mask type,issue,positive,positive,positive,positive,positive,positive
1493693290,"How would I apply this? I followed the directions on Patreon, but couldn't find the "".cache"" folder after ""mask"" to extract the zipped file. Would I have to extract in the ""pycache"" folder?

And is it automatically applied in Faceswap or do I need to uploaded it or select an option for it? TIA!",would apply could find folder mask extract file would extract folder automatically applied need select option,issue,negative,neutral,neutral,neutral,neutral,neutral
1481780226,"Is there an updated command. `conda install ""numpy>=1.23.0,<1.24.0""` results in [this](https://gist.github.com/ashleyconnor/23fdb619124c85c5824eb32e8a0437ab) for me.

My conda list output for numpy matches OPs issue.

### Edit

Resolved with

```shell
conda activate faceswap
pip install --upgrade numpy
pip install chardet
```

Test with `python -c ""import tensorflow as tf""` or `python faceswap.py -h`.",command install list output issue edit resolved shell activate pip install upgrade pip install test python import python,issue,negative,neutral,neutral,neutral,neutral,neutral
1448183895,"There is no ready made executable for any OS. Faceswap is a Python application. There are installers for Linux and Windows which set everything up for you, but there is not one for MacOS as I do not own a Mac.

However, setting up in MacOS is fairly straightforward:
https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#macos-apple-silicon-install-guide
",ready made executable o python application set everything one mac however setting fairly straightforward,issue,negative,positive,positive,positive,positive,positive
1448158537,Is there a ready made Mac OS executable?,ready made mac o executable,issue,negative,positive,positive,positive,positive,positive
1407550151,"This bug was fixed in a more recent update. Please update faceswap.

Also, you should uninstall your globally installed Cuda, as it will most likely cause you issues.",bug fixed recent update please update also globally likely cause,issue,negative,positive,neutral,neutral,positive,positive
1407549819,"You are not training on faceswap extracted faces. Use faceswap extracted faces.

Guides here:
https://forum.faceswap.dev/app.php/tag/Guide",training extracted use extracted,issue,negative,neutral,neutral,neutral,neutral,neutral
1407549612,"Network connection issue. Nothing I can do about that.

Try this if still issues, or install from a more stable internet connection:
https://forum.faceswap.dev/app.php/faqpage#f1r1",network connection issue nothing try still install stable connection,issue,negative,neutral,neutral,neutral,neutral,neutral
1398361792,"Yes, but it will take just as long. Process is the same

https://forum.faceswap.dev/app.php/faqpage#f0r6",yes take long process,issue,negative,negative,neutral,neutral,negative,negative
1398360772,"This is an installed numpy version issue.

Try opening a terminal and entering
```
conda activate faceswap
conda install ""numpy>=1.23.0,<1.24.0""
```",version issue try opening terminal entering activate install,issue,negative,neutral,neutral,neutral,neutral,neutral
1398355576,"Ok, I think this is to do with a tensorflow-metal version incompatibility. See here for potential fix:

https://forum.faceswap.dev/viewtopic.php?f=6&t=2449&p=8389#p8389",think version incompatibility see potential fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1398353909,"Have not seen this before. Are you definitely looking in the correct place (the alignments file will be stored next to the source video).

If you continue to have issues, this might be better discussed/resolved on our [discord server](https://discord.gg/FC54sYg)",seen definitely looking correct place file next source video continue might better discord server,issue,negative,positive,positive,positive,positive,positive
1398352151,"What GPU are you using?

Either your GPU is too old to be supported, or you need to update the drivers for it. If the latter, then I suggest using [DDU](https://www.guru3d.com/files-details/display-driver-uninstaller-download.html) to remove your drivers and then install the latest.


Closing this issue. Please open a new one if you continue to have problems.",either old need update latter suggest remove install latest issue please open new one continue,issue,negative,positive,positive,positive,positive,positive
1398349821,"Ok, firstly, training on CPU is so slow as to not be worth it. You have been warned. I would not recommend it!

However, if you do wish to proceed, please install the ""CPU"" version of Faceswap, not the ""AMD"" version.

This may just fix your issue. If it does not, however, and you get the same error message, then run open a terminal emulator and run these commands:
```
conda activate faceswap
pip install chardet
```
",firstly training slow worth would recommend however wish proceed please install version version may fix issue however get error message run open terminal emulator run activate pip install,issue,positive,positive,neutral,neutral,positive,positive
1396161816,"Thanks for this. Hugely appreciated. Sorry for the delay.

Merged.",thanks hugely sorry delay,issue,negative,negative,negative,negative,negative,negative
1381450530,I tried changing batch size in the GUI but nothing worked.,tried batch size nothing worked,issue,negative,neutral,neutral,neutral,neutral,neutral
1366793597,"I tried again to run on a folder with frames directly the file of alignments is well created but when I sort them then I realign I have a crash

```
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 662.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 663.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 664.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 665.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 666.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 667.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 668.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 669.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 67.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 670.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 671.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 672.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 673.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 674.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 675.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 676.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 677.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 678.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 679.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 68.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 680.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 681.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 682.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 683.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 684.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 685.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 686.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 687.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 688.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 689.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 69.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 690.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 691.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 692.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 693.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 694.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 695.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 696.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 697.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 698.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 699.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 7.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 70.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 700.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 701.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 702.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 703.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 704.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 705.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 706.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 707.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 708.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 709.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 71.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 710.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 711.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 712.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 713.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 714.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 715.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 716.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 72.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 73.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 74.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 75.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 76.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 77.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 78.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 79.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 797.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 798.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 799.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 8.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 80.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 800.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 801.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 81.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 82.png, index: 1)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 82.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 83.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 84.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 85.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 86.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 87.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 88.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 89.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 9.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 90.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 91.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 92.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 93.png, index: 1)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 93.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 94.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 95.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 96.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 97.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 98.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     alignments      filter_faces                   VERBOSE  Filtering out face: (filename: 99.png, index: 0)
12/28/2022 17:55:49 MainProcess     MainThread                     jobs_faces      process                        INFO     470 alignment(s) were removed from alignments file
12/28/2022 17:55:49 MainProcess     MainThread                     jobs_faces      _update_png_headers            DEBUG    Updating png header for '/home/cedric/faceswap/workspace/B/000815_001454_2068_1.png': face index from 1 to 0
Traceback (most recent call last):
  File ""/home/cedric/faceswap/lib/cli/launcher.py"", line 217, in execute_script
    process.process()
  File ""/home/cedric/faceswap/tools/alignments/alignments.py"", line 93, in process
    job.process()
  File ""/home/cedric/faceswap/tools/alignments/jobs_faces.py"", line 367, in process
    self._update_png_headers()
  File ""/home/cedric/faceswap/tools/alignments/jobs_faces.py"", line 405, in _update_png_headers
    face.from_alignment(self._alignments.get_faces_in_frame(frame)[new_index])
IndexError: list index out of range

============ System Information ============
encoding:            UTF-8
git_branch:          Sur la branche master
git_commits:         bcef3b4 Merge branch 'staging'
gpu_cuda:            10.1
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: NVIDIA GeForce RTX 3060 Laptop GPU
gpu_devices_active:  GPU_0
gpu_driver:          510.108.03
gpu_vram:            GPU_0: 6144MB
os_machine:          x86_64
os_platform:         Linux-5.15.0-56-generic-x86_64-with-glibc2.31
os_release:          5.15.0-56-generic
py_command:          /home/cedric/faceswap/tools.py alignments -j remove-faces -o console -a /home/cedric/faceswap/workspace/original/3684.fsa -fc /home/cedric/faceswap/workspace/B -een 1 -sz 512 -m 0 -L INFO -gui
py_conda_version:    conda 4.12.0
py_implementation:   CPython
py_version:          3.9.15
py_virtual_env:      True
sys_cores:           16
sys_processor:       x86_64
sys_ram:             Total: 15759MB, Available: 13532MB, Used: 1789MB, Free: 7821MB

=============== Pip Packages ===============
absl-py @ file:///croot/absl-py_1666362940888/work
astunparse==1.6.3
cachetools==5.2.0
certifi==2022.12.7
charset-normalizer==2.1.1
cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1632508026186/work
cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work
decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work
dm-tree @ file:///croot/dm-tree_1671027432897/work
fastcluster @ file:///home/conda/feedstock_root/build_artifacts/fastcluster_1649783242764/work
ffmpy==0.3.0
flatbuffers==22.12.6
flit_core @ file:///opt/conda/conda-bld/flit-core_1644941570762/work/source/flit_core
fonttools==4.25.0
gast==0.4.0
google-auth==2.15.0
google-auth-oauthlib==0.4.6
google-pasta==0.2.0
grpcio==1.51.1
h5py==3.7.0
idna==3.4
imageio @ file:///tmp/abs_cd920173-f360-47c5-97b0-bf4d1076d5d4dvic0oys/croots/recipe/imageio_1658785036907/work
imageio-ffmpeg @ file:///home/conda/feedstock_root/build_artifacts/imageio-ffmpeg_1649960641006/work
importlib-metadata==5.2.0
joblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work
keras==2.10.0
Keras-Preprocessing==1.1.2
kiwisolver @ file:///opt/conda/conda-bld/kiwisolver_1653292039266/work
libclang==14.0.6
Markdown==3.4.1
MarkupSafe==2.1.1
matplotlib @ file:///opt/conda/conda-bld/matplotlib-suite_1660167928326/work
mkl-fft==1.3.1
mkl-random @ file:///tmp/build/80754af9/mkl_random_1626186066731/work
mkl-service==2.4.0
munkres==1.1.4
numexpr @ file:///croot/numexpr_1668713893690/work
numpy @ file:///croot/numpy_and_numpy_base_1668593735768/work
nvidia-ml-py==11.515.75
oauthlib==3.2.2
opencv-python==4.6.0.66
opt-einsum==3.3.0
packaging @ file:///croot/packaging_1671697413597/work
pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work
Pillow==9.3.0
ply==3.11
protobuf==3.19.6
psutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work
ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl
pyasn1==0.4.8
pyasn1-modules==0.2.8
pyparsing @ file:///opt/conda/conda-bld/pyparsing_1661452539315/work
PyQt5-sip==12.11.0
python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work
requests==2.28.1
requests-oauthlib==1.3.1
rsa==4.9
scikit-learn @ file:///croot/scikit-learn_1667587546862/work
scipy==1.9.3
sip @ file:///tmp/abs_44cd77b_pu/croots/recipe/sip_1659012365470/work
six @ file:///tmp/build/80754af9/six_1644875935023/work
tensorboard==2.10.1
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow-estimator==2.10.0
tensorflow-gpu==2.10.1
tensorflow-io-gcs-filesystem==0.29.0
tensorflow-probability @ file:///tmp/build/80754af9/tensorflow-probability_1633017132682/work
termcolor==2.1.1
threadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work
toml @ file:///tmp/build/80754af9/toml_1616166611790/work
tornado @ file:///opt/conda/conda-bld/tornado_1662061693373/work
tqdm @ file:///opt/conda/conda-bld/tqdm_1664392687731/work
typing_extensions @ file:///croot/typing_extensions_1669924550328/work
urllib3==1.26.13
Werkzeug==2.2.2
wrapt==1.14.1
zipp==3.11.0

============== Conda Packages ==============
# packages in environment at /home/cedric/miniconda3/envs/faceswap:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_openmp_mutex             5.1                       1_gnu  
absl-py                   1.3.0            py39h06a4308_0  
astunparse                1.6.3                    pypi_0    pypi
blas                      1.0                         mkl  
brotli                    1.0.9                h5eee18b_7  
brotli-bin                1.0.9                h5eee18b_7  
bzip2                     1.0.8                h7b6447c_0  
c-ares                    1.18.1               h7f8727e_0  
ca-certificates           2022.12.7            ha878542_0    conda-forge
cachetools                5.2.0                    pypi_0    pypi
certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge
charset-normalizer        2.1.1                    pypi_0    pypi
cloudpickle               2.0.0              pyhd3eb1b0_0  
cudatoolkit               11.2.2              hbe64b41_10    conda-forge
cudnn                     8.1.0.77             h90431f1_0    conda-forge
curl                      7.86.0               h5eee18b_0  
cycler                    0.11.0             pyhd3eb1b0_0  
dbus                      1.13.18              hb2f20db_0  
decorator                 5.1.1              pyhd3eb1b0_0  
dm-tree                   0.1.7            py39h6a678d5_1  
expat                     2.4.9                h6a678d5_0  
fastcluster               1.2.6            py39h1832856_1    conda-forge
ffmpeg                    4.2.2                h20bf706_0  
ffmpy                     0.3.0                    pypi_0    pypi
fftw                      3.3.10          nompi_h77c792f_102    conda-forge
flatbuffers               22.12.6                  pypi_0    pypi
flit-core                 3.6.0              pyhd3eb1b0_0  
fontconfig                2.14.1               h52c9d5c_1  
fonttools                 4.25.0             pyhd3eb1b0_0  
freetype                  2.12.1               h4a9f257_0  
gast                      0.4.0                    pypi_0    pypi
gdbm                      1.18                 hd4cb3f1_4  
gettext                   0.21.0               hf68c758_0  
giflib                    5.2.1                h7b6447c_0  
git                       2.34.1          pl5262hc120c5b_0  
glib                      2.69.1               he621ea3_2  
gmp                       6.2.1                h58526e2_0    conda-forge
gnutls                    3.6.13               h85f3911_1    conda-forge
google-auth               2.15.0                   pypi_0    pypi
google-auth-oauthlib      0.4.6                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.51.1                   pypi_0    pypi
gst-plugins-base          1.14.0               h8213a91_2  
gstreamer                 1.14.0               h28cd5cc_2  
h5py                      3.7.0                    pypi_0    pypi
icu                       58.2                 he6710b0_3  
idna                      3.4                      pypi_0    pypi
imageio                   2.19.3           py39h06a4308_0  
imageio-ffmpeg            0.4.7              pyhd8ed1ab_0    conda-forge
importlib-metadata        5.2.0                    pypi_0    pypi
intel-openmp              2021.4.0          h06a4308_3561  
joblib                    1.2.0              pyhd8ed1ab_0    conda-forge
jpeg                      9e                   h7f8727e_0  
keras                     2.10.0                   pypi_0    pypi
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.4.2            py39h295c915_0  
krb5                      1.19.2               hac12032_0  
lame                      3.100             h7f98852_1001    conda-forge
lcms2                     2.12                 h3be6417_0  
ld_impl_linux-64          2.38                 h1181459_1  
lerc                      3.0                  h295c915_0  
libbrotlicommon           1.0.9                h5eee18b_7  
libbrotlidec              1.0.9                h5eee18b_7  
libbrotlienc              1.0.9                h5eee18b_7  
libclang                  14.0.6                   pypi_0    pypi
libcurl                   7.86.0               h91b91d3_0  
libdeflate                1.8                  h7f8727e_5  
libedit                   3.1.20221030         h5eee18b_0  
libev                     4.33                 h7f8727e_1  
libevent                  2.1.12               h8f2d780_0  
libffi                    3.4.2                h6a678d5_6  
libgcc-ng                 11.2.0               h1234567_1  
libgfortran-ng            12.2.0              h69a702a_19    conda-forge
libgfortran5              12.2.0              h337968e_19    conda-forge
libgomp                   11.2.0               h1234567_1  
libllvm10                 10.0.1               hbcb73fb_5  
libnghttp2                1.46.0               hce63b2e_0  
libopus                   1.3.1                h7f98852_1    conda-forge
libpng                    1.6.37               hbc83047_0  
libpq                     12.9                 h16c4e8d_3  
libssh2                   1.10.0               h8f2d780_0  
libstdcxx-ng              11.2.0               h1234567_1  
libtiff                   4.4.0                hecacb30_2  
libuuid                   1.41.5               h5eee18b_0  
libvpx                    1.7.0                h439df22_0  
libwebp                   1.2.4                h11a3e52_0  
libwebp-base              1.2.4                h5eee18b_0  
libxcb                    1.15                 h7f8727e_0  
libxkbcommon              1.0.1                hfa300c1_0  
libxml2                   2.9.14               h74e7548_0  
libxslt                   1.1.35               h4e12654_0  
lz4-c                     1.9.4                h6a678d5_0  
markdown                  3.4.1                    pypi_0    pypi
markupsafe                2.1.1                    pypi_0    pypi
matplotlib                3.5.2            py39h06a4308_0  
matplotlib-base           3.5.2            py39hf590b9c_0  
mkl                       2021.4.0           h06a4308_640  
mkl-service               2.4.0            py39h7f8727e_0  
mkl_fft                   1.3.1            py39hd3c417c_0  
mkl_random                1.2.2            py39h51133e4_0  
munkres                   1.1.4                      py_0  
ncurses                   6.3                  h5eee18b_3  
nettle                    3.6                  he412f7d_0    conda-forge
nspr                      4.33                 h295c915_0  
nss                       3.74                 h0370c37_0  
numexpr                   2.8.4            py39he184ba9_0  
numpy                     1.23.4           py39h14f4228_0  
numpy-base                1.23.4           py39h31eccc5_0  
nvidia-ml-py              11.515.75                pypi_0    pypi
oauthlib                  3.2.2                    pypi_0    pypi
opencv-python             4.6.0.66                 pypi_0    pypi
openh264                  2.1.1                h4ff587b_0  
openssl                   1.1.1s               h7f8727e_0  
opt-einsum                3.3.0                    pypi_0    pypi
packaging                 22.0             py39h06a4308_0  
pcre                      8.45                 h295c915_0  
pcre2                     10.37                he7ceb23_1  
perl                      5.34.0               h5eee18b_2  
pexpect                   4.8.0              pyhd3eb1b0_3  
pillow                    9.3.0            py39hace64e9_1  
pip                       22.3.1           py39h06a4308_0  
ply                       3.11             py39h06a4308_0  
protobuf                  3.19.6                   pypi_0    pypi
psutil                    5.9.0            py39h5eee18b_0  
ptyprocess                0.7.0              pyhd3eb1b0_2  
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pyparsing                 3.0.9            py39h06a4308_0  
pyqt                      5.15.7           py39h6a678d5_1  
pyqt5-sip                 12.11.0          py39h6a678d5_1  
python                    3.9.15               h7a1cb2a_2  
python-dateutil           2.8.2              pyhd3eb1b0_0  
python_abi                3.9                      2_cp39    conda-forge
qt-main                   5.15.2               h327a75a_7  
qt-webengine              5.15.9               hd2b0992_4  
qtwebkit                  5.212                h4eab89a_4  
readline                  8.2                  h5eee18b_0  
requests                  2.28.1                   pypi_0    pypi
requests-oauthlib         1.3.1                    pypi_0    pypi
rsa                       4.9                      pypi_0    pypi
scikit-learn              1.1.3            py39h6a678d5_0  
scipy                     1.9.3            py39h14f4228_0  
setuptools                65.5.0           py39h06a4308_0  
sip                       6.6.2            py39h6a678d5_0  
six                       1.16.0             pyhd3eb1b0_1  
sqlite                    3.40.0               h5082296_0  
tensorboard               2.10.1                   pypi_0    pypi
tensorboard-data-server   0.6.1                    pypi_0    pypi
tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
tensorflow-estimator      2.10.0                   pypi_0    pypi
tensorflow-gpu            2.10.1                   pypi_0    pypi
tensorflow-io-gcs-filesystem 0.29.0                   pypi_0    pypi
tensorflow-probability    0.14.0             pyhd3eb1b0_0  
termcolor                 2.1.1                    pypi_0    pypi
threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge
tk                        8.6.12               h1ccaba5_0  
toml                      0.10.2             pyhd3eb1b0_0  
tornado                   6.2              py39h5eee18b_0  
tqdm                      4.64.1           py39h06a4308_0  
typing-extensions         4.4.0            py39h06a4308_0  
typing_extensions         4.4.0            py39h06a4308_0  
tzdata                    2022g                h04d1e81_0  
urllib3                   1.26.13                  pypi_0    pypi
werkzeug                  2.2.2                    pypi_0    pypi
wheel                     0.37.1             pyhd3eb1b0_0  
wrapt                     1.14.1                   pypi_0    pypi
x264                      1!157.20191217       h7b6447c_0  
xz                        5.2.8                h5eee18b_0  
zipp                      3.11.0                   pypi_0    pypi
zlib                      1.2.13               h5eee18b_0  
zstd                      1.5.2                ha4553b6_0  

================= Configs ==================
--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.match_hist]
threshold:                99.0

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto
skip_mux:                 False

[writer.pillow]
format:                   png
draw_transparent:         False
separate_mask:            False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

[writer.opencv]
format:                   png
draw_transparent:         False
separate_mask:            False
jpg_quality:              75
png_compress_level:       3

[scaling.sharpen]
method:                   none
amount:                   150
radius:                   0.3
threshold:                5.0

[mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0
erosion_top:              0.0
erosion_bottom:           0.0
erosion_left:             0.0
erosion_right:            0.0

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

--------- extract.ini ---------

[global]
allow_growth:             False
aligner_min_scale:        0.07
aligner_max_scale:        2.0
aligner_distance:         22.5
aligner_roll:             45.0
aligner_features:         True
filter_refeed:            True
save_filtered:            False
realign_refeeds:          True
filter_realign:           True

[detect.mtcnn]
minsize:                  20
scalefactor:              0.709
batch-size:               8
cpu:                      True
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7

[detect.cv2_dnn]
confidence:               50

[detect.s3fd]
confidence:               70
batch-size:               4

[recognition.vgg_face2]
batch-size:               16
cpu:                      False

[mask.bisenet_fp]
batch-size:               8
cpu:                      False
weights:                  faceswap
include_ears:             False
include_hair:             False
include_glasses:          True

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.custom]
batch-size:               8
centering:                face
fill:                     False

[mask.vgg_obstructed]
batch-size:               2

[align.fan]
batch-size:               12

--------- train.ini ---------

[global]
centering:                face
coverage:                 87.5
icnr_init:                False
conv_aware_init:          False
optimizer:                adam
learning_rate:            5e-05
epsilon_exponent:         -7
autoclip:                 False
reflect_padding:          False
allow_growth:             False
mixed_precision:          False
nan_protection:           True
convert_batchsize:        16

[global.loss]
loss_function:            ssim
loss_function_2:          mse
loss_weight_2:            100
loss_function_3:          none
loss_weight_3:            0
loss_function_4:          none
loss_weight_4:            0
mask_loss_function:       mse
eye_multiplier:           3
mouth_multiplier:         2
penalized_mask_loss:      True
mask_type:                extended
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.dlight]
features:                 best
details:                  good
output_size:              256

[model.dfl_sae]
input_size:               128
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.dfl_h128]
lowmem:                   False

[model.original]
lowmem:                   False

[model.dfaker]
output_size:              128

[model.villain]
lowmem:                   False

[model.phaze_a]
output_size:              128
shared_fc:                none
enable_gblock:            True
split_fc:                 True
split_gblock:             False
split_decoders:           False
enc_architecture:         fs_original
enc_scaling:              7
enc_load_weights:         True
bottleneck_type:          dense
bottleneck_norm:          none
bottleneck_size:          1024
bottleneck_in_encoder:    True
fc_depth:                 1
fc_min_filters:           1024
fc_max_filters:           1024
fc_dimensions:            4
fc_filter_slope:          -0.5
fc_dropout:               0.0
fc_upsampler:             upsample2d
fc_upsamples:             1
fc_upsample_filters:      512
fc_gblock_depth:          3
fc_gblock_min_nodes:      512
fc_gblock_max_nodes:      512
fc_gblock_filter_slope:   -0.5
fc_gblock_dropout:        0.0
dec_upscale_method:       subpixel
dec_upscales_in_fc:       0
dec_norm:                 none
dec_min_filters:          64
dec_max_filters:          512
dec_slope_mode:           full
dec_filter_slope:         -0.45
dec_res_blocks:           1
dec_output_kernel:        5
dec_gaussian:             True
dec_skip_last_residual:   True
freeze_layers:            keras_encoder
load_layers:              encoder
fs_original_depth:        4
fs_original_min_filters:  128
fs_original_max_filters:  1024
fs_original_use_alt:      False
mobilenet_width:          1.0
mobilenet_depth:          1
mobilenet_dropout:        0.001
mobilenet_minimalistic:   False

--------- .faceswap ---------
backend:                  nvidia
```",tried run folder directly file well sort realign crash verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index verbose filtering face index process alignment removed file header face index recent call last file line file line process file line process file line frame list index range system information sur la master merge branch global version found check generic console true total available used free pip file file cycler file decorator file file file file file file file file file file file file file file file file file file file sip file six file file file file tornado file file file environment name version build channel main blas curl cycler decorator gast git glib lame markdown nettle pillow pip ply python sip six tornado wheel clip true true threshold contrast brightness loop false container preset medium tune none profile auto level auto false format false false optimize false true format false false method none amount radius threshold type threshold erosion global false tab extract font default prompt true global false true true false true true true confidence confidence false false false false true centering face fill false global centering face coverage false false false false false false true none none true extended false false best good architecture false false false false none true true false false true dense none true none full true true false false,issue,positive,negative,neutral,neutral,negative,negative
1316118712,"Not sure why this happens for a small subset of users.

Go `Start` > `Anaconda Prompt (cmd)`

Then enter each of the following commands in the terminal

```cmd
conda activate faceswap
conda install decorator
```
Re-launch faceswap and you should be good to go.",sure small subset go start anaconda prompt enter following terminal activate install decorator good go,issue,positive,positive,positive,positive,positive,positive
1310266566,"Thanks to @torzdf 
```bash
conda activate faceswap
cd faceswap
chcp 65001
python faceswap.py gui
```
These commands solved the problem",thanks bash activate python problem,issue,negative,positive,positive,positive,positive,positive
1306542240,"@torzdf I found that `\x1b[0m` is actually meant for `ESC[0m` explain in [here](https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797#colors--graphics-mode). Basically it's the escape sequence to show that the graphical settings have been reset to parse the text only. So, it's has no relation to setting up the project. That means it doesn't matter to delete that text from the installed list or just ignore it. How do you think?",found actually meant explain basically escape sequence show graphical reset parse text relation setting project matter delete text list ignore think,issue,negative,neutral,neutral,neutral,neutral,neutral
1304862494,"Short answer to your question is. no, I wouldn't except this as a PR I'm afraid. The reason being that a try/except just ignores the error, it does not fix the underlying issue.

Which leads me on to, what is the underlying issue? I have never seen this before, so worry that it is an edge case local to your machine. The first thing I would be looking at is where does `\x1b[0m` come from and why is it being inserted into the list, then work back from there.",short answer question would except afraid reason error fix underlying issue underlying issue never seen worry edge case local machine first thing would looking come inserted list work back,issue,negative,negative,neutral,neutral,negative,negative
1304810618,"If it helps, you can just run the installer exe and then navigate to /Users/*your user*/faceswap and the code is all there after install.",run installer navigate user code install,issue,negative,neutral,neutral,neutral,neutral,neutral
1301913831,"I do understand what you are saying, however there are other reasons for me to take the direction that I have chosen.

- setup.py handles the installing of cudnn and cudatoolkit from conda-forge, so that use-case is covered.
- A lot of our users are not that tech-savvy, so do not understand the concept of virtual environments nor the difference between pip and conda, so I try to avoid having instructions/install procedures which means they would need to learn what these are.
- I only want to have 1 format for requirements. `requirements.txt` files can be used in conda but `environment.yml` files cannot be used in pip. Using `requirements.txt` files gives greater flexibility for me and for those who are more technologically adept.

I can only assume you haven't experienced the dependency hell that can occur when using `environment.yml` files. When they work (most of the time) they are great. When they don't.... oh boy, they really don't. Debugging a conda conflict output is nigh on impossible, and I would prefer to try to avoid it.",understand saying however take direction chosen covered lot understand concept virtual difference pip try avoid would need learn want format used used pip greater flexibility technologically adept assume experienced dependency hell occur work time great oh boy really conflict output nigh impossible would prefer try avoid,issue,negative,positive,positive,positive,positive,positive
1301898709,"I understand the point. The only problem is that CuDnn and CUDA are sometimes a pain to install (thanks to NVidia to break everything with non-open-source libs...)

The setup.py file is OK, but conda users like to use environment to avoid the CUDA/Cudnn problems and leave conda to select the right Python version also.

Conda's environment files are, IMHO, the way to go.

There is, theoretically, only 2 files to create:
- one for GPU
- one other for CPU

Environment files, like for requirements files, can check python version and targeted OS (conditions have same syntax than in requirements files).

> So, my ""idea"" is that you probably should replace the requirements files by conda environment files (where you can also use ""pip"" for some special packages)

BTW: nice tool :) ",understand point problem sometimes pain install thanks break everything file like use environment avoid leave select right python version also environment way go theoretically create one one environment like check python version targeted o syntax idea probably replace environment also use pip special nice tool,issue,positive,positive,positive,positive,positive,positive
1300003239,"Yes. I have looked at environment files in the past, and use them in other projects, but have decided against using them here for a number of reasons.

The main one is that it is a support headache for me. Environment files are fine for a single project on a single OS. However, where we have multiple install types (CPU, AMD, Nvidia, Apple Silicon) across multiple OSes (Linux, MacOS, Windows), this then becomes a LOT of environment files which all need to be constantly tested, and which very much like to cause conflicts for esoteric reasons.

For this reason, we have [setup.py](https://github.com/deepfakes/faceswap/blob/master/setup.py) which allows me to have finer-grained control over the setup experience and is a single point of failure. It also provides me with useful logs for when things might go wrong.
",yes environment past use decided number main one support headache environment fine single project single o however multiple install apple silicon across multiple becomes lot environment need constantly tested much like cause esoteric reason control setup experience single point failure also useful might go wrong,issue,positive,negative,neutral,neutral,negative,negative
1298332621,"I do appreciate the PR, and the work you have put in, but I am going to close this one off. I feel yours is quite the edge case, and I'm not convinced that there would be considerable benefit to adjusting the scale of the image prior to swapping, vs resizing the image after the swap has occurred (although I do appreciate that this might be quite an unwieldy task when you are working with 1000s of images).

Ultimately I need to balance benefit to the project against my time needed to support any features.

Thank you again for the PR, and please do not be put off from contributing in the future. ",appreciate work put going close one feel quite edge case convinced would considerable benefit scale image prior swapping image swap although appreciate might quite unwieldy task working ultimately need balance benefit project time support thank please put future,issue,positive,positive,neutral,neutral,positive,positive
1289794058,"Yes exactly, the inspiration behind the PR was a folder of 1000+ HQ photos, each with a different size face. Some had a small face and the original resolution could be preserved without pixelation of the swap. Others were close-up and would benefit from resizing before swapping. This PR would allow faceswap to resize each image precisely.

This PR doesn't need to be merged if you feel it is not marginally beneficial - the code base has changed quite a bit since this PR was opened anyways and would need some adjusting.",yes exactly inspiration behind folder different size face small face original resolution could without swap would benefit swapping would allow resize image precisely need feel marginally beneficial code base quite bit since anyways would need,issue,positive,negative,neutral,neutral,negative,negative
1288999157,"Sorry I have sat on this for so long. I am unsure of the value add here.

If I am understanding correctly, the final output image is resized based on the size of the output of the model. If this is the case, then I have the following reservations:

- Faceswap is mostly used for videos, which would not be covered by this PR, so would be adding an option for a very limited use case
- The resizing of images can be done fairly easily on either the original images fed to Faceswap or on the final output images generated from Faceswap. It could be argued (in the latter case) that it is preferable to see the swapped output before making a judgement call on whether the image should be resized.
- The only potential benefit is if you are swapping onto lots of images of lots of different sizes, as otherwise 'output scaling' can achieve much the same effect",sorry sat long unsure value add understanding correctly final output image based size output model case following mostly used would covered would option limited use case done fairly easily either original fed final output could latter case preferable see output making call whether image potential benefit swapping onto lot lot different size otherwise scaling achieve much effect,issue,positive,positive,neutral,neutral,positive,positive
1287964797,"This looks like a corrupt image file. Without a full crash report, this impossible for me to diagnose, so closing. Please create a new issue with the corresponding crash report.",like corrupt image file without full crash report impossible diagnose please create new issue corresponding crash report,issue,positive,negative,negative,negative,negative,negative
1287964598,This looks like a temporary error reading the preview image from disk. I have pushed an update to hopefully fix this. Please update.,like temporary error reading preview image disk update hopefully fix please update,issue,positive,neutral,neutral,neutral,neutral,neutral
1244276376,"My mistake, it was because using the parameter -p with the training command and not having a display. removing the -p solves the error!,",mistake parameter training command display removing error,issue,negative,neutral,neutral,neutral,neutral,neutral
1244265526,"Hello @aopsr! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`lib/align/aligned_face.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/align/aligned_face.py):

> [Line 437:1](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/align/aligned_face.py#L437): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace

* In the file [`lib/align/detected_face.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/align/detected_face.py):

> [Line 137:1](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/align/detected_face.py#L137): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace

* In the file [`lib/cli/args.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/cli/args.py):

> [Line 789:100](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/cli/args.py#L789): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (156 > 99 characters)

* In the file [`lib/convert.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py):

> [Line 248:100](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L248): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (198 > 99 characters)
> [Line 253:52](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L253): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 254:52](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L254): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 255:52](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L255): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 256:52](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L256): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 257:52](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L257): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 257:100](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/lib/convert.py#L257): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (104 > 99 characters)

* In the file [`plugins/extract/pipeline.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/plugins/extract/pipeline.py):

> [Line 814:1](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/plugins/extract/pipeline.py#L814): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> [Line 829:54](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/plugins/extract/pipeline.py#L829): [E231](https://duckduckgo.com/?q=pep8%20E231) missing whitespace after ','

* In the file [`scripts/convert.py`](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/scripts/convert.py):

> [Line 774:1](https://github.com/deepfakes/faceswap/blob/4da900b959d5d345a173544a5eec7e6bda2d8fd2/scripts/convert.py#L774): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace

",hello thanks opening checked touched pep found file line blank line file line blank line file line line long file line line long line continuation line visual indent line continuation line visual indent line continuation line visual indent line continuation line visual indent line continuation line visual indent line line long file line blank line line missing file line blank line,issue,negative,negative,neutral,neutral,negative,negative
1229619428,I believe this bug was finally fixed with #1263 ,believe bug finally fixed,issue,negative,positive,neutral,neutral,positive,positive
1229443363,"o my god,it's work,thanks a lot.
and before this update,i found a way to pass error.it about ""output_size"".
when the model created,the ""output_size"" is 128 by defalut.then i edit ""dfaker_state.json"",output_size be changed to 256.run for years.
when i change back to 128,it run again.
why i found this way?beacause when i trainning phaze-a model,i edit ""phaze_a_state.json"" again,to change ""enc scaling"".
and recieved ValueError: Input 0 of layer ""phaze_a"" is incompatible with the layer: expected shape=(None, 64, 64, 3), found shape=(6, 272, 272, 3)\n",god work thanks lot update found way pas model edit change back run found way model edit change scaling input layer incompatible layer none found,issue,positive,positive,neutral,neutral,positive,positive
1229437198,"For what it's worth, I just fixed another bug, which *may* solve this issue (it also may not, but worth checking)",worth fixed another bug may solve issue also may worth,issue,positive,positive,positive,positive,positive,positive
1226599049,"yes，it's ok when start a new dfaker model.
thanks a lot for your work.it time to say goodbye to my old dfaker model.
now , start with phaze-a model:)",start new model thanks lot time say old model start model,issue,negative,positive,positive,positive,positive,positive
1223672090,"I cannot recreate this issue using the exact same settings as you.

I do notice that this model is over 2.5 years old! The fact that you can still run a model that old in current faceswap amazes me.

Do you get the same issue if you start a new model?
",recreate issue exact notice model old fact still run model old current get issue start new model,issue,negative,positive,positive,positive,positive,positive
1221411680,"Well I guess I have to be the one to add some cloud tutorials here:

@torzdf  if you see this please consider to add this into your tutorials, this can be really helpful for beginners without local GPUs.

For users first time setting up such environments, I strongly recommend you to follow the following steps or you might waste a lot of time just to set up a proper environment.....

My VM:  

Ubuntu 2004 GRID 11.1   4 vCPUS  20 vRAM  with  1/4 NVIDIA T4 GPU

1. What platform to choose:

I don't really recommend google colab, unless you have colab pro.
The reason is because deepfake is a time consuming ML process, any interrupt in the colab ( not pro ), whether it is internett connection or whatever, will cause the entire process to be terminated and you will literally lose all the models you have got so far, you might even have to re-upload your files which sucks even more.

So if you don't have Pro, better not use colab.

For buying VMs: 

Please be aware that choosing an image with NVIDIA in its name does not necessarily mean that VM has a GPU !!! For the image to work, you have to choose a VM with GPU !!!  The funny thing is, you can buy a VM without a GPU and install NVIDIA image on it, this can be highly misleading to beginners.

So be careful about this, if you want to do what I exactly did to set up my cloud ML environment, I suggest you buy a VM with the properties I mentioned above. 

I bought it at Tencent Cloud in HK zone, which is only like 0.5$ per hour, yes Chinese things might be unreliable but at the end of the day some of them do are reliable and my VM is one of them. 

Tencent Cloud has a GPU trial for new users, costing only around 0.2$ for 15 days. ( Only 15 days )

You can buy such VMs at Google, aws, azure etc. , but usually more expensive.

2. After you buy your VM

The first thing you should do is :

`$nvidia-smi`

This is to make sure your VM has a NVIDIA driver or even GPU. If the output says "" Ensure the driver is installed and up running"", there's a very big chance it doesn't even have a GPU, so please save yourself some time and go find another one.

3. If the VM has a GPU and a driver:

Now go to    `https://ngc.nvidia.com/`   and register your NVIDIA developer account.

Fill in whatever it wants to finish your register, it doesn't really matter what you fill in.

Then at the NGC main page at the right corner where your avatar is, hover it and click settings.

Click Set API Key

Generate an API key and save it anyway you like.

Go back to the previous page

Click Install NGC CLI.

Choose LINUX AMD64 and do exactly what it tells you to do.

If it asks for any key, it means the API key I meant earlier.

Go back to the place where you set your API key, and do the commands it tells you to.

Then, install docker on your VM, some VMs may have one installed already.

`$ sudo apt update`

`$ sudo apt install docker-ce`

This two commands should work for most VMs, if they don't, use your errors to google a solution for your VM.

Open a tmux session to keep everything you will do later permanently:

`$ tmux`


Then set up the NGC container using this command:

`$ sudo docker run --gpus all -it --rm [nvcr.io/nvidia/tensorflow:22.01-tf2-py3](http://nvcr.io/nvidia/tensorflow:22.01-tf2-py3)`

This command should be a whole but I don't know why it shows as two commands, just join them together manually.
 
This can also be quite slow the first time.

Then do this to install google drive commands.
Installing google drive is due to the complexity of locating and downloading files in the NGC container, I rather upload them to google drive first then download. 

If you figure out an easier way, do that and comment down below, this is the only part where I feel wierd about doing.

Make sure you are in    /workspace    at this moment, if not `cd /workspace` yourself there

`wget https://github.com/prasmussen/gdrive/releases/download/2.1.1/gdrive_2.1.1_linux_386.tar.gz`
`tar -xvf gdrive_2.1.1_linux_386.tar.gz`
`./gdrive about`

At this point you will be asked to verify your google account, just do whatever it says.

To upload files or directory: 
( These particular commands can only work if you installed gdrive in  `/workspace`  and  you are currently in `/workspace`  )

`./gdrive upload {FILE_PATH}`

OR

`./gdrive -r upload {DIRECTORY_PATH}`

I believe you can also download files from google drive in a similar way like that.

Then do this to install some dependencies you have to install manually:

`apt-get update`
`apt-get install ffmpeg libsm6 libxext6  -y`
`apt-get install python3-tk`

Even though the tkinter or whatever it is called is for the GUI, for whatever reasons, CLI users still have to install it.

Now clone the faceswap respo into /workspace

`git clone https://github.com/deepfakes/faceswap.git`

and  

`cd faceswap`

Then install the requirements by:

`pip install -r ./requirements/requirements_nvidia.txt`

Then configure the deepfake:

`python setup.py`

`No` for AMD
`No` for Docker   ( Yes might be OK as well, haven't tried that )
`Yes` for CUDA

Ignore "" CUDA / Cudnn not found ""

leave blank for that tensorflow thing

For your training images, I suggest you extract them at local, zip them up, and upload them to an URL, then curl them to  /workspace/faceswap    by:

`curl -O [URL]`

`unzip [whatever it is called]`

OR

upload your training data to google drives first, then download it to your VM using `./gdrive` I mentioned earlier.

sounds a bit complex, but I did this because it is much easier for me to test different VMs and find the right one, and in the long term this method does make things more convenient.

Then you can start training your model:

`python faceswap.py train -A [A-extracted_image_folder] -B [B-extracted_image_folder] -m ./my_model/`


At this point the script should be running just fine, you can see outputs like

[#130414] Saved model: A loss 0.0224   B loss 0.02614

Something like that

The [#130414] suggests that the process has finished 130414 iterations.

For deepfake, you should try to achieve 80,000 iterations at minimum for a decent result, assuming that your training data is of good quality. 
My definition for good quality is: 
At least 250 high-res clear photos with multiple angles, emotions and lightning conditions for each of your targets.

If you decides to test out your model:

press enter, wait for the training to stop

cd to /workspace

`cd /workspace`

Upload your model folder to your google drive.

`./gdrive upload -r ./faceswap/my_model/`

( If your followed my commands exactly, the model folder should be `my_model`, change it if you used sth else )

Yes you can start the training back on now to save yourself some time and money.

go do google drive via your browser and download that model folder to local.

you can delete it in google drive for easier upload next time.

convert your video using the downloaded model.

For this, go to USAGE.md of this respo.

If you didn't start the training earlier, remember to turn it back on.

You have to stop the training for the upload.

I suggest you convert things locally because the model is much smaller comparative to your training data files, thus you need to more time downloading things if you decide to convert them at the VM.

Please don't delete your tmux session, it should be named 0 by default.

To get back to the NGC container every time logging on to your VM, you should:

`tmux attach-session -t 0`

if it failed:

`tmux ls`

to see if you named it sth else

If it says: No tmux running

Congratulations, you have to redo all the steps above and you also lost your trained model.

So don't delete that tmux session, watch out for hot keys like ctrl-c and ctrl-z, there should be no reason for you to jump back to your default user directory, you really don't need to.

If you want to train 2 models at the same time on one VM, I don't recommend doing that cause the speed is basically the same if you train them one at a time consecutively.

Hope this can help.

If you realize any improvements, please comment down below to help more people.











",well guess one add cloud see please consider add really helpful without local first time setting strongly recommend follow following might waste lot time set proper environment grid platform choose really recommend unless pro reason time consuming process interrupt pro whether connection whatever cause entire process literally lose got far might even even pro better use please aware choosing image name necessarily mean image work choose funny thing buy without install image highly misleading careful want exactly set cloud environment suggest buy bought cloud zone like per hour yes might unreliable end day reliable one cloud trial new costing around day day buy azure usually expensive buy first thing make sure driver even output ensure driver running big chance even please save time go find another one driver go register developer account fill whatever finish register really matter fill main page right corner hover click click set key generate key save anyway like go back previous page click install choose exactly key key meant go back place set key install docker may one already apt update apt install two work use solution open session keep everything later permanently set container command docker run command whole know two join together manually also quite slow first time install drive drive due complexity container rather drive first figure easier way comment part feel make sure moment tar point verify account whatever directory particular work currently believe also drive similar way like install install manually update install install even though whatever whatever still install clone git clone install pip install configure python docker yes might well tried yes ignore found leave blank thing training suggest extract local zip curl curl whatever training data first bit complex much easier test different find right one long term method make convenient start training model python train point script running fine see like saved model loss loss something like process finished try achieve minimum decent result assuming training data good quality definition good quality least clear multiple lightning test model press enter wait training stop model folder drive exactly model folder change used else yes start training back save time money go drive via browser model folder local delete drive easier next time convert video model go start training remember turn back stop training suggest convert locally model much smaller comparative training data thus need time decide convert please delete session default get back container every time logging see else running redo also lost trained model delete session watch hot like reason jump back default user directory really need want train time one recommend cause speed basically train one time consecutively hope help realize please comment help people,issue,positive,positive,positive,positive,positive,positive
1221367799,"You aren't meant to be able to edit the fsa file directly. It's a binary file as it contains masks etc. as well as landmarks.

See here for how to clean up data:
https://forum.faceswap.dev/viewtopic.php?t=27#sort

Also, usage questions should be posted to our [forum](https://faceswap.dev/forum) or [Discord](https://discord.gg/FC54sYg), not to Github, which is meant for bugs.

",meant able edit file directly binary file well see clean data also usage posted forum discord meant,issue,negative,positive,positive,positive,positive,positive
1221334622,"The EFFMPEG tool is just a convienience wrapper for ffmpeg. The filetype option isn't important for you. It's for extracting images from a video.

Either just convert straight into a video (as shown in my earlier screenshot) or stitch the video back yourself in ffmpeg.

I don't have a Mac, so can't do anything about how it chooses to render the GUI.",tool wrapper option important video either convert straight video shown stitch video back mac ca anything render,issue,negative,positive,positive,positive,positive,positive
1221314980,"As you can see, there are still plenty options down below the ""extract file type"" where I don't have access to.
The problem now is, the produced mp4 file _**lost its audio**_ and I can _**only**_ open it with browser, none of other video players I have can open it. 
<img width=""366"" alt=""截屏2022-08-20 下午7 58 13"" src=""https://user-images.githubusercontent.com/76523934/185748005-fff00cb9-a6b6-4340-8afb-5b4e02ae5711.png"">
.",see still plenty extract file type access problem produced file lost audio open browser none video open,issue,negative,neutral,neutral,neutral,neutral,neutral
1221273397,"Can you screengrab that, as I'm not sure what you. mean. The display is generally handled by the OS. Unfortunately I don't have a macOS system to test on.

This is how to set video output, and get to the settings under Linux:
![image](https://user-images.githubusercontent.com/36920800/185741776-39ac130e-9cef-4e80-9d65-f40aedcd83be.png)
",sure mean display generally handled o unfortunately system test set video output get image,issue,negative,negative,neutral,neutral,negative,negative
1220397704,"I don't use Cloud servers myself, and don't really have the time to setup on cloud and support updating the instructions. I welcome PRs in this area though.

You may find some useful information here. Equally, it may be out of date:
https://forum.faceswap.dev/viewforum.php?f=23",use cloud really time setup cloud support welcome area though may find useful information equally may date,issue,positive,positive,positive,positive,positive,positive
1220165947,"Well I think might found the problem: I don't have full access to configurations while converting images to video.

I am using GUI in mac.

In tools =>  ( Image <> video ) , I can see there are plenty configurations options down there but there isn't a scroll bar for me to scroll down there and see all of them. I can barely see options like: JPG, JPEG etc... But my images are all PNGs. At the mean time, all the videos converted lost the original audio.

So my suggestion is, add a scroll bar to that page like every other pages has.

",well think might found problem full access converting video mac image video see plenty scroll bar scroll see barely see like mean time converted lost original audio suggestion add scroll bar page like every,issue,negative,positive,positive,positive,positive,positive
1219829704,"> 

ohh unistalled it with geek uninstaller it was named anaconda something sat at like 13gb guess i fucked up lol",geek anaconda something sat like guess,issue,negative,neutral,neutral,neutral,neutral,neutral
1219820735,"This doesn't sound like a faceswap problem. Faceswap does not install like a normal program. It is just a local install in a local folder. There isn't even an uninstall candidate for it. You just delete the folder.

https://forum.faceswap.dev/app.php/faqpage#f1r2
",sound like problem install like normal program local install local folder even candidate delete folder,issue,negative,positive,positive,positive,positive,positive
1219810771,Thanks for the heads up. Bug squashed in latest commit.,thanks bug latest commit,issue,positive,positive,positive,positive,positive,positive
1219804254,"You'd need to be more specific on this issue. This is not an issue I've seen and I'd need reproducible steps to look into it.

You can choose the file format and codec, as well as set some other common ffmpeg parameters within the ffmpeg writer configuration file. This should be enough to generate a playable video.",need specific issue issue seen need reproducible look choose file format well set common within writer configuration file enough generate playable video,issue,negative,negative,neutral,neutral,negative,negative
1219802537,"I'm trying to think of the use-case for this... it may be that the documentation needs to be updated. I haven't tested the above, but then I have never attempted to run faceswap from outside of the Conda environment.

It probably helps that I wrote the setup script, so know that it adds `LD_LIBRARY_PATH` to the activate script:
https://github.com/deepfakes/faceswap/blob/ee25a31d33d6e443d519e6459de8adb78616a5bd/setup.py#L345

Ultimately, I'm surprised that just executing the python binary worked in the past, as the Conda Env holds more than just a python virtual environment (required Cuda/cuDNN binaries and the like).

Generating the cli arguments from the GUI is just a convenience function. Adapting it to test for Conda environments and the like is most likely a bit out of scope.

I'm not sure if it's the same as the Docker issue (I do not use Docker), as theoretically Docker has it's own globally installed Cuda/cuDNN which should be being utilized.



",trying think may documentation need tested never run outside environment probably wrote setup script know activate script ultimately python binary worked past python virtual environment like generating convenience function test like likely bit scope sure docker issue use docker theoretically docker globally,issue,positive,positive,neutral,neutral,positive,positive
1212915348,This is not possible in the context of Faceswap. Faceswap takes the expressions of the original face and transfers them to the new face.,possible context original face new face,issue,negative,positive,positive,positive,positive,positive
1207960415,"Strategies have now changed slightly, and as there has been no update for a while will close.

Please reply if you want to keep this issue open",slightly update close please reply want keep issue open,issue,negative,negative,neutral,neutral,negative,negative
1207958865,"You need typing-extensions>=4.0.0 as per our requirements
https://github.com/deepfakes/faceswap/blob/master/requirements/_requirements_base.txt#L15

Also, do this to make sure you have no conflicts:
https://forum.faceswap.dev/app.php/faqpage?sid=980555ac98614ee46d507482752e36aa#f1r1",need per also make sure,issue,negative,positive,positive,positive,positive,positive
1207102918,I saw it as well. Feel free to raise a PR. Thank you.,saw well feel free raise thank,issue,positive,positive,positive,positive,positive,positive
1203023591,"I have recently updated the repo to support Tensorflow 2.9.

Easiest way to fix would be to delete your environment and re-run the installer.

Otherwise, I have now pinned tensorflow probability to an earlier version.",recently support easiest way fix would delete environment installer otherwise pinned probability version,issue,positive,neutral,neutral,neutral,neutral,neutral
1201781485,"If I were to guess, I would suspect that this is some kind of internal throttling. This is most likely to be a Tensorflow/M1 issue rather than specifically Faceswap though. Possibly related: https://developer.apple.com/forums/thread/708154
",guess would suspect kind internal throttling likely issue rather specifically though possibly related,issue,negative,positive,positive,positive,positive,positive
1201051766,"I have observed this as well, for there's a 50/50 chance for the GPU to stop during a training session. Sometimes it happens after 1 hour, sometimes I can train for 24 hours without issue, using the same model/settings. I'm not sure what the cause is, or how to find out..",well chance stop training session sometimes hour sometimes train without issue sure cause find,issue,negative,positive,positive,positive,positive,positive
1200094297,"Hello @what-in-the-nim! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`plugins/train/trainer/original_defaults.py`](https://github.com/deepfakes/faceswap/blob/2c69f61c9cfa4062ed6d43b2ae24f16063289d0c/plugins/train/trainer/original_defaults.py):

> [Line 99:100](https://github.com/deepfakes/faceswap/blob/2c69f61c9cfa4062ed6d43b2ae24f16063289d0c/plugins/train/trainer/original_defaults.py#L99): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (102 > 99 characters)

",hello thanks opening checked touched pep found file line line long,issue,negative,positive,neutral,neutral,positive,positive
1186132059,"preview has nothing to do with timelapse.

Preview is a random output from your training folder.
Timelapse you choose the images and they are saved to the specified folder.

Usage questions are best asked in our [forum](https://faceswap.dev/forum) or in our [Discord](https://discord.gg/FC54sYg)",preview nothing preview random output training folder choose saved folder usage best forum discord,issue,positive,positive,positive,positive,positive,positive
1185360509,"Duplicate of #1247

Please don't open exactly the same issue",duplicate please open exactly issue,issue,negative,positive,positive,positive,positive,positive
1182876178,"I don't have a MultiGPU setup to be able to test multi-gpu configurations, so only MirroredStrategy is directly supported, as MultiWorker requires more configuration to set up (which I cannnot easily test).

You can try configuring yourself with the steps here: https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy and feedback with the steps required to get it working (if you are successful).

If you do get it set up correctly, then please do feedback as I can look to add configuration options within Faceswap itself.

We use our own dataloaders, not Tensorflow/Keras implementation, so it is entirely possible that MultiWorker is not possible within Faceswap's context, but I could not say with any certainty one way or the other.

The strategy used is defined here:
https://github.com/deepfakes/faceswap/blob/279bf38746fa19edf3bfe786685368d9aeb3117c/plugins/train/model/_base/settings.py#L546",setup able test directly configuration set easily test try feedback get working successful get set correctly please feedback look add configuration within use implementation entirely possible possible within context could say certainty one way strategy used defined,issue,positive,positive,positive,positive,positive,positive
1177824292,"Wait a minute, My NVIDIA GPU has 24G RAM and when I turn on the extract and set the batch_size to 1, the same prompt occurs when I extract videos. I suppose the 24G RAM is enough for extract the video, so there might be some other problem",wait minute ram turn extract set prompt extract suppose ram enough extract video might problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1174567503,"Hey did you fix it? Whats your base nvidia and cuda version in the ubuntu OS? 
This dockerfile was for Arch, most probably @kwxiaozhu solution would work. ",hey fix whats base version o arch probably solution would work,issue,negative,negative,negative,negative,negative,negative
1174565885,"@xiaosefengyun 
Because the base image nvidia/cuda:11.7.0-runtime-ubuntu18.04 do not installed the libcudnn8.
docker exec -it  inside the docker and run 
`apt-get install libcudnn8=8.2.4.15-1+cuda11.4` 
depend on your cuda version inside the docker,run
`apt-cache show  libcudnn8`  
and find and install the proper version of libcudnn8,and then wil solve the problem.


",base image docker inside docker run install depend version inside docker run show find install proper version solve problem,issue,negative,negative,negative,negative,negative,negative
1172918709,"Correction: In fact, when running for about 3 hours and about 66500 iterations, the change stops using the GPU. And the program starts to get very slow.",correction fact running change program get slow,issue,negative,negative,negative,negative,negative,negative
1172023177,"So grateful for this work!
Does this mean we’re closer to DeepFaceLive on M1?
",grateful work mean closer,issue,negative,negative,negative,negative,negative,negative
1171022211,Closing as stale. Face pose information is accessible in code if anyone wants to revisit.,stale face pose information accessible code anyone revisit,issue,negative,negative,neutral,neutral,negative,negative
1171020932,Closing issue as method for creating video output has changed.,issue method video output,issue,negative,neutral,neutral,neutral,neutral,neutral
1171014272,"This is almost definitely a python version conflict issue.

Basically openCV should be looking inside your Conda environment for lib files, not inside your local python cache:
`/home/suciokhan/.local/lib/python3.8/site-packages/cv2/../../lib64` <- This is the wrong place to look

The easiest way to resolve this (although this may cause issues with other python applications which have been installed globally) is to remove any python folders in the location `/home/suciokhan/.local/lib/` and then reinstall Faceswap.
",almost definitely python version conflict issue basically looking inside environment inside local python cache wrong place look easiest way resolve although may cause python globally remove python location reinstall,issue,negative,negative,negative,negative,negative,negative
1171008361,"I'm closing this issue as stale, and because this is more of an Apple/XQuartz issue than a Faceswap issue.",issue stale issue issue,issue,negative,negative,negative,negative,negative,negative
1171006428,"Apple Silicon setup has now been rolled into the standard Faceswap install path (see here: https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#macos-apple-silicon-install-guide)

Hopefully this solves your issue. If not, please open a new issue.",apple silicon setup rolled standard install path see hopefully issue please open new issue,issue,positive,positive,neutral,neutral,positive,positive
1171003446,"I don't use Apple Silicon, but will leave this open in case any Apple Silicon users have any insights",use apple silicon leave open case apple silicon,issue,negative,neutral,neutral,neutral,neutral,neutral
1171001958,"You are using the global python interpreter to run faceswap. This is a very bad idea.

Unfortunately we only provide support for Faceswap installs that follow the standard install path by running the latest installer:
https://github.com/deepfakes/faceswap/releases/tag/v2.0.0

Supporting any other install method just has too many variables to troubleshooot.

I suggest following every step in the following link. It solves 99% of issues. If you still have issues, then you can open another issue:

https://forum.faceswap.dev/app.php/faqpage#f1r1


",global python interpreter run bad idea unfortunately provide support follow standard install path running latest installer supporting install method many suggest following every step following link still open another issue,issue,negative,positive,neutral,neutral,positive,positive
1170997815,"I don't use Docker. The images tend to get updated by the community. I'm tagging @rushic24 who PR'd related #1232 in case he has any insights. In the meantime, please post the output of the following:

From inside your virtual environment, inside your faceswap folder, run:
```bash
python -c ""from lib.sysinfo import sysinfo ; print(sysinfo)""
```

and post output",use docker tend get community related case please post output following inside virtual environment inside folder run bash python import print post output,issue,negative,neutral,neutral,neutral,neutral,neutral
1159435910,"The M1 install path has now been rolled into the standard path. The information here is now out of date
(related: #1238 )",install path rolled standard path information date related,issue,negative,neutral,neutral,neutral,neutral,neutral
1158413890,"Hello @torzdf! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:





* In the file [`plugins/train/model/_base/model.py`](https://github.com/deepfakes/faceswap/blob/c1439439ac9a79e9f83a8ff57f19a659e1aa8d27/plugins/train/model/_base/model.py):

> [Line 394:13](https://github.com/deepfakes/faceswap/blob/c1439439ac9a79e9f83a8ff57f19a659e1aa8d27/plugins/train/model/_base/model.py#L394): [E731](https://duckduckgo.com/?q=pep8%20E731) do not assign a lambda expression, use a def























",hello thanks opening checked touched pep found file line assign lambda expression use,issue,negative,positive,positive,positive,positive,positive
1157487722,"Thanks, testing and updates are appreciated, I had to implement this blind, so I'm fairly happy that most of the errors seem to be fairly trivial.

I'm hoping by standardising the setup path it will make it easier to maintain this going forward.",thanks testing implement blind fairly happy seem fairly trivial setup path make easier maintain going forward,issue,positive,positive,positive,positive,positive,positive
1155600241,"I *think* this is a VRAM out of memory issue. Try either:
- Going into settings and reducing the batch size to each of the plugins to 1
- Running in ""single process"" model",think memory issue try either going reducing batch size running single process model,issue,negative,negative,neutral,neutral,negative,negative
1155598196,"It is not possible, I'm afraid. However we do welcome translation contributions:
https://github.com/deepfakes/faceswap/pull/1126",possible afraid however welcome translation,issue,negative,positive,neutral,neutral,positive,positive
1155597496,This is a bug I'm aware of. It only affects display of graph/analysis during a training session though. It doesn't break training. ,bug aware display training session though break training,issue,negative,positive,positive,positive,positive,positive
1152894257,"if reporting bugs, please provide more information. I cannot fix what I cannot recreate. For developers, effectively saying ""it doesn't work"" is next to useless.

Also, see here. Is this your issue?
https://forum.faceswap.dev/viewtopic.php?p=6804#p6804",please provide information fix recreate effectively saying work next useless also see issue,issue,negative,positive,neutral,neutral,positive,positive
1152077216,Please stop using github issues as a personal support channel.,please stop personal support channel,issue,negative,neutral,neutral,neutral,neutral,neutral
1151293019,"Sorry, I still didn't succeed，i think it may be the problem of this library [psutil#2016](https://github.com/giampaolo/psutil/issues/2016) and [psutil#2098](https://github.com/giampaolo/psutil/issues/2098)
",sorry still think may problem library,issue,negative,negative,negative,negative,negative,negative
1145798739,>  Crash report written to 'E:\VisualStudioIDE\AIProject\faceswap\crash_report.2022.06.03.174758316958.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting ,crash report written log must provide file seeking assistance please verify running latest version,issue,negative,positive,positive,positive,positive,positive
1140802518,"1) When filling out bug reports please use the template provided (shown below). Single line extracts tell us nothing.
2) This is not a bug. It is a warning message generated by matplotlib when it scans your font directory, Please feel free raising to raise an with their project: https://github.com/matplotlib/matplotlib


## Bug report template:

*Note: For general usage questions and help, please use either our [FaceSwap Forum](https://faceswap.dev/forum) 
or [FaceSwap Discord server](https://discord.gg/FC54sYg). General usage questions are liable to be closed without
response.*

**Crash reports MUST be included when reporting bugs.**

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - Python Version [e.g. 3.5, 3.6]
 - Conda Version [e.g. 4.5.12]
 - Commit ID [e.g. e83819f]
 - 
**Additional context**
Add any other context about the problem here.

**Crash Report**
The crash report generated in the root of your Faceswap folder",filling bug please use template provided shown single line tell u bug warning message font directory please feel free raising raise project bug report template note general usage help please use either forum discord server general usage liable closed without response crash must included describe bug clear concise description bug reproduce reproduce behavior go click scroll see error behavior clear concise description happen applicable add help explain problem please complete following information o python version version commit id additional context add context problem crash report crash report root folder,issue,positive,positive,neutral,neutral,positive,positive
1140528347,"1) Not an error. Issue and resolution clearly stated in output
2) Github issues is not a support channel.",error issue resolution clearly stated output support channel,issue,negative,positive,positive,positive,positive,positive
1140401105,hello now that the bug is solved i have to re-download the linux installer and reinstall it ?,hello bug installer reinstall,issue,negative,neutral,neutral,neutral,neutral,neutral
1140332929,"This isn't the place for tech support. For that please visit our forums (https://forum.faceswap.dev/) or our discord (https://discord.gg/FC54sYg)

However, the most likely reason is this: https://forum.faceswap.dev/app.php/faqpage?sid=26c90023ef759be6f7a2e739aa02e9cc#f4r0",place tech support please visit discord however likely reason,issue,negative,neutral,neutral,neutral,neutral,neutral
1140332021,"Re-opening as I need to fix the audio crashing bug.

Please do not add to this issue, as I know what the problem is.",need fix audio bug please add issue know problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1140331733,no face swap applied i used the default options for my first try but it didn't work with almost 100000 iterations,face swap applied used default first try work almost,issue,negative,positive,positive,positive,positive,positive
1140331526,"i m one warning but i worked
05/28/2022 23:24:01 WARNING  IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=8, resizing from (1298, 726) to (1304, 728) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).",one warning worked warning warning input image divisible ensure video compatibility prevent make input image divisible set incompatibility,issue,negative,neutral,neutral,neutral,neutral,neutral
1140331030,"> 



> I noticed this the other day. Easiest thing for me was just disable the setting for converting audio in the config file.

I write the software and I totally forgot this was a thing :joy: 

![image](https://user-images.githubusercontent.com/36920800/170843196-d73db2ae-ed04-449f-88ae-1ffb21b796b4.png)
",day easiest thing disable setting converting audio file write totally forgot thing joy image,issue,positive,positive,positive,positive,positive,positive
1140330791,"can you detail the modification I am a beginner
ok and then I can start the conversion again?",detail modification beginner start conversion,issue,negative,neutral,neutral,neutral,neutral,neutral
1140330671,"I noticed this the other day. Easiest thing for me was just disable the setting for converting audio in the config file.
convert settings -> writer -> ffmpeg -> check ""Skip Mux""
",day easiest thing disable setting converting audio file convert writer check skip mux,issue,negative,neutral,neutral,neutral,neutral,neutral
1140330628,"yes you are right there is no sound and how to bypass can you explain? sorry i m french ;)
",yes right sound bypass explain sorry,issue,negative,positive,neutral,neutral,positive,positive
1140330473,"Ok, I will flag this as a bug as I need to find a way to check for the audio stream. In the meantime you can work around the issue by muxing a dummy audio stream onto your video, if that is reasonable.",flag bug need find way check audio stream work around issue dummy audio stream onto video reasonable,issue,negative,positive,positive,positive,positive,positive
1140329903,"Delete your faceswap folder, remove the environment and re-install faceswap. Matplotlib has been updated and it looks like your system is having conflicts with the old/new version.",delete folder remove environment like system version,issue,negative,neutral,neutral,neutral,neutral,neutral
1140329764,Would I be correct in assuming that the input video `Capture vidéo 2022-05-28 16:34:19.mp4` has no audio stream?,would correct assuming input video capture audio stream,issue,negative,neutral,neutral,neutral,neutral,neutral
1136095160,"> @geewiz94 @daniellivingston please help me

You have installed a package (psutil) with the wrong architecture (x86 [Intel/AMD] instead of aarch64 [Apple Silicon/ARM]).

Easiest solution: use this to bootstrap your Python ARM environment: https://github.com/alexfromapex/tensorexperiments",please help package wrong architecture instead apple easiest solution use bootstrap python arm environment,issue,positive,negative,negative,negative,negative,negative
1134387951,"Unfortunately Faceswap is not setup to be subject agnostic. It specifically requires models trained on 2 identities.

A subject-agnostic model would require an entirely different methodology (for example First Order Motion: https://github.com/AliaksandrSiarohin/first-order-model)",unfortunately setup subject agnostic specifically trained model would require entirely different methodology example first order motion,issue,negative,negative,negative,negative,negative,negative
1134033505,"In which case, I'm not sure. Tagging @geewiz94 @daniellivingston who did most of the work on M1 port in case they have any ideas.",case sure work port case,issue,negative,positive,positive,positive,positive,positive
1133928799,"I'm not a MacOS expert by any means, but this:
```
but is an incompatible architecture (have 'x86_64', need 'arm64e'))
```
suggests to me that you are trying to run the M1 version of the software on an Intel Mac,",expert incompatible architecture need trying run version mac,issue,negative,neutral,neutral,neutral,neutral,neutral
1133753924,"Honestly, the overhead is negligible. When I looked to add them as default, I tested extraction speed with and without creating them and there was no measurable difference.

The reason I add them as default is for a couple of reasons...

1) To make sure that end users **always** have a mask available. For new users, this is crucial, as without a mask available the final swap will look bad. When people are learning the process, then these masks being available is very valuable. Later, of course, you realize that there are better options available. Also, the default training settings have ""Penalized Mask Loss"" enabled with a default of ""Extended"" mask. This ensures that new users are not immediately hit by an error when they start training.

2) The components mask is required for the eye/mouth multiplier during training, as they tell the Neural network where the eyes and mouth are located.
",honestly overhead negligible add default tested extraction speed without measurable difference reason add default couple make sure end always mask available new crucial without mask available final swap look bad people learning process available valuable later course realize better available also default training mask loss default extended mask new immediately hit error start mask multiplier training tell neural network mouth,issue,negative,positive,positive,positive,positive,positive
1133753399,"That makes sense, thanks for the explanation. In that case, would it make sense to allow a user to not run those maskers during extracting if, say, I only intended to train with the bisenet-Fp Face mask? That way I don't have to waste processing power creating masks I don't intend to use. Unless I am misunderstanding the use of those two masks. ",sense thanks explanation case would make sense allow user run say intended train face mask way waste power intend use unless misunderstanding use two,issue,negative,neutral,neutral,neutral,neutral,neutral
1133752858,"The reason there isn't a batchsize for this is that the components and extended masks are ""dummy"" mask plugins. They use the same plugin architecture as the other masks, which are generated through neural networks, but they are actually entirely generated from the extracted landmarks.

With this in mind, it doesn't make sense to have a batchsize for these masks, as they will always be generated as one face = one mask. Increasing the batch size would just increase the number of faces sent to the maskers, but they would still be processed one at a time, so there would be zero difference in processing time.

A batchsize is required to be given to the plugin, which is why you see ""initialized with batch size of 1""",reason extended dummy mask use architecture neural actually entirely extracted mind make sense always one face one mask increasing batch size would increase number sent would still one time would zero difference time given see batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
1133023598,"> I modified the scripts to allow for multiple faceswaps within the same frame/movie - is there any interest in having me pushing my code?
> 
> You still need to train multiple models (e.g. source A to target A, source B to target B, etc), so it's pretty time consuming. It currently checks which face to swap via a face encoding based on a single image, it would benefit from neural net face ID, but it works very well as is as long as faces are different enough.

@ameenba Is the code for multiple actor swap updated in the master branch ? If not in which branch it is ? Can you mention the filenames that has been edited?",allow multiple within interest pushing code still need train multiple source target source target pretty time consuming currently face swap via face based single image would benefit neural net face id work well long different enough code multiple actor swap master branch branch mention,issue,positive,positive,neutral,neutral,positive,positive
1132112978,"that's good, thanks. I was hoping to be able to identify just on system, but it's no biggy to get the additional information from the processor.",good thanks able identify system get additional information processor,issue,positive,positive,positive,positive,positive,positive
1132110650,"@torzdf I think you're looking for a function like this, for me it outputs `darwin_arm64`: https://stackoverflow.com/a/71551501

Other ways I've tried:
```
>> platform.machine()
arm64
>> platform.processor()
arm
>> cpuinfo.get_cpu_info().get('brand_raw')
Apple M1 Pro
```
I'm not able to test this on an Intel Mac unfortunately.",think looking function like way tried arm arm apple pro able test mac unfortunately,issue,negative,neutral,neutral,neutral,neutral,neutral
1130582022,"It's certainly good news for you M1 owners. TBH if I was starting this project again, I'd probably go PyTorch, but I have no plans to port the code, as it would be a mammoth task.

At some point I'm probably going to update setup.py so M1 owners are pulled in to the same install path as Nvidia/CPU/AMD users.

@daniellivingston @geewiz94 it would be very helpful to me if you could tell me what identifying information I can pull to know that the user is running on an M1 mac (e.g. like 

```py
 platform.system() = ""Windows""/""Linux""/""Darwin""
```

but exclusively identifies M1/Apple Silicon.


",certainly good news starting project probably go port code would mammoth task point probably going update install path would helpful could tell information pull know user running mac like exclusively silicon,issue,positive,positive,positive,positive,positive,positive
1127098362,Good catch. This bug has been fixed. Thanks.,good catch bug fixed thanks,issue,positive,positive,positive,positive,positive,positive
1126838643,"This isn't a bug. It explicitly says in the report you pasted:
```
ERROR   Please run this script with Python version 3.7 or 3.8 64bit and try again.
```

FS has not been tested in higher versions of Python.",bug explicitly report pasted error please run script python version bit try tested higher python,issue,negative,positive,positive,positive,positive,positive
1126838471,This was a bug in upstream pynvml. This issue should no longer occur.,bug upstream issue longer occur,issue,negative,neutral,neutral,neutral,neutral,neutral
1126736702,"Make sure your Nvidia drivers are up to date. If needs be, use DDU to remove the current drivers and reinstall them",make sure date need use remove current reinstall,issue,negative,positive,positive,positive,positive,positive
1125894162,"Sorry, I thought it was one of the test situation of the testing branch. Let me open in a new issue! @torzdf
<img width=""1024"" alt=""截屏2022-05-13 下午6 28 12"" src=""https://user-images.githubusercontent.com/84232793/168265370-47569621-3a54-4630-b22a-7cfcdf1684ff.png"">
 ",sorry thought one test situation testing branch let open new issue,issue,negative,negative,negative,negative,negative,negative
1125885269,"@CaffreyR Please add new issues in the issues section, or on our forums (https://forum.faceswap.dev/). Also please provide the crash report as per the instructions given.

However, on the small screen grab you have given, it looks like you are trying to run training on images that have not been extracted by Faceswap.",please add new section also please provide crash report per given however small screen grab given like trying run training extracted,issue,positive,negative,neutral,neutral,negative,negative
1125881067,"<img width=""583"" alt=""image"" src=""https://user-images.githubusercontent.com/84232793/168262475-50efecbe-c404-42fc-bcd0-13c9bb23365e.png"">
@geewiz94 Hi! I test the code following your instruction, but it went wrong when I try to run this command, **python faceswap.py train -A ./tom -B ./lee -m ./weight -p** , and it report crash! ",image hi test code following instruction went wrong try run command python train report crash,issue,negative,negative,negative,negative,negative,negative
1125417635,@torzdf Works great! Tested extract/convert and training with Phaze-A and dfl_sae. Thanks for all the work!,work great tested training thanks work,issue,positive,positive,positive,positive,positive,positive
1124889795,"@geewiz94 Ok, I have done my changes to the [m1](https://github.com/deepfakes/faceswap/tree/m1) branch. If you could test that all works as expected, I'll get this merged into Master",done branch could test work get master,issue,negative,neutral,neutral,neutral,neutral,neutral
1124388264,"Ok, cool. Thanks! I'll probably create a branch for this and merge it there to move a couple of bits and pieces around. As there is not much else to do, it will be probably be quicker than reviewing/feeding back.

Once done, I'll get you to do some final testing before merging to master (don't have an M1 to test with).

Thanks for the contribution :)",cool thanks probably create branch merge move couple around much else probably back done get final testing master test thanks contribution,issue,positive,positive,positive,positive,positive,positive
1124385210,"Merged and tested, seems to be working! Hope the code is okay. I'm not too sure about error handling during Metal initialization.

I also renamed the backend to 'apple_silicon' since the M1 name is going to be outdated pretty soon when M2 comes out.",tested working hope code sure error handling metal also since name going outdated pretty soon come,issue,positive,positive,positive,positive,positive,positive
1124314329,"@torzdf Thanks, I'll take a look!
Phaze-A with non-original Enc Arch seems to work after all, I had to change Stojo to use efficientnet_v2_s and set Enc scaling to 50.

Global settings set to:
- Learning rate: 4.7e-5
- Epsilon exponent: -5
- Mixed precision: off",thanks take look arch work change use set scaling global set learning rate epsilon exponent mixed precision,issue,negative,positive,neutral,neutral,positive,positive
1124010397,"@daniellivingston @geewiz94 Ok, I have refactored gpu_stats into it's own package. This is currently in Staging (which I have changed to point this PR at), but will be in Master after I have performed some final checks.

This means that different GPU backends will get dynamically loaded depending on the faceswap backend in use. The unfortunate side effect is that this means you now have conflicts to be resolved. On the plus side it removes the issue of the pynvx dependency, as that will now only be loaded if the backend is Nvidia running on an Apple machine. 

As mentioned before, updating you code should not be too difficult. Please use the backend name 'applem1' so that it is easily distinguishable from Apple Intel machines. It should be fairly obvious what needs to be done by overriding the NotImplemented methods from the base GPUStats class, but any problems, let me know.

",package currently staging point master final different get dynamically loaded depending use unfortunate side effect resolved plus side issue dependency loaded running apple machine code difficult please use name easily distinguishable apple fairly obvious need done base class let know,issue,negative,negative,negative,negative,negative,negative
1123941263,"> Hi, I am working it on m1 pro too! But how do you fix the pynvx is not working? @geewiz94

@CaffreyR It has not been merged into the main branch yet. If you want to test, please make sure that you've checked out this fork: https://github.com/geewiz94/faceswap/tree/patch-1 (switch to branch **patch-1**)

And then follow the install instructions here:
https://github.com/geewiz94/faceswap/blob/patch-1/INSTALL.md#macos-apple-silicon-install-guide",hi working pro fix working main branch yet want test please make sure checked fork switch branch follow install,issue,positive,positive,positive,positive,positive,positive
1123780894,"Hi, I am working it on m1 pro too! But how do you fix the pynvx is not working? @geewiz94 ",hi working pro fix working,issue,negative,neutral,neutral,neutral,neutral,neutral
1123383318,"Ok great, Unbalanced is now giving me results using a lower learning rate!
I've also merged upstream changes and this seems to have fixed the NoneType error for legacy presets in Phaze-A! Still not sure about Stojo: how many iterations does it usually take before a face starts to appear in the preview?",great unbalanced giving lower learning rate also upstream fixed error legacy still sure many usually take face appear preview,issue,positive,positive,positive,positive,positive,positive
1121772424,"Ok, not sure why that would happen... I did a test install under Windows and did not hit this issue. There was a problem with a version of nvidia-ml-py which caused the above issue, but that version was pulled:
https://pypi.org/project/nvidia-ml-py/#history

Also, that code is not called when the installer runs. So idk.
",sure would happen test install hit issue problem version issue version also code installer,issue,negative,positive,positive,positive,positive,positive
1121770882,"""""""
Windows 10 Pro, 64-bit
DirectX  12
GPU NVIDIA GeForce GTX 1050 Ti
NVIDA 512.59
DCH
CUDA 768
8.17.15.1259		NVIDIA User Experience Driver Component
NVIDIA CUDA 11.6.134 driver
""""""
This is my computer information, I had solved the issue by manual installation.
The issue occures in ../lib/gpu_stats.py (Line273 and Line 298).
I delete the parameter .decode(""utf-8"") 
",pro ti user experience driver component driver computer information issue manual installation issue line line delete parameter,issue,negative,neutral,neutral,neutral,neutral,neutral
1121365610,"You may want to hold fire on any linting etc. I am going to refactor the GPUstats section for better class inheritance rather than the myriad of if/else statements, and also try to bring that section of code a bit more up to date, as it is now fairly old. It *should* then be fairly trivial to rewrite this code a bit to inherit from the (newly created) base GPUStats class.",may want hold fire going section better class inheritance rather myriad also try bring section code bit date fairly old fairly trivial rewrite code bit inherit newly base class,issue,negative,positive,positive,positive,positive,positive
1120840543,"Thanks for this PR. I'm probably going to create another branch to merge this into whilst it is tested (I do not possess an M1 Mac, so cannot do much testing myself) and so I can refactor a little bit around the multiple backends that FS will support (also I would prefer not to remove the Nvidia/Apple combo. It is likely to be a very rare use case, but may still be in use by some users).

RE: models turning white - try lowering the learning rate to see if you can get things training that way. Interesting about Phaze-A... I would expect the StoJo preset to be the one which doesn't work, as the others are mostly just recreations of existing models.

Also, if you could fix up the Linting errors, that would be appreciated. Just helps to keep with code consistency. I wouldn't recommend using Black, as it's a bit OTT imho.

If you feel up to creating an install script, that would also be appreciated. I understand if not, but it shouldn't be that hard using the linux install script as a base https://github.com/deepfakes/faceswap/blob/master/.install/linux/faceswap_setup_x64.sh

Otherwise I will look to review more thoroughly in the coming days.",thanks probably going create another branch merge whilst tested posse mac much testing little bit around multiple support also would prefer remove likely rare use case may still use turning white try lowering learning rate see get training way interesting would expect preset one work mostly also could fix would keep code consistency would recommend black bit feel install script would also understand hard install script base otherwise look review thoroughly coming day,issue,positive,positive,neutral,neutral,positive,positive
1120673326,"NO command，the issue occurs when I installing the faceswap in window-64 platform.


it confused me.



---Original---
From: ""Yahyaa ***@***.***&gt;
Date: Mon, May 9, 2022 03:00 AM
To: ***@***.***&gt;;
Cc: ***@***.******@***.***&gt;;
Subject: Re: [deepfakes/faceswap] The last step when installing faceswap---Thesyntax of the command is incorrect. (Issue #1217)




 
@lahongsang what is the command you are running ?
 
—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you were mentioned.Message ID: ***@***.***&gt;",issue platform confused date mon may subject last step command incorrect issue command running reply directly view id,issue,negative,negative,negative,negative,negative,negative
1120503958,"> Hello @geewiz94! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:
> 
> * In the file [`lib/gpu_stats.py`](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/gpu_stats.py):
> 
> > [Line 17:30](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/gpu_stats.py#L17): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> 
> * In the file [`lib/metal/__init__.py`](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py):
> 
> > [Line 3:14](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L3): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> > [Line 6:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L6): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 11:5](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L11): [E301](https://duckduckgo.com/?q=pep8%20E301) expected 1 blank line, found 0
> > [Line 14:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L14): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 20:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L20): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 28:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L28): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 29:5](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L29): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> > [Line 38:5](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L38): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> > [Line 40:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L40): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> > [Line 43:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L43): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 46:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L46): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 49:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L49): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 52:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L52): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 56:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L56): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 59:1](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L59): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> > [Line 65:62](https://github.com/deepfakes/faceswap/blob/a0d38c2d687b2826fac13150a2e344065378effe/lib/metal/__init__.py#L65): [W292](https://duckduckgo.com/?q=pep8%20W292) no newline at end of file

I think all of these issues can be resolved with [Black](https://github.com/psf/black).",hello thanks opening checked touched pep found file line least two comment file line least two comment line blank found line blank line found line blank found line blank found line blank found line block comment start line block comment start line blank line line blank found line blank found line blank found line blank found line blank found line blank found line end file think resolved black,issue,negative,negative,neutral,neutral,negative,negative
1120503855,Thanks for opening this PR! Nice work!,thanks opening nice work,issue,positive,positive,positive,positive,positive,positive
1120200554,"Hello @geewiz94! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:



* In the file [`lib/gpu_stats/apple_silicon.py`](https://github.com/deepfakes/faceswap/blob/948f0fb82e4f6b32dd065d0b3e07090cf207470b/lib/gpu_stats/apple_silicon.py):

> [Line 86:100](https://github.com/deepfakes/faceswap/blob/948f0fb82e4f6b32dd065d0b3e07090cf207470b/lib/gpu_stats/apple_silicon.py#L86): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (105 > 99 characters)
> [Line 113:100](https://github.com/deepfakes/faceswap/blob/948f0fb82e4f6b32dd065d0b3e07090cf207470b/lib/gpu_stats/apple_silicon.py#L113): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (103 > 99 characters)









##### Comment last updated at 2022-05-11 23:34:04 UTC",hello thanks checked touched pep found file line line long line line long comment last,issue,negative,positive,neutral,neutral,positive,positive
1117981498,"I'm sorry it has taken me so long to get around to this. Life has got in the way. I'm closing this PR as it currently conflicts, but I would welcome a PR updating our Docker (which I will look to merge quickly).",sorry taken long get around life got way currently would welcome docker look merge quickly,issue,negative,positive,positive,positive,positive,positive
1117943871,Sys exit is not standard and it's completely unnecessary.,exit standard completely unnecessary,issue,negative,negative,negative,negative,negative,negative
1114026051,"Hello @torzdf! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:









































There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: 

##### Comment last updated at 2022-05-02 13:15:44 UTC",hello thanks checked touched pep found currently pep pull request comment last,issue,negative,positive,neutral,neutral,positive,positive
1087390593,Resolved via private message. Most likely a blocked shared IP address.,resolved via private message likely blocked address,issue,negative,neutral,neutral,neutral,neutral,neutral
1082069786,"@daniellivingston I did some training tests with the various models: All of them seem to work, except for Phaze-A with the Stojo preset, where the images turn completely red after a few iterations. I think this is due to the selected Encoder Architecture not being fs_original. I tried changing this line:
https://github.com/daniellivingston/faceswap/blob/b76879af13bba54afbbe797d8ac5d12398820e27/plugins/train/model/phaze_a.py#L8
to `from tensorflow.keras import applications as kapp`.
Training then runs but doesn't seem to be going anywhere (again, red images).",training various seem work except preset turn completely red think due selected architecture tried line import kapp training seem going anywhere red,issue,negative,negative,neutral,neutral,negative,negative
1075940868,"Is this still not fixed? Basically, when creating the 'loss' array which is a 2-dimensional array (array for arrays that contain the loss measurement for both face A and face B), the loss for one of the faces is missing, and numpy does not allow the creation of an array of arrays of differing lengths.

I'm not the best programmer, and I just created a loop that removes an array if its length is not two, but I assume that as the session goes on, the length of the array will increase and this method will not be the most efficient. Probably better to fix it at the source and stop putting a list of size one in. I think this is caused by the iteration not being done yet, and hence missing the result for the second face. Not sure though, but yeah, my temporary fix is fine for now. O(n).",still fixed basically array array array contain loss measurement face face loss one missing allow creation array best programmer loop array length two assume session go length array increase method efficient probably better fix source stop list size one think iteration done yet hence missing result second face sure though yeah temporary fix fine,issue,positive,positive,positive,positive,positive,positive
1075031236,"@daniellivingston Very nice! I tried your fork and can confirm that extract/train and also conversion is working! I think we need to check which dependencies are actually needed for installation on a fresh system. But this is great for running some benchmarks and tests!

Spotted an instance where pynvx is still being used, but that's a quick fix:
https://github.com/daniellivingston/faceswap/pull/1/files",nice tried fork confirm also conversion working think need check actually installation fresh system great running spotted instance still used quick fix,issue,positive,positive,positive,positive,positive,positive
1073071361,"@geewiz94 I think we've been replicating each other's work. Here is my fork: https://github.com/deepfakes/faceswap/compare/master...daniellivingston:dev/livingston

I have GPU support working (verified w/ system monitor). I don't know how stable things are at the moment, but I am able to extract and train.",think work fork support working system monitor know stable moment able extract train,issue,positive,positive,positive,positive,positive,positive
1057522155,"I also encountered this problem,thank you very much.",also problem thank much,issue,negative,positive,positive,positive,positive,positive
1039825461,"You need to either allow permissions in the folder faceswap is installed in or specify the logfile locations with ` -LF LOGFILE, --logfile LOGFILE`",need either allow folder specify,issue,negative,neutral,neutral,neutral,neutral,neutral
1035022723,"If I want to modify parameter value range, or add some customized parameter to 'Configure Settings' GUI, where the code is? (specific `tkinter` code (I guess, or `wxpython` or other GUI?))",want modify parameter value range add parameter code specific code guess,issue,negative,neutral,neutral,neutral,neutral,neutral
1033995374,"You're still being very unclear, but here is my best guess as to your question: You want to add a new config option and have it show up in the GUI.

The GUI is generated from config and CLI.  There is no need to specifically modify the GUI to add new functionality.  If you add it to the config or CLI it gets automatically added to the GUI.  Here is a link to what generates the options displayed in your screenshot: https://github.com/deepfakes/faceswap/blob/c900036a4ecbb77ee4ef7e0fa12abe77d117a5b0/plugins/extract/align/fan_defaults.py

If this isn't your question, please describe exactly what you're trying to accomplish and maybe we can understand your needs.",still unclear best guess question want add new option show need specifically modify add new functionality add automatically added link displayed question please describe exactly trying accomplish maybe understand need,issue,positive,positive,positive,positive,positive,positive
1033478738,I want to understanding the parameter how to pass from GUI.,want understanding parameter pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1033178936,Can you be a bit more specific about what you're trying to achieve?,bit specific trying achieve,issue,negative,neutral,neutral,neutral,neutral,neutral
1029944589,"pip install numpy --upgrade    I tried this, it works",pip install upgrade tried work,issue,negative,neutral,neutral,neutral,neutral,neutral
1026570361,"I got a similar problem. Here's the crash_report:
```
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x0000024500A78BE0>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x0000024500A615B0>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x0000024500A615B0>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000245007CF6A0>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000245007CF670>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000245007CF1C0>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Importing 'tf.keras' as keras for backend: 'nvidia'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\faceswap\faceswap\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\python38.zip\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\DLLs\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow_core\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Scanning: 'D:\anaconda\envs\deep\lib\site-packages\tensorflow\python\keras\api\_v2' for 'keras'
02/01/2022 15:37:25 MainProcess     MainThread                     utils           find_spec                      DEBUG    Found spec: ModuleSpec(name='keras', loader=<_frozen_importlib_external.SourceFileLoader object at 0x00000244DD9A6940>, origin='D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras\\__init__.py', submodule_search_locations=['D:\\anaconda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v2\\keras'])
02/01/2022 15:37:25 MainProcess     MainThread                     launcher        _test_for_tf_version           DEBUG    Installed Tensorflow Version: 2.6
02/01/2022 15:37:26 MainProcess     MainThread                     queue_manager   __init__                       DEBUG    Initializing QueueManager
02/01/2022 15:37:26 MainProcess     MainThread                     queue_manager   __init__                       DEBUG    Initialized QueueManager
Traceback (most recent call last):
  File ""D:\faceswap\faceswap\lib\cli\launcher.py"", line 180, in execute_script
    script = self._import_script()
  File ""D:\faceswap\faceswap\lib\cli\launcher.py"", line 46, in _import_script
    module = import_module(mod)
  File ""D:\anaconda\envs\deep\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""D:\faceswap\faceswap\scripts\extract.py"", line 14, in <module>
    from scripts.fsmedia import Alignments, PostProcess, finalize
  File ""D:\faceswap\faceswap\scripts\fsmedia.py"", line 18, in <module>
    from lib.face_filter import FaceFilter as FilterFunc
  File ""D:\faceswap\faceswap\lib\face_filter.py"", line 7, in <module>
    from lib.vgg_face import VGGFace
  File ""D:\faceswap\faceswap\lib\vgg_face.py"", line 15, in <module>
    from fastcluster import linkage
  File ""D:\anaconda\envs\deep\lib\site-packages\fastcluster.py"", line 37, in <module>
    from _fastcluster import linkage_wrap, linkage_vector_wrap
ImportError: numpy.core.multiarray failed to import

============ System Information ============
encoding:            cp936
git_branch:          master
git_commits:         183aee3 bugfix: Pin pynvml to <11.515
gpu_cuda:            11.6
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: NVIDIA GeForce GTX 1050 Ti
gpu_devices_active:  GPU_0
gpu_driver:          511.23
gpu_vram:            GPU_0: 4096MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.19041-SP0
os_release:          10
py_command:          D:\faceswap\faceswap\faceswap.py extract -i D:/faceswap/faceswap/data/蔡徐坤原版无特效打篮球视频.mp4 -o D:/faceswap/faceswap/data/caixukun -D s3fd -A fan -nm none -rf 0 -min 0 -l 0.4 -sz 512 -een 1 -si 0 -L INFO -gui
py_conda_version:    conda 4.11.0
py_implementation:   CPython
py_version:          3.8.12
py_virtual_env:      True
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 165 Stepping 3, GenuineIntel
sys_ram:             Total: 16253MB, Available: 9765MB, Used: 6488MB, Free: 9765MB

=============== Pip Packages ===============
absl-py==0.15.0
addict==2.4.0
argon2-cffi @ file:///C:/ci/argon2-cffi_1613037959010/work
astunparse==1.6.3
async-generator @ file:///home/ktietz/src/ci/async_generator_1611927993394/work
attrs @ file:///opt/conda/conda-bld/attrs_1642510447205/work
autopep8 @ file:///opt/conda/conda-bld/autopep8_1639166893812/work
backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work
basicsr==1.3.4.9
bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work
cachetools==4.2.4
certifi==2021.10.8
cffi @ file:///C:/ci/cffi_1636542074879/work
charset-normalizer==2.0.10
clang==5.0
colorama @ file:///tmp/build/80754af9/colorama_1607707115595/work
cycler==0.11.0
debugpy @ file:///C:/ci/debugpy_1637073815078/work
decorator @ file:///tmp/build/80754af9/decorator_1632776554403/work
defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work
entrypoints==0.3
facexlib==0.2.1.1
fastcluster==1.2.4
ffmpy==0.2.3
filterpy==1.4.5
flatbuffers==1.12
fonttools==4.29.0
future==0.18.2
gast==0.4.0
gfpgan==0.2.4
google-auth==1.35.0
google-auth-oauthlib==0.4.6
google-pasta==0.2.0
grpcio==1.43.0
h5py==3.1.0
idna==3.3
imageio==2.14.1
imageio-ffmpeg==0.4.5
importlib-metadata @ file:///C:/ci/importlib-metadata_1638543108096/work
ipykernel @ file:///C:/ci/ipykernel_1633545574250/work/dist/ipykernel-6.4.1-py3-none-any.whl
ipython @ file:///C:/ci/ipython_1635944310712/work
ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work
ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1634143127070/work
jedi @ file:///C:/ci/jedi_1611315808330/work
Jinja2 @ file:///tmp/build/80754af9/jinja2_1635780242639/work
joblib==1.1.0
jsonschema @ file:///Users/ktietz/demo/mc3/conda-bld/jsonschema_1630511932244/work
jupyter==1.0.0
jupyter-client @ file:///tmp/build/80754af9/jupyter_client_1640335223713/work
jupyter-console @ file:///tmp/build/80754af9/jupyter_console_1616615302928/work
jupyter-core @ file:///C:/ci/jupyter_core_1636537213213/work
jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work
jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/work
keras==2.6.0
Keras-Preprocessing==1.1.2
kiwisolver==1.3.2
llvmlite==0.38.0
lmdb==1.3.0
Markdown==3.3.6
MarkupSafe @ file:///C:/ci/markupsafe_1621528314575/work
matplotlib==3.2.2
matplotlib-inline @ file:///tmp/build/80754af9/matplotlib-inline_1628242447089/work
mistune==0.8.4
mkl-fft==1.3.1
mkl-random @ file:///C:/ci/mkl_random_1626186184278/work
mkl-service==2.4.0
MouseInfo==0.1.3
mss==6.1.0
nbclient @ file:///tmp/build/80754af9/nbclient_1614364831625/work
nbconvert @ file:///C:/ci/nbconvert_1624479163777/work
nbformat @ file:///tmp/build/80754af9/nbformat_1617383369282/work
nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1613680548246/work
networkx==2.6.3
notebook @ file:///C:/ci/notebook_1637143794296/work
numba==0.55.0
numpy==1.19.5
nvidia-ml-py==11.495.46
oauthlib==3.1.1
olefile @ file:///Users/ktietz/demo/mc3/conda-bld/olefile_1629805411829/work
opencv-python==4.5.5.62
opt-einsum==3.3.0
packaging @ file:///tmp/build/80754af9/packaging_1637314298585/work
pandas==1.4.0
pandocfilters @ file:///C:/ci/pandocfilters_1605102497129/work
parso @ file:///opt/conda/conda-bld/parso_1641458642106/work
pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work
Pillow==8.4.0
prometheus-client @ file:///tmp/build/80754af9/prometheus_client_1637050397234/work
prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1633440160888/work
protobuf==3.19.3
psutil==5.9.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
PyAutoGUI==0.9.53
pycodestyle @ file:///tmp/build/80754af9/pycodestyle_1636635402688/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
PyDirectInput==1.0.4
PyGetWindow==0.0.9
Pygments @ file:///tmp/build/80754af9/pygments_1629234116488/work
PyMsgBox==1.0.9
pyparsing @ file:///tmp/build/80754af9/pyparsing_1635766073266/work
pyperclip==1.8.2
PyRect==0.1.4
pyrsistent @ file:///C:/ci/pyrsistent_1636111468851/work
PyScreeze==0.1.28
python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work
pytweening==1.0.4
pytz==2021.3
PyWavelets==1.2.0
pywin32==302
pywinpty==0.5.7
PyYAML==6.0
pyzmq @ file:///C:/ci/pyzmq_1638435185959/work
qtconsole @ file:///tmp/build/80754af9/qtconsole_1632739723211/work
QtPy @ file:///tmp/build/80754af9/qtpy_1629397026935/work
-e git+https://github.com/xinntao/Real-ESRGAN.git@01aeba2f7ae859baf08c518c539d060a80e6c3db#egg=realesrgan
requests==2.27.1
requests-oauthlib==1.3.0
rsa==4.8
scikit-image==0.19.1
scikit-learn==1.0.2
scipy==1.7.3
seaborn==0.11.2
Send2Trash @ file:///tmp/build/80754af9/send2trash_1632406701022/work
sip==4.19.13
six==1.15.0
tb-nightly==2.9.0a20220124
tensorboard==2.6.0
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow-estimator==2.6.0
tensorflow-gpu==2.6.2
termcolor==1.1.0
terminado==0.9.4
testpath @ file:///tmp/build/80754af9/testpath_1624638946665/work
thop==0.0.31.post2005241907
threadpoolctl==3.1.0
tifffile==2021.11.2
toml @ file:///tmp/build/80754af9/toml_1616166611790/work
torch==1.10.1
torchaudio==0.10.1
torchvision==0.11.2
tornado @ file:///C:/ci/tornado_1606942392901/work
tqdm==4.62.3
traitlets @ file:///tmp/build/80754af9/traitlets_1636710298902/work
typing-extensions==3.7.4.3
urllib3==1.26.8
wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work
webencodings==0.5.1
Werkzeug==2.0.2
widgetsnbextension==3.5.1
wincertstore==0.2
wrapt==1.12.1
yapf==0.32.0
zipp @ file:///opt/conda/conda-bld/zipp_1641824620731/work

============== Conda Packages ==============
# packages in environment at D:\anaconda\envs\deep:
#
# Name                    Version                   Build  Channel
absl-py                   0.15.0                   pypi_0    pypi
addict                    2.4.0                    pypi_0    pypi
argon2-cffi               20.1.0           py38h2bbff1b_1    defaults
astunparse                1.6.3                    pypi_0    pypi
async_generator           1.10               pyhd3eb1b0_0    defaults
attrs                     21.4.0             pyhd3eb1b0_0    defaults
autopep8                  1.6.0              pyhd3eb1b0_0    defaults
backcall                  0.2.0              pyhd3eb1b0_0    defaults
basicsr                   1.3.4.9                  pypi_0    pypi
blas                      1.0                         mkl    defaults
bleach                    4.1.0              pyhd3eb1b0_0    defaults
ca-certificates           2021.10.26           haa95532_4    defaults
cachetools                4.2.4                    pypi_0    pypi
certifi                   2021.10.8        py38haa95532_2    defaults
cffi                      1.15.0           py38h2bbff1b_0    defaults
charset-normalizer        2.0.10                   pypi_0    pypi
clang                     5.0                      pypi_0    pypi
colorama                  0.4.4              pyhd3eb1b0_0    defaults
cudatoolkit               11.3.1               h59b6b97_2    defaults
cudnn                     8.2.1                cuda11.3_0    defaults
cycler                    0.11.0                   pypi_0    pypi
debugpy                   1.5.1            py38hd77b12b_0    defaults
decorator                 5.1.0              pyhd3eb1b0_0    defaults
defusedxml                0.7.1              pyhd3eb1b0_0    defaults
entrypoints               0.3                      py38_0    defaults
facexlib                  0.2.1.1                  pypi_0    pypi
fastcluster               1.2.4                    pypi_0    pypi
ffmpy                     0.2.3                    pypi_0    pypi
filterpy                  1.4.5                    pypi_0    pypi
flatbuffers               1.12                     pypi_0    pypi
fonttools                 4.29.0                   pypi_0    pypi
freetype                  2.10.4               hd328e21_0    defaults
future                    0.18.2                   pypi_0    pypi
gast                      0.4.0                    pypi_0    pypi
gfpgan                    0.2.4                    pypi_0    pypi
google-auth               1.35.0                   pypi_0    pypi
google-auth-oauthlib      0.4.6                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.43.0                   pypi_0    pypi
h5py                      3.1.0                    pypi_0    pypi
icu                       58.2                 ha925a31_3    defaults
idna                      3.3                      pypi_0    pypi
imageio                   2.14.1                   pypi_0    pypi
imageio-ffmpeg            0.4.5                    pypi_0    pypi
importlib-metadata        4.8.2            py38haa95532_0    defaults
importlib_metadata        4.8.2                hd3eb1b0_0    defaults
intel-openmp              2021.4.0          haa95532_3556    defaults
ipykernel                 6.4.1            py38haa95532_1    defaults
ipython                   7.29.0           py38hd4e2768_0    defaults
ipython_genutils          0.2.0              pyhd3eb1b0_1    defaults
ipywidgets                7.6.5              pyhd3eb1b0_1    defaults
jedi                      0.18.0           py38haa95532_1    defaults
jinja2                    3.0.2              pyhd3eb1b0_0    defaults
joblib                    1.1.0                    pypi_0    pypi
jpeg                      9d                   h2bbff1b_0    defaults
jsonschema                3.2.0              pyhd3eb1b0_2    defaults
jupyter                   1.0.0                    py38_7    defaults
jupyter_client            7.1.0              pyhd3eb1b0_0    defaults
jupyter_console           6.4.0              pyhd3eb1b0_0    defaults
jupyter_core              4.9.1            py38haa95532_0    defaults
jupyterlab_pygments       0.1.2                      py_0    defaults
jupyterlab_widgets        1.0.0              pyhd3eb1b0_1    defaults
keras                     2.6.0                    pypi_0    pypi
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.3.2                    pypi_0    pypi
libpng                    1.6.37               h2a8f88b_0    defaults
libtiff                   4.2.0                hd0e1b90_0    defaults
libuv                     1.40.0               he774522_0    defaults
libwebp                   1.2.0                h2bbff1b_0    defaults
llvmlite                  0.38.0                   pypi_0    pypi
lmdb                      1.3.0                    pypi_0    pypi
lz4-c                     1.9.3                h2bbff1b_1    defaults
m2w64-gcc-libgfortran     5.3.0                         6    defaults
m2w64-gcc-libs            5.3.0                         7    defaults
m2w64-gcc-libs-core       5.3.0                         7    defaults
m2w64-gmp                 6.1.0                         2    defaults
m2w64-libwinpthread-git   5.0.0.4634.697f757               2    defaults
markdown                  3.3.6                    pypi_0    pypi
markupsafe                2.0.1            py38h2bbff1b_0    defaults
matplotlib                3.2.2                    pypi_0    pypi
matplotlib-inline         0.1.2              pyhd3eb1b0_2    defaults
mistune                   0.8.4           py38he774522_1000    defaults
mkl                       2021.4.0           haa95532_640    defaults
mkl-service               2.4.0            py38h2bbff1b_0    defaults
mkl_fft                   1.3.1            py38h277e83a_0    defaults
mkl_random                1.2.2            py38hf11a4ad_0    defaults
mouseinfo                 0.1.3                    pypi_0    pypi
mss                       6.1.0                    pypi_0    pypi
msys2-conda-epoch         20160418                      1    defaults
nbclient                  0.5.3              pyhd3eb1b0_0    defaults
nbconvert                 6.1.0            py38haa95532_0    defaults
nbformat                  5.1.3              pyhd3eb1b0_0    defaults
nest-asyncio              1.5.1              pyhd3eb1b0_0    defaults
networkx                  2.6.3                    pypi_0    pypi
notebook                  6.4.6            py38haa95532_0    defaults
numba                     0.55.0                   pypi_0    pypi
numpy                     1.19.5                   pypi_0    pypi
nvidia-ml-py              11.495.46                pypi_0    pypi
oauthlib                  3.1.1                    pypi_0    pypi
olefile                   0.46               pyhd3eb1b0_0    defaults
opencv-python             4.5.5.62                 pypi_0    pypi
openssl                   1.1.1m               h2bbff1b_0    defaults
opt-einsum                3.3.0                    pypi_0    pypi
packaging                 21.3               pyhd3eb1b0_0    defaults
pandas                    1.4.0                    pypi_0    pypi
pandocfilters             1.4.3            py38haa95532_1    defaults
parso                     0.8.3              pyhd3eb1b0_0    defaults
pickleshare               0.7.5           pyhd3eb1b0_1003    defaults
pillow                    8.4.0            py38hd45dc43_0    defaults
pip                       21.2.2           py38haa95532_0    defaults
prometheus_client         0.12.0             pyhd3eb1b0_0    defaults
prompt-toolkit            3.0.20             pyhd3eb1b0_0    defaults
prompt_toolkit            3.0.20               hd3eb1b0_0    defaults
protobuf                  3.19.3                   pypi_0    pypi
psutil                    5.9.0                    pypi_0    pypi
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pyautogui                 0.9.53                   pypi_0    pypi
pycodestyle               2.8.0              pyhd3eb1b0_0    defaults
pycparser                 2.21               pyhd3eb1b0_0    defaults
pydirectinput             1.0.4                    pypi_0    pypi
pygetwindow               0.0.9                    pypi_0    pypi
pygments                  2.10.0             pyhd3eb1b0_0    defaults
pymsgbox                  1.0.9                    pypi_0    pypi
pyparsing                 3.0.4              pyhd3eb1b0_0    defaults
pyperclip                 1.8.2                    pypi_0    pypi
pyqt                      5.9.2            py38ha925a31_4    defaults
pyrect                    0.1.4                    pypi_0    pypi
pyrsistent                0.18.0           py38h196d8e1_0    defaults
pyscreeze                 0.1.28                   pypi_0    pypi
python                    3.8.12               h6244533_0    defaults
python-dateutil           2.8.2              pyhd3eb1b0_0    defaults
pytorch                   1.10.1          py3.8_cuda11.3_cudnn8_0    pytorch
pytorch-mutex             1.0                        cuda    pytorch
pytweening                1.0.4                    pypi_0    pypi
pytz                      2021.3                   pypi_0    pypi
pywavelets                1.2.0                    pypi_0    pypi
pywin32                   302              py38h827c3e9_1    defaults
pywinpty                  0.5.7                    py38_0    defaults
pyyaml                    6.0                      pypi_0    pypi
pyzmq                     22.3.0           py38hd77b12b_2    defaults
qt                        5.9.7            vc14h73c81de_0    defaults
qtconsole                 5.1.1              pyhd3eb1b0_0    defaults
qtpy                      1.10.0             pyhd3eb1b0_0    defaults
realesrgan                0.2.3.0                   dev_0    <develop>
requests                  2.27.1                   pypi_0    pypi
requests-oauthlib         1.3.0                    pypi_0    pypi
rsa                       4.8                      pypi_0    pypi
scikit-image              0.19.1                   pypi_0    pypi
scikit-learn              1.0.2                    pypi_0    pypi
scipy                     1.7.3                    pypi_0    pypi
seaborn                   0.11.2                   pypi_0    pypi
send2trash                1.8.0              pyhd3eb1b0_1    defaults
setuptools                58.0.4           py38haa95532_0    defaults
sip                       4.19.13          py38ha925a31_0    defaults
six                       1.15.0                   pypi_0    pypi
sqlite                    3.37.0               h2bbff1b_0    defaults
tb-nightly                2.9.0a20220124           pypi_0    pypi
tensorboard               2.6.0                    pypi_0    pypi
tensorboard-data-server   0.6.1                    pypi_0    pypi
tensorboard-plugin-wit    1.8.1                    pypi_0    pypi
tensorflow-estimator      2.6.0                    pypi_0    pypi
tensorflow-gpu            2.6.2                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.9.4            py38haa95532_0    defaults
testpath                  0.5.0              pyhd3eb1b0_0    defaults
thop                      0.0.31-2005241907          pypi_0    pypi
threadpoolctl             3.1.0                    pypi_0    pypi
tifffile                  2021.11.2                pypi_0    pypi
tk                        8.6.11               h2bbff1b_0    defaults
toml                      0.10.2             pyhd3eb1b0_0    defaults
torchaudio                0.10.1               py38_cu113    pytorch
torchvision               0.11.2               py38_cu113    pytorch
tornado                   6.1              py38h2bbff1b_0    defaults
tqdm                      4.62.3                   pypi_0    pypi
traitlets                 5.1.1              pyhd3eb1b0_0    defaults
typing-extensions         3.7.4.3                  pypi_0    pypi
urllib3                   1.26.8                   pypi_0    pypi
vc                        14.2                 h21ff451_1    defaults
vs2015_runtime            14.27.29016          h5e58377_2    defaults
wcwidth                   0.2.5              pyhd3eb1b0_0    defaults
webencodings              0.5.1                    py38_1    defaults
werkzeug                  2.0.2                    pypi_0    pypi
wheel                     0.37.1                   pypi_0    pypi
widgetsnbextension        3.5.1                    py38_0    defaults
wincertstore              0.2              py38haa95532_2    defaults
winpty                    0.4.3                         4    defaults
wrapt                     1.12.1                   pypi_0    pypi
xz                        5.2.5                h62dcd97_0    defaults
yapf                      0.32.0                   pypi_0    pypi
zipp                      3.7.0              pyhd3eb1b0_0    defaults
zlib                      1.2.11               h8cc25b3_4    defaults
zstd                      1.4.9                h19a0ad4_0    defaults

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0

[scaling.sharpen]
method:                   none
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto
skip_mux:                 False

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               12

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
scalefactor:              0.709
batch-size:               8
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7

[detect.s3fd]
confidence:               70
batch-size:               4

[mask.bisenet_fp]
batch-size:               8
include_ears:             False
include_hair:             False
include_glasses:          True

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.vgg_obstructed]
batch-size:               2

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

--------- train.ini ---------

[global]
centering:                face
coverage:                 87.5
icnr_init:                False
conv_aware_init:          False
optimizer:                adam
learning_rate:            5e-05
epsilon_exponent:         -7
reflect_padding:          False
allow_growth:             False
mixed_precision:          False
nan_protection:           True
convert_batchsize:        16

[global.loss]
loss_function:            ssim
mask_loss_function:       mse
l2_reg_term:              100
eye_multiplier:           3
mouth_multiplier:         2
penalized_mask_loss:      True
mask_type:                extended
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False

[model.dfaker]
output_size:              128

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.dlight]
features:                 best
details:                  good
output_size:              256

[model.original]
lowmem:                   False

[model.phaze_a]
output_size:              128
shared_fc:                none
enable_gblock:            True
split_fc:                 True
split_gblock:             False
split_decoders:           False
enc_architecture:         fs_original
enc_scaling:              40
enc_load_weights:         True
bottleneck_type:          dense
bottleneck_norm:          none
bottleneck_size:          1024
bottleneck_in_encoder:    True
fc_depth:                 1
fc_min_filters:           1024
fc_max_filters:           1024
fc_dimensions:            4
fc_filter_slope:          -0.5
fc_dropout:               0.0
fc_upsampler:             upsample2d
fc_upsamples:             1
fc_upsample_filters:      512
fc_gblock_depth:          3
fc_gblock_min_nodes:      512
fc_gblock_max_nodes:      512
fc_gblock_filter_slope:   -0.5
fc_gblock_dropout:        0.0
dec_upscale_method:       subpixel
dec_norm:                 none
dec_min_filters:          64
dec_max_filters:          512
dec_filter_slope:         -0.45
dec_res_blocks:           1
dec_output_kernel:        5
dec_gaussian:             True
dec_skip_last_residual:   True
freeze_layers:            keras_encoder
load_layers:              encoder
fs_original_depth:        4
fs_original_min_filters:  128
fs_original_max_filters:  1024
mobilenet_width:          1.0
mobilenet_depth:          1
mobilenet_dropout:        0.001

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```",got similar problem scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning scanning found spec object launcher version recent call last file line script file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import finalize file line module import file line module import file line module import linkage file line module import import system information master pin global version found check ti extract fan none true family model stepping total available used free pip file file file file file bleach file file file file decorator file file file file file file file file jinja file file file file file file file file file file file file file file notebook file file file file file file file file file file file file file file file file file file file post file tornado file file file file environment name version build channel addict blas bleach clang cycler decorator future gast jinja markdown notebook pillow pip python develop sip six tornado wheel clip true true contrast brightness threshold type distance radius type threshold erosion method none amount radius threshold container preset medium tune none profile auto level auto false loop false format false format false optimize false true global false confidence confidence false false true global false tab extract font default prompt true global centering face coverage false false false false false true true extended false false true architecture false best good false none true true false false true dense none true none true true false true false,issue,negative,negative,neutral,neutral,negative,negative
1018821251,"Thousands of users have installed Faceswap under Windows 10 using the installer without the reporting the issue you have.  Please follow the install guide: https://forum.faceswap.dev/viewtopic.php?f=4&t=20.  Do not run the installer as an Administrator.  The default install directory is C:\Users\ ..... \faceswap, where .... represents the user name.  You should not be attempting to install faceswap to C:\Programme, or C:\Program Files.   If that's happening, then the issue is with your computer setup, not the installer.",installer without issue please follow install guide run installer administrator default install directory user name install happening issue computer setup installer,issue,negative,neutral,neutral,neutral,neutral,neutral
1014218221,"Do not attempt to revive closed issues.

Please view the forum for up to date documentation and guides to using faceswap.",attempt revive closed please view forum date documentation,issue,positive,negative,neutral,neutral,negative,negative
1014215773,"> You need alignments to continue. See https://github.com/deepfakes/faceswap/blob/master/USAGE.md for the process. You can also come to our Discord server at https://discord.gg/FC54sYg if you have other questions about how to use the software.

In the docs it says
`An alignments.json file will also be created and saved into your input folder. This file contains information about each of the faces that will be used by FaceSwap`
but only alignments.fsa was created...",need continue see process also come discord server use file also saved input folder file information used,issue,negative,neutral,neutral,neutral,neutral,neutral
1013864801,"> You need alignments to continue. See https://github.com/deepfakes/faceswap/blob/master/USAGE.md for the process. You can also come to our Discord server at https://discord.gg/FC54sYg if you have other questions about how to use the software.

Only `alignments.fsa` was created,no `alignment.json` file created after extract faces from video or images..and convert with the same errror:.
```
No alignment found for video-frame-1863.png, skipping


No alignment found for video-frame-18630.png, skipping


No alignment found for video-frame-18631.png, skipping


No alignment found for video-frame-18632.png, skipping


No alignment found for video-frame-18633.png, skipping


No alignment found for video-frame-18634.png, skipping
```

How to solve that..?",need continue see process also come discord server use file extract video convert alignment found skipping alignment found skipping alignment found skipping alignment found skipping alignment found skipping alignment found skipping solve,issue,negative,neutral,neutral,neutral,neutral,neutral
1013858018,"I have done some more tests and it is a problem in the installer, which repeatably borks the environment unter certain circumstances.

As I said, I'm running on a german Windows 10.
The german Windows 10 has a directory `C:\Programme`, which is an alias for `C:\Program Files`, the actual directory that is hidden on german Windows versions.

Whenever I use `C:\Programme\faceswap` as target directory of the installation, I get the above error. When I install to `C:\Program Files\faceswap`, it works. It also works when I install to `C:\Users\Admin\faceswap`.",done problem installer environment certain said running german german directory alias actual directory hidden german whenever use target directory installation get error install work also work install,issue,negative,positive,neutral,neutral,positive,positive
1013767732,"Your environment is borked. There is no missing dependency. Convert is a part of faceswap.

As this is an issue with your setup and not with faceswap, I am closing this issue.",environment missing dependency convert part issue setup issue,issue,negative,negative,negative,negative,negative,negative
999745320,Issues are for code bugs.  For any other topics please visit our Discord or Forums.,code please visit discord,issue,negative,neutral,neutral,neutral,neutral,neutral
998373707,"You could try my fork. I only managed to get CPU training working (but no extract/convert and GPU training doesn't seem to work):
https://github.com/geewiz94/faceswap

Some notes on my progress in this thread, but for now I'm mostly waiting for Tensorflow 2.7 or Python 3.9 support:
https://forum.faceswap.dev/viewtopic.php?f=16&t=1830",could try fork get training working training seem work progress thread mostly waiting python support,issue,positive,positive,positive,positive,positive,positive
991826038,"The issues page is for code bugs.  For anything else such as this request, please visit our forums at http://forum.faceswap.dev/

That said, you can delete them en-mass using your file manager.  The manual tool is meant for minor tweaks, batch solutions are done better in other ways.  See the Guides in the forum for advice on the best way to do things.",page code anything else request please visit said delete file manager manual tool meant minor batch done better way see forum advice best way,issue,positive,positive,positive,positive,positive,positive
991825772,"Like Torzdf said in https://github.com/deepfakes/faceswap/issues/1143#issuecomment-871276880 We cannot support what we don't have access to.  If anyone wishes to donate an M1 device, we might be able to support it but we cannot make any promises.",like said support access anyone donate device might able support make,issue,positive,positive,positive,positive,positive,positive
986235156,"Hmmm, this issue appears entirely unrelated to clicking on the graph tab. The GUI code does not touch the base faceswap code in any way. The error you are seeing is being raised when python is trying to print the latest loss values. This is some very simple code and should not be failing in any way, indeed it has never failed here before to the best of my knowledge.

This suggests that the issue is in your setup somewhere, although I couldn't say where. Maybe running out of disk space?

Either way, I am closing this unless this issue is reported elsewhere...

The fact that your crash report cannot get your installed conda version, nor list the packages would also concern me, so I would do the following in the first instance and try again:

https://forum.faceswap.dev/app.php/faqpage?sid=12454a577bd3fc94b471dfa36ddcdcbe#f1r1

",issue entirely unrelated graph tab code touch base code way error seeing raised python trying print latest loss simple code failing way indeed never best knowledge issue setup somewhere although could say maybe running disk space either way unless issue elsewhere fact crash report get version list would also concern would following first instance try,issue,negative,negative,neutral,neutral,negative,negative
980549649,"It's been a *long* time since I wrote that code, but on the face of it, I think you may be correct. I will need to do some testing to make sure though. Thanks for the heads up.",long time since wrote code face think may correct need testing make sure though thanks,issue,positive,positive,positive,positive,positive,positive
980236822,"The Phaze-A model will do exactly what you want. It already has an IAE preset, so you can load that and tweak from there:

https://forum.faceswap.dev/viewtopic.php?p=5367#p5367",model exactly want already preset load tweak,issue,negative,positive,positive,positive,positive,positive
979901309,"@bryanlyon - apologies that a further issue was opened here. This was not by intention, I will investigate what went wrong here.",issue intention investigate went wrong,issue,negative,negative,negative,negative,negative,negative
979676247,"And further, quit spamming repos like this.  We know you've been told to stop.  We've even told you the last time you spammed us.  Do not do this again.",quit like know told stop even told last time u,issue,negative,neutral,neutral,neutral,neutral,neutral
976205323,"Faceswap does not work with individual images.  See the FAQ item at https://forum.faceswap.dev/app.php/faqpage#f0r6

Also note that the issues tab is only for code bugs.  For any information or help on running Faceswap please post in the forum or visit our Discord.",work individual see item also note tab code information help running please post forum visit discord,issue,negative,neutral,neutral,neutral,neutral,neutral
972786480,Thanks for the PR. Will review when I get a chance.,thanks review get chance,issue,positive,positive,positive,positive,positive,positive
964114140,This shouldn't be necessary and seems to be an issue specific to your system. Thanks for the heads up though.,necessary issue specific system thanks though,issue,negative,positive,neutral,neutral,positive,positive
951519404,"I want to get a other version, how to uninstall this one?",want get version one,issue,negative,neutral,neutral,neutral,neutral,neutral
925539565,"I can confirm the reproduction steps. 

```
Exception in Tkinter callback
TypeError: float() argument must be a string or a number, not 'list'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\ExtProgram\anaconda3\envs\faceswap\lib\tkinter\__init__.py"", line 1892, in __call__
    return self.func(*args)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display.py"", line 186, in _on_tab_change
    selected_object.on_tab_select()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_command.py"", line 254, in on_tab_select
    self._update_page()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_page.py"", line 273, in _update_page
    self.load_display()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_page.py"", line 285, in load_display
    self.display_item_process()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_command.py"", line 388, in display_item_process
    for key in self.display_item.get_loss_keys(Session.session_ids[-1])
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\stats.py"", line 243, in get_loss_keys
    for sess_id, logs in self._tb_logs.get_loss(session_id=session_id).items()}
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 466, in get_loss
    self._check_cache(idx)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 442, in _check_cache
    self._cache_data(session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 428, in _cache_data
    parser.cache_events(session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 584, in cache_events
    self._cache.cache_data(session_id, data, self._loss_labels, is_live=self._live_data)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 169, in cache_data
    timestamps, loss = self._to_numpy(data, is_live)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 210, in _to_numpy
    times, loss = (np.array(times, dtype=""float64""), np.array(loss, dtype=""float32""))
ValueError: setting an array element with a sequence.
Exception in Tkinter callback
TypeError: float() argument must be a string or a number, not 'list'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\ExtProgram\anaconda3\envs\faceswap\lib\tkinter\__init__.py"", line 1892, in __call__
    return self.func(*args)
  File ""C:\ExtProgram\anaconda3\envs\faceswap\lib\tkinter\__init__.py"", line 814, in callit
    func(*args)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_analysis.py"", line 190, in <lambda>
    self.after(1000, lambda msg=message: self._set_session_summary(msg))
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_analysis.py"", line 196, in _set_session_summary
    result = self._thread.get_result()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\utils.py"", line 1230, in get_result
    raise self.err[1].with_traceback(self.err[2])
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\utils.py"", line 1201, in run
    retval = self._target(*self._args, **self._kwargs)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\display_analysis.py"", line 215, in _summarise_data
    return session.full_summary
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\stats.py"", line 72, in full_summary
    return self._summary.get_summary_stats()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\stats.py"", line 287, in get_summary_stats
    self._get_time_stats()
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\stats.py"", line 319, in _get_time_stats
    latest = self._session.get_timestamps(session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\stats.py"", line 209, in get_timestamps
    retval = self._tb_logs.get_timestamps(session_id=session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 498, in get_timestamps
    self._check_cache(idx)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 442, in _check_cache
    self._cache_data(session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 428, in _cache_data
    parser.cache_events(session_id)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 584, in cache_events
    self._cache.cache_data(session_id, data, self._loss_labels, is_live=self._live_data)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 169, in cache_data
    timestamps, loss = self._to_numpy(data, is_live)
  File ""C:\Users\Base Terminal 01\faceswap\lib\gui\analysis\event_reader.py"", line 210, in _to_numpy
    times, loss = (np.array(times, dtype=""float64""), np.array(loss, dtype=""float32""))
ValueError: setting an array element with a sequence.
```",confirm reproduction exception float argument must string number exception direct cause following exception recent call last file line return file terminal line file terminal line file terminal line file terminal line file terminal line key file terminal line file terminal line file terminal line file terminal line file terminal line data file terminal line loss data file terminal line time loss time float loss float setting array element sequence exception float argument must string number exception direct cause following exception recent call last file line return file line file terminal line lambda lambda file terminal line result file terminal line raise file terminal line run file terminal line return file terminal line return file terminal line file terminal line latest file terminal line file terminal line file terminal line file terminal line file terminal line data file terminal line loss data file terminal line time loss time float loss float setting array element sequence,issue,negative,positive,neutral,neutral,positive,positive
913109851,"```numpy==1.21.2```
Not compatible with Tensorflow. Downgrade to a version **below** 1.20.

In fact, Your install is a mess. You appear to have 2 versions of numpy installed (one in pip, one in conda). This certainly would not happen on a standard install. I would recommend deleting your environment and re-running the installer",compatible downgrade version fact install mess appear one pip one certainly would happen standard install would recommend environment installer,issue,negative,positive,neutral,neutral,positive,positive
912941559,"The extract process has been created specifically for use to train models in Faceswap. Whilst I can see benefit for users to use it for other applications, it is certainly not a priority for our project, and adding customizable padding would actually mean adjusting many parts of our code to know what padding that the user selected, whilst bringing no benefit to our project. Sadly I will not be implementing this, but thanks for your feedback.",extract process specifically use train whilst see benefit use certainly priority project padding would actually mean many code know padding user selected whilst benefit project sadly thanks feedback,issue,positive,positive,positive,positive,positive,positive
909139495,Hi! I'd like to contribute to this issue. I have started on making the gui run. Ran into a lot of errors due to modules and the update. I'll update soon.,hi like contribute issue making run ran lot due update update soon,issue,negative,negative,negative,negative,negative,negative
903267184,"This is an OOM. Try enabling ""allow growth"" in the training settings.",try allow growth training,issue,positive,neutral,neutral,neutral,neutral,neutral
903235013,It's only a bug if it's reproducible by others. This is not. You are welcome to join our forum or discord to discuss ways that you may be able to mitigate this situation.,bug reproducible welcome join forum discord discus way may able mitigate situation,issue,negative,positive,positive,positive,positive,positive
903185403,"See here: https://forum.faceswap.dev/viewtopic.php?f=4&t=1226
This is a false positive down to your GPU/Cuda combination.
",see false positive combination,issue,positive,negative,neutral,neutral,negative,negative
892005881,"This doesn't give us any of the required information to troubleshoot.

If you're having problems, probably best to post a thorough explanation of your problem in the forums at https://forum.faceswap.dev/",give u information probably best post thorough explanation problem,issue,negative,positive,positive,positive,positive,positive
892004897,"We have no plans to add realtime swapping in Faceswap itself.  It simply isn't a part of our goals.

Please see https://github.com/alew3/faceit_live for a project that used faceswap to do realish time swaps.",add swapping simply part please see project used time,issue,negative,neutral,neutral,neutral,neutral,neutral
892000270,"`08/02/2021 18:34:50 ERROR A NaN was detected and you have NaN protection enabled. Training has been terminated.
`

This is not an error in Faceswap.  Your model has corrupted and a NaN has been detected.  You need to rollback to an earlier model.  You can use the restore tool to go to the most recent backup or replace the folder with a snapshot, either way should get you back to a known working model.",error nan nan protection training error model corrupted nan need rollback model use restore tool go recent backup replace folder snapshot either way get back known working model,issue,negative,neutral,neutral,neutral,neutral,neutral
891999054,"You don't need to modify any code at all.  FS includes the ability to limit the GPUs in use.

Please see: https://forum.faceswap.dev/viewtopic.php?f=6&t=146#:~:text=not%20just%20training.-,Exclude%20GPUs",need modify code ability limit use please see,issue,positive,neutral,neutral,neutral,neutral,neutral
891634461,"I have tried that by changing **_gpu_stat.py_** , which is inside the lib. I modified it as **__EXCLUDE_DEVICES = [0]**.
(I wanted to exclude 0 GPU) But it did not work, Do I need to modify it anywhere else?

@wangyifan349 ",tried inside exclude work need modify anywhere else,issue,negative,neutral,neutral,neutral,neutral,neutral
891514026," thank you very much
I try to reinstall a brand new windows10",thank much try reinstall brand new,issue,negative,positive,positive,positive,positive,positive
891210466,"@wangyifan349, read the Faceswap forum and use the Windows 10 installer: https://forum.faceswap.dev/viewtopic.php?f=4&t=20.  You should NOT install CUDA or cudnn in Windows 10, the installer puts everything needed into the faceswap environment. ",read forum use installer install installer everything environment,issue,negative,neutral,neutral,neutral,neutral,neutral
890926982,"I can't do it with a graphics card

Loading...
Setting Faceswap backend to NVIDIA
08/02/2021 18:16:47 INFO     Log level set to: DEBUG
2021-08-02 18:16:47.437380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
08/02/2021 18:16:48 INFO     Model A Directory: 'C:\faceobject\1' (622 images)
08/02/2021 18:16:48 INFO     Model B Directory: 'C:\faceobject\2' (207 images)
08/02/2021 18:16:48 WARNING  At least one of your input folders contains fewer than 250 images. Results are likely to be poor.
08/02/2021 18:16:48 WARNING  You need to provide a significant number of images to successfully train a Neural Network. Aim for between 500 - 5000 images per side.
08/02/2021 18:16:48 INFO     Training data directory: C:\faceobject\5
08/02/2021 18:16:48 INFO     ===================================================
08/02/2021 18:16:48 INFO       Starting
08/02/2021 18:16:48 INFO       Press 'Stop' to save and quit
08/02/2021 18:16:48 INFO     ===================================================
08/02/2021 18:16:49 INFO     Loading data, this may take a while...
08/02/2021 18:16:49 INFO     Loading Model from Original plugin...
08/02/2021 18:16:49 VERBOSE  Loading config: 'C:\Users\Administrator\faceswap\config\train.ini'
08/02/2021 18:16:49 VERBOSE  Loading config: 'C:\Users\Administrator\faceswap\config\train.ini'
08/02/2021 18:16:49 INFO     No existing state file found. Generating.
2021-08-02 18:16:49.739171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2021-08-02 18:16:49.758480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 Laptop GPU computeCapability: 8.6
coreClock: 1.425GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2021-08-02 18:16:49.758649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-08-02 18:16:49.763295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2021-08-02 18:16:49.765836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2021-08-02 18:16:49.766590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2021-08-02 18:16:49.769473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2021-08-02 18:16:49.770908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2021-08-02 18:16:49.788129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-08-02 18:16:49.788277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-08-02 18:16:49.788712: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-02 18:16:49.794652: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2303408a650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-08-02 18:16:49.794769: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-08-02 18:16:49.794943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 Laptop GPU computeCapability: 8.6
coreClock: 1.425GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2021-08-02 18:16:49.795080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2021-08-02 18:16:49.795145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2021-08-02 18:16:49.795210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2021-08-02 18:16:49.795273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2021-08-02 18:16:49.795337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2021-08-02 18:16:49.795398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2021-08-02 18:16:49.795458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-08-02 18:16:49.795527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2021-08-02 18:20:13.700005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-08-02 18:20:13.700086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2021-08-02 18:20:13.700128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2021-08-02 18:20:13.700299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4599 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6)
2021-08-02 18:20:13.702677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23057158570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-08-02 18:20:13.702761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6
08/02/2021 18:20:14 VERBOSE  Using Adam optimizer
08/02/2021 18:20:14 VERBOSE  Model: ""original""
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Layer (type)                    Output Shape         Param #     Connected to
08/02/2021 18:20:14 VERBOSE  ==================================================================================================
08/02/2021 18:20:14 VERBOSE  face_in_a (InputLayer)          [(None, 64, 64, 3)]  0
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  face_in_b (InputLayer)          [(None, 64, 64, 3)]  0
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  encoder (Functional)            (None, 8, 8, 512)    69662976    face_in_a[0][0]
08/02/2021 18:20:14 VERBOSE                                                                   face_in_b[0][0]
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  decoder_a (Functional)          (None, 64, 64, 3)    6199747     encoder[0][0]
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  decoder_b (Functional)          (None, 64, 64, 3)    6199747     encoder[1][0]
08/02/2021 18:20:14 VERBOSE  ==================================================================================================
08/02/2021 18:20:14 VERBOSE  Total params: 82,062,470
08/02/2021 18:20:14 VERBOSE  Trainable params: 82,062,470
08/02/2021 18:20:14 VERBOSE  Non-trainable params: 0
08/02/2021 18:20:14 VERBOSE  __________________________________________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Model: ""encoder""
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Layer (type)                 Output Shape              Param #
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  input_1 (InputLayer)         [(None, 64, 64, 3)]       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_128_0_conv2d (Conv2D)   (None, 32, 32, 128)       9728
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_128_0_leakyrelu (LeakyR (None, 32, 32, 128)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_256_0_conv2d (Conv2D)   (None, 16, 16, 256)       819456
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_256_0_leakyrelu (LeakyR (None, 16, 16, 256)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_512_0_conv2d (Conv2D)   (None, 8, 8, 512)         3277312
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_512_0_leakyrelu (LeakyR (None, 8, 8, 512)         0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_1024_0_conv2d (Conv2D)  (None, 4, 4, 1024)        13108224
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  conv_1024_0_leakyrelu (Leaky (None, 4, 4, 1024)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  flatten (Flatten)            (None, 16384)             0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  dense (Dense)                (None, 1024)              16778240
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  dense_1 (Dense)              (None, 16384)             16793600
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  reshape (Reshape)            (None, 4, 4, 1024)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_512_0_conv2d_conv2d  (None, 4, 4, 2048)        18876416
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_512_0_conv2d_leakyre (None, 4, 4, 2048)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_512_0_pixelshuffler  (None, 8, 8, 512)         0
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  Total params: 69,662,976
08/02/2021 18:20:14 VERBOSE  Trainable params: 69,662,976
08/02/2021 18:20:14 VERBOSE  Non-trainable params: 0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Model: ""decoder_a""
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Layer (type)                 Output Shape              Param #
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  input_2 (InputLayer)         [(None, 8, 8, 512)]       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_0_conv2d_conv2d  (None, 8, 8, 1024)        4719616
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_0_conv2d_leakyre (None, 8, 8, 1024)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_0_pixelshuffler  (None, 16, 16, 256)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_0_conv2d_conv2d  (None, 16, 16, 512)       1180160
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_0_conv2d_leakyre (None, 16, 16, 512)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_0_pixelshuffler  (None, 32, 32, 128)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_0_conv2d_conv2d ( (None, 32, 32, 256)       295168
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_0_conv2d_leakyrel (None, 32, 32, 256)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_0_pixelshuffler ( (None, 64, 64, 64)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  face_out_a_conv2d (Conv2D)   (None, 64, 64, 3)         4803
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  face_out_a (Activation)      (None, 64, 64, 3)         0
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  Total params: 6,199,747
08/02/2021 18:20:14 VERBOSE  Trainable params: 6,199,747
08/02/2021 18:20:14 VERBOSE  Non-trainable params: 0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Model: ""decoder_b""
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  Layer (type)                 Output Shape              Param #
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  input_3 (InputLayer)         [(None, 8, 8, 512)]       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_1_conv2d_conv2d  (None, 8, 8, 1024)        4719616
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_1_conv2d_leakyre (None, 8, 8, 1024)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_256_1_pixelshuffler  (None, 16, 16, 256)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_1_conv2d_conv2d  (None, 16, 16, 512)       1180160
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_1_conv2d_leakyre (None, 16, 16, 512)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_128_1_pixelshuffler  (None, 32, 32, 128)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_1_conv2d_conv2d ( (None, 32, 32, 256)       295168
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_1_conv2d_leakyrel (None, 32, 32, 256)       0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  upscale_64_1_pixelshuffler ( (None, 64, 64, 64)        0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  face_out_b_conv2d (Conv2D)   (None, 64, 64, 3)         4803
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 VERBOSE  face_out_b (Activation)      (None, 64, 64, 3)         0
08/02/2021 18:20:14 VERBOSE  =================================================================
08/02/2021 18:20:14 VERBOSE  Total params: 6,199,747
08/02/2021 18:20:14 VERBOSE  Trainable params: 6,199,747
08/02/2021 18:20:14 VERBOSE  Non-trainable params: 0
08/02/2021 18:20:14 VERBOSE  _________________________________________________________________
08/02/2021 18:20:14 INFO     Loading Trainer from Original plugin...
08/02/2021 18:20:14 VERBOSE  Loading config: 'C:\Users\Administrator\faceswap\config\train.ini'
08/02/2021 18:20:14 VERBOSE  Enabled TensorBoard Logging
2021-08-02 18:20:21.176434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2021-08-02 18:21:40.301440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2021-08-02 18:34:47.760173: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-08-02 18:34:48.004187: W tensorflow/core/common_runtime/bfc_allocator.cc:246] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-08-02 18:34:48.446504: W tensorflow/core/common_runtime/bfc_allocator.cc:246] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.24GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

2021-08-02 18:34:49.250787: W tensorflow/core/common_runtime/bfc_allocator.cc:246] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2021-08-02 18:34:49.362508: W tensorflow/core/common_runtime/bfc_allocator.cc:246] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
08/02/2021 18:34:50 INFO     [Saved models] - Average loss since last save: face_a: 0.41939, face_b: 0.37363
08/02/2021 18:34:50 CRITICAL NaN Detected. Loss: [nan, nan]
08/02/2021 18:34:50 CRITICAL Error caught! Exiting...
08/02/2021 18:34:50 ERROR    Caught exception in thread: '_training_0'
08/02/2021 18:34:50 ERROR    A NaN was detected and you have NaN protection enabled. Training has been terminated.
Process exited.

",ca graphic card loading setting log level set successfully dynamic library model directory model directory warning least one input likely poor warning need provide significant number successfully train neural network aim per side training data directory starting press save quit loading data may take loading model original verbose loading verbose loading state file found generating successfully dynamic library found device name successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library visible binary deep neural network library use following enable rebuild appropriate compiler service platform host guarantee used device host default version found device name successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library visible device interconnect strength edge matrix device memory physical device name bus id compute capability service platform guarantee used device compute capability verbose verbose model original verbose verbose layer type output shape param connected verbose verbose none verbose verbose none verbose verbose functional none verbose verbose verbose functional none verbose verbose functional none verbose verbose total verbose trainable verbose verbose verbose model verbose verbose layer type output shape param verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose leaky none verbose verbose flatten flatten none verbose verbose dense dense none verbose verbose dense none verbose verbose reshape reshape none verbose verbose none verbose verbose none verbose verbose none verbose verbose total verbose trainable verbose verbose verbose model verbose verbose layer type output shape param verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose activation none verbose verbose total verbose trainable verbose verbose verbose model verbose verbose layer type output shape param verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose none verbose verbose activation none verbose verbose total verbose trainable verbose verbose loading trainer original verbose loading verbose logging successfully dynamic library successfully dynamic library internal compilation driver perform compilation modify path location message logged allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available saved average loss since last save critical nan loss nan nan critical error caught error caught exception thread error nan nan protection training process,issue,positive,positive,neutral,neutral,positive,positive
890925051,I hope you can help me. Thank you very much,hope help thank much,issue,positive,positive,positive,positive,positive,positive
890923841,"I cannot use GPU to train neural network on my computer, but CPU can run successfully ",use train neural network computer run successfully,issue,negative,positive,positive,positive,positive,positive
890287715,"I tried to change the video, but still can't solve it 
When I select Exclude in the extracted settings
   After Gups 0, the program runs successfully 
But I installed the graphics driver
My graphics card is NVIDIA GeForce RTX 3060 Laptop GPU  6G",tried change video still ca solve select exclude extracted program successfully graphic driver graphic card,issue,negative,neutral,neutral,neutral,neutral,neutral
890265976,"This is not a problem with FAN or a bug, it's usually caused by your video.  Please see more here: https://forum.faceswap.dev/viewtopic.php?p=5848#p5848",problem fan bug usually video please see,issue,negative,negative,negative,negative,negative,negative
887391320,"Traceback (most recent call last):
  File ""D:\faceswap\lib\cli\launcher.py"", line 182, in execute_script
    process.process()
  File ""D:\faceswap\scripts\extract.py"", line 119, in process
    self._run_extraction()
  File ""D:\faceswap\scripts\extract.py"", line 216, in _run_extraction
    for idx, extract_media in enumerate(status_bar):
  File ""C:\Users\LWRF4\anaconda3\envs\faceswap\lib\site-packages\tqdm\std.py"", line 1185, in __iter__
    for obj in iterable:
  File ""D:\faceswap\plugins\extract\pipeline.py"", line 239, in detected_faces
    if self._check_and_raise_error():
  File ""D:\faceswap\plugins\extract\pipeline.py"", line 662, in _check_and_raise_error
    if plugin.check_and_raise_error():
  File ""D:\faceswap\plugins\extract\_base.py"", line 347, in check_and_raise_error
    err = thread.check_and_raise_error()
  File ""D:\faceswap\lib\multithreading.py"", line 84, in check_and_raise_error
    raise error[1].with_traceback(error[2])
  File ""D:\faceswap\lib\multithreading.py"", line 37, in run
    self._target(*self._args, **self._kwargs)
  File ""D:\faceswap\plugins\extract\_base.py"", line 480, in _thread_process
    for item in self.finalize(batch):
  File ""D:\faceswap\plugins\extract\detect\_base.py"", line 160, in finalize
    batch_faces = [[self.to_detected_face(face[0], face[1], face[2], face[3])
  File ""D:\faceswap\plugins\extract\detect\_base.py"", line 160, in <listcomp>
    batch_faces = [[self.to_detected_face(face[0], face[1], face[2], face[3])
  File ""D:\faceswap\plugins\extract\detect\_base.py"", line 160, in <listcomp>
    batch_faces = [[self.to_detected_face(face[0], face[1], face[2], face[3])
  File ""D:\faceswap\plugins\extract\detect\_base.py"", line 197, in to_detected_face
    return DetectedFace(x=int(round(left)),
👇
OverflowError: cannot convert float infinity to integer",recent call last file line file line process file line enumerate file line iterable file line file line file line err file line raise error error file line run file line item batch file line finalize face face face face file line face face face face file line face face face face file line return round left convert float infinity integer,issue,negative,negative,neutral,neutral,negative,negative
883262553,Thanks for the PR. Appreciated. I have a lot on at the moment but will review as soon as I can.,thanks lot moment review soon,issue,negative,positive,positive,positive,positive,positive
875649453,"I have just seen your replay, I see the issue marked as a bug, do i still
need to add more steps or you could reproduce it?

On Wed, Jun 30, 2021 at 12:06 PM torzdf ***@***.***> wrote:

> I cannot recreate this bug. I would need reproducible steps to be able to
> fix it.
>
> I am closing this issue, but if you can add reproducible steps, I will
> re-open it.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/1165#issuecomment-871269146>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEAMKH2S57NOHVVPRP6F4WLTVLUCXANCNFSM47E64BZA>
> .
>
",seen replay see issue marked bug still need add could reproduce wed wrote recreate bug would need reproducible able fix issue add reproducible thread reply directly view,issue,negative,positive,positive,positive,positive,positive
871494817,"Hello @torzdf - thanks for the feedback. I apologise if the notification came over as spammy - we will definitely take this into consideration and can re-assure that we are constantly iterating on our outreach.

We do still have a security vulnerability report for you - do you have some preferred e-mail or place I can send this to you?
",hello thanks feedback notification came definitely take consideration constantly outreach still security vulnerability report preferred place send,issue,positive,positive,neutral,neutral,positive,positive
871277663,"> Generally I try to avoid using Conda-Forge packages as they sometimes cause issues for some users.

That indeed is the case sometimes but the Tensorflow port is now primarily being done on conda-forge with the Anaconda team being involved there as well, just as an FYI. Additionally, only conda-forge currently compiles for arm macs.",generally try avoid sometimes cause indeed case sometimes port primarily done anaconda team involved well additionally currently arm,issue,negative,positive,positive,positive,positive,positive
871276880,"This is because you are running on an M1 Mac.

I will update documentation at some point, but M1 Mac's are not supported by default, and would require some work on your part to get working.

When pynvx was added as a lib for Mac users, M1 did not exist. Clearly this package cannot be used for M1 Macs, so some work would need to be done to handle this.

I do not own a Mac, much less an M1 Mac, so it's unlikely I'm going to be able to do much with this,",running mac update documentation point mac default would require work part get working added mac exist clearly package used work would need done handle mac much le mac unlikely going able much,issue,negative,positive,neutral,neutral,positive,positive
871274915,"> 
> 
> If this is still relevant, Tensorflow 2.4.1 is now available through conda-forge on intel and arm macs: https://github.com/conda-forge/tensorflow-feedstock

It is to an extent, insofar as we pull Tensorflow from Anaconda channel rather than Conda-Forge.

Generally I try to avoid using Conda-Forge packages as they sometimes cause issues for some users. Whilst installing from Conda-Forge is definitely a workaround for Mac users to get around this issue, as the installer/setup.py does not pull this version in, then it is technically still a bug.",still relevant available arm extent insofar pull anaconda channel rather generally try avoid sometimes cause whilst definitely mac get around issue pull version technically still bug,issue,negative,positive,positive,positive,positive,positive
871272803,"Honestly, only 1 backup is kept, and the backup is only created when loss on both sides has dropped between save iterations to it's lowest average level. This is not a huge overhead on disk space or time.

I will tag this as ""suggestion"" but I cannot see myself implementing this any time soon. As always, I welcome pull requests",honestly backup kept backup loss side save average level huge overhead disk space time tag suggestion see time soon always welcome pull,issue,positive,positive,positive,positive,positive,positive
871271047,I believe that this is just a preview window rendering error rather than a bug with the mask. Will look when I get a chance.,believe preview window rendering error rather bug mask look get chance,issue,negative,neutral,neutral,neutral,neutral,neutral
871269146,"I cannot recreate this bug. I would need reproducible steps to be able to fix it.

I am closing this issue, but if you can add reproducible steps, I will re-open it.",recreate bug would need reproducible able fix issue add reproducible,issue,negative,positive,positive,positive,positive,positive
871028840,"@JamieSlome @huntr-helper Why do you think it is reasonable to spam Open Source developers with arbitrary messages demanding the adding of a SECURITY.md file. Do you not think developers give up enough time without having to deal with crap like this?

https://githubmemory.com/@huntr-helper

Consider yourself reported.
",think reasonable open source arbitrary demanding file think give enough time without deal crap like consider,issue,negative,negative,negative,negative,negative,negative
867047578,"Mutables as a default arg can cause problems, however, this is a test function which those kwargs are defined in every case and never mutated in the function (the only place that could be mutated).

We do not generally accept PRs on minor changes like this, especially when they fail basic pep8 format issues.  If you wish to participate in FaceSwap development there are a lot of areas that some substantial improvements could be made and we'd be more than happy to mentor or advise on what you could do to get a successful PR.  But minor changes like your last two PRs will not be accepted (unless they're fixing an actual live bug).",default cause however test function defined every case never function place could generally accept minor like especially fail basic pep format wish participate development lot substantial could made happy mentor advise could get successful minor like last two accepted unless fixing actual live bug,issue,positive,positive,neutral,neutral,positive,positive
867042777,"These fixes are not acceptable.  They fail Pep8, provide no real improvement, and actually make the code harder to read.  dict() is completely acceptable as nothing we're doing will benefit from a 0.2 microsecond speed increase yet it is significantly easier to read.",acceptable fail pep provide real improvement actually make code harder read completely acceptable nothing benefit microsecond speed increase yet significantly easier read,issue,positive,positive,neutral,neutral,positive,positive
866993528,"Hello @albernsrya! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`tests/lib/model/layers_test.py`](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py):

> [Line 21:1](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py#L21): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> [Line 27:22](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py#L27): [E701](https://duckduckgo.com/?q=pep8%20E701) multiple statements on one line (colon)
> [Line 27:26](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py#L27): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace
> [Line 28:8](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py#L28): [E111](https://duckduckgo.com/?q=pep8%20E111) indentation is not a multiple of four
> [Line 28:8](https://github.com/deepfakes/faceswap/blob/a61990d022a30ad6ad8dcd8883fa4d23b54e8dd1/tests/lib/model/layers_test.py#L28): [E113](https://duckduckgo.com/?q=pep8%20E113) unexpected indentation

",hello thanks opening checked touched pep found file line blank found line multiple one line colon line trailing line indentation multiple four line unexpected indentation,issue,negative,positive,neutral,neutral,positive,positive
866988777,"Hello @albernsrya! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`lib/align/detected_face.py`](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py):

> [Line 90:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L90): [E111](https://duckduckgo.com/?q=pep8%20E111) indentation is not a multiple of four
> [Line 90:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L90): [E113](https://duckduckgo.com/?q=pep8%20E113) unexpected indentation
> [Line 466:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L466): [E111](https://duckduckgo.com/?q=pep8%20E111) indentation is not a multiple of four
> [Line 466:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L466): [E113](https://duckduckgo.com/?q=pep8%20E113) unexpected indentation
> [Line 681:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L681): [E111](https://duckduckgo.com/?q=pep8%20E111) indentation is not a multiple of four
> [Line 681:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L681): [E113](https://duckduckgo.com/?q=pep8%20E113) unexpected indentation
> [Line 914:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L914): [E111](https://duckduckgo.com/?q=pep8%20E111) indentation is not a multiple of four
> [Line 914:10](https://github.com/deepfakes/faceswap/blob/4333e8176ac123cb7dc56d6237fdfe6be4807688/lib/align/detected_face.py#L914): [E117](https://duckduckgo.com/?q=pep8%20E117) over-indented

",hello thanks opening checked touched pep found file line indentation multiple four line unexpected indentation line indentation multiple four line unexpected indentation line indentation multiple four line unexpected indentation line indentation multiple four line,issue,negative,positive,neutral,neutral,positive,positive
856676159,Grammar PRs are really beginning to annoy me. Especially when they offer very little.,grammar really beginning annoy especially offer little,issue,negative,positive,neutral,neutral,positive,positive
856014016,"```
CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/noarch/current_repodata.json>
Elapsed: -
An HTTP error occurred when trying to retrieve this URL.
HTTP errors are often intermittent, and a simple retry will get you on your way.
```
Connection error for MiniConda3. Probably intermittent, just try again

If it still fails follow the manual steps on the install.MD page.

Ultimately the installer is a convenience tool. The actual setting up of environments is done by MiniConda.
",connection error trying retrieve often intermittent simple retry get way connection error probably intermittent try still follow manual page ultimately installer convenience tool actual setting done,issue,negative,neutral,neutral,neutral,neutral,neutral
855800401,"`Translated original message:`

> **An exception was thrown during training. Automatically try to retrain**
>During the training process, because of the poor computer configuration. Every once in a while, the program will throw an exception. You need to manually re-click Training to continue training.
Can you catch this common anomaly and try to retrain automatically 



We would need to know the specifics of the error. Either way, this is something we are unlikely to implement as everyone's setup is very different and it is impossible to cover for all eventualities

`Translated response:`
>我们需要知道错误的细节。 无论哪种方式，这是我们不太可能实施的，因为每个人的设置都非常不同，并且不可能涵盖所有可能发生的情况 


",original message exception thrown training automatically try retrain training process poor computer configuration every program throw exception need manually training continue training catch common anomaly try retrain automatically would need know error either way something unlikely implement everyone setup different impossible cover response,issue,negative,negative,negative,negative,negative,negative
855513809,"We appreciate the notification but, In general, we do not accept grammar/spelling PRs.",appreciate notification general accept,issue,positive,positive,neutral,neutral,positive,positive
855324333,In general we do not accept grammar/spelling PRs.  We appreciate the notification but many of these fixes are actually invalid.,general accept appreciate notification many actually invalid,issue,positive,positive,positive,positive,positive,positive
854780754,Make sure you're using the alignments file made for that video.  If you have any other issues please post in the forums at faceswap.dev .  The issues here are only for code bugs.,make sure file made video please post code,issue,positive,positive,positive,positive,positive,positive
853904119,"If this is still relevant, Tensorflow 2.4.1 is now available through conda-forge on intel and arm macs: https://github.com/conda-forge/tensorflow-feedstock",still relevant available arm,issue,negative,positive,positive,positive,positive,positive
850979175,"I *believe* this has been implemented, so closing. Please let me know if it's not working for you.",believe please let know working,issue,negative,neutral,neutral,neutral,neutral,neutral
850979060,Thanks for the heads up. Should be fixed in latest commit,thanks fixed latest commit,issue,positive,positive,positive,positive,positive,positive
850947262,@ymzlygw Isn't changing the body and changing the face equivalent? You can put the face of A torso on top of B torso,body face equivalent put face torso top torso,issue,negative,positive,positive,positive,positive,positive
846931259,"We got budget.
If it’s easier to quote daily rates that would be ok.
We’re on aws.



On Friday, May 14, 2021, torzdf ***@***.***> wrote:

> For some reason your email wasn't delivered (may have gone to spam, but my
> folder doesn't go back that far).
>
> I have removed the screengrab for privacy reasons (have taken a copy with
> contact details), but will take a look when I have a second.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/1146#issuecomment-841143099>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AACGZSRESFLYDHIK2RBR4R3TNTXZFANCNFSM42WCYTRQ>
> .
>
",got budget easier quote daily would may wrote reason may gone folder go back far removed privacy taken copy contact take look second thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
841143099,"For some reason your email wasn't delivered (may have gone to spam, but my folder doesn't go back that far).

I have removed the screengrab for privacy reasons (have taken a copy with contact details), but will take a look when I have a second.",reason may gone folder go back far removed privacy taken copy contact take look second,issue,negative,positive,neutral,neutral,positive,positive
841140178,"[image removed]

still waiting on a reply. ",image removed still waiting reply,issue,negative,neutral,neutral,neutral,neutral,neutral
840317723,Issues here are just for bugs.  If you have problems like this you can go to https://forum.faceswap.dev/ particularly start with the FAQ page at https://forum.faceswap.dev/app.php/faqpage especially The Q/A at https://forum.faceswap.dev/app.php/faqpage#f1r1 which solves most problems.,like go particularly start page especially,issue,negative,positive,neutral,neutral,positive,positive
839340444,"I'm closing this PR as somehow it has got fairly mangled, so will be tricky to merge. Please feel free to submit another",somehow got fairly tricky merge please feel free submit another,issue,positive,positive,positive,positive,positive,positive
829452582,"Seems I forgot to use the -d command, silly question.",forgot use command silly question,issue,negative,negative,negative,negative,negative,negative
823615258,"Hey @torzdf, 

I feel your depression of having to say it over and over again.
Anyways, thanks for you great work and letting me use it. 
Next time I'll read the manual twice. 

Cheers
Chris ",hey feel depression say anyways thanks great work use next time read manual twice,issue,positive,positive,positive,positive,positive,positive
823438952,"Sure, you can call me arrogant on a page reserved for issues and bugs. or you could do your own research and find this answer is presented to you in a guide, I wrote for free (and keep updated), to answer one of many questions which is constantly asked, so that I don't need to live in some kind of Groundhog Day answering the same questions again and again and again.

I gave you a link to the solution. I apologise if that has not met your value expectation for the free product I develop in my own time for no financial remuneration.

As @gessyoo alludes to above. The guide is written with the GUI as a contextual device as most of our users use the GUI. However, it is just a front-end for the cli, and everything done in the GUI can be done with the Cli. This is explicitly stated in the opening part of the guide... and then the guide goes on to explicitly cover Alignments files, what they are and how to get them. Here is a direct ink for you: https://forum.faceswap.dev/viewtopic.php?f=7&t=1083#Alignments

I apologise if you still think this is arrogant... but then, what is being presented with an answer and totally ignoring it?",sure call arrogant page reserved could research find answer guide wrote free keep answer one many constantly need live kind day gave link solution met value expectation free product develop time financial remuneration guide written contextual device use however everything done done explicitly stated opening part guide guide go explicitly cover get direct ink still think arrogant answer totally,issue,positive,positive,positive,positive,positive,positive
823410868,"It's recommended to read the guides several times:  https://forum.faceswap.dev/viewtopic.php?f=7&t=1083 (""As in the other guides, I will be using the GUI, but all the commands here are also available in the cli, You can execute python faceswap.py convert -h to get a list of the commands, and python tools.py -h to get a list of the available tools."").  There is an abundance of useful information in the Faceswap forum.",read several time also available execute python convert get list python get list available abundance useful information forum,issue,negative,positive,positive,positive,positive,positive
823312939,"@torzdf your comment reflects the common behavior of human arrogance.
That is im my opinion totally unnecessary as I was just looking for some help.

Leaving the humanities aside, I am using CLI only and the Manuel is only GUI based. 
Nevertheless, I read through it and couldn't find anything about an alignments.json.
Are there some instructions for using CLI only and how to create an alignments.json?",comment common behavior human arrogance opinion totally unnecessary looking help leaving aside based nevertheless read could find anything create,issue,negative,negative,negative,negative,negative,negative
823255057,How did you solve it? Please tell us! ,solve please tell u,issue,negative,neutral,neutral,neutral,neutral,neutral
823251461,Thanks. This should be fixed in latest update.,thanks fixed latest update,issue,negative,positive,positive,positive,positive,positive
817280260,"This never existed and there are no plans to implement.

The original image is a mock up from over 3 years ago",never implement original image mock ago,issue,negative,positive,positive,positive,positive,positive
814815500,You may run into other issues. Our lowest version is 2.2 as we use features which were introduced then (although I cannot remember what they are),may run version use although remember,issue,negative,neutral,neutral,neutral,neutral,neutral
814653876,"thanks for help... mi mac is intel fortunely

I tried to remove version on file cpy_req*.txt and installation run correctly

<img width=""584"" alt=""image"" src=""https://user-images.githubusercontent.com/5438823/113823220-aed80c00-977e-11eb-9850-b117de3d7c4e.png"">
",thanks help mi mac tried remove version file installation run correctly image,issue,positive,positive,positive,positive,positive,positive
814496261,"I'm re-opening this as it *may* be an issue as Anaconda has stopped updating Tensorflow for Mac (last version 2.0.0)

Ultimately, MacOS is a pain as they refuse to play nice with Nvidia and have now gone ARM. It is going to be increasingly difficult to support Macs going forward. You can thank Apple and their entire disregard for ML for that one.

I will investigate, but you may be stuck with sourcing versions yourself and installing manually.

Ultimately, if you are serious about ML then use a better Operating System.",may issue anaconda stopped mac last version ultimately pain refuse play nice gone arm going increasingly difficult support going forward thank apple entire disregard one investigate may stuck manually ultimately serious use better operating system,issue,negative,positive,neutral,neutral,positive,positive
814458877,This is not a bug.  Make sure your installing on the right version of python and inside anaconda and it will work.,bug make sure right version python inside anaconda work,issue,negative,positive,positive,positive,positive,positive
813919754,"hi, @torzdf ，@rodrigo-puente ，I encountered the same problem, how to set TF_FORCE_GPU_ALLOW_GROWTH=true, where is this variable? ",hi problem set variable,issue,negative,neutral,neutral,neutral,neutral,neutral
812848057,"Faceswap will run on TF 2.4, which supports 30xx cards, however it involves you setting up the environment yourself and we will not provide direct support for this kind of install.

Ultimately, we are waiting for Anaconda to update their Cuda/cuDNN to support Cuda 11.x cuDNN 8.x when we can update our auto-install scripts. We have no control over this.

You are best off chasing up Anaconda. In the meantime there are some unofficial instructions here: 
https://forum.faceswap.dev/viewtopic.php?f=4&t=1226",run however setting environment provide direct support kind install ultimately waiting anaconda update support update control best chasing anaconda unofficial,issue,positive,positive,positive,positive,positive,positive
812479656,"> If you join our Discord though, someone there may have found something.

ok, Thanks!",join discord though someone may found something thanks,issue,negative,positive,positive,positive,positive,positive
812479191,"If you join our Discord though, someone there may have found something.",join discord though someone may found something,issue,negative,neutral,neutral,neutral,neutral,neutral
812479081,"Not that I know of, I'm afraid (not to say it doesn't exist... it's just not something I have come across)",know afraid say exist something come across,issue,negative,negative,negative,negative,negative,negative
812478905,"> Faceswap is entirely built to work on faces. You would need to create a pipeline (detect/align/extract) to work on body parts.

thanks, is there has been any bodyswap lib or opensource can do it?",entirely built work would need create pipeline work body thanks,issue,positive,positive,neutral,neutral,positive,positive
812476555,Faceswap is entirely built to work on faces. You would need to create a pipeline (detect/align/extract) to work on body parts.,entirely built work would need create pipeline work body,issue,negative,neutral,neutral,neutral,neutral,neutral
812476228,"This, unfortunately, is a system issue, not a Faceswap issue.

You can try this solution by a user posted on our forums:
https://forum.faceswap.dev/viewtopic.php?t=572

Otherwise, you're going to need to do some googling, I'm afraid:
https://www.google.com/search?q=%22DLL+load+failed+while+importing+qhull%22&client=firefox-b-d&sxsrf=ALeKk02XrVsRJ-pnaKqLJXuc1jL3VWze0Q%3A1617359912453&ei=KPRmYIaEG8aK9u8Pv_eJsAE&oq=%22DLL+load+failed+while+importing+qhull%22&gs_lcp=Cgdnd3Mtd2l6EAMyBAgjECcyBggAEAcQHjICCAAyBAgAEB4yBggAEAcQHjoHCCMQsAMQJzoHCAAQRxCwAzoGCAAQFhAeUPI1WI87YMo8aAFwAngAgAF_iAH0AZIBAzIuMZgBAKABAaoBB2d3cy13aXrIAQnAAQE&sclient=gws-wiz&ved=0ahUKEwiGuLiYr9_vAhVGhf0HHb97AhYQ4dUDCAw&uact=5",unfortunately system issue issue try solution user posted otherwise going need afraid,issue,negative,negative,negative,negative,negative,negative
811516350,"Thanks.

```
supported = devices
        # supported = [device for device in devices
        #              if device.details
        #              and json.loads(device.details.decode()).get(""type"", ""cpu"").lower() == ""gpu""]
```

```
        experi = devices
        # experi = [device for device in devices
        #           if device.details
        #           and json.loads(device.details.decode()).get(""type"", ""cpu"").lower() == ""gpu""]
```",thanks device device type device device type,issue,negative,positive,positive,positive,positive,positive
811192379,Run in verbose mode. It will tell you,run verbose mode tell,issue,negative,neutral,neutral,neutral,neutral,neutral
810159523,"Ok, Thank you. 

Yes, it may be convenient for me to reproduce the issue and add some code because my disk is almost full.

I just learned the project one day. May be when I become more familiar with the project, I can submit the pull request.

Thanks. The issue may should be closed right now.",thank yes may convenient reproduce issue add code disk almost full learned project one day may become familiar project submit pull request thanks issue may closed right,issue,positive,positive,positive,positive,positive,positive
810153445,"This isn't really a bug, per-se. This is just what happens when you run out of space on your drive....

To code in protection against full disks into every level of Faceswap would be a mammoth task, and not an endeavor I'm likely to embark on. I welcome Pull Requests though.",really bug run space drive code protection full every level would mammoth task endeavor likely embark welcome pull though,issue,negative,positive,positive,positive,positive,positive
809687948,"I *think* this is a memory error.

Sadly the cv2-dnn method is really not good, so never really going to prioritize looking at it. One day I may well research a better CPU friendly aligner (if anyone knows of any implementation/papers, then feel free to ping them over).
",think memory error sadly method really good never really going looking one day may well research better friendly aligner anyone feel free ping,issue,positive,positive,positive,positive,positive,positive
809634892,"I see... but...
If installer is for non-expert end user, shouldn't the expert ones that already have conda env setup, install using some scripts instead of trusting an installer to do some magic conda env setup?

I would expect installer to install all non-windows dependencies inside the `faceswap` folder to not conflict with other conda environments. This way, a safe uninstaller could be made.
For expert users, they will install using some scripts that use the shared pre-install conda environment.

This way, the setup is encapsulated, install and uninstall.

Having said that, the current uninstall is easy enough, but instructions are hidden inside FAQ. 
A link should be added to [install instructions](https://forum.faceswap.dev/viewtopic.php?t=20).",see installer end user expert already setup install instead trusting installer magic setup would expect installer install inside folder conflict way safe could made expert install use environment way setup install said current easy enough hidden inside link added install,issue,positive,positive,positive,positive,positive,positive
809605431,"It would.

Until it destroys someone's carefully curated Conda environment for an entirely separate project because it was flagged for uninstall.

Faceswap is not a compiled Windows application. It does not appear in Windows programs. It does not touch the registry. The installer exists *purely* to make the installation process easier, rather than having the end user having to familiarize themselves with git commands, python environments and Conda applications.

I could always remove it. That would solve the uninstall problem.

Decisions, decisions.",would someone carefully environment entirely separate project application appear touch registry installer purely make installation process easier rather end user familiarize git python could always remove would solve problem,issue,negative,positive,neutral,neutral,positive,positive
809521633,"From the FAQ.  https://forum.faceswap.dev/app.php/faqpage#f1r2

How do I uninstall Faceswap?
Faceswap is deliberately installed ""standalone"" so that it doesn't interfere with the rest of your computer. To uninstall, simply delete the folder that you installed Faceswap into.

Then if you want to you can also uninstall MiniConda (the only 3rd party app that we install) the usual way.",deliberately interfere rest computer simply delete folder want also party install usual way,issue,negative,negative,negative,negative,negative,negative
804843181,"You'll want to merge the Staging branch into your branch and fix the conflicts.

The easiest thing to do would be to close this PR, and create a new one based off the staging branch (as the number of edits actually required are so few)

FYI: Going forward I highly recommend working from the Staging Branch, purely because it can be ahead of Master, and avoids issues like this.",want merge staging branch branch fix easiest thing would close create new one based staging branch number actually going forward highly recommend working staging branch purely ahead master like,issue,positive,positive,positive,positive,positive,positive
804285613,"Thanks for doing this. I'm going to leave it open, as I have discovered a potential flaw in Faceswap code re: tf 2.4.

Also, I would quite like to update the base install to 2.4 (and hence 30xx cards) for all users, but am currently at the mercy of waiting for Conda.",thanks going leave open discovered potential flaw code also would quite like update base install hence currently mercy waiting,issue,positive,negative,negative,negative,negative,negative
803501634,"And the below warning is showing:
`WARNING: apt does not have a stable CLI interface. Use with caution in scripts.`",warning showing warning apt stable interface use caution,issue,negative,positive,positive,positive,positive,positive
801987817,"Hello! I have a problem:
Conversion settings have been successfully launched, preview images are loaded, parameters can be configured. But after changing something, there is no update preview, although the progress bar animates.

Nvidia-smi showed that GPU RAM is allocated, GPU-utilization is 0%.

After waiting 10 minutes, I decided to save the configuration and close the tool. After that, the conversion process accepts manually configured parameters. I got new result, but unpredictive :D

Extraction, train, convert stages worked well.

OS: Ubuntu 18.04
GPU: GeForce RTX 2080 Ti
CUDA: 11.0
Envinronment: conda, python 3.8
",hello problem conversion successfully preview loaded something update preview although progress bar ram waiting decided save configuration close tool conversion process manually got new result extraction train convert worked well o ti python,issue,positive,positive,positive,positive,positive,positive
801893486,"Please can you fix the pep8speaks nag, and I will look into reviewing. Thanks",please fix nag look thanks,issue,negative,positive,positive,positive,positive,positive
801882713,"Thanks for this.

Please could you also update the following files...
- `locales/es/LC_MESSAGES/tools.manual.po`
- `locales/es/LC_MESSAGES/tools.preview.po`

You can just open the `.po` files directly into PoEdit (I have added the English source files). Make the changes, then save the `.po` file back, and the `.mo` file should then auto-update",thanks please could also update following open directly added source make save file back file,issue,positive,positive,neutral,neutral,positive,positive
801864069,"If you can cite the reason for this, it would be appreciated, as imho apt is fine",cite reason would apt fine,issue,negative,positive,positive,positive,positive,positive
796503856,"Hello @dmiszkiewicz! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`tools/sort/sort.py`](https://github.com/deepfakes/faceswap/blob/ac231ea7a18ca014c50783a1ceff1c72934bfe9c/tools/sort/sort.py):

> [Line 261:32](https://github.com/deepfakes/faceswap/blob/ac231ea7a18ca014c50783a1ceff1c72934bfe9c/tools/sort/sort.py#L261): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 262:32](https://github.com/deepfakes/faceswap/blob/ac231ea7a18ca014c50783a1ceff1c72934bfe9c/tools/sort/sort.py#L262): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 263:32](https://github.com/deepfakes/faceswap/blob/ac231ea7a18ca014c50783a1ceff1c72934bfe9c/tools/sort/sort.py#L263): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent

",hello thanks opening checked touched pep found file line continuation line visual indent line continuation line visual indent line continuation line visual indent,issue,negative,positive,neutral,neutral,positive,positive
792739013,This is model corruption. Use the restore tool to restore a good backup.,model corruption use restore tool restore good backup,issue,positive,positive,positive,positive,positive,positive
787801631,"I also found a solution to this problem. It's not a perfect solution, but we've identified a error with file _""faceswap/plugins/extract/align/cv2_dnn.py""_ and we've fixed it as below.

**Edit function align_image in file:cv2_dnn.py:** 
```
face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
```
**to**
```
try:
    face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
except:
    face = np.zeros((128, 128, 3), np.uint8)
    pass
```

When we **resize**, I handled the problem by replacing it with a blank image, and we could see that it was running again, although it was not the exact method.",also found solution problem perfect solution error file fixed edit function file face face try face face except face pas resize handled problem blank image could see running although exact method,issue,negative,positive,positive,positive,positive,positive
782732181,"FYI. You can ignore the failing check. It has nothing to do with this PR
",ignore failing check nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
782694354,"Hi. Thanks for the PR. Sorry it took so long, but I've finally got around to pushing a fix for this: https://github.com/deepfakes/faceswap/commit/ef22c576f66dafdc355876eacf3f32096489dbd9

The issue was actually in part of the extract code (specifically around skipping existing alignments). The fix I have pushed re-enables skipping existing alignments/faces. This PR did help me with where to look though.

Any further issues, please feel free to raise.

Closing this PR as it is superseded by the upstream fix..",hi thanks sorry took long finally got around pushing fix issue actually part extract code specifically around skipping fix skipping help look though please feel free raise upstream fix,issue,positive,positive,neutral,neutral,positive,positive
782254634,"Thanks for this. I will review over the weekend.

Yeah, unfortunately ""option names"" have to remain the same across languages, otherwise it becomes hard to maintain. But language specific help text/group headers should help some",thanks review weekend yeah unfortunately option remain across otherwise becomes hard maintain language specific help help,issue,positive,negative,negative,negative,negative,negative
780765904,"Thanks for the heads up on this. I have pushed a fix which should stop this occurring in future (ref: https://github.com/deepfakes/faceswap/commit/48ca4d1b0e52ad940067896a5955553fbd785db3), so closing",thanks fix stop future ref,issue,negative,positive,neutral,neutral,positive,positive
778863800,"We have lots of support at https://forum.faceswap.dev/ including guides, explanations of processes.

The answer to your batch size question is even answered there, at https://forum.faceswap.dev/viewtopic.php?f=6&t=146#:~:text=Batch%20Size",lot support answer batch size question even,issue,negative,neutral,neutral,neutral,neutral,neutral
778850166,We don't provide support via Github (especially by pull requests.)  Please visit forum.faceswap.dev for our forum where you can post support requrests.,provide support via especially pull please visit forum post support,issue,positive,neutral,neutral,neutral,neutral,neutral
774805742,"Should be fixed in latest commit. Please update.
",fixed latest commit please update,issue,positive,positive,positive,positive,positive,positive
768426232,"The manual tool takes Frames as a source not Faces.

aka: you're using it wrong.",manual tool source aka wrong,issue,negative,negative,negative,negative,negative,negative
766736404,"If you go help > Output System Info, one of the earlier lines will tell you what commit you are on.

If the issue persists, then I will need new test data to recreate the error, as it works with the test data I received.",go help output system one tell commit issue need new test data recreate error work test data received,issue,negative,positive,positive,positive,positive,positive
766735519,Hugely appreciated. No rush (as it is a secondary detector).,hugely rush secondary detector,issue,negative,positive,neutral,neutral,positive,positive
766641972,"I didn't test recently, as S3FD is doing the job.

I will eventually test again. Stay tuned.",test recently job eventually test stay tuned,issue,negative,neutral,neutral,neutral,neutral,neutral
766334544,"How can I check if the latest commit is included in the latest release?

Just updated from the GUI and ran into the same error.
 
 Thanks.",check latest commit included latest release ran error thanks,issue,negative,positive,positive,positive,positive,positive
766137095,Does this issue still persist? I haven't been able to replicate on latest code.,issue still persist able replicate latest code,issue,negative,positive,positive,positive,positive,positive
766136969,"This should be fixed in latest commit. Would appreciate confirmation.
",fixed latest commit would appreciate confirmation,issue,positive,positive,positive,positive,positive,positive
764433778,"I am not sure why this problem occurs but I seem to have fixed it in my setup by removing some faces from my Set A: When going through the images, I realized that for some input images, the extraction process generated very zoomed-out images, with most of the image area being just black. I assume that the alignment data for those images included very tiny faces, close to 0 in height or width, which might have caused the error.

Before deleting those images, I'd run into that crash after about 10 minutes. After removing them, I haven't had a crash even after about 10 hours of training.",sure problem seem fixed setup removing set going input extraction process image area black assume alignment data included tiny close height width might error run crash removing crash even training,issue,negative,positive,positive,positive,positive,positive
759383260,"If the issue persists on 457.51 then there is an issue in your setup somewhere.

This error: `An unhandled exception occured loading pynvml. Original error: Uninitialized` is **specific** to the 460 drivers. You may need to [DDU](https://www.guru3d.com/files-details/display-driver-uninstaller-download.html) your drivers.",issue issue setup somewhere error unhandled exception loading original error specific may need,issue,negative,positive,positive,positive,positive,positive
757466035,"thanks for ur help,i'll try ur guid.thanks",thanks ur help try ur,issue,positive,positive,positive,positive,positive,positive
757465564,"The issue is that your GPU driver is not detected.

For AMD on Linux, the AMDGPU PRO drivers must be used. I do not know the nuances of getting the correct components on Arch, but hopefully this helps:
https://wiki.archlinux.org/index.php/AMDGPU_PRO

I'm closing this issue as it is not a bug in FS. If you need further help getting this working, then our [forum](https://faceswap.dev/forum) or [Discord](https://discord.gg/FC54sYg) will probably serve you better as other AMD users can hopefully help out.
",issue driver pro must used know getting correct arch hopefully issue bug need help getting working forum discord probably serve better hopefully help,issue,positive,positive,positive,positive,positive,positive
757451222,"> > 461.09 solves this issue.
> 
> Not the case for GeForce 1050 Ti.

You've tried to reinstall faceswap?",issue case ti tried reinstall,issue,negative,neutral,neutral,neutral,neutral,neutral
757450398,"I'm also running into the same issue.
 
I have a small set of files so I could upload the whole image set with the crash report & alignments:

https://drive.google.com/drive/folders/1LDP1LRuEXRyYDH_4CBPjg5ZsdNJZ_a0D?usp=sharing

The alignments files are for the following faces:
20210109_190633_alignments = faceA
VID_20210109_170015_alignments = faceB

Hope this helps!",also running issue small set could whole image set crash report following hope,issue,negative,negative,neutral,neutral,negative,negative
757404107,"> Please post output of Help>Output System Informaton

thanks for reply
hereis my output context of  `help==>output system inf`

>============ System Information ============
encoding:            UTF-8
git_branch:          位于分支 master
git_commits:         f9a5b72 Bugfix - setup.py. Explicitly install cudatoolkit in Conda. b1420a6 Merge pull request #1096 from deepfakes/dev-tf2.4. 29667b4 Expand support for tf2.2-2.4. 3438198 Merge branch 'master' into dev-tf2.4. b67f91e travis test typo fix
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         
gpu_devices_active:  
gpu_driver:          []
gpu_vram:            
os_machine:          x86_64
os_platform:         Linux-5.10.5-arch1-1-x86_64-with-glibc2.10
os_release:          5.10.5-arch1-1
py_command:          faceswap.py gui
py_conda_version:    conda 4.9.2
py_implementation:   CPython
py_version:          3.8.5
py_virtual_env:      True
sys_cores:           12
sys_processor:       
sys_ram:             Total: 16018MB, Available: 6479MB, Used: 8838MB, Free: 2343MB

> =============== Pip Packages ===============
absl-py @ file:///tmp/build/80754af9/absl-py_1607439979954/work
aiohttp @ file:///tmp/build/80754af9/aiohttp_1602530294624/work
astunparse==1.6.3
async-timeout==3.0.1
attrs @ file:///tmp/build/80754af9/attrs_1604765588209/work
blinker==1.4
brotlipy==0.7.0
cachetools @ file:///tmp/build/80754af9/cachetools_1607706694405/work
certifi==2020.12.5
cffi @ file:///tmp/build/80754af9/cffi_1606255081583/work
chardet @ file:///tmp/build/80754af9/chardet_1605303185383/work
click==7.1.2
cryptography @ file:///tmp/build/80754af9/cryptography_1607635341180/work
cycler==0.10.0
enum34==1.1.10
fastcluster==1.1.26
ffmpy==0.2.3
gast==0.3.3
google-auth @ file:///tmp/build/80754af9/google-auth_1607969906642/work
google-auth-oauthlib @ file:///tmp/build/80754af9/google-auth-oauthlib_1603929124518/work
google-pasta==0.2.0
grpcio @ file:///tmp/build/80754af9/grpcio_1597424474635/work
h5py @ file:///tmp/build/80754af9/h5py_1593454122442/work
idna @ file:///tmp/build/80754af9/idna_1593446292537/work
imageio @ file:///tmp/build/80754af9/imageio_1594161405741/work
imageio-ffmpeg @ file:///home/conda/feedstock_root/build_artifacts/imageio-ffmpeg_1609799311556/work
importlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1602276842396/work
joblib @ file:///tmp/build/80754af9/joblib_1607970656719/work
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver @ file:///tmp/build/80754af9/kiwisolver_1604014535162/work
Markdown @ file:///tmp/build/80754af9/markdown_1605111056890/work
matplotlib @ file:///tmp/build/80754af9/matplotlib-base_1592846008246/work
mkl-fft==1.2.0
mkl-random==1.1.1
mkl-service==2.3.0
multidict @ file:///tmp/build/80754af9/multidict_1600456399709/work
numpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603570489231/work
nvidia-ml-py3 @ git+https://github.com/deepfakes/nvidia-ml-py3.git@6fc29ac84b32bad877f078cb4a777c1548a00bf6
oauthlib==3.1.0
olefile==0.46
opencv-python==4.5.1.48
opt-einsum==3.1.0
pathlib==1.0.1
Pillow @ file:///tmp/build/80754af9/pillow_1609786786540/work
plaidml==0.7.0
plaidml-keras==0.7.0
protobuf==3.13.0
psutil @ file:///tmp/build/80754af9/psutil_1598370257551/work
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work
PyJWT==1.7.1
pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1608057966937/work
pyparsing==2.4.7
PySocks @ file:///tmp/build/80754af9/pysocks_1605305779399/work
python-dateutil==2.8.1
PyYAML==5.3.1
requests @ file:///tmp/build/80754af9/requests_1608241421344/work
requests-oauthlib==1.3.0
rsa @ file:///tmp/build/80754af9/rsa_1596998415516/work
scikit-learn @ file:///tmp/build/80754af9/scikit-learn_1598376899566/work
scipy==1.4.1
sip==4.19.13
six @ file:///tmp/build/80754af9/six_1605205327372/work
tensorboard==2.2.2
tensorboard-plugin-wit==1.6.0
tensorflow==2.2.0
tensorflow-estimator==2.2.0
termcolor==1.1.0
threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl
tornado @ file:///tmp/build/80754af9/tornado_1606942300299/work
tqdm @ file:///tmp/build/80754af9/tqdm_1609788246169/work
urllib3 @ file:///tmp/build/80754af9/urllib3_1606938623459/work
Werkzeug==1.0.1
wrapt==1.12.1
yarl @ file:///tmp/build/80754af9/yarl_1606939922162/work
zipp @ file:///tmp/build/80754af9/zipp_1604001098328/work

> ============== Conda Packages ==============
> #packages in environment at /home/wind/Project/anaconda3/envs/faceswap:
> #
> #Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_tflow_select             2.3.0                       mkl  
absl-py                   0.11.0             pyhd3eb1b0_1  
aiohttp                   3.6.3            py38h7b6447c_0  
astunparse                1.6.3                      py_0  
async-timeout             3.0.1                    py38_0  
attrs                     20.3.0             pyhd3eb1b0_0  
blas                      1.0                         mkl  
blinker                   1.4                      py38_0  
brotlipy                  0.7.0           py38h27cfd23_1003  
bzip2                     1.0.8                h516909a_3    conda-forge
c-ares                    1.17.1               h27cfd23_0  
ca-certificates           2020.12.8            h06a4308_0  
cachetools                4.2.0              pyhd3eb1b0_0  
certifi                   2020.12.5        py38h06a4308_0  
cffi                      1.14.4           py38h261ae71_0  
chardet                   3.0.4           py38h06a4308_1003  
click                     7.1.2                      py_0  
cryptography              3.3.1            py38h3c74f83_0  
cycler                    0.10.0                   py38_0  
dbus                      1.13.18              hb2f20db_0  
enum34                    1.1.10                   pypi_0    pypi
expat                     2.2.10               he6710b0_2  
fastcluster               1.1.26           py38hc5bc63f_2    conda-forge
ffmpeg                    4.3.1                h3215721_1    conda-forge
ffmpy                     0.2.3                    pypi_0    pypi
fontconfig                2.13.0               h9420a91_0  
freetype                  2.10.4               h5ab3b9f_0  
gast                      0.3.3                      py_0  
glib                      2.66.1               h92f7085_0  
gmp                       6.2.1                h58526e2_0    conda-forge
gnutls                    3.6.13               h85f3911_1    conda-forge
google-auth               1.24.0             pyhd3eb1b0_0  
google-auth-oauthlib      0.4.2              pyhd3eb1b0_2  
google-pasta              0.2.0                      py_0  
grpcio                    1.31.0           py38hf8bcb03_0  
gst-plugins-base          1.14.0               h8213a91_2  
gstreamer                 1.14.0               h28cd5cc_2  
h5py                      2.10.0           py38hd6299e0_1  
hdf5                      1.10.6               hb1b8bf9_0  
icu                       58.2                 he6710b0_3  
idna                      2.10                       py_0  
imageio                   2.9.0                      py_0  
imageio-ffmpeg            0.4.3              pyhd8ed1ab_0    conda-forge
importlib-metadata        2.0.0                      py_1  
intel-openmp              2020.2                      254  
joblib                    1.0.0              pyhd3eb1b0_0  
jpeg                      9b                   h024ee3a_2  
keras                     2.2.4                    pypi_0    pypi
keras-applications        1.0.8                    pypi_0    pypi
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.3.0            py38h2531618_0  
lame                      3.100             h14c3975_1001    conda-forge
lcms2                     2.11                 h396b838_0  
ld_impl_linux-64          2.33.1               h53a641e_7  
libedit                   3.1.20191231         h14c3975_1  
libffi                    3.3                  he6710b0_2  
libgcc-ng                 9.1.0                hdf63c60_0  
libgfortran-ng            7.3.0                hdf63c60_0  
libiconv                  1.16                 h516909a_0    conda-forge
libpng                    1.6.37               hbc83047_0  
libprotobuf               3.13.0.1             hd408876_0  
libstdcxx-ng              9.1.0                hdf63c60_0  
libtiff                   4.1.0                h2733197_1  
libuuid                   1.0.3                h1bed415_2  
libxcb                    1.14                 h7b6447c_0  
libxml2                   2.9.10               hb55368b_3  
lz4-c                     1.9.2                heb0550a_3  
markdown                  3.3.3            py38h06a4308_0  
matplotlib                3.2.2                         0  
matplotlib-base           3.2.2            py38hef1b27d_0  
mkl                       2020.2                      256  
mkl-service               2.3.0            py38he904b0f_0  
mkl_fft                   1.2.0            py38h23d657b_0  
mkl_random                1.1.1            py38h0573a6f_0  
multidict                 4.7.6            py38h7b6447c_1  
ncurses                   6.2                  he6710b0_1  
nettle                    3.6                  he412f7d_0    conda-forge
numpy                     1.19.2           py38h54aff64_0  
numpy-base                1.19.2           py38hfa32c7d_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
oauthlib                  3.1.0                      py_0  
olefile                   0.46                       py_0  
opencv-python             4.5.1.48                 pypi_0    pypi
openh264                  2.1.1                h8b12597_0    conda-forge
openssl                   1.1.1i               h27cfd23_0  
opt_einsum                3.1.0                      py_0  
pathlib                   1.0.1                      py_1  
pcre                      8.44                 he6710b0_0  
pillow                    8.1.0            py38he98fc37_0  
pip                       20.3.3           py38h06a4308_0  
plaidml                   0.7.0                    pypi_0    pypi
plaidml-keras             0.7.0                    pypi_0    pypi
protobuf                  3.13.0.1         py38he6710b0_1  
psutil                    5.7.2            py38h7b6447c_0  
pyasn1                    0.4.8                      py_0  
pyasn1-modules            0.2.8                      py_0  
pycparser                 2.20                       py_2  
pyjwt                     1.7.1                    py38_0  
pyopenssl                 20.0.1             pyhd3eb1b0_1  
pyparsing                 2.4.7                      py_0  
pyqt                      5.9.2            py38h05f1152_4  
pysocks                   1.7.1            py38h06a4308_0  
python                    3.8.5                h7579374_1  
python-dateutil           2.8.1                      py_0  
python_abi                3.8                      1_cp38    conda-forge
pyyaml                    5.3.1                    pypi_0    pypi
qt                        5.9.7                h5867ecd_1  
readline                  8.0                  h7b6447c_0  
requests                  2.25.1             pyhd3eb1b0_0  
requests-oauthlib         1.3.0                      py_0  
rsa                       4.6                        py_0  
scikit-learn              0.23.2           py38h0573a6f_0  
scipy                     1.4.1                    pypi_0    pypi
setuptools                51.0.0           py38h06a4308_2  
sip                       4.19.13          py38he6710b0_0  
six                       1.15.0           py38h06a4308_0  
sqlite                    3.33.0               h62c20be_0  
tensorboard               2.2.2                    pypi_0    pypi
tensorboard-plugin-wit    1.6.0                      py_0  
tensorflow                2.2.0           mkl_py38h6d3daf0_0  
tensorflow-base           2.2.0           mkl_py38h5059a2d_0  
tensorflow-estimator      2.2.0              pyh208ff02_0  
termcolor                 1.1.0                    py38_1  
threadpoolctl             2.1.0              pyh5ca1d4c_0  
tk                        8.6.10               hbc83047_0  
tornado                   6.1              py38h27cfd23_0  
tqdm                      4.55.1             pyhd3eb1b0_0  
urllib3                   1.26.2             pyhd3eb1b0_0  
werkzeug                  1.0.1                      py_0  
wheel                     0.36.2             pyhd3eb1b0_0  
wrapt                     1.12.1           py38h7b6447c_1  
x264                      1!152.20180806       h14c3975_0    conda-forge
xz                        5.2.5                h7b6447c_0  
yarl                      1.6.3            py38h27cfd23_0  
zipp                      3.4.0              pyhd3eb1b0_0  
zlib                      1.2.11               h7b6447c_3  
zstd                      1.4.5                h9ceee32_0  

> ================= Configs ==================
> --------- gui.ini ---------

> [global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

> --------- train.ini ---------

> [global]
centering:                face
coverage:                 68.75
icnr_init:                False
conv_aware_init:          False
optimizer:                adam
learning_rate:            5e-05
reflect_padding:          False
allow_growth:             False
mixed_precision:          False
convert_batchsize:        16

> [global.loss]
loss_function:            ssim
mask_loss_function:       mse
l2_reg_term:              100
eye_multiplier:           3
mouth_multiplier:         2
penalized_mask_loss:      True
mask_type:                extended
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False

> [model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

> [model.dfaker]
output_size:              128

> [model.dlight]
features:                 best
details:                  good
output_size:              256

>[model.dfl_h128]
lowmem:                   False

> [model.villain]
lowmem:                   False

> [model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

> [model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

> [model.original]
lowmem:                   False

> [trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
disable_warp:             False
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4

> --------- extract.ini ---------

> [global]
allow_growth:             False

> [detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

> [detect.cv2_dnn]
confidence:               50

> [detect.s3fd]
confidence:               70
batch-size:               4

> [mask.vgg_clear]
batch-size:               6

> [mask.unet_dfl]
batch-size:               8

> [mask.vgg_obstructed]
batch-size:               2

> [align.fan]
batch-size:               12

> --------- convert.ini ---------

 > [scaling.sharpen]
method:                   none
amount:                   150
radius:                   0.3
threshold:                5.0

> [mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0

> [mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

> [writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

> [writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

> [writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

> [writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto
skip_mux:                 False

> [color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

> [color.color_transfer]
clip:                     True
preserve_paper:           True

> [color.match_hist]
threshold:                99.0

> --------- .faceswap ---------
backend:                  amd

that's all .thanks!",please post output help output system thanks reply output context output system system information master explicitly install ba merge pull request expand support merge branch travis test typo fix global version found check global version found check true total available used free pip file file file file file file cryptography file file file file file file file file file file file markdown file file file file pillow file file file file file file file file six file file tornado file file file yarl file file environment name version build channel main blas blinker click cryptography cycler gast glib lame markdown nettle pillow pip python sip six tornado wheel yarl global false tab extract font default prompt true global centering face coverage false false false false false true extended false false true best good false false true architecture false false false global false confidence confidence method none amount radius threshold type threshold erosion type distance radius loop false format false format false optimize false true container preset medium tune none profile auto level auto false contrast brightness clip true true threshold,issue,positive,negative,neutral,neutral,negative,negative
757400712,"> You can downgrade your driver to a pre-460 version. Ultimately this issue is an Nvidia driver issue. They have an open ticket for it, and it will eventually be resolved upstream.

I completely uninstalled drivers and installed 457.51 but the issue still persists.
I understand this is an NVidia issue, but I think this is worth an update to your Readme.",downgrade driver version ultimately issue driver issue open ticket eventually resolved upstream completely uninstalled issue still understand issue think worth update,issue,negative,positive,neutral,neutral,positive,positive
757397948,"@arturgontijo built out this - though it depends on singularity 3rd party hosted solution.

https://github.com/johndpope/dnn-model-services/tree/master/services/deepfakes-faceswap


UPDATE
@luckyluckydadada - cut this api service / and wrote up an article in Chinese
https://blog.csdn.net/weixin_41965898/article/details/84930788

**7 Code usage examples
1 Convert Wu Yanzu and Wang Baoqiang videos to frame sequence pictures**

```shell

ffmpeg -i video/wyz/yanzu.mp4 photo/wyz/video-frame-%d.png
ffmpeg -i video/wbq/wbq.mp4 photo/wbq/video-frame-%d.png

2 Cut out the face close-up picture and save it, and output the landmark to the json file
python faceswap.py extract -i photo/wyz -o photo/faces/wyz
python faceswap.py extract -i photo/wbq -o photo/faces/wbq

3 Train close-up photos of two people's faces
python faceswap.py train -A photo/faces/wyz -B photo/faces/wbq -m models/wyz_wbq

4 Convert Wu Yanzu's original frame sequence picture to Wang Baoqiang's frame sequence picture
python faceswap.py convert -i photo/wyz -o photo/wyz_wbq -m models/wyz_wbq

5 Combine the converted picture frames into a video, how to add audio please use Google
ffmpeg -i photo/wyz_wbq/video-frame-%0d.png -c:v libx264 -vf “fps=24,format=yuv420p” video/wyz_wbq/out.mp4
```

https://github.com/luckyluckydadada/faceswap

",built though singularity party solution update cut service wrote article code usage convert wang frame sequence shell cut face picture save output landmark file python extract python extract train two people python train convert original frame sequence picture wang frame sequence picture python convert combine converted picture video add audio please use,issue,positive,positive,positive,positive,positive,positive
757396943,"You can downgrade your driver to a pre-460 version. Ultimately this issue is an Nvidia driver issue. They have an open ticket for it, and it will eventually be resolved upstream.",downgrade driver version ultimately issue driver issue open ticket eventually resolved upstream,issue,negative,neutral,neutral,neutral,neutral,neutral
757393974,"Don't do this.

Use working drivers. The latest Nvidia drivers are meant to have fixed this issue, otherwise roll back to a version prior to 460.

Updating system library files is rarely a good idea.

(see here for reference: https://forum.faceswap.dev/viewtopic.php?f=4&t=1191
",use working latest meant fixed issue otherwise roll back version prior system library rarely good idea see reference,issue,negative,positive,positive,positive,positive,positive
757352919,"This has been merged into Master.

Whilst Faceswap will now run on the Tensorflow 2.4 api, it will not install it by default (We still need to wait for Conda to update for this).

I have some instructions here: 
https://forum.faceswap.dev/viewtopic.php?f=4&t=1226

However, you are on your own, and we won't directly support this until we can pull Cuda 11 in from Conda.",master whilst run install default still need wait update however wo directly support pull,issue,negative,positive,neutral,neutral,positive,positive
757352399,"Yep, it's mostly covered there. Either way, the best place for this kind of discussion is our [forum](https://faceswap.dev/forum) or [Discord](https://discord.gg/FC54sYg)",yep mostly covered either way best place kind discussion forum discord,issue,positive,positive,positive,positive,positive,positive
757352165,"None of the current Devs use Docker, however a user has kindly raised a PR which hopefully addresses this which is now in the main code.",none current use docker however user kindly raised hopefully main code,issue,positive,positive,positive,positive,positive,positive
757351913,The best place for this kind of discussion is our [forum](https://faceswap.dev/forum) or [Discord](https://discord.gg/FC54sYg),best place kind discussion forum discord,issue,positive,positive,positive,positive,positive,positive
757351401,"If there is anyway you can provide your training images + alignment files, I can look into this.",anyway provide training alignment look,issue,negative,neutral,neutral,neutral,neutral,neutral
757351255,Please post output of Help>Output System Informaton,please post output help output system,issue,positive,neutral,neutral,neutral,neutral,neutral
757055643,"I guess if you go through the guide of Extraction, Training and Convert at https://faceswap.dev/. You will have an overview of the whole process procedure and the underlying algorithm. 
",guess go guide extraction training convert overview whole process procedure underlying algorithm,issue,negative,positive,positive,positive,positive,positive
756575853,"Never mind, the solution is to run the python inside the conda environment. bash was defaulting to the system-wide python. Use `~/anaconda3/envs/<name>/bin/python3.8 faceswap.py gui` for the correct functionality. ",never mind solution run python inside environment bash python use name correct functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
754133213,"Many thanks for this. None of the current Devs use Docker, but this looks good on the face of it.

I'll leave this for a couple of days in case there is any feedback from other Docker users.",many thanks none current use docker good face leave couple day case feedback docker,issue,positive,positive,positive,positive,positive,positive
754085019,"> > Not sure if you all actually care about that failing check but that was done prior to this commit [b67f91e](https://github.com/deepfakes/faceswap/commit/b67f91ea0b9d75bd9a2b1c312eedc7ff2e47a2b1)
> 
> Also, please fix the linting errors from pep8speaks nagbot.

Fixed",sure actually care failing check done prior commit also please fix fixed,issue,positive,positive,positive,positive,positive,positive
753668013,"> > Not sure if you all actually care about that failing check but that was done prior to this commit [b67f91e](https://github.com/deepfakes/faceswap/commit/b67f91ea0b9d75bd9a2b1c312eedc7ff2e47a2b1)
> 
> What is this PR meant to do exactly? Sorry, I'm a little confused because it shows changes to the legacy landmarks update (now super old code), but references existing alignments files.
> 
> Also, please fix the linting errors from pep8speaks nagbot.

If you input an already existing alignment file, the script will crash with the key error, see [here](https://discord.com/channels/441989398465085440/537225614852227082/793745224953495552)
My PR just adds a warning telling the user that the alignments file that they are attempting to write to already exists. ",sure actually care failing check done prior commit meant exactly sorry little confused legacy update super old code also please fix input already alignment file script crash key error see warning telling user file write already,issue,negative,negative,neutral,neutral,negative,negative
752975064,"> 
> 
> Not sure if you all actually care about that failing check but that was done prior to this commit [b67f91e](https://github.com/deepfakes/faceswap/commit/b67f91ea0b9d75bd9a2b1c312eedc7ff2e47a2b1)

No. That's fine. I pushed the fix when I saw this failing.
What is this PR meant to do exactly? Sorry, I'm a little confused because it shows changes to the legacy landmarks update (now super old code), but references existing alignments files.

Also, please fix the linting errors from pep8speaks nagbot.
",sure actually care failing check done prior commit fine fix saw failing meant exactly sorry little confused legacy update super old code also please fix,issue,positive,positive,neutral,neutral,positive,positive
752807707,"I welcome cleaning up of the grammar/spelling as  long as it is done in a single PR and not 1 word changes here and there in separate PRs....

The main cli arguments are here:
https://github.com/deepfakes/faceswap/blob/master/lib/cli/args.py

The config items can be found in the plugins folder (search for files called `_config.py`) for each  plugin type, and some plugins also have their own config items (`<plugin_name>_defaults.py`)
",welcome cleaning long done single word separate main found folder search type also,issue,negative,positive,positive,positive,positive,positive
752671292,Not sure if you all actually care about that failing check but that was done prior to this commit b67f91e,sure actually care failing check done prior commit,issue,positive,positive,positive,positive,positive,positive
752174836,"Hello @CaptainStabs! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`lib/align/alignments.py`](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py):

> [Line 697:13](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py#L697): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 698:17](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py#L698): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 699:21](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py#L699): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 705:1](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py#L705): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> [Line 708:1](https://github.com/deepfakes/faceswap/blob/51d9c097cf34c1e99906742b151ad388250eadbe/lib/align/alignments.py#L708): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace



##### Comment last updated at 2020-12-29 17:35:34 UTC",hello thanks checked touched pep found file line continuation line visual indent line continuation line visual indent line continuation line visual indent line blank line line blank line comment last,issue,negative,positive,neutral,neutral,positive,positive
752133864,"> Ok, this should be fixed in the latest version.
> 
> It seems that AMD backend is no longer compatible with Tensorboard logging above Tensorflow version 2.2.
> 
> As this is a dependency regression, it is best that you delete your Faceswap folder + re-run the installer. This should get things working again.

I can confirm that, after I removed `tensorflow` from my Conda environment and installed `tensorflow-2.2.0` all is working correctly. Many thanks for the great work @torzdf!",fixed latest version longer compatible logging version dependency regression best delete folder installer get working confirm removed environment working correctly many thanks great work,issue,positive,positive,positive,positive,positive,positive
751734165,"Ok, this should be fixed in the latest version.

It seems that AMD backend is no longer compatible with Tensorboard logging above Tensorflow version 2.2.

As this is a dependency regression, it is best that you delete your Faceswap folder + re-run the installer. This should get things working again.",fixed latest version longer compatible logging version dependency regression best delete folder installer get working,issue,positive,positive,positive,positive,positive,positive
751523844,"> Did you tried the branch with Tensorflow 2.4? @HilalHk 

No luck, I tried.",tried branch luck tried,issue,negative,neutral,neutral,neutral,neutral,neutral
751512463,"I have the same problem on my MacBook Pro, currently trying to find a workaround not involving using my CPU as a toaster...",problem pro currently trying find toaster,issue,negative,neutral,neutral,neutral,neutral,neutral
751511684,"same issue as https://forum.faceswap.dev/viewtopic.php?t=1210

I'm currently using v1 of faceswap, this worked : https://newreleases.io/project/github/deepfakes/faceswap/release/v1.0.0

Let me know if i can help :)",issue currently worked let know help,issue,negative,neutral,neutral,neutral,neutral,neutral
751462012,"In the first instance try this:

https://forum.faceswap.dev/app.php/faqpage#f1r1

If you are still having issues then you will need to look for support from Anaconda, as these are network issues.",first instance try still need look support anaconda network,issue,negative,positive,positive,positive,positive,positive
743324998,"Ok, the main issue I see with this PR is that even if it is pinned to tf2.4_rc4, then it still will not work fully on RTX 3xxx cards, as ALL Tensorflow pip 2.4 packages are compiled with Cuda 11.0 and the 3xxx cards require Cuda 11.1.

Any work that Faceswap do to support a currently unreleased TF version is for nothing as end users will still need to compile their own Tensorflow version. And if they need to do that, they might as well compile a supported version.",main issue see even pinned still work fully pip require work support currently unreleased version nothing end still need compile version need might well compile version,issue,positive,positive,neutral,neutral,positive,positive
741157630,"> 
> 
> On Ampere, mixed_precision is turned on automatically, even if you set it to false in faceswap app. I think seting it to false should disable it on Ampere also. I will collect all issues I have faced on Ampere and paste them here.

Thanks. I do not currently have an Ampere GPU so will just be working through issues on TF2.4rc + Cuda 11.1 on an RTX 2080Ti",ampere turned automatically even set false think false disable ampere also collect faced ampere paste thanks currently ampere working ti,issue,negative,negative,negative,negative,negative,negative
740841263,"On Ampere, mixed_precision is turned on automatically, even if you set it to false in faceswap app. I think seting it to false should disable it on Ampere also.  I will collect all issues I have faced on Ampere and paste them here.",ampere turned automatically even set false think false disable ampere also collect faced ampere paste,issue,negative,negative,negative,negative,negative,negative
739455712,"I solved it, because of the CUDA driver version is insufficient for CUDA runtime version
",driver version insufficient version,issue,negative,neutral,neutral,neutral,neutral,neutral
739255551,"No one has provided a crash report, hence the issue closed.

Please open a new issue with the crash report for support.",one provided crash report hence issue closed please open new issue crash report support,issue,negative,positive,neutral,neutral,positive,positive
738721695,"This looks like a system issue rather than a bug in the software.

You should look for support either at our Forum (https://forum.faceswap.dev/index.php) or Discord (https://discord.gg/FC54sYg)",like system issue rather bug look support either forum discord,issue,negative,neutral,neutral,neutral,neutral,neutral
738709701,"Contributors can be found here:
https://github.com/deepfakes/faceswap/graphs/contributors

Any further questions should be directed to our forum (https://forum.faceswap.dev/index.php) or Discord (https://discord.gg/FC54sYg)",found directed forum discord,issue,negative,neutral,neutral,neutral,neutral,neutral
738492665,"> Looking at your EG/s and you system info, I'm pretty sure you are running on GPU. What makes you think you're not?

I see it from system resources monitor....",looking system pretty sure running think see system monitor,issue,positive,positive,positive,positive,positive,positive
737862326,"Looking at your EG/s and you system info, I'm pretty sure you are running on GPU. What makes you think you're not?",looking system pretty sure running think,issue,positive,positive,positive,positive,positive,positive
737835132,"> All of it :/
```
============ System Information ============
encoding:            cp936
git_branch:          master
git_commits:         c24bf2b GUI - Revert Conda default font fix
gpu_cuda:            10.1
gpu_cudnn:           7.6.5
gpu_devices:         GPU_0: Quadro P600
gpu_devices_active:  GPU_0
gpu_driver:          419.72
gpu_vram:            GPU_0: 4096MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.18362-SP0
os_release:          10
py_command:          faceswap.py gui
py_conda_version:    conda 4.8.3
py_implementation:   CPython
py_version:          3.8.5
py_virtual_env:      True
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
sys_ram:             Total: 32623MB, Available: 9175MB, Used: 23448MB, Free: 9175MB

=============== Pip Packages ===============
absl-py==0.11.0
astunparse==1.6.3
cachetools==4.1.1
certifi==2020.11.8
chardet==3.0.4
cycler==0.10.0
fastcluster==1.1.26
ffmpy==0.2.3
gast==0.3.3
google-auth==1.23.0
google-auth-oauthlib==0.4.2
google-pasta==0.2.0
grpcio==1.33.2
h5py==2.10.0
idna==2.10
imageio @ file:///tmp/build/80754af9/imageio_1594161405741/work
imageio-ffmpeg @ file:///home/conda/feedstock_root/build_artifacts/imageio-ffmpeg_1589202782679/work
joblib @ file:///tmp/build/80754af9/joblib_1601912903842/work
Keras-Preprocessing==1.1.2
kiwisolver @ file:///C:/ci/kiwisolver_1604014703538/work
Markdown==3.3.3
matplotlib @ file:///C:/ci/matplotlib-base_1592837548929/work
mkl-fft==1.2.0
mkl-random==1.1.1
mkl-service==2.3.0
numpy==1.18.5
nvidia-ml-py3 @ git+https://github.com/deepfakes/nvidia-ml-py3.git@6fc29ac84b32bad877f078cb4a777c1548a00bf6
oauthlib==3.1.0
olefile==0.46
opencv-python==4.4.0.46
opt-einsum==3.3.0
pathlib==1.0.1
Pillow @ file:///C:/ci/pillow_1603823068645/work
protobuf==3.14.0
psutil @ file:///C:/ci/psutil_1598370330503/work
pyasn1==0.4.8
pyasn1-modules==0.2.8
pyparsing==2.4.7
python-dateutil==2.8.1
pywin32==227
requests==2.25.0
requests-oauthlib==1.3.0
rsa==4.6
scikit-learn @ file:///C:/ci/scikit-learn_1598377018496/work
scipy @ file:///C:/ci/scipy_1604596260408/work
sip==4.19.13
six @ file:///C:/ci/six_1605187374963/work
tensorboard==2.2.2
tensorboard-plugin-wit==1.7.0
tensorflow-gpu @ file:///D:/Karol_face_swap/tensorflow_gpu-2.2.1-cp38-cp38-win_amd64.whl
tensorflow-gpu-estimator==2.2.0
termcolor==1.1.0
threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl
tornado==6.0.4
tqdm @ file:///tmp/build/80754af9/tqdm_1605303662894/work
urllib3==1.26.2
Werkzeug==1.0.1
wincertstore==0.2
wrapt==1.12.1

============== Conda Packages ==============
# packages in environment at D:\Anaconda\envs\karol_faceswap:
#
# Name                    Version                   Build  Channel
absl-py                   0.11.0                   pypi_0    pypi
astunparse                1.6.3                    pypi_0    pypi
blas                      1.0                         mkl  
ca-certificates           2020.10.14                    0  
cachetools                4.1.1                    pypi_0    pypi
certifi                   2020.11.8        py38haa95532_0  
chardet                   3.0.4                    pypi_0    pypi
cudatoolkit               10.1.243             h74a9793_0  
cudnn                     7.6.5                cuda10.1_0  
cycler                    0.10.0                   py38_0  
fastcluster               1.1.26           py38h251f6bf_2    conda-forge
ffmpeg                    4.3.1                ha925a31_0    conda-forge
ffmpy                     0.2.3                    pypi_0    pypi
freetype                  2.10.4               hd328e21_0  
gast                      0.3.3                    pypi_0    pypi
google-auth               1.23.0                   pypi_0    pypi
google-auth-oauthlib      0.4.2                    pypi_0    pypi
google-pasta              0.2.0                    pypi_0    pypi
grpcio                    1.33.2                   pypi_0    pypi
h5py                      2.10.0                   pypi_0    pypi
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha925a31_3  
idna                      2.10                     pypi_0    pypi
imageio                   2.9.0                      py_0  
imageio-ffmpeg            0.4.2                      py_0    conda-forge
intel-openmp              2020.2                      254  
joblib                    0.17.0                     py_0  
jpeg                      9b                   hb83a4c4_2  
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.3.0            py38hd77b12b_0  
libpng                    1.6.37               h2a8f88b_0  
libtiff                   4.1.0                h56a325e_1  
lz4-c                     1.9.2                hf4a77e7_3  
markdown                  3.3.3                    pypi_0    pypi
matplotlib                3.2.2                         0  
matplotlib-base           3.2.2            py38h64f37c6_0  
mkl                       2020.2                      256  
mkl-service               2.3.0            py38h2bbff1b_0  
mkl_fft                   1.2.0            py38h45dec08_0  
mkl_random                1.1.1            py38h47e9c7a_0  
numpy                     1.18.5                   pypi_0    pypi
nvidia-ml-py3             7.352.1                  pypi_0    pypi
oauthlib                  3.1.0                    pypi_0    pypi
olefile                   0.46                       py_0  
opencv-python             4.4.0.46                 pypi_0    pypi
openssl                   1.1.1h               he774522_0  
opt-einsum                3.3.0                    pypi_0    pypi
pathlib                   1.0.1                      py_1  
pillow                    8.0.1            py38h4fa10fc_0  
pip                       20.3             py38haa95532_0  
protobuf                  3.14.0                   pypi_0    pypi
psutil                    5.7.2            py38he774522_0  
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pyparsing                 2.4.7                      py_0  
pyqt                      5.9.2            py38ha925a31_4  
python                    3.8.5                h5fd99cc_1  
python-dateutil           2.8.1                      py_0  
python_abi                3.8                      1_cp38    conda-forge
pywin32                   227              py38he774522_1  
qt                        5.9.7            vc14h73c81de_0  
requests                  2.25.0                   pypi_0    pypi
requests-oauthlib         1.3.0                    pypi_0    pypi
rsa                       4.6                      pypi_0    pypi
scikit-learn              0.23.2           py38h47e9c7a_0  
scipy                     1.5.2            py38h14eb087_0  
setuptools                50.3.1           py38haa95532_1  
sip                       4.19.13          py38ha925a31_0  
six                       1.15.0           py38haa95532_0  
sqlite                    3.33.0               h2a8f88b_0  
tensorboard               2.2.2                    pypi_0    pypi
tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
tensorflow-gpu            2.2.1                    pypi_0    pypi
tensorflow-gpu-estimator  2.2.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
threadpoolctl             2.1.0              pyh5ca1d4c_0  
tk                        8.6.10               he774522_0  
tornado                   6.0.4            py38he774522_1  
tqdm                      4.51.0             pyhd3eb1b0_0  
urllib3                   1.26.2                   pypi_0    pypi
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.16.27012          hf0eaf9b_3  
werkzeug                  1.0.1                    pypi_0    pypi
wheel                     0.35.1             pyhd3eb1b0_0  
wincertstore              0.2                      py38_0  
wrapt                     1.12.1                   pypi_0    pypi
xz                        5.2.5                h62dcd97_0  
zlib                      1.2.11               h62dcd97_4  
zstd                      1.4.5                h04227a9_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0

[scaling.sharpen]
method:                   none
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto
skip_mux:                 False

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               12

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.s3fd]
confidence:               70
batch-size:               4

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.vgg_obstructed]
batch-size:               2

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

--------- train.ini ---------

[global]
coverage:                 68.75
icnr_init:                False
conv_aware_init:          False
optimizer:                adam
learning_rate:            5e-05
reflect_padding:          False
allow_growth:             False
mixed_precision:          False
convert_batchsize:        16

[global.loss]
loss_function:            ssim
mask_loss_function:       mse
l2_reg_term:              100
eye_multiplier:           3
mouth_multiplier:         2
penalized_mask_loss:      True
mask_type:                extended
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.dlight]
features:                 best
details:                  good
output_size:              256

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
disable_warp:             False
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```",system information master revert default font fix true family model stepping total available used free pip file file file file file pillow file file file file six file file file file environment name version build channel blas cycler gast markdown pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type threshold erosion method none amount radius threshold container preset medium tune none profile auto level auto false loop false format false format false optimize false true global false confidence confidence global false tab extract font default prompt true global coverage false false false false false true extended false false true architecture false best good false false true false false,issue,positive,negative,neutral,neutral,negative,negative
737223980,"You're best off looking at this thread for GPU stuff as it gets updated fairly regularly.
https://forum.faceswap.dev/viewtopic.php?f=16&t=10

For RAM, I deliberately dev on a machine limited to 8GB RAM so anything over and above this will be fine.
",best looking thread stuff fairly regularly ram deliberately dev machine limited ram anything fine,issue,positive,positive,positive,positive,positive,positive
737222775,"> Please post the output (from the GUI) of `Help` > `Output System Information` and post output here.

============ System Information ============
encoding:            cp936
git_branch:          master
git_commits:         c24bf2b GUI - Revert Conda default font fix
gpu_cuda:            10.1
gpu_cudnn:           7.6.5
gpu_devices:         GPU_0: Quadro P600
gpu_devices_active:  GPU_0
gpu_driver:          419.72
gpu_vram:            GPU_0: 4096MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.18362-SP0
os_release:          10
py_command:          faceswap.py gui
py_conda_version:    conda 4.8.3
py_implementation:   CPython
py_version:          3.8.5
py_virtual_env:      True
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
sys_ram:             Total: 32623MB, Available: 19988MB, Used: 12635MB, Free: 19988MB",please post output help output system information post output system information master revert default font fix true family model stepping total available used free,issue,positive,positive,positive,positive,positive,positive
737220970,Please post the output (from the GUI) of `Help` > `Output System Information` and post output here.,please post output help output system information post output,issue,positive,neutral,neutral,neutral,neutral,neutral
732514314,"> so you may never get this to work.

what you mean ， could you like to give some detail, why i may never get this to work.  It is AMD vega 8, can be work? :)",may never get work mean could like give detail may never get work work,issue,negative,negative,negative,negative,negative,negative
732278184,"> self._as_parameter_ = _lib().plaidml_schedule_invocation(ctx, invoker)
> OSError: exception: access violation writing 0x0000000000000010
> 

This is a GPU memory error. You can try lowering the batch (Settings > Extract Settings), find all the plugins and lower to 1.

However, I believe you are using an integrated GPU, so you may never get this to work.
",invoker exception access violation writing memory error try lowering batch extract find lower however believe may never get work,issue,negative,neutral,neutral,neutral,neutral,neutral
731757946,"I have the same crash issues at the last version on master branch.
I am tring to extract face a 60 min vedio, but when the process most done, the crash happend.
something like this:
    return Invocation(self._ctx, self)
  File ""..\lib\site-packages\plaidml\__init__.py"", line 1484, in __init__
    self._as_parameter_ = _lib().plaidml_schedule_invocation(ctx, invoker)
OSError: exception: access violation writing 0x0000000000000010


@torzdf 
the total log as annx. thanks. please give me some advise.
[crash_report.2020.11.22.222458711067.log](https://github.com/deepfakes/faceswap/files/5579663/crash_report.2020.11.22.222458711067.log)

I think something worng with the mem, because when the crash happend, sys mem only a little 
Total: 7103MB, Available: 18MB, Used: 7084MB, Free: 19MB
....

how can i fixed that?  is there someplace can set to save the infomation to disk, just not handler on in mem?

#+==============================
I had fixed the problem by adjust params",crash last version master branch extract face min process done crash something like return invocation self file line invoker exception access violation writing total log thanks please give advise log think something mem crash mem little total available used free fixed someplace set save disk handler mem fixed problem adjust,issue,negative,positive,positive,positive,positive,positive
729391955,restart the installer and if that doesn't work delete and download the installer again (turning off ur antivirus might help),restart installer work delete installer turning ur antivirus might help,issue,negative,neutral,neutral,neutral,neutral,neutral
727192312,"Thanks for this. I am currently working on implementing some other work, but will review when I can....

I won't be implementing to main repo until 2.4 is released (due to potential API changes), and whilst we will add support for tf 2.4, we won't add it to requirements until Conda update their packages.

Something to bear in mind, at least whilst we transition, we will need support for 2.2 - 2.4, which will require some branching logic. This is due to Conda generally being behind Pip.",thanks currently working work review wo main due potential whilst add support wo add update something bear mind least whilst transition need support require branching logic due generally behind pip,issue,positive,negative,neutral,neutral,negative,negative
727191244,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
725939815,"Hi, I created https://github.com/deepfakes/faceswap/pull/1086 which includes update TensorFlow to 2.4.0rc1. I tested it with 3080 and basic stuff is working, there is a problem with few things like the learning graph and analysis table.",hi update tested basic stuff working problem like learning graph analysis table,issue,negative,neutral,neutral,neutral,neutral,neutral
725937808,"Hello @dmiszkiewicz! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:



* In the file [`lib/gui/stats.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/lib/gui/stats.py):

> [Line 20:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/lib/gui/stats.py#L20): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)

* In the file [`plugins/extract/_base.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/_base.py):

> [Line 9:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/_base.py#L9): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)

* In the file [`plugins/extract/align/_base.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/align/_base.py):

> [Line 20:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/align/_base.py#L20): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)

* In the file [`plugins/extract/detect/_base.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/detect/_base.py):

> [Line 21:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/detect/_base.py#L21): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)

* In the file [`plugins/extract/mask/_base.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/mask/_base.py):

> [Line 19:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/extract/mask/_base.py#L19): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)



* In the file [`plugins/train/trainer/_base.py`](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/train/trainer/_base.py):

> [Line 21:100](https://github.com/deepfakes/faceswap/blob/c33cd991e55d79adbdab88acfc5b6ceb3706572d/plugins/train/trainer/_base.py#L21): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)



##### Comment last updated at 2020-12-08 11:52:26 UTC",hello thanks checked touched pep found file line line long file line line long file line line long file line line long file line line long file line line long comment last,issue,negative,negative,neutral,neutral,negative,negative
723721130,"@torzdf maybe I can help with this, can you point me to the right set of files to look at?",maybe help point right set look,issue,negative,positive,positive,positive,positive,positive
721252371,"Thanks for this.... I won't implement until Tensorflow 2.4 releases in case of API changes....

Ideally I'd wait for Conda to update too, but I know people are sitting on their 3xxx cards wanting to get going.",thanks wo implement case ideally wait update know people sitting wanting get going,issue,positive,positive,positive,positive,positive,positive
710857838,"This is a problem with your video file. Try converting it to mp4. Ultimately the header of your video file has not stored the duration correctly.
",problem video file try converting ultimately header video file duration correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
706210057,"There isn't a trained model. You need to train it yourself.

See here:
https://forum.faceswap.dev/app.php/tag/Guide

",trained model need train see,issue,negative,neutral,neutral,neutral,neutral,neutral
703896012,"A better place for these kinds of messages is in our Discord (https://discord.gg/FC54sYg) or at our forum (https://faceswap.dev/forum), where you are welcome to join.",better place discord forum welcome join,issue,positive,positive,positive,positive,positive,positive
703895912,"Your GPU isn't detected. Make sure you have the latest AMDGPU PRO drivers installed.

If you still have issues, enter your faceswap environment and run `plaidml-setup`",make sure latest pro still enter environment run,issue,negative,positive,positive,positive,positive,positive
703184608,"That's a corrupted model file. Use the ""Restore"" Tool to recover it.",corrupted model file use restore tool recover,issue,negative,neutral,neutral,neutral,neutral,neutral
703184508,"Well, that's very nice to say, and your support is appreciated.

A better place for these kinds of messages is in our Discord (https://discord.gg/FC54sYg) or at our forum (https://faceswap.dev/forum), where you are welcome to join.
",well nice say support better place discord forum welcome join,issue,positive,positive,positive,positive,positive,positive
699563033,"I'm closing this, as this section has been rewritten. Any new bugs pertaining to this area should open a new issue.",section new pertaining area open new issue,issue,negative,positive,neutral,neutral,positive,positive
699562141,"This issue has been superseded by quite a substantial update, so I'm closing it.

Unfortunately, whilst we have a Docker container, which (I think) still works, none of the current devs use it, so it is unsupported.

We welcome PRs to keep it working, but that is as far as our support goes on it. If it finally bites the bullet, it will be, sadly, removed.",issue quite substantial update unfortunately whilst docker container think still work none current use unsupported welcome keep working far support go finally bullet sadly removed,issue,positive,negative,neutral,neutral,negative,negative
699561822,"I would very much welcome a PR on this, to investigate it's usefulness, but it is unlikely I would develop anything like it.

I would guess this would be best as a tool, perhaps part of the sort tool (which really needs a rework anyway),",would much welcome investigate usefulness unlikely would develop anything like would guess would best tool perhaps part sort tool really need rework anyway,issue,positive,positive,positive,positive,positive,positive
699561663,"Unfortunately, whilst we have a Docker container, which (I think) still works, none of the current devs use it, so it is unsupported.

We welcome PRs to keep it working, but that is as far as our support goes on it.",unfortunately whilst docker container think still work none current use unsupported welcome keep working far support go,issue,positive,positive,neutral,neutral,positive,positive
699561503,"I believe this bug has been fixed. If not, please reopen with a new crash report",believe bug fixed please reopen new crash report,issue,negative,positive,positive,positive,positive,positive
699561239,"This is an error which only seems to happen on Windows, and I haven't found the cause of it.",error happen found cause,issue,negative,neutral,neutral,neutral,neutral,neutral
699561043,"For some reason you don't have psutil installed, so I can't see the whole log.

However this looks like the same issue: #1071 
",reason ca see whole log however like issue,issue,negative,positive,positive,positive,positive,positive
699560574,"Please update to latest code and try again.

I have just tried this model with your settings, and it trains fine. ",please update latest code try tried model fine,issue,negative,positive,positive,positive,positive,positive
699001785,"@torzdf thanks for the fast response, so would you recommend using Linux / Windows then?",thanks fast response would recommend,issue,positive,positive,positive,positive,positive,positive
698852119,"I doubt anything like this will be implemented... I simply do not have the time, although anyone else is welcome to post benchmark stats.

Probably the best place for this discussion is on our discord (https://discord.gg/FC54sYg) or our forum (https://forum.faceswap.dev/index.php) though.",doubt anything like simply time although anyone else welcome post probably best place discussion discord forum though,issue,positive,positive,positive,positive,positive,positive
696354860,"I don't know who added that help text (well, I do), but it's a guide at best.

S3FD takes close to 4GB just for the model itself. It's possible that means 2GB + the model size.

Ultimately, @bryanlyon is correct. These are not bugs. Reduce your batch size.",know added help text well guide best close model possible model size ultimately correct reduce batch size,issue,positive,positive,positive,positive,positive,positive
695901253,"I have 4Gb of vram. It's not small. System tell that size batch = 8 is normal for 2 gb. So i expect that work with 16 value, not with 3
![Screenshot (349)](https://user-images.githubusercontent.com/35644089/93734214-9f291980-fbd8-11ea-86f5-9716fd6662f2.png)

![Screenshot (350)](https://user-images.githubusercontent.com/35644089/93734247-c41d8c80-fbd8-11ea-9af5-681c1115312c.png)

",small system tell size batch normal expect work value,issue,negative,negative,neutral,neutral,negative,negative
695892675,"These are not a bugs and are mostly normal.  You have a very small amount of vram and it sounds like 3 is the largest batch size you can support.  The FSA is created with the original video unless you specify differently.  This is as designed.  PlaidML is converting Cuda Ops to OpenCL and some warning messages are normal.  As long as it's training that's fine.

On the forum: Check your spam/junk folder.  I guarantee it sends an email every time.  You can also join our Discord if you have any questions.",mostly normal small amount like batch size support original video unless specify differently designed converting warning normal long training fine forum check folder guarantee every time also join discord,issue,positive,positive,positive,positive,positive,positive
690813730,"S3Fd for some reason is not working. +1
No matter what video is used, it is the same error👇
`
OverflowError: cannot convert float infinity to integer
`",reason working matter video used error convert float infinity integer,issue,negative,neutral,neutral,neutral,neutral,neutral
687648505,"Sure, please email me at bryanlyon@faceswap.dev and we can arrange for you to transfer it.",sure please arrange transfer,issue,positive,positive,positive,positive,positive,positive
687648225,"Issues are for code bugs not for technical support. You can go to the forums or discord for support. I suggest starting here https://forum.faceswap.dev/app.php/faqpage?sid=0cf9364decab1e655b7a44b4a450a885#f1r1
",code technical support go discord support suggest starting,issue,negative,neutral,neutral,neutral,neutral,neutral
678888695,"hi @torzdf, this causes some issues because there is no handy gpu tensorflow image with py3.7, can you maybe utilize the fix that is shown in [this SO post](https://stackoverflow.com/a/45187287)?

I ask *maybe* because I haven't fully confirmed the minor change for testing.  With an update of the `Dockerfile.gpu` to ``tensorflow/tensorflow:2.2.0rc2-gpu-py3`` the handy usage guide is working at least to the extract stage...

```
class NullContextManager(object):
    def __init__(self, dummy_resource=None):
        self.dummy_resource = dummy_resource
    def __enter__(self):
        return self.dummy_resource
    def __exit__(self, *args):
        pass
```",hi handy image maybe utilize fix shown post ask maybe fully confirmed minor change testing update handy usage guide working least extract stage class object self self return self pas,issue,negative,positive,positive,positive,positive,positive
677815799,"The log file :

08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'align_cv2-dnn_aligner_predict_0'
08/20/2020 17:47:53 MainProcess     align_cv2-dnn_aligner_predict_0 _base           _thread_process           DEBUG    threading: (function: '_predict')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'align_cv2-dnn_aligner_predict': 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'align_cv2-dnn_aligner_output'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'align_cv2-dnn_aligner_output_0'
08/20/2020 17:47:53 MainProcess     align_cv2-dnn_aligner_output_0 _base           _thread_process           DEBUG    threading: (function: 'process_output')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'align_cv2-dnn_aligner_output': 1
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launched align plugin
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launching mask_0 plugin
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    in_qname: extract0_mask_0_in, out_qname: extract0_mask_1_in
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                DEBUG    initialize Mask: (args: (), kwargs: {'in_queue': <queue.Queue object at 0x7ff0f7a90d00>, 'out_queue': <queue.Queue object at 0x7ff0f7a90ac0>})
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                INFO     Initializing Components (Mask)...
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'mask0_predict_components'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'mask0_predict_components', maxsize: 1)
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'mask0_predict_components')
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'mask0_predict_components'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'mask0_post_components'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'mask0_post_components', maxsize: 1)
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'mask0_post_components')
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'mask0_post_components'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiling mask threads
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_components_input, function: <bound method Mask.process_input of <plugins.extract.mask.components.Mask object at 0x7ff0f7aecf40>>, in_queue: <queue.Queue object at 0x7ff0f7a90d00>, out_queue: <queue.Queue object at 0x7ff0d43d72b0>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_components_input', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_components_input'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_components_input
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_components_predict, function: <bound method Masker._predict of <plugins.extract.mask.components.Mask object at 0x7ff0f7aecf40>>, in_queue: <queue.Queue object at 0x7ff0d43d72b0>, out_queue: <queue.Queue object at 0x7ff0d43d7850>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_components_predict', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_components_predict'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_components_predict
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_components_output, function: <bound method Mask.process_output of <plugins.extract.mask.components.Mask object at 0x7ff0f7aecf40>>, in_queue: <queue.Queue object at 0x7ff0d43d7850>, out_queue: <queue.Queue object at 0x7ff0f7a90ac0>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_components_output', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_components_output'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_components_output
08/20/2020 17:47:53 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiled mask threads: [<lib.multithreading.MultiThread object at 0x7ff0d43ceb50>, <lib.multithreading.MultiThread object at 0x7ff0d43d79d0>, <lib.multithreading.MultiThread object at 0x7ff0d43d7a00>]
08/20/2020 17:47:53 MainProcess     MainThread      components      init_model                DEBUG    No mask model to initialize
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                INFO     Initialized Components (Mask) with batchsize of 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_components_input'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_components_input_0'
08/20/2020 17:47:53 MainProcess     mask_components_input_0 _base           _thread_process           DEBUG    threading: (function: 'process_input')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_components_input': 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_components_predict'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_components_predict_0'
08/20/2020 17:47:53 MainProcess     mask_components_predict_0 _base           _thread_process           DEBUG    threading: (function: '_predict')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_components_predict': 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_components_output'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_components_output_0'
08/20/2020 17:47:53 MainProcess     mask_components_output_0 _base           _thread_process           DEBUG    threading: (function: 'process_output')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_components_output': 1
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launched mask_0 plugin
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launching mask_1 plugin
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    in_qname: extract0_mask_1_in, out_qname: extract0_mask_1_out
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                DEBUG    initialize Mask: (args: (), kwargs: {'in_queue': <queue.Queue object at 0x7ff0f7a90ac0>, 'out_queue': <queue.Queue object at 0x7ff0f7a970a0>})
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                INFO     Initializing Extended (Mask)...
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'mask0_predict_extended'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'mask0_predict_extended', maxsize: 1)
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'mask0_predict_extended')
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'mask0_predict_extended'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'mask0_post_extended'
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'mask0_post_extended', maxsize: 1)
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'mask0_post_extended')
08/20/2020 17:47:53 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'mask0_post_extended'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiling mask threads
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_extended_input, function: <bound method Mask.process_input of <plugins.extract.mask.extended.Mask object at 0x7ff0f7aecd60>>, in_queue: <queue.Queue object at 0x7ff0f7a90ac0>, out_queue: <queue.Queue object at 0x7ff0d43ce820>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_extended_input', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_extended_input'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_extended_input
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_extended_predict, function: <bound method Masker._predict of <plugins.extract.mask.extended.Mask object at 0x7ff0f7aecd60>>, in_queue: <queue.Queue object at 0x7ff0d43ce820>, out_queue: <queue.Queue object at 0x7ff0d43eb280>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_extended_predict', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_extended_predict'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_extended_predict
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: mask_extended_output, function: <bound method Mask.process_output of <plugins.extract.mask.extended.Mask object at 0x7ff0f7aecd60>>, in_queue: <queue.Queue object at 0x7ff0d43eb280>, out_queue: <queue.Queue object at 0x7ff0f7a970a0>)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'mask_extended_output', thread_count: 1)
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'mask_extended_output'
08/20/2020 17:47:53 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: mask_extended_output
08/20/2020 17:47:53 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiled mask threads: [<lib.multithreading.MultiThread object at 0x7ff0d43d7a30>, <lib.multithreading.MultiThread object at 0x7ff0d43eb550>, <lib.multithreading.MultiThread object at 0x7ff0d43eb580>]
08/20/2020 17:47:53 MainProcess     MainThread      extended        init_model                DEBUG    No mask model to initialize
08/20/2020 17:47:53 MainProcess     MainThread      _base           initialize                INFO     Initialized Extended (Mask) with batchsize of 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_extended_input'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_extended_input_0'
08/20/2020 17:47:53 MainProcess     mask_extended_input_0 _base           _thread_process           DEBUG    threading: (function: 'process_input')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_extended_input': 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_extended_predict'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_extended_predict_0'
08/20/2020 17:47:53 MainProcess     mask_extended_predict_0 _base           _thread_process           DEBUG    threading: (function: '_predict')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_extended_predict': 1
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'mask_extended_output'
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'mask_extended_output_0'
08/20/2020 17:47:53 MainProcess     mask_extended_output_0 _base           _thread_process           DEBUG    threading: (function: 'process_output')
08/20/2020 17:47:53 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'mask_extended_output': 1
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launched mask_1 plugin
08/20/2020 17:47:53 MainProcess     MainThread      pipeline        detected_faces            DEBUG    Running Detection. Phase: '['detect', 'align', 'mask_0', 'mask_1']'
08/20/2020 17:47:56 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:56 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:58 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:58 MainProcess     detect_mtcnn_predict_0 def_function    __call__                  WARNING  11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:48:00 MainProcess     align_cv2-dnn_aligner_input_0 multithreading  run                       DEBUG    Error in thread (align_cv2-dnn_aligner_input_0): OpenCV(4.4.0) /tmp/pip-req-build-6179nsls/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n
08/20/2020 17:48:00 MainProcess     MainThread      multithreading  check_and_raise_error     DEBUG    Thread error caught: [(<class 'cv2.error'>, error(""OpenCV(4.4.0) /tmp/pip-req-build-6179nsls/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n""), <traceback object at 0x7ff020279b00>)]
Traceback (most recent call last):
  File ""/home/solyomimre4/faceswap/faceswap/lib/cli/launcher.py"", line 156, in execute_script
    process.process()
  File ""/home/solyomimre4/faceswap/faceswap/scripts/extract.py"", line 117, in process
    self._run_extraction()
  File ""/home/solyomimre4/faceswap/faceswap/scripts/extract.py"", line 213, in _run_extraction
    for idx, extract_media in enumerate(status_bar):
  File ""/home/solyomimre4/miniconda3/envs/faceswap/lib/python3.8/site-packages/tqdm/std.py"", line 1130, in __iter__
    for obj in iterable:
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/pipeline.py"", line 233, in detected_faces
    if self._check_and_raise_error():
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/pipeline.py"", line 655, in _check_and_raise_error
    if plugin.check_and_raise_error():
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/_base.py"", line 302, in check_and_raise_error
    err = thread.check_and_raise_error()
  File ""/home/solyomimre4/faceswap/faceswap/lib/multithreading.py"", line 84, in check_and_raise_error
    raise error[1].with_traceback(error[2])
  File ""/home/solyomimre4/faceswap/faceswap/lib/multithreading.py"", line 37, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/_base.py"", line 420, in _thread_process
    batch = function(batch)
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/align/cv2_dnn.py"", line 54, in process_input
    faces, batch[""roi""], batch[""offsets""] = self.align_image(batch)
  File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/align/cv2_dnn.py"", line 82, in align_image
    face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
cv2.error: OpenCV(4.4.0) /tmp/pip-req-build-6179nsls/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'


============ System Information ============
encoding:            UTF-8
git_branch:          master
git_commits:         619bd41 Catch further AMD OOM errors. 445aa49 Bugfix - Legacy Models. Set penalized_loss and learn_mask to ""False"" if mask_type is None. ebf84c5 GUI - Configs - Handle ""None"" options correctly. 0a25dff model.config - Make convert batchsize a user configurable option. 45d6995 bugfix - Extract - VGG Clear Mask - Fix for TF2
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         
gpu_devices_active:  
gpu_driver:          No Nvidia driver found
gpu_vram:            
os_machine:          x86_64
os_platform:         Linux-4.15.0-1080-gcp-x86_64-with-glibc2.10
os_release:          4.15.0-1080-gcp
py_command:          /home/solyomimre4/faceswap/faceswap/faceswap.py extract -i /home/solyomimre4/faceswap/faceswap/source/video-1597933718.mp4 -o /home/solyomimre4/faceswap/faceswap/output -D mtcnn -A cv2-dnn -nm none -min 0 -l 0.4 -een 1 -sz 256 -si 0 -L INFO -gui
py_conda_version:    conda 4.8.4
py_implementation:   CPython
py_version:          3.8.5
py_virtual_env:      True
sys_cores:           8
sys_processor:       x86_64
sys_ram:             Total: 7167MB, Available: 5198MB, Used: 1692MB, Free: 4349MB

=============== Pip Packages ===============
absl-py==0.9.0
astunparse==1.6.3
blinker==1.4
brotlipy==0.7.0
cachetools @ file:///tmp/build/80754af9/cachetools_1596822027882/work
certifi==2020.6.20
cffi @ file:///tmp/build/80754af9/cffi_1596809843656/work
chardet==3.0.4
click==7.1.2
cryptography==2.9.2
cycler==0.10.0
docopt==0.6.2
fastcluster==1.1.26
ffmpy==0.2.3
gast==0.3.3
google-auth @ file:///tmp/build/80754af9/google-auth_1596863485713/work
google-auth-oauthlib==0.4.1
google-pasta==0.2.0
grpcio @ file:///tmp/build/80754af9/grpcio_1597424474635/work
h5py @ file:///tmp/build/80754af9/h5py_1593454122442/work
idna @ file:///tmp/build/80754af9/idna_1593446292537/work
imageio @ file:///tmp/build/80754af9/imageio_1594161405741/work
imageio-ffmpeg @ file:///home/conda/feedstock_root/build_artifacts/imageio-ffmpeg_1589202782679/work
importlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1593446406207/work
joblib @ file:///tmp/build/80754af9/joblib_1594236160679/work
Keras-Preprocessing==1.1.0
kiwisolver==1.2.0
Markdown @ file:///tmp/build/80754af9/markdown_1597433240441/work
matplotlib @ file:///tmp/build/80754af9/matplotlib-base_1592846008246/work
mkl-fft==1.1.0
mkl-random==1.1.1
mkl-service==2.3.0
numpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1596233721170/work
nvidia-ml-py3 @ git+https://github.com/deepfakes/nvidia-ml-py3.git@6fc29ac84b32bad877f078cb4a777c1548a00bf6
oauthlib==3.1.0
olefile==0.46
opencv-python==4.4.0.42
opt-einsum==3.1.0
pathlib==1.0.1
Pillow==7.2.0
protobuf==3.12.4
psutil==5.7.0
pyasn1==0.4.8
pyasn1-modules==0.2.7
pycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work
PyJWT==1.7.1
pyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1594392929924/work
pyparsing==2.4.7
PySocks==1.7.1
python-dateutil==2.8.1
requests @ file:///tmp/build/80754af9/requests_1592841827918/work
requests-oauthlib==1.3.0
resize==0.1.0
rsa @ file:///tmp/build/80754af9/rsa_1596998415516/work
scikit-learn @ file:///tmp/build/80754af9/scikit-learn_1592502866053/work
scipy @ file:///tmp/build/80754af9/scipy_1592930511789/work
sip==4.19.13
six==1.15.0
tensorboard==2.2.1
tensorboard-plugin-wit==1.6.0
tensorflow==2.2.0
tensorflow-estimator==2.2.0
termcolor==1.1.0
threadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl
tornado==6.0.4
tqdm @ file:///tmp/build/80754af9/tqdm_1596810128862/work
urllib3 @ file:///tmp/build/80754af9/urllib3_1597086586889/work
Werkzeug==1.0.1
wrapt==1.12.1
zipp==3.1.0

============== Conda Packages ==============
# packages in environment at /home/solyomimre4/miniconda3/envs/faceswap:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_tflow_select             2.3.0                       mkl  
absl-py                   0.9.0                    py38_0  
astunparse                1.6.3                      py_0  
blas                      1.0                         mkl  
blinker                   1.4                      py38_0  
brotlipy                  0.7.0           py38h7b6447c_1000  
bzip2                     1.0.8                h516909a_2    conda-forge
c-ares                    1.15.0            h7b6447c_1001  
ca-certificates           2020.6.24                     0  
cachetools                4.1.1                      py_0  
certifi                   2020.6.20                py38_0  
cffi                      1.14.1           py38he30daa8_0  
chardet                   3.0.4                 py38_1003  
click                     7.1.2                      py_0  
cryptography              2.9.2            py38h1ba5d50_0  
cycler                    0.10.0                   py38_0  
dbus                      1.13.16              hb2f20db_0  
docopt                    0.6.2                    pypi_0    pypi
expat                     2.2.9                he6710b0_2  
fastcluster               1.1.26           py38hcb8c335_1    conda-forge
ffmpeg                    4.3.1                h167e202_0    conda-forge
ffmpy                     0.2.3                    pypi_0    pypi
fontconfig                2.13.0               h9420a91_0  
freetype                  2.10.2               h5ab3b9f_0  
gast                      0.3.3                      py_0  
git                       2.23.0          pl526hacde149_0  
glib                      2.65.0               h3eb4bd4_0  
gmp                       6.2.0                he1b5a44_2    conda-forge
gnutls                    3.6.13               h79a8f9a_0    conda-forge
google-auth               1.20.1                     py_0  
google-auth-oauthlib      0.4.1                      py_2  
google-pasta              0.2.0                      py_0  
grpcio                    1.31.0           py38hf8bcb03_0  
gst-plugins-base          1.14.0               hbbd80ab_1  
gstreamer                 1.14.0               hb31296c_0  
h5py                      2.10.0           py38hd6299e0_1  
hdf5                      1.10.6               hb1b8bf9_0  
icu                       58.2                 he6710b0_3  
idna                      2.10                       py_0  
imageio                   2.9.0                      py_0  
imageio-ffmpeg            0.4.2                      py_0    conda-forge
importlib-metadata        1.7.0                    py38_0  
intel-openmp              2020.1                      217  
joblib                    0.16.0                     py_0  
jpeg                      9b                   h024ee3a_2  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.2.0            py38hfd86e86_0  
krb5                      1.18.2               h173b8e3_0  
lame                      3.100             h14c3975_1001    conda-forge
lcms2                     2.11                 h396b838_0  
ld_impl_linux-64          2.33.1               h53a641e_7  
libcurl                   7.71.1               h20c2e04_1  
libedit                   3.1.20191231         h14c3975_1  
libffi                    3.3                  he6710b0_2  
libgcc-ng                 9.1.0                hdf63c60_0  
libgfortran-ng            7.3.0                hdf63c60_0  
libiconv                  1.16                 h516909a_0    conda-forge
libpng                    1.6.37               hbc83047_0  
libprotobuf               3.12.4               hd408876_0  
libssh2                   1.9.0                h1ba5d50_1  
libstdcxx-ng              9.1.0                hdf63c60_0  
libtiff                   4.1.0                h2733197_1  
libuuid                   1.0.3                h1bed415_2  
libxcb                    1.14                 h7b6447c_0  
libxml2                   2.9.10               he19cac6_1  
lz4-c                     1.9.2                he6710b0_1  
markdown                  3.2.2                    py38_0  
matplotlib                3.2.2                         0  
matplotlib-base           3.2.2            py38hef1b27d_0  
mkl                       2020.1                      217  
mkl-service               2.3.0            py38he904b0f_0  
mkl_fft                   1.1.0            py38h23d657b_0  
mkl_random                1.1.1            py38h0573a6f_0  
ncurses                   6.2                  he6710b0_1  
nettle                    3.4.1             h1bed415_1002    conda-forge
numpy                     1.19.1           py38hbc911f0_0  
numpy-base                1.19.1           py38hfa32c7d_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
oauthlib                  3.1.0                      py_0  
olefile                   0.46                       py_0  
opencv-python             4.4.0.42                 pypi_0    pypi
openh264                  2.1.1                h8b12597_0    conda-forge
openssl                   1.1.1g               h7b6447c_0  
opt_einsum                3.1.0                      py_0  
pathlib                   1.0.1                      py_1  
pcre                      8.44                 he6710b0_0  
perl                      5.26.2               h14c3975_0  
pillow                    7.2.0            py38hb39fc2d_0  
pip                       20.2.2                   py38_0  
protobuf                  3.12.4           py38he6710b0_0  
psutil                    5.7.0            py38h7b6447c_0  
pyasn1                    0.4.8                      py_0  
pyasn1-modules            0.2.7                      py_0  
pycparser                 2.20                       py_2  
pyjwt                     1.7.1                    py38_0  
pyopenssl                 19.1.0                     py_1  
pyparsing                 2.4.7                      py_0  
pyqt                      5.9.2            py38h05f1152_4  
pysocks                   1.7.1                    py38_0  
python                    3.8.5                hcff3b4d_0  
python-dateutil           2.8.1                      py_0  
python_abi                3.8                      1_cp38    conda-forge
qt                        5.9.7                h5867ecd_1  
readline                  8.0                  h7b6447c_0  
requests                  2.24.0                     py_0  
requests-oauthlib         1.3.0                      py_0  
resize                    0.1.0                    pypi_0    pypi
rsa                       4.6                        py_0  
scikit-learn              0.23.1           py38h423224d_0  
scipy                     1.5.0            py38h0b6359f_0  
setuptools                49.6.0                   py38_0  
sip                       4.19.13          py38he6710b0_0  
six                       1.15.0                     py_0  
sqlite                    3.32.3               h62c20be_0  
tensorboard               2.2.1              pyh532a8cf_0  
tensorboard-plugin-wit    1.6.0                      py_0  
tensorflow                2.2.0           mkl_py38h6d3daf0_0  
tensorflow-base           2.2.0           mkl_py38h5059a2d_0  
tensorflow-estimator      2.2.0              pyh208ff02_0  
termcolor                 1.1.0                    py38_1  
threadpoolctl             2.1.0              pyh5ca1d4c_0  
tk                        8.6.10               hbc83047_0  
tornado                   6.0.4            py38h7b6447c_1  
tqdm                      4.48.2                     py_0  
urllib3                   1.25.10                    py_0  
werkzeug                  1.0.1                      py_0  
wheel                     0.34.2                   py38_0  
wrapt                     1.12.1           py38h7b6447c_1  
x264                      1!152.20180806       h14c3975_0    conda-forge
xz                        5.2.5                h7b6447c_0  
zipp                      3.1.0                      py_0  
zlib                      1.2.11               h7b6447c_3  
zstd                      1.4.5                h9ceee32_0  

================= Configs ==================
--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    always
timeout:                  120
auto_load_model_stats:    True

--------- .faceswap ---------
backend:                  cpu

--------- convert.ini ---------

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto
skip_mux:                 False

[color.match_hist]
threshold:                99.0

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.color_transfer]
clip:                     True
preserve_paper:           True

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               12

[detect.s3fd]
confidence:               70
batch-size:               4

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.cv2_dnn]
confidence:               50

[mask.unet_dfl]
batch-size:               8

[mask.vgg_obstructed]
batch-size:               2

[mask.vgg_clear]
batch-size:               6

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                extended
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False
penalized_mask_loss:      True
loss_function:            mae
icnr_init:                False
conv_aware_init:          False
optimizer:                adam
learning_rate:            5e-05
reflect_padding:          False
allow_growth:             False
mixed_precision:          False
convert_batchsize:        16

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.villain]
lowmem:                   False

[model.dfl_h128]
lowmem:                   False

[model.dlight]
features:                 best
details:                  good
output_size:              256",log file start starting thread function start start starting thread start starting thread function start pipeline align pipeline pipeline initialize initialize mask object object initialize mask getting name added name got getting name added name got mask thread name function bound method object object object target added thread thread name function bound method object object object target added thread thread name function bound method object object object target added thread mask object object object mask model initialize initialize mask start starting thread start starting thread function start start starting thread start starting thread function start start starting thread start starting thread function start pipeline pipeline pipeline initialize initialize mask object object initialize extended mask getting name added name got getting name added name got mask thread name function bound method object object object target added thread thread name function bound method object object object target added thread thread name function bound method object object object target added thread mask object object object extended mask model initialize initialize extended mask start starting thread start starting thread function start start starting thread start starting thread function start start starting thread start starting thread function start pipeline pipeline running detection phase warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer run error thread error assertion function thread error caught class error error assertion function object recent call last file line file line process file line enumerate file line iterable file line file line file line err file line raise error error file line run file line batch function batch file line batch roi batch batch file line face face error assertion function system information master catch aa legacy set false none handle none correctly make convert user option extract clear mask fix global version found check global version found check driver found extract none true total available used free pip file file file file file file file file file file markdown file file file file file file file file file file file file environment name version build channel main blas blinker click cryptography cycler gast git glib lame markdown nettle pillow pip python resize sip six tornado wheel global false tab extract font default always true method amount radius threshold format false loop false format false optimize false true container preset medium tune none profile auto level auto false threshold contrast brightness clip true true type distance radius type threshold erosion global false confidence confidence global coverage extended false true mae false false false false false false true true architecture false false false false best good,issue,negative,negative,negative,negative,negative,negative
677814137,```Crash report written to '/home/solyomimre4/faceswap/faceswap/crash_report.2020.08.20.174800998286.log'. You MUST provide this file if seeking assistance```,crash report written log must provide file seeking assistance,issue,negative,neutral,neutral,neutral,neutral,neutral
677813497,"The conda command worked

The gui terminal output :


`
Loading...
Setting Faceswap backend to CPU
There was an error reading from the Nvidia Machine Learning Library. Either you do not have an Nvidia GPU (in which case this warning can be ignored) or the most likely cause is incorrectly installed drivers. If this is the case, Please remove and reinstall your Nvidia drivers before reporting.Original Error: NVML Shared Library Not Found
No GPU detected. Switching to CPU mode
08/20/2020 17:47:51 INFO     Log level set to: INFO
08/20/2020 17:47:51 WARNING  There was an error reading from the Nvidia Machine Learning Library. Either you do not have an Nvidia GPU (in which case this warning can be ignored) or the most likely cause is incorrectly installed drivers. If this is the case, Please remove and reinstall your Nvidia drivers before reporting.Original Error: NVML Shared Library Not Found
08/20/2020 17:47:51 WARNING  No GPU detected. Switching to CPU mode
08/20/2020 17:47:53 INFO     Output Directory: /home/solyomimre4/faceswap/faceswap/output

08/20/2020 17:47:53 WARNING  There was an error reading from the Nvidia Machine Learning Library. Either you do not have an Nvidia GPU (in which case this warning can be ignored) or the most likely cause is incorrectly installed drivers. If this is the case, Please remove and reinstall your Nvidia drivers before reporting.Original Error: NVML Shared Library Not Found
08/20/2020 17:47:53 WARNING  No GPU detected. Switching to CPU mode
08/20/2020 17:47:53 INFO     Loading Detect from Mtcnn plugin...
08/20/2020 17:47:53 INFO     Loading Align from Cv2_Dnn plugin...
08/20/2020 17:47:53 INFO     Loading Mask from Components plugin...
08/20/2020 17:47:53 INFO     Loading Mask from Extended plugin...
08/20/2020 17:47:53 INFO     Starting, this may take a while...
08/20/2020 17:47:53 INFO     Initializing MTCNN (Detect)...
08/20/2020 17:47:53 INFO     Initialized MTCNN (Detect) with batchsize of 8
08/20/2020 17:47:53 INFO     Initializing cv2-DNN Aligner (Align)...
08/20/2020 17:47:53 INFO     Initialized cv2-DNN Aligner (Align) with batchsize of 1
08/20/2020 17:47:53 INFO     Initializing Components (Mask)...
08/20/2020 17:47:53 INFO     Initialized Components (Mask) with batchsize of 1
08/20/2020 17:47:53 INFO     Initializing Extended (Mask)...
08/20/2020 17:47:53 INFO     Initialized Extended (Mask) with batchsize of 1

08/20/2020 17:47:56 WARNING  6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 WARNING  7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 WARNING  8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:57 WARNING  9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:58 WARNING  10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
08/20/2020 17:47:58 WARNING  11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0f61fce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.


OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
ls: cannot access '/usr/lib/mesa-diverted/x86_64-linux-gnu': No such file or directory
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
ls: cannot access '/usr/lib/x86_64-linux-gnu/gallium-pipe': No such file or directory
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
OMP: Warning #190: Forking a process while a parallel region is active is potentially unsafe.
ls: cannot access '/usr/lib/mesa-diverted/x86_64-linux-gnu': No such file or directory
ls: cannot access '/usr/lib/x86_64-linux-gnu/gallium-pipe': No such file or directory
08/20/2020 17:48:07 ERROR    Got Exception on main handler:
Traceback (most recent call last):
File ""/home/solyomimre4/faceswap/faceswap/lib/cli/launcher.py"", line 156, in execute_script
process.process()
File ""/home/solyomimre4/faceswap/faceswap/scripts/extract.py"", line 117, in process
self._run_extraction()
File ""/home/solyomimre4/faceswap/faceswap/scripts/extract.py"", line 213, in _run_extraction
for idx, extract_media in enumerate(status_bar):
File ""/home/solyomimre4/miniconda3/envs/faceswap/lib/python3.8/site-packages/tqdm/std.py"", line 1130, in __iter__
for obj in iterable:
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/pipeline.py"", line 233, in detected_faces
if self._check_and_raise_error():
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/pipeline.py"", line 655, in _check_and_raise_error
if plugin.check_and_raise_error():
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/_base.py"", line 302, in check_and_raise_error
err = thread.check_and_raise_error()
File ""/home/solyomimre4/faceswap/faceswap/lib/multithreading.py"", line 84, in check_and_raise_error
raise error[1].with_traceback(error[2])
File ""/home/solyomimre4/faceswap/faceswap/lib/multithreading.py"", line 37, in run
self._target(*self._args, **self._kwargs)
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/_base.py"", line 420, in _thread_process
batch = function(batch)
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/align/cv2_dnn.py"", line 54, in process_input
faces, batch[""roi""], batch[""offsets""] = self.align_image(batch)
File ""/home/solyomimre4/faceswap/faceswap/plugins/extract/align/cv2_dnn.py"", line 82, in align_image
face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
cv2.error: OpenCV(4.4.0) /tmp/pip-req-build-6179nsls/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'

08/20/2020 17:48:07 CRITICAL An unexpected crash has occurred. Crash report written to '/home/solyomimre4/faceswap/faceswap/crash_report.2020.08.20.174800998286.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting
Process exited.

`

What is the problem?",command worked terminal output loading setting error reading machine learning library either case warning likely cause incorrectly case please remove reinstall error library found switching mode log level set warning error reading machine learning library either case warning likely cause incorrectly case please remove reinstall error library found warning switching mode output directory warning error reading machine learning library either case warning likely cause incorrectly case please remove reinstall error library found warning switching mode loading detect loading align loading mask loading mask extended starting may take detect detect aligner align aligner align mask mask extended mask extended mask warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning last function triggered tracing expensive excessive number likely due passing python instead also option argument avoid unnecessary please refer warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe access file directory warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe access file directory warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe warning process parallel region active potentially unsafe access file directory access file directory error got exception main handler recent call last file line file line process file line enumerate file line iterable file line file line file line err file line raise error error file line run file line batch function batch file line batch roi batch batch file line face face error assertion function critical unexpected crash crash report written log must provide file seeking assistance please verify running latest version process problem,issue,negative,negative,negative,negative,negative,negative
677689419,"You need to activate your faceswap environment. Assuming that it's a standard install (can't speak for the nuances of cloud VM services) then the command will be `conda activate faceswap`

As an aside, doing this on CPU is a bad idea, and will take weeks or months to even approach anything useful.",need activate environment assuming standard install ca speak cloud command activate aside bad idea take even approach anything useful,issue,negative,negative,negative,negative,negative,negative
676955416,"@poly000, the solution is to create an option to change the colour of the main menu bar, am i right to assume that?
 and can you elaborate on what you mean by "" mouse hover on a option to callout "".",poly solution create option change colour main menu bar right assume elaborate mean mouse hover option,issue,positive,positive,positive,positive,positive,positive
675634886,"This is basically an out of memory issue. You might be able to train with a super low batchsize, but most likely that card will not be able to handle Faceswap.",basically memory issue might able train super low likely card able handle,issue,negative,positive,positive,positive,positive,positive
675626681,"Use python >=3.7

I will update our requirements to reflect this.",use python update reflect,issue,negative,neutral,neutral,neutral,neutral,neutral
675295953,"Sure, it's possible, but it's unlikely to be something we implement, as argparse is the main entry point for the faceswap software and passing the namespace through the various processes is a lot easier in terms of code maintenance.

That said, you can just create your own ""dummy"" namespace.

https://stackoverflow.com/questions/28345780/how-do-i-create-a-python-namespace-argparse-parse-args-value

",sure possible unlikely something implement main entry point passing various lot easier code maintenance said create dummy,issue,positive,positive,neutral,neutral,positive,positive
674742484,"@GoldExplosion Sure. Go for it....

You'll need to add a config option to https://github.com/deepfakes/faceswap/blob/master/lib/gui/_config.py and reference it in https://github.com/deepfakes/faceswap/blob/725d8649752057cfcf7ba485772007c1805406a8/lib/gui/custom_widgets.py#L532

You can access the user config options from `get_config().user_config`
https://github.com/deepfakes/faceswap/blob/725d8649752057cfcf7ba485772007c1805406a8/lib/gui/utils.py#L50
https://github.com/deepfakes/faceswap/blob/725d8649752057cfcf7ba485772007c1805406a8/lib/gui/utils.py#L863",sure go need add option reference access user,issue,negative,positive,positive,positive,positive,positive
674686770,"i would like to take this issue, seems like a good first issue. 

",would like take issue like good first issue,issue,positive,positive,positive,positive,positive,positive
673439528,"@TXien   hi  are you fixed this?  i want know how, 
in my input dir. there is an xx_alignments.fsa file  
dont know how to use it ",hi fixed want know input file dont know use,issue,negative,positive,neutral,neutral,positive,positive
672766846,"Sorry for sitting on this PR for so long. I completely forgot about it (and thought I had got back to you), I am cleaning up PRs as things have moved on.

We discussed this amongst our Devs, but decided that we wouldn't include this in our repo, as we want to avoid plugging into 3rd party libraries where possible.

Thanks for taking the time though.",sorry sitting long completely forgot thought got back cleaning amongst decided would include want avoid plugging party possible thanks taking time though,issue,positive,negative,neutral,neutral,negative,negative
671278821,"Closing due to lack of activity, but if this is something that may be useful, then we can look to revisit in the future.",due lack activity something may useful look revisit future,issue,negative,positive,neutral,neutral,positive,positive
671215219,"As long as it still works, it won't be going anywhere.

Glad this is resolved.",long still work wo going anywhere glad resolved,issue,positive,positive,positive,positive,positive,positive
671165395,Yes. Changing the docker ignore file works. I really hope the docker function can be formally supported. That simplifies everything.,yes docker ignore file work really hope docker function formally everything,issue,positive,positive,positive,positive,positive,positive
671030596,I have just merged #1041 which may or may not resolve this issue,may may resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
671013248,"I am still having this issue. My build command is 
`docker build -t faceswap:latest -f Dockerfile.gpu .`

Even specifying the building folder does not work. Does anyone has the similar issue?",still issue build command docker build latest even building folder work anyone similar issue,issue,negative,positive,positive,positive,positive,positive
670598983,"The github is for bugs and issues. You are best off getting tips about this kind of thing from our Discord Server:

https://discord.gg/FC54sYg
",best getting kind thing discord server,issue,positive,positive,positive,positive,positive,positive
667862372,"We have seen this error reported a few times, but have never been able to reproduce it, and suspect it is a GPU memory issue.

Try a different Detector, and see if the problem persists.",seen error time never able reproduce suspect memory issue try different detector see problem,issue,negative,negative,negative,negative,negative,negative
667861205,"This looks like a local install issue. I recommend setting up a new virtual environment and trying again.

If this doesn't work, please look for usage support on  our [Discord server](https://discord.gg/FC54sYg) or [Forum](https://faceswap.dev/forum)",like local install issue recommend setting new virtual environment trying work please look usage support discord server forum,issue,positive,positive,neutral,neutral,positive,positive
667859589,"Thanks for this, I assume this resolves #1037 ?

None of the current Devs use Docker, so I will merge this.",thanks assume none current use docker merge,issue,negative,positive,neutral,neutral,positive,positive
667858621,Please direct usage questions to the [FaceSwap Discord server](https://discord.gg/FC54sYg) or the [FaceSwap Forum](https://faceswap.dev/forum),please direct usage discord server forum,issue,negative,positive,neutral,neutral,positive,positive
667856949,"Use the ""FFMEG"" plugin in the writer settings.

Please direct further general usage questions to the [FaceSwap Discord server](https://discord.gg/FC54sYg) or the [FaceSwap Forum](https://faceswap.dev/forum)",use writer please direct general usage discord server forum,issue,negative,positive,neutral,neutral,positive,positive
665293404,"Is this option on the GUI? If so, it's already selected.

![Untitled](https://user-images.githubusercontent.com/1883285/88724238-87657580-d100-11ea-9fa8-fa88b9195277.png)
",option already selected untitled,issue,negative,neutral,neutral,neutral,neutral,neutral
665008134,"Enable the ""allow growth"" option.",enable allow growth option,issue,positive,neutral,neutral,neutral,neutral,neutral
663833799,"Hello @torzdf! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

























* In the file [`tools/manual/frameviewer/frame.py`](https://github.com/deepfakes/faceswap/blob/4fdb2fdc694e115ba9ee511824dfa18b7cd76d38/tools/manual/frameviewer/frame.py):

> [Line 402:17](https://github.com/deepfakes/faceswap/blob/4fdb2fdc694e115ba9ee511824dfa18b7cd76d38/tools/manual/frameviewer/frame.py#L402): [E731](https://duckduckgo.com/?q=pep8%20E731) do not assign a lambda expression, use a def
> [Line 407:17](https://github.com/deepfakes/faceswap/blob/4fdb2fdc694e115ba9ee511824dfa18b7cd76d38/tools/manual/frameviewer/frame.py#L407): [E731](https://duckduckgo.com/?q=pep8%20E731) do not assign a lambda expression, use a def





##### Comment last updated at 2020-07-25 09:29:50 UTC",hello thanks checked touched pep found file line assign lambda expression use line assign lambda expression use comment last,issue,negative,positive,neutral,neutral,positive,positive
661937236,"Ultimately none of the current devs use Docker, so it's kind of unsupported and is really still hanging around for legacy reasons and because (to date) it hasn't broken yet....

We very much welcome PRs to fix any issues with the docker version, otherwise our only real choice is to drop support altogether,",ultimately none current use docker kind unsupported really still hanging around legacy date broken yet much welcome fix docker version otherwise real choice drop support altogether,issue,negative,positive,positive,positive,positive,positive
661932548,"
This approach worked for me. Notice the '.' which seems to give docker the current workdir so that it knows where to catch the files given by COPY command. Did not test (yet) if COPY without build-directory also works.

> ```shell
> #!/bin/bash
> cp ../_requirements_base.txt .
> sudo docker build -t faceswap-gpu . -f ../Dockerfile.gpu
> ```",approach worked notice give docker current catch given copy command test yet copy without also work shell docker build,issue,negative,neutral,neutral,neutral,neutral,neutral
661931061,"Something still goes wrong for me always getting this Error trying to build:
> COPY failed: stat /var/lib/docker/tmp/docker-builder790036227/_requirements_base.txt: no such file or directory",something still go wrong always getting error trying build copy file directory,issue,negative,negative,negative,negative,negative,negative
660494028,"> That's fine, but I can see from your environment you have the CPU version installed, so follow the instructions and it should resolve the issue

Thank you. I'll try.",fine see environment version follow resolve issue thank try,issue,positive,positive,positive,positive,positive,positive
660490004,"That's fine, but I can see from your environment you have the CPU version installed, so follow the instructions and it should resolve the issue",fine see environment version follow resolve issue,issue,positive,positive,positive,positive,positive,positive
660489759,"Yes. although I believe that the Conda version is compiled with AVX (should be pulled in by the installer)

You'll need to refer to the Tensorflow docs for compiling your own TF.",yes although believe version installer need refer,issue,negative,neutral,neutral,neutral,neutral,neutral
660478206,"> You have the CPU version installed.
> 
> Easiest fix is to remove your faceswap folder, re-run the installer and make sure you select the ""Nvidia"" option

 But I chose GPU installation.",version easiest fix remove folder installer make sure select option chose installation,issue,positive,positive,positive,positive,positive,positive
660467470,"You have the CPU version installed.

Easiest fix is to remove your faceswap folder, re-run the installer and make sure you select the ""Nvidia"" option",version easiest fix remove folder installer make sure select option,issue,positive,positive,positive,positive,positive,positive
657098361,"No problem, it happens :)

I'll close this and let you open a new one if you need.
",problem close let open new one need,issue,negative,positive,neutral,neutral,positive,positive
657097967,"Oh my god I'm really sorry about that I've made Pull request with the wrong
file

On Sat, Jul 11, 2020, 15:51 torzdf <notifications@github.com> wrote:

> Is this a mistake? I'm not sure what this 1 line markdown file is meant to
> do?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/1034#issuecomment-657035376>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMNLINMQ7ZWP3NWLRJS3LGDR3A4J5ANCNFSM4OXFW6YA>
> .
>
",oh god really sorry made pull request wrong file sat wrote mistake sure line markdown file meant thread reply directly view,issue,negative,negative,neutral,neutral,negative,negative
657035376,Is this a mistake? I'm not sure what this 1 line markdown file is meant to do?,mistake sure line markdown file meant,issue,negative,positive,positive,positive,positive,positive
656054287,It works to comment relevant code in scripts/train.py,work comment relevant code,issue,negative,positive,positive,positive,positive,positive
655643864,S3FD is a pre-trained model. Initializing is loading it into VRAM and setting up. Bigger models take more time.,model loading setting bigger take time,issue,negative,neutral,neutral,neutral,neutral,neutral
648277474,"Please only use issues for actual code bugs.  For questions on using the application please post on https://forum.faceswap.dev/ .  However, we do have blur options, you can test the various settings to find a good match for your video in the preview tool.",please use actual code application please post however blur test various find good match video preview tool,issue,positive,positive,positive,positive,positive,positive
633320120,"It is already grammatically correct. Your PR would make it nonsensical.

And you raised an identical PR about a month ago which was closed for the same reason.
https://github.com/deepfakes/faceswap/pull/1018
",already grammatically correct would make nonsensical raised identical month ago closed reason,issue,negative,negative,neutral,neutral,negative,negative
630654605,"@JustinGuese Thanks a lot, that helped! I changed the image size from 64px to 128px in the extraction process. Now the training process works. 😀",thanks lot image size extraction process training process work,issue,negative,positive,positive,positive,positive,positive
628892255,"I removed my system Cuda and cuDNN.

And then I added the env var TF_FORCE_GPU_ALLOW_GROWTH on my conda activate script as `EXPORT TF_FORCE_GPU_ALLOW_GROWTH=true` and now it's all working.

thanks for your help @torzdf.",removed system added activate script export working thanks help,issue,positive,positive,positive,positive,positive,positive
628504729,"In the first instance, remove your system installed Cuda and cuDNN, they can conflict with the version that Conda installs.

Reboot, retry.

If it is still an issue, try enabling ""Allow Growth"". Unfortunately, currently for sort, we do not have this as a selectable option, so you will need to set the `TF_FORCE_GPU_ALLOW_GROWTH` Environment Variable prior to launch:

From here: https://www.tensorflow.org/guide/gpu 

> Another way to enable this option is to set the environmental variable TF_FORCE_GPU_ALLOW_GROWTH to true. This configuration is platform specific.
",first instance remove system conflict version retry still issue try allow growth unfortunately currently sort selectable option need set environment variable prior launch another way enable option set environmental variable true configuration platform specific,issue,negative,positive,positive,positive,positive,positive
627922913,"This is likely to be an issue/conflict with your system, as in 99% of cases the installer works fine.

That said, Intel HD Graphics won't be good enough to run Faceswap, so this probably isn't worth diagnosing.",likely system installer work fine said graphic wo good enough run probably worth,issue,positive,positive,positive,positive,positive,positive
627922156,"This is for bugs, not for support.

See our [Discord](https://discord.gg/FC54sYg) or [Forum](https://faceswap.dev/forum) for support:",support see discord forum support,issue,negative,neutral,neutral,neutral,neutral,neutral
625191055,"File ""D:\develop\Anaconda3\envs\faceswap\lib\site-packages\keras\engine\base_layer.py"", line 285, in assert_input_compatibility
str(inputs) + '. All inputs to the layer '
ValueError: Layer LAYER_44 was called with an input that isn't a symbolic tensor. Received type: <class 'theano.tensor.var.TensorConstant'>. Full input: [Elemwise{mul,no_inplace}.0, TensorConstant{2.0}]. All inputs to the layer should be tensors.
[crash_report.2020.05.07.190935881586.log](https://github.com/deepfakes/faceswap/files/4592582/crash_report.2020.05.07.190935881586.log)
",file line layer layer input symbolic tensor received type class full input layer log,issue,negative,positive,positive,positive,positive,positive
618310997,"The wiki information is outdated (and has now been disabled).

We do not provide pre-trained models or extracted faces. It is up to the user to generate these themselves.",information outdated disabled provide extracted user generate,issue,negative,negative,negative,negative,negative,negative
617520671,Change the detector from S3Fd to cv2-dnn and it passes. S3Fd for some reason is not working.,change detector reason working,issue,negative,neutral,neutral,neutral,neutral,neutral
609400384,"Ultimately this is a local/plaidML issue. You may be able to solve it here:
https://github.com/plaidml/plaidml/issues/370",ultimately issue may able solve,issue,negative,positive,positive,positive,positive,positive
609398647,"Thanks for this....

I am actually trying to reduce the number of jobs listed in the alignments tool, so I think I would prefer an approach which adds an interpolation parameter (from 0 (no spatial) to a number you feel is sensible)",thanks actually trying reduce number listed tool think would prefer approach interpolation parameter spatial number feel sensible,issue,positive,positive,neutral,neutral,positive,positive
609398300,"This is a local issue to do with your plaidML install. 

Unfortunately I no longer have an AMD graphics card to test, but hopefully you'll find a solution here:

https://github.com/plaidml/plaidml/issues/370",local issue install unfortunately longer graphic card test hopefully find solution,issue,negative,negative,negative,negative,negative,negative
609397318,"This is best discussed in our Discord (https://discord.gg/FC54sYg) or our Forum (https://forum.faceswap.dev/index.php).

Ultimately it comes down to having better data and more training.

Also see this section in the training guide: https://forum.faceswap.dev/viewtopic.php?f=6&t=146#monitor",best discord forum ultimately come better data training also see section training guide,issue,positive,positive,positive,positive,positive,positive
608921254,any information on this I've receive this same message when I try to run python3.7 faceswap.py gui after I installed plaidml-setup,information receive message try run python,issue,negative,neutral,neutral,neutral,neutral,neutral
607947107,"tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory

Cuda has not been installed correctly.  Try reinstalling.  If you continue to have problems, please come post in the Forum or Discord ( https://forum.faceswap.dev/ ) where we can help you diagnose.",could library open object file file directory correctly try continue please come post forum discord help diagnose,issue,negative,neutral,neutral,neutral,neutral,neutral
606494625,"Yep. Not enough training.

You should see our guides here: https://forum.faceswap.dev/app.php/tag/Guide",yep enough training see,issue,negative,neutral,neutral,neutral,neutral,neutral
606490986,"sorry, but Thank you for your suggestion. I will try more training epoch ,and more Input pic.
@wiso ",sorry thank suggestion try training epoch input pic,issue,negative,negative,negative,negative,negative,negative
606471498,"Did you run ""convert"" successfully ? When I run convert ,I get no face picture. Can you help me to sovle it ?
My issue detail  is here: #1002 ",run convert successfully run convert get face picture help issue detail,issue,positive,positive,positive,positive,positive,positive
606470928,"Hello @Tian14267 , I am not an ""author""

By the way it seems that you just need to train more or to provide more input images.",hello author way need train provide input,issue,negative,neutral,neutral,neutral,neutral,neutral
606148588,"The first order model does not fit in the scope of Faceswap, which focuses on replacing one face with another.  First Order, on the other hand, re-animates or ""puppeteers"" a face.  This is unlikely to ever come to Faceswap, though we do accept PRs.

Further, a simple copy of the First Order Model into Faceswap is impossible, since the license that code was released under is incompatible with the GPL license we use.  Someone would have to reimplement it in a clean way for us to be able to accept it.

If that really interests you and you do it, we would be happy to review your Pull Request.",first order model fit scope one face another first order hand face unlikely ever come though accept simple copy first order model impossible since license code incompatible license use someone would clean way u able accept really would happy review pull request,issue,positive,positive,positive,positive,positive,positive
605797245,"The error Log of Faceswap Folder in Linux system is :
`03/30/2020 13:51:17 MainProcess     MainThread      logger          log_setup                 INFO     Log level set to: INFO`

The error Log of Faceswap Folder in Windows system is:
`03/30/2020 13:47:13 MainProcess     MainThread      logger          log_setup                 INFO     Log level set to: INFO
03/30/2020 13:47:29 MainProcess     MainThread      train           _get_images               INFO     Model A Directory: E:\fffan\DeepFake\FacesWap\faceswap-master\input\input_A
03/30/2020 13:47:29 MainProcess     MainThread      train           _get_images               INFO     Model B Directory: E:\fffan\DeepFake\FacesWap\faceswap-master\input\input_B
03/30/2020 13:47:29 MainProcess     MainThread      train           process                   INFO     Training data directory: E:\fffan\DeepFake\FacesWap\faceswap-master\models
03/30/2020 13:47:29 MainProcess     MainThread      train           _monitor                  INFO     ===================================================
03/30/2020 13:47:29 MainProcess     MainThread      train           _monitor                  INFO       Starting
03/30/2020 13:47:29 MainProcess     MainThread      train           _monitor                  INFO       Press 'ENTER' to save and quit
03/30/2020 13:47:29 MainProcess     MainThread      train           _monitor                  INFO       Press 'S' to save model weights immediately
03/30/2020 13:47:29 MainProcess     MainThread      train           _monitor                  INFO     ===================================================
03/30/2020 13:47:30 MainProcess     _training_0     train           _training                 INFO     Loading data, this may take a while...
03/30/2020 13:47:30 MainProcess     _training_0     plugin_loader   _import                   INFO     Loading Model from Original plugin...
03/30/2020 13:47:30 MainProcess     _training_0     _base           load                      INFO     No existing state file found. Generating.
03/30/2020 13:47:30 MainProcess     _training_0     deprecation_wrapper __getattr__               DEBUG    From D:\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n
03/30/2020 13:47:30 MainProcess     _training_0     deprecation_wrapper __getattr__               DEBUG    From D:\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n
03/30/2020 13:47:30 MainProcess     _training_0     deprecation_wrapper __getattr__               DEBUG    From D:\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n
03/30/2020 13:47:31 MainProcess     MainThread      train           _end_thread               CRITICAL Error caught! Exiting...
03/30/2020 13:47:31 MainProcess     MainThread      multithreading  join                      ERROR    Caught exception in thread: '_training_0'`
Do you konw why and How to run it ?
@torzdf",error log folder system logger log level set error log folder system logger log level set train model directory train model directory train process training data directory train train starting train press save quit train press save model immediately train train loading data may take loading model original load state file found generating name please use name please use name please use train critical error caught join error caught exception thread run,issue,positive,positive,positive,positive,positive,positive
605685863,"Filter is poor and not recommended. It will be improved and fixed.

Much better to extract all faces, then sort after, More info here:
https://forum.faceswap.dev/viewtopic.php?f=5&t=27#sort

As to your second point, your output would suggest that they are not the same, but I haven't checked:

faceswap.py extract -L INFO **-D=s3fd -A=fan**

```
03/28/2020 10:48:55 INFO     Loading Detect from Cv2_Dnn plugin...
03/28/2020 10:48:55 INFO     Loading Align from Cv2_Dnn plugin..
```


",filter poor fixed much better extract sort second point output would suggest checked extract loading detect loading align,issue,negative,positive,neutral,neutral,positive,positive
605685368,"Well, I don't want to sound irritating, but `=` and ` ` are the same for command line params.
BTW, is it correct?
```
python3 faceswap.py extract -L INFO -D mtcnn -A fan -i /srv/face/in -o /srv/face/out -f /srv/filter/test.jpg /srv/filter/test1.jpg 
```
 the result is the same, it's stuck.
I don't see any reason it should be closed.
I think filters don't work inside ""faceswap` Docker image",well want sound irritating command line correct python extract fan result stuck see reason closed think work inside docker image,issue,negative,negative,neutral,neutral,negative,negative
605671304,"Filter is unlikely to be looked at as the way it works will change in the future.

You are entering commands incorrectly. Don't put an equals sign between the flag and the option.",filter unlikely way work change future entering incorrectly put sign flag option,issue,negative,negative,negative,negative,negative,negative
605670776,"Closing as OP didn't respond and follow up is off-topic

Please open a new issue if problems persist.",respond follow please open new issue persist,issue,negative,positive,neutral,neutral,positive,positive
605663470,"> 
> 
> Seeing similar problem running
> Running a command inside the docker container:
> 
> ```
> faceswap.py extract -L INFO -D=s3fd -A=fan -nm=clahe -i=/srv/trump -o=/srv/trump_out -f /srv/trump_example/*
> ```
> 
> Output:
> 
> ```
> Setting Faceswap backend to NVIDIA
> 03/28/2020 10:48:53 INFO     Log level set to: INFO
> 03/28/2020 10:48:54 INFO     Output Directory: /srv/trump_out
> 03/28/2020 10:48:55 INFO     Extracting and aligning face for Face Filter...
> 03/28/2020 10:48:55 INFO     Filter: ['/srv/trump_example/11_0.jpeg', '/srv/trump_example/1_0.jpeg', '/srv/trump_example/21_0.jpg'']
> 03/28/2020 10:48:55 INFO     Loading Detect from Cv2_Dnn plugin...
> 03/28/2020 10:48:55 INFO     Loading Align from Cv2_Dnn plugin..
> ```
> 
> Then it got stuck.
> Tried on two different platfoms: Laptop Ubuntu 18.04 Geforce GTX 965m and GCP instance with Nvidia T4:
> 
> [logs.txt](https://github.com/deepfakes/faceswap/files/4396998/logs.txt)

Syntactically incorrect. Don't use an equals sign, use a space",seeing similar problem running running command inside docker container extract output setting log level set output directory face face filter filter loading detect loading align got stuck tried two different instance syntactically incorrect use sign use space,issue,negative,neutral,neutral,neutral,neutral,neutral
605650457,"After debugging:
 I run script with `-f` filter provided.
From my debugging I ended up seeing the problem in `def queue_images()` method of `faceswap/lib/face_filter.py`. It tries to execute `in_queue.put(feed_dict)` and waits for free slot.
If we add timeout to put() it crashes with:
```
INFO     Sending EOF to filter queue
ERROR    Got Exception on main handler:
Traceback (most recent call last):
  File ""/srv/lib/cli.py"", line 127, in execute_script
    process = script(arguments)
  File ""/srv/scripts/extract.py"", line 51, in __init__
    self._post_process = PostProcess(arguments)
  File ""/srv/scripts/fsmedia.py"", line 349, in __init__
    self._actions = self._set_actions()
  File ""/srv/scripts/fsmedia.py"", line 368, in _set_actions
    task = globals()[action](*args, **kwargs)
  File ""/srv/scripts/fsmedia.py"", line 533, in __init__
    self._filter = self._load_face_filter(**kwargs)
  File ""/srv/scripts/fsmedia.py"", line 576, in _load_face_filter
    ref_threshold)
  File ""/srv/lib/face_filter.py"", line 46, in __init__
    self.align_faces(""cv2-dnn"", ""cv2-dnn"", ""none"", multiprocess)
  File ""/srv/lib/face_filter.py"", line 78, in align_faces
    self.run_extractor(extractor)
  File ""/srv/lib/face_filter.py"", line 89, in run_extractor
    self.queue_images(extractor)
  File ""/srv/lib/face_filter.py"", line 125, in queue_images
    in_queue.put(""EOF"", timeout=1)
  File ""/usr/lib/python3.6/queue.py"", line 141, in put
    raise Full
queue.Full

````
Is it any reason you limited to 1 a Queue size in `plugins/extract/pipeline.py::Extractor` ?
I mean, I read a comment, but I wonder if the scripts puts at least one filter and EOF into 1-sized Queue, is it right?
________________________
It was fixed after I changed `self.queue_size = 0 ` and checked out to `18660da1c92994615e88a032242c552295dc96e3` commit, as next commit, where `ExtractMedia ` has been added - failed for me, I got no instance of `ExtractMedia`, but a `dict`.",run script filter provided ended seeing problem method execute free slot add put sending filter queue error got exception main handler recent call last file line process script file line file line file line task action file line file line file line none file line extractor file line extractor file line file line put raise full reason limited queue size mean read comment wonder least one filter queue right fixed checked commit next commit added got instance,issue,negative,positive,neutral,neutral,positive,positive
605514626,"Well, not sure I have the same issue as @Valeronich , as I run script with `-f` filter provided.",well sure issue run script filter provided,issue,positive,positive,positive,positive,positive,positive
605498472,"I've just noticed the log `INFO     Loading Align from Cv2_Dnn plugin..` is shown regardless if `-A=fan` or `-A=cv2-dnn`. Or even `-A` is omitted.
Is it intended?",log loading align shown regardless even intended,issue,negative,neutral,neutral,neutral,neutral,neutral
605432958,"Seeing similar problem running 
Running a command inside the docker container:
```
faceswap.py extract -L INFO -D=s3fd -A=fan -nm=clahe -i=/srv/trump -o=/srv/trump_out -f /srv/trump_example/*
```
Output:
```
Setting Faceswap backend to NVIDIA
03/28/2020 10:48:53 INFO     Log level set to: INFO
03/28/2020 10:48:54 INFO     Output Directory: /srv/trump_out
03/28/2020 10:48:55 INFO     Extracting and aligning face for Face Filter...
03/28/2020 10:48:55 INFO     Filter: ['/srv/trump_example/11_0.jpeg', '/srv/trump_example/1_0.jpeg', '/srv/trump_example/21_0.jpg'']
03/28/2020 10:48:55 INFO     Loading Detect from Cv2_Dnn plugin...
03/28/2020 10:48:55 INFO     Loading Align from Cv2_Dnn plugin..
```
Then it got stuck.
Tried on two different platfoms: Laptop Ubuntu 18.04 Geforce GTX 965m and GCP instance with Nvidia T4:


[logs.txt](https://github.com/deepfakes/faceswap/files/4396998/logs.txt)
",seeing similar problem running running command inside docker container extract output setting log level set output directory face face filter filter loading detect loading align got stuck tried two different instance,issue,negative,neutral,neutral,neutral,neutral,neutral
605419645,"> 帮助>输出系统信息>粘贴在这里

Error obtaining system info: Could not find PlaidML configuration file: ""experimental.json"".",error system could find configuration file,issue,negative,neutral,neutral,neutral,neutral,neutral
604951481,"I guess, they are the first frame of the video. Could it come from there?",guess first frame video could come,issue,negative,positive,positive,positive,positive,positive
604948129,"Are the first 2 images meant to be blank?

![image](https://user-images.githubusercontent.com/36920800/77751267-4445a980-701d-11ea-821d-947ae7b03d00.png)
",first meant blank image,issue,negative,positive,positive,positive,positive,positive
604945435,"FYI, it fails at first or second frame...
Here you have first, second and 34th frame.

No judgement, it is just a personal project 
 :)

![video-frame-1](https://user-images.githubusercontent.com/790558/77750735-9f2ecf00-7024-11ea-8267-8605a540d855.png)![video-frame-2](https://user-images.githubusercontent.com/790558/77750835-ca192300-7024-11ea-9a52-07990e8bc595.png)

![video-frame-34](https://user-images.githubusercontent.com/790558/77750748-a3f38300-7024-11ea-9069-34e8e08db9f6.png)
",first second frame first second th frame personal project,issue,negative,positive,neutral,neutral,positive,positive
604941423,@torzdf I tried directly fomr video and form images. I'll get you an image right now,tried directly video form get image right,issue,negative,positive,positive,positive,positive,positive
604935475,"Please provide your system info.

**GUI Users:** Go to Help -> Output system information

**CLI Users**: From inside your virtual environment, inside your faceswap folder, run: 
```python -c ""from lib.sysinfo import SysInfo ;  print(SysInfo().full_info())""```",please provide system go help output system information inside virtual environment inside folder run python import print,issue,positive,neutral,neutral,neutral,neutral,neutral
604934811,Help > Output System Info > Paste here,help output system paste,issue,negative,neutral,neutral,neutral,neutral,neutral
604933605,Please provide crash report from you Faceswap Folder,please provide crash report folder,issue,negative,neutral,neutral,neutral,neutral,neutral
599850963,"While we would welcome a PR with TPU support, this PR does not provide that.  What it does provide -- A downloader for the VGGFace2 dataset is encumbered with limitations and license restrictions while providing basically no benefit to the majority of our users.

For these reasons I'm going to close this PR.

If you want to try again and submit a PR to add TPU support, we will welcome it, but please do not mix in unnecessary features or side packages like VGGFace2.",would welcome support provide provide license providing basically benefit majority going close want try submit add support welcome please mix unnecessary side like,issue,positive,positive,positive,positive,positive,positive
599215281,"Hello @muhammetfaik! Thanks for opening this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`vgg2dataset.py`](https://github.com/deepfakes/faceswap/blob/e45fe693042b928a8e821fe13a0e359bd083d766/vgg2dataset.py):

> [Line 44:17](https://github.com/deepfakes/faceswap/blob/e45fe693042b928a8e821fe13a0e359bd083d766/vgg2dataset.py#L44): [W292](https://duckduckgo.com/?q=pep8%20W292) no newline at end of file

",hello thanks opening checked touched pep found file line end file,issue,negative,positive,positive,positive,positive,positive
598676506,"I believe this is an internal error to ImageIO (a library we use for working with video).

I don't believe that it actually has any impact beyond spitting out an annoying message.

I will leave this issue open, to remind myself to double check, but I think you can safely ignore it.",believe internal error library use working video believe actually impact beyond spitting annoying message leave issue open remind double check think safely ignore,issue,negative,negative,neutral,neutral,negative,negative
597086066,"From inside your virtual environment, inside your faceswap folder, run: 
```python -c ""from lib.sysinfo import SysInfo ;  print(SysInfo().full_info())""```
and post output",inside virtual environment inside folder run python import print post output,issue,negative,neutral,neutral,neutral,neutral,neutral
595747978,Could you link me to this commit @torzdf ? I do not find it.,could link commit find,issue,negative,neutral,neutral,neutral,neutral,neutral
595742251,@ZackJohn This bug has finally been found and fixed in latest commit,bug finally found fixed latest commit,issue,negative,positive,positive,positive,positive,positive
595361321,Update. This was fixed in the latest commit.,update fixed latest commit,issue,negative,positive,positive,positive,positive,positive
590896425,"This solution actually works.
When attempted to run faceswap from docker I've faced same two issues: with required matplotlib version (#970 ) and with python version being outdated in 1.12 (required 3.6, but only 3.5 provided in image).",solution actually work run docker faced two version python version outdated provided image,issue,negative,negative,negative,negative,negative,negative
590794477,"Thanks for this.

None of the current Devs use Docker, so I am going to wait for some feedback from other Docker users (@JustinGuese ?) and push if confirmed.",thanks none current use docker going wait feedback docker push confirmed,issue,negative,positive,positive,positive,positive,positive
590727972,"I have same problem too.

**Environment**
- Mac OS 10.15.3
- Python 3.6.9
- Detector: S3Fd 

Already test with these setting but still not working
- use absolute directory
- change input source 
   - another video
   - use image directory as input source

https://mega.nz/#!jRs3HDhS!wT2h-TTUS02XsXswhnRSe5qZoikz4T1-GuIsqnbWbK8

[crash_report.2020.02.25.123103291503.log](https://github.com/deepfakes/faceswap/files/4248622/crash_report.2020.02.25.123103291503.log)
",problem environment mac o python detector already test setting still working use absolute directory change input source another video use image directory input source log,issue,negative,positive,positive,positive,positive,positive
589616964,"I'm closing this issue as the recommended install method for Linux is to use the install script:

https://github.com/deepfakes/faceswap/releases/tag/v1.0.0",issue install method use install script,issue,negative,neutral,neutral,neutral,neutral,neutral
589616506,I'm closing this issue as I don't think there is anything to do here. Please comment again if you disagree and I can look to reopen.,issue think anything please comment disagree look reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
589616162,"I'm not sure why you are hitting this issue, this package is definitely available:
https://pypi.org/project/opencv-python/4.1.2.30/",sure issue package definitely available,issue,positive,positive,positive,positive,positive,positive
589615575,"It will be a barrier, yes. We rely on NVML for reporting GPU stats etc. You will need to find a way to patch it out.",barrier yes rely need find way patch,issue,negative,neutral,neutral,neutral,neutral,neutral
588202115,"Ok. The Jetson Nano has 4gb shared memory so it still may be possible with further tweaking.  I'll report back if I'm successful.

I just wanted to also confirm if the lack of support for NVML is a barrier?",memory still may possible report back successful also confirm lack support barrier,issue,positive,positive,positive,positive,positive,positive
588146926,"Unfortunately I don't have this board to be able to test on, but I don't think it would be best suited to Faceswap.

The absolute minimum that FS will run on (for the lowest end models) is around 2GB of dedicated VRAM.",unfortunately board able test think would best absolute minimum run end around,issue,negative,positive,positive,positive,positive,positive
586578162,"I have a problem with extract too... 
face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
cv2.error: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'

02/15/2020 18:51:45 CRITICAL An unexpected crash has occurred. Crash report written to '/home/zph/faceswap/crash_report.2020.02.15.185145448631.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting

Running pass 1 of 1: Extraction:   3%|▏    | 1022/33830 [00:34<17:50, 30.64it/s]terminate called without an active exception
Aborted (core dumped)
",problem extract face face error assertion function critical unexpected crash crash report written log must provide file seeking assistance please verify running latest version running pas extraction terminate without active exception aborted core,issue,negative,positive,positive,positive,positive,positive
585253322,And I've experienced sth similar when using input with 64 pixels instead of 128? But @deepfakes 64 pixels should work as well right? Anyways if it is not the TF error try using face extraction with 128px,experienced similar input instead work well right anyways error try face extraction,issue,negative,positive,positive,positive,positive,positive
585241478,"For me it was an error with tensorflow. Sth that helped for me was to reinstall TF  1.15 and reboot

cmd/terminal:
conda activate faceswap
conda remove tensorflow*
conda install tensorflow-gpu==1.15

cd [faceswap folder]
python update_deps.py

 [REBOOT system]
",error reinstall activate remove install folder python system,issue,negative,neutral,neutral,neutral,neutral,neutral
581164887,"We don't have immediate plans to upgrade to Tensorflow 2.  We'd have to rewrite huge portions of the code, and we'd lose support for AMD users.  Because of these we are evaluating our options and not planning on upgrading to Tensorflow 2 right now.",immediate upgrade rewrite huge code lose support right,issue,negative,positive,positive,positive,positive,positive
581071540,"Update:
I fixed my issue by changing my conda environment's python version from 3.7 to 3.6 and re-running pip install -r requirements.txt",update fixed issue environment python version pip install,issue,negative,positive,neutral,neutral,positive,positive
581071285,"I'm still having the same problem as well, and as I have multiple conda environments, I cannot just blow away and reinstall it. Has anyone had any success outside of this atomic option?",still problem well multiple blow away reinstall anyone success outside atomic option,issue,negative,positive,neutral,neutral,positive,positive
578696264,"The docker version is community maintained, none of the current Devs use it.

You should be able to edit `requirements.txt` and change

```
matplotlib==3.1.1
```
to
```
matplotlib
```",docker version community none current use able edit change,issue,negative,positive,positive,positive,positive,positive
578408680,Closing issue as Manual Tool will be replaced soon,issue manual tool soon,issue,negative,neutral,neutral,neutral,neutral,neutral
578408627,"This is a bug inherited from a reason plaidml update. See here for causes and solution:
https://forum.faceswap.dev/viewtopic.php?f=4&t=350",bug reason update see solution,issue,negative,neutral,neutral,neutral,neutral,neutral
578408574,"pyyaml isn't a dependency of Faceswap, so I'm not sure why this issue would occur.",dependency sure issue would occur,issue,negative,positive,positive,positive,positive,positive
575427853,"@torzdf sorry, I made a mistake. I will be more careful next time.",sorry made mistake careful next time,issue,negative,negative,negative,negative,negative,negative
575427057,"@nat236919 Pretty sure you're doing GIT wrong :/
",nat pretty sure git wrong,issue,negative,positive,neutral,neutral,positive,positive
573788771,"The code written by /u/deepfakes was released a long time ago and represents a very tiny amount of code.  When he released it, he didn't assign a specific license to it, however, he did provide an implied license by providing it and allowing people to use it.  Since then he commented on posts about the use of the code in other places including reddit posts about this repo and other forks (some of which were closed source) which further supports the license to use it.  Unfortunately, all of this history has been deleted by Reddit when they purged deepfakes from the site.

Today, the only parts that can even remotely be considered even ""derived"" would be the Original model (whose code is by necessity of maintaining compatibility closely related to the original code).  All other code has been COMPLETELY rewritten from scratch with absolutely no remaining relation to the original code.

Further, I think you guys are missing the point of a ""Derivative work"".  In the US and all countries that have copyright treaties with the US, Deritivative works have their own copyright protection independent of the original's (which also has copyright protection).  This doesn't mean we have to clean room develop Faceswap, just that Faceswap is protected on it's own.  Any use of u/Deepfakes' code is either under implied license or fair use for compatibility.

Faceswap is licensed as GPLv3 .  Nothing here changes that.

If you have any other questions on this, please bring them to our Discord server https://discord.gg/FC54sYg",code written long time ago tiny amount code assign specific license however provide license providing people use since use code closed source license use unfortunately history site today even remotely considered even derived would original model whose code necessity compatibility closely related original code code completely scratch absolutely relation original code think missing point derivative work u copyright u work copyright protection independent original also copyright protection mean clean room develop use code either license fair use compatibility licensed nothing please bring discord server,issue,positive,positive,neutral,neutral,positive,positive
573644865,"> This is good, if I understand correctly, all contributions after u/deepfakes have been under GPL 3.0.7

I am not even sure that is true.
All contributions after the pull request that added the license were released under GPL 3.0. If there are any contributions before then from authors that no longer are part of the project, their contributions are also provided without any license (which is bad).

But let's say it's true and we already are at that point: there is no code from u/deepfake. This would not help: the code would still qualify as a derviative.

Imagine translating a book in French: even if there is no word from the original author, the book is still a derivative.

I think it's ok to say ""all our contributions are under GPL 3.0"": that means a potential user will never be sued by any of the current authors (as long as they are not breaking the license) and, if they trust that u/deepfake will never sue them either (note that he absolutely could have proofs he is the original author even if he was anonymous: in Italy, where I live, I know of some proofs one can have, I don't know about the rules of other countries), which is indeed unlikely, they can feel pretty much safe using the software.

However, for many, including myself, it's different: many don't care whether it's likely to get sued or not, but want to follow copyright law as a matter of principle. Additionally, many companies take extra care and free software must be usable for commercial purposes as well. Additionally, I would argue if this still is a derivative work of the original, it's not fair to u/deepfake to claim it has a license which he didn't give.

The core point here is what we mean by ""ground up"": if we mean there is simply not a line of code that he wrote originally, it doesn't matter. If we mean a different team of people, without ever looking at the source code (based on descriptions of the program, on papers about it etc...) build it from scratch and **independently**, releasing every contribution under GPL 3.0, there is no copyright issue (at worst patent issues). Everything in between, as I said, is either a gray area or an area which I do not understand since I am not an expert in laws.",good understand correctly even sure true pull request added license longer part project also provided without license bad let say true already point code would help code would still qualify imagine book even word original author book still derivative think say potential user never current long breaking license trust never sue either note absolutely could original author even anonymous live know one know indeed unlikely feel pretty much safe however many different many care whether likely get want follow copyright law matter principle additionally many take extra care free must usable commercial well additionally would argue still derivative work original fair claim license give core point mean ground mean simply line code wrote originally matter mean different team people without ever looking source code based program build scratch independently every contribution copyright issue worst patent everything said either gray area area understand since expert,issue,positive,positive,positive,positive,positive,positive
573519921,"> The entire code base has been entirely rewritten from the ground up, several times over

This is good, if I understand correctly, all contributions after u/deepfakes have been under GPL 3.0. If we can do a blame on the code, and see how much of u/deepfake's code is remaining, from that we can keep an eye out. 

It's entirely possible that in the future, through continuous improvement, and contributions, we could reach a point where u/deepfake's code will have been cycled out to the 99%-100% range. 

I can self assign an issue to tracking down how much of u/deepfake's original code is in the repo if there's interest?",entire code base entirely ground several time good understand correctly blame code see much code keep eye entirely possible future continuous improvement could reach point code range self assign issue much original code interest,issue,positive,positive,neutral,neutral,positive,positive
573420233,"> Ultimately no-one knows who /u/deepfakes is and he has never come forward to make himself known.

That is very irrelevant, though.
The fact that obtaining a license is hard, or even impossible, does not matter: if it did, licenses wouldn't matter, as everybody would just give themselves a license.
Plese, note: I am not an expert in law, so I could be wrong about the gray area (not giving yourself a license is not a gray area). However, unless the user can be sure to be allowed to use the project, this potential problem should be noted in the documentation: not doing so can potentially harm a user who wants to be sure they can legally use the project.

> At no point are we looking to profit from this project, but that isn't to say others won't be looking to profit themselves.

Exactly! If it is free software, it must be possible to use it for commercial purposes (otherwise it's not).

I think this project is awesome, but this potential issue should not be unnoticed by the user, if it exist. If we can determine this is safe, however, I will obviously close the issue.",ultimately never come forward make known irrelevant though fact license hard even impossible matter would matter everybody would give license note expert law could wrong gray area giving license gray area however unless user sure use project potential problem noted documentation potentially harm user sure legally use project point looking profit project say wo looking profit exactly free must possible use commercial otherwise think project awesome potential issue unnoticed user exist determine safe however obviously close issue,issue,positive,positive,neutral,neutral,positive,positive
573419793,"I would say that this is ""gray area"" territory.

Ultimately no-one knows who /u/deepfakes is and he has never come forward to make himself known. At no point are we looking to profit from this project, but that isn't to say others won't be looking to profit themselves.

@bryanlyon Is more up to speed on this kind of thing, so hopefully he will come along and add his 2 cents when he's around.",would say gray area territory ultimately never come forward make known point looking profit project say wo looking profit speed kind thing hopefully come along add around,issue,positive,positive,positive,positive,positive,positive
573419523,"Ok, thank you very much for telling me, as I didn't notice it in the mentioned issues.

Before closing the issue, however, I'd like to ask: is this still a derived work from the original or not?

I checked:
- http://digital-law-online.info/lpdi1.0/treatise27.html
- https://softwareengineering.stackexchange.com/questions/208776/would-copyrights-drop-if-i-re-write-open-source-project-into-another-language (I know in this case the language is the same).
- https://softwareengineering.stackexchange.com/questions/81705/rewriting-gpl-code-to-change-license

The answer seems to be that it's not very clear. If you take somebody else's code and you modify it, even extensively, until no similarity can be found, it's still derivative work. If you start from scratch and make something with similar functionalities, it is clearly not. Everything in between (expecially when studying the original source code) seems to be a gray area.",thank much telling notice issue however like ask still derived work original checked know case language answer clear take somebody else code modify even extensively similarity found still derivative work start scratch make something similar clearly everything original source code gray area,issue,positive,positive,positive,positive,positive,positive
573418674,"That is hideously outdated.

The entire code base has been entirely rewritten from the ground up, several times over",hideously outdated entire code base entirely ground several time,issue,negative,negative,negative,negative,negative,negative
573214239,"Yep, I'll take a look. Thanks",yep take look thanks,issue,positive,positive,positive,positive,positive,positive
573193034,"Based on this error output, I changed the Mask Type in the convert panel. It was set on Predicted.

Changing to Components gave me an error that I only had Extended in my alignments, so I change to Extended and now the conversion is working. 

I assume the Predicted type is supposed to auto pick?",based error output mask type convert panel set gave error extended change extended conversion working assume type supposed auto pick,issue,negative,neutral,neutral,neutral,neutral,neutral
573191607,"Here's the error output now:

`
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000117.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000118.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000119.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000120.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000121.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:25 ERROR    Failed to convert image: 'hk trim_000122.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000123.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000124.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000125.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000126.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000127.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
01/10/2020 15:22:26 ERROR    Failed to convert image: 'hk trim_000128.png'. Reason: 'NoneType' object is not subscriptable
Traceback (most recent call last):
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 156, in process
image = self._patch_image(item)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 189, in _patch_image
new_image, background = self._get_new_image(predicted, frame_size)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 234, in _get_new_image
new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 277, in _pre_warp_adjustments
new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\lib\convert.py"", line 306, in _get_image_mask
mask, raw_mask = self._adjustments[""mask""].run(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\_base.py"", line 123, in run
retval = self.process(*args, **kwargs)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 48, in process
mask = self._get_mask(detected_face, predicted_mask)
File ""C:\Users\jpcho\faceswap\plugins\convert\mask\mask_blend.py"", line 75, in _get_mask
mask = predicted_mask[..., None]
TypeError: 'NoneType' object is not subscriptable
Terminating Process...
Terminated
Process exited.
`",error output recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object error convert image reason object recent call last file line process image item file line background file line file line file line mask mask file line run file line process mask file line mask none object process process,issue,negative,neutral,neutral,neutral,neutral,neutral
573010996,"Thanks for the report.

Manual Tool is end of life, with an improved tool being developed, so we are unlikely to look to fix this bug.",thanks report manual tool end life tool unlikely look fix bug,issue,negative,negative,negative,negative,negative,negative
573010705,"@jpchow26 Annoyingly, that error has happened inside a thread, so we don't get the full traceback.

If you are comfortable editing the code, please uncomment these 2 lines and run again to get the full traceback:

https://github.com/deepfakes/faceswap/blob/ff76461a2750afb3612ae4d4947a9156528a6c6d/lib/convert.py#L163
https://github.com/deepfakes/faceswap/blob/ff76461a2750afb3612ae4d4947a9156528a6c6d/lib/convert.py#L164",annoyingly error inside thread get full comfortable code please run get full,issue,negative,positive,neutral,neutral,positive,positive
573008473,"Ok, I have been provided with a video, but cannot recreate this bug....

My next request is for a full TRACE log.

If you encounter this issue, then please set loglevel to TRACE and provide the full trace report. Note that the process will run slower and the log is likely to be huge.",provided video recreate bug next request full trace log encounter issue please set trace provide full trace report note process run log likely huge,issue,positive,positive,positive,positive,positive,positive
572939211,"We are using it in a project , where we tried for the default input size but still doesn't render the desired quality, so we are trying a lot of things, one of them is increasing the input size.
So we modified the code a bit with the input size, but then it breaks in this line. In general is not a good idea that input size is hardcoded in my opinion but if it is, I think is best that it is done in one place.",project tried default input size still render desired quality trying lot one increasing input size code bit input size line general good idea input size opinion think best done one place,issue,positive,positive,positive,positive,positive,positive
572680831,"While this isn't exactly a ""bug"" I don't see any reason to not commit this PR.  (The reason it's not really a bug is that Villain is meant to only allow a 128x input.)

Just as a curiosity, what do you see as the need for changing the input size here?",exactly bug see reason commit reason really bug villain meant allow input curiosity see need input size,issue,negative,positive,positive,positive,positive,positive
571633407,"Ran an update and restart. Now the error is slightly different on convert:
```
Loading...
Setting Faceswap backend to NVIDIA
01/07/2020 10:22:14 INFO     Log level set to: INFO
Using TensorFlow backend.
01/07/2020 10:22:16 INFO     Input Video: D:\hk source\hk trim.mp4

01/07/2020 10:22:16 INFO     Reading alignments from: 'D:\hk source\hk trim_alignments.fsa'
01/07/2020 10:22:16 INFO     Loading Writer from Ffmpeg plugin...

01/07/2020 10:22:16 INFO     Using configuration saved in state file
01/07/2020 10:22:20 INFO     Loaded model from disk: 'D:\jp cho villain model'
01/07/2020 10:22:21 INFO     Loading Mask from Box_Blend plugin...
01/07/2020 10:22:21 INFO     Loading Mask from Mask_Blend plugin...
01/07/2020 10:22:21 INFO     Loading Color from Avg_Color plugin...
01/07/2020 10:22:22 INFO     Outputting to: 'd:\output 8\hk trim_converted.mp4'

01/07/2020 10:22:37 ERROR    Failed to convert image: 'hk trim_000117.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:37 ERROR    Failed to convert image: 'hk trim_000118.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000119.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000120.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000121.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000122.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000123.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000124.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000125.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:38 ERROR    Failed to convert image: 'hk trim_000126.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:39 ERROR    Failed to convert image: 'hk trim_000127.png'. Reason: 'NoneType' object is not subscriptable
01/07/2020 10:22:39 ERROR    Failed to convert image: 'hk trim_000128.png'. Reason: 'NoneType' object is not subscriptable
Terminating Process...

Terminated
Process exited.

```

============ System Information ============
encoding:            cp1252
git_branch:          master
git_commits:         ff76461 lib.cli - Add dfaker tooltip and typo fix.. 86d039c Convert - bugfixes - Default mask to an available mask in Preview tool - Correctly output predicted mask. 497779d lib.gui Centralize get_scaling and set_geometry to utils.config Suppress Error when rebuilding GUI for TreeView. f2333e1 tools.preview - Limit mask selection to only masks available for all faces plugins.mask - Correctly set dtype for ""None"" mask. 91da1bb tools.mask - Bugfixes - Missing masks - fix memory leak - Missing masks - Handle multiple faces in frames properly
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: GeForce GTX 1060 3GB
gpu_devices_active:  GPU_0
gpu_driver:          441.87
gpu_vram:            GPU_0: 3072MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.18362-SP0
os_release:          10
py_command:          C:\Users\jpcho\faceswap/faceswap.py gui
py_conda_version:    conda 4.7.10
py_implementation:   CPython
py_version:          3.6.8
py_virtual_env:      True
sys_cores:           4
sys_processor:       Intel64 Family 6 Model 42 Stepping 7, GenuineIntel
sys_ram:             Total: 16351MB, Available: 12487MB, Used: 3863MB, Free: 12487MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.7.1
certifi==2019.11.28
cloudpickle==1.1.1
cycler==0.10.0
cytoolz==0.9.0.1
dask==1.2.2
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.6.1
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==3.1.1
mkl-fft==1.0.12
mkl-random==1.0.2
mkl-service==2.0.2
mock==3.0.5
networkx==2.3
numpy==1.17.4
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.2.30
pathlib==1.0.1
Pillow==6.2.1
protobuf==3.8.0
psutil==5.6.2
pyparsing==2.4.0
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.1
PyWavelets==1.0.3
pywin32==223
PyYAML==5.1
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.2.1
six==1.12.0
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
toolz==0.9.0
toposort==1.5
tornado==6.0.2
tqdm==4.32.1
Werkzeug==0.15.4
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at C:\Users\jpcho\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.1                    py36_0  
astor                     0.7.1                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.11.27                    0  
certifi                   2019.11.28               py36_0  
cloudpickle               1.1.1                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.0                cuda10.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.9.0.1          py36hfa6e2cd_1  
dask-core                 1.2.2                      py_0  
decorator                 4.4.0                    py36_1  
fastcluster               1.1.25                   pypi_0    pypi
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.6.1                    py36_0  
imageio-ffmpeg            0.3.0                    pypi_0    pypi
intel-openmp              2019.4                      245  
joblib                    0.13.2                   py36_0  
jpeg                      9c                hfa6e2cd_1001    conda-forge
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py36ha925a31_0  
libblas                   3.8.0                     8_mkl    conda-forge
libcblas                  3.8.0                     8_mkl    conda-forge
liblapack                 3.8.0                     8_mkl    conda-forge
liblapacke                3.8.0                     8_mkl    conda-forge
libmklml                  2019.0.3                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.8.0                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
libwebp                   1.0.2                hfa6e2cd_2    conda-forge
markdown                  3.1.1                    py36_0  
matplotlib                3.1.1            py36hc8f65d3_0  
mkl                       2019.4                      245  
mkl-service               2.0.2            py36he774522_0  
mkl_fft                   1.0.12           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
mock                      3.0.5                    py36_0  
networkx                  2.3                        py_0  
numpy                     1.17.4           py36h4320e6b_0  
numpy-base                1.17.4           py36hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv                    4.1.0            py36hb4945ee_5    conda-forge
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1d               he774522_3  
pathlib                   1.0.1                    py36_1  
pillow                    6.2.1            py36hdc69c19_0  
pip                       19.1.1                   py36_0  
protobuf                  3.8.0            py36h33f27b4_0  
psutil                    5.6.2            py36he774522_0  
pyparsing                 2.4.0                      py_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.8                h9f7ef89_7  
python-dateutil           2.8.0                    py36_0  
pytz                      2019.1                     py_0  
pywavelets                1.0.3            py36h8c2d366_1  
pywin32                   223              py36hfa6e2cd_1  
pyyaml                    5.1              py36he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py36ha925a31_0  
scikit-learn              0.21.2           py36h6288b17_0  
scipy                     1.2.1            py36h29ff71c_0  
setuptools                41.0.1                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.28.0               he774522_0  
tensorboard               1.13.1           py36h33f27b4_0  
tensorflow                1.13.1          gpu_py36h9006a92_0  
tensorflow-base           1.13.1          gpu_py36h871c8ca_0  
tensorflow-estimator      1.13.0                     py_0  
tensorflow-gpu            1.13.1               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.9.0                    py36_0  
toposort                  1.5                      pypi_0    pypi
tornado                   6.0.2            py36he774522_0  
tqdm                      4.32.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.16.27012          hf0eaf9b_1  
werkzeug                  0.15.4                     py_0  
wheel                     0.33.4                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
kernel_size:              3
passes:                   4
threshold:                4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               8

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.s3fd]
confidence:               75
batch-size:               8

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.vgg_obstructed]
batch-size:               2

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.dfl_h128]
lowmem:                   True

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.dlight]
features:                 lowmem
details:                  good
output_size:              256

[model.original]
lowmem:                   True

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   True
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   True

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4


",ran update restart error slightly different convert loading setting log level set input video reading loading writer configuration saved state file loaded model disk cho villain loading mask loading mask loading color error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object error convert image reason object process process system information master add typo fix convert default mask available mask preview tool correctly output mask centralize suppress error fe limit mask selection available correctly set none mask dabb missing fix memory leak missing handle multiple properly global version found check global version found check true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast markdown mock pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type threshold erosion method amount radius threshold container preset medium tune none profile auto level auto loop false format false format false optimize false true global false confidence confidence global false tab extract font default prompt true global coverage none false false false false false true mae true true architecture false good true true true true,issue,positive,positive,neutral,neutral,positive,positive
570761510,"Got the exact same problem while running faceswap.py. Cannot start gui nor extract in conda prompt Clean Windows 10 installation with Nvidia GPUs.

Solved by following: https://forum.faceswap.dev/app.php/faqpage#f1r1

Make sure you don't have other versions of python installed on your machine",got exact problem running start extract prompt clean installation following make sure python machine,issue,negative,positive,positive,positive,positive,positive
570755825,"@torzdf As @SharkEzz mentioned there's no crash happening when I run the convert or preview tool.  There's just exceptions outputted to the console as mentioned. FWIW the model I'm using is pretty old. I do run update within deepfake before every run, so it's safe to say the model was created using code from Nov 27 if this coul be an issue.

![image](https://user-images.githubusercontent.com/10886704/71759807-c9874b00-2e80-11ea-91f2-21f693e9b982.png)
",crash happening run convert preview tool console model pretty old run update within every run safe say model code coul issue image,issue,positive,positive,positive,positive,positive,positive
570055504,"It happens when I start the conversion process.
No matter which trainer or which video is used, I always have the same issue
Here is all the logs generated, it does not generate a crash report file :

https://gist.github.com/SharkEzz/87061478efccc22b2ef3be1852350b9c

Thank you in advance !",start conversion process matter trainer video used always issue generate crash report file thank advance,issue,negative,neutral,neutral,neutral,neutral,neutral
569978412,"Hi guys,

I was able to fix the issue by changing the detector to 'cv2-dnn'. 

command that works for me: python3.7 faceswap.py extract -D cv2-dnn -i __input_folder__ -o __output_folder__

@torzdf next time i encounter this bug, i will make sure to create a video and share it with you.

Thanks!",hi able fix issue detector command work python extract next time encounter bug make sure create video share thanks,issue,positive,positive,positive,positive,positive,positive
569943208,"As I said before, I cannot diagnose this bug without a source video that fails. If *anyone* can provide a video that causes this failure I can look into it",said diagnose bug without source video anyone provide video failure look,issue,negative,negative,negative,negative,negative,negative
569942651,I need the full crash report that is generated to diagnose this issue,need full crash report diagnose issue,issue,negative,positive,positive,positive,positive,positive
569467389,"@AbysmalBiscuit 


I have the same problem too.  
Mac sys. 
Python 3.7.4
And I run in a virtual environment tool by using pip3.

My solution way is  try for the absolute directory. And it does works well !
May be you should try for ab dir rather than relatively dir. Good luck.
",problem mac python run virtual environment tool pip solution way try absolute directory work well may try rather relatively good luck,issue,positive,positive,positive,positive,positive,positive
569150464,"Yeah that is a Memory error. Reduce the batchsize for FAN.
But tbh. you probably won't get anything really good out of that machine.
Think about using cloud computing our using another machine with a better GPU with more VRAM.",yeah memory error reduce fan probably wo get anything really good machine think cloud another machine better,issue,positive,positive,positive,positive,positive,positive
569138170,"Same issue here

============ System Information ============
encoding:            cp1252
git_branch:          master
git_commits:         dc2787d Bugfix: GUI - Crash when resizing options panel.
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: GeForce GTX 1060 6GB
gpu_devices_active:  GPU_0
gpu_driver:          441.66
gpu_vram:            GPU_0: 6144MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.18362-SP0
os_release:          10
py_command:          D:\faceswap/faceswap.py gui
py_conda_version:    conda 4.8.0
py_implementation:   CPython
py_version:          3.7.5
py_virtual_env:      True
sys_cores:           12
sys_processor:       AMD64 Family 23 Model 1 Stepping 1, AuthenticAMD
sys_ram:             Total: 16338MB, Available: 12140MB, Used: 4197MB, Free: 12140MB

=============== Pip Packages ===============
absl-py==0.8.1
astor==0.8.0
certifi==2019.11.28
cloudpickle==1.2.2
cycler==0.10.0
cytoolz==0.10.1
dask==2.9.0
decorator==4.4.1
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
google-pasta==0.1.8
grpcio==1.16.1
h5py==2.9.0
imageio==2.6.1
imageio-ffmpeg==0.3.0
joblib==0.14.1
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==3.1.1
mkl-fft==1.0.15
mkl-random==1.1.0
mkl-service==2.3.0
networkx==2.4
numpy==1.17.4
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.2.30
opt-einsum==3.1.0
pathlib==1.0.1
Pillow==6.2.1
protobuf==3.11.2
psutil==5.6.7
pyparsing==2.4.5
pyreadline==2.1
python-dateutil==2.8.1
pytz==2019.3
PyWavelets==1.1.1
pywin32==227
PyYAML==5.2
scikit-image==0.15.0
scikit-learn==0.22
scipy==1.3.2
six==1.13.0
tensorboard==2.0.0
tensorflow==1.15.0
tensorflow-estimator==1.15.1
termcolor==1.1.0
toolz==0.10.0
toposort==1.5
tornado==6.0.3
tqdm==4.40.2
Werkzeug==0.16.0
wincertstore==0.2
wrapt==1.11.2

============== Conda Packages ==============
# packages in environment at C:\Users\Tristan\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.8.1                    py37_0  
astor                     0.8.0                    py37_0  
blas                      1.0                         mkl  
ca-certificates           2019.11.27                    0  
certifi                   2019.11.28               py37_0  
cloudpickle               1.2.2                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.5                cuda10.0_0  
cycler                    0.10.0                   py37_0  
cytoolz                   0.10.1           py37he774522_0  
dask-core                 2.9.0                      py_0  
decorator                 4.4.1                      py_0  
fastcluster               1.1.25          py37he350917_1000    conda-forge
ffmpeg                    4.2                  h6538335_0    conda-forge
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py37_0  
git                       2.23.0               h6bb4b03_0  
google-pasta              0.1.8                      py_0  
grpcio                    1.16.1           py37h351948d_1  
h5py                      2.9.0            py37h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.6.1                    py37_0  
imageio-ffmpeg            0.3.0                      py_0    conda-forge
intel-openmp              2019.4                      245  
joblib                    0.14.1                     py_0  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py37_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py37ha925a31_0  
libmklml                  2019.0.5                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.11.2               h7bd577a_0  
libtiff                   4.1.0                h56a325e_0  
markdown                  3.1.1                    py37_0  
matplotlib                3.1.1            py37hc8f65d3_0  
mkl                       2019.4                      245  
mkl-service               2.3.0            py37hb782905_0  
mkl_fft                   1.0.15           py37h14836fe_0  
mkl_random                1.1.0            py37h675688f_0  
networkx                  2.4                        py_0  
numpy                     1.17.4           py37h4320e6b_0  
numpy-base                1.17.4           py37hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py37_0  
opencv-python             4.1.2.30                 pypi_0    pypi
openssl                   1.1.1d               he774522_3  
opt_einsum                3.1.0                      py_0  
pathlib                   1.0.1                    py37_1  
pillow                    6.2.1            py37hdc69c19_0  
pip                       19.3.1                   py37_0  
protobuf                  3.11.2           py37h33f27b4_0  
psutil                    5.6.7            py37he774522_0  
pyparsing                 2.4.5                      py_0  
pyqt                      5.9.2            py37h6538335_2  
pyreadline                2.1                      py37_1  
python                    3.7.5                h8c8aaf0_0  
python-dateutil           2.8.1                      py_0  
pytz                      2019.3                     py_0  
pywavelets                1.1.1            py37he774522_0  
pywin32                   227              py37he774522_0  
pyyaml                    5.2              py37he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py37ha925a31_0  
scikit-learn              0.22             py37h6288b17_0  
scipy                     1.3.2            py37h29ff71c_0  
setuptools                42.0.2                   py37_0  
sip                       4.19.8           py37h6538335_0  
six                       1.13.0                   py37_0  
sqlite                    3.30.1               he774522_0  
tensorboard               2.0.0              pyhb38c66f_1  
tensorflow                1.15.0          gpu_py37hc3743a6_0  
tensorflow-base           1.15.0          gpu_py37h1afeea4_0  
tensorflow-estimator      1.15.1             pyh2649769_0  
tensorflow-gpu            1.15.0               h0d30ee6_0  
termcolor                 1.1.0                    py37_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.10.0                     py_0  
toposort                  1.5                        py_3    conda-forge
tornado                   6.0.3            py37he774522_0  
tqdm                      4.40.2                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.16.27012          hf0eaf9b_1  
werkzeug                  0.16.0                     py_0  
wheel                     0.33.6                   py37_0  
wincertstore              0.2                      py37_0  
wrapt                     1.11.2           py37he774522_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               12

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.s3fd]
confidence:               70
batch-size:               4

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.vgg_obstructed]
batch-size:               2

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
icon_size:                14
font:                     default
font_size:                9
autosave_last_session:    prompt
timeout:                  120
auto_load_model_stats:    True

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur_kernel:         3
mask_threshold:           4
learn_mask:               False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.dlight]
features:                 best
details:                  good
output_size:              256

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4",issue system information master crash panel global version found check global version found check true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast git markdown pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type radius erosion method amount radius threshold container preset medium tune none profile auto level auto loop false format false format false optimize false true global false confidence confidence global false tab extract font default prompt true global coverage none false false false false false true mae false true architecture false best good false false true false,issue,positive,negative,neutral,neutral,negative,negative
569008877,"yeah, i have the same problem with extract too, i run;
`python faceswap.py gui `",yeah problem extract run python,issue,negative,neutral,neutral,neutral,neutral,neutral
567742285,"@bsisic hi, im facing the same issue. can you please elaborate on what the missed configuration was.

TIA!",hi facing issue please elaborate configuration,issue,negative,positive,positive,positive,positive,positive
567207542,"Using the Preview tool also fails when loading the source video and model, with the same error in the title",preview tool also loading source video model error title,issue,negative,neutral,neutral,neutral,neutral,neutral
565741488,"If anyone is able to provide a source that this occurs for, then it will help with diagnosing.",anyone able provide source help,issue,negative,positive,positive,positive,positive,positive
565741105,"Same deal. I've attached my log file as well.
[crash_report.2019.12.14.132632110976.log](https://github.com/deepfakes/faceswap/files/3964187/crash_report.2019.12.14.132632110976.log)
",deal attached log file well log,issue,negative,neutral,neutral,neutral,neutral,neutral
564594443,"You were right, it was a problem of compatibility between libraries. But in my case, the downgrading of tensorflow was not suffisant, the problem came from CUDA's version, which was not compatible with the tensorflow-gpu. Indeed, no matter the version, it doesn't seem to work with CUDA 9.1.

You have to either get CUDA 9.0 or 10.0, and after get careful with the tensorflow version as mentioned in the requirements.txt : 1.12.0<=tensorflow-gpu<=1.13.0 for CUDA 9.0 and 1.13.1<=tensorflow-gpu<1.15 for CUDA 10.0. 

In my case, I upgraded CUDA to 10.0, because the official Nvidia's archives don't distribute the 9.0 version for my version of OS : Linux Ubuntu X86_64 18.04.

So it's now working with the following configuration : 
- Linux Ubuntu X86_64 18.04
- CUDA 10.0
- tensorflow==1.13.1
- tensorflow-gpu==1.13.1
",right problem compatibility case problem came version compatible indeed matter version seem work either get get careful version case official distribute version version o working following configuration,issue,negative,positive,neutral,neutral,positive,positive
563209921,"Images: 68547

Old: 132.78
Mine: 0.22
Yours: 29.63

Thanks for this PR, it is appreciated, but we'll go with the quicker solution",old mine thanks go solution,issue,positive,positive,positive,positive,positive,positive
563199112,"Haha. I've also coded a fix for this.

I'll run some tests. Quickest will get implemented ;)",also fix run get,issue,negative,neutral,neutral,neutral,neutral,neutral
562880410,Adjusted status message as suggested to 'Extraction' when multi-processing. This was just a minor pet peeve of mine,status message minor pet peeve mine,issue,negative,negative,neutral,neutral,negative,negative
562852843,"Hmmm. Not too keen on this. I do take the point though. Probably best to say ""Extraction"" rather than spamming all the individual phase names though. The ""Phase 1 of 1"" should be enough to be clear it is only running through once.",keen take point though probably best say extraction rather individual phase though phase enough clear running,issue,positive,positive,positive,positive,positive,positive
562701546,"Tensorflow 1.14 is not compatible with the keras/multi_gpu_model code due to a bug in the more recent 1.14 version. 

This has been noted for a while ( https://github.com/keras-team/keras/issues/13057 & https://github.com/tensorflow/tensorflow/issues/30728 ). There has been some chatter about whether Keras 2.3.0 has fixed this or not.

Suggest downgrading to TF 1.13 as I'm sure that versioning works with everything.",compatible code due bug recent version noted chatter whether fixed suggest sure work everything,issue,negative,positive,positive,positive,positive,positive
562301556,"Try changing the extractor batch size settings in Extract Settings to 1.

@kilroythethird May be able to offer more advise as he is The AMD Guy.",try extractor batch size extract may able offer advise guy,issue,negative,positive,positive,positive,positive,positive
560453327,"Ok. A better approach would be to replace all of the `exit()` commands with either `sys.exit()` or a `raise SystemExit`

However, this is still not without its issues, because afaik sys.exit() exits the thread rather than the application which is problematic for multithreaded operations.

Either way, exits have been in the code since this repo started, and this is the first time this issue has ever been raised.",better approach would replace exit either raise however still without thread rather application problematic multithreaded either way code since first time issue ever raised,issue,negative,positive,positive,positive,positive,positive
560451542,"@torzdf in the url that you cited, it explicitly says that the recommendation is:
""Replace uses of exit() and quit() with sys.exit() which is built into the interpreter and is guaranteed to be present.""

It doesn't look like an issue in my setup, the script was executed from a notebook, I guess that's why exit was not imported automatically. ",explicitly recommendation replace exit quit built interpreter present look like issue setup script executed notebook guess exit automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
560392600,"This shouldn't be a bug....

`exit()` isn't an alias for `sys.exit()`. Whilst it effectively does the same thing, it gets imported from the `site` module which should be auto imported for all Python projects. 
https://docs.python.org/3/library/site.html
ref: https://help.semmle.com/wiki/pages/viewpage.action?pageId=29394142

If you are having issues with `exit()` then this suggest issues with your setup.",bug exit alias whilst effectively thing site module auto python ref exit suggest setup,issue,negative,positive,positive,positive,positive,positive
559982827,"run with the default extract values
Images found:        22
Faces detected:      17
[faceswap.log](https://github.com/deepfakes/faceswap/files/3907228/faceswap.log)
",run default extract found,issue,negative,neutral,neutral,neutral,neutral,neutral
559979581,"Run with trace logging and post log please.

FYI: Logfile will be huge",run trace logging post log please huge,issue,positive,positive,positive,positive,positive,positive
559888367,"It says it there were no faces detected in your penultimate image.

If you can share your source/dest that may help",penultimate image share may help,issue,positive,neutral,neutral,neutral,neutral,neutral
559859552,"Preview for convert is just a GUI extra, it's non-breaking. I haven't seen this before, so I assume it was a freak circumstance.",preview convert extra seen assume freak circumstance,issue,negative,neutral,neutral,neutral,neutral,neutral
559665564,Well done. It works right now. Thanks:),well done work right thanks,issue,positive,positive,positive,positive,positive,positive
559301741,"Yes, not bad. Thanks for your advice that raise my idea up.",yes bad thanks advice raise idea,issue,negative,negative,negative,negative,negative,negative
559062602,"Ok, cool. That shouldn't be necessary tho, so I am going to look into this.",cool necessary tho going look,issue,negative,positive,positive,positive,positive,positive
558950829,fixed it. I cut the video with short frames.,fixed cut video short,issue,negative,positive,neutral,neutral,positive,positive
558885470,"Yes, 64g ram. The video info is as ffmpeg described:
Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080, 34393 kb/s, 50 fps, 50 tbr, 50k tbn, 100k tbc (default)",yes ram video stream video high default,issue,negative,positive,positive,positive,positive,positive
558883349,64GB of RAM? That makes no sense at all.... What is the resolution of the video you're extracting from?,ram sense resolution video,issue,negative,neutral,neutral,neutral,neutral,neutral
558883120,"Okay,
============ System Information ============
encoding:            UTF-8
git_branch:          master
git_commits:         578aec2 Update INSTALL.md. e4b7717 Minor fixes. 47681a8 Landmarks stored and used as floating point numbers (#928). 36be6cd Vectorize FAN post-processing (#926). 2d229ce Color channel sorting (#905)
gpu_cuda:            9.1
gpu_cudnn:           7.6.5
gpu_devices:         GPU_0: GeForce RTX 2080 SUPER
gpu_devices_active:  GPU_0
gpu_driver:          435.21
gpu_vram:            GPU_0: 7979MB
os_machine:          x86_64
os_platform:         Linux-4.15.0-68-generic-x86_64-with-Ubuntu-18.04-bionic
os_release:          4.15.0-68-generic
py_command:          -c
py_conda_version:    N/A
py_implementation:   CPython
py_version:          3.6.9
py_virtual_env:      True
sys_cores:           8
sys_processor:       x86_64
sys_ram:             Total: 64339MB, Available: 62611MB, Used: 1015MB, Free: 53408MB

=============== Pip Packages ===============
absl-py==0.8.1
astor==0.8.0
cffi==1.13.2
cycler==0.10.0
decorator==4.4.1
enum34==1.1.6
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.3.2
google-pasta==0.1.8
grpcio==1.25.0
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.14.0
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
networkx==2.4
numpy==1.16.2
nvidia-ml-py3==7.352.1
opencv-python==4.1.1.26
pathlib==1.0.1
Pillow==6.1.0
plaidml==0.6.4
plaidml-keras==0.6.4
protobuf==3.10.0
psutil==5.6.5
pycparser==2.19
pyparsing==2.4.5
python-dateutil==2.8.1
pytz==2019.3
PyWavelets==1.1.1
PyYAML==5.1.2
scikit-image==0.16.2
scikit-learn==0.21.3
scipy==1.3.2
six==1.13.0
tensorboard==1.14.0
tensorflow-estimator==1.14.0
tensorflow-gpu==1.14.0
termcolor==1.1.0
toposort==1.5
tqdm==4.38.0
Werkzeug==0.16.0
wrapt==1.11.2

================= Configs ==================
--------- convert.ini ---------

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.match_hist]
threshold:                99.0

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

--------- .faceswap ---------
backend:                  amd

--------- extract.ini ---------

[global]
allow_growth:             False

[align.fan]
batch-size:               12

[mask.unet_dfl]
batch-size:               8

[mask.vgg_clear]
batch-size:               6

[mask.vgg_obstructed]
batch-size:               2

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.s3fd]
confidence:               70
batch-size:               4

[detect.cv2_dnn]
confidence:               50

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur:                False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.villain]
lowmem:                   False

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.dlight]
features:                 best
details:                  good
output_size:              256

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4",system information master update minor used floating point fan color channel super generic true total available used free pip format false format false optimize false true container preset medium tune none profile auto level auto loop false type distance radius type radius erosion method amount radius threshold clip true true threshold contrast brightness global false confidence confidence global coverage none false false false false false true mae false false false true architecture false false true best good,issue,positive,negative,neutral,neutral,negative,negative
558881413,"Ok, if you're not using GUI, From inside your virtual environment, inside your faceswap folder, run: 
```
python -c ""from lib.sysinfo import SysInfo ;  print(SysInfo().full_info())""
```
",inside virtual environment inside folder run python import print,issue,negative,neutral,neutral,neutral,neutral,neutral
558589965,"This is a memory error.....
Can you output your system info and post that please `Help > Output System Info`",memory error output system post please help output system,issue,negative,neutral,neutral,neutral,neutral,neutral
557829239,I checked out into  54b6e860084bf21f7971ed0c35ec96bc686d8403 and now extract images works correctly.,checked extract work correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
557795386,"I think I have a related issue. But I use ""extract"" with default parameters (I don't touch filter). It runs for 1 batch and handles on the detection. 

Like [here](https://pastenow.ru/1b4a9c88878278f554677e35b153cfd5). This is my trace: [faceswap.log](https://github.com/deepfakes/faceswap/files/3882454/faceswap.log).",think related issue use extract default touch filter batch detection like trace,issue,negative,neutral,neutral,neutral,neutral,neutral
557748673,"Bookmark this comment. Then the future you can come and shake his head in dismay at the past you.

Up until recently Tensorflow didn't even support Python 3.7. We will upgrade when we upgrade.",bookmark comment future come shake head dismay past recently even support python upgrade upgrade,issue,negative,negative,neutral,neutral,negative,negative
557747874,I don't bother with (Ana)Condas. On my system I have ~700 python packages installed and there are zero conflicts; so I don't understand the need for env's.,bother ana system python zero understand need,issue,negative,neutral,neutral,neutral,neutral,neutral
557590692,"We rely on a large number of libraries and with each Python version update, it takes time to verify that each library is updated and working on the newest version before we move everyone to that version.  We typically value stability over being on the cutting edge.  That said, we highly recommend using Conda so that each environment can run on different versions, this way your base system can use the latest Python version while Faceswap stays at a supported version without interference.

You are of course welcome with overriding the defaults and trying 3.8 and if you run into any problems, we'd appreciate a bug report letting us know any issues you run into.",rely large number python version update time verify library working version move everyone version typically value stability cutting edge said highly recommend environment run different way base system use latest python version stay version without interference course welcome trying run appreciate bug report u know run,issue,positive,positive,neutral,neutral,positive,positive
555998023,"No it doesn't, although Intel Iris is not directly supported, so your mileage may vary.

You have downloaded as a zip rather than cloned the repo, so it's impossible to know what version you are on

```
Downloads/faceswap-master
git_branch:          Not Found
git_commits:         Not Found
```

But the specific bug you are displaying was fixed in a recent commit
",although iris directly mileage may vary zip rather impossible know version found found specific bug fixed recent commit,issue,negative,negative,neutral,neutral,negative,negative
555821226,"> Get latest code. This has been fixed.

Does it have anything to do with my GPU support",get latest code fixed anything support,issue,negative,positive,positive,positive,positive,positive
555821005,"> Get latest code. This has been fixed.

I clone the code from https://github.com/deepfakes/faceswap ,Isn't this the latest code?",get latest code fixed clone code latest code,issue,negative,positive,positive,positive,positive,positive
555814971,"I attach the trace logs.
I may use sort tool, thank you.

[trace.zip](https://github.com/deepfakes/faceswap/files/3867118/trace.zip)
",attach trace may use sort tool thank,issue,negative,neutral,neutral,neutral,neutral,neutral
555813918,Get latest code. This has been fixed.,get latest code fixed,issue,negative,positive,positive,positive,positive,positive
555807867,"> ```
> Crash report written to '/Users/xxx/Downloads/faceswap-master/crash_report.2019.11.20.075506446544.log'.
> You MUST provide this file if seeking assistance.
> ```

- [ ] 

> ```
> Crash report written to '/Users/xxx/Downloads/faceswap-master/crash_report.2019.11.20.075506446544.log'.
> You MUST provide this file if seeking assistance.
> ```

```
11/20/2019 10:28:07 MainProcess     MainThread      pipeline        detected_faces            DEBUG    Running Detection. Phase: 'detect'
11/20/2019 10:28:07 MainProcess     detect_input_0  _base           _thread_process           DEBUG    Putting EOF
11/20/2019 10:28:17 MainProcess     detect_predict_0 _base           _thread_process           DEBUG    Putting EOF
11/20/2019 10:28:17 MainProcess     detect_output_0 _base           _thread_process           DEBUG    Putting EOF
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'detect_input'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'detect_input_0'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joined all Threads: 'detect_input'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'detect_predict'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'detect_predict_0'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joined all Threads: 'detect_predict'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'detect_output'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'detect_output_0'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  join                      DEBUG    Joined all Threads: 'detect_output'
11/20/2019 10:28:17 MainProcess     MainThread      pipeline        detected_faces            DEBUG    Switching to align phase
11/20/2019 10:28:17 MainProcess     MainThread      extract         _run_extraction           DEBUG    Reloading images
11/20/2019 10:28:17 MainProcess     MainThread      extract         _threaded_redirector      DEBUG    Threading task: (Task: 'reload')
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: '_reload', thread_count: 1)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: '_reload'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): '_reload'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: '_reload_0'
11/20/2019 10:28:17 MainProcess     _reload_0       extract         _reload                   DEBUG    Reload Images: Start. Detected Faces Count: 1
11/20/2019 10:28:17 MainProcess     _reload_0       image           load                      DEBUG    Initializing Load Generator
11/20/2019 10:28:17 MainProcess     _reload_0       image           _set_thread               DEBUG    Setting thread
11/20/2019 10:28:17 MainProcess     _reload_0       multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'ImagesLoader', thread_count: 1)
11/20/2019 10:28:17 MainProcess     _reload_0       multithreading  __init__                  DEBUG    Initialized MultiThread: 'ImagesLoader'
11/20/2019 10:28:17 MainProcess     _reload_0       image           _set_thread               DEBUG    Set thread: <lib.multithreading.MultiThread object at 0x154491f60>
11/20/2019 10:28:17 MainProcess     _reload_0       multithreading  start                     DEBUG    Starting thread(s): 'ImagesLoader'
11/20/2019 10:28:17 MainProcess     _reload_0       multithreading  start                     DEBUG    Starting thread 1 of 1: 'ImagesLoader_0'
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads '_reload': 1
11/20/2019 10:28:17 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launching align plugin
11/20/2019 10:28:17 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    in_qname: extract_align_in, out_qname: extract_mask_in
11/20/2019 10:28:17 MainProcess     MainThread      _base           initialize                DEBUG    initialize Align: (args: (), kwargs: {'in_queue': <queue.Queue object at 0x1516727f0>, 'out_queue': <queue.Queue object at 0x1516728d0>})
11/20/2019 10:28:17 MainProcess     ImagesLoader_0  image           _process                  DEBUG    Load iterator: <bound method ImagesLoader._from_folder of <lib.image.ImagesLoader object at 0x151455a58>>
11/20/2019 10:28:17 MainProcess     ImagesLoader_0  image           _from_folder              DEBUG    Loading images from folder: '/Users/wutongtong/Downloads/faceswap-master/cl_s'. with_hash: False
11/20/2019 10:28:17 MainProcess     _reload_0       multithreading  start                     DEBUG    Started all threads 'ImagesLoader': 1
11/20/2019 10:28:17 MainProcess     MainThread      _base           initialize                INFO     Initializing FAN (Align)...
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'align_predict'
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'align_predict', maxsize: 1)
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'align_predict')
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'align_predict'
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'align_post'
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'align_post', maxsize: 1)
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'align_post')
11/20/2019 10:28:17 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'align_post'
11/20/2019 10:28:17 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiling align threads
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: align_input, function: <bound method Align.process_input of <plugins.extract.align.fan.Align object at 0x15145ec50>>, in_queue: <queue.Queue object at 0x1516727f0>, out_queue: <queue.Queue object at 0x154491a20>)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'align_input', thread_count: 1)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'align_input'
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: align_input
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: align_predict, function: <bound method Aligner._predict of <plugins.extract.align.fan.Align object at 0x15145ec50>>, in_queue: <queue.Queue object at 0x154491a20>, out_queue: <queue.Queue object at 0x1544919b0>)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'align_predict', thread_count: 1)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'align_predict'
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: align_predict
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Adding thread: (name: align_output, function: <bound method Align.process_output of <plugins.extract.align.fan.Align object at 0x15145ec50>>, in_queue: <queue.Queue object at 0x1544919b0>, out_queue: <queue.Queue object at 0x1516728d0>)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'align_output', thread_count: 1)
11/20/2019 10:28:17 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'align_output'
11/20/2019 10:28:17 MainProcess     MainThread      _base           _add_thread               DEBUG    Added thread: align_output
11/20/2019 10:28:17 MainProcess     MainThread      _base           _compile_threads          DEBUG    Compiled align threads: [<lib.multithreading.MultiThread object at 0x154491b00>, <lib.multithreading.MultiThread object at 0x154491828>, <lib.multithreading.MultiThread object at 0x1544917f0>]
11/20/2019 10:28:17 MainProcess     MainThread      session         load_model                VERBOSE  Initializing plugin model: FAN
11/20/2019 10:28:18 MainProcess     _reload_0       image           load                      DEBUG    Closing Load Generator
11/20/2019 10:28:18 MainProcess     _reload_0       multithreading  join                      DEBUG    Joining Threads: 'ImagesLoader'
11/20/2019 10:28:18 MainProcess     _reload_0       multithreading  join                      DEBUG    Joining Thread: 'ImagesLoader_0'
11/20/2019 10:28:18 MainProcess     _reload_0       multithreading  join                      DEBUG    Joined all Threads: 'ImagesLoader'
11/20/2019 10:28:24 MainProcess     MainThread      library         _logger_callback          INFO     Analyzing Ops: 1052 of 3641 operations complete
11/20/2019 10:28:26 MainProcess     MainThread      library         _logger_callback          INFO     Analyzing Ops: 2946 of 3641 operations complete
11/20/2019 10:28:45 MainProcess     MainThread      _base           initialize                INFO     Initialized FAN (Align) with batchsize of 12
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'align_input'
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'align_input_0'
11/20/2019 10:28:45 MainProcess     align_input_0   _base           _thread_process           DEBUG    threading: (function: 'process_input')
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'align_input': 1
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'align_predict'
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'align_predict_0'
11/20/2019 10:28:45 MainProcess     _reload_0       extract         _reload                   DEBUG    Reload Images: Complete
11/20/2019 10:28:45 MainProcess     align_predict_0 _base           _thread_process           DEBUG    threading: (function: '_predict')
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'align_predict': 1
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'align_output'
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'align_output_0'
11/20/2019 10:28:45 MainProcess     align_output_0  _base           _thread_process           DEBUG    threading: (function: 'process_output')
11/20/2019 10:28:45 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'align_output': 1
11/20/2019 10:28:45 MainProcess     MainThread      pipeline        _launch_plugin            DEBUG    Launched align plugin
11/20/2019 10:28:45 MainProcess     MainThread      pipeline        detected_faces            DEBUG    Running Detection. Phase: 'align'
11/20/2019 10:28:45 MainProcess     align_input_0   fan             process_input             DEBUG    Aligning faces around center
11/20/2019 10:28:45 MainProcess     align_input_0   fan             get_center_scale          DEBUG    Calculating center and scale
11/20/2019 10:28:45 MainProcess     align_input_0   fan             crop                      DEBUG    Cropping images
11/20/2019 10:28:45 MainProcess     align_input_0   fan             transform                 DEBUG    Transforming Points
11/20/2019 10:28:45 MainProcess     align_input_0   fan             transform                 DEBUG    Transforming Points
11/20/2019 10:28:45 MainProcess     align_input_0   _base           _thread_process           DEBUG    Putting EOF
11/20/2019 10:28:45 MainProcess     align_predict_0 fan             predict                   DEBUG    Predicting Landmarks
11/20/2019 10:28:49 MainProcess     align_predict_0 library         _logger_callback          INFO     Analyzing Ops: 1516 of 3641 operations complete
11/20/2019 10:28:51 MainProcess     align_predict_0 library         _logger_callback          INFO     Analyzing Ops: 3377 of 3641 operations complete
11/20/2019 10:29:06 MainProcess     align_predict_0 _base           _thread_process           DEBUG    Putting EOF
11/20/2019 10:29:06 MainProcess     align_output_0  fan             get_pts_from_predict      DEBUG    Obtain points from prediction
11/20/2019 10:29:06 MainProcess     align_output_0  multithreading  run                       DEBUG    Error in thread (align_output_0): index 64 is out of bounds for axis 3 with size 64
11/20/2019 10:29:07 MainProcess     MainThread      multithreading  check_and_raise_error     DEBUG    Thread error caught: [(<class 'IndexError'>, IndexError('index 64 is out of bounds for axis 3 with size 64',), <traceback object at 0x15167f4c8>)]
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   initialize                DEBUG    PlaidML already initialized
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   get_supported_devices     DEBUG    []
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   get_all_devices           DEBUG    Experimental Devices: [<plaidml._DeviceConfig object at 0x153201dd8>]
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   get_all_devices           DEBUG    [<plaidml._DeviceConfig object at 0x153201dd8>]
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   __init__                  DEBUG    Initialized: PlaidMLStats
11/20/2019 10:29:07 MainProcess     MainThread      plaidml_tools   supported_indices         DEBUG    []
Traceback (most recent call last):
  File ""/Users/wutongtong/Downloads/faceswap-master/lib/cli.py"", line 128, in execute_script
    process.process()
  File ""/Users/wutongtong/Downloads/faceswap-master/scripts/extract.py"", line 116, in process
    self._run_extraction()
  File ""/Users/wutongtong/Downloads/faceswap-master/scripts/extract.py"", line 212, in _run_extraction
    for idx, faces in enumerate(status_bar):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tqdm/std.py"", line 1091, in __iter__
    for obj in iterable:
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/pipeline.py"", line 217, in detected_faces
    if self._check_and_raise_error():
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/pipeline.py"", line 482, in _check_and_raise_error
    if plugin.check_and_raise_error():
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/_base.py"", line 292, in check_and_raise_error
    err = thread.check_and_raise_error()
  File ""/Users/wutongtong/Downloads/faceswap-master/lib/multithreading.py"", line 84, in check_and_raise_error
    raise error[1].with_traceback(error[2])
  File ""/Users/wutongtong/Downloads/faceswap-master/lib/multithreading.py"", line 37, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/_base.py"", line 405, in _thread_process
    batch = function(batch)
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/align/fan.py"", line 129, in process_output
    self.get_pts_from_predict(batch)
  File ""/Users/wutongtong/Downloads/faceswap-master/plugins/extract/align/fan.py"", line 147, in get_pts_from_predict
    x_subpixel_shift = batch[""prediction""][offsets[0]] - batch[""prediction""][offsets[1]]
IndexError: index 64 is out of bounds for axis 3 with size 64

============ System Information ============
encoding:            UTF-8
git_branch:          Not Found
git_commits:         Not Found
gpu_cuda:            Unsupported OS
gpu_cudnn:           Unsupported OS
gpu_devices:         GPU_0: Intel - Iris Pro (experimental)
gpu_devices_active:  GPU_0
gpu_driver:          ['1.2(Apr 25 2019 22:05:48)']
gpu_vram:            GPU_0: 1536MB
os_machine:          x86_64
os_platform:         Darwin-17.7.0-x86_64-i386-64bit
os_release:          17.7.0
py_command:          faceswap.py extract -i ./cl_s/ -o ./cl_s_dist/
py_conda_version:    N/A
py_implementation:   CPython
py_version:          3.6.3
py_virtual_env:      False
sys_cores:           8
sys_processor:       i386
sys_ram:             Total: 16384MB, Available: 4861MB, Used: 11520MB, Free: 1151MB

=============== Pip Packages ===============
absl-py==0.8.1
astor==0.8.0
cachetools==3.1.1
certifi==2019.9.11
cffi==1.13.2
chardet==3.0.4
Click==7.0
cmake==3.15.3
cycler==0.10.0
decorator==4.4.1
dlib==19.18.0
enum34==1.1.6
face-recognition==1.2.3
face-recognition-models==0.3.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
google-auth==1.7.1
google-auth-oauthlib==0.4.1
google-images-download==2.8.0
google-pasta==0.1.8
grpcio==1.25.0
h5py==2.9.0
idna==2.8
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.14.0
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
networkx==2.4
numpy==1.16.2
nvidia-ml-py3==7.352.1
oauthlib==3.1.0
opencv-contrib-python==4.1.1.26
opencv-python==4.1.1.26
opt-einsum==3.1.0
pathlib==1.0.1
Pillow==6.1.0
plaidml==0.6.4
plaidml-keras==0.6.4
protobuf==3.10.0
psutil==5.6.5
pyasn1==0.4.8
pyasn1-modules==0.2.7
pycparser==2.19
pynvx==0.0.4
pyparsing==2.4.5
python-dateutil==2.8.1
pytz==2019.3
PyWavelets==1.1.1
PyYAML==5.1.2
requests==2.22.0
requests-oauthlib==1.3.0
rsa==4.0
scikit-image==0.16.2
scikit-learn==0.21.3
scipy==1.3.2
selenium==3.141.0
six==1.13.0
tensorboard==1.14.0
tensorflow==1.14.0
tensorflow-estimator==1.14.0
termcolor==1.1.0
toposort==1.5
# Editable install with no version control (tqdm==4.38.0)
-e /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages
urllib3==1.25.7
Werkzeug==0.16.0
wrapt==1.11.2

================= Configs ==================
--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.match_hist]
threshold:                99.0

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
font:                     default
font_size:                9

--------- .faceswap ---------
backend:                  amd

--------- extract.ini ---------

[global]
allow_growth:             False

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709
batch-size:               8

[detect.cv2_dnn]
confidence:               50

[detect.s3fd]
confidence:               70
batch-size:               4

[align.fan]
batch-size:               12

[mask.unet_dfl]
batch-size:               8

[mask.vgg_obstructed]
batch-size:               2

[mask.vgg_clear]
batch-size:               6

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur:                False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.dlight]
features:                 best
details:                  good
output_size:              256

[model.villain]
lowmem:                   False

[model.original]
lowmem:                   False

[model.dfl_h128]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```
this is the file",crash report written log must provide file seeking assistance crash report written log must provide file seeking assistance pipeline running detection phase join joining join joining thread join join joining join joining thread join join joining join joining thread join pipeline switching align phase extract extract task task target start starting thread start starting thread extract reload start count image load load generator image setting thread target image set thread object start starting thread start starting thread start pipeline align pipeline initialize initialize align object object image load bound method object image loading folder false start initialize fan align getting name added name got getting name added name got align thread name function bound method object object object target added thread thread name function bound method object object object target added thread thread name function bound method object object object target added thread align object object object session verbose model fan image load load generator join joining join joining thread join library complete library complete initialize fan align start starting thread start starting thread function start start starting thread start starting thread extract reload complete function start start starting thread start starting thread function start pipeline align pipeline running detection phase fan around center fan calculating center scale fan crop fan transform transforming fan transform transforming fan predict library complete library complete fan obtain prediction run error thread index axis size thread error caught class axis size object initialize already experimental object object recent call last file line file line process file line enumerate file line iterable file line file line file line err file line raise error error file line run file line batch function batch file line batch file line batch prediction batch prediction index axis size system information found found unsupported o unsupported o iris pro experimental extract false total available used free pip install version control clip true true threshold contrast brightness format false optimize false true container preset medium tune none profile auto level auto loop false format false type radius erosion type distance radius method amount radius threshold global false tab extract font default global false confidence confidence global coverage none false false false false false true mae true architecture false false true best good false false false file,issue,positive,negative,neutral,neutral,negative,negative
555793054,"```
Loading minibatch generator: (image_count: 0, side: 'b', do_shuffle: False)
```

You have specified a timelapse folder with no faces in it.
",loading generator side false folder,issue,negative,negative,negative,negative,negative,negative
555776644,"> `Running pass 2 of 3: Align: 0%| | 0/1 [00:05<?, ?it/s]WARNING: Could not generate requirement for distribution -vidia-ml-py3 7.352.1 (/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages): Parse error at ""'-vidia-m'"": Expected W:(abcd...)
> WARNING: Could not generate requirement for distribution -ensorflow 2.0.0 (/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages): Parse error at ""'-ensorfl'"": Expected W:(abcd...)
> WARNING: Could not generate requirement for distribution -ensorboard 1.14.0 (/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages): Parse error at ""'-ensorbo'"": Expected W:(abcd...)
> 11/20/2019 07:55:06 ERROR Got Exception on main handler:
> .....
> IndexError: index 64 is out of bounds for axis 3 with size 64
> 11/20/2019 07:55:06 CRITICAL An unexpected crash has occurred. Crash report written to '/Users/xxx/Downloads/faceswap-master/crash_report.2019.11.20.075506446544.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting
> Running pass 2 of 3: Align: 0%| | 0/1 [00:25<?, ?it/s]
> 
> `

This error is triggered when i run  python3 faceswap.py extract -i ./cl_s/ -o ./cl_s_dist/ ",running pas align warning could generate requirement distribution parse error warning could generate requirement distribution parse error warning could generate requirement distribution parse error error got exception main handler index axis size critical unexpected crash crash report written log must provide file seeking assistance please verify running latest version running pas align error triggered run python extract,issue,negative,positive,positive,positive,positive,positive
555569562,"Please run with logging set to trace, zip the faceswap.log file and send that to us.  The current information is not enough to go off of,.

However, filter is a less than ideal solution for filtering (ironic we know), we recommend instead following the extract guide in our forums and using the sort tool after extract instead.",please run logging set trace zip file send u current information enough go however filter le ideal solution filtering know recommend instead following extract guide sort tool extract instead,issue,positive,positive,positive,positive,positive,positive
555234235,"I just did the same exact process on a Windows 10 machine, CUDA 10.1, cuDNN installed, and same exact error.

",exact process machine exact error,issue,negative,positive,positive,positive,positive,positive
554774638,"I just ran this on another Linux machine, 19.04, fresh install of Faceswap, ran the extractions, and went to train with the files provided.

Same error.

Tried lowering batch sizes in case it was a GPU memory error, but didn't matter.

System difference: CUDA 10.1, Python 3.7

In the logs, neither of them seem to find cuDnn, thought the libraries are clearly installed, don't know if that plays a part. ",ran another machine fresh install ran went train provided error tried lowering batch size case memory error matter system difference python neither seem find thought clearly know part,issue,negative,positive,positive,positive,positive,positive
554762769,"Hello @solidji! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`faceswap.py`](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/faceswap.py):

> [Line 33:31](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/faceswap.py#L33): [E127](https://duckduckgo.com/?q=pep8%20E127) continuation line over-indented for visual indent

* In the file [`scripts/webcam.py`](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py):

> [Line 33:1](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L33): [E402](https://duckduckgo.com/?q=pep8%20E402) module level import not at top of file
> [Line 35:1](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L35): [E302](https://duckduckgo.com/?q=pep8%20E302) expected 2 blank lines, found 1
> [Line 153:9](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L153): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 167:13](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L167): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 174:100](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L174): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (117 > 99 characters)
> [Line 175:100](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L175): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (124 > 99 characters)
> [Line 205:53](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L205): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 205:55](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L205): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 205:81](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L205): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 205:83](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L205): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 295:51](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L295): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 295:53](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L295): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 318:100](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L318): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (120 > 99 characters)
> [Line 319:100](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L319): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)
> [Line 326:52](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L326): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 326:54](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L326): [E251](https://duckduckgo.com/?q=pep8%20E251) unexpected spaces around keyword / parameter equals
> [Line 357:5](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L357): [E115](https://duckduckgo.com/?q=pep8%20E115) expected an indented block (comment)
> [Line 357:5](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L357): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 366:26](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L366): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 368:27](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L368): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 373:28](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L373): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 390:9](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L390): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 392:20](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L392): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 392:21](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L392): [E262](https://duckduckgo.com/?q=pep8%20E262) inline comment should start with '# '
> [Line 404:13](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L404): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 415:1](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L415): [E305](https://duckduckgo.com/?q=pep8%20E305) expected 2 blank lines after class or function definition, found 1
> [Line 430:1](https://github.com/deepfakes/faceswap/blob/459b6a8d2c0ddd15f9e160e32107744b1b486738/scripts/webcam.py#L430): [W391](https://duckduckgo.com/?q=pep8%20W391) blank line at end of file



##### Comment last updated at 2019-11-17 16:32:37 UTC",hello thanks checked touched pep found file line continuation line visual indent file line module level import top file line blank found line block comment start line block comment start line line long line line long line unexpected around parameter line unexpected around parameter line unexpected around parameter line unexpected around parameter line unexpected around parameter line unexpected around parameter line line long line line long line unexpected around parameter line unexpected around parameter line indented block comment line block comment start line least two comment line least two comment line least two comment line block comment start line least two comment line comment start line block comment start line blank class function definition found line blank line end file comment last,issue,negative,positive,neutral,neutral,positive,positive
554496175,"What is your Windows version and are you using the latest NVIDIA drivers?
You can always try to completely uninstall the drivers (with DDU for example) and then reinstall them to see if there is any improvement.
It can also be an hardware issue, you can check the Windows Event Viewer to see if there is any error messages related to the GPU.
Have you experienced any issues with your graphic card before ?",version latest always try completely example reinstall see improvement also hardware issue check event viewer see error related experienced graphic card,issue,negative,positive,positive,positive,positive,positive
553868500,"Thanks for this PR. I am closing it off due to the unrelated dockerfile/colab stuff in it, but will make the amend as the PR suggests",thanks due unrelated stuff make amend,issue,negative,positive,neutral,neutral,positive,positive
553652050,"I'm closing this off, as realistically the code has moved on a bit too much.

I'm also not entirely sold on the benefits.",realistically code bit much also entirely sold,issue,negative,positive,neutral,neutral,positive,positive
553645611,"i have problem with extract too... something like this:

File ""/Developer/faceswap/plugins/extract/detect/_base.py"", line 199, in to_detected_face
y=int(round(top)),
OverflowError: cannot convert float infinity to integer

",problem extract something like file line round top convert float infinity integer,issue,negative,positive,positive,positive,positive,positive
553598853,"Hello @ameenba! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:

* In the file [`scripts/convert.py`](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py):

> [Line 46:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L46): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 48:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L48): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 51:91](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L51): [E231](https://duckduckgo.com/?q=pep8%20E231) missing whitespace after ','
> [Line 51:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L51): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (141 > 99 characters)
> [Line 52:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L52): [E722](https://duckduckgo.com/?q=pep8%20E722) do not use bare 'except'
> [Line 56:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L56): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 58:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L58): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (106 > 99 characters)
> [Line 59:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L59): [E722](https://duckduckgo.com/?q=pep8%20E722) do not use bare 'except'
> [Line 60:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L60): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (120 > 99 characters)
> [Line 63:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L63): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 65:73](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L65): [E231](https://duckduckgo.com/?q=pep8%20E231) missing whitespace after ','
> [Line 65:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L65): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (120 > 99 characters)
> [Line 66:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L66): [E722](https://duckduckgo.com/?q=pep8%20E722) do not use bare 'except'
> [Line 70:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L70): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 73:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L73): [E722](https://duckduckgo.com/?q=pep8%20E722) do not use bare 'except'
> [Line 90:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L90): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 91:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L91): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 96:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L96): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 122:9](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L122): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 123:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L123): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (110 > 99 characters)
> [Line 145:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L145): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 146:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L146): [E266](https://duckduckgo.com/?q=pep8%20E266) too many leading '#' for block comment
> [Line 147:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L147): [E266](https://duckduckgo.com/?q=pep8%20E266) too many leading '#' for block comment
> [Line 154:1](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L154): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> [Line 155:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L155): [E266](https://duckduckgo.com/?q=pep8%20E266) too many leading '#' for block comment
> [Line 213:5](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L213): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 218:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L218): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 220:13](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L220): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 222:17](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L222): [E266](https://duckduckgo.com/?q=pep8%20E266) too many leading '#' for block comment
> [Line 225:100](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L225): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (106 > 99 characters)
> [Line 227:45](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L227): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace
> [Line 228:17](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L228): [E722](https://duckduckgo.com/?q=pep8%20E722) do not use bare 'except'
> [Line 232:17](https://github.com/deepfakes/faceswap/blob/5b21dfa6cb482686b258e0977bdea04fa9fcdd13/scripts/convert.py#L232): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '

",hello thanks checked touched pep found file line block comment start line block comment start line missing line line long line use bare line block comment start line line long line use bare line line long line block comment start line missing line line long line use bare line block comment start line use bare line block comment start line block comment start line block comment start line block comment start line line long line block comment start line many leading block comment line many leading block comment line blank line line many leading block comment line block comment start line block comment start line block comment start line many leading block comment line line long line trailing line use bare line block comment start,issue,negative,positive,neutral,neutral,positive,positive
552200445,@Tylersuard Could you check if that error still occurs with the current version ?,could check error still current version,issue,negative,neutral,neutral,neutral,neutral,neutral
550514054,Fixed in current master branch,fixed current master branch,issue,negative,positive,neutral,neutral,positive,positive
550472809,"This was in fact still a problem when providing .json files, for example when using a config created pre FSA changes.
I merged  (a changed) version of your PR in #929
Thanks for your PR.",fact still problem providing example version thanks,issue,negative,positive,positive,positive,positive,positive
549110901,"@50mkw 
I think you already have one or both as .fsa file, change the A + B_alignments.json to "".fsa"", worked for me.",think already one file change worked,issue,negative,neutral,neutral,neutral,neutral,neutral
549026972,"sorry, but after systemfreez->reboot => no problem, work fine for me !?

",sorry problem work fine,issue,negative,negative,neutral,neutral,negative,negative
548861462,"I don't believe there is an issue here any more.....
https://github.com/deepfakes/faceswap/blob/11ab910c5e830dacc4030ac3b70e4bb49a5879b0/lib/serializer.py#L258

https://github.com/deepfakes/faceswap/blob/11ab910c5e830dacc4030ac3b70e4bb49a5879b0/lib/alignments.py#L81

Test:
```py
>>> import os
>>> filename = ""/path/to/alignments.fsa""
>>> extension = os.path.splitext(filename)[1]
>>> serializer_extension = ""fsa""
>>> extension[1:] == serializer_extension
True
```

So if an alignments file is passed in with a .fsa extension it will never reach your code.",believe issue test import o extension extension true file extension never reach code,issue,negative,positive,positive,positive,positive,positive
548081421,I'm on latest 30th now.... I can't seem to make the exception stack to pop up now. /shrug,latest th ca seem make exception stack pop,issue,negative,positive,positive,positive,positive,positive
548057059,"I cannot recreate this issue :/

I will take another look.",recreate issue take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
548056651,Can confirm with last Oct 29th build I was seeing the same error messages when trying to move an alignment.,confirm last th build seeing error trying move alignment,issue,negative,neutral,neutral,neutral,neutral,neutral
547663732,"> 
> 
> @Clorr Feedback is welcome.
> I will try this model on the Trump/Cage dataset this weekend and post the result.

Is this dataset available to download?I want a dataset, so I can see how well different models train by time before making my own training",feedback welcome try model weekend post result available want see well different train time making training,issue,positive,positive,positive,positive,positive,positive
547579522,"I spoke with torzdf on discord and it looks like it is a error in the function that detects the faces in the video. 
To fix it:
Go to tools -> EFFMPEG
in the action section select extract.
Input: The video you want to convert.
Output: any folder where the frames from the video will be saved
Fps: -1
the press the button effmpeg.
Then go to extract and extract the faces from the frames of the video like you do it for your training data. Check the results and delete the wrong detected faces. Refactor the aligment to remove the deleted faces from it.
Then go to convert.
InputFile: File with the frames from the video (not the extracted faces!!!)
output dir: where the video would be saved
aligments: aligments file in the frame folder.
reference Video: the original video
every thing else like you want it. 
This fixed it for me.
For a good tutorial for extraction and refactor the aligment file look at https://forum.faceswap.dev/viewtopic.php?f=5&t=27
",spoke discord like error function video fix go action section select extract input video want convert output folder video saved press button go extract extract video like training data check delete wrong remove go convert file video extracted output video would saved file frame folder reference video original video every thing else like want fixed good tutorial extraction file look,issue,positive,positive,positive,positive,positive,positive
547515165,"I got the same problem too. 
I test a mini video with a man whose face is without rotation, and it works.
But with rotation, it doesn't. That's why?
Looking forward to resolution.",got problem test video man whose face without rotation work rotation looking forward resolution,issue,negative,neutral,neutral,neutral,neutral,neutral
547503119,We evaluate version increases on our own as time goes on.  Closing this as premature.,evaluate version time go premature,issue,negative,neutral,neutral,neutral,neutral,neutral
546702007,"> Frustratingly (for you) you pulled the code during a brief period when untested code was pushed to the faceswap Master branch :/
> 
> Could you delete your faceswap folder and get the code again to see if your problem persists.
> 
> Thanks

I reinstalled the code and it worked,

Thanks !",code brief period untested code master branch could delete folder get code see problem thanks code worked thanks,issue,negative,positive,positive,positive,positive,positive
546685811,"> Frustratingly (for you) you pulled the code during a brief period when untested code was pushed to the faceswap Master branch :/
> 
> Could you delete your faceswap folder and get the code again to see if your problem persists.
> 
> Thanks

Thank you,
I will try that now, I had the code training for a 100,000 iterations to kinda get a feel for it :)",code brief period untested code master branch could delete folder get code see problem thanks thank try code training get feel,issue,negative,positive,neutral,neutral,positive,positive
546590340,"Frustratingly (for you) you pulled the code during a brief period when untested code was pushed to the faceswap Master branch :/

Could you delete your faceswap folder and get the code again to see if your problem persists.

Thanks",code brief period untested code master branch could delete folder get code see problem thanks,issue,negative,positive,neutral,neutral,positive,positive
546554506,"This was a push against the wrong branch :/

Have had to force reset it.",push wrong branch force reset,issue,negative,negative,negative,negative,negative,negative
546549099,@torzdf what are all these changes? Should I be looking only for a this small one https://github.com/deepfakes/faceswap/commit/bb26afde3494d2f06a8225f2d908708a845889c1?diff=split#diff-3445dbb2b17101f403f25d977ac60d7f or everything interconnected? For me it looks like the whole smart-mask-alpha branch got merged within this pull request.,looking small one everything like whole branch got within pull request,issue,negative,negative,neutral,neutral,negative,negative
544751516,"@deepfakes I implemented the following changes per your comments:

- I made pep8speaks happy
- logging through W&B is now opt-in by using `-wandb` or `--wandb-logs`
- there is no more prompt from the cli (logging is anonymous if wandb has not been configured) so Travis CI check passed

Let me know if anything else is needed.

**EDIT**: short run with latest code -> https://app.wandb.ai/borisd13/faceswap/runs/bvgqszt1?workspace=user-borisd13",following per made happy logging prompt logging anonymous travis check let know anything else edit short run latest code,issue,positive,positive,positive,positive,positive,positive
544176458,"First of all: are you sure you use the same command for both converts ?
If not 100% sure try adding `-s` to swap the sides.

Additionally, and probably unrelated to your problem:
- Seamless clone is not really a good option for videos
- You are using your model_snapshot folder. The snapshots are normally only to restore the model in case something goes wrong.",first sure use command sure try swap side additionally probably unrelated problem seamless clone really good option folder normally restore model case something go wrong,issue,negative,positive,positive,positive,positive,positive
541555654,"Tensorflow raised an unknown error. This is most likely caused by a failure to launch cuDNN which can occur for some GPU/Tensorflow combinations.

You should enable `allow_growth` to attempt to resolve this issue:
- **GUI:** Go to Settings > Extract Plugins > Global and enable the `allow_growth` option.
- **CLI:** Go to `faceswap/config/extract.ini` and change the `allow_growth` option to `True`.",raised unknown error likely failure launch occur enable attempt resolve issue go extract global enable option go change option true,issue,negative,negative,neutral,neutral,negative,negative
541410254,"Beautiful - tensorflow version was the problem - simply uninstalling righted things.  BTW, appreciate your help even though this was not an issue with faceswap itself.  Now to locate an OpenCL driver for Ryzen 5 2400g . . .",beautiful version problem simply appreciate help even though issue locate driver,issue,positive,positive,positive,positive,positive,positive
541358966,"This might be related to `tensorflow==1.5.0rc0` you have installed via pip.
Not sure if that coming from outside your env or not, but `pip uninstall tensorflow` might already solve your problem.
AFAIK the only project using `libComputeCpp.so` is https://github.com/codeplaysoftware/tensorflow so maybe you tried that one once ?

Additionally it looks like we don't detect your GPU.
If after uninstalling tensorflow==1.5.0rc0 it still won't work try running `plaidml-setup`.
Select experimental and the opencl version.
If you only see llvm as option there you are missing opencl support and need to install an opencl driver.

",might related via pip sure coming outside pip might already solve problem project maybe tried one additionally like detect still wo work try running select experimental version see option missing support need install driver,issue,positive,positive,neutral,neutral,positive,positive
539755644,"I have not seen this bug reported anywhere else, so I am closing this issue, as I suspect it is unique to your setup.",seen bug anywhere else issue suspect unique setup,issue,negative,positive,positive,positive,positive,positive
539755443,"This is an internal error to Tensorflow, most likely caused by a conflict.

You have not installed in a virtual environment, we cannot possibly troubleshoot all possible conflicts.

You should install faceswap inside a virtual environment.",internal error likely conflict virtual environment possibly possible install inside virtual environment,issue,negative,neutral,neutral,neutral,neutral,neutral
539754882,"The error message tells you exactly what is wrong and what to do.

```
You do not have enough GPU memory available to train the selected model at the selected settings. You can try a number of things:
1) Close any other application that is using your GPU (web browsers are particularly bad for this).
2) Lower the batchsize (the amount of images fed into the model each iteration).
3) Try 'Memory Saving Gradients' and/or 'Optimizer Savings' and/or 'Ping Pong Training'.
4) Use a more lightweight model, or select the model's 'LowMem' option (in config) if it has one.
```",error message exactly wrong enough memory available train selected model selected try number close application web particularly bad lower amount fed model iteration try saving pong use lightweight model select model option one,issue,negative,negative,negative,negative,negative,negative
539599837,@deepfakes - we would really like wandb to be useful for open source repos.  We are committed to making the tool always free to open source repositories.  I would love to talk to you about how we could make that commitment feel binding and what uses of data feel good/bad.  Would you be up for jumping on a hangout?,would really like useful open source making tool always free open source would love talk could make commitment feel binding data feel would hangout,issue,positive,positive,positive,positive,positive,positive
539148536,"Thank you so much for this detailed feedback @deepfakes . I'll try to answer the best I can.

> At an absolute minimum PRs need to meet PEP8 standards, and have to make [pep8speaks happy](https://github.com/deepfakes/faceswap/pull/891#issuecomment-537658611) , so this PR will not be accepted until then.

Noted, I'll make sure it is PEP8 compliant.

> With that said, I do see some value in being able to share data, however I have some outstanding concerns.
> 
> 1. If we were to accept this PR then it would have to be Opt-In rather than Opt-Out. This is standard practice for information stored on remote servers and should not come as a surprise.

That's a fair point. Actually the integration to W&B is more valuable to ML Engineers/Scientists who try to fine-tune the architecture. It would be less valuable to people ""just"" playing with the GUI. So I can definitely change the CLI arg to be ""no W&B logging"" by default.

> 2. This prompts the user to create an account (from the cli) when running with WandDB:
> 
> ```
> wandb: W&B is a tool that helps track and visualize machine learning experiments
> wandb: (1) Private W&B dashboard, no account required
> wandb: (2) Create a W&B account
> wandb: (3) Use an existing W&B account
> wandb: (4) Don't visualize my results
> wandb: Enter your choice: 
> ```
> 
> This is, unfortunately, not a workable solution for our users, as many, if not most, use the GUI to run Faceswap and will not be able to enter information in the displayed console window.

No problem, the library actually won’t show this menu if it doesn’t have access to stdin.  When that’s the case it doesn’t send any metrics to the cloud, instead only logging locally.  The first option in the menu allows users to log metrics to W&B without an account so we can also see what possibilities there are there.

@lukas (CEO of Weights & Biases) can you reply to the next points?

Thanks again for those comments which are very useful to ensure W&B can benefit the open-source community. This is definitely a great feedback for them.

I've been personally using it for my own projects and I feel it can help the AI community with more transparency and reproducibility especially when publishing new papers.

",thank much detailed feedback try answer best absolute minimum need meet pep make happy accepted noted make sure pep compliant said see value able share data however outstanding accept would rather standard practice information remote come surprise fair point actually integration valuable try architecture would le valuable people definitely change logging default user create account running tool track visualize machine learning private dashboard account create account use account visualize enter choice unfortunately workable solution many use run able enter information displayed console window problem library actually show menu access case send metric cloud instead logging locally first option menu log metric without account also see reply next thanks useful ensure benefit community definitely great feedback personally feel help ai community transparency reproducibility especially new,issue,positive,positive,positive,positive,positive,positive
538793801,You're best bet is to come to our Discord Server. Link on the front page.,best bet come discord server link front page,issue,negative,positive,positive,positive,positive,positive
538708787,"Oh okay, I'd love to contribute. Any suggestions for papers/implementations? (Apart from avatar)",oh love contribute apart,issue,positive,positive,positive,positive,positive,positive
538635602,We have no plans to port this model as we don't believe it is of a high enough quality. We do welcome PRs though,port model believe high enough quality welcome though,issue,negative,positive,positive,positive,positive,positive
538350934,"First up, thanks for the Pull Request.

At an absolute minimum PRs need to meet PEP8 standards, and have to make [pep8speaks happy](https://github.com/deepfakes/faceswap/pull/891#issuecomment-537658611) , so this PR will not be accepted until then.

With that said, I do see some value in being able to share data, however I have some outstanding concerns.

1) If we were to accept this PR then it would have to be Opt-In rather than Opt-Out. This is standard practice for information stored on remote servers and should not come as a surprise.

2) This prompts the user to create an account (from the cli) when running with WandDB:
```
wandb: W&B is a tool that helps track and visualize machine learning experiments
wandb: (1) Private W&B dashboard, no account required
wandb: (2) Create a W&B account
wandb: (3) Use an existing W&B account
wandb: (4) Don't visualize my results
wandb: Enter your choice: 
```
This is, unfortunately, not a workable solution for our users, as many, if not most, use the GUI to run Faceswap and will not be able to enter information in the displayed console window.

3) Monetization. Whilst I see that there is some benefit to this tool, the primary goal will be to monetize for WanDB. Faceswap is entirely open source, with no paywall for our users at any stage. We have not looked to monetize and have no plans to do so in future. We are driven entirely by voluntary donations. We would need assurances that:
    - The T+Cs would not change and users who previously were able to use wandDB for free would not suddenly find that they have to pay for the same service.
    - That any revenue generated by wanDB from faceswap users would be shared with faceswap. The details of this would clearly need to be ironed out.

4) I would require clarification about what you intend to do with the data that you collect from our users.

These are all deal breakers, from our perspective.

I have posted this as a comment on this PR as I would like to remain as transparent as possible to our users about our plans for Faceswap. You are welcome to continue this discussion with me at: deepfakesrepo@gmail.com

",first thanks pull request absolute minimum need meet pep make happy accepted said see value able share data however outstanding accept would rather standard practice information remote come user create account running tool track visualize machine learning private dashboard account create account use account visualize enter choice unfortunately workable solution many use run able enter information displayed console monetization whilst see benefit tool primary goal monetize entirely open source stage monetize future driven entirely voluntary would need would change previously able use free would suddenly find pay service revenue would would clearly need would require clarification intend data collect deal perspective posted comment would like remain transparent possible welcome continue discussion,issue,positive,positive,positive,positive,positive,positive
538198017,Please state your question and/or fill out the form you posted above?,please state question fill form posted,issue,negative,neutral,neutral,neutral,neutral,neutral
537935351,"Let me retest both again after merging some recent commits by Torzdf. Had been making some last minute refinements as well for review and maybe something didn't transfer. 

EDIT: @linnik , just retested and it seems my test video is running as expected on extract/training? Can you send an error log? If you're on the Discord support forum, I can also take a look at your particular video/images ...?",let retest recent making last minute well review maybe something transfer edit test video running send error log discord support forum also take look particular,issue,negative,positive,neutral,neutral,positive,positive
537928084,"Also, do you have any idea whats up with unet-dfl masker model? I get corrupted mask results with it while others work fine.
![zzz](https://user-images.githubusercontent.com/902428/66127317-03338600-e5f4-11e9-8b27-b4be9b78f791.png)
",also idea whats masker model get corrupted mask work fine,issue,negative,positive,positive,positive,positive,positive
537926784,"Thank you for your work! I've tried your branch and while VGG maskers are working very well, previews aren't showing in preview window and i get following exception for it:
```
Exception in Tkinter callback
Traceback (most recent call last):
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 1705, in __call__
    return self.func(*args)
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 749, in callit
    func(*args)
  File ""/srv/lib/gui/display_page.py"", line 248, in <lambda>
    self.after(waittime, lambda t=waittime: self.update_page(t))
  File ""/srv/lib/gui/display_page.py"", line 246, in update_page
    self.display_item_set()
  File ""/srv/lib/gui/display_command.py"", line 29, in display_item_set
    frame_dims=(self.winfo_width(), self.winfo_height()))
  File ""/srv/lib/gui/utils.py"", line 309, in load_latest_preview
    show_image = self.place_previews(frame_dims)
  File ""/srv/lib/gui/utils.py"", line 420, in place_previews
    samples = np.concatenate((samples, placeholder))
ValueError: all the input array dimensions except for the concatenation axis must match exactly
```",thank work tried branch working well showing preview window get following exception exception recent call last file line return file line file line lambda lambda file line file line file line file line input array except concatenation axis must match exactly,issue,positive,positive,neutral,neutral,positive,positive
537716774,"@torzdf W&B is a superset of Tensorboard.
To try to summarize quickly, Tensorboard is for a single user training a specific model, W&B is for collaboration on a training paradigm: many model variants and experiments by many users, persisting in the cloud (or optionally in local storage) with easy reproducibility over the lifetime of a project, and it's framework agnostic, and it tracks your system/hardware metrics, and lets you log way more formats.

You can see this as an example: https://app.wandb.ai/borisd13/faceswap/runs/vz384aby?workspace=user-borisd13

Those runs are long but let's say I (or other people) did several with different parameters, we would be able to compare them together. Also it's always convenient for reproducibility to log and keep track of an experiment.",try summarize quickly single user training specific model collaboration training paradigm many model many persisting cloud optionally local storage easy reproducibility lifetime project framework agnostic metric log way see example long let say people several different would able compare together also always convenient reproducibility log keep track experiment,issue,negative,positive,positive,positive,positive,positive
537705037,@borisdayma Thanks for the PR. Could you explain what this gives us that Tensorboard doesn't?,thanks could explain u,issue,negative,positive,positive,positive,positive,positive
536950860,"Scope creeeeeeep! ;)

Can I suggest that you start splitting this out? Maybe get the extraction pipeline in first?",scope suggest start splitting maybe get extraction pipeline first,issue,negative,positive,positive,positive,positive,positive
536309421,"@torzdf, yes, but only on the training scripts.
This method fixes extraction and conversion scripts too.",yes training method extraction conversion,issue,negative,neutral,neutral,neutral,neutral,neutral
536298625,"This is an annoying inconsistent issue with Tensorflow and some GPUs.

If you update to the latest code, go settings>extract>global and enable allow growth this issue should be resolved.",annoying inconsistent issue update latest code go extract global enable allow growth issue resolved,issue,negative,negative,negative,negative,negative,negative
536279158,"@gildo Thanks for the feedback. There is actually an ""Allow Growth"" option for TF in the cli for training",thanks feedback actually allow growth option training,issue,positive,positive,neutral,neutral,positive,positive
536278503,"Hello, this seems a Tensorflow/cuDNN issue related with RTX cards, I've fixed it with
`TF_FORCE_GPU_ALLOW_GROWTH=true` enviroment variable.

Hope this helps fellow googlenauts.",hello issue related fixed variable hope fellow,issue,negative,positive,neutral,neutral,positive,positive
536233225,"Try latest commit. I've forced it to use ffmpeg for all video files,",try latest commit forced use video,issue,negative,positive,neutral,neutral,positive,positive
535541288,"Yes, this is a bug with the conda installer or your local install.  Unfortunately there is really nothing that we can do about this ourselves.  Our only suggestion is to try a clean install.  Remove all signs of Python and Conda and try again.  If that doesn't solve it, please raise an issue with Anaconda as they're the only ones who could resolve it.",yes bug installer local install unfortunately really nothing suggestion try clean install remove python try solve please raise issue anaconda could resolve,issue,positive,positive,positive,positive,positive,positive
535537883,"Thanks for that suggestion. 

Obviously it's not your issue, but for some reason I was unable to install that older version of Miniconda. The errors returned were strangely similar to those I get trying to run the Faceswap install script.

Shown is trying to install Miniconda2, which I tried after Miniconda3 didn't work...
 
![miniconda3-4-5-12-screen1](https://user-images.githubusercontent.com/20094391/65698567-a1fc3780-e074-11e9-95a3-eccf7e9eabc1.png)
![miniconda3-4-5-12-screen2](https://user-images.githubusercontent.com/20094391/65698577-a6c0eb80-e074-11e9-9a25-f147a5aca1be.png)

",thanks suggestion obviously issue reason unable install older version returned strangely similar get trying run install script shown trying install tried work screen screen,issue,negative,negative,neutral,neutral,negative,negative
535391003,"Thanks for your time, it's worked after installed again,What a foolish question ,I'm so careless.
Appreciate again @kilroythethird  @torzdf ",thanks time worked foolish question careless appreciate,issue,negative,negative,negative,negative,negative,negative
535240037,"I am not sure why you are running into this error, but it looks like you selected the AMD option while you in fact have an nvidia. card.
Please delete `D:\soft\Anaconda\envs\face` and `E:\faceswap` and rerun the installer.
Make sure you select the nvidia option when prompted.",sure running error like selected option fact card please delete rerun installer make sure select option,issue,positive,positive,positive,positive,positive,positive
535097341,"This is a Conda issue, not a faceswap issue. We have seen this problem before, when Conda made changes.

You can try installing an older version of miniconda. 4.5.12 is known to work",issue issue seen problem made try older version known work,issue,negative,positive,positive,positive,positive,positive
535086039,"Still having no success with that.
I cleaned out all Anaconda/Miniconda files. Restarted, successfully installed Miniconda and ran the faceswap install package. Got exactly the same error.

I tried a couple of times, running the installer under main user, and again with admin privileges. Same problem.

Again, I was able to create a conda environment from the command line without any problems,",still success successfully ran install package got exactly error tried couple time running installer main user problem able create environment command line without,issue,positive,positive,positive,positive,positive,positive
535008793,"@stevepowellGV I incurred into the same error, I installed miniconda without creating anything and the installer worked. Remember to remove the old Anaconda folders as they contain libraries and stuff that may break the installer",error without anything installer worked remember remove old anaconda contain stuff may break installer,issue,negative,positive,neutral,neutral,positive,positive
534952533,It's possible. These kinds of discussions are best placed in our [FaceSwap Forum](https://faceswap.dev/forum) or [FaceSwap Discord server](https://discord.gg/FC54sYg),possible best forum discord server,issue,negative,positive,positive,positive,positive,positive
534951695,"Whilst Faceswap runs on MacOS, none of the current devs have a Mac to test on. You will probably be best off getting help on either our [FaceSwap Forum](https://faceswap.dev/forum) 
or [FaceSwap Discord server](https://discord.gg/FC54sYg)",whilst none current mac test probably best getting help either forum discord server,issue,positive,positive,positive,positive,positive,positive
534951192,"For general usage questions and help, please use either our [FaceSwap Forum](https://faceswap.dev/forum) 
or [FaceSwap Discord server](https://discord.gg/FC54sYg)",general usage help please use either forum discord server,issue,negative,positive,neutral,neutral,positive,positive
534063678,"Cleared out my installs - Conda and Python, cleaned up as per the instructions. 

Running the all-in-one installer ran into a problem creating the Conda envirnment...
![miniconda_fail](https://user-images.githubusercontent.com/20094391/65422829-79b7d300-ddff-11e9-8983-94007378881d.png)

I tried creating the environment manually from Miniconda command line, which worked fine - but then ran into the same issue with the setup script as before.",python per running installer ran problem tried environment manually command line worked fine ran issue setup script,issue,negative,positive,positive,positive,positive,positive
534058904,Thanks a lot. You should add this tip to readme :),thanks lot add tip,issue,negative,positive,positive,positive,positive,positive
534058020,"For some reason `setup.py` sometimes misses items.

To fix this do:

Start > Anaconda Prompt
```
conda activate faceswap
cd faceswap
python updates_deps.py
```
Then try running again",reason sometimes fix start anaconda prompt activate python try running,issue,negative,neutral,neutral,neutral,neutral,neutral
534011602,Many thanks. I'll give that a go and see how I get on.,many thanks give go see get,issue,negative,positive,positive,positive,positive,positive
533689715,"This repo is for FaceSwap, not Faceapp.  If the problem you're having is for FaceSwap please go to https://faceswap.dev/forum/ or our Discord and post your crash log.",problem please go discord post crash log,issue,negative,neutral,neutral,neutral,neutral,neutral
533652420,"This is a conda issue :/

My advice would be to completely remove Conda from your machine, clean it up (as per: https://faceswap.dev/forum/app.php/faqpage?sid=6c5e612f4f04596edebf98168c1ecb8f#f1r1) and run the latest installer from here: https://github.com/deepfakes/faceswap/releases/tag/v1.0.0",issue advice would completely remove machine clean per run latest installer,issue,negative,positive,positive,positive,positive,positive
533639171,My rational is someone familiar with codebase could do this in less than hour. For me it will take days. But can't blame you. It is specific thing to ask.,rational someone familiar could le hour take day ca blame specific thing ask,issue,negative,positive,positive,positive,positive,positive
533637404,"Yeah, we wont be implementing that as I can't see how that will be useful to the project. Sorry.",yeah wont ca see useful project sorry,issue,negative,negative,neutral,neutral,negative,negative
533636923,"Extractor cuts faces out to aligned folder. External program then transforms all images in aligned folder.
Then I need something that places them back to original picture. Converter already does that, but I need it to skip Prediction/Transformation. Like converter flag to skip prediction step.",extractor folder external program folder need something back original picture converter already need skip like converter flag skip prediction step,issue,positive,positive,positive,positive,positive,positive
533634770,"I'm not sure what you're asking. You want the converter to output frames with the original faces on the original frames....

Which is just the original frames? So just use the original frames??",sure want converter output original original original use original,issue,positive,positive,positive,positive,positive,positive
533629305,"I mean not to convert face. If i extract A faces I need converter to add them back.
They extracted faces will be transformed externally.",mean convert face extract need converter add back extracted externally,issue,negative,negative,negative,negative,negative,negative
533628660,This is already how Faceswap works.  It will convert a face on the original image.,already work convert face original image,issue,negative,positive,positive,positive,positive,positive
532754285,"Looking at the one odd model ( IAE ) . Think it may be good to have the encoder.trainable flag logic you've added apply to both the ""encoder"" , ""intermediate_a"", ""intermediate_b"" sub-models if they exist.",looking one odd model think may good flag logic added apply exist,issue,negative,positive,positive,positive,positive,positive
532639263,"@kvrooman Thanks for reviewing. I shall think of a reasonable docstring.
I've seen other developers do `isinstance(layer, (Dense, SomethingThatTrains)): layer.trainable=trainable`,
perhaps I should also be more selective instead of ""brute-forcing"" it.
The setting probably won't work for all models layouts as @torzdf mentioned.
",thanks shall think reasonable seen layer dense perhaps also selective instead setting probably wo work,issue,negative,positive,positive,positive,positive,positive
532609028,"Windows 7 is not directly supported and is untested, so it may or may not be to do with this.

Either way, you are better off getting support on usage on either the discord server or the forums (links in README.md). These issues are for code issues.",directly untested may may either way better getting support usage either discord server link code,issue,negative,positive,positive,positive,positive,positive
532359550,"Yep, Currently only in Extract, but the class needs expanding and shipping across the code imho.

Things to bear in mind (for my reference as much as anything), There can only ever be one TF Session per process, so it is not possible to set up a config_proto for an aligner + detector in the same session. However, we should be able to leverage with K.tf.device() for this kind of use case ",yep currently extract class need expanding shipping across code bear mind reference much anything ever one session per process possible set aligner detector session however able leverage kind use case,issue,positive,positive,positive,positive,positive,positive
532357996,"yes, me too. Easiest to incorporate into the session.py structure using config_proto now. The code moved on so much it made sense to shut this down. I'll swing back around to using the current struture in the to-do list",yes easiest incorporate structure code much made sense shut swing back around current list,issue,positive,positive,neutral,neutral,positive,positive
532357357,"I still want to implement this, or a version of.",still want implement version,issue,negative,neutral,neutral,neutral,neutral,neutral
532353843,left out to long and session architectures changes setup,left long session setup,issue,negative,negative,neutral,neutral,negative,negative
532345517,"Yeah, this is either or. We will keep the styling as is.

Thanks for taking an interest though ",yeah either keep styling thanks taking interest though,issue,positive,positive,positive,positive,positive,positive
531606221,"You've set inputs for timelapse, and nothing exists in those folders.

```Setting timelapse feed: (side: 'b', input_images: '[]', batchsize: 0)```",set nothing setting feed side,issue,negative,neutral,neutral,neutral,neutral,neutral
531588898,"I re-did the break points and found out there's something wrong with my tf, which is strange because neither the setup.py nor `pip install tensorflow-gpu` returned error to me.

I create another venv and used `conda install tensorflow-gpu` , and now it is working.",break found something wrong strange neither pip install returned error create another used install working,issue,negative,negative,negative,negative,negative,negative
531575619,"> 
> 
> Hello @torzdf! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:
> 
>     * In the file [`docs/conf.py`](https://github.com/deepfakes/faceswap/blob/e70623b3c495e02c3a1aa07b7e42df0e9bfadbfd/docs/conf.py):
> 
> 
> > [Line 34:1](https://github.com/deepfakes/faceswap/blob/e70623b3c495e02c3a1aa07b7e42df0e9bfadbfd/docs/conf.py#L34): [E124](https://duckduckgo.com/?q=pep8%20E124) closing bracket does not match visual indentation

This is what happens when you use auto-generated scripts!",hello thanks checked touched pep found file line bracket match visual indentation use,issue,negative,positive,neutral,neutral,positive,positive
531528178,"Same here, using anaconda3 in Windows 10. GPU is 1080Ti, manually installed tk and tensorflow-gpu(1.14) as instructed in Install.md",anaconda ti manually instructed,issue,negative,neutral,neutral,neutral,neutral,neutral
531470629,There is a refactor of extract coming in the next few days. I suggest you wait for that and then let me know if the issue persists afterwards,extract coming next day suggest wait let know issue afterwards,issue,negative,neutral,neutral,neutral,neutral,neutral
531470411,"1) This is a cuDNN initialization error.
2) 

> An unexpected crash has occurred. Crash report written to '/home/andy/Projects/FaceSwap/faceswap/crash_report.2019.09.12.144903345346.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting",unexpected crash crash report written log must provide file seeking assistance please verify running latest version,issue,negative,positive,positive,positive,positive,positive
530957181,"Same error.

The error report is below:

```Setting Faceswap backend to NVIDIA
09/12/2019 14:48:56 INFO     Log level set to: INFO
Using TensorFlow backend.
09/12/2019 14:48:56 INFO     Model A Directory: /home/andy/Projects/FaceSwap/faceswap/data/li
09/12/2019 14:48:56 INFO     Model B Directory: /home/andy/Projects/FaceSwap/faceswap/data/trump
09/12/2019 14:48:56 INFO     Training data directory: /home/andy/Projects/FaceSwap/faceswap/model
09/12/2019 14:48:56 INFO     ===================================================
09/12/2019 14:48:56 INFO       Starting
09/12/2019 14:48:56 INFO       Using live preview
09/12/2019 14:48:56 INFO       Press 'ENTER' to save and quit
09/12/2019 14:48:56 INFO       Press 'S' to save model weights immediately
09/12/2019 14:48:56 INFO     ===================================================
09/12/2019 14:48:57 INFO     Loading data, this may take a while...
09/12/2019 14:48:57 INFO     Loading Model from Original plugin...
09/12/2019 14:48:57 WARNING  No existing state file found. Generating.
09/12/2019 14:48:57 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n
09/12/2019 14:48:57 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n
09/12/2019 14:48:57 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n
09/12/2019 14:48:58 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n
09/12/2019 14:48:58 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n
09/12/2019 14:48:58 INFO     Creating new 'original' model in folder: '/home/andy/Projects/FaceSwap/faceswap/model'
09/12/2019 14:48:59 WARNING  From /home/andy/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n
09/12/2019 14:48:59 INFO     Loading Trainer from Original plugin...
09/12/2019 14:48:59 INFO     Enabled TensorBoard Logging
2019-09-12 14:49:02.179225: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-09-12 14:49:02.191476: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
09/12/2019 14:49:02 CRITICAL Error caught! Exiting...
09/12/2019 14:49:02 ERROR    Caught exception in thread: 'training_0'
09/12/2019 14:49:03 ERROR    Got Exception on main handler:\nTraceback (most recent call last):\n File ""/home/andy/Projects/FaceSwap/faceswap/lib/cli.py"", line 128, in execute_script\n process.process()\n File ""/home/andy/Projects/FaceSwap/faceswap/scripts/train.py"", line 98, in process\n self.end_thread(thread, err)\n File ""/home/andy/Projects/FaceSwap/faceswap/scripts/train.py"", line 124, in end_thread\n thread.join()\n File ""/home/andy/Projects/FaceSwap/faceswap/lib/multithreading.py"", line 216, in join\n raise thread.err[1].with_traceback(thread.err[2])\n File ""/home/andy/Projects/FaceSwap/faceswap/lib/multithreading.py"", line 147, in run\n self._target(*self._args, **self._kwargs)\n File ""/home/andy/Projects/FaceSwap/faceswap/scripts/train.py"", line 149, in training\n raise err\n File ""/home/andy/Projects/FaceSwap/faceswap/scripts/train.py"", line 139, in training\n self.run_training_cycle(model, trainer)\n File ""/home/andy/Projects/FaceSwap/faceswap/scripts/train.py"", line 221, in run_training_cycle\n trainer.train_one_step(viewer, timelapse)\n File ""/home/andy/Projects/FaceSwap/faceswap/plugins/train/trainer/_base.py"", line 211, in train_one_step\n raise err\n File ""/home/andy/Projects/FaceSwap/faceswap/plugins/train/trainer/_base.py"", line 179, in train_one_step\n loss[side] = batcher.train_one_batch(do_preview)\n File ""/home/andy/Projects/FaceSwap/faceswap/plugins/train/trainer/_base.py"", line 275, in train_one_batch\n loss = self.model.predictors[self.side].train_on_batch(*batch)\n File ""/home/andy/.local/lib/python3.7/site-packages/keras/engine/training.py"", line 1217, in train_on_batch\n outputs = self.train_function(ins)\n File ""/home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2715, in __call__\n return self._call(inputs)\n File ""/home/andy/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py"", line 2675, in _call\n fetched = self._callable_fn(*array_vals)\n File ""/home/andy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1458, in __call__\n run_metadata_ptr)\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\n (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n	 [[{{node encoder/conv_0_conv2d/convolution}}]]\n	 [[loss/mul/_295]]\n (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n	 [[{{node encoder/conv_0_conv2d/convolution}}]]\n0 successful operations.\n0 derived errors ignored.
09/12/2019 14:49:03 CRITICAL An unexpected crash has occurred. Crash report written to '/home/andy/Projects/FaceSwap/faceswap/crash_report.2019.09.12.144903345346.log'. You MUST provide this file if seeking assistance. Please verify you are running the latest version of faceswap before reporting
```",error error report setting log level set model directory model directory training data directory starting live preview press save quit press save model immediately loading data may take loading model original warning state file found generating warning name please use warning name please use warning name please use warning name please use warning name please use new model folder warning name please use loading trainer original logging could create handle could create handle critical error caught error caught exception thread error got exception main handler recent call last file line file line thread err file line file line raise file line file line raise file line model trainer file line viewer file line raise file line loss side file line loss batch file line file line return file line fetched file line root error unknown get convolution algorithm probably initialize try looking see warning log message printed node unknown get convolution algorithm probably initialize try looking see warning log message printed node successful derived critical unexpected crash crash report written log must provide file seeking assistance please verify running latest version,issue,negative,positive,positive,positive,positive,positive
530206942,"Have you solved this problem? i meet the same problem. I only use tensorflow-gpu, the code dont run, must install tensorflow. when i train the model, gpu usage is less than %20 and i guess the code using cpu, but the log dont show using cpu. ",problem meet problem use code dont run must install train model usage le guess code log dont show,issue,negative,neutral,neutral,neutral,neutral,neutral
529237528,"Per feedback, I have added a tool to replicate the functionality. This simplifies the code-base but still allows a means of aligning a image dataset if absolutely desired.

![image](https://user-images.githubusercontent.com/3772434/64493895-a4c0f500-d24b-11e9-8054-f677947f00ae.png)
",per feedback added tool replicate functionality still image absolutely desired image,issue,negative,positive,positive,positive,positive,positive
529078971,"I found this why. It is that opencv version is 3.4.1. So I upgrade opencv version, from 3.4.1 to 3.4.5. Then I resolved this isuue.",found version upgrade version resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
528845876,These sorts of questions are best asked on the support forum or on the discord server. GitHub is typically used for bug reporting and testing features.,best support forum discord server typically used bug testing,issue,positive,positive,positive,positive,positive,positive
528815027,"Thanks @torzdf Can you explain how the predicted face is wrapped and swapped with the source face and how mask is formed
 ",thanks explain face wrapped source face mask formed,issue,negative,positive,positive,positive,positive,positive
528253247,"Can someone explain how to train the model IAE step by step
currently i am not able to interpretate  how faceswap.py extract works which functions it calls etc
",someone explain train model step step currently able extract work,issue,negative,positive,positive,positive,positive,positive
528185840,"How can i train the IAE model can you @torzdf, provide me any scripts for data preparation and training. And also how is the predicted face and mask is merged on the destination face
 ",train model provide data preparation training also face mask destination face,issue,negative,neutral,neutral,neutral,neutral,neutral
528132362,"Whilst we maintain a Docker build, none of the devs actively use or support it. We welcome PRs to fix any issues though.",whilst maintain docker build none actively use support welcome fix though,issue,negative,positive,positive,positive,positive,positive
528075188,"Hi all,
Yes I think that one shot learning with GAN, would be useful in understanding, Especially with the recent GAO faceswap app.
Best regards, Haaris Siddiqie 

    On Wednesday, 4 September 2019, 15:50:50 BST, ak9250 <notifications@github.com> wrote:  
 
 
recent one/few shot approaches seems promising for swapping faces into video from a single image such as https://github.com/shaoanlu/fewshot-face-translation-GAN
can ideas from here to used to improve FS or look into one model to swap all faces instead of training two face pairs, possibly a long term project

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub, or mute the thread.
  ",hi yes think one shot learning gan would useful understanding especially recent best ak wrote recent shot promising swapping video single image used improve look one model swap instead training two face possibly long term project thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
528005193,"The sorting part is working now.
Thanks for your quick contribution.",part working thanks quick contribution,issue,negative,positive,positive,positive,positive,positive
528004195,No worries... so all working? Please close if resolved. Thanks,working please close resolved thanks,issue,positive,positive,positive,positive,positive,positive
528003089,"Yes I am running on a VM in the cloud.
Now it works after clicking ""Update Faceswap...""
It downloaded some plugin... I don't know why it didn't install that plugin in the first time.

Sorry for the ""bug report""",yes running cloud work update know install first time sorry bug report,issue,negative,negative,negative,negative,negative,negative
527972384,"Instead of completely removing this functionality, what do you think about moving it out to separate script?",instead completely removing functionality think moving separate script,issue,negative,positive,neutral,neutral,positive,positive
527733337,Not much feedback one way or another from other folks. Leave up for comments for two more days and then merge?,much feedback one way another leave two day merge,issue,negative,positive,positive,positive,positive,positive
527714778,I'm relatively new to python.  I'll see what I can do.,relatively new python see,issue,negative,positive,positive,positive,positive,positive
527622790,"I made the BackgroundGenerator use multiple threads.
Trainingdata currently uses 2 threads per side.
This brought up my performance from ~80 img/s for both sides to ~ 113.

Also fixed an error in `MultiThread` where `check_and_raise_error` would have failed if anything else except the first thread raised an exception.",made use multiple currently per side brought performance side also fixed error would anything else except first thread raised exception,issue,negative,positive,neutral,neutral,positive,positive
527589876,"Feel free to raise a PR for checking of cuDNN on Fedora.

Unfortunately different OSes have it in different places, so it is hard to capture them all",feel free raise unfortunately different different hard capture,issue,negative,positive,neutral,neutral,positive,positive
527391232,"One small bit of feedback.... It's annoying that we have to insert `pylint:disable=no-member` for cv2, but linter complains otherwise :(

My preference is to keep it on the line which triggers the linter. Putting it at the top of the function means that it will ignore any actual ""no-member"" errors that occur.",one small bit feedback annoying insert linter otherwise preference keep line linter top function ignore actual occur,issue,negative,negative,negative,negative,negative,negative
527248770,"This is a GUI bug which I thought I had squashed. Make sure you are running with the latest code.

Either way, it won't impact training, just the analysis/graph display.",bug thought make sure running latest code either way wo impact training display,issue,negative,positive,positive,positive,positive,positive
526926501,"```09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       initialize                DEBUG    OS is not macOS. Using pynvml
09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       get_device_count          DEBUG    GPU Device count: 1
09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       get_active_devices        DEBUG    Active GPU Devices: [0]
09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       get_handles               DEBUG    GPU Handles found: 1
09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       get_free                  DEBUG    GPU VRAM free: [1750.859375]
09/01/2019 22:03:29 Aligner.run     MainThread      gpu_stats       get_card_most_free        DEBUG    Active GPU Card with most free VRAM: {'card_id': 0, 'device': 'GeForce GTX 1050', 'free': 1750.859375, 'total': 2048.0}
09/01/2019 22:03:29 Aligner.run     MainThread      _base           get_vram_free             VERBOSE  Using device GeForce GTX 1050 with 1750MB free of 2048MB
09/01/2019 22:03:29 Aligner.run     MainThread      fan             initialize                VERBOSE  Reserving 2240MB for face alignments
09/01/2019 22:03:29 Aligner.run     MainThread      fan             load_graph                VERBOSE  Initializing Face Alignment Network model...
09/01/2019 22:03:29 Aligner.run     MainThread      deprecation_wrapper __getattr__               WARNING  From C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:206: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n
09/01/2019 22:03:29 Aligner.run     MainThread      deprecation_wrapper __getattr__               WARNING  From C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:207: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n
09/01/2019 22:03:33 Aligner.run     MainThread      deprecation_wrapper __getattr__               WARNING  From C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:219: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n
09/01/2019 22:03:33 Aligner.run     MainThread      deprecation_wrapper __getattr__               WARNING  From C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:221: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n
09/01/2019 22:03:34 Aligner.run     MainThread      fan             set_session               DEBUG    Using GPU
09/01/2019 22:03:42 Aligner.run     MainThread      _base           run                       ERROR    Caught exception in child process: 9144
09/01/2019 22:03:42 Aligner.run     MainThread      _base           run                       ERROR    Traceback:
Traceback (most recent call last):
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1356, in _do_call
    return fn(*args)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node fa/convolution}}]]
	 [[fa/transpose_647/_3]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node fa/convolution}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 112, in run
    self.align(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 127, in align
    self.initialize(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 47, in initialize
    raise err
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 41, in initialize
    self.model = FAN(self.model_path, ratio=tf_ratio)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 199, in __init__
    self.session = self.set_session(ratio)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 227, in set_session
    session.run(self.output, feed_dict={self.input: placeholder})
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 950, in run
    run_metadata_ptr)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1350, in _do_run
    run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
	 [[fa/transpose_647/_3]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'fa/convolution':
  File ""<string>"", line 1, in <module>
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 118, in _main
    return self._bootstrap()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 258, in _bootstrap
    self.run()
  File ""C:\Users\ppepp\faceswap\lib\multithreading.py"", line 362, in run
    super().run()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 112, in run
    self.align(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 127, in align
    self.initialize(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 41, in initialize
    self.model = FAN(self.model_path, ratio=tf_ratio)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 196, in __init__
    self.graph = self.load_graph()
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 211, in load_graph
    self.tf.import_graph_def(graph_def, name=""fa"")
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 443, in import_graph_def
    _ProcessNewOps(graph)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 236, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3641, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
Traceback (most recent call last):
  File ""C:\Users\ppepp\faceswap\lib\cli.py"", line 125, in execute_script
    process.process()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 62, in process
    self.run_extraction()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 189, in run_extraction
    self.extractor.launch()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 178, in launch
    self.launch_aligner()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 206, in launch_aligner
    raise ValueError(""Error initializing Aligner"")
ValueError: Error initializing Aligner

============ System Information ============
encoding:            cp1252
git_branch:          master
git_commits:         10c5c7e Double number of log lines in crash report
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: GeForce GTX 1050
gpu_devices_active:  GPU_0
gpu_driver:          436.15
gpu_vram:            GPU_0: 2048MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.17763-SP0
os_release:          10
py_command:          C:\Users\ppepp\faceswap\faceswap.py extract -i C:/Users/ppepp/Desktop/test.mp4 -o C:/Users/ppepp/Downloads/test --serializer json -D s3fd -A fan -nm none -min 0 -l 0.4 -bt 0.0 -een 1 -sz 256 -si 0 -sp -L INFO -gui
py_conda_version:    conda 4.7.11
py_implementation:   CPython
py_version:          3.6.9
py_virtual_env:      True
sys_cores:           4
sys_processor:       Intel64 Family 6 Model 158 Stepping 11, GenuineIntel
sys_ram:             Total: 8143MB, Available: 3235MB, Used: 4908MB, Free: 3235MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cloudpickle==1.2.1
cycler==0.10.0
cytoolz==0.10.0
dask==2.3.0
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mkl-fft==1.0.14
mkl-random==1.0.2
mkl-service==2.0.2
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
protobuf==3.8.0
psutil==5.6.3
pyparsing==2.4.2
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.2
PyWavelets==1.0.3
pywin32==223
PyYAML==5.1.2
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.1
six==1.12.0
tensorboard==1.14.0
tensorflow==1.14.0
tensorflow-estimator==1.14.0
termcolor==1.1.0
toolz==0.10.0
toposort==1.5
tornado==6.0.3
tqdm==4.32.1
Werkzeug==0.15.5
wincertstore==0.2
wrapt==1.11.2

============== Conda Packages ==============
# packages in environment at C:\Users\ppepp\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.1                    py36_0  
astor                     0.8.0                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.5.15                     1  
certifi                   2019.6.16                py36_1  
cloudpickle               1.2.1                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.0                cuda10.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.10.0           py36he774522_0  
dask-core                 2.3.0                      py_0  
decorator                 4.4.0                    py36_1  
fastcluster               1.1.25          py36h830ac7b_1000    conda-forge
ffmpeg                    4.2                  h6538335_0    conda-forge
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.5.0                    py36_0  
imageio-ffmpeg            0.3.0                      py_0    conda-forge
intel-openmp              2019.4                      245  
joblib                    0.13.2                   py36_0  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py36ha925a31_0  
libmklml                  2019.0.5                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.8.0                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.1.1                    py36_0  
matplotlib                2.2.2            py36had4c4a9_2  
mkl                       2019.4                      245  
mkl-service               2.0.2            py36he774522_0  
mkl_fft                   1.0.14           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
networkx                  2.3                        py_0  
numpy                     1.16.2           py36h19fb1c0_0  
numpy-base                1.16.2           py36hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1c               he774522_1  
pathlib                   1.0.1                    py36_1  
pillow                    6.1.0            py36hdc69c19_0  
pip                       19.2.2                   py36_0  
protobuf                  3.8.0            py36h33f27b4_0  
psutil                    5.6.3            py36he774522_0  
pyparsing                 2.4.2                      py_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.9                h5500b2f_0  
python-dateutil           2.8.0                    py36_0  
pytz                      2019.2                     py_0  
pywavelets                1.0.3            py36h8c2d366_1  
pywin32                   223              py36hfa6e2cd_1  
pyyaml                    5.1.2            py36he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py36ha925a31_0  
scikit-learn              0.21.2           py36h6288b17_0  
scipy                     1.3.1            py36h29ff71c_0  
setuptools                41.0.1                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.29.0               he774522_0  
tensorboard               1.14.0           py36he3c9ec2_0  
tensorflow                1.14.0          gpu_py36h305fd99_0  
tensorflow-base           1.14.0          gpu_py36h55fc52a_0  
tensorflow-estimator      1.14.0                     py_0  
tensorflow-gpu            1.14.0               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.10.0                     py_0  
toposort                  1.5                        py_3    conda-forge
tornado                   6.0.3            py36he774522_0  
tqdm                      4.32.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_4  
werkzeug                  0.15.5                     py_0  
wheel                     0.33.4                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
wrapt                     1.11.2           py36he774522_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709

[detect.s3fd_amd]
confidence:               50
batch-size:               8

[detect.s3fd]
confidence:               50

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
font:                     default
font_size:                9

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur:                False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```",initialize o device count active found free active card free verbose device free fan initialize verbose face fan verbose face alignment network model warning name please use warning name please use warning name please use warning name please use fan run error caught exception child process run error recent call last file line return file line file line root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node unknown get convolution algorithm probably initialize try looking see warning log message printed node successful derived handling exception another exception recent call last file line run file line align file line initialize raise err file line initialize fan file line ratio file line file line run file line file line file line raise type message root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node defined unknown get convolution algorithm probably initialize try looking see warning log message printed node defined successful derived original stack trace file string line module file line file line return file line file line run super file line run file line run file line align file line initialize fan file line file line fa file line return file line graph file line file line self file line self file line ret operation self file line recent call last file line file line process file line file line launch file line raise error aligner error aligner system information master double number log crash report global version found check global version found check extract fan none true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast markdown pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type radius erosion method amount radius threshold container preset medium tune none profile auto level auto loop false format false format false optimize false true confidence confidence confidence global false tab extract font default global coverage none false false false false false true mae false true architecture false false false true false,issue,positive,negative,neutral,neutral,negative,negative
526919702,"Ok. A couple of things to try. Firstly update to latest code as I have increased the number of loglines output to the crash report (the information above doesn't show me where the point of failure is).

1) Try singleprocess mode (under settings in the extract tab)
2) Completely remove Faceswap and re-install (the Cuda install may have been a problem at install time). You should follow these steps to make sure that the Conda environment is clean prior to re-installing:
https://faceswap.dev/forum/app.php/faqpage#f1r1",couple try firstly update latest code number output crash report information show point failure try mode extract tab completely remove install may problem install time follow make sure environment clean prior,issue,negative,positive,positive,positive,positive,positive
526918894,"```Still recieving the same error after uninstalling CUDA
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1350, in _do_run
    run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
	 [[fa/transpose_647/_3]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'fa/convolution':
  File ""<string>"", line 1, in <module>
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 118, in _main
    return self._bootstrap()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 258, in _bootstrap
    self.run()
  File ""C:\Users\ppepp\faceswap\lib\multithreading.py"", line 362, in run
    super().run()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 112, in run
    self.align(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 127, in align
    self.initialize(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 41, in initialize
    self.model = FAN(self.model_path, ratio=tf_ratio)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 196, in __init__
    self.graph = self.load_graph()
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 211, in load_graph
    self.tf.import_graph_def(graph_def, name=""fa"")
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 443, in import_graph_def
    _ProcessNewOps(graph)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 236, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3641, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
Traceback (most recent call last):
  File ""C:\Users\ppepp\faceswap\lib\cli.py"", line 125, in execute_script
    process.process()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 62, in process
    self.run_extraction()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 189, in run_extraction
    self.extractor.launch()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 178, in launch
    self.launch_aligner()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 206, in launch_aligner
    raise ValueError(""Error initializing Aligner"")
ValueError: Error initializing Aligner

============ System Information ============
encoding:            cp1252
git_branch:          master
git_commits:         5bf54d9 Add configs and state file to crash report
gpu_cuda:            No global version found. Check Conda packages for Conda Cuda
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: GeForce GTX 1050
gpu_devices_active:  GPU_0
gpu_driver:          436.15
gpu_vram:            GPU_0: 2048MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.17763-SP0
os_release:          10
py_command:          C:\Users\ppepp\faceswap\faceswap.py extract -i C:/Users/ppepp/Desktop/test.mp4 -o C:/Users/ppepp/Downloads/test --serializer json -D s3fd -A fan -nm none -min 0 -l 0.4 -bt 0.0 -een 1 -sz 256 -si 0 -L INFO -gui
py_conda_version:    conda 4.7.11
py_implementation:   CPython
py_version:          3.6.9
py_virtual_env:      True
sys_cores:           4
sys_processor:       Intel64 Family 6 Model 158 Stepping 11, GenuineIntel
sys_ram:             Total: 8143MB, Available: 3699MB, Used: 4444MB, Free: 3699MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cloudpickle==1.2.1
cycler==0.10.0
cytoolz==0.10.0
dask==2.3.0
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mkl-fft==1.0.14
mkl-random==1.0.2
mkl-service==2.0.2
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
protobuf==3.8.0
psutil==5.6.3
pyparsing==2.4.2
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.2
PyWavelets==1.0.3
pywin32==223
PyYAML==5.1.2
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.1
six==1.12.0
tensorboard==1.14.0
tensorflow==1.14.0
tensorflow-estimator==1.14.0
termcolor==1.1.0
toolz==0.10.0
toposort==1.5
tornado==6.0.3
tqdm==4.32.1
Werkzeug==0.15.5
wincertstore==0.2
wrapt==1.11.2

============== Conda Packages ==============
# packages in environment at C:\Users\ppepp\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.1                    py36_0  
astor                     0.8.0                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.5.15                     1  
certifi                   2019.6.16                py36_1  
cloudpickle               1.2.1                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.0                cuda10.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.10.0           py36he774522_0  
dask-core                 2.3.0                      py_0  
decorator                 4.4.0                    py36_1  
fastcluster               1.1.25          py36h830ac7b_1000    conda-forge
ffmpeg                    4.2                  h6538335_0    conda-forge
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.5.0                    py36_0  
imageio-ffmpeg            0.3.0                      py_0    conda-forge
intel-openmp              2019.4                      245  
joblib                    0.13.2                   py36_0  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py36ha925a31_0  
libmklml                  2019.0.5                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.8.0                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.1.1                    py36_0  
matplotlib                2.2.2            py36had4c4a9_2  
mkl                       2019.4                      245  
mkl-service               2.0.2            py36he774522_0  
mkl_fft                   1.0.14           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
networkx                  2.3                        py_0  
numpy                     1.16.2           py36h19fb1c0_0  
numpy-base                1.16.2           py36hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1c               he774522_1  
pathlib                   1.0.1                    py36_1  
pillow                    6.1.0            py36hdc69c19_0  
pip                       19.2.2                   py36_0  
protobuf                  3.8.0            py36h33f27b4_0  
psutil                    5.6.3            py36he774522_0  
pyparsing                 2.4.2                      py_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.9                h5500b2f_0  
python-dateutil           2.8.0                    py36_0  
pytz                      2019.2                     py_0  
pywavelets                1.0.3            py36h8c2d366_1  
pywin32                   223              py36hfa6e2cd_1  
pyyaml                    5.1.2            py36he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py36ha925a31_0  
scikit-learn              0.21.2           py36h6288b17_0  
scipy                     1.3.1            py36h29ff71c_0  
setuptools                41.0.1                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.29.0               he774522_0  
tensorboard               1.14.0           py36he3c9ec2_0  
tensorflow                1.14.0          gpu_py36h305fd99_0  
tensorflow-base           1.14.0          gpu_py36h55fc52a_0  
tensorflow-estimator      1.14.0                     py_0  
tensorflow-gpu            1.14.0               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.10.0                     py_0  
toposort                  1.5                        py_3    conda-forge
tornado                   6.0.3            py36he774522_0  
tqdm                      4.32.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_4  
werkzeug                  0.15.5                     py_0  
wheel                     0.33.4                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
wrapt                     1.11.2           py36he774522_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709

[detect.s3fd_amd]
confidence:               50
batch-size:               8

[detect.s3fd]
confidence:               50

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
font:                     default
font_size:                9

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur:                False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```",still error file line file line raise type message root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node defined unknown get convolution algorithm probably initialize try looking see warning log message printed node defined successful derived original stack trace file string line module file line file line return file line file line run super file line run file line run file line align file line initialize fan file line file line fa file line return file line graph file line file line self file line self file line ret operation self file line recent call last file line file line process file line file line launch file line raise error aligner error aligner system information master add state file crash report global version found check global version found check extract fan none true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast markdown pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type radius erosion method amount radius threshold container preset medium tune none profile auto level auto loop false format false format false optimize false true confidence confidence confidence global false tab extract font default global coverage none false false false false false true mae false true architecture false false false true false,issue,negative,negative,neutral,neutral,negative,negative
526911935,Remove your system Cuda install. It is most likely conflicting with Conda Cuda.,remove system install likely conflicting,issue,negative,neutral,neutral,neutral,neutral,neutral
526876813,"```
feed_dict_tensor, options, run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1350, in _do_run
    run_metadata)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
	 [[fa/transpose_647/_3]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node fa/convolution (defined at C:\Users\ppepp\faceswap\plugins\extract\align\fan.py:211) ]]
0 successful operations.
0 derived errors ignored.

Original stack trace for 'fa/convolution':
  File ""<string>"", line 1, in <module>
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\spawn.py"", line 118, in _main
    return self._bootstrap()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 258, in _bootstrap
    self.run()
  File ""C:\Users\ppepp\faceswap\lib\multithreading.py"", line 362, in run
    super().run()
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 112, in run
    self.align(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\_base.py"", line 127, in align
    self.initialize(*args, **kwargs)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 41, in initialize
    self.model = FAN(self.model_path, ratio=tf_ratio)
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 196, in __init__
    self.graph = self.load_graph()
  File ""C:\Users\ppepp\faceswap\plugins\extract\align\fan.py"", line 211, in load_graph
    self.tf.import_graph_def(graph_def, name=""fa"")
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 443, in import_graph_def
    _ProcessNewOps(graph)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\importer.py"", line 236, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3751, in <listcomp>
    for c_op in c_api_util.new_tf_operations(self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 3641, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File ""C:\Users\ppepp\MiniConda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
Traceback (most recent call last):
  File ""C:\Users\ppepp\faceswap\lib\cli.py"", line 125, in execute_script
    process.process()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 62, in process
    self.run_extraction()
  File ""C:\Users\ppepp\faceswap\scripts\extract.py"", line 189, in run_extraction
    self.extractor.launch()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 178, in launch
    self.launch_aligner()
  File ""C:\Users\ppepp\faceswap\plugins\extract\pipeline.py"", line 206, in launch_aligner
    raise ValueError(""Error initializing Aligner"")
ValueError: Error initializing Aligner

============ System Information ============
encoding:            cp1252
git_branch:          master
git_commits:         5bf54d9 Add configs and state file to crash report
gpu_cuda:            10.1
gpu_cudnn:           No global version found. Check Conda packages for Conda cuDNN
gpu_devices:         GPU_0: GeForce GTX 1050
gpu_devices_active:  GPU_0
gpu_driver:          436.15
gpu_vram:            GPU_0: 2048MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.17763-SP0
os_release:          10
py_command:          C:\Users\ppepp\faceswap\faceswap.py extract -i C:/Users/ppepp/Desktop/test.mp4 -o C:/Users/ppepp/Downloads/test --serializer json -D s3fd -A fan -nm none -min 0 -l 0.4 -bt 0.0 -een 1 -sz 256 -si 0 -L INFO -gui
py_conda_version:    conda 4.7.11
py_implementation:   CPython
py_version:          3.6.9
py_virtual_env:      True
sys_cores:           4
sys_processor:       Intel64 Family 6 Model 158 Stepping 11, GenuineIntel
sys_ram:             Total: 8143MB, Available: 3968MB, Used: 4175MB, Free: 3968MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cloudpickle==1.2.1
cycler==0.10.0
cytoolz==0.10.0
dask==2.3.0
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mkl-fft==1.0.14
mkl-random==1.0.2
mkl-service==2.0.2
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
protobuf==3.8.0
psutil==5.6.3
pyparsing==2.4.2
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.2
PyWavelets==1.0.3
pywin32==223
PyYAML==5.1.2
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.1
six==1.12.0
tensorboard==1.14.0
tensorflow==1.14.0
tensorflow-estimator==1.14.0
termcolor==1.1.0
toolz==0.10.0
toposort==1.5
tornado==6.0.3
tqdm==4.32.1
Werkzeug==0.15.5
wincertstore==0.2
wrapt==1.11.2

============== Conda Packages ==============
# packages in environment at C:\Users\ppepp\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.1                    py36_0  
astor                     0.8.0                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.5.15                     1  
certifi                   2019.6.16                py36_1  
cloudpickle               1.2.1                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.0                cuda10.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.10.0           py36he774522_0  
dask-core                 2.3.0                      py_0  
decorator                 4.4.0                    py36_1  
fastcluster               1.1.25          py36h830ac7b_1000    conda-forge
ffmpeg                    4.2                  h6538335_0    conda-forge
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.5.0                    py36_0  
imageio-ffmpeg            0.3.0                      py_0    conda-forge
intel-openmp              2019.4                      245  
joblib                    0.13.2                   py36_0  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py36ha925a31_0  
libmklml                  2019.0.5                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.8.0                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.1.1                    py36_0  
matplotlib                2.2.2            py36had4c4a9_2  
mkl                       2019.4                      245  
mkl-service               2.0.2            py36he774522_0  
mkl_fft                   1.0.14           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
networkx                  2.3                        py_0  
numpy                     1.16.2           py36h19fb1c0_0  
numpy-base                1.16.2           py36hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1c               he774522_1  
pathlib                   1.0.1                    py36_1  
pillow                    6.1.0            py36hdc69c19_0  
pip                       19.2.2                   py36_0  
protobuf                  3.8.0            py36h33f27b4_0  
psutil                    5.6.3            py36he774522_0  
pyparsing                 2.4.2                      py_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.9                h5500b2f_0  
python-dateutil           2.8.0                    py36_0  
pytz                      2019.2                     py_0  
pywavelets                1.0.3            py36h8c2d366_1  
pywin32                   223              py36hfa6e2cd_1  
pyyaml                    5.1.2            py36he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py36ha925a31_0  
scikit-learn              0.21.2           py36h6288b17_0  
scipy                     1.3.1            py36h29ff71c_0  
setuptools                41.0.1                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.29.0               he774522_0  
tensorboard               1.14.0           py36he3c9ec2_0  
tensorflow                1.14.0          gpu_py36h305fd99_0  
tensorflow-base           1.14.0          gpu_py36h55fc52a_0  
tensorflow-estimator      1.14.0                     py_0  
tensorflow-gpu            1.14.0               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.10.0                     py_0  
toposort                  1.5                        py_3    conda-forge
tornado                   6.0.3            py36he774522_0  
tqdm                      4.32.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_4  
werkzeug                  0.15.5                     py_0  
wheel                     0.33.4                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
wrapt                     1.11.2           py36he774522_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  

================= Configs ==================
--------- .faceswap ---------
backend:                  nvidia

--------- convert.ini ---------

[color.color_transfer]
clip:                     True
preserve_paper:           True

[color.manual_balance]
colorspace:               HSV
balance_1:                0.0
balance_2:                0.0
balance_3:                0.0
contrast:                 0.0
brightness:               0.0

[color.match_hist]
threshold:                99.0

[mask.box_blend]
type:                     gaussian
distance:                 11.0
radius:                   5.0
passes:                   1

[mask.mask_blend]
type:                     normalized
radius:                   3.0
passes:                   4
erosion:                  0.0

[scaling.sharpen]
method:                   unsharp_mask
amount:                   150
radius:                   0.3
threshold:                5.0

[writer.ffmpeg]
container:                mp4
codec:                    libx264
crf:                      23
preset:                   medium
tune:                     none
profile:                  auto
level:                    auto

[writer.gif]
fps:                      25
loop:                     0
palettesize:              256
subrectangles:            False

[writer.opencv]
format:                   png
draw_transparent:         False
jpg_quality:              75
png_compress_level:       3

[writer.pillow]
format:                   png
draw_transparent:         False
optimize:                 False
gif_interlace:            True
jpg_quality:              75
png_compress_level:       3
tif_compression:          tiff_deflate

--------- extract.ini ---------

[detect.cv2_dnn]
confidence:               50

[detect.mtcnn]
minsize:                  20
threshold_1:              0.6
threshold_2:              0.7
threshold_3:              0.7
scalefactor:              0.709

[detect.s3fd_amd]
confidence:               50
batch-size:               8

[detect.s3fd]
confidence:               50

--------- gui.ini ---------

[global]
fullscreen:               False
tab:                      extract
options_panel_width:      30
console_panel_height:     20
font:                     default
font_size:                9

--------- train.ini ---------

[global]
coverage:                 68.75
mask_type:                none
mask_blur:                False
icnr_init:                False
conv_aware_init:          False
subpixel_upscaling:       False
reflect_padding:          False
penalized_mask_loss:      True
loss_function:            mae
learning_rate:            5e-05

[model.dfl_h128]
lowmem:                   False

[model.dfl_sae]
input_size:               128
clipnorm:                 True
architecture:             df
autoencoder_dims:         0
encoder_dims:             42
decoder_dims:             21
multiscale_decoder:       False

[model.original]
lowmem:                   False

[model.realface]
input_size:               64
output_size:              128
dense_nodes:              1536
complexity_encoder:       128
complexity_decoder:       512

[model.unbalanced]
input_size:               128
lowmem:                   False
clipnorm:                 True
nodes:                    1024
complexity_encoder:       128
complexity_decoder_a:     384
complexity_decoder_b:     512

[model.villain]
lowmem:                   False

[trainer.original]
preview_images:           14
zoom_amount:              5
rotation_range:           10
shift_range:              5
flip_chance:              50
color_lightness:          30
color_ab:                 8
color_clahe_chance:       50
color_clahe_max_size:     4
```",file line file line raise type message root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node defined unknown get convolution algorithm probably initialize try looking see warning log message printed node defined successful derived original stack trace file string line module file line file line return file line file line run super file line run file line run file line align file line initialize fan file line file line fa file line return file line graph file line file line self file line self file line ret operation self file line recent call last file line file line process file line file line launch file line raise error aligner error aligner system information master add state file crash report global version found check extract fan none true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast markdown pillow pip python sip six tornado wheel clip true true contrast brightness threshold type distance radius type radius erosion method amount radius threshold container preset medium tune none profile auto level auto loop false format false format false optimize false true confidence confidence confidence global false tab extract font default global coverage none false false false false false true mae false true architecture false false false true false,issue,positive,negative,neutral,neutral,negative,negative
526474318,Other PR incorporates better method and have implemented a new method for adding masks to encoder. Cleaning this up and closing,better method new method cleaning,issue,negative,positive,positive,positive,positive,positive
526451372,"Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:













* In the file [`tools/lib_alignments/annotate.py`](https://github.com/deepfakes/faceswap/blob/e0b2cc399c531486b28d9e06a29fd8cb04c4fce8/tools/lib_alignments/annotate.py):

> [Line 63:1](https://github.com/deepfakes/faceswap/blob/e0b2cc399c531486b28d9e06a29fd8cb04c4fce8/tools/lib_alignments/annotate.py#L63): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace
> [Line 107:1](https://github.com/deepfakes/faceswap/blob/e0b2cc399c531486b28d9e06a29fd8cb04c4fce8/tools/lib_alignments/annotate.py#L107): [W293](https://duckduckgo.com/?q=pep8%20W293) blank line contains whitespace











##### Comment last updated at 2019-09-17 18:59:01 UTC",hello thanks checked touched pep found file line blank line line blank line comment last,issue,negative,positive,neutral,neutral,positive,positive
526297788,This cycles through all the parameter combos and the config options too ? I had a long debugging process especially on all the config options.,parameter long process especially,issue,negative,negative,neutral,neutral,negative,negative
525672992,"Thanks for this.....
We *may* need to rework it a little though, Basically, how would it work for IAE (for example).
",thanks may need rework little though basically would work example,issue,negative,positive,neutral,neutral,positive,positive
525564774,"No, this is not possible.  The AI has to train on both to be able to swap them.",possible ai train able swap,issue,negative,positive,positive,positive,positive,positive
524892714,"(I swear I'm not like super-stalking this page since I'm replying within just a few minutes. Just decided to check this morning haha.)

I don't think this error is related to the convolution aware initialization; the amount of available memory isn't the issue, and turning CA init off will still give you this error. It's related to how faceswap uses the protocol buffer. 

For anyone else trying to do this, I found setting both ddim/edim to 60 worked by slowly titrating down the settings without CA init until it was under the protobuf limit, deleting the model, then rerunning it with CA. Obviously this isn't the full quality model, but it's better than the default settings.

And that's actually kind of what I was doing. I noted that the documentation said it could only use 1 GPU, and to initialize the model with 1 GPU when doing it. So instead, I used a 96 core CPU, 640GB RAM server to do the init, saved the model, and swapped over to GPUs (I used CPUs because it takes approximately 1 hour at that size, and 1 GPU does not have enough VRAM to set up the model.)",swear like page since within decided check morning think error related convolution aware amount available memory issue turning ca still give error related protocol buffer anyone else trying found setting worked slowly without ca limit model ca obviously full quality model better default actually kind noted documentation said could use initialize model instead used core ram server saved model used approximately hour size enough set model,issue,positive,positive,positive,positive,positive,positive
524887090,"I would suggest starting CA Init with one GPU until the initialization compiles, let it run until the first model save, stop it, and then restart training the saved model with multi_gpu. The CA inititialization is the only issue here, so once weights are saved you can multi_gpu to your heart's content.

By the way, you could also just not use CA Init. You might like it, but reading directly from the author's paper, it gave less than a 0.5% to 1.0% improvement ( and I have to assume that those were the best examples presented and/or within the margin of error. )",would suggest starting ca one let run first model save stop restart training saved model ca issue saved heart content way could also use ca might like reading directly author paper gave le improvement assume best within margin error,issue,positive,positive,positive,positive,positive,positive
524623777,"Yup. Its only still here as template for the changes i did for FAN-keras, but i am going to close it.",still template going close,issue,negative,neutral,neutral,neutral,neutral,neutral
523739772,This page is only for bugs and issues with the code.  Please see https://faceswap.dev/forum/ for questions like this.,page code please see like,issue,positive,neutral,neutral,neutral,neutral,neutral
523367759,"No, you need to train the model for the two people you want to swap.

https://github.com/deepfakes/faceswap/blob/master/USAGE.md",need train model two people want swap,issue,negative,neutral,neutral,neutral,neutral,neutral
523367127,"> That is pretty much exactly what this repo is.
> 
> https://faceswap.dev

the model is  a general model which i can use to  convert  trump’s face to anyone‘s face  which i input  without trainning a model using Two specific people",pretty much exactly model general model use convert trump face anyone face input without model two specific people,issue,negative,positive,positive,positive,positive,positive
522915366,"This usage question is covered by our extract guide here:
https://faceswap.dev/forum/viewtopic.php?f=5&t=27",usage question covered extract guide,issue,negative,neutral,neutral,neutral,neutral,neutral
522829999,how do you know which face to extract and ignore others?,know face extract ignore,issue,negative,neutral,neutral,neutral,neutral,neutral
522378492,"cool, yep, makes sense. thank you. yeah i just accidentally chose to back it with AMD config (during 'python setup.py'). this machine had plaid l pre-installed because of the ML-in-a-Box template (Paperspace machine) that i was working from. currently they're nVidia. ",cool yep sense thank yeah accidentally chose back machine plaid template machine working currently,issue,positive,positive,positive,positive,positive,positive
522367253,"Just to be clear, plaidml shouldn't be uninstalled from inside the environment (for AMD cards) otherwise you'll be forced into CPU mode.

For Nvidia cards, plaidml shouldn't be installed anyway",clear uninstalled inside environment otherwise forced mode anyway,issue,negative,negative,neutral,neutral,negative,negative
522353949,"Just FYI we just now ran into this same issue on a Paperspace Ubuntu 18.04 machine running nVidia Quadro P5000 and ML-in-a-Box template, while using conda virtual env, so we ran `pip uninstall plaidml plaidml-keras`, and it finally worked. Thanks for the help! :)",ran issue machine running template virtual ran pip finally worked thanks help,issue,positive,positive,neutral,neutral,positive,positive
522251181,Hey @randomkpopfan SAE model is now available in master!,hey model available master,issue,negative,positive,positive,positive,positive,positive
520604276,"I *think* this happens because TF 1.13.1 uses more VRAM, so the amount we allocate for s3fd is not enough. I use TF 1.12 and do not get this issue.

I will probably up the allocation for S3FD at some point, but in the meantime, just use single process.",think amount allocate enough use get issue probably allocation point use single process,issue,negative,negative,neutral,neutral,negative,negative
520401595,Any news regarding this issue ? I'm facing the same (but the 'Single Process' workaround worked),news regarding issue facing process worked,issue,negative,neutral,neutral,neutral,neutral,neutral
520295193,"Please read the error messages.  It tells you the problem right here: Status: CUDA driver version is insufficient for CUDA runtime version

Update your driver.",please read error problem right status driver version insufficient version update driver,issue,negative,positive,positive,positive,positive,positive
520160930,"This is a known occasional issue with Windows. Enable ""Disable Monitor"" option.",known occasional issue enable disable monitor option,issue,negative,neutral,neutral,neutral,neutral,neutral
520111353,"- Added rotation support for s3fd-amd.
- Changed detector._base.compile_detection_image method to return the used padding if pad_to parameter is given,
- Removed the -r deprecation message.

From my point of view it should be good to go now.",added rotation support method return used padding parameter given removed deprecation message point view good go,issue,positive,positive,positive,positive,positive,positive
519748830,"Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:























































* In the file [`plugins/extract/pipeline.py`](https://github.com/deepfakes/faceswap/blob/e4bcb6d8d4266575ff3afd0916e58e7187195f31/plugins/extract/pipeline.py):

> [Line 377:12](https://github.com/deepfakes/faceswap/blob/e4bcb6d8d4266575ff3afd0916e58e7187195f31/plugins/extract/pipeline.py#L377): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace
> [Line 383:13](https://github.com/deepfakes/faceswap/blob/e4bcb6d8d4266575ff3afd0916e58e7187195f31/plugins/extract/pipeline.py#L383): [E129](https://duckduckgo.com/?q=pep8%20E129) visually indented line with same indent as next logical line

























* In the file [`plugins/train/trainer/_base.py`](https://github.com/deepfakes/faceswap/blob/e4bcb6d8d4266575ff3afd0916e58e7187195f31/plugins/train/trainer/_base.py):

> [Line 345:48](https://github.com/deepfakes/faceswap/blob/e4bcb6d8d4266575ff3afd0916e58e7187195f31/plugins/train/trainer/_base.py#L345): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace











##### Comment last updated at 2019-10-07 01:37:40 UTC",hello thanks checked touched pep found file line trailing line visually indented line indent next logical line file line trailing comment last,issue,negative,positive,neutral,neutral,positive,positive
519311368,"I think I have tried both running setup.py in (base) and (condaEnv) but still getting cudNN Version: (empty)

It might be possible that tensorflow is not correctly installed though...",think tried running base still getting version empty might possible correctly though,issue,negative,negative,negative,negative,negative,negative
519310932,"If you setup in a Conda environment, you can completely remove system Cuda/cuDNN and just let setup.py install Cuda for you.",setup environment completely remove system let install,issue,negative,positive,neutral,neutral,positive,positive
519310462,"Thanks. Now it seems as if cudNN is not installed, even though I did this:

```
$ CUDNN_FILE=""cudnn-9.0-linux-x64-v7.2.1.38""
$ wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.2.1/
      prod/9.0_20180806/${CUDNN_FILE}
$ tar -xzvf ${CUDNN_FILE}
```
Then this:
```
$ sudo cp -P cuda/include/cudnn.h /usr/local/cuda-9.0/include
$ sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-9.0/lib64/
$ sudo chmod a+r /usr/local/cuda-9.0/lib64/libcudnn*
```

Now I'm getting this:
```WARNING Running without root/admin privileges
INFO    The tool provides tips for installation
        and installs required python packages
INFO    Setup in Linux 4.15.0-55-generic
INFO    Installed Python: 3.7.3 64bit
INFO    Encoding: UTF-8
INFO    Upgrading pip...
INFO    Installed pip: 19.2.1
INFO    AMD Support: AMD GPU support is currently limited.
        Nvidia Users MUST answer 'no' to this option.
Enable AMD Support? [y/N] n
INFO    AMD Support Disabled
Enable  Docker? [y/N] n
INFO    Docker Disabled
Enable  CUDA? [Y/n] y
INFO    CUDA Enabled
INFO    CUDA version: 9.0
ERROR   cuDNN not found. See https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#cudnn for instructions
WARNING The minimum Tensorflow requirement is 1.12. 
        Tensorflow currently has no official prebuild for your CUDA, cuDNN combination.
        Either install a combination that Tensorflow supports or build and install your own tensorflow-gpu.
        CUDA Version: 9.0
        cuDNN Version: 
        Help:
        Building Tensorflow: https://www.tensorflow.org/install/install_sources
        Tensorflow supported versions: https://www.tensorflow.org/install/source#tested_build_configurations
Location of custom tensorflow-gpu wheel (leave blank to manually install): 
```

How can I tell if cudNN is correctly installed?",thanks even though tar getting warning running without tool installation python setup generic python bit pip pip support support currently limited must answer option enable support support disabled enable docker docker disabled enable version error found see warning minimum requirement currently official combination either install combination build install version version help building location custom wheel leave blank manually install tell correctly,issue,positive,negative,neutral,neutral,negative,negative
519028662,"one model  A :3or4 kind faces    B: one faces
",one model kind one,issue,positive,positive,positive,positive,positive,positive
518760348,"I have the same issue.
Added some print before that line, and it turns out to be ""self.state is None""",issue added print line turn none,issue,negative,neutral,neutral,neutral,neutral,neutral
518531061,@torzdf I reinstalled everything in Conda and after pulling latest changes it has finally started to work.,everything latest finally work,issue,negative,positive,positive,positive,positive,positive
518431797,Don't use the Docker. Re-run setup.py but say `n` to docker,use docker say docker,issue,negative,neutral,neutral,neutral,neutral,neutral
518242583,"After discussions with our resident AMD guy, we have decided to just disable ping-pong for AMD users.

Unfortunately (as you noted) plaidML does not currently support multi GPU, so any performance boost (albeit briefly) is entirely accidental.",resident guy decided disable unfortunately noted currently support performance boost albeit briefly entirely accidental,issue,negative,negative,negative,negative,negative,negative
518213978,"Problem is still here:
```
08/05/2019 15:28:04 INFO     Exit requested! The trainer will complete its current cycle, save the models and quit (This can take a couple of minutes depending on your training speed).
08/05/2019 15:28:09 INFO     [Saved models] - Average since last save: face_loss_A: 0.03513, face_loss_B: 0.04683
Process exited.
Exception in Tkinter callback
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\faceswap\lib\tkinter\__init__.py"", line 1705, in __call__
    return self.func(*args)
  File ""C:\ProgramData\Anaconda3\envs\faceswap\lib\tkinter\__init__.py"", line 749, in callit
    func(*args)
  File ""C:\Users\Vadim\faceswap\lib\gui\display_analysis.py"", line 141, in <lambda>
    self.after(1000, lambda msg=message: self.set_session_summary(msg))
  File ""C:\Users\Vadim\faceswap\lib\gui\display_analysis.py"", line 144, in set_session_summary
    self.summary = self.thread.get_result()
  File ""C:\Users\Vadim\faceswap\lib\gui\utils.py"", line 1111, in get_result
    raise self.err[1].with_traceback(self.err[2])
  File ""C:\Users\Vadim\faceswap\lib\gui\utils.py"", line 1090, in run
    retval = self._target(*self._args, **self._kwargs)
  File ""C:\Users\Vadim\faceswap\lib\gui\display_analysis.py"", line 153, in summarise_data
    return session.full_summary
  File ""C:\Users\Vadim\faceswap\lib\gui\stats.py"", line 131, in full_summary
    return self.summary.compile_stats()
  File ""C:\Users\Vadim\faceswap\lib\gui\stats.py"", line 290, in compile_stats
    compiled_stats = self.sessions_stats
  File ""C:\Users\Vadim\faceswap\lib\gui\stats.py"", line 274, in sessions_stats
    iterations = self.session.get_iterations_for_session(sess_idx)
  File ""C:\Users\Vadim\faceswap\lib\gui\stats.py"", line 244, in get_iterations_for_session
    session = self.state[""sessions""].get(str(session_id), None)
TypeError: 'NoneType' object is not subscriptable
```",problem still exit trainer complete current cycle save quit take couple depending training speed saved average since last save process exception recent call last file line return file line file line lambda lambda file line file line raise file line run file line return file line return file line file line file line session session none object,issue,positive,negative,neutral,neutral,negative,negative
518209078,"That's standard. I'll probably look to pin Pillow, but nvidia-ml-py3 will always check as we had to hold a fork in our github repo (https://github.com/deepfakes/nvidia-ml-py3).

There is a problem with stock nvidia-ml-py3 that does not work with Windows Update installed Nvidia drivers. Our version fixes this, but unfortunately pip cannot check the version number until it has downloaded the latest git version, so it will attempt to re-install it every time you check for updates. It is (unfortunately) a small price to pay to make sure we can support Nvidia drivers installed by Windows update",standard probably look pin pillow always check hold fork problem stock work update version unfortunately pip check version number latest git version attempt every time check unfortunately small price pay make sure support update,issue,negative,positive,neutral,neutral,positive,positive
518092091,"Yes, I tried to update, but also found a strange thing: I clicked ""Check for updates..."", then I restarted FaceSwap and ran it again. And every time I'm trying to update I get the following log:
```
08/05/2019 08:32:15 INFO     Checking for updates...
08/05/2019 08:32:15 INFO     Faceswap is up to date.
08/05/2019 08:32:15 INFO     Updating dependencies...
08/05/2019 08:32:15 INFO     Setup in Windows 10
08/05/2019 08:32:15 INFO     Installed Python: 3.6.9 64bit
08/05/2019 08:32:15 INFO     Running in Conda
08/05/2019 08:32:15 INFO     Running in a Virtual Environment
08/05/2019 08:32:15 INFO     Encoding: cp1251
08/05/2019 08:32:15 INFO     Installed pip: 19.1.1
08/05/2019 08:32:17 INFO     Installing Required Python Packages. This may take some time...
08/05/2019 08:32:17 INFO     Installing Pillow>=6.0.0
08/05/2019 08:32:22 INFO     Installing git+https://github.com/deepfakes/nvidia-ml-py3.git
08/05/2019 08:32:25 INFO     git+https://github.com/deepfakes/nvidia-ml-py3.git not available in Conda. Installing with pip
08/05/2019 08:32:25 INFO     Installing git+https://github.com/deepfakes/nvidia-ml-py3.git
08/05/2019 08:32:28 INFO     Dependencies updated
```
Also, I can do it all the time after I ran the program.",yes tried update also found strange thing check ran every time trying update get following log date setup python bit running running virtual environment pip python may take time pillow available pip also time ran program,issue,negative,positive,positive,positive,positive,positive
517746965,"Ok, sorry. A few outstanding things......

**coverage**
Thanks for moving coverage. The help text should probably be amended though. Something like:
```
How much of the extracted image to train on. Higher coverage will train on more of the face,
but come at a detail cost, as more face is being fit into the same size image. Sensible values
to use are:
...
```
**loss options**
The loss description is much better now... I'm going to make a couple of requests though.

I would suggest changing `image_loss_function` to just `loss_function`.

Please abbreviate those that can be abbreviated (e.g. `Mean_Absolute_Error` > `mae`). The descriptions tell us what the abbreviations mean.

Also, please lowercase the options for these. It helps us handle in the code as we can `lower()` any of the options to make it case insensitive.

Both of these make it easier for cli users and also ensures less room for error

**dssim**
Now that DSSIM has been removed, then the old values for True/False will have to be handled when loading legacy models, and the associated state file updated accordingly to point to the correct loss. This is the first time that a config option has been explicitly changed, so we currently have no code to handle this. I would imagine that the best place to put it would be in `model._base.py` within `State().load()` with a call for check + update legacy options there.

**missing defaults**
We should probably remove any `_defaults.py` files for models which have no options to get them out of the config file/GUI tabs. I'm not sure if they can just be deleted or will have to insert a bit of code to handle. I can do this after merge if you'd prefer.

",sorry outstanding coverage thanks moving coverage help text probably though something like much extracted image train higher coverage train face come detail cost face fit size image sensible use loss loss description much better going make couple though would suggest please abbreviate mae tell u mean also please u handle code lower make case insensitive make easier also le room error removed old handled loading legacy associated state file accordingly point correct loss first time option explicitly currently code handle would imagine best place put would within state call check update legacy missing probably remove get sure insert bit code handle merge prefer,issue,positive,positive,positive,positive,positive,positive
517699560,"> > Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:
> > ```
> > * In the file [`plugins/train/_config.py`](https://github.com/deepfakes/faceswap/blob/f1a881dc288fc3992961ac05afa22c1b65032688/plugins/train/_config.py):
> > ```
> > 
> > 
> > > [Line 39:12](https://github.com/deepfakes/faceswap/blob/f1a881dc288fc3992961ac05afa22c1b65032688/plugins/train/_config.py#L39): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace
> > > [Line 73:100](https://github.com/deepfakes/faceswap/blob/f1a881dc288fc3992961ac05afa22c1b65032688/plugins/train/_config.py#L73): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)
> > > [Line 149:17](https://github.com/deepfakes/faceswap/blob/f1a881dc288fc3992961ac05afa22c1b65032688/plugins/train/_config.py#L149): [E131](https://duckduckgo.com/?q=pep8%20E131) continuation line unaligned for hanging indent
> > 
> > 
> > ##### Comment last updated at 2019-08-02 06:32:36 UTC
> 
> Sorry, please resolve these and I'll review

pepped",hello thanks checked touched pep found file line trailing line line long line continuation line unaligned hanging indent comment last sorry please resolve review,issue,positive,negative,neutral,neutral,negative,negative
517412648,"Yeah AMD support is rough I noticed, however everything still works fine and preferably I don't even want to use ping-pong. With this niche setup ping-pong I just accidentally tapped into a 3x performance boost with that specific setting because actual compute load is going from 30% to 95% when stuff is stored on GPU2 instead of RAM. If it's is doing it by accident then maybe it's relatively easy enough to implement it in default AMD settings, while also not having it crash. 

It could also be a bug with PlaidML, but I really have no idea how any of this works, just noticed this weird behavior. ",yeah support rough however everything still work fine preferably even want use niche setup accidentally performance boost specific setting actual compute load going stuff instead ram accident maybe relatively easy enough implement default also crash could also bug really idea work weird behavior,issue,negative,positive,neutral,neutral,positive,positive
517407443,"@kilroythethird Will need to help look into this....

Bottom line is AMD support is secondary, I'm afraid, so I can't promise that we will be able to solve this. Ping Pong was built as a way to load an unload Tensorflow-GPU sessions from VRAM. As AMD does not use TF-GPU (rather it uses PlaidML as a backend), its release mechanism won't be the same.

I would welcome patches to address this. Unfortunately I run with an Nvidia card, so it isn't something I can patch. I will leave this as an open issue though.

In the meantime, sadly, your only option is ""don't use ping-pong"".
",need help look bottom line support secondary afraid ca promise able solve ping pong built way load unload session use rather release mechanism wo would welcome address unfortunately run card something patch leave open issue though sadly option use,issue,positive,negative,neutral,neutral,negative,negative
517246563,"Is it possible to extract the decoder component of the GAN to allow for a simple decoder exchange and swap generation via calling .predict?

Currently having trouble shortening the code to create a simpler call to predict - all I'm getting is A-to-A autoencoding with the GAN",possible extract component gan allow simple exchange swap generation via calling currently trouble shortening code create simpler call predict getting gan,issue,negative,negative,neutral,neutral,negative,negative
517057934,"If you want.

Alternatively, thousands of users who max their GPUs vs 1 who doesn't. Where do you think the issue is likely to lie?

This is not a support forum. I have given you 2 locations where you can get support.",want alternatively think issue likely lie support forum given get support,issue,positive,neutral,neutral,neutral,neutral,neutral
517056397,"So all users of swapface have fully loaded CPU and literally GPU? Because if 12 threads of CPU is not enough, I don't know what you should have to fully load GPU...
Testing FakeApp again, but I think it's load GPU as it should be.",fully loaded literally enough know fully load testing think load,issue,negative,neutral,neutral,neutral,neutral,neutral
517051746,"But the performance of my system is limited to CPU because it's fully loaded, but not GPU. It's not a bug?",performance system limited fully loaded bug,issue,negative,negative,neutral,neutral,negative,negative
517050806,"Your GPU is definitely being picked up:
```gpu_devices:         GPU_0: GeForce RTX 2060
gpu_devices_active:  GPU_0
gpu_driver:          431.60
gpu_vram:            GPU_0: 6144MB
os_machine:          AMD64
```

This is a place for bugs and issues with the FS code, but I don't think there is one here. For setup/usage help, please use the Faceswap Forums or the Discord server.",definitely picked place code think one help please use discord server,issue,positive,neutral,neutral,neutral,neutral,neutral
517046294,"You don't need to install the standard drivers for faceswap. If you have installed your drivers correctly, then faceswap will pick it up. Ultimately the location of nvml.dll has to be in either:

`Program Files\NVIDIA Corporation\NVSMI\nvml.dll`
or
`Windows\System32\nvml.dll`



",need install standard correctly pick ultimately location either program,issue,negative,neutral,neutral,neutral,neutral,neutral
517045480,"I didn't understand the answer. As I said, I don't know the way to install standart driver on laptop, i tried two ways. I get this ""System Information"":

```
============ System Information ============
encoding:            cp1251
git_branch:          master
git_commits:         9a000f9 Merge branch 'master' into staging
gpu_cuda:            10.0
gpu_cudnn:           7.6.2
gpu_devices:         GPU_0: GeForce RTX 2060
gpu_devices_active:  GPU_0
gpu_driver:          431.60
gpu_vram:            GPU_0: 6144MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.18362-SP0
os_release:          10
py_command:          C:\Users\Vadim\faceswap/faceswap.py gui
py_conda_version:    conda 4.7.10
py_implementation:   CPython
py_version:          3.6.9
py_virtual_env:      True
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
sys_ram:             Total: 16233MB, Available: 10853MB, Used: 5380MB, Free: 10853MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.7.1
certifi==2019.6.16
cloudpickle==1.2.1
cycler==0.10.0
cytoolz==0.10.0
dask==2.1.0
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mkl-fft==1.0.12
mkl-random==1.0.2
mkl-service==2.0.2
mock==3.0.5
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.1
olefile==0.46
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
protobuf==3.8.0
psutil==5.6.3
pyparsing==2.4.0
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.1
PyWavelets==1.0.3
pywin32==223
PyYAML==5.1.1
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.0
six==1.12.0
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
toolz==0.10.0
toposort==1.5
tornado==6.0.3
tqdm==4.32.1
Werkzeug==0.15.4
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at C:\ProgramData\Anaconda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.1                    py36_0  
astor                     0.7.1                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.5.15                     0  
certifi                   2019.6.16                py36_1  
cloudpickle               1.2.1                      py_0  
cudatoolkit               10.0.130                      0  
cudnn                     7.6.0                cuda10.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.10.0           py36he774522_0  
dask-core                 2.1.0                      py_0  
decorator                 4.4.0                    py36_1  
fastcluster               1.1.25          py36h830ac7b_1000    conda-forge
ffmpeg                    4.1.3                h6538335_0    conda-forge
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.5.0                    py36_0  
imageio-ffmpeg            0.3.0                      py_0    conda-forge
intel-openmp              2019.4                      245  
joblib                    0.13.2                   py36_0  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.8                      py_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.1.0                      py_1  
kiwisolver                1.1.0            py36ha925a31_0  
libmklml                  2019.0.3                      0  
libpng                    1.6.37               h2a8f88b_0  
libprotobuf               3.8.0                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.1.1                    py36_0  
matplotlib                2.2.2            py36had4c4a9_2  
mkl                       2019.4                      245  
mkl-service               2.0.2            py36he774522_0  
mkl_fft                   1.0.12           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
mock                      3.0.5                    py36_0  
networkx                  2.3                        py_0  
numpy                     1.16.2           py36h19fb1c0_0  
numpy-base                1.16.2           py36hc3f5095_0  
nvidia-ml-py3             7.352.1                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv-python             4.1.0.25                 pypi_0    pypi
openssl                   1.1.1c               he774522_1  
pathlib                   1.0.1                    py36_1  
pillow                    6.1.0            py36hdc69c19_0  
pip                       19.1.1                   py36_0  
protobuf                  3.8.0            py36h33f27b4_0  
psutil                    5.6.3            py36he774522_0  
pyparsing                 2.4.0                      py_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.9                h5500b2f_0  
python-dateutil           2.8.0                    py36_0  
pytz                      2019.1                     py_0  
pywavelets                1.0.3            py36h8c2d366_1  
pywin32                   223              py36hfa6e2cd_1  
pyyaml                    5.1.1            py36he774522_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.15.0           py36ha925a31_0  
scikit-learn              0.21.2           py36h6288b17_0  
scipy                     1.3.0            py36h29ff71c_0  
setuptools                41.0.1                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.29.0               he774522_0  
tensorboard               1.13.1           py36h33f27b4_0  
tensorflow                1.13.1          gpu_py36h9006a92_0  
tensorflow-base           1.13.1          gpu_py36h871c8ca_0  
tensorflow-estimator      1.13.0                     py_0  
tensorflow-gpu            1.13.1               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.10.0                     py_0  
toposort                  1.5                        py_3    conda-forge
tornado                   6.0.3            py36he774522_0  
tqdm                      4.32.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_4  
werkzeug                  0.15.4                     py_0  
wheel                     0.33.4                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0
```",understand answer said know way install driver tried two way get system information system information master merge branch staging true family model stepping total available used free pip environment name version build channel astor blas cycler decorator gast markdown mock pillow pip python sip six tornado wheel,issue,positive,positive,positive,positive,positive,positive
516777288,"The article linked in the above post explains what alignments are used for, how to create it and how to clean it, If you have generated an alignments file for the source video, then you should be able to leave the alignments field blank.

Usage questions should be directed to our forum or the Discord server",article linked post used create clean file source video able leave field blank usage directed forum discord server,issue,negative,positive,positive,positive,positive,positive
516654774,"> 
> 
> That suggests that there's a problem with one of your images, or there is a bug in the cv2 DNN detector. If it's the latter, it's unlikely to be addressed any time soon, because it is really the last choice detector.
> 
> Either way, in the first instance I would recommend not using on the fly conversion, and generating an alignments file. You will get better results (and will bypass this potential issue)
> 
> See here:
> https://faceswap.dev/forum/viewtopic.php?f=5&t=27

I created the alignments file and will train with them.  Once complete and ready to perform a conversion, I see that the Convert tab has an Alignments field.  Where should this alignments file come from?  Source Video?  Face A faces?  Face B faces?  I looked around the FAQ and couldn't find that specific answer.",problem one bug detector latter unlikely time soon really last choice detector either way first instance would recommend fly conversion generating file get better bypass potential issue see file train complete ready perform conversion see convert tab field file come source video face face around could find specific answer,issue,positive,positive,positive,positive,positive,positive
516642959,"Get the latest code and try again. A bug was fixed around this recently.

As an aside, you are going to struggle with that card. Your best bet will be the Lightweight model.

I'm closing this issue off. If it persists, please reply with a full trace log (enable `loglevel` `TRACE`, let it run till about 30 seconds after it gets stuck, then post the `faceswap.log` file from your faceswap folder)

NB: Only run with tracelogging when requested. It will slow down your process and generate massive files.",get latest code try bug fixed around recently aside going struggle card best bet lightweight model issue please reply full trace log enable trace let run till stuck post file folder run slow process generate massive,issue,negative,positive,positive,positive,positive,positive
516633920,"That suggests that there's a problem with one of your images, or there is a bug in the cv2 DNN detector. If it's the latter, it's unlikely to be addressed any time soon, because it is really the last choice detector.

Either way, in the first instance I would recommend not using on the fly conversion, and generating an alignments file. You will get better results (and will bypass this potential issue)

See here:
https://faceswap.dev/forum/viewtopic.php?f=5&t=27",problem one bug detector latter unlikely time soon really last choice detector either way first instance would recommend fly conversion generating file get better bypass potential issue see,issue,negative,positive,positive,positive,positive,positive
516632495,"> 
> 
> You'd need to post the crash log.

Just updated the main post with the crash log.  I did a smaller video successfully (2 minutes) this one is about 9 minutes in length.",need post crash log main post crash log smaller video successfully one length,issue,negative,positive,positive,positive,positive,positive
516623025,You'd need to post the crash log.,need post crash log,issue,negative,neutral,neutral,neutral,neutral,neutral
516072813,The filter/nfilter bug in convert should be fixed in latest commit,bug convert fixed latest commit,issue,negative,positive,positive,positive,positive,positive
515769623,This is a setup/configuration issue and is best discussed in the Discord server or on https://faceswap.dev/forum,issue best discord server,issue,negative,positive,positive,positive,positive,positive
515769537,"Usage issues are best raised in the Forum or in the Discord Server.

I am leaving this open as the initial issue is a bug.",usage best raised forum discord server leaving open initial issue bug,issue,negative,positive,positive,positive,positive,positive
515734150,"I am really use Windows Task manager. now i use  nvidia-smi, GPU usage rate no more than %30. Most of the time it is %0,  Memory-Usage always is 220M/2048M, How should I troubleshoot where the problem is? thank you very much!

![image](https://user-images.githubusercontent.com/3920019/62002579-85f21d80-b139-11e9-8c62-5010e823bbda.png)
![image](https://user-images.githubusercontent.com/3920019/62002612-1cbeda00-b13a-11e9-8c90-b9f9bf0dbab9.png)
",really use task manager use usage rate time always problem thank much image image,issue,negative,positive,positive,positive,positive,positive
515721296,"I relied on the FAQ and the documentation pretty heavily to get me to this point! Im just trying to make a shitty preliminary test so that, should I not be able to do this for one reason or another, I don't waste _too_ much time haha.

So, clearing both of those fields let it run without error, and gave me a converted clip as output. Which is nice...but there appears to be no discernible difference between the before/after. No edit at all.

I knew it wouldn't be good, but I was kind of expecting at least a garbled face-mess to confirm the process is working. Should it remain completely unchanged?",documentation pretty heavily get point trying make preliminary test able one reason another waste much time clearing let run without error gave converted clip output nice discernible difference edit knew would good kind least confirm process working remain completely unchanged,issue,positive,positive,positive,positive,positive,positive
515720957,"@deyu260  Sorry for the late reply. Here is the link:
https://github.com/deepfakes/faceswap-playground/issues/168#issuecomment-391056247
",sorry late reply link,issue,negative,negative,negative,negative,negative,negative
515720674,"You should follow the FAQ because it will take you to a guide for extraction etc.

Basically don't use the filter/nfilter box. I will look to fix it at some point, but it won't be immediate.",follow take guide extraction basically use box look fix point wo immediate,issue,negative,neutral,neutral,neutral,neutral,neutral
515720643,"No, totally, I get that! This was just a preliminary test to see if I understand the workflow and process. Once I get this whole thing start to finish I'll be able to make a more complex one later this week.

Thanks for the help, by the way! I'm unsure how to not use the face filter - using the GUI version of faceswap. Is it a box or something? Sorry!",totally get preliminary test see understand process get whole thing start finish able make complex one later week thanks help way unsure use face filter version box something sorry,issue,positive,positive,neutral,neutral,positive,positive
515720355,"This looks like a bug in face filter. Don't use the face filter and it should run through fine.

Also. 100 photos? 2 hours 40 mins? Your swap is going to be bad!

See here: https://faceswap.dev/forum/app.php/faqpage",like bug face filter use face filter run fine also swap going bad see,issue,negative,negative,negative,negative,negative,negative
515708012,"@torzdf Where were we with this CPU enabler? I recall some dicussion on preferences for where we configure TF sessions? Anyways, I've resolved the conflicts and ready to re-test this again",enabler recall configure session anyways resolved ready,issue,negative,positive,positive,positive,positive,positive
515704855,"Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:









* In the file [`lib/model/masks.py`](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/lib/model/masks.py):

> [Line 18:100](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/lib/model/masks.py#L18): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (104 > 99 characters)











* In the file [`plugins/train/_config.py`](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/_config.py):

> [Line 39:12](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/_config.py#L39): [W291](https://duckduckgo.com/?q=pep8%20W291) trailing whitespace
> [Line 73:100](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/_config.py#L73): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)
> [Line 149:17](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/_config.py#L149): [E131](https://duckduckgo.com/?q=pep8%20E131) continuation line unaligned for hanging indent

* In the file [`plugins/train/model/_base.py`](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/model/_base.py):

> [Line 776:58](https://github.com/deepfakes/faceswap/blob/9f24475e182b7c177dd2ed6d91e2e2cf68d07471/plugins/train/model/_base.py#L776): [E225](https://duckduckgo.com/?q=pep8%20E225) missing whitespace around operator







































##### Comment last updated at 2019-08-02 06:43:40 UTC",hello thanks checked touched pep found file line line long file line trailing line line long line continuation line unaligned hanging indent file line missing around operator comment last,issue,negative,negative,neutral,neutral,negative,negative
515701612,"> 
> 
> Let me know but the two PEP8 comment flags by the bot are two things I'd ignore
> 
>     * the first looks clean to me but can change if youd like
> 
>     * the hardcoded matrix for edge detection is large, and its clarity is much improved if the matrix rows are not split to two lines

It's a bit annoying, I know, but the first one should be indented one space, as it should line up with the list, not the function call:
```py
        return pad(x,
                   [[0, 0],
                    [padding_top, padding_bot],
                    [padding_left, padding_right],
                    [0, 0]],
                   'REFLECT')
```

Add I would rather try to remain pep8 compliant (with line length of 100) if at all possible. I'm not really too bothered about extra lines, so this would be fine for me:
```py
    matrix = [[[[0.00070, 0.0007]],
               [[0.00520, 0.0037]],
               [[0.03700, 0.]],
               [[0.00520, -0.0037]],
               [[0.00070, -0.0007]]],
              [[[0.00370, 0.0052]],
               [[0.11870, 0.1187]],
               [[0.25890, 0.]],
               [[0.11870, -0.1187]],
               [[0.00370, -0.0052]]],
              [[[0.00000, 0.0370]],
               [[0.00000, 0.2589]],
               [[0.00000, 0.]],
               [[0.00000, -0.2589]],
               [[0.00000, -0.0370]]],
              [[[-0.0037, 0.0052]],
               [[-0.1187, 0.1187]],
               [[-0.2589, 0.]],
               [[-0.1187, -0.1187]],
               [[-0.0037, -0.0052]]],
              [[[-0.0007, 0.0007]],
               [[-0.0052, 0.0037]],
               [[-0.0370, 0.]],
               [[-0.0052, -0.0037]],
               [[-0.0007, -0.0007]]]]```",let know two pep comment bot two ignore first clean change youd like matrix edge detection large clarity much matrix split two bit annoying know first one indented one space line list function call return pad add would rather try remain pep compliant line length possible really extra would fine matrix,issue,positive,positive,neutral,neutral,positive,positive
515691617,"Let me know but the two PEP8 comment flags by the bot are two things I'd ignore
- the first looks clean to me but can change if youd like
- the hardcoded matrix for edge detection is large, and its clarity is much improved if the matrix rows are not split to two lines",let know two pep comment bot two ignore first clean change youd like matrix edge detection large clarity much matrix split two,issue,positive,positive,positive,positive,positive,positive
515663819,Are you checking your GPU usage with Windows Task manager?  See https://faceswap.dev/forum/app.php/faqpage#f0r3 for why that is not a good idea.,usage task manager see good idea,issue,negative,positive,positive,positive,positive,positive
515658019,"Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:













* In the file [`plugins/train/_config.py`](https://github.com/deepfakes/faceswap/blob/92121648f3578f1ad0157e68e4970beeb89fbb35/plugins/train/_config.py):

> [Line 148:100](https://github.com/deepfakes/faceswap/blob/92121648f3578f1ad0157e68e4970beeb89fbb35/plugins/train/_config.py#L148): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (104 > 99 characters)
> [Line 149:100](https://github.com/deepfakes/faceswap/blob/92121648f3578f1ad0157e68e4970beeb89fbb35/plugins/train/_config.py#L149): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (103 > 99 characters)
> [Line 150:100](https://github.com/deepfakes/faceswap/blob/92121648f3578f1ad0157e68e4970beeb89fbb35/plugins/train/_config.py#L150): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (106 > 99 characters)

























##### Comment last updated at 2019-08-03 05:18:32 UTC",hello thanks checked touched pep found file line line long line line long line line long comment last,issue,negative,positive,neutral,neutral,positive,positive
515142971,"No.

Questions like these are best placed in our discord server or our forum. Links to both can be found at https://faceswap.dev",like best discord server forum link found,issue,positive,positive,positive,positive,positive,positive
515128565,"At the first time, I selected `Fan`. but now I am using` Fan-amd`. Thank you for helping me out; I really appreciate your kindness and support.
I have another question:
Does this program support ""Audio manipulation"" ?? like for example this video https://www.youtube.com/watch?v=347jdBs-mRU

",first time selected fan thank helping really appreciate kindness support another question program support audio manipulation like example video,issue,positive,positive,positive,positive,positive,positive
515002251,"There was an issue where if a crash occurred in the loading/saving threads then the process would hang indefinitely. This *should* now be caught and handled. If this issue has not been resolved, please comment and I will re-open.",issue crash process would indefinitely caught handled issue resolved please comment,issue,negative,neutral,neutral,neutral,neutral,neutral
514982420,"As discussed in Discord server, I would much prefer a flag ""no-rename"" or similar added to cli.py and checked for so that we can support both workflows.

Otherwise, thanks for the PR!",discord server would much prefer flag similar added checked support otherwise thanks,issue,negative,positive,positive,positive,positive,positive
514961411,Ok. Thanks for the feedback. I think I know why this happens then and will look to push a fix,thanks feedback think know look push fix,issue,negative,positive,positive,positive,positive,positive
514927319,"> We have not seen this issue before, and it really shouldn't happen (especially since it must have successfully snapshotted 4 times before.
> 
> Did you roll back to a previous backup/snapshot prior to hitting this error? This is the only way I can see that this might have occured?

Yes but around the 90k and up to the 124k I've had no problem ",seen issue really happen especially since must successfully time roll back previous prior error way see might yes around problem,issue,negative,positive,positive,positive,positive,positive
514751919,"From the output above it does not look like you used `Fan-amd` but are in fact using `Fan`.
Are you sure you selected the fan-amd aligner ?

Only a part of the pipeline currently supports AMD cards.
So if you choose fan-amd and checked the amd checkbox a part of the flow uses you GPU, but its still CPU heavy.",output look like used fact fan sure selected aligner part pipeline currently choose checked part flow still heavy,issue,positive,positive,neutral,neutral,positive,positive
514748051,"Yes, I choose fan-amd and I enable AMD option.
The extraction runs on CPU. is it normal? or I should run the extraction on GPU.",yes choose enable option extraction normal run extraction,issue,negative,positive,positive,positive,positive,positive
514704171,"We have not seen this issue before, and it really shouldn't happen (especially since it must have successfully snapshotted  4 times before.

Did you roll back to a previous backup/snapshot prior to hitting this error? This is the only way I can see that this might have occured?",seen issue really happen especially since must successfully time roll back previous prior error way see might,issue,negative,positive,positive,positive,positive,positive
514687819,"You should use the fan-amd plugin, and make sure that you enable the ""AMD"" option (at the bottom of the extract page).",use make sure enable option bottom extract page,issue,negative,positive,positive,positive,positive,positive
514687332,"It works now, it shows me like this 
`Loading...
07/24/2019 17:36:16 INFO     Log level set to: INFO
07/24/2019 17:36:16 INFO     Setting up for PlaidML
07/24/2019 17:36:17 INFO     Setting GPU to largest available experimental device. If you want to override this selection, run `plaidml-setup` from the command line.
07/24/2019 17:36:17 INFO     Using GPU: ['opencl_amd_oland.0']
07/24/2019 17:36:17 INFO     Successfully set up for PlaidML
07/24/2019 17:36:19 INFO     Output Directory: D:\faces
07/24/2019 17:36:19 INFO     Input Video: D:\src\data_dst.mp4
07/24/2019 17:36:19 INFO     Loading Detect from S3Fd plugin...
07/24/2019 17:36:19 INFO     Loading Align from Fan plugin...
07/24/2019 17:36:19 INFO     Starting, this may take a while...
07/24/2019 17:36:20 INFO     Initializing Face Alignment Network...
07/24/2019 17:36:23 WARNING  Using CPU
07/24/2019 17:36:34 INFO     Initialized Face Alignment Network.
07/24/2019 17:36:35 INFO     Initializing S3FD Detector...
07/24/2019 17:36:49 WARNING  Using CPU
07/24/2019 17:36:49 WARNING  You are running s3fd with 2048MB VRAM. The model is optimized for 4096MB VRAM. Detection should still run but you may get warnings/errors`",work like loading log level set setting setting available experimental device want override selection run command line successfully set output directory input video loading detect loading align fan starting may take face alignment network warning face alignment network detector warning warning running model detection still run may get,issue,negative,positive,positive,positive,positive,positive
514681693,"Ok, I have read through this, and the issue is basically that DFL does not install python into a virtual environment. This is not good practice, and is going to lead to more issues down the line.

My advice (and you are probably not going to like it) is to do one of 2 things.

1) Delete DFL. Nuke everything, run installer. See here: https://faceswap.dev/forum/app.php/faqpage#f1r1
2) Clean up your base python and create proper environments for DFL and Faceswap and install each into their relevant environment. You will not be able to use the installer for this option, and you will need to research this for yourself.

Ultimately, there is only so much support we can give because of poor design in other applications.",read issue basically install python virtual environment good practice going lead line advice probably going like one delete nuke everything run installer see clean base python create proper install relevant environment able use installer option need research ultimately much support give poor design,issue,positive,positive,positive,positive,positive,positive
514676549,"Depending on how python is installed on your system its a bit hard for me to guide you through that step sorry.

Did you try:

> 
Otherwise try to delete everything in you c:\users\lpmc_user\appdata\roaming\python\python37\site-packages folder with plaidml in the name.
Followed by
```
conda activate faceswap
pip install -U plaidml-keras plaidml
```

If that works that is way easier.",depending python system bit hard guide step sorry try otherwise try delete everything folder name activate pip install work way easier,issue,negative,negative,negative,negative,negative,negative
514675757,"I don't know how to run pip outside of anaconda environment.
could you please tell me how?",know run pip outside anaconda environment could please tell,issue,negative,neutral,neutral,neutral,neutral,neutral
514665989,"Sorry, just deleting the plaidml folder doesn't seem to cut it.
But it is definitely one step in the right direction.

The proper way would be a `pip uninstall plaidml plaidml-keras` if you know how to run pip **outside** of your anaconda environment.

Otherwise try to delete everything in you `c:\users\lpmc_user\appdata\roaming\python\python37\site-packages` folder with plaidml in the name.
Afterwards try to install plaidml in your anaconda environment with the commands in the post above.

If that doesn't work you could try a:
```
conda activate faceswap
pip install plaidml plaidml-keras --upgrade --force-reinstall
```
from your anaconda prompt, but tbh. i am not sure if that will remove packages outside of the anaconda environment.

And if that *still* doesn't work let me know and i am going to install python in my windows VM so i can guide you better through this.
",sorry folder seem cut definitely one step right direction proper way would pip know run pip outside anaconda environment otherwise try delete everything folder name afterwards try install anaconda environment post work could try activate pip install upgrade anaconda prompt sure remove outside anaconda environment still work let know going install python guide better,issue,positive,positive,neutral,neutral,positive,positive
514659216,"the error still the same 
`Loading...
07/24/2019 16:34:59 INFO     Log level set to: INFO
07/24/2019 16:34:59 ERROR    PlaidML not found. Run `pip install plaidml-keras` for AMD support
Process exited.`",error still loading log level set error found run pip install support process,issue,negative,neutral,neutral,neutral,neutral,neutral
514659067,"I executed these commands, it shows me like this : 

`(base) C:\Users\lpmc_user>conda activate faceswap

(faceswap) C:\Users\lpmc_user>pip install -U plaidml-keras plaidml
Requirement already up-to-date: plaidml-keras in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (0.6.3)
Requirement already up-to-date: plaidml in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (0.6.3)
Requirement already satisfied, skipping upgrade: six in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from plaidml-keras) (1.12.0)
Requirement already satisfied, skipping upgrade: keras==2.2.4 in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from plaidml-keras) (2.2.4)
Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from plaidml) (1.1.6)
Requirement already satisfied, skipping upgrade: cffi in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from plaidml) (1.12.3)
Requirement already satisfied, skipping upgrade: numpy in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from plaidml) (1.16.2)
Requirement already satisfied, skipping upgrade: pyyaml in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from keras==2.2.4->plaidml-keras) (5.1.1)
Requirement already satisfied, skipping upgrade: scipy>=0.14 in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from keras==2.2.4->plaidml-keras) (1.3.0)
Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from keras==2.2.4->plaidml-keras) (1.0.8)
Requirement already satisfied, skipping upgrade: h5py in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from keras==2.2.4->plaidml-keras) (2.9.0)
Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from keras==2.2.4->plaidml-keras) (1.1.0)
Requirement already satisfied, skipping upgrade: pycparser in c:\users\lpmc_user\appdata\roaming\python\python37\site-packages (from cffi->plaidml) (2.19)
`",executed like base activate pip install requirement already requirement already requirement already satisfied skipping upgrade six requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade,issue,positive,positive,positive,positive,positive,positive
514653808,"Conda on windows is just no fun ;)
This one should be easy enough to solve though.

Please open your anaconda prompt and do:
```
conda activate faceswap
pip install -U plaidml-keras plaidml
```
",fun one easy enough solve though please open anaconda prompt activate pip install,issue,positive,positive,positive,positive,positive,positive
514650126,"I deleted `C:\Users\lpmc_user\AppData\Roaming\Python\Python37\site-packages\plaidml`
It gives me now this error 
`Loading...
07/24/2019 16:13:07 INFO     Log level set to: INFO
07/24/2019 16:13:07 ERROR    PlaidML not found. Run `pip install plaidml-keras` for AMD support
Process exited.`",error loading log level set error found run pip install support process,issue,negative,neutral,neutral,neutral,neutral,neutral
514623920,"iseeeeeeeeeeeeeeeee
isee iseeisee iseeisee iseeisee iseeisee iseeisee iseeisee iseeisee i see 
IT IS NOT SUPPORT FLV  FORMAT!!!!!!!!!!!!!!!!!!!!
IT IS NOT SUPPORT FLV  FORMAT!!!!!!!!!!!!!!!!!!!!
IT IS NOT SUPPORT FLV  FORMAT!!!!!!!!!!!!!!!!!!!!
IT IS NOT SUPPORT FLV  FORMAT!!!!!!!!!!!!!!!!!!!!
",see support format support format support format support format,issue,positive,neutral,neutral,neutral,neutral,neutral
514391702,"Well it should at least solve this issue.
It might lead to DeefaceLab not working anymore, but as far as i see in the current settings it should produce the same error i think.
In the worst case you would need to reinstall plaidml system wide again to use deepfacelab (They really should use conda too tho).

As alternative you could try to downgrade your system wide installed plaidml to plaidml==0.6.0, but that is just a shot in the dark.",well least solve issue might lead working far see current produce error think worst case would need reinstall system wide use really use tho alternative could try downgrade system wide shot dark,issue,negative,negative,negative,negative,negative,negative
514389480,"I also use  deepfacelab ""https://github.com/iperov/DeepFaceLab"". I had it installed before I installed anaconda and faceswap.
Should I delete  `C:\Users\lpmc_user\AppData\Roaming\Python\Python37\site-packages\plaidml`?",also use anaconda delete,issue,negative,neutral,neutral,neutral,neutral,neutral
514371944,"Happy to help.
It for sure looks like you have plaidml installed twice. Are you using anything else which requires plaidml ?
The easiest fix for now would probably be to simply delete `C:\Users\lpmc_user\AppData\Roaming\Python\Python37\site-packages\plaidml` if you don't need it for something else.",happy help sure like twice anything else easiest fix would probably simply delete need something else,issue,positive,positive,positive,positive,positive,positive
514346380,"Thank you. It looks like you have also a plaidml version installed outside of this virtual environment.
I need to check how plaidml is set up under windows. Will get back to you shortly.",thank like also version outside virtual environment need check set get back shortly,issue,positive,neutral,neutral,neutral,neutral,neutral
514343385,"Yes I choose   ""Setup for AMD gpu option"" 
`(base) C:\Users\lpmc_user>conda activate faceswap
this is the output

(faceswap) C:\Users\lpmc_user>pip freeze
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cffi==1.12.3
cycler==0.10.0
decorator==4.4.0
enum34==1.1.6
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.22.0
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mkl-fft==1.0.12
mkl-random==1.0.2
mock==3.0.5
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.1
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
plaidml==0.6.3
plaidml-keras==0.6.3
protobuf==3.9.0
psutil==5.6.3
pycparser==2.19
pyparsing==2.4.1
pyreadline==2.1
python-dateutil==2.8.0
pytz==2019.1
PyWavelets==1.0.3
pywin32==224
PyYAML==5.1.1
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.0
six==1.12.0
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
toposort==1.5
tqdm==4.32.2
Werkzeug==0.15.5
wincertstore==0.2

(faceswap) C:\Users\lpmc_user>`",yes choose setup option base activate output pip freeze,issue,negative,negative,negative,negative,negative,negative
514341343,"Just to be sure: You used the installer and selected the ""Setup for AMD gpu option"" ?

If so please open the anaconda prompt (find it via the start menu) and do a:
```
conda activate faceswap
pip freeze
```

and post the output here.",sure used installer selected setup option please open anaconda prompt find via start menu activate pip freeze post output,issue,positive,positive,positive,positive,positive,positive
514226137,"@Clorr I think he meant ""Faceswap"", not ""fakeapp"". 
Because I have the same problem:
![image](https://user-images.githubusercontent.com/5371279/61718918-2e803600-ad64-11e9-9a87-1ec051dc30ae.png)
![image](https://user-images.githubusercontent.com/5371279/61718958-43f56000-ad64-11e9-9638-d90711380b65.png)
",think meant problem image image,issue,negative,neutral,neutral,neutral,neutral,neutral
513966670,"@torzdf Where did you get this info about the ""fact"" of `99% of people`? Most of the people who can't make it work simply forget about it, and only that small part of the people who cares - create issue topics at bugtracker.",get fact people people ca make work simply forget small part people create issue,issue,negative,negative,negative,negative,negative,negative
513950656,"@torzdf And I tested it again several times.
It's not working in ""INFO"" mode, but working in every other mode. Definitely a bug.",tested several time working mode working every mode definitely bug,issue,negative,neutral,neutral,neutral,neutral,neutral
513840097,"Heh. Always the way.
Don't leave trace logging on. It will slow everything down and will generate massive log files!",always way leave trace logging slow everything generate massive log,issue,negative,negative,negative,negative,negative,negative
513839806,"@torzdf It's working now.
I've already restarted it several times, but after I set the `TRACE` level, as you said, it suddenly started working!
It looks like a bug.",working already several time set trace level said suddenly working like bug,issue,negative,neutral,neutral,neutral,neutral,neutral
513830266,"For some reason On first initialization it can get stuck for a while. Stop it and try again. If it still hasn't started after 5 minutes, please set loglevel to ""TRACE"" and let it run until it hangs. Let it run for about 30 seconds more, then kill it. Go into your Faceswap folder and post the faceswap.log file.....

 ",reason first get stuck stop try still please set trace let run let run kill go folder post file,issue,negative,positive,positive,positive,positive,positive
513830198,"Are you using studio drivers ? 
If you are, use the game ready driver. 
This solved the issu for me.",studio use game ready driver,issue,negative,negative,neutral,neutral,negative,negative
513829096,"It isn't a problem with the installer. Please don't bump closed threads which have nothing to do with the issue.

If you want to see what the installer does, look at it's source code. The fact that it works for 99% of people means that, in all likelihood, the problem is with their setup, not with the installer.",problem installer please bump closed nothing issue want see installer look source code fact work people likelihood problem setup installer,issue,negative,negative,neutral,neutral,negative,negative
513778882,"@torzdf No, it's a problem with your installator.
Same issue here - extraction doesn't work after installing through this installator: https://github.com/deepfakes/faceswap/releases with admin privileges enabled.

All other Python neural projects are working, except yours.",problem issue extraction work python neural working except,issue,negative,neutral,neutral,neutral,neutral,neutral
513592724,"For some reason you aren't setup correctly.

From inside your faceswap folder (whilst in your faceswap environment):
```python update_deps.py```
",reason setup correctly inside folder whilst environment python,issue,negative,neutral,neutral,neutral,neutral,neutral
513583540,"mmm…again
Here is error:

(faceswap) D:\FaceSwap\faceswap-master\faceswap-master>python faceswap.py -h
Traceback (most recent call last):
  File ""faceswap.py"", line 5, in <module>
    import lib.cli as cli
  File ""D:\FaceSwap\faceswap-master\faceswap-master\lib\cli.py"", line 16, in <module>
    from lib.logger import crash_log, log_setup
  File ""D:\FaceSwap\faceswap-master\faceswap-master\lib\logger.py"", line 13, in <module>
    from tqdm import tqdm
ModuleNotFoundError: No module named 'tqdm'",error python recent call last file line module import file line module import file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
513580759,"Not sure if this can help. May you try in your env:

`conda install -c conda-forge basemap fiona`",sure help may try install,issue,positive,positive,positive,positive,positive,positive
513576047,"You may also want to edit this file:
https://github.com/deepfakes/faceswap/blob/plugin_realface_description_change/plugins/train/model/realface_defaults.py
",may also want edit file,issue,negative,neutral,neutral,neutral,neutral,neutral
513573831,"Color Transfer is pretty much a stock implementation, so i think my preference would be to not add to it....

I will look at how we can create a ""multi-plugin"" plugin, because I also appreciate that having it on it's own may not be particularly helpful.",color transfer pretty much stock implementation think preference would add look create also appreciate may particularly helpful,issue,positive,positive,positive,positive,positive,positive
513555601,"> Why have you added this to the color transfer plugin? I think it would be better as standalone

I think it fits the paradigm. I thought we discussed that at `#dev-chat`
There is no issue in creating a standalone plugin yet we don't have plugin chains. Therefore putting it in front of color effects would be hacky.",added color transfer think would better think paradigm thought issue yet therefore front color effect would hacky,issue,negative,positive,positive,positive,positive,positive
513546560,Why have you added this to the color transfer plugin? I think it would be better as standalone,added color transfer think would better,issue,negative,positive,positive,positive,positive,positive
513454278,"Your actual error is the one posted up a bit ""Status: CUDA driver version is insufficient for CUDA runtime version"".

This is saying your graphics card drivers are to old for cuda.  You need to update your drivers and try again.",actual error one posted bit status driver version insufficient version saying graphic card old need update try,issue,negative,positive,neutral,neutral,positive,positive
513454089,This feature is already available in the software.  Check out the convert plug-in options.,feature already available check convert,issue,negative,positive,positive,positive,positive,positive
513427075,"There is a bug when using copy previous on the first frame or copy next on the last frame, will fix ",bug copy previous first frame copy next last frame fix,issue,negative,positive,neutral,neutral,positive,positive
512862106,"I did have that engaged, I did just downgrade from s3fd to the other gpu
one and it started to go.

On Thu, Jul 18, 2019 at 8:06 AM torzdf <notifications@github.com> wrote:

> We are trying to find the cause of this bug.
>
> If you run with --single-process or the Single Process flag enabled, it
> should run.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/798?email_source=notifications&email_token=AMQ45HCZVMMPZRLXGWWPSV3QACBG3A5CNFSM4IE4RORKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2IY3ZI#issuecomment-512855525>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AMQ45HE5DTOLN2VPD63PATDQACBG3ANCNFSM4IE4RORA>
> .
>
",engaged downgrade one go wrote trying find cause bug run single process flag run thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
512855525,"We are trying to find the cause of this bug.

If you run with `--single-process` or the `Single Process` flag enabled, it should run.",trying find cause bug run single process flag run,issue,negative,negative,neutral,neutral,negative,negative
512033895,"They already have a solution, see the following which details how to fix. 
 https://conda.io/projects/conda/en/latest/user-guide/troubleshooting.html#numpy-mkl-library-load-failed",already solution see following fix,issue,negative,neutral,neutral,neutral,neutral,neutral
512033483,"This is an Anaconda issue, not a faceswap Issue. You should look to see if you can resolve this upstream:
https://github.com/ContinuumIO/anaconda-issues/issues/10213
",anaconda issue issue look see resolve upstream,issue,negative,neutral,neutral,neutral,neutral,neutral
511930335,"My System Info 


```
============ System Information ============
encoding:            cp936
git_branch:          Not Found
git_commits:         Not Found
gpu_cuda:            9.0
gpu_cudnn:           7.6.0
gpu_devices:         GPU_0: GeForce GTX 1060
gpu_devices_active:  GPU_0
gpu_driver:          431.36
gpu_vram:            GPU_0: 6144MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.17763-SP0
os_release:          10
py_command:          faceswap.py gui
py_conda_version:    conda 4.7.5
py_implementation:   CPython
py_version:          3.6.8
py_virtual_env:      True
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
sys_ram:             Total: 16230MB, Available: 9844MB, Used: 6386MB, Free: 9844MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cycler==0.10.0
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
grpcio==1.22.0
h5py==2.9.0
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.0
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.1.0
protobuf==3.9.0
psutil==5.6.3
pyparsing==2.4.0
python-dateutil==2.8.0
pytz==2019.1
PyWavelets==1.0.3
pywin32==224
PyYAML==5.1.1
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.0
six==1.12.0
tensorboard==1.12.2
tensorflow-gpu==1.12.0
termcolor==1.1.0
toposort==1.5
tqdm==4.32.2
Werkzeug==0.15.4
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at C:\Users\LPDR\Anaconda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
absl-py                   0.7.1                    pypi_0    pypi
astor                     0.8.0                    pypi_0    pypi
certifi                   2019.6.16                py36_0    defaults
cycler                    0.10.0                   pypi_0    pypi
decorator                 4.4.0                    pypi_0    pypi
fastcluster               1.1.25                   pypi_0    pypi
ffmpy                     0.2.2                    pypi_0    pypi
gast                      0.2.2                    pypi_0    pypi
grpcio                    1.22.0                   pypi_0    pypi
h5py                      2.9.0                    pypi_0    pypi
imageio                   2.5.0                    pypi_0    pypi
imageio-ffmpeg            0.3.0                    pypi_0    pypi
joblib                    0.13.2                   pypi_0    pypi
keras                     2.2.4                    pypi_0    pypi
keras-applications        1.0.8                    pypi_0    pypi
keras-preprocessing       1.1.0                    pypi_0    pypi
kiwisolver                1.1.0                    pypi_0    pypi
markdown                  3.1.1                    pypi_0    pypi
matplotlib                2.2.2                    pypi_0    pypi
networkx                  2.3                      pypi_0    pypi
numpy                     1.16.2                   pypi_0    pypi
nvidia-ml-py3             7.352.0                  pypi_0    pypi
opencv-python             4.1.0.25                 pypi_0    pypi
pathlib                   1.0.1                    pypi_0    pypi
pillow                    6.1.0                    pypi_0    pypi
pip                       19.1.1                   py36_0    defaults
protobuf                  3.9.0                    pypi_0    pypi
psutil                    5.6.3                    pypi_0    pypi
pyparsing                 2.4.0                    pypi_0    pypi
python                    3.6.8                h9f7ef89_7    defaults
python-dateutil           2.8.0                    pypi_0    pypi
pytz                      2019.1                   pypi_0    pypi
pywavelets                1.0.3                    pypi_0    pypi
pywin32                   224                      pypi_0    pypi
pyyaml                    5.1.1                    pypi_0    pypi
scikit-image              0.15.0                   pypi_0    pypi
scikit-learn              0.21.2                   pypi_0    pypi
scipy                     1.3.0                    pypi_0    pypi
setuptools                41.0.1                   py36_0    defaults
six                       1.12.0                   pypi_0    pypi
sqlite                    3.29.0               he774522_0    defaults
tensorboard               1.12.2                   pypi_0    pypi
tensorflow-gpu            1.12.0                   pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
toposort                  1.5                      pypi_0    pypi
tqdm                      4.32.2                   pypi_0    pypi
vc                        14.1                 h0510ff6_4    defaults
vs2015_runtime            14.15.26706          h3a45250_4    defaults
werkzeug                  0.15.4                   pypi_0    pypi
wheel                     0.33.4                   py36_0    defaults
wincertstore              0.2              py36h7fe50ca_0    defaults

```",system system information found found true family model stepping total available used free pip environment name version build channel astor cycler decorator gast markdown pillow pip python six wheel,issue,positive,positive,positive,positive,positive,positive
511930275,It can happen. You can try killing it and running again. Sometimes Cuda gets stuck caching stuff.,happen try killing running sometimes stuck stuff,issue,negative,neutral,neutral,neutral,neutral,neutral
511929944,"@torzdf Thanks for help, I reinstall my requirements by conda, I've been working on this all night. It looks like I'm on the right track. But when I start it, it doesn't seem to work at all. I've been waiting for it for 10 minutes. I know the first start may be a little slow, but is 10 minutes a normal range?",thanks help reinstall working night like right track start seem work waiting know first start may little slow normal range,issue,positive,positive,neutral,neutral,positive,positive
511844593,"Ok. This does not tell me what I need to know, specifically what Pip Packages you have installed. The fact that it did not output properly and that it says `py_virtual_env: False` leads me to  believe you are not set up correctly. 

You should be in a virtual environment.

Secondly this:
```From c:\program files\python3\lib\site-packages\tensorflow\python\framework\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.``` suggests to me you are using Tensorflow 1.13. Tensorflow 1.13 is not compatible with Cuda 9.0 which it says you have on your system. I hugely doubt you have compiled Tensorflow yourself to support Cuda 9.0, given the issues you are having.

Basically you have an unsupported install. You should remove your install and follow the instructions in INSTALL.md. There is no way we can support non-standard installs.",tell need know specifically pip fact output properly false believe set correctly virtual environment secondly removed future handled automatically compatible system hugely doubt support given basically unsupported install remove install follow way support,issue,negative,neutral,neutral,neutral,neutral,neutral
511791612,"This is my System info
============ System Information ============
encoding:            cp936
git_branch:          Not Found
git_commits:         Not Found
gpu_cuda:            9.0
gpu_cudnn:           7.6.0
gpu_devices:         GPU_0: GeForce GTX 1060
gpu_devices_active:  GPU_0
gpu_driver:          431.36
gpu_vram:            GPU_0: 6144MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.17763-SP0
os_release:          10
py_command:          .\faceswap.py gui
py_conda_version:    N/A
py_implementation:   CPython
py_version:          3.7.4
py_virtual_env:      False
sys_cores:           12
sys_processor:       Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
sys_ram:             Total: 16230MB, Available: 12164MB, Used: 4066MB, Free: 12164MB

=============== Pip Packages ===============",system system information found found false family model stepping total available used free pip,issue,positive,positive,neutral,neutral,positive,positive
511781639,"Post the output from Tools Menu > Output System Info
",post output menu output system,issue,negative,neutral,neutral,neutral,neutral,neutral
511395016,"@torzdf Yes, I first used DDU to uninstall the graphics card driver of the machine, and then downloaded the driver from the official website. The difference between the standard version and DCH is that the former has a driver panel and the latter does not? At present, I have a driver panel.",yes first used graphic card driver machine driver official difference standard version former driver panel latter present driver panel,issue,negative,positive,neutral,neutral,positive,positive
511238200,"This most likely an Nvidia driver issue. You must make sure your drivers are installed from the Nvidia website (the Standard Drivers not DCH). Windows basically puts the Machine Learning tools in the wrong place. Unfortunately Windows has made this difficult.

From here: https://www.tenforums.com/graphic-cards/131259-after-win-10-clean-install-cant-install-nvidia-driver-help-2.html#post1619616

> If you want to use standard then remove the current DCH driver using DDU (Display Driver Uninstaller) and install the latest standard driver without an internet connection. Nvidia offers both on their website, 

Make sure you select ""Standard"" not DCH",likely driver issue must make sure standard basically machine learning wrong place unfortunately made difficult want use standard remove current driver display driver install latest standard driver without connection make sure select standard,issue,negative,neutral,neutral,neutral,neutral,neutral
511053712,Switched lambda layer to keras custom layer to be compatible with different python version.,switched lambda layer custom layer compatible different python version,issue,negative,neutral,neutral,neutral,neutral,neutral
510579414,"This is a problem with your setup, not with the repo, so I am closing the issue. You are welcome to look for help in the discord server. In the meantime, uninstall your drivers with DDU and re-install from Nvidia site.",problem setup issue welcome look help discord server site,issue,negative,positive,positive,positive,positive,positive
510302521,*Fixed potential bug with using CPU mode when the backend is tensorflow.*,fixed potential bug mode,issue,negative,positive,neutral,neutral,positive,positive
510259061,It can take a few minutes to launch on the first run as it needs to cache files.,take launch first run need cache,issue,negative,positive,positive,positive,positive,positive
510258867,"There isn't really such a thing as ""Best Trainer"". The data you feed a model is by far and away the most important factor.

As a general rule of thumb, the heavier the model, the better it will perform (with the same data), but this is by no means a hard and fast rule.",really thing best trainer data feed model far away important factor general rule thumb model better perform data hard fast rule,issue,positive,positive,positive,positive,positive,positive
509731894,This looks fine. I think remove_alignment is still hanging around from before filter_hashes was implemented (which does the same job),fine think still hanging around job,issue,negative,positive,positive,positive,positive,positive
509728477,"It's not a virus. This is a false positive, Source Code is included in the repository. If you really don't trust it you can compile the installer yourself.

https://github.com/deepfakes/faceswap/tree/master/.install/windows

",virus false positive source code included repository really trust compile installer,issue,positive,positive,neutral,neutral,positive,positive
508993773,"> Thanks for referring. I found the answer there.

please tell me the answer",thanks found answer please tell answer,issue,positive,positive,positive,positive,positive,positive
508989664,Yes it's was a pretty straight forward fix,yes pretty straight forward fix,issue,positive,positive,positive,positive,positive,positive
508433868,"I'm closing this issue off due to lack of feedback, and no way to test on this GPU.

Please feel free to post the information to this closed issue and I will re-open.",issue due lack feedback way test please feel free post information closed issue,issue,positive,positive,neutral,neutral,positive,positive
508433689,"I'm hoping that moving CV2-DNN detection from pooled process to spawned process has fixed this issue.

Please open a new issue if the problem persists.",moving detection process process fixed issue please open new issue problem,issue,negative,positive,neutral,neutral,positive,positive
508433416,"We have now switched to ImageIO for reading videos in, so hopefully that has resolved this issue.

Please raise a new issue if it persists.",switched reading hopefully resolved issue please raise new issue,issue,positive,positive,positive,positive,positive,positive
508171796,"Closing this off as I think setup.py and INSTALL.md are in a relatively good place at the moment.

Thanks for all your help @DKingCN ",think relatively good place moment thanks help,issue,positive,positive,positive,positive,positive,positive
507019428,This is outside of scope for how FaceSwap is meant to be run. It monitors the terminal for keypresses. You are welcome to raise a PR for background running as long as it is correctly detected/handled.,outside scope meant run terminal welcome raise background running long correctly,issue,negative,positive,positive,positive,positive,positive
507019349,"Loss prints to console. This works for 99% of use cases. I cannot test this on a cloud server, but you are welcome to raise a PR to fix.

Alternatively you can use tensorboard to view the logs",loss console work use test cloud server welcome raise fix alternatively use view,issue,negative,positive,positive,positive,positive,positive
506907579,"Ah, ok :) Let's close this pull request then - if I still encounter problems with the newer version, I'll open a new one.

Thanks a lot!",ah let close pull request still encounter version open new one thanks lot,issue,negative,positive,positive,positive,positive,positive
506907043,"Oh. Things have moved on a bit. Sorry. @torzdf has updated to TF1.13 and bumped the Python versions.

You may need to review what is still required",oh bit sorry python may need review still,issue,negative,negative,negative,negative,negative,negative
506906704,"Fair enough, I did notice problems with logging, but didn't understand that the cause is Python version. I'll remove the first part of the pull request and try to clean-up the second part to make it as reliable as I can.

Thanks a lot!",fair enough notice logging understand cause python version remove first part pull request try second part make reliable thanks lot,issue,positive,positive,positive,positive,positive,positive
506817446,This issue should be fixed in latest commit,issue fixed latest commit,issue,negative,positive,positive,positive,positive,positive
506809099,"Actually, this looks like a bug.... Will push a potential fix shortly.",actually like bug push potential fix shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
506807579,There was an error reading from the Nvidia Machine Learning Library. The most likely cause is incorrectly installed drivers. Please remove and reinstall your Nvidia drivers.,error reading machine learning library likely cause incorrectly please remove reinstall,issue,negative,neutral,neutral,neutral,neutral,neutral
506803202,"That check shouldn't run if you run in Conda

An example output from running in a Conda environment:
```
WARNING Running without root/admin privileges
INFO    The tool provides tips for installation
        and installs required python packages
INFO    Setup in Windows 10
INFO    Installed Python: 3.6.8 64bit
INFO    Running in Conda
```
Note the last line in the example.

Please could you open up an Anaconda Prompt. Enter your faceswap environment and post the output of this:
```bash
python -c ""import sys ; print(sys.version.lower()) ; print('conda' in sys.version.lower())""
```",check run run example output running environment warning running without tool installation python setup python bit running note last line example please could open anaconda prompt enter environment post output bash python import print print,issue,negative,neutral,neutral,neutral,neutral,neutral
506656904,"We do not directly support Colab. You are best off looking for help in this repo:
https://github.com/seranus/faceswap-notebooks/blob/master/faceswap_trainer.ipynb

",directly support best looking help,issue,positive,positive,positive,positive,positive,positive
506588171,"I try to run it on colab and met some trouble, Here is my [colab](https://colab.research.google.com/drive/18h5xYp4WBgl50OXhr98I70OwuEzIkG0H), but it can't work, can you hava some help?",try run met trouble ca work help,issue,negative,negative,negative,negative,negative,negative
506467155,"I have just this minute update INSTALL.md. It is recommended to use Conda for your faceswap environment, as it removes the requirement to manually install Cuda and cuDNN.
",minute update use environment requirement manually install,issue,negative,neutral,neutral,neutral,neutral,neutral
506250926,"We can't just comment out that line as it is required (Nvidia is our primary userbaser)

Please could you provide the traceback + crash report that is created when this code is run so that we can correctly handle the init failure in your use case",ca comment line primary please could provide crash report code run correctly handle failure use case,issue,negative,positive,neutral,neutral,positive,positive
506227280,"To work around, I have to comment out following lines within lib\gpu_stats.py
```
    def initialize(self, log=False):
        """""" Initialize pynvml """"""
        if not self.initialized:
            if K.backend() == ""plaidml.keras.backend"":
                loglevel = ""INFO""
                if self.logger:
                    self.logger.debug(""plaidML Detected. Using plaidMLStats"")
                    loglevel = self.logger.getEffectiveLevel()
                self.plaid = plaidlib(loglevel=loglevel, log=log)
            elif IS_MACOS:
                if self.logger:
                    self.logger.debug(""macOS Detected. Using pynvx"")
                try:
                    pynvx.cudaInit()
                except RuntimeError:
                    self.initialized = True
                    return
            else:
                try:
                    if self.logger:
                        self.logger.debug(""OS is not macOS. Using pynvml"")
                    # pynvml.nvmlInit()  # ------------------------------ commented out
                except (pynvml.NVMLError_LibraryNotFound,  # pylint: disable=no-member
                        pynvml.NVMLError_DriverNotLoaded,  # pylint: disable=no-member
                        pynvml.NVMLError_NoPermission) as err:  # pylint: disable=no-member
                    if plaidlib is not None:
                        self.plaid = plaidlib(log=log)
                    else:
                        raise err
            self.initialized = True
            self.get_device_count()
            self.get_active_devices()
            self.get_handles()

    def shutdown(self):
        """""" Shutdown pynvml """"""
        if self.initialized:
            self.handles = None
            if not IS_MACOS and not self.plaid:
                pynvml.nvmlShutdown()
            self.initialized = False

    def get_device_count(self):
        """""" Return count of Nvidia devices """"""
        if self.plaid is not None:
            self.device_count = self.plaid.device_count
        elif IS_MACOS:
            self.device_count = pynvx.cudaDeviceGetCount(ignore=True)
        else:
            try:
                self.device_count = 0  # pynvml.nvmlDeviceGetCount()  # ------- commented out
            except pynvml.NVMLError:
                self.device_count = 0
        if self.logger:
            self.logger.debug(""GPU Device count: %s"", self.device_count)
```",work around comment following within initialize self initialize try except true return else try o except err none else raise err true shutdown self shutdown none false self return count none else try except device count,issue,positive,positive,neutral,neutral,positive,positive
505764141,Loss is displayed in the console when training.,loss displayed console training,issue,negative,neutral,neutral,neutral,neutral,neutral
505737971,"The issue you linked could definitely be related.
I think you have two different plaidml versions installed.
You could check this maybe by running
```
import plaidml
plaidml.__version__
```
in your venv. and additionally check if `/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/plaidm/op.py` has the `extract_image_patches` function/variable. If not that is indeed an old plaidml version.

You could try to undo your manual changes, force a new plaidml and plaidml-keras install and, if required, redo the linked fix.

But besides that and if my assumption is correct that is nothing where we can really help, sorry.",issue linked could definitely related think two different could check maybe running import additionally check indeed old version could try undo manual force new install redo linked fix besides assumption correct nothing really help sorry,issue,negative,negative,neutral,neutral,negative,negative
505727706,"Here is the plaidml-setup results, and I am using the AMD Radeon VII (Metal) to train as I type this. 

```
(plaidml) 22:09:29 ~/Local/Workspace/faceswap $ plaidml-setup

PlaidML Setup (0.6.1)

Thanks for using PlaidML!

Some Notes:
  * Bugs and other issues: https://github.com/plaidml/plaidml
  * Questions: https://stackoverflow.com/questions/tagged/plaidml
  * Say hello: https://groups.google.com/forum/#!forum/plaidml-dev
  * PlaidML is licensed under the Apache License 2.0
 
Default Config Devices:
   metal_intel(r)_iris(tm)_graphics_6100.0 : Intel(R) Iris(TM) Graphics 6100 (Metal)
   metal_amd_radeon_vii.0 : AMD Radeon VII (Metal)

Experimental Config Devices:
   llvm_cpu.0 : CPU (LLVM)
   opencl_cpu.0 : Intel CPU (OpenCL)
   opencl_intel_iris(tm)_graphics_6100.0 : Intel Inc. Intel(R) Iris(TM) Graphics 6100 (OpenCL)
   opencl_amd_radeon_vii_compute_engine.0 : AMD AMD Radeon VII Compute Engine (OpenCL)
   metal_intel(r)_iris(tm)_graphics_6100.0 : Intel(R) Iris(TM) Graphics 6100 (Metal)
   metal_amd_radeon_vii.0 : AMD Radeon VII (Metal)

Using experimental devices can cause poor performance, crashes, and other nastiness.

Enable experimental device support? (y,n)[n]:
```

Here is the output when I start training, which is also a bit strange. As you can see it says ""Using GPU: []"" but then later shows ""Opening device ""metal_amd_radeon_vii.0"""".

```
06/25/2019 22:15:25 INFO     Log level set to: INFO
06/25/2019 22:15:25 INFO     Setting up for PlaidML
06/25/2019 22:15:25 INFO     Using GPU: []
06/25/2019 22:15:25 INFO     Successfully set up for PlaidML
Using plaidml.keras.backend backend.
06/25/2019 22:15:31 INFO     Model A Directory: /Users/hero/Local/Workspace/faceswap/facesA
06/25/2019 22:15:31 INFO     Model B Directory: /Users/hero/Local/Workspace/faceswap/facesB
06/25/2019 22:15:31 INFO     Training data directory: /Users/hero/Local/Workspace/faceswap/model
06/25/2019 22:15:31 INFO     ===================================================
06/25/2019 22:15:31 INFO       Starting
06/25/2019 22:15:31 INFO       Using live preview
06/25/2019 22:15:31 INFO       Press 'ENTER' to save and quit
06/25/2019 22:15:31 INFO       Press 'S' to save model weights immediately
06/25/2019 22:15:31 INFO     ===================================================
06/25/2019 22:15:32 INFO     Loading data, this may take a while...
06/25/2019 22:15:32 INFO     Loading Model from Villain plugin...
06/25/2019 22:15:34 INFO     Using configuration saved in state file
06/25/2019 22:15:34 INFO     Opening device ""metal_amd_radeon_vii.0""
06/25/2019 22:15:37 INFO     Opening device ""metal_amd_radeon_vii.0""
```

I've verified the amd gpu is actually being used by watching its processor and memory usage. The training speed seems to be about what I expect. I was having [this](https://github.com/plaidml/plaidml/issues/245#issuecomment-502730000) issue earlier and fixed it so maybe it's related?

",metal train type setup thanks say hello licensed apache license default iris graphic metal metal experimental iris graphic compute engine iris graphic metal metal experimental cause poor performance nastiness enable experimental device support output start training also bit strange see later opening device log level set setting successfully set model directory model directory training data directory starting live preview press save quit press save model immediately loading data may take loading model villain configuration saved state file opening device opening device actually used watching processor memory usage training speed expect issue fixed maybe related,issue,positive,positive,neutral,neutral,positive,positive
505718710,"I did read your log again and it seems plaidml doesn't detect any gpu on your system.
I have no clue why it would work after you replaced the plaidml_utils.py and losses.py without changing your installed plaidml version to be honest.

But can you please run
`plaidml-setup` and post the result in here ?

And just to make sure: You have an AMD GPU ?",read log detect system clue would work without version honest please run post result make sure,issue,negative,positive,positive,positive,positive,positive
505675018,"@learning2makethings
It is in plaidml==0.6.1 which you seem to have.
~So they might have build the wrong release for mac os.~
Just to be sure can you try to update it anyway:

`pip install -U --force-reinstall plaidml==0.6.1 plaidml-keras==0.6.1`",seem might build wrong release mac sure try update anyway pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
505672486,"What release of plaidml does this require? For reference it's my first time using faceswap so it's highly likely I made a mistake elsewhere. I installed plaidml with pip, without picking a version and I couldn't train without getting the error:
```
ImportError: cannot import name 'extract_image_patches' from 'plaidml.op'
```

I went back and used the old versions of plaidml_utils.py and losses.py that had the needed functions built in and it worked fine. Appreciate the work you guys put in, thanks!

Crash Report
```
06/25/2019 17:19:11 MainProcess     MainThread      plaidml_tools   load_active_devices       DEBUG    Setting PlaidML devices from user_settings
06/25/2019 17:19:11 MainProcess     MainThread      plaidml_tools   setup_plaidml             INFO     Using GPU: []
06/25/2019 17:19:11 MainProcess     MainThread      plaidml_tools   setup_plaidml             INFO     Successfully set up for PlaidML
06/25/2019 17:19:11 MainProcess     MainThread      cli             setup_amd                 DEBUG    setup up for PlaidML
06/25/2019 17:19:12 MainProcess     MainThread      cli             test_for_tf_version       DEBUG    Installed Tensorflow Version: 1.13
06/25/2019 17:19:12 MainProcess     MainThread      train           __init__                  DEBUG    Initializing Train: (args: Namespace(alignments_path_a=None, alignments_path_b=None, allow_growth=False, amd=True, augment_color=False, batch_size=32, configfile=None, func=<bound method ScriptExecutor.execute_script of <lib.cli.ScriptExecutor object at 0x10c3a8978>>, gpus=1, input_a='/Users/hero/Local/Workspace/faceswap/faces_out', input_b='/Users/hero/Local/Workspace/faceswap/goal_out', iterations=1000000, logfile=None, loglevel='INFO', memory_saving_gradients=False, model_dir='/Users/hero/Local/Workspace/faceswap/model', no_flip=False, no_logs=False, pingpong=False, preview=False, preview_scale=50, redirect_gui=False, save_interval=100, snapshot_interval=25000, timelapse_input_a=None, timelapse_input_b=None, timelapse_output=None, trainer='dfaker', warp_to_landmarks=False, write_image=False)
06/25/2019 17:19:12 MainProcess     MainThread      train           get_images                DEBUG    Getting image paths
06/25/2019 17:19:12 MainProcess     MainThread      utils           get_image_paths           DEBUG    Scanned Folder contains 57 files
06/25/2019 17:19:12 MainProcess     MainThread      utils           get_image_paths           DEBUG    Returning 55 images
06/25/2019 17:19:12 MainProcess     MainThread      utils           get_image_paths           DEBUG    Scanned Folder contains 413 files
06/25/2019 17:19:12 MainProcess     MainThread      utils           get_image_paths           DEBUG    Returning 411 images
06/25/2019 17:19:12 MainProcess     MainThread      train           get_images                INFO     Model A Directory: /Users/hero/Local/Workspace/faceswap/faces_out
06/25/2019 17:19:12 MainProcess     MainThread      train           get_images                INFO     Model B Directory: /Users/hero/Local/Workspace/faceswap/goal_out
06/25/2019 17:19:12 MainProcess     MainThread      train           get_images                DEBUG    Got image paths: [('a', '55 images'), ('b', '411 images')]
06/25/2019 17:19:12 MainProcess     MainThread      train           __init__                  DEBUG    Initialized Train
06/25/2019 17:19:12 MainProcess     MainThread      train           process                   DEBUG    Starting Training Process
06/25/2019 17:19:12 MainProcess     MainThread      train           process                   INFO     Training data directory: /Users/hero/Local/Workspace/faceswap/model
06/25/2019 17:19:12 MainProcess     MainThread      utils           set_system_verbosity      DEBUG    System Verbosity level: 2
06/25/2019 17:19:12 MainProcess     MainThread      train           start_thread              DEBUG    Launching Trainer thread
06/25/2019 17:19:12 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initializing MultiThread: (target: 'training', thread_count: 1)
06/25/2019 17:19:12 MainProcess     MainThread      multithreading  __init__                  DEBUG    Initialized MultiThread: 'training'
06/25/2019 17:19:12 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread(s): 'training'
06/25/2019 17:19:12 MainProcess     MainThread      multithreading  start                     DEBUG    Starting thread 1 of 1: 'training_0'
06/25/2019 17:19:12 MainProcess     MainThread      multithreading  start                     DEBUG    Started all threads 'training': 1
06/25/2019 17:19:12 MainProcess     MainThread      train           start_thread              DEBUG    Launched Trainer thread
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   DEBUG    Launching Monitor
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   INFO     ===================================================
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   INFO       Starting
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   INFO       Press 'ENTER' to save and quit
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   INFO       Press 'S' to save model weights immediately
06/25/2019 17:19:12 MainProcess     MainThread      train           monitor                   INFO     ===================================================
06/25/2019 17:19:13 MainProcess     training_0      train           training                  DEBUG    Commencing Training
06/25/2019 17:19:13 MainProcess     training_0      train           training                  INFO     Loading data, this may take a while...
06/25/2019 17:19:13 MainProcess     training_0      train           load_model                DEBUG    Loading Model
06/25/2019 17:19:13 MainProcess     training_0      utils           get_folder                DEBUG    Requested path: '/Users/hero/Local/Workspace/faceswap/model'
06/25/2019 17:19:13 MainProcess     training_0      utils           get_folder                DEBUG    Returning: '/Users/hero/Local/Workspace/faceswap/model'
06/25/2019 17:19:13 MainProcess     training_0      plugin_loader   _import                   INFO     Loading Model from Dfaker plugin...
06/25/2019 17:19:14 MainProcess     training_0      multithreading  run                       DEBUG    Error in thread (training_0): cannot import name 'extract_image_patches' from 'plaidml.op' (/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/plaidml/op.py)
06/25/2019 17:19:14 MainProcess     MainThread      train           monitor                   DEBUG    Thread error detected
06/25/2019 17:19:14 MainProcess     MainThread      train           monitor                   DEBUG    Closed Monitor
06/25/2019 17:19:14 MainProcess     MainThread      train           end_thread                DEBUG    Ending Training thread
06/25/2019 17:19:14 MainProcess     MainThread      train           end_thread                CRITICAL Error caught! Exiting...
06/25/2019 17:19:14 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'training'
06/25/2019 17:19:14 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'training_0'
06/25/2019 17:19:14 MainProcess     MainThread      multithreading  join                      ERROR    Caught exception in thread: 'training_0'
06/25/2019 17:19:14 MainProcess     MainThread      plaidml_tools   initialize                DEBUG    PlaidML already initialized
06/25/2019 17:19:14 MainProcess     MainThread      plaidml_tools   get_supported_devices     DEBUG    []
06/25/2019 17:19:14 MainProcess     MainThread      plaidml_tools   get_all_devices           DEBUG    Experimental Devices: []
06/25/2019 17:19:14 MainProcess     MainThread      plaidml_tools   get_all_devices           DEBUG    []
06/25/2019 17:19:14 MainProcess     MainThread      plaidml_tools   __init__                  DEBUG    Initialized: PlaidMLStats
Traceback (most recent call last):
  File ""/Users/hero/Local/Workspace/faceswap/lib/cli.py"", line 124, in execute_script
    process.process()
  File ""/Users/hero/Local/Workspace/faceswap/scripts/train.py"", line 98, in process
    self.end_thread(thread, err)
  File ""/Users/hero/Local/Workspace/faceswap/scripts/train.py"", line 123, in end_thread
    thread.join()
  File ""/Users/hero/Local/Workspace/faceswap/lib/multithreading.py"", line 460, in join
    raise thread.err[1].with_traceback(thread.err[2])
  File ""/Users/hero/Local/Workspace/faceswap/lib/multithreading.py"", line 390, in run
    self._target(*self._args, **self._kwargs)
  File ""/Users/hero/Local/Workspace/faceswap/scripts/train.py"", line 149, in training
    raise err
  File ""/Users/hero/Local/Workspace/faceswap/scripts/train.py"", line 137, in training
    model = self.load_model()
  File ""/Users/hero/Local/Workspace/faceswap/scripts/train.py"", line 156, in load_model
    model = PluginLoader.get_model(self.trainer_name)(
  File ""/Users/hero/Local/Workspace/faceswap/plugins/plugin_loader.py"", line 26, in get_model
    return PluginLoader._import(""train.model"", name, disable_logging)
  File ""/Users/hero/Local/Workspace/faceswap/plugins/plugin_loader.py"", line 47, in _import
    module = import_module(mod)
  File ""/Users/hero/Local/Workspace/faceswap/plaidml/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""/Users/hero/Local/Workspace/faceswap/plugins/train/model/dfaker.py"", line 10, in <module>
    from .original import logger, Model as OriginalModel
  File ""/Users/hero/Local/Workspace/faceswap/plugins/train/model/original.py"", line 10, in <module>
    from ._base import ModelBase, logger
  File ""/Users/hero/Local/Workspace/faceswap/plugins/train/model/_base.py"", line 23, in <module>
    from lib.model.losses import DSSIMObjective, PenalizedLoss
  File ""/Users/hero/Local/Workspace/faceswap/lib/model/losses.py"", line 18, in <module>
    from plaidml.op import extract_image_patches
ImportError: cannot import name 'extract_image_patches' from 'plaidml.op' (/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/plaidml/op.py)

============ System Information ============
encoding:            UTF-8
git_branch:          master
git_commits:         e2ed465 Fix typo. 9265b64 GUI Fixups. 529743a AMD Support - Merge pull request #774 from deepfakes/plaidml. e6653dd Disable parallel processing when non-amd user uses a Keras extractor + non Keras extractor. f5adc99 AMD Support for Manual Tool
gpu_cuda:            Unsupported OS
gpu_cudnn:           Unsupported OS
gpu_devices:         
gpu_devices_active:  
gpu_driver:          []
gpu_vram:            
os_machine:          x86_64
os_platform:         Darwin-18.6.0-x86_64-i386-64bit
os_release:          18.6.0
py_command:          faceswap.py train -A /Users/hero/Local/Workspace/faceswap/faces_out -B /Users/hero/Local/Workspace/faceswap/goal_out -m /Users/hero/Local/Workspace/faceswap/model -bs 32 -amd -t dfaker
py_conda_version:    N/A
py_implementation:   CPython
py_version:          3.7.3
py_virtual_env:      True
sys_cores:           4
sys_processor:       i386
sys_ram:             Total: 16384MB, Available: 8343MB, Used: 7193MB, Free: 1984MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.8.0
certifi==2019.6.16
cffi==1.12.3
chardet==3.0.4
Click==7.0
colorama==0.4.1
cycler==0.10.0
decorator==4.4.0
enum34==1.1.6
fastcluster==1.1.25
ffmpy==0.2.2
gast==0.2.2
google-pasta==0.1.7
grpcio==1.21.1
h5py==2.9.0
idna==2.8
imageio==2.5.0
imageio-ffmpeg==0.3.0
joblib==0.13.2
Keras==2.2.2
Keras-Applications==1.0.4
Keras-Preprocessing==1.0.2
kiwisolver==1.1.0
Markdown==3.1.1
matplotlib==2.2.2
mock==3.0.5
networkx==2.3
numpy==1.16.2
nvidia-ml-py3==7.352.0
opencv-python==4.1.0.25
pathlib==1.0.1
Pillow==6.0.0
plaidbench==0.6.1
plaidml==0.6.1
plaidml-keras==0.6.1
protobuf==3.8.0
psutil==5.6.3
pycparser==2.19
pynvx==1.0.0
pyparsing==2.4.0
python-dateutil==2.8.0
pytz==2019.1
PyWavelets==1.0.3
PyYAML==5.1.1
requests==2.22.0
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.3.0
six==1.12.0
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
toposort==1.5
tqdm==4.32.2
urllib3==1.25.3
Werkzeug==0.15.4
wrapt==1.11.2
```",release require reference first time highly likely made mistake elsewhere pip without version could train without getting error import name went back used old built worked fine appreciate work put thanks crash report setting successfully set setup version train train bound method object train getting image folder folder train model directory train model directory train got image train train train process starting training process train process training data directory system verbosity level train trainer thread target start starting thread start starting thread start train trainer thread train monitor monitor train monitor train monitor starting train monitor press save quit train monitor press save model immediately train monitor train training training train training loading data may take train loading model path loading model run error thread import name train monitor thread error train monitor closed monitor train ending training thread train critical error caught join joining join joining thread join error caught exception thread initialize already experimental recent call last file line file line process thread err file line file line join raise file line run file line training raise err file line training model file line model file line return name file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import logger model file line module import logger file line module import file line module import import name system information master fix typo support merge pull request disable parallel user extractor non extractor support manual tool unsupported o unsupported o train true total available used free pip,issue,positive,positive,positive,positive,positive,positive
505258330,"@jasonTong68, reboot and close all other programs that might be using GPU memory.  Try training with the Lightweight model instead of the IAE model.      ",close might memory try training lightweight model instead model,issue,negative,neutral,neutral,neutral,neutral,neutral
505248180,"I've turned down the batch size to 2, enabled Ping Pong and Memory Saving Gradients, but it still crashes. However, ResourceExhaustedError does not appear in the crash report now.

Crash report: https://pastebin.com/iSysUfKH",turned batch size ping pong memory saving still however appear crash report crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
505243975,"It is the same issue. You are out of memory.

From the very log you posted:
```
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[64,32,32,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node decoder_b/conv2d_7/BiasAdd-1-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.```",issue memory log posted tensor shape type float allocator node hint want see list add current allocation,issue,negative,neutral,neutral,neutral,neutral,neutral
505242542,"
> [deepfakes/faceswap-playground#283](https://github.com/deepfakes/faceswap-playground/issues/283)

I don't think this is a duplicate of that issue. Changing the batch size does not affect the result either.

The error given is ""FileNotFoundError: [WinError 2] The system cannot find the file specified"", not ""ResourceExhaustedError"" in the issue you mentioned.",think duplicate issue batch size affect result either error given system find file issue,issue,negative,neutral,neutral,neutral,neutral,neutral
504698567,"here you are


On Sat, Jun 22, 2019 at 10:08 PM torzdf <notifications@github.com> wrote:

> We would need the crash report.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/770?email_source=notifications&email_token=AMNPYUOB3PUOKRQVZZR7ESDP32IGJA5CNFSM4H2XPTV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODYKRMHY#issuecomment-504698399>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AMNPYUMEXXUBOEETAES5NJLP32IGJANCNFSM4H2XPTVQ>
> .
>
",sat wrote would need crash report thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
504698399,We would need the crash report.,would need crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
504698292,"How  would I go about fixing the error so it will work properly in the
future?

Many thanks
Nathan L

On Sat, 22 Jun 2019, 9:29 pm torzdf, <notifications@github.com> wrote:

>
>    1. We would need the crash report.
>    2. This is a CUDA error. Not a Faceswap error
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/770?email_source=notifications&email_token=AMNPYUJVQQPC4NX5FQVLSV3P32DTRA5CNFSM4H2XPTV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODYKQZ3Y#issuecomment-504696047>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AMNPYUKCQG42UVDBWDUPGHDP32DTRANCNFSM4H2XPTVQ>
> .
>
",would go fixing error work properly future many thanks sat wrote would need crash report error error thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
504696047,"1) We would need the crash report.
2) This is a CUDA error. Not a Faceswap error",would need crash error error,issue,negative,neutral,neutral,neutral,neutral,neutral
504686213,"I've split this off to a new plaidML branch as there are still a few bugs I'm finding around the plaidML implementation (logging on extract etc.), and I want to be able to fix those with this in place.

I will merge the branch directly back to staging to ensure that you maintain your contrib status.

Good work. Works great on my test AMD rig. Still need to do some testing on Nvidia platform.",split new branch still finding around implementation logging extract want able fix place merge branch directly back staging ensure maintain status good work work great test rig still need testing platform,issue,positive,positive,positive,positive,positive,positive
504673501,"Sorry for the delay.
I also changed the ""Using GPU:"" log output in plaidml_tools to output the device ids again instead of the index. Hope that was ok.",sorry delay also log output output device instead index hope,issue,negative,negative,negative,negative,negative,negative
504651103,"I have added a `supports_plaidml` flag that defaults to False for extract plugins. You may want to push a change to your initialization script to set it to True. I will then check out this PR and see about getting it integrated asap.

Want to close the book on plaidML support",added flag false extract may want push change script set true check see getting want close book support,issue,positive,negative,neutral,neutral,negative,negative
504488873,"I'm guessing that the original was actually 30fps not 25fps which is the cause of your problem.  When you encode a new video you need to match the original's framerate.

Please don't post issues on this repo if they're not about the code if the repo.  You can go to faceswap-playground or the discord for issues like this.",guessing original actually cause problem encode new video need match original please post code go discord like,issue,negative,positive,positive,positive,positive,positive
504391734,"```06/21/2019 11:40:53 MainProcess     MainThread      logger          log_setup                 INFO     Log level set to: INFO
06/21/2019 11:40:53 MainProcess     MainThread      cli             execute_script            DEBUG    Executing: extract. PID: 1656
06/21/2019 11:41:02 MainProcess     MainThread      cli             test_for_tf_version       DEBUG    Installed Tensorflow Version: 1.14
06/21/2019 11:41:02 MainProcess     MainThread      extract         __init__                  DEBUG    Initializing Extract: (args: Namespace(align_eyes=False, aligner='fan', alignments_path=None, blur_thresh=0.0, configfile=None, debug_landmarks=False, detector='mtcnn', extract_every_n=1, filter=None, func=<bound method ScriptExecutor.execute_script of <lib.cli.ScriptExecutor object at 0x000001E80862FCC0>>, input_dir='C:\\Users\\Raj\\Desktop\\inputFacesAime\\P6210490.mp4.MOV', logfile=None, loglevel='INFO', min_size=0, nfilter=None, normalization='none', output_dir='C:\\Users\\Raj\\Desktop\\OutputFacesAime', redirect_gui=False, ref_threshold=0.4, rotate_images=None, save_interval=0, serializer='json', singleprocess=False, size=256, skip_existing=False, skip_faces=False)
06/21/2019 11:41:02 MainProcess     MainThread      utils           set_system_verbosity      DEBUG    System Verbosity level: 2
06/21/2019 11:41:02 MainProcess     MainThread      utils           get_folder                DEBUG    Requested path: 'C:\Users\Raj\Desktop\OutputFacesAime'
06/21/2019 11:41:02 MainProcess     MainThread      utils           get_folder                DEBUG    Returning: 'C:\Users\Raj\Desktop\OutputFacesAime'
06/21/2019 11:41:02 MainProcess     MainThread      extract         __init__                  INFO     Output Directory: C:\Users\Raj\Desktop\OutputFacesAime
06/21/2019 11:41:02 MainProcess     MainThread      fsmedia         __init__                  DEBUG    Initializing Images
06/21/2019 11:41:02 MainProcess     MainThread      fsmedia         check_input_folder        INFO     Input Directory: C:\Users\Raj\Desktop\inputFacesAime\P6210490.mp4.MOV
Traceback (most recent call last):
  File ""C:\Users\Raj\faceeswap\lib\cli.py"", line 113, in execute_script
    process = script(arguments)
  File ""C:\Users\Raj\faceeswap\scripts\extract.py"", line 30, in __init__
    self.images = Images(self.args)
  File ""C:\Users\Raj\faceeswap\scripts\fsmedia.py"", line 140, in __init__
    self.input_images = self.get_input_images()
  File ""C:\Users\Raj\faceeswap\scripts\fsmedia.py"", line 173, in get_input_images
    input_images = get_image_paths(self.args.input_dir)
  File ""C:\Users\Raj\faceeswap\lib\utils.py"", line 54, in get_image_paths
    dir_scanned = sorted(os.scandir(directory), key=lambda x: x.name)
NotADirectoryError: [WinError 267] Nom de répertoire non valide: 'C:\\Users\\Raj\\Desktop\\inputFacesAime\\P6210490.mp4.MOV'
```",logger log level set extract version extract extract bound method object system verbosity level path extract output directory input directory recent call last file line process script file line file line file line file line sorted directory de non,issue,negative,neutral,neutral,neutral,neutral,neutral
504368337,It may be a capitalization issue. If you give me the crash_report I can look to bugfix,may capitalization issue give look,issue,negative,neutral,neutral,neutral,neutral,neutral
503973379,"This is a better discussion for either the discord server, or faceswap-playground.",better discussion either discord server,issue,negative,positive,positive,positive,positive,positive
502495642,"The last issue was a special character creeping into the default config. Fixed some time ago. The first issue is a non utf-8 keypress of some description, but not something that can be easily fixed.",last issue special character creeping default fixed time ago first issue non description something easily fixed,issue,positive,positive,positive,positive,positive,positive
502080220,This has been deprecated and parallel processing is on by default. I will update the output message.,parallel default update output message,issue,negative,neutral,neutral,neutral,neutral,neutral
501943564,"ok, thank you.   i use the newest installer i think everything is ok when i finish...",thank use installer think everything finish,issue,negative,neutral,neutral,neutral,neutral,neutral
501751603,"cuDNN didn't initialize because it can't find your GPU. Check your drivers. This is a system issue, not a Faceswap Issue.",initialize ca find check system issue issue,issue,negative,neutral,neutral,neutral,neutral,neutral
501515775,"> Logging in tf1.13.1 is now supported.

Confirmed from local compiled version of tf1.13.1. ",logging confirmed local version,issue,negative,positive,positive,positive,positive,positive
501473075,"Thanks, the answer is clear.
Do you know of any other service where I could run the setup? 
Maybe only on a VPS? 
Or Maybe with a docker image: the script could run from the `.dockerfile`",thanks answer clear know service could run setup maybe maybe docker image script could run,issue,positive,positive,positive,positive,positive,positive
501463729,"I thought most issues had now been resolved? I'll re-review.

The biggest barrier is getting the location of cuDNN, as Nvidia/various OSes seem to move that around at will. Executing nvcc -V gets the CUDA version across systems, but doesn't support multi-CUDAs... but covering it all off across all OSes is next to impossible.

I'm glad you made the script. It's been a big help, and it probably works fine in 99% of cases. As most users now use the installer, it's fully automated for Conda environments, with no other downloads required.",thought resolved biggest barrier getting location seem move around version across support covering across next impossible glad made script big help probably work fine use installer fully,issue,positive,positive,neutral,neutral,positive,positive
501457380,"I regretted making the stupid script. Too buggy to keep up with  the changes.
@torzdf do you have any thought about the situation in issues list that nearly half open issues are about setup.py? a way to improve the situation. like switching to another env setup solution.",making stupid script buggy keep thought situation list nearly half open way improve situation like switching another setup solution,issue,positive,negative,negative,negative,negative,negative
501455995,"Google colab is not directly supported, so we're unlikely to put in options to support this.

It *can* be run unattended if run in a conda environment by passing `--installer` and optionally `--gpu` if the tf-gpu version is required. This is an undocumented feature to support the Windows installer.",directly unlikely put support run unattended run environment passing installer optionally version undocumented feature support installer,issue,positive,negative,negative,negative,negative,negative
501454810,This is never an unattended script since it requires manual os dependencies installation as well as cuda/cudnn inatallation.,never unattended script since manual o installation well,issue,negative,neutral,neutral,neutral,neutral,neutral
501296678,"This area is for reporting bugs in the code, not for tutorials on how to use the program.  Post questions in faceswap playground, or visit the discord server.",area code use program post playground visit discord server,issue,negative,neutral,neutral,neutral,neutral,neutral
501293215,"@gessyoo Thanks for your reply, and the small sample is one problem, another one may be the model building. I am not sure if the model building is okay. Do you have any console snapshot of model building which ended successfully? if you do, can you show me here?",thanks reply small sample one problem another one may model building sure model building console snapshot model building ended successfully show,issue,positive,positive,positive,positive,positive,positive
501285236,"@Royalways, you need to train with a much larger data set (500 to 3,000 images) and you need to train the model longer (days of training, 24 to 48 hours or more). ",need train much data set need train model longer day training,issue,negative,positive,positive,positive,positive,positive
501149060,"Didn't see closed the closed issues regarding OpenCL, this can be closed.",see closed closed regarding closed,issue,negative,negative,negative,negative,negative,negative
501082381,"Sure. Sounds like the better idea actually (Means a bunch of duplicated code tho, but i guess that's fine).
Gotta love the plugin system.",sure like better idea actually bunch code tho guess fine got ta love system,issue,positive,positive,positive,positive,positive,positive
501068982,Could you put this in as a separate plugin please? (fan_plaidml or fan_amd maybe). I'd rather have the separation in case of changes/running into issues down the line.,could put separate please maybe rather separation case line,issue,negative,neutral,neutral,neutral,neutral,neutral
500888099,"Cuda 10 is workable but may require extra troubleshooting and work.  This may include a custom compiled tensorflow (though i believe that a working cuda 10 version is compiled).  You may also lose graphing due to changes in how tensor works in newer versions.  For beginners we recommend cuda 9 as installed by the installer.  We intend to migrate to cuda 10 in the future, but it's just started becoming usable.",workable may require extra work may include custom though believe working version may also lose due tensor work recommend installer intend migrate future becoming usable,issue,negative,positive,neutral,neutral,positive,positive
500609058,"Yes, as @kilroythethird says we will not lift the python 3.6 requirement until we can get Keras Tensorboard logging to play nice with Tensorflow 1.13.1. Also, TF 1.12 is faster than TF 1.13.

I will be revisiting the TF 1.13 issue again soon, as it is currently a barrier to RTX users.

I'm happy to add any further checks for Cuda/cuDNN (it is a pain in the ass to detect. Especially cuDNN), but please either remove the check for Python 3.7 or add in an additional check that TF 1.13 is being run in conjunction with Python 3.7",yes lift python requirement get logging play nice also faster issue soon currently barrier happy add pain as detect especially please either remove check python add additional check run conjunction python,issue,positive,positive,positive,positive,positive,positive
500563809,"On my last system where i used py3.7 there where no wheels for tensorflow 1.12.* for python 3.7, only for py <= 3.6.
And while faceswap runs with tensorflow 1.14.* the graphs in the GUI won't work with that version due to changes in tensorboard.
This might have changed, so just a heads up that this could potential lead to problems.
*You could ofc. always compile tensorflow 1.12 for py > 3.6*",last system used python wo work version due might could potential lead could always compile,issue,negative,negative,neutral,neutral,negative,negative
500115474,"None of the extractors are written in Keras. They are written in source Tensorflow, so PlaidML is unlikely to pick them up.

We do not directly support PlaidML at this time, unfortunately.",none written written source unlikely pick directly support time unfortunately,issue,negative,negative,negative,negative,negative,negative
499918020,"I had pulled the latest code to a new directory and still had this error.  I fixed by modifying the command for executing like:
docker exec -e LC_ALL=C.UTF-8 deepfakes-gpu python3 /srv/faceswap.py gui",latest code new directory still error fixed command like docker python,issue,negative,positive,positive,positive,positive,positive
499029689,"I used python3.7.3,must be use python3.6?",used python must use python,issue,negative,neutral,neutral,neutral,neutral,neutral
499028652,Almost definitely a conflict with a pre-installed python version. Check your environment and system installed pythons.,almost definitely conflict python version check environment system,issue,negative,neutral,neutral,neutral,neutral,neutral
498996894,"OOM = Out of Memory.
You will not be able to train RealFace on a 4GB card.",memory able train card,issue,negative,positive,positive,positive,positive,positive
498804075,"```
============ System Information ============
encoding:            cp1251
git_branch:          master
git_commits:         081da3c Merge branch 'master' into staging
gpu_cuda:            10.0
gpu_cudnn:           7.4.1
gpu_devices:         GPU_0: GeForce GTX 1050 Ti
gpu_devices_active:  GPU_0
gpu_driver:          417.01
gpu_vram:            GPU_0: 4096MB
os_machine:          AMD64
os_platform:         Windows-10-10.0.15063-SP0
os_release:          10
py_command:          D:\face\faceswap/faceswap.py gui
py_conda_version:    conda 4.6.11
py_implementation:   CPython
py_version:          3.6.8
py_virtual_env:      True
sys_cores:           4
sys_processor:       Intel64 Family 6 Model 94 Stepping 3, GenuineIntel
sys_ram:             Total: 8147MB, Available: 4903MB, Used: 3243MB, Free: 4903MB

=============== Pip Packages ===============
absl-py==0.7.1
aioChatbase==1.0.0
aiodownload==0.2.5
aiogram==1.4
aiohttp==3.4.4
aiohttp-requests==0.1.2
aiourllib==0.1.3
aliexpress-api-client==1.2
args==0.1.0
aspy.yaml==1.1.1
astor==0.7.1
async-timeout==3.0.0
Automat==0.7.0
cached-property==1.5.1
cchardet==2.1.1
certifi==2018.10.15
cfgv==1.1.0
click==6.7
clint==0.5.1
cloudpickle==1.0.0
constantly==15.1.0
contextvars==2.3
cycler==0.10.0
cytoolz==0.9.0.1
dask==1.2.2
decorator==4.4.0
fastcluster==1.1.25
ffmpy==0.2.2
filelock==3.0.9
gast==0.2.2
google==2.0.1
google-search==1.0.2
googletrans==2.3.0
grpcio==1.16.1
h5py==2.9.0
hyperlink==18.0.0
identify==1.1.7
imageio==2.5.0
imageio-ffmpeg==0.3.0
immutables==0.6
incremental==17.5.0
InstagramAPI==1.0.1
joblib==0.13.2
Keras==2.2.4
Keras-Applications==1.0.7
Keras-Preprocessing==1.0.9
kiwisolver==1.1.0
Markdown==3.1
matplotlib==2.2.2
mkl-fft==1.0.12
mkl-random==1.0.2
mkl-service==2.0.2
mock==3.0.5
moviepy==0.2.3.2
networkx==2.3
nodeenv==1.3.2
numpy==1.16.2
nvidia-ml-py3==7.352.0
olefile==0.46
opencv-python==4.1.0.25
outcome==1.0.0
parse==1.8.4
pathlib==1.0.1
Pillow==6.0.0
pluggy==0.8.0
pre-commit==1.11.2
protobuf==3.7.1
psutil==5.4.8
psycopg2==2.7.5
py==1.7.0
PyHamcrest==1.9.0
pymediawiki==0.4.1
pyocclient==0.4
pyparsing==2.4.0
pyreadline==2.1
python-dateutil==2.8.0
python3-weather-api==0.0.3rc0
pytube==9.2.2
pytz==2019.1
PyWavelets==1.0.3
PyYAML==3.13
qiwipy==2.1.4
qrcode==6.1
requests==2.11.1
requests-toolbelt==0.7.0
scikit-image==0.15.0
scikit-learn==0.21.2
scipy==1.2.1
six==1.12.0
sniffio==1.0.0
sortedcontainers==2.0.5
SQLAlchemy==1.2.12
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
tensorflow-gpu==1.13.1
termcolor==1.1.0
toml==0.10.0
toolz==0.9.0
toposort==1.5
tornado==6.0.2
tox==3.5.2
tqdm==4.31.1
translate==3.5.0
trio==0.8.0
unittest-data-provider==1.0.1
urllib3-mock==0.3.3
urllib5==5.0.0
weather-api==1.0.6
Werkzeug==0.15.2
Wikipedia-API==0.3.7
wincertstore==0.2
zope.interface==4.5.0

============== Conda Packages ==============
Could not get package list

```",system information master merge branch staging ti true family model stepping total available used free pip could get package list,issue,positive,positive,positive,positive,positive,positive
498457365,"Yeah, we tend to put it there first, just to prevent anything catastrophic occurring in Master ;)",yeah tend put first prevent anything catastrophic master,issue,negative,positive,positive,positive,positive,positive
498439864,This should now be caught and handled in the latest commit.,caught handled latest commit,issue,negative,positive,positive,positive,positive,positive
498070104,Please post these kind of questions in faceswap playground or the Discord server,please post kind playground discord server,issue,negative,positive,positive,positive,positive,positive
498037167,"No, it definitely doesn't need X to run. You would only need X for displaying the preview and the GUI.

The `self.show` function just compiles the preview image. By setting it to None, obviously nothing gets compiled. But with the -w flag (without the -p flag), it won't try to pop anything to X, it will just write out the image to disk.

There are certainly people in the Discord who run on Google Collab, so I would imagine that AWS would work too, and some people may have done it.",definitely need run would need preview function preview image setting none obviously nothing flag without flag wo try pop anything write image disk certainly people discord run would imagine would work people may done,issue,negative,positive,neutral,neutral,positive,positive
498012219,"ah, see, I don't do the X forwarding. I just ssh through the command line, there is no X at all here :).
I thought I would just scp the preview image when it's written to disk.

So, do you confirm the script absolutely needs a X to run?",ah see forwarding command line thought would preview image written disk confirm script absolutely need run,issue,negative,positive,positive,positive,positive,positive
497980514,"You mean ssh tunneling with x forwarding? Yes it does. Many people run it this way, myself included (from a headless linux box)",mean tunneling forwarding yes many people run way included headless box,issue,negative,positive,neutral,neutral,positive,positive
497975795,"It's definitely not a permission problem. The script would crash on an OSError. Also I can read/write in this folder. Also the image is generated at the very beginning of the process. Writing to the image works.

The code tries to render something at some point. I might try on the discord server later, but I would like a confirmation first that the training works on a remote server with a X server, because I don't think it's specific to AWS.",definitely permission problem script would crash also folder also image beginning process writing image work code render something point might try discord server later would like confirmation first training work remote server server think specific,issue,negative,positive,neutral,neutral,positive,positive
497974734,You may have better luck getting help in the discord server,may better luck getting help discord server,issue,positive,positive,positive,positive,positive,positive
497974685,The file is written to the root of the faceswap folder. This definitely works. It may be a permissions issue on aws which is not directly supported by this project,file written root folder definitely work may issue directly project,issue,negative,positive,neutral,neutral,positive,positive
497974061,You misread the issue. I do use the -w flag. Please re-open.,misread issue use flag please,issue,negative,neutral,neutral,neutral,neutral,neutral
497973876,"This is likely to be a problem somewhere else in your setup. Probably a conflict.

I run: 
fastcluster==1.1.25
opencv-python==4.1.0.25

with zero issues.",likely problem somewhere else setup probably conflict run zero,issue,negative,neutral,neutral,neutral,neutral,neutral
497968025,"This is now either an issue with pyvnx or your setup. I recommend using MiniConda, or contacting the author of pynvx on his github page.

Either way, it's out of scope.",either issue setup recommend author page either way scope,issue,negative,neutral,neutral,neutral,neutral,neutral
497963457,"Thanks for quick reply! I tried the suggestions and got this error: 
```
Cleaning up...
Command /Users/user/.pyenv/versions/3.4.0/bin/python3.4 -c ""import setuptools, tokenize;__file__='/private/var/folders/yw/y2_zx6wd0hq286ccjddngy0m0000gn/T/pip_build_artiumsirchenko/pynvx/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /var/folders/yw/y2_zx6wd0hq286ccjddngy0m0000gn/T/pip-owx06yd6-record/install-record.txt --single-version-externally-managed --compile failed with error code 1 in /private/var/folders/yw/y2_zx6wd0hq286ccjddngy0m0000gn/T/pip_build_artiumsirchenko/pynvx
Storing debug log for failure in /Users/user/.pip/pip.log
```

I suspect its something related to the python version? Have any clue what what it?",thanks quick reply tried got error cleaning command import compile open install record compile error code log failure suspect something related python version clue,issue,negative,positive,neutral,neutral,positive,positive
497963292,"Also fastcluster module has same import problem
Down-grade to fastcluster==1.1.24 (newist is 1.1.25)",also module import problem,issue,negative,neutral,neutral,neutral,neutral,neutral
497635588,"We use opencv for extracting from videos, and it only supports a limited number of codecs. Most likely, it does not support the codec that your mp4 is encoded in.

We may look to change this in future, but in the meantime you should look to use the effmpeg tool to split your video into separate frames.",use limited number likely support may look change future look use tool split video separate,issue,negative,negative,neutral,neutral,negative,negative
497475875,"While yes, torzdf is right.  The short answer is no you can't.  Both are required to train even one-way swaps.",yes right short answer ca train even,issue,negative,positive,positive,positive,positive,positive
497257649,Please raise these kinds of questions in Faceswap Playground or the Discord Server,please raise playground discord server,issue,negative,neutral,neutral,neutral,neutral,neutral
496604362,"OH I see your point - sorry it is about the graphical part - when will the versions be updated so everything works again?
Regards",oh see point sorry graphical part everything work,issue,negative,negative,negative,negative,negative,negative
495919178,"why does the quality improve over time then? 

```
total 641344

24828656 Mai 25 15:43 original_decoder_A.h5
24828656 Mai 22 06:27 original_decoder_A.h5.bk
24828656 Mai 25 15:43 original_decoder_B.h5
24828656 Mai 22 06:27 original_decoder_B.h5.bk
278691560 Mai 25 15:43 original_encoder.h5
278691560 Mai 22 06:27 original_encoder.h5.bk
4096 Mai 18 16:43 original_logs/
8050 Mai 25 15:43 original_state.json
5616 Mai 22 06:27 original_state.json.bk


ll ../deepfake_faceswap/faceswap/xxxl/original_logs/b/session_28/
total 220
4096 Mai 24 08:40 ./
4096 Mai 24 08:40 ../
213129 Mai 24 08:40 events.out.tfevents.1558680006.$(uname -n)

```
",quality improve time total total,issue,negative,neutral,neutral,neutral,neutral,neutral
495912332,You're still missing the point. Not the output. Storing the history doesn't work. ,still missing point output history work,issue,negative,negative,negative,negative,negative,negative
495909907,"works for me tho .. hmm ...
![g](https://user-images.githubusercontent.com/1809702/58368649-1325b580-7ef0-11e9-9625-9eabdf2b7237.png)

i dont use the gui tho except for merging alignment files because the alignments tool is broken as CLI tool",work tho dont use tho except alignment tool broken tool,issue,negative,negative,negative,negative,negative,negative
495908745,"Villain does not need a mask either.

Though it's really memory hungry, I found it's the best model out of all of them.",villain need mask either though really memory hungry found best model,issue,negative,positive,positive,positive,positive,positive
495905746,Not that logging. Loss value logging. IE the graph and tensorboard don't work with tf 1.13,logging loss value logging ie graph work,issue,negative,neutral,neutral,neutral,neutral,neutral
495903572,"Hey,
try it with python 3.7 also maybe in a virtualenv.

Kind Regards

Am Fr., 24. Mai 2019 um 00:27 Uhr schrieb Olivier Gagnon <
notifications@github.com>:

> We don't currently officially support TF 1.13 because there is a
> Tensorboard/Keras callback issue with logging.
>
> @torzdf <https://github.com/torzdf>
> Is that the reason for that error ?
>
> Exception in Tkinter callback
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.6/tkinter/__init__.py"", line 1705, in __call__
>     return self.func(*args)
>   File ""/usr/local/lib/python3.6/tkinter/__init__.py"", line 749, in callit
>     func(*args)
>   File ""/opt/faceswap/lib/gui/display_page.py"", line 245, in <lambda>
>     self.after(waittime, lambda t=waittime: self.update_page(t))
>   File ""/opt/faceswap/lib/gui/display_page.py"", line 244, in update_page
>     self.load_display()
>   File ""/opt/faceswap/lib/gui/display_page.py"", line 256, in load_display
>     self.display_item_process()
>   File ""/opt/faceswap/lib/gui/display_command.py"", line 217, in display_item_process
>     selections=[""raw"", ""trend""])
>   File ""/opt/faceswap/lib/gui/stats.py"", line 343, in __init__
>     self.refresh()
>   File ""/opt/faceswap/lib/gui/stats.py"", line 352, in refresh
>     self.stats = self.get_raw()
>   File ""/opt/faceswap/lib/gui/stats.py"", line 364, in get_raw
>     loss_dict = self.session.total_loss if self.is_totals else self.session.loss
>   File ""/opt/faceswap/lib/gui/stats.py"", line 139, in loss
>     loss_dict = self.tb_logs.get_loss(session=self.session_id)[self.session_id]
>   File ""/opt/faceswap/lib/gui/stats.py"", line 61, in get_loss
>     for event in tf.train.summary_iterator(logfile):
>   File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/summary/summary_iterator.py"", line 68, in summary_iterator
>     for r in tf_record.tf_record_iterator(path):
>   File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/lib/io/tf_record.py"", line 181, in tf_record_iterator
>     reader.GetNext()
>   File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 489, in GetNext
>     return _pywrap_tensorflow_internal.PyRecordReader_GetNext(self)
> tensorflow.python.framework.errors_impl.DataLossError: truncated record at 234295
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/729?email_source=notifications&email_token=AANZ2JW4TWPARJKDXLVBEH3PW4K6NA5CNFSM4HNWLDQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWDVA2Y#issuecomment-495407211>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AANZ2JWGS3MYUEJUNNBAE23PW4K6NANCNFSM4HNWLDQQ>
> .
>
",hey try python also maybe kind um currently officially support issue logging reason error exception recent call last file line return file line file line lambda lambda file line file line file line raw trend file line file line refresh file line else file line loss file line event file line path file line file line return self truncated record thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
495492793,"lol it works for me - with GUI or command line.
```
Keras-Applications==1.0.7
Keras-Preprocessing==1.0.9
tensorflow==1.13.1
tensorflow-estimator==1.13.0
tensorflow-gpu==1.13.1
tensorboard==1.13.1
```
is it only about the log being displayed wrong?
i.e. 
```
05/22/2019 14:49:20 WARNING  From /home/$USER/Projects/devel/deepfake_faceswap/faceswap/faceswap/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.
```
Regards
",work command line log displayed wrong warning removed future instead,issue,negative,negative,negative,negative,negative,negative
494641416,"ValueError: Error: Alignments file not found at /home/wanqi/Desktop/faceswap-master/faces/source/alignments.json

You specified an alignment file that does not exist apparently...
Likely, the Original model is not using a mask in your config file, but all the other models are setup to use a mask and thus need the alignment file.",error file found alignment file exist apparently likely original model mask file setup use mask thus need alignment file,issue,negative,positive,positive,positive,positive,positive
494029827,"> This may be a macos specific issue. Unfortunately I do not currently have a mac to be able to test on.

It's all right, thank you. Indeed and there is no refresh button as you described on Mac. 
If I have spare time, I may dig into this later, never touched X11 Gui before...",may specific issue unfortunately currently mac able test right thank indeed refresh button mac spare time may dig later never touched,issue,negative,positive,positive,positive,positive,positive
494028405,This may be a macos specific issue. Unfortunately I do not currently have a mac to be able to test on.,may specific issue unfortunately currently mac able test,issue,negative,positive,positive,positive,positive,positive
493988249,"> That screengrab shows another crash happening, but there was a bug in sys.info preventing it from showing.
> 
> Try again with latest code.

@torzdf 

checked-out the latest one, re-installed in a blank new environment, graph is still the same as before.
however, system.info is correct this time (no errors).

![sc2](https://user-images.githubusercontent.com/8183249/58025197-8329e980-7b46-11e9-90c8-ce5257992863.jpg)
",another crash happening bug showing try latest code latest one blank new environment graph still however correct time,issue,negative,positive,positive,positive,positive,positive
493958027,"That screengrab shows another crash happening, but there was a bug in sys.info preventing it from showing.

Try again with latest code.",another crash happening bug showing try latest code,issue,negative,positive,positive,positive,positive,positive
493899369,We don't currently officially support TF 1.13 because there is a Tensorboard/Keras callback issue with logging.,currently officially support issue logging,issue,negative,neutral,neutral,neutral,neutral,neutral
493805575,"> It updates every save interval or when the refresh button is pressed.

@torzdf 
I have updated to your latest stats.py i.e. (Bugfix: GUI Analysis - Correctly report iterations and rate)
But still won't refresh every 5 steps. 

![def](https://user-images.githubusercontent.com/8183249/57990386-c9486400-7ad8-11e9-96e5-a8ce59b6355e.jpeg)




",every save interval refresh button latest analysis correctly report rate still wo refresh every,issue,negative,positive,positive,positive,positive,positive
493801111,It updates every save interval or when the refresh button is pressed.,every save interval refresh button,issue,negative,neutral,neutral,neutral,neutral,neutral
493801070,"> Tensorboard/Tensorflow 1.13 is not currently officially supported. The Keras callback for logging on training does not appear to work correctly. Until this is fixed upstream, this is how it will be.
> 
> If you want/need logs, use Tensorflow 1.12

This is not a must for now, I am using console just fine. 
One more thing to mention, even when it was working under 1.12, the graph only showed 2 iterations (of A, B) i.e. 4 points, and not update accordingly. Is this a designed feature or it supposed to tick?",currently officially logging training appear work correctly fixed upstream use must console fine one thing mention even working graph update accordingly designed feature supposed tick,issue,negative,positive,positive,positive,positive,positive
493800218,"Tensorboard/Tensorflow 1.13 is not currently officially supported. The Keras callback for logging on training does not appear to work correctly. Until this is fixed upstream, this is how it will be.

If you want/need logs, use Tensorflow 1.12",currently officially logging training appear work correctly fixed upstream use,issue,negative,positive,neutral,neutral,positive,positive
493799576,"> Is this definitely from a model that has started training? There's no loss records in it, just the graph definition
> ![image](https://user-images.githubusercontent.com/36920800/54219010-88cfd700-44e6-11e9-9540-2d7c773b8c11.png)

I have double checked and is pretty sure all sessions were in it... nevertheless training from new or continued from an old existing, error pops.

./original_logs/a/session_2
./original_logs/a/session_3
./original_logs/a/session_4
./original_logs/a/session_1
./original_logs/a
./original_logs/b/session_2
./original_logs/b/session_3
./original_logs/b/session_4
./original_logs/b/session_1
./original_logs/b

TensorBoard Logging upgration could be the issue.",definitely model training loss graph definition image double checked pretty sure session nevertheless training new continued old error logging could issue,issue,negative,positive,positive,positive,positive,positive
493728450,"  2 May 17 22:18 .recent.json
 cat .recent.json 
[]
got this file, with 2bytes, only an empty list there.

same problem, graph won't show when under training after TF1.12 -> 1.13
tensorflow.python.framework.errors_impl.DataLossError: truncated record at XXX",may cat got file empty list problem graph wo show training truncated record,issue,negative,negative,neutral,neutral,negative,negative
493635734,"Oh i see, I'll just make a pull request with the fix for the users that might prefer to use Faceswap with Docker. Thanks!",oh see make pull request fix might prefer use docker thanks,issue,negative,positive,positive,positive,positive,positive
493632549,"Honestly? None of the primary devs use docker. It is kept around as it's always been there, and we will accept PRs to fix issues, but none of us are likely to fix this.",honestly none primary use docker kept around always accept fix none u likely fix,issue,positive,positive,positive,positive,positive,positive
492653659,"@HobbitArmy  replace [first part of this method](https://github.com/deepfakes/faceswap/blob/b1568824056513d07bd218eae2f04d56148cf60d/setup.py#L432)
with this:
```python
def cudnn_check(self):
        """""" Check Linux or Windows cuDNN Version from cudnn.h """"""
        if self.env.os_version[0] == ""Linux"":
            cudnn_checkfiles = self.cudnn_checkfiles_linux()
        elif self.env.os_version[0] == ""Windows"":
             if self.env.cuda_path == """":
                 cuda_keys = [key
                         for key in os.environ.keys()
                         if key.lower().startswith(""cuda_path_v"")]
                self.env.cuda_path = os.environ[cuda_keys[0]]
            cudnn_checkfiles = self.cudnn_checkfiles_windows()
```

this will check if `self.env.cuda_path` is empty then get it from env

",replace first part method python self check version key key check empty get,issue,negative,positive,neutral,neutral,positive,positive
492558738,"![error](https://user-images.githubusercontent.com/32774415/57760513-487f1600-772e-11e9-9363-35349d0a778b.jpg)
os:Windows10 
Could anybody help, already add cudnn file in correct place; but it just dosen't work.
thanks",error o could anybody help already add file correct place dose work thanks,issue,negative,positive,positive,positive,positive,positive
492188379,"This is a python issue, not a faceswap issue. 

Completely remove all versions of python from your system (Conda/Python). Delete any python/conda files in `C:\users\<username>` and  `C:\users\<username>\roaming` and try to install again.",python issue issue completely remove python system delete try install,issue,negative,positive,neutral,neutral,positive,positive
492010161,I would say that your model has corrupted. This is an h5py error.,would say model corrupted error,issue,negative,neutral,neutral,neutral,neutral,neutral
491841728,"@Enyakk it's like you said `reversed` in a way. The above size are to be expected and it doesn't mean the model is lacking but simply of a different layout.
PS: I am not sure there is such thing as `typical` when i comes to `ae` with models like `villian` which are anything but that.
",like said reversed way size mean model simply different layout sure thing typical come ae like anything,issue,positive,positive,neutral,neutral,positive,positive
491815191,"Can the model still be commented on? I set up the model like this:
Input 96, Output 160, everything else default.

I noticed this results in Decoder B.h5 being 767MB, while encoder being 115MB. In other trainer models the encoder is typically much more complex than the decoder. Can you comment on why Realface is reversed in this fashion?",model still set model like input output everything else default trainer typically much complex comment reversed fashion,issue,negative,negative,negative,negative,negative,negative
491368020,"This is most likely an error specific to you. I would need the full output from the installer, and then the output of a test run of the failing command.

None of Chocolately, Cuda, cuDNN or Python are pre-requisites for running the Faceswap installer.

If you want to install Faceswap in Chocolatey you will need to manually install these components yourself.",likely error specific would need full output installer output test run failing command none python running installer want install need manually install,issue,negative,positive,positive,positive,positive,positive
490719113,"Hello @kvrooman! Thanks for updating this PR. We checked the lines you've touched for [PEP 8](https://www.python.org/dev/peps/pep-0008) issues, and found:





* In the file [`lib/model/layers.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/layers.py):

> [Line 345:20](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/layers.py#L345): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 346:20](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/layers.py#L346): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent
> [Line 347:20](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/layers.py#L347): [E128](https://duckduckgo.com/?q=pep8%20E128) continuation line under-indented for visual indent

* In the file [`lib/model/losses.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py):

> [Line 487:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py#L487): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (118 > 99 characters)
> [Line 488:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py#L488): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (118 > 99 characters)
> [Line 489:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py#L489): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (118 > 99 characters)
> [Line 490:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py#L490): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (118 > 99 characters)
> [Line 491:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/losses.py#L491): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (118 > 99 characters)

* In the file [`lib/model/masks.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py):

> [Line 197:15](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L197): [E271](https://duckduckgo.com/?q=pep8%20E271) multiple spaces after keyword
> [Line 221:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L221): [E303](https://duckduckgo.com/?q=pep8%20E303) too many blank lines (2)
> [Line 254:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L254): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 255:35](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L255): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 262:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L262): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 263:32](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L263): [E261](https://duckduckgo.com/?q=pep8%20E261) at least two spaces before inline comment
> [Line 272:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/model/masks.py#L272): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '



* In the file [`lib/training_data.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py):

> [Line 79:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py#L79): [E306](https://duckduckgo.com/?q=pep8%20E306) expected 1 blank line before a nested definition, found 0
> [Line 92:9](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py#L92): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 95:72](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py#L95): [E231](https://duckduckgo.com/?q=pep8%20E231) missing whitespace after ','
> [Line 284:11](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py#L284): [E114](https://duckduckgo.com/?q=pep8%20E114) indentation is not a multiple of four (comment)
> [Line 284:11](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/lib/training_data.py#L284): [E116](https://duckduckgo.com/?q=pep8%20E116) unexpected indentation (comment)



* In the file [`plugins/convert/mask/box_blend.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/convert/mask/box_blend.py):

> [Line 39:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/convert/mask/box_blend.py#L39): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)

* In the file [`plugins/convert/mask/mask_blend.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/convert/mask/mask_blend.py):

> [Line 55:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/convert/mask/mask_blend.py#L55): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (100 > 99 characters)



* In the file [`plugins/train/model/_base.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/model/_base.py):

> [Line 817:58](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/model/_base.py#L817): [E225](https://duckduckgo.com/?q=pep8%20E225) missing whitespace around operator

















* In the file [`plugins/train/trainer/_base.py`](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py):

> [Line 134:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py#L134): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (102 > 99 characters)
> [Line 162:13](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py#L162): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 163:13](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py#L163): [E265](https://duckduckgo.com/?q=pep8%20E265) block comment should start with '# '
> [Line 168:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py#L168): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (104 > 99 characters)
> [Line 417:100](https://github.com/deepfakes/faceswap/blob/895aaa349e5651c8c5d4a685792af2aa73c00afb/plugins/train/trainer/_base.py#L417): [E501](https://duckduckgo.com/?q=pep8%20E501) line too long (157 > 99 characters)







##### Comment last updated at 2019-07-27 04:51:08 UTC",hello thanks checked touched pep found file line continuation line visual indent line continuation line visual indent line continuation line visual indent file line line long line line long line line long line line long line line long file line multiple line many blank line block comment start line least two comment line block comment start line least two comment line block comment start file line blank line definition found line block comment start line missing line indentation multiple four comment line unexpected indentation comment file line line long file line line long file line missing around operator file line line long line block comment start line block comment start line line long line line long comment last,issue,negative,negative,neutral,neutral,negative,negative
490691114,"Faceswap installer allows you to specify the location. 

Miniconda will default to C:\users\Username. If you don't want it there, then download miniconda separately and install it prior to running faceswap installer.",installer specify location default want separately install prior running installer,issue,negative,neutral,neutral,neutral,neutral,neutral
490406607,This is a bug which was fixed a few days ago. Get latest code.,bug fixed day ago get latest code,issue,negative,positive,positive,positive,positive,positive
490308806,Hi @zy1620454507 ， Can you tell me how to solve this problem? Thanks!,hi tell solve problem thanks,issue,negative,positive,positive,positive,positive,positive
490018935,"There is a windows installer for faceswap and a GUI. I'm not sure how it could be simpler?
https://github.com/deepfakes/faceswap/releases/tag/v0.97.3b

We cannot distribute CUDA/cuDNN as it would be in breach of NVIDIA's license agreement.",installer sure could simpler distribute would breach license agreement,issue,positive,positive,positive,positive,positive,positive
489817047,"Latest version of conda appears to have issues....

I advise removing conda from your system and installing the following version:
https://repo.anaconda.com/miniconda/Miniconda3-4.5.12-Windows-x86_64.exe

Then running Faceswap installer again.
I may look at pinning the conda version until this is resolved upstream.
",latest version advise removing system following version running installer may look pinning version resolved upstream,issue,negative,positive,positive,positive,positive,positive
489514236,"It's an issue with Conda, not faceswap.

See https://github.com/conda/conda/issues/8046 
and 
https://conda.io/projects/conda/en/latest/user-guide/troubleshooting.html#ssl-connection-errors

You should be able to find which case applies to you.",issue see able find case,issue,negative,positive,positive,positive,positive,positive
489014507,OOM = Out of Memory. Lower your batch size,memory lower batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
487827101,@torzdf made some additional linting and error fixes from the additional items that have crept in,made additional error additional crept,issue,negative,neutral,neutral,neutral,neutral,neutral
487733403,"With a video like that, they most likely tracked Jordan Peele's mouth movement and then worked it in with faceswap, and while I'm not exactly sure, in faceswap and deepfakes, syncing audio and video at the same time isn't always possible, which I may be wrong on, but this is what I remember last time from using deepfakes.",video like likely tracked jordan peele mouth movement worked exactly sure audio video time always possible may wrong remember last time,issue,negative,neutral,neutral,neutral,neutral,neutral
487615672,"we can do both. hide the CUDA device in the environment and set the session parameters...as you suggest its probably best to pull the configure_session function out of TRAIN and use it everywhere in train, extract, and convert ( useful for allow_growth or VRAM capping too )

there are some advantages to fine-tuning the CPU process thread variables to the Intel suggested optimized values so it would be good to keep the session config",hide device environment set session suggest probably best pull function train use everywhere train extract convert useful capping process thread would good keep session,issue,positive,positive,positive,positive,positive,positive
487548922,Hopefully fixed by latest commit,hopefully fixed latest commit,issue,positive,positive,positive,positive,positive,positive
487513613,"I think my preference for this would be to make cpu an option for all workflows (extract, train, convert) and to set `os.environ[""CUDA_VISIBLE_DEVICES""] = """"`. I am happy to implement this if you don't want to,",think preference would make option extract train convert set happy implement want,issue,positive,positive,positive,positive,positive,positive
487392243,"Thank you for answer. But, It is hard that python beginer like me update the latest code in  /config/convert.ini.
May I explain more sepcifically? And How can I use fileformat site?",thank answer hard python like update latest code may explain use site,issue,positive,positive,positive,positive,positive,positive
487380061,"Looks like an error in your config file. Specifically a long dash where it should be a short one:
https://www.fileformat.info/info/unicode/char/2013/index.htm

Delete the file `/config/convert.ini`, and pull the latest code.",like error file specifically long dash short one delete file pull latest code,issue,negative,positive,positive,positive,positive,positive
487379986,"Looks like an error in your config file. Specifically you seem to have a long dash where you should have a short one:
https://www.fileformat.info/info/unicode/char/2013/index.htm

Delete the file `/config/convert.ini`, and pull the latest code.",like error file specifically seem long dash short one delete file pull latest code,issue,negative,positive,positive,positive,positive,positive
487289583,"I am also getting similar issue:
UnicodeEncodeError: 'ascii' codec can't encode character '\u2013' in position 158: ordinal not in range(128)

Here is the copy of terminal logs: https://pastebin.com/j4n6suit

I tried with .png and .jpg format but got the same error.",also getting similar issue ca encode character position ordinal range copy terminal tried format got error,issue,negative,neutral,neutral,neutral,neutral,neutral
486279191,"SSD is no longer expensive，just buy one won‘t cost you much, man.",longer buy one cost much man,issue,negative,positive,positive,positive,positive,positive
485783499,"> @kvrooman why it produces so imprecise mask?
> 
> I trained fanseg that produces smooth mask.
> 

@iperov  I haven't been able to work on this recently, but thought I'd point out that the network produces smooths masks natively just like your example above. I purposely binarize them in the post-processing at a certain threshold.

Looks like you've been manually annotating training examples with your mask editor to feed into your new training.  I know that takes a good amount of time so I appreciate the effort and congratulate you. 

I can run my training examples through this new network to get an idea how well it generalizes. I was shown a previous mask training model from your github repo as of about a week or two ago so it looks like you've made some good progress with the new one.  

""why it produces so imprecise mask"". Lol, I always love your friendly competitive banter!",imprecise mask trained smooth mask able work recently thought point network natively like example purposely certain threshold like manually training mask editor feed new training know good amount time appreciate effort congratulate run training new network get idea well shown previous mask training model week two ago like made good progress new one imprecise mask always love friendly competitive banter,issue,positive,positive,positive,positive,positive,positive
485747076,"NSFW example using fanseg at [.....] (edited by kvrooman - @iperov  I appreciate it if you don't post NSFW items here. If you'd like, you can link to your repo and then link from there. Thank you)",example appreciate post like link link thank,issue,positive,neutral,neutral,neutral,neutral,neutral
485652677,"if you want, you can try to train your own seg model
my dataset located in
https://mega.nz/#F!b9MzCK4B!zEAG9txu7uaRUjXz9PtBqg
contains 3277 manually refined and segmented FAN-aligned faces. 
Fixed mask produced by include/exclude polygons ( IEPolys.py class )",want try train seg model manually refined segmented fixed mask produced class,issue,negative,positive,neutral,neutral,positive,positive
485651786,"@kvrooman why it produces so imprecise mask?

I trained fanseg that produces smooth mask.

![python_2019-04-19_21-57-12](https://user-images.githubusercontent.com/8076202/56557450-1b669a00-65ac-11e9-9d6f-e0f6550e8d32.jpg)


",imprecise mask trained smooth mask,issue,negative,positive,positive,positive,positive,positive
484865278,"Questions like this are best raised in our discord server (see README.md) or faceswap_playground,",like best raised discord server see,issue,positive,positive,positive,positive,positive,positive
484610463,"Iterations will always be slower on multiple cards due to the need to syncronize the gradients between the cards.  The advantage of multiple cards is the ability to use much larger batch sizes and still fit inside the memory.  Essentially you should multiply your normal single card BS by the number of cards you're using.  That is how you get the speed increase from multiple cards.

Again: Iterations are slower with multiple GPUs, but you get that back in increased batch size.",always multiple due need advantage multiple ability use much batch size still fit inside memory essentially multiply normal single card number get speed increase multiple multiple get back batch size,issue,positive,positive,neutral,neutral,positive,positive
484277458,"s3fd is even better than mtcnn (see #649 ). The only reason I haven't made it the default is it's quite resource heavy.

There shouldn't be any backwards compatibility breakages. Old models should still load (although the filenames may have changed)",even better see reason made default quite resource heavy backwards compatibility old still load although may,issue,negative,positive,positive,positive,positive,positive
484240982,"Well, the project has made a tremendous progress over the year, so well done! Gotta admit, the new MTCNN detector together with the FAN aligner are absolutely amazing. The results are almost perfect even with more than 90 degree head turns.

Combined with a simple filtering technique I mentioned above, it appears to produce meaningful results for [interviews](https://www.youtube.com/watch?v=_cDGkmhDxaU) with a mostly static camera. For more dynamic scenes it still requires lots of manual editing afterwards. I'm going to play with this technique a little more, check how robust it is in different scenarios, and maybe come up with a pull request if results will look promising. In general, it may be feasible to replace the recognition with some sort of tracking, preferably temporal, because of simplicity, and avoid the costly `face_encodings` calls.
![ze](https://user-images.githubusercontent.com/13799992/56316519-22804900-6163-11e9-9181-6559b8ddcd2d.gif)

Thanks for the instructions. Great to know the proper solution to the problem without hacking my way through the code :)

As a side note, is there anywhere I can read about the network architecture change, which breaks backward-compatibility of the models? Some sort of changelog? Thanks again.",well project made tremendous progress year well done got ta admit new detector together fan aligner absolutely amazing almost perfect even degree head turn combined simple filtering technique produce meaningful mostly static camera dynamic still lot manual afterwards going play technique little check robust different maybe come pull request look promising general may feasible replace recognition sort preferably temporal simplicity avoid costly thanks great know proper solution problem without hacking way code side note anywhere read network architecture change sort thanks,issue,positive,positive,positive,positive,positive,positive
483893245,"We're all for different face filters. We want to remove the requirement on dlib from the whole of the project, so we have it on the 'todo' list to change the face filter (it currently relies on face-recognition, which relies on dlib). It is a long, long, long way down though.

For post processing items if you look from line 286 of `scripts/fsmedia.py` you'll see how the current actions get implemented (to be honest, I'm not too sure why they are there and not in extract.py, but anyway).

You would basicaly inherit from `class PostProcessAction()` and have a `process` method which takes an `output` item. This is a dict that is received from the aligner that contains:
```  
    ""filename"": <filename of source frame>,
     ""image"": <source image>,
     ""detected_faces"": <list of detected_faces objects>,
     ""landmarks"": <list of landmarks>}
```

These actions are called from the `PostProcess` class within the same file.
",different face want remove requirement whole project list change face filter currently long long long way though post look line see current get honest sure anyway would inherit class process method output item received aligner source frame image source image list list class within file,issue,positive,positive,positive,positive,positive,positive
483884018,"@Kirin-kun I confess it came out a little more power hungry than I anticipated. I was aiming at preserving fine details versus high memory optimizations. Though it's still much less demanding than `DFL` SAE and whatnot. Saying that I  plan to release it's close cousin `FaceLight` (codenamed: ""Buttercup"") with tighter memory optimizations and arguably comparable level of detail.
PS: If `villain` works for you that is probably the one you should be using. I highly recommend his models.
",confess came little power hungry aiming fine versus high memory though still much le demanding whatnot saying plan release close cousin buttercup memory comparable level detail villain work probably one highly recommend,issue,negative,positive,positive,positive,positive,positive
483757283,"> @Kirin-kun Depending on the resolution I might require more memory. I suppose 64->128 should start with 6G which is the resolution I made my swap with. It has a slightly high `dense` size which could perhaps be lowered to 1024 in `config.ini`

With the defaults, this model requires more memory than villain and I couldn't start it with 6Gb. Only with ping-pong did it start, The model files are obviously bigger too.

Villain starts with a bs of 8 with 6Gb, no problem. 

The result is good, but as you said, it's less detailed than villain. It's difficult to judge, because the amount of iterations between the two and the losses, are not the same, so I can't definitely say that one is better than the other.",depending resolution might require memory suppose start resolution made swap slightly high dense size could perhaps model memory villain could start start model obviously bigger villain problem result good said le detailed villain difficult judge amount two ca definitely say one better,issue,negative,positive,positive,positive,positive,positive
483046766,"I'm really sorry dude. I introduced conflicts again :/

I will look at this PR next, once resolved.",really sorry dude look next resolved,issue,negative,negative,negative,negative,negative,negative
482936347,@Kirin-kun Depending on the resolution I might require more memory. I suppose 64->128 should start with 6G which is the resolution I made my swap with. It has a slightly high `dense` size which could perhaps be lowered to 1024 in `config.ini`,depending resolution might require memory suppose start resolution made swap slightly high dense size could perhaps,issue,negative,positive,positive,positive,positive,positive
482884359,"re: ""No augmentation toggle"" I'd recommend removing this as an option and just make sure the previews don't go through augmentation. I don't think there is any reason why a user wouldn't want this.",augmentation toggle recommend removing option make sure go augmentation think reason user would want,issue,positive,positive,positive,positive,positive,positive
482841216,"@Kirin-kun, the model is very memory hungry.  This was made with Pegasus rc1, https://youtu.be/C0nr0429Q2k, but I obviously don't have AnDenixa's level of skill.",model memory hungry made obviously level skill,issue,negative,neutral,neutral,neutral,neutral,neutral
482794426,"Tried it with a GTX 1060 6Gb with ""Memory Saving Gradient"" and ""Allow Growth"", it doesn't even start. It crashes with OOM even with a batch size of 2. Either it doesn't support MSG, or it's really, really, memory hungry.

It actually started with ping pong and a batch size of 8, but I think the training will take a looong time. ",tried memory saving gradient allow growth even start even batch size either support really really memory hungry actually ping pong batch size think training take time,issue,positive,positive,neutral,neutral,positive,positive
482787489,And villain has a nasty habit of changing the colors on the converted faces.,villain nasty habit color converted,issue,negative,negative,negative,negative,negative,negative
482787388,"> 
> 
> > I'm just interested to know how this training model compares to the others? how is it different?
> 
> There is a link of a swap made with it at 128x128 resolution.
> [RealFace ""Pegasus"" at 128x128](https://www.youtube.com/watch?v=PJwdtPy1c64&t=3s)
> I'd say it somewhere in between `Unbalanced` and `Villain` details-wise meaning it's pretty detailed.
> It would be better if you'd just try it. It also supports variable resolutions from `128x128` to `256x256` (in steps of 64)

What GPU did you use to get that result? What were the final losses? Either with unbalanced or villain, I never get that level of detail on the teeth and eyes.",interested know training model different link swap made resolution say somewhere unbalanced villain meaning pretty detailed would better try also variable use get result final either unbalanced villain never get level detail teeth,issue,negative,positive,positive,positive,positive,positive
482508907,"> I'm just interested to know how this training model compares to the others? how is it different?

There is a link of a swap made with it at 128x128 resolution.
[RealFace ""Pegasus"" at 128x128](https://www.youtube.com/watch?v=PJwdtPy1c64&t=3s)
I'd say it somewhere in between `Unbalanced` and `Villain` details-wise meaning it's pretty detailed.
It would be better if you'd just try it. It also supports variable resolutions from `128x128` to `256x256` (in steps of 64)",interested know training model different link swap made resolution say somewhere unbalanced villain meaning pretty detailed would better try also variable,issue,positive,positive,positive,positive,positive,positive
482326915,I'm just interested to know how this training model compares to the others? how is it different?,interested know training model different,issue,negative,positive,positive,positive,positive,positive
482048158,"Check if you pressed ""pg up""/""pg dn"" arrow key when you train your  model. I have encountered the same question.",check arrow key train model question,issue,negative,neutral,neutral,neutral,neutral,neutral
481483567,"Unfortunately I don't use docker, but would welcome a PR that addresses this,",unfortunately use docker would welcome,issue,negative,positive,positive,positive,positive,positive
481351083,"I see (strange...)

The point is that if you build the Docker image you get python 3.7 inside and so, with the present version of faceswap it doesn't work. So, if you don't want to fix this you have to fix the Dockerfile.",see strange point build docker image get python inside present version work want fix fix,issue,negative,negative,neutral,neutral,negative,negative
481340383,This change has been made. Thanks for the feedback.,change made thanks feedback,issue,negative,positive,positive,positive,positive,positive
481338303,"Keras does not 'officially' support Python 3.7. Whilst it does work, there is no guarantee that it will in the future until it is updates. For that reason, we pin faceswap at 3.6",support python whilst work guarantee future reason pin,issue,positive,neutral,neutral,neutral,neutral,neutral
481332741,"Sorry, there are conflicts now due to #688 getting merged. Could you resolve conflicts and I'll review + merge",sorry due getting could resolve review merge,issue,negative,negative,negative,negative,negative,negative
481331734,"This seems to work without generating the previous errors.
Merging",work without generating previous,issue,negative,negative,negative,negative,negative,negative
481161499,Please post general query questions in either the Discord server or faceswap-playground,please post general query either discord server,issue,negative,positive,neutral,neutral,positive,positive
480782073,"> If you use the GUI can you go Tools>Output System Info and post that please

I have updated this issues.
again,thX. ",use go output system post please,issue,negative,neutral,neutral,neutral,neutral,neutral
480621031,"> Full crash report please.

think for your answer.
I have updated the issues.
I don't know how to provide any more details, case the program seem to get into a dead loop,but no crash.so it doesn't output any other log.Those are all that I have.",full crash report please think answer know provide case program seem get dead loop output,issue,negative,positive,neutral,neutral,positive,positive
480615094,Full crash report please.,full crash report please,issue,negative,positive,positive,positive,positive,positive
480609554,"The other way that I try to fix this.

1. reboot
2. remove The folder where this program is located and clone it again, run setup.py again

and yet this problem still.",way try fix remove folder program clone run yet problem still,issue,negative,neutral,neutral,neutral,neutral,neutral
480600430,"is there any specific unit test I can run?

I just tried train.py with default arguments and it works.

By the way: now the Docker image is broken, since it contains python 3.7",specific unit test run tried default work way docker image broken since python,issue,negative,negative,negative,negative,negative,negative
480587390,"You mentioned that you havent checked if Python 3.7 actually works...? Perhaps, you should do some testing before making any potentially breaking changes?",havent checked python actually work perhaps testing making potentially breaking,issue,negative,neutral,neutral,neutral,neutral,neutral
480498197,"You have a 2GB GPU running on Windows.

The best you can hope for is to run the lightweight model with a low batchsize, with Memory Saving Gradients and PingPong enabled.",running best hope run lightweight model low memory saving,issue,positive,positive,positive,positive,positive,positive
480497912,"This could be any number of issues. At the moment TF 1.13.1 is not directly supported. Also, you are not installed within an environment, so you may have conflicts.

Windows users should use the installer to install faceswap to make sure everything is set up correctly:
https://github.com/deepfakes/faceswap/releases
",could number moment directly also within environment may use installer install make sure everything set correctly,issue,negative,positive,positive,positive,positive,positive
480464990,"> There is not enough information here. Provide the crash report.

Dear Sir,  here‘s my crash report
```
04/05/2019 19:29:11 MainProcess     training_0      training_data   __init__                  DEBUG    Initialized TrainingDataGenerator
04/05/2019 19:29:11 MainProcess     training_0      training_data   minibatch_ab              DEBUG    Queue batches: (image_count: 740, batchsize: 4, side: 'b', do_shuffle: True, is_timelapse: False)
04/05/2019 19:29:11 MainProcess     training_0      training_data   make_queues               DEBUG    ['train_b_in', 'train_b_out']
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   get_queue                 DEBUG    QueueManager getting: 'train_b_in'
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'train_b_in', maxsize: 0)
04/05/2019 19:29:11 SpawnProcess-2  MainThread      multithreading  _runner                   DEBUG    FixedProducerDispatcher worker for <bound method TrainingDataGenerator.load_batches of <lib.training_data.TrainingDataGenerator object at 0x0000021D633C47F0>> started
04/05/2019 19:29:11 SpawnProcess-2  MainThread      training_data   load_batches              DEBUG    Loading batch: (image_count: 3546, side: 'a', is_timelapse: False, do_shuffle: True)
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'train_b_in')
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   get_queue                 DEBUG    QueueManager got: 'train_b_in'
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   get_queue                 DEBUG    QueueManager getting: 'train_b_out'
04/05/2019 19:29:11 MainProcess     training_0      queue_manager   add_queue                 DEBUG    QueueManager adding: (name: 'train_b_out', maxsize: 0)
04/05/2019 19:29:12 MainProcess     training_0      queue_manager   add_queue                 DEBUG    QueueManager added: (name: 'train_b_out')
04/05/2019 19:29:12 MainProcess     training_0      queue_manager   get_queue                 DEBUG    QueueManager got: 'train_b_out'
04/05/2019 19:29:12 MainProcess     training_0      multithreading  __init__                  DEBUG    Initializing FixedProducerDispatcher: (method: '<bound method TrainingDataGenerator.load_batches of <lib.training_data.TrainingDataGenerator object at 0x000001CBBB7B2AC8>>', shapes: [(4, 192, 192, 3), (4, 64, 64, 3), (4, 128, 128, 3), (4, 128, 128, 1)], args: (['C:\\Users\\steph\\Desktop\\output3\\蔡_000025_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000026_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000027_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000028_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000029_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000030_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000031_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000032_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000033_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000034_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000035_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000036_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000037_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000038_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000039_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000040_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000041_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000042_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000043_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000044_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000045_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000046_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000047_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000048_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000049_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000050_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000051_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000052_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000053_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000054_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000055_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000056_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000057_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000058_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000059_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000060_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000061_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000062_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000063_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000064_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000065_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000066_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000067_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000068_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000069_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000070_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000071_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000072_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000073_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000074_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000075_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000076_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000077_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000078_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000079_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000080_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000081_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000082_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000083_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000084_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000085_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000086_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000087_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000088_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000089_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000090_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000091_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000092_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000093_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000094_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000095_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000096_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000097_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000098_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000099_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000100_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000101_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000102_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000103_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000104_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000105_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000106_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000107_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000108_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000109_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000110_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000111_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000112_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000113_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000114_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000115_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000116_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000117_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000118_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000119_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000120_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000121_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000122_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000123_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000124_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000125_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000126_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000127_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000128_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000129_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000130_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000131_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000132_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000133_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000134_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000135_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000136_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000137_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000138_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000139_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000140_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000141_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000142_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000143_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000144_0.png', 'C:\\Users\\steph\\Desktop\\output3\\蔡_000145_0.png'], 'b', False, True, 4), kwargs: {}, ctype: <class 'ctypes.c_float'>, workers: 1, buffers: None)
04/05/2019 19:29:12 MainProcess     training_0      multithreading  __init__                  DEBUG    Initialized FixedProducerDispatcher
04/05/2019 19:29:12 MainProcess     training_0      training_data   minibatch_ab              DEBUG    Batching to queue: (side: 'b', is_timelapse: False)
04/05/2019 19:29:12 MainProcess     training_0      _base           set_tensorboard           DEBUG    Enabling TensorBoard Logging
04/05/2019 19:29:12 MainProcess     training_0      _base           set_tensorboard           DEBUG    Setting up TensorBoard Logging. Side: a
04/05/2019 19:29:12 MainProcess     training_0      _base           name                      DEBUG    model name: 'dfaker'
04/05/2019 19:29:12 SpawnProcess-3  MainThread      multithreading  _runner                   DEBUG    FixedProducerDispatcher worker for <bound method TrainingDataGenerator.load_batches of <lib.training_data.TrainingDataGenerator object at 0x0000028B0A244860>> started
04/05/2019 19:29:12 SpawnProcess-3  MainThread      training_data   load_batches              DEBUG    Loading batch: (image_count: 740, side: 'b', is_timelapse: False, do_shuffle: True)
04/05/2019 19:29:12 SpawnProcess-3  MainThread      multithreading  _runner                   ERROR    object supporting the buffer API required\nTraceback (most recent call last):\n File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\multithreading.py"", line 261, in _runner\n target(*args, **kwargs)\n File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\training_data.py"", line 105, in load_batches\n imgs = self.process_face(img_path, side, is_timelapse)\n File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\training_data.py"", line 151, in process_face\n src_pts = self.get_landmarks(filename, image, side)\n File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\training_data.py"", line 177, in get_landmarks\n lm_key = sha1(image).hexdigest()\nTypeError: object supporting the buffer API required
04/05/2019 19:29:12 SpawnProcess-3  MainThread      multithreading  _runner                   DEBUG    FixedProducerDispatcher worker for <bound method TrainingDataGenerator.load_batches of <lib.training_data.TrainingDataGenerator object at 0x0000028B0A244860>> shutdown
04/05/2019 19:29:13 MainProcess     training_0      _base           set_tensorboard           DEBUG    Setting up TensorBoard Logging. Side: b
04/05/2019 19:29:13 MainProcess     training_0      _base           name                      DEBUG    model name: 'dfaker'
04/05/2019 19:29:13 MainProcess     training_0      _base           set_tensorboard           INFO     Enabled TensorBoard Logging
04/05/2019 19:29:13 MainProcess     training_0      _base           use_mask                  DEBUG    True
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initializing Samples: model: '<plugins.train.model.dfaker.Model object at 0x000001CB88707E80>', use_mask: True, coverage_ratio: 1.0)
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initialized Samples
04/05/2019 19:29:13 MainProcess     training_0      _base           use_mask                  DEBUG    True
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initializing Timelapse: model: <plugins.train.model.dfaker.Model object at 0x000001CB88707E80>, use_mask: True, coverage_ratio: 1.0, batchers: '{'a': <plugins.train.trainer._base.Batcher object at 0x000001CBDCEF22B0>, 'b': <plugins.train.trainer._base.Batcher object at 0x000001CBBB7B2EB8>}')
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initializing Samples: model: '<plugins.train.model.dfaker.Model object at 0x000001CB88707E80>', use_mask: True, coverage_ratio: 1.0)
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initialized Samples
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initialized Timelapse
04/05/2019 19:29:13 MainProcess     training_0      _base           __init__                  DEBUG    Initialized TrainerBase
04/05/2019 19:29:13 MainProcess     training_0      train           load_trainer              DEBUG    Loaded Trainer
04/05/2019 19:29:13 MainProcess     training_0      train           run_training_cycle        DEBUG    Running Training Cycle
04/05/2019 19:29:13 MainProcess     training_0      training_data   minibatch                 DEBUG    Launching minibatch generator for queue (side: 'a', is_timelapse: False)
04/05/2019 19:29:13 MainProcess     training_0      deprecation     new_func                  WARNING  From C:\Users\steph\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.
04/05/2019 19:29:44 MainProcess     training_0      _base           compile_sample            DEBUG    Compiling samples: (side: 'a', samples: 4)
04/05/2019 19:29:44 MainProcess     training_0      training_data   minibatch                 DEBUG    Launching minibatch generator for queue (side: 'b', is_timelapse: False)
04/05/2019 19:29:44 MainProcess     training_0      training_data   minibatch                 DEBUG    Finished minibatch generator for queue: (side: 'b', is_timelapse: False)
04/05/2019 19:29:44 MainProcess     training_0      multithreading  run                       DEBUG    Error in thread (training_0):
04/05/2019 19:29:45 MainProcess     MainThread      train           monitor                   DEBUG    Thread error detected
04/05/2019 19:29:45 MainProcess     MainThread      train           monitor                   DEBUG    Closed Monitor
04/05/2019 19:29:45 MainProcess     MainThread      train           end_thread                DEBUG    Ending Training thread
04/05/2019 19:29:45 MainProcess     MainThread      train           end_thread                CRITICAL Error caught! Exiting...
04/05/2019 19:29:45 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'training'
04/05/2019 19:29:45 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'training_0'
04/05/2019 19:29:45 MainProcess     MainThread      multithreading  join                      ERROR    Caught exception in thread: 'training_0'
Traceback (most recent call last):
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\cli.py"", line 107, in execute_script
    process.process()
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\scripts\train.py"", line 98, in process
    self.end_thread(thread, err)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\scripts\train.py"", line 123, in end_thread
    thread.join()
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\multithreading.py"", line 443, in join
    raise thread.err[1].with_traceback(thread.err[2])
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\multithreading.py"", line 381, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\scripts\train.py"", line 149, in training
    raise err
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\scripts\train.py"", line 139, in training
    self.run_training_cycle(model, trainer)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\scripts\train.py"", line 214, in run_training_cycle
    trainer.train_one_step(viewer, timelapse)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\plugins\train\trainer\_base.py"", line 153, in train_one_step
    loss[side] = batcher.train_one_batch(do_preview)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\plugins\train\trainer\_base.py"", line 234, in train_one_batch
    batch = self.get_next(do_preview)
  File ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\plugins\train\trainer\_base.py"", line 242, in get_next
    batch = next(self.feed)
StopIteration

============ System Information ============
encoding:          cp936
git_branch:        Not Found
git_commits:       Not Found
gpu_cuda:          Not Found
gpu_cudnn:         Not Found
gpu_devices:       
gpu_driver:        No Nvidia driver found
gpu_vram:          
os_machine:        AMD64
os_platform:       Windows-10-10.0.17134-SP0
os_release:        10
py_command:        C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\faceswap.py train -A C:/Users/steph/Desktop/output5 -B C:/Users/steph/Desktop/output3 -ala C:/Users/steph/Desktop/韩国语/han_alignments.json -alb C:/Users/steph/Desktop/韩国语/蔡_alignments.json -m C:/Users/steph/Desktop/trainingmodel -t dfaker -s 100 -bs 4 -it 1000000 -g 1 -ps 50 -p -L INFO -gui
py_conda_version:  N/A
py_implementation: CPython
py_version:        3.7.2
py_virtual_env:    False
sys_cores:         4
sys_processor:     Intel64 Family 6 Model 142 Stepping 9, GenuineIntel
sys_ram:           Total: 3994MB, Available: 572MB, Used: 3422MB, Free: 572MB

=============== Pip Packages ===============
absl-py==0.7.1
astor==0.7.1
astroid==2.2.5
attrs==19.1.0
backcall==0.1.0
bleach==3.1.0
Click==7.0
colorama==0.4.1
cycler==0.10.0
decorator==4.4.0
defusedxml==0.5.0
dlib==19.17.0
entrypoints==0.3
face-recognition==1.2.3
face-recognition-models==0.3.0
ffmpy==0.2.2
gast==0.2.2
google-pasta==0.1.4
grpcio==1.19.0
h5py==2.9.0
imageio==2.5.0
ipykernel==5.1.0
ipython==7.4.0
ipython-genutils==0.2.0
isort==4.3.15
jedi==0.13.3
Jinja2==2.10
jsonschema==3.0.1
jupyter-client==5.2.4
jupyter-core==4.4.0
Keras==2.2.4
Keras-Applications==1.0.7
Keras-Preprocessing==1.0.9
kiwisolver==1.0.1
lazy-object-proxy==1.3.1
Markdown==3.1
MarkupSafe==1.1.1
matplotlib==2.2.2
mccabe==0.6.1
mistune==0.8.4
mock==2.0.0
nbconvert==5.4.1
nbformat==4.4.0
networkx==2.2
notebook==5.7.7
numpy==1.16.2
nvidia-ml-py3==7.352.0
opencv-python==4.0.0.21
pandocfilters==1.4.2
parso==0.3.4
pathlib==1.0.1
pbr==5.1.3
pickleshare==0.7.5
Pillow==6.0.0
prometheus-client==0.6.0
prompt-toolkit==2.0.9
protobuf==3.7.1
psutil==5.6.1
pygame==1.9.4
Pygments==2.3.1
pylint==2.3.1
pyparsing==2.3.1
pyrsistent==0.14.11
python-dateutil==2.8.0
pytz==2018.9
PyWavelets==1.0.2
pywinpty==0.5.5
PyYAML==5.1
pyzmq==18.0.1
rope==0.12.0
scikit-image==0.15.0
scikit-learn==0.20.3
scipy==1.2.1
Send2Trash==1.5.0
six==1.12.0
tb-nightly==1.14.0a20190301
tensorboard==1.13.1
tensorflow==1.13.1
tensorflow-estimator==1.13.0
termcolor==1.1.0
terminado==0.8.2
testpath==0.4.2
tf-estimator-nightly==1.14.0.dev2019030115
toposort==1.5
tornado==6.0.2
tqdm==4.31.1
traitlets==4.3.2
typed-ast==1.3.1
wcwidth==0.1.7
webencodings==0.5.1
Werkzeug==0.15.2
wrapt==1.11.1
```",enough information provide crash report dear sir crash report queue side true false getting name worker bound method object loading batch side false true added name got getting name added name got method bound method object false true class none queue side false logging setting logging side name model name worker bound method object loading batch side false true error object supporting buffer recent call last file line target file line side file line image side file line sha image object supporting buffer worker bound method object shutdown setting logging side name model name logging true model object true true model object true object object model object true train loaded trainer train running training cycle generator queue side false deprecation warning removed future instead side generator queue side false finished generator queue side false run error thread train monitor thread error train monitor closed monitor train ending training thread train critical error caught join joining join joining thread join error caught exception thread recent call last file line file line process thread err file line file line join raise file line run file line training raise err file line training model trainer file line viewer file line loss side file line batch file line batch next system information found found found found driver found train false family model stepping total available used free pip dev,issue,positive,positive,neutral,neutral,positive,positive
480444748,There is not enough information here. Provide the crash report.,enough information provide crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
480444556,OOM = Out of Memory. Lower your batchsize. If you still have issues provide the crash report,memory lower still provide crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
480271557,"> ""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\training_data.py"", line 226, in color_adjust\n return img.astype('float32') / 255.0
> 
> \nAttributeError: 'NoneType' object has no attribute 'astype'
> 
> it's trying to process an image which isn't there. guessing that the image directory pointer could be wrong ?

Thanks for replying, yeah noticed that， have checked over and over again, still no idea.. :(",line return object attribute trying process image guessing image directory pointer could wrong thanks yeah checked still idea,issue,negative,negative,negative,negative,negative,negative
480266828,"""C:\Users\steph\Desktop\mirrors-faceswap-master\faceswap\lib\training_data.py"", line 226, in color_adjust\n return img.astype('float32') / 255.0

\nAttributeError: 'NoneType' object has no attribute 'astype'

it's trying to process an image which isn't there. guessing that the image directory pointer could be wrong ?",line return object attribute trying process image guessing image directory pointer could wrong,issue,negative,negative,negative,negative,negative,negative
480152806,"Unfortunately, nothing you have stated is actually a bug or anything with the code.
Faceswap is data driven and starts from a random state.  Unfortunately, it is not possible to guarantee particular results no matter what we do.  There are only actions you can take to try to maximize your quality.
Teeth are always problematic due to their VERY low scoring potential.  Since even predicting a black line in the wrong place will actually reduce the scoring.
MSG is much slower than without and will always take longer to train out of blur.
Lowmem only differs from Original by how much latent space it has.  There is literally nothing that Lowmem can do that Original cannot. (except for run on lower end systems)
Loss is not a measure of quality and is unlikely to EVER go below .02 for the simple fact that AIs are lossy, they will always have some loss.  They can't recreate an image perfectly without just memorizing that image.

I'm closing this issue since it's really not an issue.  This isn't a bug, or a fixable problem, it's just a matter of your data and particular training.  If you want to discuss your issues, please join our Discord server since it's a much better place for discussions.",unfortunately nothing stated actually bug anything code data driven random state unfortunately possible guarantee particular matter take try maximize quality teeth always problematic due low scoring potential since even black line wrong place actually reduce scoring much without always take longer train blur original much latent space literally nothing original except run lower end loss measure quality unlikely ever go simple fact always loss ca recreate image perfectly without image issue since really issue bug fixable problem matter data particular training want discus please join discord server since much better place,issue,negative,positive,neutral,neutral,positive,positive
480130928,"I have heavily curated the facesets and they are not garbage, there are no false identified faces or blurry images but I understand why you may think that.  Are you suggesting to train the exposed teeth temporary facesets against themselves or the smaller teeth faceset against the whole of the original faceset? i will try reducing the batch size and training only on the teeth mages and get back to you.",heavily garbage false blurry understand may think suggesting train exposed teeth temporary smaller teeth whole original try reducing batch size training teeth get back,issue,negative,negative,neutral,neutral,negative,negative
480113486,"The window will stop responding for a while, thanks for finally quit:

04/05/2019 08:51:06 INFO saved models
Sending Exit Signal
Terminating Process...
Terminated
Process exited.",window stop thanks finally quit saved sending exit signal process process,issue,positive,positive,neutral,neutral,positive,positive
480106880,"Okay, listen. Teeth has no simple relation to a model and more relation to your data.

* It's not how many samples you have it's _the number of samples with teeth with matching face pitch_ that is important. 
* Low-mem model doesn't help but I believe it might be possible.
* Using hideous batch sizes such as 256 definitely doesn't help because of how `loss` is calculated for big batches.
* Using 10k faces doesn't help as I am sure you are unable to check all of these and I assume that _most of dataset are garbage_ which makes the training worse. 

* What you can do is:
1. sieve through the A and B datasets choosing only ones that have teeth clearly exposed and copy these to a different folder.
2. Train specifically on these samples until teeth details manifest to a level you are happy with.
3. Go back to training on the overall dataset.
",listen teeth simple relation model relation data many number teeth matching face important model help believe might possible hideous batch size definitely help loss calculated big help sure unable check assume training worse sieve choosing teeth clearly exposed copy different folder train specifically teeth manifest level happy go back training overall,issue,positive,positive,neutral,neutral,positive,positive
480088735,"I have never been able to get teeth using Original model. I've seen quite a few mentions of these fine-grained details showing up in larger models though ( dfaker / villian / unbalanced ).

 I'm surprised at your mentioning that the Low men model returns better detail considering it's the same model architecture but using fewer filters/complexity to transform the image. Do you have an example?

The loss should never reduce to zero ( and would likely represent a bad thing as it signifies major over-fitting ). The loss level that you plateau at should be proportionate to your dataset diversity ( and it sounds like your using 10k + images so that's a lot )

There has been general feedback that batch sizes of 8, 16, 32 have been returning better quality versus larger batch sizes ( although large batch sizes compute faster ) but this is still somewhat unsettled.

You shouldn't use memory saving gradients on a model unless you can't run batch size 8 on a model. while the results won't differ, it just slows computation down overall.

if you're fitting a batch size of 256 on original, I really recommend you use a better, more complex model since you will have the VRAM for it (@256 batch size sounds like you do). if not use m-s-g or ping-pong to enable those models
",never able get teeth original model seen quite showing though unbalanced low men model better detail considering model architecture transform image example loss never reduce zero would likely represent bad thing major loss level plateau proportionate diversity like lot general feedback batch size better quality versus batch size although large batch size compute faster still somewhat unsettled use memory saving model unless ca run batch size model wo differ slows computation overall fitting batch size original really recommend use better complex model since batch size like use enable,issue,positive,positive,positive,positive,positive,positive
479824791,"```py_virtual_env: False```
My advice is to install into a virtual environment. You have a lot of packages installed, and troubleshooting potential conflicts would not be a great use of time.",false advice install virtual environment lot potential would great use time,issue,positive,positive,positive,positive,positive,positive
479547318,closing due to time. also the implementation of new models and more res blocks have ameliorated pupils and teeth to some extent.,due time also implementation new teeth extent,issue,negative,positive,neutral,neutral,positive,positive
479545155,saw that a timeout toggle was added in recent commits? is this issue solved?,saw toggle added recent issue,issue,negative,neutral,neutral,neutral,neutral,neutral
478375213,Damn it i did it again. Please switch to staging. Its based on it but i (once again)missed to switch it in the GH interface. Sorry about that.,damn please switch staging based switch interface sorry,issue,negative,negative,negative,negative,negative,negative
477618840,"> I'd advise leaving it pinned to tf 1.12 for now. FS hasn't been fully tested on 1.13.1 yet

reverted to 1.12 now.",advise leaving pinned fully tested yet,issue,negative,neutral,neutral,neutral,neutral,neutral
477571090,"1.removed the --yes option
2.update by using tensorflow/tensorflow:latest-gpu-py3-jupyter [Tensorflow Version 1.13.1, CUDA Version 10.0.130]",yes option version version,issue,negative,neutral,neutral,neutral,neutral,neutral
476058915,probably need to use >python 3.5,probably need use python,issue,negative,neutral,neutral,neutral,neutral,neutral
475948840,There is no way near enough information here to diagnose anything,way near enough information diagnose anything,issue,negative,positive,neutral,neutral,positive,positive
475874643,@kvrooman partially because I agree with @torzdf and because it received more criticism than I would anticipate :),partially agree received criticism would anticipate,issue,negative,negative,neutral,neutral,negative,negative
475626672,Hey @andenixa - as discussed on discord. I'm fine with adding this toggle. Allows some flexibility if you don't want bias. Why'd you close?,hey discord fine toggle flexibility want bias close,issue,negative,positive,positive,positive,positive,positive
475612396,"I threw import Scale into staging real quick for a test.  The old GAN code is unsupported and untested but still included in the nn_blocks for re-implementation one day. ...

Happy to merge your's to master, just thought I do a quick test first",threw import scale staging real quick test old gan code unsupported untested still included one day happy merge master thought quick test first,issue,negative,positive,positive,positive,positive,positive
475554021,"In theory, yes, in current implementation, no.

Best to discuss this in the playground or on the discord server",theory yes current implementation best discus playground discord server,issue,positive,positive,positive,positive,positive,positive
475524106,"> chk = os.popen(""ldconfig -p | grep -P ""libcudnn.so.\d+"" | head -n 1"").read()

The nested double quotes aren't valid, so I had to change the outer quotes to single",head double valid change outer single,issue,negative,negative,neutral,neutral,negative,negative
475163667,"```assert height == width and height % 2 == 0```
Non training image in your input folder",assert height width height non training image input folder,issue,negative,neutral,neutral,neutral,neutral,neutral
474790585,"to maintain consistency, we also should pin the specific version to 1.12 as the main non-Docker code uses that version. ( conda still working on 1.13 packages ... )",maintain consistency also pin specific version main code version still working,issue,negative,positive,neutral,neutral,positive,positive
474027161,"3GB of VRAM is low. Original model will generally not work on less than 4GB.

However there are new VRAM saving features in the latest commit, so either try them, or use the lightweight model or lowmem version of the original model.",low original model generally work le however new saving latest commit either try use lightweight model version original model,issue,positive,positive,positive,positive,positive,positive
473596979,"We do not yet support tensorflow 1.13.  It's too new and only released last week along with the announcement that tensorflow 2.0 is coming soon.  We are evaluating the options but for now we have a known working solution.

Please install a supported version through anaconda since this is a good working solution.

",yet support new last week along announcement coming soon known working solution please install version anaconda since good working solution,issue,positive,positive,positive,positive,positive,positive
473596634,@torzdf Tensorflow 1.13.1 already supports Python 3.7 (https://github.com/tensorflow/tensorflow/releases/tag/v1.13.1) on all operating systems. Is it possible to remove the restriction in faceswap now. Thank you.,already python operating possible remove restriction thank,issue,negative,neutral,neutral,neutral,neutral,neutral
473488288,"> You're out of memory. Lower batch size or choose a different model. If you still have issues provide a crash report.



> You're out of memory. Lower batch size or choose a different model. If you still have issues provide a crash report.

It's not OK ,although I set batch size the minimum 2.   My laptop  has 8g RAM,and my graphic gard is GetForce 970m about 3g vram.

@torzdf 


[crash_report.2019.03.16.094702509958.log](https://github.com/deepfakes/faceswap/files/2973353/crash_report.2019.03.16.094702509958.log)
",memory lower batch size choose different model still provide crash report memory lower batch size choose different model still provide crash report although set batch size minimum ram graphic log,issue,negative,neutral,neutral,neutral,neutral,neutral
473348662,"I haven't had a chance to look at this code yet, I will do. However, Convert is getting refactored very shortly, so I will look then",chance look code yet however convert getting shortly look,issue,negative,neutral,neutral,neutral,neutral,neutral
473347665,You're out of memory. Lower batch size or choose a different model. If you still have issues provide a crash report.,memory lower batch size choose different model still provide crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
473344055,"> @Nostalgia1990, have you tried to force version install:
> conda install tensorflow-gpu==1.12
> conda install tensorboard==1.12
> conda install tensorflow-estimator==1.12

 Could not find a version that satisfies the requirement tensorflow-estimator==1.12.0 (from versions: 1.10.6, 1.10.7, 1.10.8, 1.10.9, 1.10.10, 1.10.11, 1.10.12, 1.13.0rc0, 1.13.0)
No matching distribution found for tensorflow-estimator==1.12.0

Could not find a version that satisfies the requirement tensorboardrd==1.12.0 (from versions: )
No matching distribution found for tensorboardrd==1.12.0

",nostalgia tried force version install install install install could find version requirement matching distribution found could find version requirement matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
473342889,"> @Nostalgia1990, have you tried to force version install:
> conda install tensorflow-gpu==1.12
> conda install tensorboard==1.12
> conda install tensorflow-estimator==1.12


my tensorflow-gpu==1.12.0
my  tensorflow-estimator==1.13.0
my conda install tensorboard==1.12.2

let me try your advice ,thank you. wait a moment.",nostalgia tried force version install install install install install let try advice thank wait moment,issue,negative,neutral,neutral,neutral,neutral,neutral
473341961,"@Nostalgia1990, have you tried to force version install: 
conda install tensorflow-gpu==1.12
conda install tensorboard==1.12
conda install tensorflow-estimator==1.12 
 ",nostalgia tried force version install install install install,issue,negative,neutral,neutral,neutral,neutral,neutral
473340340,"I removed TF 1.13.1 and installed TF 1.12,but it also doesn't work.


**error log**

Loading...
03/15/2019 23:33:12 INFO     Log level set to: INFO
Using TensorFlow backend.
03/15/2019 23:33:13 INFO     Model A Directory: C:\Users\jinyi\faceswap\workspace\data_dst\aligned
03/15/2019 23:33:13 INFO     Model B Directory: C:\Users\jinyi\faceswap\workspace\data_src\aligned
03/15/2019 23:33:13 INFO     Training data directory: C:\Users\jinyi\faceswap\models
03/15/2019 23:33:13 INFO     ===============================================
03/15/2019 23:33:13 INFO     - Starting                                    -
03/15/2019 23:33:13 INFO     - Press 'ENTER' to save and quit              -
03/15/2019 23:33:13 INFO     - Press 'S' to save model weights immediately -
03/15/2019 23:33:13 INFO     ===============================================
03/15/2019 23:33:15 INFO     Loading data, this may take a while...
03/15/2019 23:33:15 INFO     Loading Model from Original plugin...
03/15/2019 23:36:18 INFO     Loading config: 'C:\Users\jinyi\faceswap\config\train.ini'
03/15/2019 23:36:18 WARNING  No existing state file found. Generating.
03/15/2019 23:36:44 INFO     Creating new 'original' model in folder: 'C:\Users\jinyi\faceswap\models'
03/15/2019 23:37:07 INFO     Loading Trainer from Original plugin...
03/15/2019 23:41:31 INFO     Enabled TensorBoard Logging
03/15/2019 23:48:04 CRITICAL Error caught! Exiting...
03/15/2019 23:48:04 ERROR    Caught exception in thread: 'training_0'
03/15/2019 23:48:08 ERROR    Got Exception on main handler:
Traceback (most recent call last):
File ""C:\Users\jinyi\faceswap\lib\cli.py"", line 107, in execute_script
process.process()
File ""C:\Users\jinyi\faceswap\scripts\train.py"", line 101, in process
self.end_thread(thread, err)
File ""C:\Users\jinyi\faceswap\scripts\train.py"", line 126, in end_thread
thread.join()
File ""C:\Users\jinyi\faceswap\lib\multithreading.py"", line 443, in join
raise thread.err[1].with_traceback(thread.err[2])
File ""C:\Users\jinyi\faceswap\lib\multithreading.py"", line 381, in run
self._target(*self._args, **self._kwargs)
File ""C:\Users\jinyi\faceswap\scripts\train.py"", line 152, in training
raise err
File ""C:\Users\jinyi\faceswap\scripts\train.py"", line 142, in training
self.run_training_cycle(model, trainer)
File ""C:\Users\jinyi\faceswap\scripts\train.py"", line 214, in run_training_cycle
trainer.train_one_step(viewer, timelapse)
File ""C:\Users\jinyi\faceswap\plugins\train\trainer\_base.py"", line 139, in train_one_step
loss[side] = batcher.train_one_batch(do_preview)
File ""C:\Users\jinyi\faceswap\plugins\train\trainer\_base.py"", line 214, in train_one_batch
loss = self.model.predictors[self.side].train_on_batch(*batch)
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\keras\engine\training.py"", line 1217, in train_on_batch
outputs = self.train_function(ins)
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2715, in __call__
return self._call(inputs)
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2675, in _call
fetched = self._callable_fn(*array_vals)
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1439, in __call__
run_metadata_ptr)
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 528, in __exit__
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[16384,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[{{node training_1/Adam/mul_43}} = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/beta_2/read, training_1/Adam/Variable_30/read)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

[[{{node loss_1/mul/_401}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1638_loss_1/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

03/15/2019 23:48:08 CRITICAL An unexpected crash has occurred. Crash report written to C:\Users\jinyi\faceswap\crash_report.2019.03.15.234804885710.log. Please verify you are running the latest version of faceswap before reporting
Exception ignored in: <generator object TrainingDataGenerator.minibatch at 0x00000168780462B0>
Traceback (most recent call last):
File ""C:\Users\jinyi\faceswap\lib\training_data.py"", line 135, in minibatch
File ""C:\Users\jinyi\faceswap\lib\multithreading.py"", line 43, in __exit__
File ""C:\Users\jinyi\faceswap\lib\multithreading.py"", line 35, in free
File ""C:\Users\jinyi\faceswap\lib\multithreading.py"", line 173, in free
File ""<string>"", line 2, in put
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\multiprocessing\managers.py"", line 753, in _callmethod
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\multiprocessing\managers.py"", line 740, in _connect
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\multiprocessing\connection.py"", line 485, in Client
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\multiprocessing\connection.py"", line 686, in PipeClient
FileNotFoundError: [WinError 2] 系统找不到指定的文件。
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x0000016878045400>>
Traceback (most recent call last):
File ""D:\PC_apps\Anaconda3\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 738, in __del__
TypeError: 'NoneType' object is not callable
Process exited.



",removed also work error log loading log level set model directory model directory training data directory starting press save quit press save model immediately loading data may take loading model original loading warning state file found generating new model folder loading trainer original logging critical error caught error caught exception thread error got exception main handler recent call last file line file line process thread err file line file line join raise file line run file line training raise err file line training model trainer file line viewer file line loss side file line loss batch file line file line return file line fetched file line file line tensor shape type float allocator node hint want see list add current allocation node hint want see list add current allocation critical unexpected crash crash report written log please verify running latest version exception generator object recent call last file line file line file line free file line free file string line put file line file line file line client file line exception bound method object recent call last file line object callable process,issue,negative,positive,positive,positive,positive,positive
473333984,"> @Nostalgia1990, use the Windows installer: https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#windows-install-guide.

I always use the guide,it's helpless to this problem.",nostalgia use installer always use guide helpless problem,issue,negative,neutral,neutral,neutral,neutral,neutral
473330679,"I assume this is also related to your other issue where you mention you use Tensorflow 1.131.

Suggest using Tensorflow 1.12",assume also related issue mention use suggest,issue,negative,neutral,neutral,neutral,neutral,neutral
473311967,"@torzdf @kvrooman 

# Name                    Version                   Build  Channel
tensorboard               1.13.1                   pypi_0    pypi
tensorflow                1.12.0          gpu_py36ha5f9131_0
tensorflow-base           1.12.0          gpu_py36h6e53903_0
tensorflow-estimator      1.13.0                   pypi_0    pypi
tensorflow-gpu            1.13.1                   pypi_0    pypi



Tensorflow-gpu should be <=1.13.0 for CUDA 9.0?",name version build channel,issue,negative,neutral,neutral,neutral,neutral,neutral
473281050,"> This is usually because of a version conflict somewhere, either multiple versions of numpy/cv2 installed in different environments. Google around for solutions.


Thank you.I resolved the problem.
1.install numpy 1.15.4
2.python setup.py again

both steps are important.",usually version conflict somewhere either multiple different around thank resolved problem important,issue,negative,positive,neutral,neutral,positive,positive
473280958,"> Likely wrong version of numpy installed
> 
> type
> `conda list numpy`
> it should be 1.15.4

Thank you.I resolved the problem.
1.install numpy 1.15.4
2.python setup.py again

both steps are important.",likely wrong version type list thank resolved problem important,issue,negative,negative,neutral,neutral,negative,negative
473239177,"This is usually because of a version conflict somewhere, either multiple versions of numpy/cv2 installed in different environments. Google around for solutions.",usually version conflict somewhere either multiple different around,issue,negative,negative,neutral,neutral,negative,negative
473226929,"> Likely wrong version of numpy installed
> 
> type
> `conda list numpy`
> it should be 1.15.4

My numpy's version is 1.15.4.  Is there something wrong with opencv-python? My opencv-python's version is 4.0.0.21",likely wrong version type list version something wrong version,issue,negative,negative,negative,negative,negative,negative
473209554,"Likely wrong version of numpy installed

type
```conda list numpy```
it should be 1.15.4",likely wrong version type list,issue,negative,negative,negative,negative,negative,negative
473119923,"First of all, thank you for your reply, for some reason, my python is not working, I am trying to fix it, or reconfigure the environment. I will try again after I finish.",first thank reply reason python working trying fix environment try finish,issue,negative,positive,positive,positive,positive,positive
473095997,"First time you run FAN it may timeout, after it's first ever initialization, it initializes fast.",first time run fan may first ever fast,issue,negative,positive,positive,positive,positive,positive
472858070,The 'pre-refactor-snapshot' branch? I'll be working on this the next couple of days,branch working next couple day,issue,negative,neutral,neutral,neutral,neutral,neutral
472819311,"This issue has not been reported before and I've never seen it. There may be an issue/conflict in one of your packages, so I suggest wiping your environment clean, re-installing and see if the issue persists.",issue never seen may one suggest environment clean see issue,issue,negative,positive,positive,positive,positive,positive
472813626,"Hi,
Just wondering if anyone else is experiencing the same error?

Thanks!",hi wondering anyone else error thanks,issue,negative,positive,positive,positive,positive,positive
472808285,"```tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor```
Lower your batch size or try the lowmem option",tensor lower batch size try option,issue,negative,neutral,neutral,neutral,neutral,neutral
472337334,"Cudnn 7 uses different path instead of staying with the same path of cuda. I fixed setup.py/cudnn_check function like:
        chk = os.popen(""ldconfig -p | grep -P \""libcudnn.so.\\d+\"" | head -n 1"").read()
        chk = chk.strip().replace(""libcudnn.so."", """")
        cudnn_path = chk[chk.find(""=>"") + 3:chk.find(""libcudnn"") - 1]
        cudnn_path = cudnn_path.replace(""lib"", ""include"")
        cudnn_checkfile = os.path.join(cudnn_path, ""cudnn_v7.h"")
",different path instead path fixed function like head include,issue,negative,positive,neutral,neutral,positive,positive
472190340,"for check:
1. I made checkout to tags/v0.90, the graph is showing
2. next step made upgrade TF/TB up to 1.13, the graph is still showing.
3. checkout to  tags/v0.95b, the graph isn't showing

> Can you run a couple of iterations with loglevel TRACE and provide the faceswap.log.

faceswap.log:https://www.dropbox.com/s/lb6wrmnbtz841av/faceswap.log.zip?dl=0
my env:
<pre>
:~/Documents/faceswap$ git describe --tags 
v0.95b-36-g80a6c73
<pre>
$ pip3 list | grep tensor
tensorboard             1.13.1  
tensorflow              1.13.1  
tensorflow-estimator    1.13.0  
tensorflow-gpu          1.13.1 
</pre>",check made graph showing next step made upgrade graph still showing graph showing run couple trace provide git describe pip list tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
472118283,"Can you run a couple of iterations with loglevel TRACE and provide the faceswap.log.

Don't leave it running long as it will generate a huge amount of data.",run couple trace provide leave running long generate huge amount data,issue,negative,positive,positive,positive,positive,positive
472110477,"@spackofatzo 
> But training works anyways.

Yes, training works, but without graph is not clear
",training work anyways yes training work without graph clear,issue,negative,positive,positive,positive,positive,positive
472108642,"I made downgrade TF/TB to 1.12 but bug is still (
<pre>
$ pip3 list | grep -e ""tensorflow""
tensorflow-estimator         1.13.0
tensorflow-gpu               1.12.0

~$ pip3 list | grep -e ""tensorboard""
tensorboard                  1.12.2</pre>

The graph isn't showing and get error in gui ""log"":https://github.com/deepfakes/faceswap/issues/656#issuecomment-471565261

",made downgrade bug still pip list pip list graph showing get error log,issue,negative,neutral,neutral,neutral,neutral,neutral
472103462,"Ok, this is a tf 1.13 then most likely. We use the Keras callback to log for tensorboard. I would guess that Keras backend has not been updated.",likely use log would guess,issue,negative,neutral,neutral,neutral,neutral,neutral
472102590,"Just tested on a fresh environment, got the same error in the gui and graph is not showing.
But training works anyways.

Ubuntu 16.04, Cuda 10.0 ,tensorflow-gpu>=1.13.1",tested fresh environment got error graph showing training work anyways,issue,negative,positive,positive,positive,positive,positive
472095378,"> Is this definitely from a model that has started training?

Yes, this logs from model which must have info about 1000 epoch.

> This may be a TF/TB 1.13 related issue. 

Ок. I will try to compile TF/TB 1.12 for cuda 10.0 and cudnn v7.4.1.5, and see would be working the graph 

Thank you!",definitely model training yes model must epoch may related issue try compile see would working graph thank,issue,positive,neutral,neutral,neutral,neutral,neutral
472084636,This may be a TF/TB 1.13 related issue. Unfortunately we only officially support up to 1.12 at the moment.,may related issue unfortunately officially support moment,issue,negative,negative,negative,negative,negative,negative
472084064,"Is this definitely from a model that has started training? There's no loss records in it, just the graph definition
![image](https://user-images.githubusercontent.com/36920800/54219010-88cfd700-44e6-11e9-9540-2d7c773b8c11.png)
",definitely model training loss graph definition image,issue,negative,neutral,neutral,neutral,neutral,neutral
471695981,It's the tensorboard logs that are stored in your model folder that I need. They just contain the loss history,model folder need contain loss history,issue,negative,neutral,neutral,neutral,neutral,neutral
471568444,"Unfortunately this looks like corruption in one of your logfiles
```tensorflow.python.framework.errors_impl.DataLossError: truncated record at 305961```
How many logfiles do you have? Would you be able to zip up the log folder and put it somewhere for me to download and have a look to see whether I can handle this error",unfortunately like corruption one truncated record many would able zip log folder put somewhere look see whether handle error,issue,negative,positive,positive,positive,positive,positive
471565261,"unfortunately the graph is not showing with last commit.
In gui log error:
<pre>
03/11/2019 17:35:05 WARNING  From /home/telecast/Documents/faceswap_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.

03/11/2019 17:35:31 INFO     saved models
Exception in Tkinter callback
Traceback (most recent call last):
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 1705, in __call__
    return self.func(*args)
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 749, in callit
    func(*args)
  File ""/home/telecast/Documents/faceswap/lib/gui/display_page.py"", line 245, in <lambda>
    self.after(waittime, lambda t=waittime: self.update_page(t))
  File ""/home/telecast/Documents/faceswap/lib/gui/display_page.py"", line 244, in update_page
    self.load_display()
  File ""/home/telecast/Documents/faceswap/lib/gui/display_page.py"", line 256, in load_display
    self.display_item_process()
  File ""/home/telecast/Documents/faceswap/lib/gui/display_command.py"", line 217, in display_item_process
    selections=[""raw"", ""trend""])
  File ""/home/telecast/Documents/faceswap/lib/gui/stats.py"", line 348, in __init__
    self.refresh()
  File ""/home/telecast/Documents/faceswap/lib/gui/stats.py"", line 358, in refresh
    self.stats = self.get_raw()
  File ""/home/telecast/Documents/faceswap/lib/gui/stats.py"", line 370, in get_raw
    loss_dict = self.session.total_loss if self.is_totals else self.session.loss
  File ""/home/telecast/Documents/faceswap/lib/gui/stats.py"", line 144, in loss
    loss_dict = self.tb_logs.get_loss(session=self.session_id)[self.session_id]
  File ""/home/telecast/Documents/faceswap/lib/gui/stats.py"", line 67, in get_loss
    for event in tf.train.summary_iterator(logfile):
  File ""/home/telecast/Documents/faceswap_env/lib/python3.6/site-packages/tensorflow/python/summary/summary_iterator.py"", line 68, in summary_iterator
    for r in tf_record.tf_record_iterator(path):
  File ""/home/telecast/Documents/faceswap_env/lib/python3.6/site-packages/tensorflow/python/lib/io/tf_record.py"", line 181, in tf_record_iterator
    reader.GetNext()
  File ""/home/telecast/Documents/faceswap_env/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 489, in GetNext
    return _pywrap_tensorflow_internal.PyRecordReader_GetNext(self)
tensorflow.python.framework.errors_impl.DataLossError: truncated record at 305961",unfortunately graph showing last commit log error warning removed future instead saved exception recent call last file line return file line file line lambda lambda file line file line file line raw trend file line file line refresh file line else file line loss file line event file line path file line file line return self truncated record,issue,negative,negative,negative,negative,negative,negative
471565240,"Yes, can only force X to close every time. This crash report after forced shutdown:
==========================================================
```
03/10/2019 20:00:56 MainProcess     save_encoder_0  _base           save                      DEBUG    Saving model: 'E:\model\iae_encoder.h5'
03/10/2019 20:00:56 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_encoder': 1
03/10/2019 20:00:56 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread(s): 'save_decoder'
03/10/2019 20:00:56 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread 1 of 1: 'save_decoder_0'
03/10/2019 20:00:56 MainProcess     save_decoder_0  _base           save                      DEBUG    Saving model: 'E:\model\iae_decoder.h5'
03/10/2019 20:00:56 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_decoder': 1
03/10/2019 20:00:57 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread(s): 'save_intermediate_a'
03/10/2019 20:00:57 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread 1 of 1: 'save_intermediate_a_0'
03/10/2019 20:00:58 MainProcess     save_intermediate_a_0 _base           save                      DEBUG    Saving model: 'E:\model\iae_intermediate_A.h5'
03/10/2019 20:00:58 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_intermediate_a': 1
03/10/2019 20:00:59 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread(s): 'save_intermediate_b'
03/10/2019 20:00:59 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread 1 of 1: 'save_intermediate_b_0'
03/10/2019 20:00:59 MainProcess     save_intermediate_b_0 _base           save                      DEBUG    Saving model: 'E:\model\iae_intermediate_B.h5'
03/10/2019 20:00:59 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_intermediate_b': 1
03/10/2019 20:00:59 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread(s): 'save_inter'
03/10/2019 20:01:00 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread 1 of 1: 'save_inter_0'
03/10/2019 20:01:00 MainProcess     save_inter_0    _base           save                      DEBUG    Saving model: 'E:\model\iae_inter.h5'
03/10/2019 20:01:00 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_inter': 1
03/10/2019 20:01:00 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread(s): 'save_state'
03/10/2019 20:01:00 MainProcess     training_0      multithreading  start                     DEBUG    Starting thread 1 of 1: 'save_state_0'
03/10/2019 20:01:02 MainProcess     save_state_0    _base           save                      DEBUG    Saving State
03/10/2019 20:01:02 MainProcess     training_0      multithreading  start                     DEBUG    Started all threads 'save_state': 1
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_encoder'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_encoder_0'
03/10/2019 20:01:02 MainProcess     save_state_0    _base           save                      DEBUG    Saved State
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_encoder'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_decoder'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_decoder_0'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_decoder'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_intermediate_a'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_intermediate_a_0'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_intermediate_a'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_intermediate_b'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_intermediate_b_0'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_intermediate_b'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_inter'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_inter_0'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_inter'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Threads: 'save_state'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joining Thread: 'save_state_0'
03/10/2019 20:01:02 MainProcess     training_0      multithreading  join                      DEBUG    Joined all Threads: 'save_state'
03/10/2019 20:01:02 MainProcess     training_0      _base           save_models               INFO     saved models
03/10/2019 20:01:12 MainProcess     training_0      multithreading  run                       DEBUG    Error in thread (training_0): [Errno 22] Invalid argument
03/10/2019 20:01:12 MainProcess     MainThread      train           monitor_console           DEBUG    Thread error detected
03/10/2019 20:01:12 MainProcess     MainThread      train           monitor_console           DEBUG    Closed Console Monitor
03/10/2019 20:01:12 MainProcess     MainThread      train           end_thread                DEBUG    Ending Training thread
03/10/2019 20:01:12 MainProcess     MainThread      train           end_thread                CRITICAL Error caught! Exiting...
03/10/2019 20:01:12 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Threads: 'training'
03/10/2019 20:01:12 MainProcess     MainThread      multithreading  join                      DEBUG    Joining Thread: 'training_0'
03/10/2019 20:01:12 MainProcess     MainThread      multithreading  join                      ERROR    Caught exception in thread: 'training_0'
Traceback (most recent call last):
  File ""C:\Users\000\faceswap\lib\cli.py"", line 107, in execute_script
    process.process()
  File ""C:\Users\000\faceswap\scripts\train.py"", line 101, in process
    self.end_thread(thread, err)
  File ""C:\Users\000\faceswap\scripts\train.py"", line 126, in end_thread
    thread.join()
  File ""C:\Users\000\faceswap\lib\multithreading.py"", line 443, in join
    raise thread.err[1].with_traceback(thread.err[2])
  File ""C:\Users\000\faceswap\lib\multithreading.py"", line 381, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\000\faceswap\scripts\train.py"", line 152, in training
    raise err
  File ""C:\Users\000\faceswap\scripts\train.py"", line 142, in training
    self.run_training_cycle(model, trainer)
  File ""C:\Users\000\faceswap\scripts\train.py"", line 214, in run_training_cycle
    trainer.train_one_step(viewer, timelapse)
  File ""C:\Users\000\faceswap\plugins\train\trainer\_base.py"", line 152, in train_one_step
    self.print_loss(loss)
  File ""C:\Users\000\faceswap\plugins\train\trainer\_base.py"", line 130, in print_loss
    self.timestamp, self.model.iterations, output[0], output[1]), end='\r')
OSError: [Errno 22] Invalid argument

============ System Information ============
encoding:          cp936
git_branch:        master
git_commits:        1f8da1d Tensorflow version check
gpu_cuda:          9.0
gpu_cudnn:        7.3.1
gpu_devices:       GPU_0: GeForce GTX 1060 6GB
gpu_driver:        419.17
gpu_vram:          GPU_0: 6144MB
os_machine:        AMD64
os_platform:       Windows-10-10.0.17763-SP0
os_release:        10
py_command:        C:\Users\000\faceswap\faceswap.py train -A E:/A/face/ -B E:/B/Face -m E:/model -t iae -s 100 -bs 64 -it 1000000 -g 1 -ps 100 -nl -L INFO -gui
py_conda_version:  conda 4.5.12
py_implementation: CPython
py_version:        3.6.8
py_virtual_env:    True
sys_cores:         8
sys_processor:     Intel64 Family 6 Model 58 Stepping 9, GenuineIntel
sys_ram:           Total: 16065MB, Available: 10308MB, Used: 5757MB, Free: 10308MB

=============== Pip Packages ===============
absl-py==0.7.0
astor==0.7.1
certifi==2018.11.29
Click==7.0
cloudpickle==0.8.0
cmake==3.13.3
cycler==0.10.0
cytoolz==0.9.0.1
dask==1.1.2
decorator==4.3.2
dlib==19.16.99
face-recognition==1.2.3
face-recognition-models==0.3.0
ffmpy==0.2.2
gast==0.2.2
grpcio==1.16.1
h5py==2.9.0
imageio==2.5.0
Keras==2.2.4
Keras-Applications==1.0.6
Keras-Preprocessing==1.0.5
kiwisolver==1.0.1
Markdown==3.0.1
matplotlib==2.2.2
mkl-fft==1.0.10
mkl-random==1.0.2
networkx==2.2
numpy==1.15.4
nvidia-ml-py3==7.352.0
olefile==0.46
opencv-python==4.0.0.21
pathlib==1.0.1
Pillow==5.4.1
protobuf==3.6.1
psutil==5.5.0
pyparsing==2.3.1
pyreadline==2.1
python-dateutil==2.8.0
pytz==2018.9
PyWavelets==1.0.1
PyYAML==3.13
scikit-image==0.14.1
scikit-learn==0.20.2
scipy==1.2.1
six==1.12.0
tensorboard==1.12.2
tensorflow==1.12.0
termcolor==1.1.0
toolz==0.9.0
tornado==5.1.1
tqdm==4.31.1
Werkzeug==0.14.1
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at C:\Users\000\MiniConda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.0                    py36_0  
astor                     0.7.1                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.1.23                     0  
certifi                   2018.11.29               py36_0  
Click                     7.0                       <pip>
cloudpickle               0.8.0                    py36_0  
cmake                     3.13.3                    <pip>
cudatoolkit               9.0                           1  
cudnn                     7.3.1                 cuda9.0_0  
cycler                    0.10.0           py36h009560c_0  
cytoolz                   0.9.0.1          py36hfa6e2cd_1  
dask-core                 1.1.2                      py_0  
decorator                 4.3.2                    py36_0  
dlib                      19.16.99                  <pip>
face-recognition          1.2.3                     <pip>
face-recognition-models   0.3.0                     <pip>
ffmpeg                    4.1               h6538335_1002    conda-forge
ffmpy                     0.2.2                     <pip>
freetype                  2.9.1                ha9979f8_1  
gast                      0.2.2                    py36_0  
grpcio                    1.16.1           py36h351948d_1  
h5py                      2.9.0            py36h5e291fa_0  
hdf5                      1.10.4               h7ebc959_0  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
imageio                   2.5.0                    py36_0  
intel-openmp              2019.1                      144  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.6                    py36_0  
keras-base                2.2.4                    py36_0  
keras-preprocessing       1.0.5                    py36_0  
kiwisolver                1.0.1            py36h6538335_0  
libpng                    1.6.36               h2a8f88b_0  
libprotobuf               3.6.1                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.0.1                    py36_0  
matplotlib                2.2.2            py36had4c4a9_2  
mkl                       2019.1                      144  
mkl_fft                   1.0.10           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
networkx                  2.2                      py36_1  
numpy                     1.15.4           py36h19fb1c0_0  
numpy-base                1.15.4           py36hc3f5095_0  
nvidia-ml-py3             7.352.0                   <pip>
olefile                   0.46                     py36_0  
opencv-python             4.0.0.21                  <pip>
openssl                   1.1.1b               he774522_0  
pathlib                   1.0.1                    py36_1  
pillow                    5.4.1            py36hdc69c19_0  
pip                       19.0.3                   py36_0  
protobuf                  3.6.1            py36h33f27b4_0  
psutil                    5.5.0            py36he774522_0  
pyparsing                 2.3.1                    py36_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
python                    3.6.8                h9f7ef89_7  
python-dateutil           2.8.0                    py36_0  
pytz                      2018.9                   py36_0  
pywavelets                1.0.1            py36h8c2d366_0  
pyyaml                    3.13             py36hfa6e2cd_0  
qt                        5.9.7            vc14h73c81de_0  
scikit-image              0.14.1           py36ha925a31_0  
scikit-learn              0.20.2           py36h343c172_0  
scipy                     1.2.1            py36h29ff71c_0  
setuptools                40.8.0                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.26.0               he774522_0  
tensorboard               1.12.2           py36h33f27b4_0  
tensorflow                1.12.0          gpu_py36ha5f9131_0  
tensorflow-base           1.12.0          gpu_py36h6e53903_0  
tensorflow-gpu            1.12.0               h0d30ee6_0  
termcolor                 1.1.0                    py36_1  
tk                        8.6.8                hfa6e2cd_0  
toolz                     0.9.0                    py36_0  
tornado                   5.1.1            py36hfa6e2cd_0  
tqdm                      4.31.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_0  
werkzeug                  0.14.1                   py36_0  
wheel                     0.33.1                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  ```",yes force close every time crash report forced shutdown save saving model start start starting thread start starting thread save saving model start start starting thread start starting thread save saving model start start starting thread start starting thread save saving model start start starting thread start starting thread save saving model start start starting thread start starting thread save saving state start join joining join joining thread save saved state join join joining join joining thread join join joining join joining thread join join joining join joining thread join join joining join joining thread join join joining join joining thread join saved run error thread invalid argument train thread error train closed console monitor train ending training thread train critical error caught join joining join joining thread join error caught exception thread recent call last file line file line process thread err file line file line join raise file line run file line training raise err file line training model trainer file line viewer file line loss file line output output invalid argument system information master version check train true family model stepping total available used free pip environment name version build channel astor blas click pip pip cycler decorator pip pip pip pip gast markdown pip pip pillow pip python sip six tornado wheel,issue,positive,positive,neutral,neutral,positive,positive
471531762,"Does this happen every time? If not, don't worry about it, as sometimes the train process gets stuck on shutdown. If it does, please provide the crash report",happen every time worry sometimes train process stuck shutdown please provide crash report,issue,negative,neutral,neutral,neutral,neutral,neutral
471320886,"Hi, @torzdf 
thank for your reply!
This file is exist, but it's empty. 
> :~/Documents/faceswap$ ll lib/gui/.cache/.recent.json
-rw-rw-r-- 1 telecast telecast 0 мар  3 16:56 lib/gui/.cache/.recent.json


",hi thank reply file exist empty telecast telecast,issue,negative,negative,neutral,neutral,negative,negative
471309554,Added in code attribution to master,added code attribution master,issue,negative,neutral,neutral,neutral,neutral,neutral
471293319,"Can you confirm whether the following file exists, and if so, could you provide it?
`<faceswap folder>/lib/gui/.cache/.recent.json`",confirm whether following file could provide folder,issue,negative,neutral,neutral,neutral,neutral,neutral
471180233,"quick note:

doc here https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#prerequisites should change from 
docker exec faceswap-gpu python /srv/tools.py gui
to
docker exec  deepfakes-gpu python /srv/faceswap.py gui
for me the gui only works this on latest manjaro (im using the nvidia-docker approach)",quick note doc change docker python docker python work latest approach,issue,negative,positive,positive,positive,positive,positive
471159836,"My solution is to set self.env.cuda_path after line 391 instead of 406.
the total cuda_check_linux function is like below:
    def cuda_check_linux(self):
        """""" Check Linux CUDA Version """"""
        chk = os.popen(""ldconfig -p | grep -P \""libcudart.so.\\d+.\\d+\"" | head -n 1"").read()
        if self.env.ld_library_path and not chk:
            paths = self.env.ld_library_path.split("":"")
            for path in paths:
                chk = os.popen(""ls {} | grep -P -o \""libcudart.so.\\d+.\\d+\"" | ""
                               ""head -n 1"".format(path)).read()
                self.env.cuda_path = path+""/../"" # set cuda_path to parent folder of directory that contains libcudart.so
                if chk:
                    break
        if not chk:
            self.output.error(""CUDA not found. Install and try again.\n""
                              ""Recommended version:      CUDA 9.0     cuDNN 7.1.3\n""
                              ""CUDA: https://developer.nvidia.com/cuda-downloads\n""
                              ""cuDNN: https://developer.nvidia.com/rdp/cudnn-download"")
            return
        cudavers = chk.strip().replace(""libcudart.so."", """")
        #self.env.cuda_version = cudavers[:cudavers.find("" "")]
        self.env.cuda_version = cudavers
        if self.env.cuda_version:
            self.output.info(""CUDA version: "" + self.env.cuda_version)
            #self.env.cuda_path = chk[chk.find(""=>"") + 3:chk.find(""targets"") - 1]",solution set line instead total function like self check version head path head path set parent folder directory break found install try version return version,issue,positive,neutral,neutral,neutral,neutral,neutral
470995864,"Discord would be a better place for this kind of discussion:
https://discord.gg/FdEwxXd
",discord would better place kind discussion,issue,positive,positive,positive,positive,positive,positive
470303625,Pull latest code. Update requirements. Specifically tensorflow to 1.12,pull latest code update specifically,issue,negative,positive,positive,positive,positive,positive
469641537,"Unfortunately stability changes to the code, and work from @andenixa means that the OHR pre-refactor does not work in the new world (it is the only model we were unable to migrate). There is a snapshot branch pre-refactor to be able to load/train this model.

See: https://github.com/deepfakes/faceswap-playground/issues/249#issuecomment-463845624",unfortunately stability code work work new world model unable migrate snapshot branch able model see,issue,negative,negative,neutral,neutral,negative,negative
469321949,"We have no current plans on our roadmap to implement an api.

We are open to pull requests though",current implement open pull though,issue,negative,neutral,neutral,neutral,neutral,neutral
469243682,"I faced the same issue while building it, as the log says your using python version 3.6

Consider executing with python3

python3 setup.py

python3 faceswap.py -h 

Thanks",faced issue building log python version consider python python python thanks,issue,negative,positive,positive,positive,positive,positive
469083272,Are you running CPU or GPU version of faceswap? What's your graphics card?,running version graphic card,issue,negative,neutral,neutral,neutral,neutral,neutral
469062437,"@torzdf : updating requirement.txt  **numpy==1.16.2**, helped me.
```log
tqdm
psutil
pathlib
numpy==1.16.2
opencv-python
scikit-image
scikit-learn
matplotlib==2.2.2
ffmpy==0.2.2
nvidia-ml-py3
h5py==2.9.0
Keras==2.2.4
cmake
dlib
face-recognition

# tensorflow is included within the docker image.
# If you are looking for dependencies for a manual install,

# NB: Tensorflow version 1.12 is the minimum supported version of Tensorflow.
#    If your graphics card support is below Cuda 9.0 you will need to either
#    compile tensorflow yourself or download a custom version.
#    Install 1.12.0<=tensorflow-gpu<=1.13.0 for CUDA 9.0
#    or tensorflow-gpu>=1.13.1 or tf-nightly-gpu for CUDA 10.0
```

```terminal
Adarshs-MacBook-Pro:faceswap-0.95b adarsh$ python3 setup.py
WARNING Running without root/admin privileges
INFO    The tool provides tips for installation
        and installs required python packages
INFO    Setup in Darwin 18.2.0
INFO    Installed Python: 3.6.8 64bit
INFO    Encoding: UTF-8
INFO    Upgrading pip...
INFO    Installed pip: 19.0.3
Enable  Docker? [y/N] n
INFO    Docker Disabled
Enable  CUDA? [Y/n] n
INFO    CUDA Disabled
INFO    Checking System Dependencies...
INFO    CMake version: 3.13.4
Please ensure your System Dependencies are met. Continue? [y/N] y
INFO    Installing Required Python Packages. This may take some time...
INFO    Installing numpy==1.16.2
INFO    All python3 dependencies are met.
        You are good to go.
        
        Enter:  'python faceswap.py -h' to see the options
                'python faceswap.py gui' to launch the GUI
Adarshs-MacBook-Pro:faceswap-0.95b adarsh$ python3 faceswap.py gui
03/04/2019 02:11:48 INFO     Log level set to: INFO
03/04/2019 02:11:50 INFO     font search path ['/Users/adarsh/Library/Python/3.6/lib/python/site-packages/matplotlib/mpl-data/fonts/ttf', '/Users/adarsh/Library/Python/3.6/lib/python/site-packages/matplotlib/mpl-data/fonts/afm', '/Users/adarsh/Library/Python/3.6/lib/python/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']
Unable to revert mtime: /Library/Fonts
Fontconfig warning: ignoring UTF-8: not a valid region tag
03/04/2019 02:11:51 INFO     Could not open font file /Library/Fonts/NISC18030.ttf
03/04/2019 02:11:52 INFO     generated new fontManager
03/04/2019 02:11:52 INFO     Updating config at: '/Users/adarsh/Documents/Playground/faceswap-0.95b/config/train.ini'
03/04/2019 02:11:52 INFO     Loading config: '/Users/adarsh/Documents/Playground/faceswap-0.95b/config/train.ini'
03/04/2019 02:11:52 INFO     Updating config at: '/Users/adarsh/Documents/Playground/faceswap-0.95b/config/extract.ini'
03/04/2019 02:11:52 INFO     Loading config: '/Users/adarsh/Documents/Playground/faceswap-0.95b/config/extract.ini'

```


<img width=""1015"" alt=""screenshot 2019-03-04 at 2 16 01 am"" src=""https://user-images.githubusercontent.com/11833079/53701448-7d641800-3e23-11e9-9854-cf18d8e0e182.png"">

Thanks",log included within docker image looking manual install version minimum version graphic card support need either compile custom version install terminal python warning running without tool installation python setup python bit pip pip enable docker docker disabled enable disabled system version please ensure system met continue python may take time python met good go enter see launch python log level set font search path unable revert warning valid region tag could open font file new loading loading thanks,issue,positive,positive,neutral,neutral,positive,positive
469058659,"@torzdf : Thanks, :)  let me redo it: set the env correctly for Numpy and other again and get back again.",thanks let redo set correctly get back,issue,negative,positive,neutral,neutral,positive,positive
469057907,"Ok, you won't have one, because the log won't have been generated yet.

This is a problem with Numpy/your environment not Faceswap. so you will need to look into the issue there.",wo one log wo yet problem environment need look issue,issue,negative,neutral,neutral,neutral,neutral,neutral
469056806,"I just find these logs getting generated.
[faceswap_gui.log](https://github.com/deepfakes/faceswap/files/2923593/faceswap_gui.log)

Kindly can you please tell me the path of other logs which can be useful for you?

",find getting kindly please tell path useful,issue,positive,positive,positive,positive,positive,positive
469050037,"The temp folder only exists for the duration of the install, so it would no longer exist when you run that command. I'm not sure why that command would fail initially though, I haven't seen that happen before. I would guess that it was an issue with pip rather than an issue with the location though, as the previous rename command ran ok.

You can get the dlib file by opening the installer with 7zip, renaming the correct one (as per the log... it has to be named correctly) and then doing pip install yourself.

Yes, you would need to delete the folder. This is a safety precaution to stop people scrubbing old data.",temp folder duration install would longer exist run command sure command would fail initially though seen happen would guess issue pip rather issue location though previous rename command ran get file opening installer zip correct one per log correctly pip install yes would need delete folder safety precaution stop people old data,issue,negative,negative,neutral,neutral,negative,negative
469047346,"By the way, when I manually run the command, I got this message:
```
C:\Users\Dante>""C:\Users\Dante\Miniconda3\scripts\activate.bat"" && conda activate ""faceswap"" && pip install C:\Users\Dante\AppData\Local\Temp\nsxC770.tmp\faceswap\temp\dlib-19.16.99-cp36-cp36m-win_amd64.whl &&  conda deactivate
Requirement 'C:\\Users\\Dante\\AppData\\Local\\Temp\\nsxC770.tmp\\faceswap\\temp\\dlib-19.16.99-cp36-cp36m-win_amd64.whl' looks like a filename, but the file does not exist
Processing c:\users\dante\appdata\local\temp\nsxc770.tmp\faceswap\temp\dlib-19.16.99-cp36-cp36m-win_amd64.whl
Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\Users\\Dante\\AppData\\Local\\Temp\\nsxC770.tmp\\faceswap\\temp\\dlib-19.16.99-cp36-cp36m-win_amd64.whl
```
I could only assume the temp folder was placed in a wrong directory during the installation.",way manually run command got message activate pip install deactivate requirement like file exist could install due file directory could assume temp folder wrong directory installation,issue,negative,negative,negative,negative,negative,negative
469047117,"Confirmed the fix is working now. Thanks for the quick update.

However, when running the installer again, after git clone successfully ran, I got the following error:
```
(check) Git installed: git version 2.13.0.windows.1
(check) MiniConda installed: conda 4.5.12
(check) CPU Supports AVX Instructions
(check) CPU Supports SSE4 Instructions
(check) Completed check for installed applications

All Prerequisites installed.
Downloading Faceswap...
Execute: git clone --depth 1 --no-single-branch https://github.com/deepfakes/faceswap.git ""d:\faceswap""
Creating Conda Virtual Environment...
Execute: ""C:\Users\Dante\Miniconda3\scripts\activate.bat"" && conda env remove -y -n ""faceswap"" && conda deactivate
Execute: ""C:\Users\Dante\Miniconda3\scripts\activate.bat"" && conda create -y python=3.6 -n  ""faceswap"" && conda deactivate
Installing Dlib...
Renaming dlib-19.16.99-cp36-cp36m-win_amd64_cuda90_avx.whl to dlib-19.16.99-cp36-cp36m-win_amd64.whl
Execute: ""C:\Users\Dante\Miniconda3\scripts\activate.bat"" && conda activate ""faceswap"" && pip install C:\Users\Dante\AppData\Local\Temp\nsxC770.tmp\faceswap\temp\dlib-19.16.99-cp36-cp36m-win_amd64.whl &&  conda deactivate
Error Installing Dlib
Install Aborted
```

I'm not so sure what is causing this, but when I tried to run the installer again, I got a pop-up message box saying ""Destination directory exists"". I assume I have to remove the directory to keep going?",confirmed fix working thanks quick update however running installer git clone successfully ran got following error check git git version check check check check check execute git clone depth virtual environment execute remove deactivate execute create deactivate execute activate pip install deactivate error install aborted sure causing tried run installer got message box saying destination directory assume remove directory keep going,issue,positive,positive,positive,positive,positive,positive
469045533,"Module not found is probably system conflicts.

No frames to process is because there are no frames in your input folder.",module found probably system process input folder,issue,negative,neutral,neutral,neutral,neutral,neutral
469040351,"problem:
python faceswap.py extract

when I try to install numpy as 1.15.4 will be
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'

I change numpy as 1.16.2 will be 
ERROR No frames to process. Exiting

I am using mac.",problem python extract try install module change error process mac,issue,negative,neutral,neutral,neutral,neutral,neutral
469013145,"I've had a quick look at this PR. It definitely speeds things up, so that's good. It does break the timelapse function though, so that will need to be looked at.

I may raise a PR against your repo for this, to try and standardise the code a bit more over what exists, and then hopefully we can pull this over and get it merged.",quick look definitely good break function though need may raise try code bit hopefully pull get,issue,positive,positive,positive,positive,positive,positive
469006769,"The execution command for git in the installer source is:
```""$\""$PROGRAMFILES64\git\bin\git.exe$\""```
Assuming your windows path for program files is correct, this should point to your d:\ drive:
https://nsis.sourceforge.io/Reference/$PROGRAMFILES

I have changed the installer just to run `git clone ...` if a previous installation is detected, otherwise to execute as it previously did. Hopefully this will fix this potential issue. Uploaded to v0.95b in releases
",execution command git installer source assuming path program correct point drive installer run git clone previous installation otherwise execute previously hopefully fix potential issue,issue,negative,negative,negative,negative,negative,negative
468959929,"I cleaned the multiprocessing part up a bit and rebased it on staging.
https://github.com/kilroythethird/faceswap/tree/mp_training_data
I found a windows tester an at least on win10 it seem to run fine (it also does when setting multiprocessing.set_start_method(""spawn"")).
Code review/critic would be awesome.

IMO the training_data generator definitely needs multiprocessing. In some cases i wait over half a second on batches sometimes even more.
And mp.Queues for sending the batches is simply not useable.
See:

```
sh-5.0$ python -m timeit -n 10 -r 5 -s 'import numpy as np; import pickle; d=np.zeros(64*(256*256*3+128*128*3+128*128*3+128*128), dtype='float')' -c 'pickle.loads(pickle.dumps(d))'
10 loops, best of 5: 391 msec per loop
```
This is assuming a 128x128 model with a mask and batchsize 64. And that is just one side.

*e: Not sure why github show all the other changes when comparing with staging. `git diff upstream/staging` on my local version doesn't*",part bit staging found tester least win seem run fine also setting spawn code would awesome generator definitely need wait half second sometimes even sending simply see python import pickle best per loop assuming model mask one side sure show staging git local version,issue,positive,positive,positive,positive,positive,positive
468913895,"More information please, which model? Which commit? If you're on the GUI post the output of Tools>System Informations

This is model corruption which can happen with Convolution Networks. You can restore from the .bk files in your model folder and carry on.",information please model commit post output system model corruption happen convolution restore model folder carry,issue,positive,neutral,neutral,neutral,neutral,neutral
468736497,"These issues aren't bugs.

Please repost either in Discord or Faceswap_Playground.",please repost either discord,issue,negative,neutral,neutral,neutral,neutral,neutral
468735823,"There is not enough information here to know if this is an issue. Which trainer are you using? What command did you run? What are your config options?

There is a known issue with filling the queue for training leading to slower launch times.",enough information know issue trainer command run known issue filling queue training leading launch time,issue,negative,neutral,neutral,neutral,neutral,neutral
468609210,"```Number of images is lower than batch-size (Note that too few images may lead to bad training). # images: 1, batch-size: 64```",number lower note may lead bad training,issue,negative,negative,negative,negative,negative,negative
468604051,"I have the same issue. My Git is placed into 'C:\Program Files\git\bin\git.exe', And I want to install faceswap into 'D:\Program Files\faceswap'. In order to to prevent ambiguity from blanks in paths, these paths should be wrapped in quotes.

```
# Failed
C:\Program Files\git\bin\git.exe clone --depth 1 --no-single-branch https://github.com/deepfakes/faceswap.git D:\Program Files\faceswap
```

```
# Succeed
'C:\Program Files\git\bin\git.exe clone' --depth 1 --no-single-branch https://github.com/deepfakes/faceswap.git 'D:\Program Files\faceswap'
```",issue git want install order prevent ambiguity wrapped clone depth succeed clone depth,issue,positive,neutral,neutral,neutral,neutral,neutral
468568247,"when i try to train new model like that:

```03/01/2019 14:14:43 INFO     Loading data, this may take a while...
03/01/2019 14:14:43 INFO     Loading Model from Original plugin...
03/01/2019 14:14:43 INFO     Loading config: 'D:\phpStudy2\PHPTutorial\WWW\faces
wap\config\train.ini'
03/01/2019 14:14:43 WARNING  No existing state file found. Generating.
03/01/2019 14:14:43 WARNING  From D:\Python37\lib\site-packages\tensorflow\pytho
n\framework\op_def_library.py:263: colocate_with (from tensorflow.python.framewo
rk.ops) is deprecated and will be removed in a future version.\nInstructions for
 updating:\nColocations handled automatically by placer.
03/01/2019 14:14:43 WARNING  Failed loading existing training data. Generating n
ew models
03/01/2019 14:14:44 INFO     Loading Trainer from Original plugin...
03/01/2019 14:14:44 INFO     Enabled TensorBoard Logging
03/01/2019 14:14:44 ERROR    Caught exception in thread: 'load_batches_0'
03/01/2019 14:14:45 CRITICAL Error caught! Exiting...
03/01/2019 14:14:45 ERROR    Caught exception in thread: 'training_0'
03/01/2019 14:14:46 ERROR    Got Exception on main handler:\nTraceback (most rec
ent call last):\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\cli.py"", line
90, in execute_script\n process.process()\n File ""D:\phpStudy2\PHPTutorial\WWW\f
aceswap\scripts\train.py"", line 97, in process\n self.end_thread(thread, err)\n
File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\scripts\train.py"", line 122, in end_
thread\n thread.join()\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\multith
reading.py"", line 179, in join\n raise thread.err[1].with_traceback(thread.err[2
])\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\multithreading.py"", line 11
7, in run\n self._target(*self._args, **self._kwargs)\n File ""D:\phpStudy2\PHPTu
torial\WWW\faceswap\scripts\train.py"", line 148, in training\n raise err\n File
""D:\phpStudy2\PHPTutorial\WWW\faceswap\scripts\train.py"", line 138, in training\
n self.run_training_cycle(model, trainer)\n File ""D:\phpStudy2\PHPTutorial\WWW\f
aceswap\scripts\train.py"", line 210, in run_training_cycle\n trainer.train_one_s
tep(viewer, timelapse)\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\plugins\tra
in\trainer\_base.py"", line 138, in train_one_step\n loss[side] = batcher.train_o
ne_batch(is_preview_iteration)\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\plu
gins\train\trainer\_base.py"", line 211, in train_one_batch\n batch = self.get_ne
xt(is_preview_iteration)\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\plugins\t
rain\trainer\_base.py"", line 219, in get_next\n batch = next(self.feed)\n File ""
D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\training_data.py"", line 118, in miniba
tch\n load_thread.join()\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\multi
threading.py"", line 179, in join\n raise thread.err[1].with_traceback(thread.err
[2])\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\multithreading.py"", line
117, in run\n self._target(*self._args, **self._kwargs)\n File ""D:\phpStudy2\PHP
Tutorial\WWW\faceswap\lib\training_data.py"", line 77, in load_batches\n self.val
idate_samples(images)\n File ""D:\phpStudy2\PHPTutorial\WWW\faceswap\lib\training
_data.py"", line 95, in validate_samples\n assert length >= self.batchsize, msg\n
AssertionError: Number of images is lower than batch-size (Note that too few ima
ges may lead to bad training). # images: 1, batch-size: 64
03/01/2019 14:14:46 CRITICAL An unexpected crash has occurred. Crash report writ
ten to D:\phpStudy2\PHPTutorial\WWW\faceswap\crash_report.2019.03.01.14144502481
9.log. Please verify you are running the latest version of faceswap before repor
ting```

does anyone know why?",try train new model like loading data may take loading model original loading warning state file found generating warning removed future handled automatically placer warning loading training data generating loading trainer original logging error caught exception thread critical error caught error caught exception thread error got exception main handler call last file line file line thread err file line file line raise file line file line raise file line model trainer file line viewer file line loss side file line batch file line batch next file line file line raise file line file line file line assert length number lower note may lead bad training critical unexpected crash crash report writ ten please verify running latest version ting anyone know,issue,negative,positive,neutral,neutral,positive,positive
468543804,"@kvrooman Hi, thank you for your reply!
I have done extract process (contain alignment file from extract process) and i can train the model with original option successfully.
Need i do extract process for ""dfaker"" or ""dfl"" again? and what option i need choose for extract?",hi thank reply done extract process contain alignment file extract process train model original option successfully need extract process option need choose extract,issue,positive,positive,positive,positive,positive,positive
468293242,"You're trying to train a model that requires an alignment file to create masks from the landmarks in the alignment file.

The error says the software can't find 62725350.jpg in the alignment file. 

Likely you either have no alignment file, you pointed to the wrong file location for the alignment file, or the alignment file doesn't contain that image as the extract/detect tool didn't find and align a face in that image.

The alignment file is created by the extract process",trying train model alignment file create alignment file error ca find alignment file likely either alignment file pointed wrong file location alignment file alignment file contain image tool find align face image alignment file extract process,issue,negative,negative,negative,negative,negative,negative
468226299,"i solve this issue. thank you
Dlib needs to be compiled and installed, pip install dlib would not work",solve issue thank need pip install would work,issue,positive,neutral,neutral,neutral,neutral,neutral
468135032,"import dlib. 

This means this problem is coming from dlib

ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

This is saying it's looking for cuda 8.  You've either force installed the wrong dlib binary or haven't rebuilt your dlib after you installed cuda 9.  Either way, you need to remove the dlib you have installed then follow the install guide to install the correct version.",import problem coming open object file file directory saying looking either force wrong binary rebuilt either way need remove follow install guide install correct version,issue,negative,negative,negative,negative,negative,negative
468133988,"for my environment, when cuda9.0, cudnn 7.3 and tensorflow-gpu==1.12 are installed, there will be other issue:  for
python faceswap.py train -A ~/faceswap/data/trump -B ~/faceswap/data/cage -m ~/faceswap/models/
Traceback (most recent call last):
File ""faceswap.py"", line 5, in
import lib.cli as cli
File ""/home/csy/faceswap/lib/cli.py"", line 12, in
from lib.utils import safe_shutdown
File ""/home/csy/faceswap/lib/utils.py"", line 15, in
import dlib
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory
Have you ever encountered such a problem?",environment issue python train recent call last file line import file line import file line import open object file file directory ever problem,issue,negative,neutral,neutral,neutral,neutral,neutral
468124132,"Update Tensorflow to 1.12.

changyunke <notifications@github.com> 于2019年2月28日周四 上午8:54写道：

> I also have this problem, did you fix it?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/626#issuecomment-468091921>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AA9uSllA_JqvfxFLTeilQ1q74J0cHwWvks5vRyi9gaJpZM4bSSUA>
> .
>
",update also problem fix thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
468105957,"If you want to make it easier for yourself, install Anaconda and run setup.py in there. It will install Cuda and cuDNN for you. You can follow the relevant steps from the Windows Install Guide in INSTALL.md",want make easier install anaconda run install follow relevant install guide,issue,negative,positive,positive,positive,positive,positive
468105781,No. Nvidia's SLA prohibits it and we would need to support multiple graphics cards/OSes.,sla would need support multiple graphic,issue,negative,neutral,neutral,neutral,neutral,neutral
468104886,Can you provide a running configuration environment?,provide running configuration environment,issue,negative,neutral,neutral,neutral,neutral,neutral
468102744,"

Tensorflow 1.12 is unfortunately now a requirement, due to the above issue.

`ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory`
Tensorflow 1.12 supports Cuda 9.0 and cuDNN 7.3 by default, so you will need to install those from the Nvidia site.

If your graphics card does not support Cuda 9.0 then you will need to compile Tensorflow yourself for your Cuda/cuDNN combination. There are guides online.",unfortunately requirement due issue open object file file directory default need install site graphic card support need compile combination,issue,negative,negative,negative,negative,negative,negative
468038125,"faceswap.py is the main entry point.
Use `python faceswap.py gui`",main entry point use python,issue,negative,positive,positive,positive,positive,positive
468004855,"There is an intermittent bug in Windows which makes it hard to monitor if the windows are open or not.

To get around this, enable the `-dm`, `--disable-monitor` flag",intermittent bug hard monitor open get around enable flag,issue,negative,negative,negative,negative,negative,negative
467972421,"Please don't raise general questions here. Use either:
https://github.com/deepfakes/faceswap-playground
or Discord:
https://discord.gg/FdEwxXd",please raise general use either discord,issue,negative,positive,neutral,neutral,positive,positive
467818473,"Thanks for the PR. I have had a discussion with some of the other devs, and whilst we all agree that we should, at some point, implement a framework to test commits, it is something we'll need to review in more depth before implementing anything solid.

I'm closing this off for now, but may well revisit it at some point in the future.",thanks discussion whilst agree point implement framework test something need review depth anything solid may well revisit point future,issue,positive,positive,neutral,neutral,positive,positive
467544804,"By the author's own admission, Villain is not so great at learning colours, so the source/dest image selection is more important, You could try average color adjust

You can maybe get more advice from the Discord server:
https://discord.gg/FdEwxXd
",author admission villain great learning image selection important could try average color adjust maybe get advice discord server,issue,negative,positive,positive,positive,positive,positive
467459085,Thank you. Hugely appreciated. I will close this one off and re-address the Windows/VS2017 issue in future.,thank hugely close one issue future,issue,negative,positive,positive,positive,positive,positive
467457486,"Fix about docker #625 

Now this old PR only exists because of the trouble of dlib installation and VS2017. Maybe you can close this when you managed to find a way to get around with dlib.",fix docker old trouble installation maybe close find way get around,issue,negative,negative,neutral,neutral,negative,negative
467362211,@kartikey20 I think it will have to use `--ip=0.0.0.0` for jupyter notebook as well.,think use notebook well,issue,negative,neutral,neutral,neutral,neutral,neutral
466978449,"@DKingCN Thanks again for this. As you may have seen, I decided to go a different way and create an Installer for Windows, packaging in Dlib.... At some point in the future I will go back and review the Windows Code for compiling, but unfortunately my proposed solution up there didn't work.

Would it be possible for you to raise a new PR to amend the new code to fix the recent issues with Docker (#615 and https://github.com/deepfakes/faceswap-playground/issues/245)? You don't need to do anything with Windows, I will look at that at some point in the future, taking your notes on board.

I really appreciate any assistance you can give.",thanks may seen decided go different way create installer point future go back review code unfortunately solution work would possible raise new amend new code fix recent docker need anything look point future taking board really appreciate assistance give,issue,positive,positive,neutral,neutral,positive,positive
466977542,"Thanks for this PR. I need to review it, which I will do as soon as I can.",thanks need review soon,issue,negative,positive,positive,positive,positive,positive
466977214,I need to review first. I will once I get a chance,need review first get chance,issue,negative,positive,positive,positive,positive,positive
466785862,"Please stop posting general questions in issues.

Use the Discord: https://discord.gg/FdEwxXd
or Faceswap playground: https://github.com/deepfakes/faceswap-playground
",please stop posting general use discord playground,issue,negative,positive,neutral,neutral,positive,positive
466782037,"You can change from CMD ['./run_jupyter.sh'] to CMD ['/bin/bash'] and after creating the image from the new Dockerfile, run it using:

docker run -it --name jupyter-container --net=host -v ~/docker_files/:/ds tutorial

when the container comes to life, just run inside it:

jupyter notebook --no-browser --allow-root --port=7745 --NotebookApp.token='tutorial'

Finally, go to the http://localhost:7745/ and see the magic :D

I hope this is useful for you",change image new run docker run name tutorial container come life run inside notebook finally go see magic hope useful,issue,positive,positive,positive,positive,positive,positive
466771112,"And I'm closing again, because
1) this is not an issue
2) the correct locations are shown in INSTALL.md
3) You have already been told the correct versions to get.

To be safe, install the version closest to or above 7.2 that you can find.

Tensorflow site explicitily says you need a version greater or equal to 7.2:
![image](https://user-images.githubusercontent.com/36920800/53299449-2f06b600-3832-11e9-8a7e-26811487583e.png)


Any of these version of cuDNN available from the Nvidia cuDNNsite will work
![image](https://user-images.githubusercontent.com/36920800/53299436-ef3fce80-3831-11e9-8264-b7f7131bb104.png)
",issue correct shown already told correct get safe install version find site need version greater equal image version available work image,issue,positive,positive,positive,positive,positive,positive
466643700,"```02/23/2019 04:07:22 MainProcess     MainThread      logger          log_setup                 INFO     Log level set to: INFO
02/23/2019 04:07:22 MainProcess     MainThread      cli             execute_script            DEBUG    Executing: effmpeg. PID: 3020
02/23/2019 04:07:22 MainProcess     MainThread      effmpeg         process                   DEBUG    Running Effmpeg
02/23/2019 04:07:22 MainProcess     MainThread      effmpeg         __run_ffmpeg              DEBUG    Running ffmpeg: (exe: 'ffmpeg', inputs: {'C:\\faceswap_data\\final\\.%1_000001d.png': '-hide_banner ', 'C:\\faceswap_data\\1.mp4': None}, outputs: {'C:\\faceswap_data\\final.mpeg': '-c copy -map 0:0 -map 1:1 -y -vf fps=""24"" -c:v libx264'}
Traceback (most recent call last):
  File ""C:\faceswap\tools\effmpeg.py"", line 468, in __run_ffmpeg
    ff.run(stderr=subprocess.STDOUT)
  File ""C:\Anaconda3\envs\py35\lib\site-packages\ffmpy.py"", line 105, in run
    raise FFRuntimeError(self.cmd, self.process.returncode, out[0], out[1])
ffmpy.FFRuntimeError: `ffmpeg -hide_banner -i C:\faceswap_data\final\.%1_000001d.png -i C:\faceswap_data\1.mp4 -c copy -map 0:0 -map 1:1 -y -vf fps=24 -c:v libx264 C:\faceswap_data\final.mpeg` exited with status 1

STDOUT:


STDERR:


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\faceswap\lib\cli.py"", line 90, in execute_script
    process.process()
  File ""C:\faceswap\tools\effmpeg.py"", line 271, in process
    self.effmpeg_process()
  File ""C:\faceswap\tools\effmpeg.py"", line 290, in effmpeg_process
    action(**kwargs)
  File ""C:\faceswap\tools\effmpeg.py"", line 328, in gen_vid
    Effmpeg.__run_ffmpeg(exe=exe, inputs=_inputs, outputs=_outputs)
  File ""C:\faceswap\tools\effmpeg.py"", line 475, in __run_ffmpeg
    ""{}"".format(ffe))
ValueError: An unexpected FFRuntimeError occurred: `ffmpeg -hide_banner -i C:\faceswap_data\final\.%1_000001d.png -i C:\faceswap_data\1.mp4 -c copy -map 0:0 -map 1:1 -y -vf fps=24 -c:v libx264 C:\faceswap_data\final.mpeg` exited with status 1

STDOUT:


STDERR:


============ System Information ============
git_branch:        master
git_commits:       5ef7f8f Show samples... wrong input. a6c5f22 Creating Input Size config for models. b578e43 Update README.md. 6641c32 Change logfile dialog to SaveAs. c38cca0 bugfix: Alignments tool, missing-frames validation
gpu_cuda:          10.0
gpu_cudnn:         7.4.2
gpu_devices:       GPU_0: GeForce GTX 1070
gpu_driver:        419.17
gpu_vram:          GPU_0: 8192MB
os_machine:        AMD64
os_platform:       Windows-10-10.0.17763-SP0
os_release:        10
py_command:        tools.py effmpeg -a gen-vid -i C:\faceswap_data\final\ -o C:\faceswap_data\final.mpeg -fps 24 -m -r C:\faceswap_data\1.mp4
py_conda_version:  conda 4.6.4
py_implementation: CPython
py_version:        3.6.8
py_virtual_env:    False
sys_cores:         8
sys_processor:     Intel64 Family 6 Model 94 Stepping 3, GenuineIntel
sys_ram:           Total: 16266MB, Available: 8533MB, Used: 7733MB, Free: 8533MB

=============== Pip Packages ===============
absl-py==0.7.0
astor==0.7.1
certifi==2018.11.29
Click==7.0
cloudpickle==0.8.0
cmake==3.13.3
cycler==0.10.0
dask==1.1.1
datashape==0.5.4
decorator==4.3.2
dlib==19.16.0
face-recognition==1.2.3
face-recognition-models==0.3.0
ffmpeg-python==0.1.17
ffmpy==0.2.2
future==0.17.1
gast==0.2.2
grpcio==1.18.0
h5py==2.8.0
Keras==2.2.4
Keras-Applications==1.0.6
Keras-Preprocessing==1.0.5
kiwisolver==1.0.1
Markdown==3.0.1
matplotlib==2.2.2
mkl-fft==1.0.10
mkl-random==1.0.2
multipledispatch==0.6.0
networkx==2.2
numpy==1.15.4
nvidia-ml-py3==7.352.0
olefile==0.46
opencv-python==4.0.0.21
pathlib==1.0.1
Pillow==5.4.1
protobuf==3.6.1
psutil==5.5.0
pyparsing==2.3.1
pyreadline==2.1
pyshp==2.0.1
python-dateutil==2.7.5
pytz==2018.9
PyWavelets==1.0.1
PyYAML==3.13
scandir==1.7
scikit-image==0.14.2
scikit-learn==0.20.2
scipy==1.2.1
six==1.12.0
tensorboard==1.12.2
tensorflow==1.12.0
tensorflow-gpu==1.12.0
termcolor==1.1.0
toolz==0.9.0
tornado==5.1.1
tqdm==4.31.1
Werkzeug==0.14.1
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at C:\Anaconda3\envs\py35:
#
# Name                    Version                   Build  Channel
_tflow_select             2.1.0                       gpu  
absl-py                   0.7.0                    pypi_0    pypi
astor                     0.7.1                    py36_0  
blas                      1.0                         mkl  
ca-certificates           2019.1.23                     0  
certifi                   2018.11.29               py36_0  
click                     7.0                      pypi_0    pypi
cmake                     3.12.2               he025d50_0  
cmake-binary              3.9.1                h8f04fe6_1  
cudatoolkit               9.0                           1  
cudnn                     7.3.1                 cuda9.0_0  
cycler                    0.10.0           py36h009560c_0  
datashape                 0.5.4                    py36_1  
dlib                      19.16.0                  pypi_0    pypi
face-recognition          1.2.3                    pypi_0    pypi
face-recognition-models   0.3.0                    pypi_0    pypi
ffmpeg                    2.7.0                         0    menpo
ffmpeg-python             0.1.17                   pypi_0    pypi
ffmpy                     0.2.2                    pypi_0    pypi
freetype                  2.9.1                ha9979f8_1  
future                    0.17.1                   pypi_0    pypi
gast                      0.2.2                    pypi_0    pypi
grpcio                    1.18.0                   pypi_0    pypi
h5py                      2.8.0            py36hf7173ca_2  
hdf5                      1.8.20               hac2f561_1  
icc_rt                    2019.0.0             h0cc432a_1  
icu                       58.2                 ha66f8fd_1  
intel-openmp              2019.1                      144  
jpeg                      9b                   hb83a4c4_2  
keras                     2.2.4                         0  
keras-applications        1.0.6                    py36_0  
keras-base                2.2.4                    py36_0  
keras-gpu                 2.2.4                         0  
keras-preprocessing       1.0.5                    py36_0  
kiwisolver                1.0.1            py36h6538335_0  
libopencv                 3.4.2                h20b85fd_0  
libpng                    1.6.36               h2a8f88b_0  
libprotobuf               3.6.1                h7bd577a_0  
libtiff                   4.0.10               hb898794_2  
markdown                  3.0.1                    py36_0  
matplotlib                3.0.2            py36hc8f65d3_0  
mkl                       2019.1                      144  
mkl_fft                   1.0.10           py36h14836fe_0  
mkl_random                1.0.2            py36h343c172_0  
multipledispatch          0.6.0                    py36_0  
numpy                     1.15.4           py36h19fb1c0_0  
numpy-base                1.15.4           py36hc3f5095_0  
nvidia-ml-py3             7.352.0                  pypi_0    pypi
olefile                   0.46                     py36_0  
opencv                    3.4.2            py36h40b0b35_0  
openssl                   1.1.1a               he774522_0  
pillow                    5.4.1                    pypi_0    pypi
pip                       19.0.1                   py36_0  
protobuf                  3.6.1                    pypi_0    pypi
psutil                    5.5.0            py36he774522_0  
py-opencv                 3.4.2            py36hc319ecb_0  
pyparsing                 2.3.1                    py36_0  
pyqt                      5.9.2            py36h6538335_2  
pyreadline                2.1                      py36_1  
pyshp                     2.0.1                    py36_0  
python                    3.6.8                h9f7ef89_1  
python-dateutil           2.7.5                    py36_0  
pytz                      2018.9                   py36_0  
pyyaml                    3.13             py36hfa6e2cd_0  
qt                        5.9.7            vc14h73c81de_0  
scipy                     1.2.1            py36h29ff71c_0  
setuptools                40.8.0                   py36_0  
sip                       4.19.8           py36h6538335_0  
six                       1.12.0                   py36_0  
sqlite                    3.26.0               he774522_0  
tensorboard               1.12.2           py36h33f27b4_0  
tensorflow                1.12.0          gpu_py36ha5f9131_0  
tensorflow-base           1.12.0          gpu_py36h6e53903_0  
tensorflow-gpu            1.12.0                   pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
tk                        8.6.8                hfa6e2cd_0  
tornado                   5.1.1            py36hfa6e2cd_0  
tqdm                      4.31.1                     py_0  
vc                        14.1                 h0510ff6_4  
vs2015_runtime            14.15.26706          h3a45250_0  
werkzeug                  0.14.1                   pypi_0    pypi
wheel                     0.32.3                   py36_0  
wincertstore              0.2              py36h7fe50ca_0  
xz                        5.2.4                h2fa13f4_4  
yaml                      0.1.7                hc54c509_2  
zlib                      1.2.11               h62dcd97_3  
zstd                      1.3.7                h508b16e_0  ```",logger log level set process running running none copy recent call last file line file line run raise copy status handling exception another exception recent call last file line file line process file line action file line file line unexpected copy status system information master show wrong input input size update change tool validation false family model stepping total available used free pip environment name version build channel astor blas click cycler future gast markdown pillow pip python sip six tornado wheel,issue,negative,positive,neutral,neutral,positive,positive
466268572,"I have the same issue, I ended up installing it without Docker but it would be great to find a solution",issue ended without docker would great find solution,issue,negative,positive,positive,positive,positive,positive
464940297,"Whilst docker is technically supported, none of the primary Devs actually use it, so you're likely to get better support either in https://github.com/deepfakes/faceswap-playground or on the Discord server: https://discord.gg/FdEwxXd

I'd recommend following the Windows Install guide on the INSTALL.md page for better support.",whilst docker technically none primary actually use likely get better support either discord server recommend following install guide page better support,issue,positive,positive,positive,positive,positive,positive
464848914,"This is a different type of AI more suited to interview style/head close ups. Faceswap can do similar to what is shown here, but probably isn't the best tool for the job.",different type ai interview close similar shown probably best tool job,issue,positive,positive,positive,positive,positive,positive
464847856,Issues on this repo are for technical problems only.  Please see faceswap-playground or the discord server for questions like these.,technical please see discord server like,issue,negative,neutral,neutral,neutral,neutral,neutral
464847829,"This is currently an unused loss functions, which is why they haven't been picked up yet....

For style consistency, please could you `import numpy as np` and update the references accordingly?

Thanks",currently unused loss picked yet style consistency please could import update accordingly thanks,issue,negative,positive,neutral,neutral,positive,positive
464707069,"If you could transfer to me, that would be great. If you need to discuss, then email torzdf@gmail.com.

Thanks",could transfer would great need discus thanks,issue,positive,positive,positive,positive,positive,positive
462314955,"Also, the issues area is not the place for looking for technical support. You're best off going to the discord.

https://discord.gg/FdEwxXd
",also area place looking technical support best going discord,issue,positive,positive,positive,positive,positive,positive
462314577,"Crash report.

Ultimately if this isn't importing, you haven't set up correctly.",crash report ultimately set correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
462194412,"I never tried conda, and still not feeling like to do it. Will prefer leave this to you. Thanks.",never tried still feeling like prefer leave thanks,issue,positive,positive,positive,positive,positive,positive
462159236,"Coverage should be a percent value which only ever changes the final coverage by an amount divisible by 8 (or perhaps even 2). A better solution would be to assert this at runtime (probably by adding a custom action for argparse that spits out valid amounts either side of the given figure)... so 67% should not be a valid coverage (256 * 0.67 = 171.52), but 68.75% and 65.625% would be valid (176 and 168 pixels respectively)

*[edit]* Or even better, make it totally transparent to the end user, and automatically select the closest valid percentage to the given value (so under the hood, in your example, switch the coverage to 65.625%)",coverage percent value ever final coverage amount divisible perhaps even better solution would assert probably custom action valid either side given figure valid coverage would valid respectively edit even better make totally transparent end user automatically select valid percentage given value hood example switch coverage,issue,positive,positive,positive,positive,positive,positive
462144429,"@DKingCN   Ok, I've finally had a chance to look at this... I can build dlib with Visual Studio Build Tools 2017 without a cmake (non-python) install, but only if I download dlib from the github repo and run setup.py. If I try to install from pypi I get the following error:
```""distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('PasteScript==dev,>=1.6.3dev-r7326')""``` 
and I can't solve this with any amount of googling :/

Secondly, we can entirely scrap the CUDA and cuDNN steps by installing tensorflow from conda (```conda install tensorflow-gpu```), this automatically handles the CUDA and cuDNN requirements inside the environment and will make install a LOT easier. This does mean that tensorflow will need to be installed prior to dlib installation so that CUDA can be picked up for dlib.

With this in mind I propose the following:
- updating INSTALL.md for Windows to remove cmake, cuda and cudnn steps. Change VS2015 step to VS Build Tools 2017
- Work on checks for correct version of build tools/vs >= 2015 <= 2017
- Install Tensorflow from Conda for Conda environments
- Get the Conda Cuda Library Path to correctly pass to dlib
- clone dlib from 'https://github.com/davisking/dlib' at depth=1 or download the zip and unzip it.
- run `python setup.py install` from the cloned dlib repo with detected optional arguments `--yes ""USE_AVX_INSTRUCTIONS""`, `--yes ""DLIB_USE_CUDA""`. Detected argument `-G ""Visual Studio 14/15 2015/2017""` `--set ""CUDA_TOOLKIT_ROOT_DIR=<path to Conda CUDA>""` `--clean`
- delete cloned repo
- It may also be worth switching to Conda rather than PIP for conda environments to keep things consistent

I'm happy to do this, but thought you may want to, or maybe make a start? Let me know how you want to proceed. You'll need to fix any conflicts you currently have (setup.py hasn't been touched, so should be fairly straightforward). Once done raise a PR, I'll merge into a new branch and make any further amends.

If you don't want to touch this, that's fine, I'll do it, but I didn't want to deny you the contribution if you still want it.",finally chance look build visual studio build without install run try install get following error could find suitable distribution ca solve amount secondly entirely scrap install automatically inside environment make install lot easier mean need prior installation picked mind propose following remove change step build work correct version build install get library path correctly pas clone zip run python install optional yes yes argument visual studio set path clean delete may also worth switching rather pip keep consistent happy thought may want maybe make start let know want proceed need fix currently touched fairly straightforward done raise merge new branch make amends want touch fine want deny contribution still want,issue,positive,positive,positive,positive,positive,positive
461979973,"Thanks for the explanations on the these changes, makes a lot of sense now.

I am interested in the loading of weights into a different model arch. There already is a `convert_legacy_weights` function in place which uses `load_weights`. From what I read in the docs one could pass `by_name`: 

> By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use by_name=True to load only those layers with the same name.

but that will not work because the layer names are not only different, layers with the same name are used in different places. ie a `conv2d_10` in the new model is in a different location than the `conv2d_10` of the old model. Do you have any suggestion on how to approach this?

Would I need to make a mapping between old names and new names of corresponding layers and the `layer.set_weights` each layer individually?

Thanks!",thanks lot sense interested loading different model arch already function place read one could pas default architecture unchanged load different architecture common use load name work layer different name used different ie new model different location old model suggestion approach would need make old new corresponding layer individually thanks,issue,positive,positive,neutral,neutral,positive,positive
461848516,"some notes on the items you highlighted. 

there was a focus on improving performance & better stability for models, especially when some training instability errors crept up. I generally applied some typical practices in resnet models to our code. realize this may make some back compatability issues with legacy models. you could use a weight loader to load your old weights in the updated model arch. as the layers are still all the same. we don't do this is our code, but I've done it myself for other models

---There now is a res_block_follows param to upscale, when it is true the LeakyReLU gets moved into in the res_block. However upscale does add a PixelShuffler. This thus result in a reversed order of these layers compared to the original model. ie orginal upscale conv2d -> leaky_re_lu -> pixel_shuffler, model in this branch conv2d -> pixel_shuffler -> leaky_re_lu (c9d6698)
 - multiplying by a constant ( as in RELU ) and then reshaping vs. reshaping with the same method and then multiplying by the same constant won't change any values. the order of operations won't affect the result as Pixel shuffler is just a fancy reshape function and involves no math. advantage is better flow through the res_block with a pre-activation style residual.

---With change to LeakyReLU from upscale to res_block, the alpha changed from 0.1 to 0.2. (c9d6698)
- ideally the alpha of the leaky Relu should be the same throughout the whole model and be fine-tuned...i.e. is .105 better than .10. that being said, the current code base uses .1 and .2 in the res block. I left the res block alpha as it was, but we can at least keep the first pre-activation relu as the same .1, and consider moving the rest to .1 as well
---Added a Scale layer (62f2b6f)
- this was related to stability issues in some models where they would have exploding gradients. adding a learnable scale layer with the multiplier initially set at zero or a small value helps with stability and speed of training the preceding residual block. old model's weights in the residual block would have internally learned this scaling factor

---Removal of Bias=False in res_block's conv2d layers
- traditionally, residual blocks will always use Batch Normalization after the convolution. BN has a bias adder internally so the bias in the preceding convolution is usually removed as superfluous to speed up calculation. we don't use BN as it worsens / stops the identity swapping, so adding the bias back in to the conv adds more expressive power as seen in every other convolution in the model",focus improving performance better stability especially training instability crept generally applied typical code realize may make back legacy could use weight loader load old model arch still code done param upscale true however upscale add thus result reversed order original model ie upscale model branch multiplying constant method multiplying constant wo change order wo affect result shuffler fancy reshape function math advantage better flow style residual change upscale alpha ideally alpha leaky throughout whole model better said current code base block left block alpha least keep first consider moving rest well scale layer related stability would learnable scale layer multiplier initially set zero small value stability speed training preceding residual block old model residual block would internally learned scaling factor traditionally residual always use batch normalization convolution bias adder internally bias preceding convolution usually removed superfluous speed calculation use identity swapping bias back expressive power seen every convolution model,issue,positive,positive,neutral,neutral,positive,positive
461677442,"Thanks for the answers, that clears up some things I was wondering.

Where I said ""legacy dfaker"" I was referring to the models defined in the original [df](github.com/dfaker/df/blob/master/model.py) repo. I have quite some weights files that match this model, which I would love to re-use with this project. They have many hours of training in them and in my experience it works quite well to re-use existing weights from decoders as a crude form of transfer learning.

Regarding the required resources for the dfaker feeder, if it is similar to the original dfaker code with its warping and matching of similar landmarks I can imagine it would be slower than others. I understand this gets a lower priority compared to getting this merged into master. In the mean time I will dig into this part of the code base and see if is either some low hanging fruit or if I can start getting the feeding multiprocess, at the very least get an idea on what needs to be done there.

Thanks!",thanks wondering said legacy defined original quite match model would love project many training experience work quite well crude form transfer learning regarding feeder similar original code warping matching similar imagine would understand lower priority getting master mean time dig part code base see either low hanging fruit start getting feeding least get idea need done thanks,issue,positive,positive,neutral,neutral,positive,positive
461673963,"Thanks for the feedback! To answer some of your points.

In an ideal world dfaker would be model compatible with the original @dfaker model. My main goal was to keep it as 'vanilla' as possible, whilst extending functionality where possible. The main purpose of this refactor is to standardize as much as possible, and make any resource used in one model available for all existing models and any new models. Unfortunately some of those ideals don't necessarily play nicely with each other, so I will always choose to move towards standardized beyond maintaining custom compatibility. That said @kvrooman would be better placed to comment on the reasoning behind the changes to the nn_blocks. 

When you say legacy dfaker? Do you mean earlier versions in this branch? If so, unfortunately we won't maintain backwards compatibility. Anything and everything in this branch is subject to change until it gets merged to staging (hopefully very soon).

Whilst ""While True"" loops aren't particularly great practice, they also don't generally eat too many CPU cycles, so it shouldn't be too much of an issue here. There is definitely an issue with the feeders, and the plan is to move A and B into their own processes, as everything is competing for single threaded CPU time at the moment. I have also noticed that dfaker feeds particularly slowly, and I will investigate why. I've decided to put it on the backburner for now as, whilst it isn't great, it isn't model breaking, and moving to multiprocesses is likely to involve a fairly hefty rewrite to keep everything thread-safe. It is high on the list once we've got this migrated into master though.

I will look into the possibility of adding a converter for dfaker's alignments files.

",thanks feedback answer ideal world would model compatible original model main goal keep possible whilst extending functionality possible main purpose standardize much possible make resource used one model available new unfortunately necessarily play nicely always choose move towards standardized beyond custom compatibility said would better comment reasoning behind say legacy mean branch unfortunately wo maintain backwards compatibility anything everything branch subject change staging hopefully soon whilst true particularly great practice also generally eat many much issue definitely issue plan move everything single threaded time moment also particularly slowly investigate decided put whilst great model breaking moving likely involve fairly hefty rewrite keep everything high list got master though look possibility converter,issue,positive,positive,positive,positive,positive,positive
461664136,"Hi I took this branch for a spin. I have been using (a fork of) dfaker's repo for a while and I wanted to check this project out. My fork didn't touch the model architecture at all so I figured I could use my weights files on the dfaker model of your branch.

Let me first say that I love the refactor done in this branch! When I last checked out master a few months ago I quickly gave up. Thanks for all that work.

That said, I did ran into some issues:
1. `dfaker` model is no longer compatible with ""legacy dfaker"" model. @kvrooman made some changes to the nn_blocks which caused this (listed below). Do we want to keep compatibility with legacy models (I would like that)? I assume the changes to the model are made with good reason, so should we then have a model 'dfaker original' and another 'dfaker kvrooman' for example?
2. At first I did not enable previews and to whole thing ran very slowly. Later when I realized that it would run at a normal speed when previews were enabled I may have found the cause for the slowness: `monitor_console` has a tight while loop without any sleep at all. This may eat up resources unnecessarily. I haven't confirmed though, if I do I'll follow up on that.  (could be related to `[Postponed - minor issue] Training takes a long time to start?`)
3. This is not a big issue, but I was wondering if it would be at all possible to write a converter for dfaker's `alignment.json` format to the format used by this project? I took a quick look and I saw there is one converter for `deepfacelabs` format.
4. While I haven't done proper investigation, it looks like the image processing in the training data acquiring process/thread is not fast enough to keep a single 1080ti busy. Whatever the cause, the GPU is not fully utilized (it get to about 30 to 40%). Original dfakers project wasn't able to exhaust the GPU resources either, but there it was able to keep it at about 80% (on this same hardware configuration) CPU is a i7 3770, disk is fast and does not appear to be a bottleneck. CPU is not 100% utilized, is there a way to spawn more python processes to parallelise the training data processing? 

Regarding the model changes (from point 1), listing changes I changed back to make the model compatible again:

   * There now is a `res_block_follows` param to `upscale`, when it is true the `LeakyReLU` gets added in the `res_block`. However upscale does add a `PixelShuffler`. This thus result in a reversed order of these layers compared to the original model. ie orginal upscale `conv2d -> leaky_re_lu -> pixel_shuffler`, model in this branch `conv2d -> pixel_shuffler -> leaky_re_lu ` (c9d669835ba6cc6941a3f50548c066026d3b10ab)
   * With change to `LeakyReLU` from `upscale` to `res_block`, the alpha changed from 0.1 to 0.2. (c9d669835ba6cc6941a3f50548c066026d3b10ab)
   * Added a `Scale` layer (62f2b6f5fac1861e70d86e1e30abf60e9b1bfba1)
   * Removal of Bias in res_block's conv2d layers (268ccf298aec9cc03f3e6325f23127243ce3f0c9)


 
I've only started looking into this codebase today, so I apologize if I missed anything and I don't want to step on anyone's toes here, just wanting to share some thoughts while I have them.

Please let me know your thoughts, thanks!
 ",hi took branch spin fork check project fork touch model architecture figured could use model branch let first say love done branch last checked master ago quickly gave thanks work said ran model longer compatible legacy model made listed want keep compatibility legacy would like assume model made good reason model original another example first enable whole thing ran slowly later would run normal speed may found cause tight loop without sleep may eat unnecessarily confirmed though follow could related minor issue training long time start big issue wondering would possible write converter format format used project took quick look saw one converter format done proper investigation like image training data fast enough keep single ti busy whatever cause fully get original project able exhaust either able keep hardware configuration disk fast appear bottleneck way spawn python training data regarding model point listing back make model compatible param upscale true added however upscale add thus result reversed order original model ie upscale model branch change upscale alpha added scale layer removal bias looking today apologize anything want step anyone wanting share please let know thanks,issue,positive,positive,positive,positive,positive,positive
461253552,"There is no --ag cli option for training as far as I can tell, you should add that in the next version. ",option training far tell add next version,issue,negative,positive,neutral,neutral,positive,positive
461043208,"Note quality 1 takes much longer than other more moderate quality levels
for less and less incremental quality gain.  Fine if this is for offline
work, but we may want a preset for ""real-time"" in the future

On Tue, Feb 5, 2019 at 8:26 PM torzdf <notifications@github.com> wrote:

> Merged #600 <https://github.com/deepfakes/faceswap/pull/600> into staging.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/600#event-2120170257>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ADmQEvlFVobsdDT-xgaJkNTYiymJ7YQQks5vKj1GgaJpZM4agRKq>
> .
>
",note quality much longer moderate quality le le incremental quality gain fine work may want preset future tue wrote staging thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
460870163,"Unfortunately this fix disables the use of multi-gpus.

--allow-growth should perform the same function anyway? If not, let me know and I'll make sure it's fixed in a forthcoming update.",unfortunately fix use perform function anyway let know make sure fixed forthcoming update,issue,negative,positive,neutral,neutral,positive,positive
460248375,"The guide is pretty much there in setup.py
The needed command line to run the docker container is listed there and the remaining things are all docker stuff. nothing special.

The tf version tho, i need to check the current status of it in pypi and decide whether to update the script.",guide pretty much command line run docker container listed docker stuff nothing special version tho need check current status decide whether update script,issue,negative,positive,positive,positive,positive,positive
460216816,"This is still on the agenda.

@DKingCN I don't suppose you'd want to write a docker install/useage guide for the wiki? @kvrooman has started adding wiki pages, and a docker guide is likely to be useful.

Thanks",still agenda suppose want write docker guide docker guide likely useful thanks,issue,positive,positive,positive,positive,positive,positive
460071220,"I'd certainly be interested in taking a look. Could you raise a PR against the train_refactor branch? If we decide to merge, it will need to be against that branch as this is what will soon be going to master.

Thanks.",certainly interested taking look could raise branch decide merge need branch soon going master thanks,issue,positive,positive,positive,positive,positive,positive
458482935,"We don't all use Windows. Linux is actually my primary OS. Windows gets more attention, as most of our users are Windows users and have more issues with installing. I take a general view that linux users know what they're doing ;)

This has been left open as I plan to address it in future, but it is not top of the priority list.",use actually primary o attention take general view know left open plan address future top priority list,issue,negative,positive,positive,positive,positive,positive
458394683,"Dose it support anaconda installing? we follow the install guide but get the unsuspected error.
To fix this error, I change the line 372 in the setup.py script in function check_cudnn() from 
cudnn_checkfile = os.path.join(CUDA_PATH, ""include"", ""cudnn.h"") to 
cudnn_checkfile = os.path.join(""/usr/local/cuda"", ""include"", ""cudnn.h""), 
and it can successfully setup the project.
Hope that can be useful.",dose support anaconda follow install guide get unsuspected error fix error change line script function include include successfully setup project hope useful,issue,positive,positive,positive,positive,positive,positive
458390157,"For linux, we recommend following the install guide at https://github.com/deepfakes/faceswap/blob/master/INSTALL.md .  You can skip the Microsoft Visual C and use GCC instead.  It's actually much easier to install on Linux than Windows so there is no need for the script.",recommend following install guide skip visual use instead actually much easier install need script,issue,positive,positive,neutral,neutral,positive,positive
458380126,"Thanks for your reply.
When I print the CUDA_PATH, it shows bcudart.so.9, not a path at all. 
Maybe the script need to be rewrite, sounds terrible. ",thanks reply print path maybe script need rewrite terrible,issue,negative,negative,negative,negative,negative,negative
458378168,"> Hi @rail5
> I encounter with the same problems, have you solved it ?
> Thanks.

Unfortunately I haven't. I tried to edit setup.py to force it to look in a place that made sense, but that ended up with a bunch of other errors, and there's too much code for me to really dig through and find out where all the errors are. I imagine the devs just all use Windows, so they're not too concerned",hi rail encounter thanks unfortunately tried edit force look place made sense ended bunch much code really dig find imagine use concerned,issue,negative,positive,neutral,neutral,positive,positive
458376755,"Hi @rail5
I encounter with the same problems, have you solved it ?
Thanks.",hi rail encounter thanks,issue,negative,positive,positive,positive,positive,positive
457906468,"Run a virtual environment for python 3.6. Anaconda can do this. I don't know if homebrew can.

This is a Tensorflow limitation, not Faceswap.",run virtual environment python anaconda know limitation,issue,negative,neutral,neutral,neutral,neutral,neutral
457785675,Not really happy updating requirements/setup until it enters full release,really happy full release,issue,positive,positive,positive,positive,positive,positive
457707349,easy. maybe I need to remove the temp solution for cuda 10.0 once TF is officially released with cuda 10.0 support. TF 1.12 release note is not mentioning this so i guess we need to wait some more time.,easy maybe need remove temp solution officially support release note guess need wait time,issue,positive,positive,positive,positive,positive,positive
457022857,"I'd happily remove fixed versions, only implementing them if new versions bug our code.

@DKingCN Sorry that it's taking so long to get around this. The refactor has taken longer than expected. It will be looked at!
",happily remove fixed new bug code sorry taking long get around taken longer,issue,positive,positive,neutral,neutral,positive,positive
457021346,"thanks for this work as well. We'll try to get here to test in the near future as the refactor is integrated and bug fixes are fixed.

-Two notes:
TF 1.13 is supposed to come in Jan 2019, so should we wait for that stable build to be released?

The following are listed as exact versions. Do we need these exact versioning? Can we support >= to give users more flexibility...
cmake>=3.13
dlib==19.16.0
pathlib==1.0.1
ffmpy==0.2.2
scandir==1.7
h5py==2.9.0
matplotlib==3.0.2",thanks work well try get test near future bug fixed supposed come wait stable build following listed exact need exact support give flexibility,issue,positive,positive,positive,positive,positive,positive
457009051,GAN is being removed with a view to add GAN2.2 in the future. Use masked converter.,gan removed view add gan future use masked converter,issue,negative,neutral,neutral,neutral,neutral,neutral
457007098,There are no errors during performing convert with Adjust plugin in case of Original/OriginalHighRes/IAE model,convert adjust case model,issue,negative,neutral,neutral,neutral,neutral,neutral
456928530,"Crash report:
```01/22/2019 20:05:34 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:34 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:35 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:35 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:36 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:36 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:37 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:37 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:38 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:39 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:39 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:40 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:40 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:41 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:41 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:42 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:42 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:42 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:43 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:44 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:45 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:45 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:46 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:46 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:47 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 2731x4096 to 1175x1763.
01/22/2019 20:05:47 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:48 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:50 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:50 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:50 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:50 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:51 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:59 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:05:59 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:03 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:04 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:04 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:05 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:05 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:06 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:06 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:07 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:07 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:10 Detector.run detect_thread_3 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:11 Detector.run detect_thread_4 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:11 Detector.run detect_thread_2 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:12 Detector.run detect_thread_6 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:12 Detector.run detect_thread_1 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:14 Detector.run detect_thread_0 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
01/22/2019 20:06:14 Detector.run detect_thread_5 _base set_detect_image VERBOSE Resizing image from 4096x2731 to 1763x1175.
Traceback (most recent call last):
File ""C:\Users\nope\df\faceswap\lib\cli.py"", line 90, in execute_script
process.process()
File ""C:\Users\nope\df\faceswap\scripts\extract.py"", line 49, in process
self.run_extraction()
File ""C:\Users\nope\df\faceswap\scripts\extract.py"", line 146, in run_extraction
self.run_detection(to_process)
File ""C:\Users\nope\df\faceswap\scripts\extract.py"", line 202, in run_detection
desc=""Detecting faces""):
File ""C:\Users\nope\Anaconda3\envs\face\lib\site-packages\tqdm_tqdm.py"", line 979, in iter
for obj in iterable:
File ""C:\Users\nope\df\faceswap\scripts\extract.py"", line 405, in detect_faces
faces = out_queue.get(True, 1)
File """", line 2, in get
File ""C:\Users\nope\Anaconda3\envs\face\lib\multiprocessing\managers.py"", line 732, in _callmethod
raise convert_to_error(kind, result)
multiprocessing.managers.RemoteError:

Unserializable message: Traceback (most recent call last):
File ""C:\Users\nope\Anaconda3\envs\face\lib\multiprocessing\managers.py"", line 276, in serve_client
send(msg)
File ""C:\Users\nope\Anaconda3\envs\face\lib\multiprocessing\connection.py"", line 206, in send
self._send_bytes(ForkingPickler.dumps(obj))
File ""C:\Users\nope\Anaconda3\envs\face\lib\multiprocessing\reduction.py"", line 50, in dumps
cls(buf, protocol).dump(obj)
MemoryError

============ System Information ============
git_branch: master
git_commits: 4376bbf Alignments tool: Filename clash bugfix. 20cb538 Merge branch 'master' into staging. af3acaa Alignments tool: Allow empty folder/non existant folder for extract. 8f5bbef Merge branch 'master' into staging. f761a31 Extract - bugfix: Skip non-loaded image
gpu_cuda: 9.0
gpu_cudnn: 7.2.1
gpu_devices: GPU_0: GeForce GTX 1080 Ti
gpu_driver: 417.35
gpu_vram: GPU_0: 11264MB
os_machine: AMD64
os_platform: Windows-10-10.0.17763-SP0
os_release: 10
py_command: C:\Users\nope\df\faceswap\faceswap.py extract -i D:/deep_temp/kayden/kayden -o D:/deep_temp/kayden/face2 -l 0.7 --serializer yaml -D mtcnn -A fan -mtms 20 -mtth 0.7 0.7 0.8 -mtsc 0.709 -bt 15 -sz 256 -s -sf -si 500 -L VERBOSE -LF D:/deep_temp/kayden/log.txt
py_conda_version: conda 4.5.12
py_implementation: CPython
py_version: 3.5.6
py_virtual_env: False
sys_cores: 12
sys_processor: Intel64 Family 6 Model 85 Stepping 4, GenuineIntel
sys_ram: Total: 32643MB, Available: 1161MB, Used: 31481MB, Free: 1161MB

=============== Pip Packages ===============
absl-py==0.7.0
astor==0.7.1
certifi==2018.8.24
Click==7.0
cloudpickle==0.6.1
cmake==3.13.2.post1
cycler==0.10.0
dask==1.0.0
decorator==4.3.0
dlib==19.16.0
face-recognition==1.2.3
face-recognition-models==0.3.0
ffmpy==0.2.2
gast==0.2.2
grpcio==1.18.0
h5py==2.8.0
Keras==2.2.4
Keras-Applications==1.0.6
keras-contrib==2.0.8
Keras-Preprocessing==1.0.5
kiwisolver==1.0.1
Markdown==3.0.1
matplotlib==2.2.2
mkl-fft==1.0.6
mkl-random==1.0.1
networkx==2.2
numpy==1.16.0
nvidia-ml-py3==7.352.0
opencv-python==3.4.4.19
pathlib==1.0.1
Pillow==5.3.0
protobuf==3.6.1
psutil==5.4.8
pyparsing==2.3.0
python-dateutil==2.7.5
pytz==2018.7
PyWavelets==1.0.1
PyYAML==3.13
scandir==1.7
scikit-image==0.14.1
scikit-learn==0.20.2
scipy==1.2.0
six==1.12.0
tensorboard==1.9.0
tensorflow-gpu==1.9.0
termcolor==1.1.0
toolz==0.9.0
tqdm==4.28.1
Werkzeug==0.14.1
wincertstore==0.2

============== Conda Packages ==============
packages in environment at C:\Users\nope\Anaconda3\envs\face:
Name Version Build Channel

absl-py 0.6.1
astor 0.7.1
blas 1.0 mkl
certifi 2018.8.24 py35_1001 conda-forge
Click 7.0
cloudpickle 0.6.1
cmake 3.13.2.post1
cudatoolkit 9.0 1 anaconda
cycler 0.10.0
dask 1.0.0
decorator 4.3.0
dlib 19.16.0
face-recognition 1.2.3
face-recognition-models 0.3.0
ffmpeg 4.1 h8fefcd1_0 conda-forge
ffmpy 0.2.2
gast 0.2.0
grpcio 1.17.1
h5py 2.8.0
hdf5 1.8.20 hac2f561_1
icc_rt 2019.0.0 h0cc432a_1
intel-openmp 2019.1 144
jpeg 9b hb83a4c4_2
Keras 2.2.4
Keras-Applications 1.0.6
keras-contrib 2.0.8
Keras-Preprocessing 1.0.5
kiwisolver 1.0.1
libopencv 3.4.2 h20b85fd_0
libpng 1.6.36 h2a8f88b_0
libtiff 4.0.9 h36446d0_2
Markdown 3.0.1
matplotlib 2.2.2
mkl 2018.0.3 1
mkl_fft 1.0.6 py35hdbbee80_0
mkl_random 1.0.1 py35h77b88f5_1
networkx 2.2
numpy 1.15.4
numpy 1.15.2 py35ha559c80_0
numpy-base 1.15.2 py35h8128ebf_0
nvidia-ml-py3 7.352.0
opencv 3.4.2 py35h40b0b35_0
opencv-python 3.4.4.19
pathlib 1.0.1
Pillow 5.3.0
pip 18.1
pip 18.0 py35_1001 conda-forge
protobuf 3.6.1
psutil 5.4.8
py-opencv 3.4.2 py35hc319ecb_0
pyparsing 2.3.0
python 3.5.6 he025d50_0
python-dateutil 2.7.5
pytz 2018.7
PyWavelets 1.0.1
PyYAML 3.13
scandir 1.7
scikit-image 0.14.1
scikit-learn 0.20.2
scipy 1.2.0
setuptools 40.2.0 py35_0
six 1.12.0
tensorboard 1.12.1
tensorflow-gpu 1.12.0
termcolor 1.1.0
tk 8.6.8 hfa6e2cd_0
toolz 0.9.0
tqdm 4.28.1
vc 14.1 h21ff451_3 anaconda
vs2015_runtime 15.5.2 3 anaconda
Werkzeug 0.14.1
wheel 0.31.1 py35_0
wincertstore 0.2 py35hfebbdb8_0
zlib 1.2.11 h62dcd97_3```",crash report verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image verbose image recent call last file line file line process file line file line file line iter iterable file line true file line get file line raise kind result message recent call last file line send file line send file line protocol system information master tool clash merge branch staging tool allow empty folder extract merge branch staging fa extract skip image ti extract fan verbose false family model stepping total available used free pip post environment name version build channel astor blas click post anaconda cycler decorator gast markdown pillow pip pip python six anaconda anaconda wheel,issue,positive,positive,positive,positive,positive,positive
456928201,"Crash Report:
```01/16/2019 22:49:22 MainProcess     MainThread      multithreading  start                     DEBUG    Spawning Process: (name: 'Detector.run', args: (), kwargs: {'event': <multiprocessing.synchronize.Event object at 0x00000163BB308A90>, 'log_queue': <AutoProxy[Queue] object, typeid 'Queue' at 0x163a9c7c978>, 'log_init': <function set_root_logger at 0x00000163A9B9D1E0>, 'out_queue': <AutoProxy[Queue] object, typeid 'Queue' at 0x163bb2e3860>, 'in_queue': <AutoProxy[Queue] object, typeid 'Queue' at 0x163bb2e3be0>}, daemon: True)
01/16/2019 22:49:22 MainProcess     MainThread      multithreading  start                     DEBUG    Spawned Process: (name: 'Detector.run', PID: 11260)
01/16/2019 22:49:22 MainProcess     MainThread      extract         launch_detector           DEBUG    Launched Detector
01/16/2019 22:49:22 MainProcess     MainThread      extract         detect_faces              DEBUG    Running Detection. Pass: 'align'
01/16/2019 22:49:22 Detector.run    MainThread      dlib_cnn        initialize                INFO     Initialized Dlib-CNN Detector...
01/16/2019 22:49:22 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager getting: 'align'
01/16/2019 22:49:22 MainProcess     MainThread      queue_manager   get_queue                 DEBUG    QueueManager got: 'align'
01/16/2019 22:49:25 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1.png
01/16/2019 22:49:25 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10.png
01/16/2019 22:49:38 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10148.png
01/16/2019 22:49:38 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10149.png
01/16/2019 22:49:38 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10150.png
01/16/2019 22:49:38 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10151.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10152.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10153.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10154.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10155.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10156.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10157.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10158.png
01/16/2019 22:49:39 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10159.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10160.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10161.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10162.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10163.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10164.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10165.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10166.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10167.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10168.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10169.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10170.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10171.png
01/16/2019 22:49:40 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10172.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10173.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10174.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10175.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10176.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10177.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10178.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 10179.png
01/16/2019 22:49:41 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1018.png
01/16/2019 22:49:42 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1019.png
01/16/2019 22:49:43 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1020.png
01/16/2019 22:49:43 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1021.png
01/16/2019 22:49:44 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1022.png
01/16/2019 22:49:45 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1023.png
01/16/2019 22:49:46 MainProcess     MainThread      extract         run_extraction            VERBOSE  No faces were detected in image: 1024.png
01/16/2019 22:50:07 Detector.run    MainThread      _base           run                       ERROR    Caught exception in child process: 11260
01/16/2019 22:50:07 Aligner.run     MainThread      _base           run                       ERROR    Caught exception in child process: 9320
Traceback (most recent call last):
  File ""F:\PythonProject\faceswap\lib\cli.py"", line 90, in execute_script
    process.process()
  File ""F:\PythonProject\faceswap\scripts\extract.py"", line 49, in process
    self.run_extraction()
  File ""F:\PythonProject\faceswap\scripts\extract.py"", line 149, in run_extraction
    desc=""Extracting faces""):
  File ""C:\Users\jsy20\AppData\Roaming\Python\Python35\site-packages\tqdm\_tqdm.py"", line 1002, in __iter__
    for obj in iterable:
  File ""F:\PythonProject\faceswap\scripts\extract.py"", line 409, in detect_faces
    raise Exception(err)
Exception: Error in child process 9320. Traceback (most recent call last):
  File ""F:\PythonProject\faceswap\plugins\extract\align\_base.py"", line 90, in run
    self.align(*args, **kwargs)
  File ""F:\PythonProject\faceswap\plugins\extract\align\dlib.py"", line 44, in align
    self.finalize(item)
  File ""F:\PythonProject\faceswap\plugins\extract\align\_base.py"", line 113, in finalize
    self.queues[""out""].put((output))
  File ""<string>"", line 2, in put
  File ""D:\Anaconda3\envs\faceswap\lib\multiprocessing\managers.py"", line 732, in _callmethod
    raise convert_to_error(kind, result)
multiprocessing.managers.RemoteError: 
---------------------------------------------------------------------------
Traceback (most recent call last):
  File ""D:\Anaconda3\envs\faceswap\lib\multiprocessing\managers.py"", line 228, in serve_client
    request = recv()
  File ""D:\Anaconda3\envs\faceswap\lib\multiprocessing\connection.py"", line 250, in recv
    buf = self._recv_bytes()
  File ""D:\Anaconda3\envs\faceswap\lib\multiprocessing\connection.py"", line 318, in _recv_bytes
    return self._get_more_data(ov, maxsize)
  File ""D:\Anaconda3\envs\faceswap\lib\multiprocessing\connection.py"", line 344, in _get_more_data
    f.write(ov.getbuffer())
MemoryError
---------------------------------------------------------------------------


============ System Information ============
git_branch:        Not Found
git_commits:       Not Found
gpu_cuda:          9.0
gpu_cudnn:         7.4.2
gpu_devices:       GPU_0: GeForce GTX 1080 Ti
gpu_driver:        417.71
gpu_vram:          GPU_0: 11264MB
os_machine:        AMD64
os_platform:       Windows-10-10.0.17763-SP0
os_release:        10
py_command:        F:\PythonProject\faceswap\faceswap.py extract -i F:/testvideo/data_a/frame -o F:/testvideo/data_a/frame/face -l 0.99 --serializer json -D dlib-cnn -A dlib -mtms 50 -mtth 0.6 0.7 0.7 -mtsc 0.709 -sz 256 -L INFO
py_conda_version:  conda 4.5.12
py_implementation: CPython
py_version:        3.5.6
py_virtual_env:    False
sys_cores:         8
sys_processor:     Intel64 Family 6 Model 158 Stepping 9, GenuineIntel
sys_ram:           Total: 16343MB, Available: 5105MB, Used: 11238MB, Free: 5105MB

=============== Pip Packages ===============
absl-py==0.7.0
astor==0.7.1
certifi==2018.8.24
Click==7.0
cloudpickle==0.6.1
cmake==3.13.3
cycler==0.10.0
dask==1.0.0
decorator==4.3.0
dlib==19.16.0
face-recognition==1.2.3
face-recognition-models==0.3.0
ffmpy==0.2.2
gast==0.2.2
grpcio==1.18.0
h5py==2.8.0
Keras==2.2.4
Keras-Applications==1.0.6
Keras-Preprocessing==1.0.5
kiwisolver==1.0.1
Markdown==3.0.1
matplotlib==2.2.2
networkx==2.2
numpy==1.16.0
nvidia-ml-py3==7.352.0
opencv-python==4.0.0.21
pathlib==1.0.1
Pillow==5.4.1
protobuf==3.6.1
psutil==5.4.8
pyparsing==2.3.1
python-dateutil==2.7.5
pytz==2018.9
PyWavelets==1.0.1
PyYAML==3.13
scandir==1.7
scikit-image==0.14.1
scikit-learn==0.20.2
scipy==1.2.0
six==1.12.0
tensorboard==1.12.2
tensorflow-gpu==1.12.0
termcolor==1.1.0
toolz==0.9.0
tqdm==4.29.1
Werkzeug==0.14.1
wincertstore==0.2

============== Conda Packages ==============
# packages in environment at D:\Anaconda3\envs\faceswap:
#
# Name                    Version                   Build  Channel
certifi                   2018.8.24             py35_1001    conda-forge
ffmpeg                    4.1               h86867b3_1000    conda-forge
pip                       10.0.1                   py35_0    defaults
python                    3.5.6                he025d50_0    defaults
setuptools                40.2.0                   py35_0    defaults
tk                        8.6.8                hfa6e2cd_0    defaults
vc                        14.1                 h0510ff6_4    defaults
vs2015_runtime            14.15.26706          h3a45250_0    defaults
wheel                     0.31.1                   py35_0    defaults
wincertstore              0.2              py35hfebbdb8_0    defaults```",crash report start spawning process name object queue object function queue object queue object daemon true start process name extract detector extract running detection pas initialize detector getting got extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image extract verbose image run error caught exception child process run error caught exception child process recent call last file line file line process file line file line iterable file line raise exception err exception error child process recent call last file line run file line align item file line finalize output file string line put file line raise kind result recent call last file line request file line file line return file line system information found found ti extract false family model stepping total available used free pip environment name version build channel pip python wheel,issue,negative,positive,positive,positive,positive,positive
456925756,"A macOS user will need to get back to you. I do not currently have access to a macOS machine.

It should ""just work""",user need get back currently access machine work,issue,negative,neutral,neutral,neutral,neutral,neutral
455704858,Question on the OriginalHiRes - do we want to standardize to He initializers there as well...,question want standardize well,issue,negative,neutral,neutral,neutral,neutral,neutral
455517335,"The code for the nn_block should probably come out, as the initializer can be passed in as an argument from the model, so it should be selected from the model and passed through to the nn_block.

Once this change is made, I'll merge.",code probably come argument model selected model change made merge,issue,negative,neutral,neutral,neutral,neutral,neutral
455516797,"I have standardised the nn_blocks, so please could you fix for the conflicts.
`kernel_initializer` can also be passed through as a parameter from the models (e.g. OriginalHiRes), so please could you make it overridable?

Once this is done I'll merge this
",please could fix also parameter please could make done merge,issue,positive,neutral,neutral,neutral,neutral,neutral
454983059,"GAN is being dropped from the repo. It may be re-added in future. Either way, it will be a new implementation,",gan may future either way new implementation,issue,negative,positive,neutral,neutral,positive,positive
454950308,"Sorry, I just tested it again and it worked perfectly for all 3 processes. I forgot to change batch file to direct to the staging commit. Thank you for the update.",sorry tested worked perfectly forgot change batch file direct staging commit thank update,issue,positive,positive,positive,positive,positive,positive
454931935,"@Teckt I just tested this on extract and it worked fine for me. Are you sure?
",tested extract worked fine sure,issue,negative,positive,positive,positive,positive,positive
454930126,"Hmmm, I thought I'd put it in as a global option. Will double check",thought put global option double check,issue,negative,neutral,neutral,neutral,neutral,neutral
454905380,Thanks for the quick fix! It only works for training. Are you planning to make the changes to extract and convert as well?,thanks quick fix work training make extract convert well,issue,positive,positive,positive,positive,positive,positive
454844774,see #576 for work in progress of segmentation masks / occlusion masks,see work progress segmentation occlusion,issue,negative,neutral,neutral,neutral,neutral,neutral
454607117,"@kvrooman , i found you have merge the face segmentation into the train_refactor branch.
may i know how we can activate the face segmentation during the training in train_refactor branch ?? will it automatic start when we do the training??  ",found merge face segmentation branch may know activate face segmentation training branch automatic start training,issue,negative,neutral,neutral,neutral,neutral,neutral
454602417,"Ok logfile has been added to latest Staging Branch. Can you test it works ok for you and report back, and I'll merge it to master.

```-LF --logfile```",added latest staging branch test work report back merge master,issue,negative,positive,positive,positive,positive,positive
454558854,"It would be great if a log file could be specified in the arguments. Here's the error output:

Traceback (most recent call last):
  File ""faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""C:\fs-new\lib\cli.py"", line 85, in execute_script
    log_setup(arguments.loglevel, self.command)
  File ""C:\fs-new\lib\logger.py"", line 79, in log_setup
    f_handler = file_handler(numeric_loglevel, log_format, command)
  File ""C:\fs-new\lib\logger.py"", line 97, in file_handler
    log_file.doRollover()
  File ""C:\Users\Cool\AppData\Local\Programs\Python\Python36\lib\logging\handlers.py"", line 173, in doRollover
    self.rotate(self.baseFilename, dfn)
  File ""C:\Users\Cool\AppData\Local\Programs\Python\Python36\lib\logging\handlers.py"", line 113, in rotate
    os.rename(source, dest)
PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\fs-new\\faceswap.log' -> 'C:\\fs-new\\faceswap.log.1
`",would great log file could error output recent call last file line module file line file line command file line file line file line rotate source process access file used another process,issue,negative,positive,positive,positive,positive,positive
454550224,"Unfortunately logging is not going anywhere, as it's integral to solving issues and development.
I can look at the possibility of specifying a logfile. What is the specific error that you receive?",unfortunately logging going anywhere integral development look possibility specific error receive,issue,negative,negative,negative,negative,negative,negative
454392464,"I will redo my tests and look into the issue, sorry for your inconvenience.",redo look issue sorry inconvenience,issue,negative,negative,negative,negative,negative,negative
453873020,"In the meantime, I will merge this into staging, as it does address an existing bug.",merge staging address bug,issue,negative,neutral,neutral,neutral,neutral,neutral
453856642,"It does work now and I believe your addressing of the out_of_bounds issues are a good item ( although I haven't tested extensively )

Unfortunately, we're in the midst of a code refactor with the training code being updated. As part of that, I had consolidated the Convert_Masked and Convert_Adjust converters into one converter ( PR #574 ) over the last week or so. So the Convert_Masked will hopefully shortly be overwritten in order to provide more features and have proper face alignment.

If you'd like to review #574 and think something should be modified there to address these similar issues, lemme know

",work believe good item although tested extensively unfortunately midst code training code part consolidated one converter last week hopefully shortly order provide proper face alignment like review think something address similar know,issue,positive,positive,neutral,neutral,positive,positive
453802132,"@kvrooman: Thanks for your kind reply. It seems maskx, masky are just local variables, I changed their names so that maskx, masky corresponds to X,Y. Is this feasible? Thanks~",thanks kind reply local feasible,issue,positive,positive,positive,positive,positive,positive
453788183,"The crop adjusting for the out of bounds error is a good addition. I did something similar by just padding the source image which we are pasting into to ensure there are no cases for out of bounds.

Regarding the y,x versus the x,y order of the center parameter in the function call... this is a case of poor code labeling.  Note in the original code
```
lenx = maxx - minx
leny = maxy - miny
masky = int(minx + (lenx // 2))
maskx = int(miny + (leny // 2))
outimage = cv2.seamlessClone(new_image.astype(numpy.uint8),             base_image.astype(numpy.uint8), unitMask, (masky, maskx), cv2.NORMAL_CLONE)
```

The masky variable actually refers to the x coordinates
```
masky = int(minx + (lenx // 2))
```
so when the center is defined as
```(masky,maskx)```
it really means (x,y)",crop error good addition something similar padding source image pasting ensure regarding versus order center parameter function call case poor code note original code minx miny minx miny outimage variable actually minx center defined really,issue,negative,positive,neutral,neutral,positive,positive
453773575,@kvrooman Does this look ok to you? We can merge it into staging/master with the understanding that any of these changes will be overwritten by your convert refactor,look merge understanding convert,issue,negative,neutral,neutral,neutral,neutral,neutral
453767148,"Sorry it appears git logs are truncated 

I am getting the following error when using seamlessclone (-S) option When I convert images using trained model: 

OpenCV Error: Assertion failed (0 <= roi.x && 0 <= roi.width && roi.x + 
roi.width <= m.cols && 0 <= roi.y && 0 <= roi.height && roi.y + roi.height 
<= m.rows) in cv::Mat::Mat

The exception is thrown by the apply_new_face function in Convert_Masked.py if new_image cannot ""fit"" into base_image at the coordinates of (maskx, masky). The PR determine if new_image will exceed the boundary of base_image and crops new_image if necessary.

Also, the point in openCV should follow the format of (X, Y) instead of (Y,X) so I modified the call of cv2.seamlessClone.

Thanks",sorry git truncated getting following error option convert trained model error assertion exception thrown function fit determine exceed boundary necessary also point follow format instead call thanks,issue,negative,positive,neutral,neutral,positive,positive
453436973,This issue is closed. The original user had not setup faceswap properly.,issue closed original user setup properly,issue,negative,positive,neutral,neutral,positive,positive
453418425,"> This looks like a problem with your setup. As long as you are in a Python3 environment `pynvml` will import from `nvidia-ml-py3`
> 
> ```
> $ python
> Python 3.5.6 (default, Aug  4 2018, 00:54:51)
> [GCC 7.3.0] on linux
> Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
> 
> >>> import pynvml
> 
> >>> raise pynvml.NVMLError_LibraryNotFound
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
> pynvml.NVMLError_LibraryNotFound: NVML Shared Library Not Found
> 
> >>> raise pynvml.NVMLError_DriverNotLoaded
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
> pynvml.NVMLError_DriverNotLoaded: Driver Not Loaded
> ```

Yes. Thank you so much for your help. py3nvml is wrong.
The former code `import pynvml` is right and it can be installed 
`pip install nvidia-ml-py3`",like problem setup long python environment import python python default type help copyright license information import raise recent call last file line module library found raise recent call last file line module driver loaded yes thank much help wrong former code import right pip install,issue,positive,negative,neutral,neutral,negative,negative
453414757,"see：https://github.com/deepfakes/faceswap-playground/issues/232#issuecomment-452345536 。
Maybe it's the same problem,   maybe it's the same problem, but for different reasons.",maybe problem maybe problem different,issue,negative,neutral,neutral,neutral,neutral,neutral
453410729,"![image](https://user-images.githubusercontent.com/36145675/51019669-be277980-15b6-11e9-8920-4428629e3eae.png)

still couldn't work.",image still could work,issue,negative,neutral,neutral,neutral,neutral,neutral
453403017,"![image](https://user-images.githubusercontent.com/36145675/51018505-cf6e8700-15b2-11e9-9d77-c5b2a9c9812d.png)

![image](https://user-images.githubusercontent.com/36145675/51018530-e90fce80-15b2-11e9-8b71-29f1a50bd00b.png)
the log is:
![image](https://user-images.githubusercontent.com/36145675/51018574-0cd31480-15b3-11e9-9365-7297e07d1381.png)


Would you please tell me how to fix it?",image image log image would please tell fix,issue,negative,neutral,neutral,neutral,neutral,neutral
453401054,I have the same error. May I ask how to fix it?,error may ask fix,issue,negative,neutral,neutral,neutral,neutral,neutral
452837224,"@IEWbgfnYDwHRoRRSKtkdyMDUzgdwuBYgDKtDJWd , is this issue already fixed on your side? if yes, could you please share your solution?  I am having the same issue. Everything seems fine but nothing is being updated. However the GPU shows it is in use.",issue already fixed side yes could please share solution issue everything fine nothing however use,issue,positive,positive,positive,positive,positive,positive
452679089,"This looks like a problem with your setup. As long as you are in a Python3 environment `pynvml` will import from `nvidia-ml-py3`


```
$ python
Python 3.5.6 (default, Aug  4 2018, 00:54:51)
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

>>> import pynvml

>>> raise pynvml.NVMLError_LibraryNotFound
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
pynvml.NVMLError_LibraryNotFound: NVML Shared Library Not Found

>>> raise pynvml.NVMLError_DriverNotLoaded
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
pynvml.NVMLError_DriverNotLoaded: Driver Not Loaded
```",like problem setup long python environment import python python default type help copyright license information import raise recent call last file line module library found raise recent call last file line module driver loaded,issue,negative,negative,neutral,neutral,negative,negative
452584990,"It seems you should use py3nvml instead, but the new error is 
`except (py3nvml.NVMLError_LibraryNotFound, py3nvml.NVMLError_DriverNotLoaded):
AttributeError: module 'py3nvml' has no attribute 'NVMLError_LibraryNotFound'
`
I'm trying to figure out.",use instead new error except module attribute trying figure,issue,negative,positive,positive,positive,positive,positive
452307619,"Please post this either in https://github.com/deepfakes/faceswap-playground/issues
or even better, on the Discord:
https://discord.gg/FdEwxXd",please post either even better discord,issue,negative,positive,positive,positive,positive,positive
452204822,Please don't open multiple issues for the same problem.  See my response in your duplicate issue https://github.com/deepfakes/faceswap/issues/580 for information on how to do every step.,please open multiple problem see response duplicate issue information every step,issue,negative,neutral,neutral,neutral,neutral,neutral
452202124,You need alignments to continue.  See https://github.com/deepfakes/faceswap/blob/master/USAGE.md for the process.  You can also come to our Discord server at https://discord.gg/FC54sYg if you have other questions about how to use the software.,need continue see process also come discord server use,issue,negative,neutral,neutral,neutral,neutral,neutral
452168522,"> run the extract process to generate an alignments file
i have run the following command, however don't generate the alignments.json
python faceswap.py extract -i /nfs/private/faceswap-GAN/faceB -o /nfs/private/faceswap/data/trump
python faceswap.py extract -i /nfs/private/faceswap-GAN/faceA -o /nfs/private/faceswap/data/cage",run extract process generate file run following command however generate python extract python extract,issue,negative,neutral,neutral,neutral,neutral,neutral
452168228,run the extract process to generate an alignments file,run extract process generate file,issue,negative,neutral,neutral,neutral,neutral,neutral
451891223,You need to create images (use Extract). You don't need the pre-trained model.,need create use extract need model,issue,negative,neutral,neutral,neutral,neutral,neutral
451889941,"I haven't, don't worry. I need to do quite a lot of testing with Dlib, and I'm a little busy with work and train-refactor at the moment.

It is on the list, sorry for the delay!",worry need quite lot testing little busy work moment list sorry delay,issue,negative,negative,negative,negative,negative,negative
451830764,the link of dataset and trained model lose efficiency.can I train this model without images  as train_set.,link trained model lose train model without,issue,negative,neutral,neutral,neutral,neutral,neutral
451666588,"@TXien In case if still an issue for you( or hope it helps someone else), you should look for the file inside the input dir because in my case it is in the input directory where alignments file is created and if you look at extract command output the path is written there",case still issue hope someone else look file inside input case input directory file look extract command output path written,issue,negative,neutral,neutral,neutral,neutral,neutral
451234896,@Enyakk I just randomly hit the same bug. Should be fixed now.,randomly hit bug fixed,issue,negative,negative,negative,negative,negative,negative
451210658,"Looking at the i/o pre-processing into the gan model... 
you should build the normalization input step into either the configs or alternatively into the gan v2.2 model file itself.
i.e. after `inp = Input(shape=(input_size, input_size, self.num_chans_g_inp))` insert
              `varx = Lambda(lambda x: x * 2.0 - 1.0)(inp)`",looking gan model build normalization input step either alternatively gan model file input insert lambda lambda,issue,negative,neutral,neutral,neutral,neutral,neutral
451191091,"Thanks for this. Going to change base to train_refactor so you can remove GAN. 

If you'd rather it went straight to Staging > Master, then feel free to change it back,",thanks going change base remove gan rather went straight staging master feel free change back,issue,positive,negative,neutral,neutral,negative,negative
451089001,"@HighCommander4 Nvidia GPU support is pretty good these days (for ML anyway, I don't use mine for gaming).

And yes. You can use integrated for display and GPU for training.",support pretty good day anyway use mine gaming yes use display training,issue,positive,positive,positive,positive,positive,positive
451045239,"@Clorr So, have you successfully trained a generic encoder? This will improve the training speed for swap faces~",successfully trained generic improve training speed swap,issue,positive,positive,positive,positive,positive,positive
451043154,"@HighCommander4 @bryanlyon 
Thanks,i will try it. A month or two  is really too long.",thanks try month two really long,issue,negative,positive,neutral,neutral,positive,positive
451042942,"> We HIGHLY recommend an nvidia GPU.

Is there a way of having an nvidia GPU and using it for this purpose, while still using integrated graphics for display? The main reason I don't have an nvidia GPU is that I run Linux and their Linux support is terrible.",highly recommend way purpose still graphic display main reason run support terrible,issue,negative,negative,negative,negative,negative,negative
451041406,"Just a note: your CPU will require on the order of a month or two in order to train.  We *HIGHLY* recommend an nvidia GPU.  If you really don't have any way of one, you can try using AWS or Google Colab.  But CPU only is completely unsupported due to the time it'd take to train and run being unacceptably slow.",note require order month two order train highly recommend really way one try completely unsupported due time take train run unacceptably slow,issue,negative,positive,neutral,neutral,positive,positive
451039596,"The suggestion by @torzdf in [this comment](https://github.com/deepfakes/faceswap/issues/536#issuecomment-438616012) seems promising, but I haven't had the time to try it.",suggestion comment promising time try,issue,negative,positive,positive,positive,positive,positive
450906172,"There is another bug in the loss function for dfaker, so this may be related. On the face of it, I don't see an issue with your setup.

Next on my list is to implement the mask for dfaker and fix the loss function, so hold tight until the next update (probably tomorrow) and try again.",another bug loss function may related face see issue setup next list implement mask fix loss function hold tight next update probably tomorrow try,issue,negative,negative,neutral,neutral,negative,negative
450895925,"@kvrooman  Thanks, would be appreciated
@Enyakk Please post crash log",thanks would please post crash log,issue,negative,positive,positive,positive,positive,positive
450886313,"I am getting the following error when trying the dfaker model:
Configuration is: Windows 10, GTX 2080, CUDA 9.0. Tensorflow 1.12

<replaced by newer log>",getting following error trying model configuration log,issue,negative,neutral,neutral,neutral,neutral,neutral
450883618,"Like the re-org, I have a few of the same losses in an offline repo. Along with the testing, I can add some of the loss codes",like along testing add loss,issue,negative,neutral,neutral,neutral,neutral,neutral
450807749,"@HighCommander4
 Hi, do you solve it ? I only  have an AMD graphics card ,so i must use CPU, what should i do ?",hi solve graphic card must use,issue,negative,neutral,neutral,neutral,neutral,neutral
450801906,@shuai700  In short you shouldn't. But I shall make another commit to aid in doing so. I realized that converter ain't up to snuff.,short shall make another commit aid converter ai snuff,issue,negative,neutral,neutral,neutral,neutral,neutral
450677396,"Thanks for looking into this and the explanation. When I have a bit of time (probably in a week or 2) I will have a play around compiling DLIB with VS2017. Ultimately, I agree, the less prerequisites the user has to install for Windows, the better.",thanks looking explanation bit time probably week play around ultimately agree le user install better,issue,positive,positive,positive,positive,positive,positive
450674621,"### About CMake installation
I did some more tests.

The conclusion is:
1. In theory, only one installation of cmake is needed.
2. Yet compile with cmake from VS2017 will fail.
3. Yet the fail of 2 is not the fault of VS2017, its a bug of dlib CMakeList.txt.
4. dlib made an [inappropriate cmake version check](https://github.com/davisking/dlib/blob/61a021c932b74e591ce6a57ec1efa2dd59f33a7f/dlib/CMakeLists.txt#L624), which failed cmake(ver 3.12.18...) from VS2017 who actually should pass the build. 

The easy solution for most people is to install another cmake(ver 3.13.2) as a python dependency from requirements.txt, So python will use the ideal version of cmake.

The right and fast thing to do is to fix dlib CMakeList.txt, so we will only need a single cmake installation from VS2017. change the mentioned value above to **3.13** will fix it.",installation conclusion theory one installation yet compile fail yet fail fault bug made inappropriate version check actually pas build easy solution people install another python dependency python use ideal version right fast thing fix need single installation change value fix,issue,negative,positive,neutral,neutral,positive,positive
450667429,"Glad you point all these things that I am not so sure about.

Lets sort them out one by one.

### 1. Compile dlib against VS2017
This is the main reason why Im pulling this request. I think I located the real problem that troubled most people so trying to give some real tips here.

VS2017 actually works to compile dlib with AVX&CUDA but it requires packages of VC++ 2017 for Spectre which I have mentioned in commit message. This is the reason that troubled most people. I had an article debugging it [here](https://blog.qaq.link/cmake-with-vs2017-error/). I hope it explained well for you.

The following content is translated by google
```
CMAKE WITH VS2017 COMPILATION FAILURE REASON AND SOLUTION
 Published on: December 31, 2018  Category: Uncategorized Edit
When compiling dlib, I found that cmake reported an error. 

The hint is that the CMAKE_C_COMPILER and CMAKE_C_COMPILER cannot be found. 
This error is very vague, because in fact the VS2017 C++ project supports direct compilation. Setting vcvars manually has no effect.

So the troubleshooting method is as follows:

Try to compile dlib manually, check CMakeOutput.log and CMakeError.log for error, and find out the actual reasons are: 
1. CMake activates Spectre mitigation option by default (/Qspectre is enabled in cmdline)
2. Spectre Mitigation library does not exist, resulting in MSVCRTD.lib not found.

So the solution is to use the VS2017 Installer to manually select 
VC++2017 version 15.X v14.x Libs for Spectre (x86 and X64)

Try to recompile and successfully resolve.
```

### 2. Why Im trying to remove detection of VS
I suppose people to have many hacky styles of building environment. Not only Visual Studio 201X but also CMake and MinGW together or whatever else. They all actually works.\
But you are right and I might have gone too far. People seeking to use the `setup.py` seems to be less flexible on this. They might not expect this much information but simple detection and guides.\
I will start to improve the detection right now.

Tho cmake path is actually unnecessary so I removed them. pip automatically finds VS2017 and setup everything well for cmake. \
AVX&CUDA options too, dlib now smart enable them when compile. Check [dlib release notes](http://dlib.net/release_notes.html) in `Release 19.13` and `Release 19.2`

### 3. Dep version
you are right.
The update is too aggresive to apply. Forget it.

But I am sure they work with latest deps (2018/12/31). I installed every deps without version declaration. just saying.",glad point sure sort one one compile main reason request think real problem people trying give real actually work compile commit message reason people article hope well following content compilation failure reason solution category uncategorized edit found error hint found error vague fact project direct compilation setting manually effect method try compile manually check error find actual mitigation option default mitigation library exist resulting found solution use installer manually select version try recompile successfully resolve trying remove detection suppose people many hacky building environment visual studio also together whatever else actually right might gone far people seeking use le flexible might expect much information simple detection start improve detection right tho path actually unnecessary removed pip automatically setup everything well smart enable compile check release release release version right update apply forget sure work latest every without version declaration saying,issue,positive,positive,positive,positive,positive,positive
450643078,"Ok, some feedback.

Firstly, thanks for taking the time to do this PR. I think it will be useful and it is appreciated.

However.

The main reason that I did the full install instructions for Windows and put so many 'hacky' checks for correct installed versions in setup,py was because I was having to take an inordinate amount of time walking people through installing for Windows.

I still have issues now, albeit no where near as many, from people who fail to follow the instructions and then don't understand why their install doesn't work. 

It is widely reported that Dlib won't compile with VS 2017, so I will need to check that. If we do move to VS 2017 (ideally build tools, rather than full code), then we will need checks in place to make sure it is installed for Windows users. The check may not catch 100% of the installs, but if we can catch 80% then it will make my life a great deal easier. If there is one thing I've learned it's that: 

>  Lets just hope user make it right.

Will happen far less often than I would like!",feedback firstly thanks taking time think useful however main reason full install put many correct setup take inordinate amount time walking people still albeit near many people fail follow understand install work widely wo compile need check move ideally build rather full code need place make sure check may catch catch make life great deal easier one thing learned hope user make right happen far le often would like,issue,positive,positive,positive,positive,positive,positive
450642213,"This issue is closed.

Please do not raise general enquiries here.

Use: https://github.com/deepfakes/faceswap-playground
or: https://discord.gg/FdEwxXd",issue closed please raise general use,issue,negative,negative,neutral,neutral,negative,negative
450608521,"We can't remove all version declarations in requirements.txt.  Even if it works right now (which is not actually given, though I'm glad it works for you), we include the version declarations to prevent future problems as much as anything.  Actually changing those declarations over time as new versions come out and are verified is MUCH easier than handling the troubleshooting when it doesn't.

The rest of these pulls make sense to me, but torzdf will have to make the final call on that.",ca remove version even work right actually given though glad work include version prevent future much anything actually time new come much easier handling rest make sense make final call,issue,positive,positive,positive,positive,positive,positive
450604232,"You've got a ton of packages installed there, so there is probably a conflict somewhere which will be next to impossible to troubleshoot.

```py_virtual_env:    False```

Set up a clean virtual environment, run setup.py in your environment and try again.",got ton probably conflict somewhere next impossible false set clean virtual environment run environment try,issue,negative,negative,negative,negative,negative,negative
450592203,Yes. Several people do this. You are best getting advice from other users on discord: https://discord.gg/FdEwxXd,yes several people best getting advice discord,issue,positive,positive,positive,positive,positive,positive
450580866,"Ah, yeah. Ok. Pretty sure adjust doesn't work with GAN.

This will be looked at in a future update",ah yeah pretty sure adjust work gan future update,issue,positive,positive,positive,positive,positive,positive
450565970,Your pynvml looks wrong (my installed version doesn't have 1831 lines in it). Re-install pynvml or raise an issue with the author.,wrong version raise issue author,issue,negative,negative,negative,negative,negative,negative
450550997,"@surahul I don't know if I did it right. I also use Mac and change the default aligner from ""fan"" to ""dlib"" in cli.py line 394. It is running now.",know right also use mac change default aligner fan line running,issue,negative,positive,positive,positive,positive,positive
450534578,"@surahul You have no graphics card, so the error tells you exactly what to do ",graphic card error exactly,issue,negative,positive,positive,positive,positive,positive
450503800,"[crash_report.2018.12.29.215130393590.log](https://github.com/deepfakes/faceswap/files/2716538/crash_report.2018.12.29.215130393590.log)
Same here. macOS without graphic card",log without graphic card,issue,negative,neutral,neutral,neutral,neutral,neutral
450349156,"Good PR. I will test it out. Sort by Blur has always been problematic, so any improvements are appreciated",good test sort blur always problematic,issue,negative,positive,positive,positive,positive,positive
449638734,"Most likely it's a timeout. 

```12/23/2018 17:04:48 INFO     Waiting for Detector... Time out in 4 minutes```
means there's still 4 minutes remaining on the timeout. You should wait.

First time FAN runs always takes a long time. It's quick after that",likely waiting detector time still wait first time fan always long time quick,issue,negative,positive,positive,positive,positive,positive
449631964,@torzdf  i resolved it .just run `python faceswap.py extract -i _data/in/lyf/ -o _data/out/lyf/ -A dlib` in docker bash,resolved run python extract docker bash,issue,negative,neutral,neutral,neutral,neutral,neutral
449623663,"Same Error.And I Try it many times。Mac & Docker & CPU only

```
12/23/2018 17:03:44 INFO     Log level set to: INFO
12/23/2018 17:03:47 INFO     Output Directory: /Users/xxx/github/python/face-data/lyf/out/lyf
12/23/2018 17:03:47 INFO     Input Directory: /Users/xxx/github/python/face-data/lyf/in
12/23/2018 17:03:47 INFO     Loading Detect from Mtcnn plugin...
12/23/2018 17:03:48 INFO     Loading Align from Fan plugin...
12/23/2018 17:03:48 WARNING  No GPU detected. Switching to CPU mode
12/23/2018 17:03:48 INFO     Starting, this may take a while...
12/23/2018 17:03:48 INFO     Initializing Face Alignment Network...
12/23/2018 17:03:48 WARNING  No GPU detected. Switching to CPU mode
12/23/2018 17:03:48 ERROR    Caught exception in child process: 68481
12/23/2018 17:03:49 INFO     Initializing MTCNN Detector...
12/23/2018 17:03:49 ERROR    Caught exception in child process: 68485
12/23/2018 17:04:48 INFO     Waiting for Detector... Time out in 4 minutes
``` ",try many docker log level set output directory input directory loading detect loading align fan warning switching mode starting may take face alignment network warning switching mode error caught exception child process detector error caught exception child process waiting detector time,issue,negative,positive,positive,positive,positive,positive
449600473,"Please provide the crash report file.

Also your output says:
""KeyboardInterrupt"" which suggests you terminated the process",please provide crash report file also output process,issue,negative,neutral,neutral,neutral,neutral,neutral
449594463,"Alternatively (And easier)

From inside your environment enter:
```conda install -c conda-forge ffmpeg```

I have added automatic install to setup.py for future installs.",alternatively easier inside environment enter install added automatic install future,issue,negative,neutral,neutral,neutral,neutral,neutral
449562285,"Ok, you haven't installed properly. setup.py would have compiled and installed dlib for you.

Delete your environment and follow the instructions here to the letter:
https://github.com/deepfakes/faceswap/blob/master/INSTALL.md#windows-install-guide
",properly would delete environment follow letter,issue,negative,neutral,neutral,neutral,neutral,neutral
449540357,"@torzdf  it do help! but there  is new error...

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 105, in spawn_main
    exitcode = _main(fd)
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 114, in _main
    prepare(preparation_data)
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 225, in prepare
    _fixup_main_from_path(data['init_main_from_path'])
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 277, in _fixup_main_from_path
    run_name=""__mp_main__"")
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""C:\Users\17294\AppData\Local\Programs\Python\Python36\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""F:\git_clone\faceswap\faceswap.py"", line 5, in <module>
    import lib.cli as cli
  File ""F:\git_clone\faceswap\lib\cli.py"", line 12, in <module>
    from lib.utils import safe_shutdown
  File ""F:\git_clone\faceswap\lib\utils.py"", line 15, in <module>
    import dlib
ModuleNotFoundError: No module named 'dlib'",help new error recent call last file string line module file line file line prepare file line prepare data file line file line file line file line code file line module import file line module import file line module import module,issue,negative,positive,neutral,neutral,positive,positive
449513512,"Closing PR as code base has moved on a lot, and video import PR is raised, with video export to come.

May revisit this for the additional features that this was looking to implement",code base lot video import raised video export come may revisit additional looking implement,issue,negative,negative,negative,negative,negative,negative
448937145,"At the very first time it runs it can time out when initializing. Just try it again.

Also, rather than spamming issues with user questions, please use the Discord:
https://discord.gg/FdEwxXd

Thanks",first time time try also rather user please use discord thanks,issue,negative,positive,positive,positive,positive,positive
448916084,"It can work in either direction.
By default, Face B goes onto Body A.
There is a Swap Model checkbox in the Convert tab that can put Face A onto Body B.",work either direction default face go onto body swap model convert tab put face onto body,issue,negative,neutral,neutral,neutral,neutral,neutral
448850415,"The installation itself suggest me to not install it, since it's for Linux.

I close it.",installation suggest install since close,issue,negative,neutral,neutral,neutral,neutral,neutral
448785399,"I *think* vscode integration is only for compiling samples, so you should be ok. Try and see what happens.",think integration try see,issue,negative,neutral,neutral,neutral,neutral,neutral
448660123,"> 
> 
> That release is interested and unsupported. You can certainly try it, but you'll be in your own for installing supported libraries and troubleshooting the related issues. I recommend installing anaconda dinner it can be installed alongside any version you're using without interference.

Ok, thx.",release interested unsupported certainly try related recommend anaconda dinner alongside version without interference,issue,positive,positive,positive,positive,positive,positive
447588727,"I don't have an Nvidia card, so the exception is correct. (Using AMD GPU via plaidml keras backend)
The reason i get the NVMLError_DriverNotLoaded and not NVMLError_LibraryNotFound on Manjaro might be the way manjaros [hardware detection](https://wiki.manjaro.org/index.php?title=Manjaro_Hardware_Detection_Overview) works.

Will update with the added log line later.

",card exception correct via reason get might way hardware detection work update added log line later,issue,negative,neutral,neutral,neutral,neutral,neutral
447561486,"Also, to roll into 1 commit you can add:

```
self.logger.warning(""No GPU detected. Switching to CPU mode"")
```
on line 35",also roll commit add switching mode line,issue,negative,neutral,neutral,neutral,neutral,neutral
447561365,"Thanks for this.

Could you explain your setup please? Do you have an Nvidia card, but it's misconfigured, or you don't have an Nvidia Card?",thanks could explain setup please card card,issue,positive,positive,positive,positive,positive,positive
447551406,"```
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\,,amd64,14.0,bundle
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\,,x86,14.0,bundle
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AppInsightsToolsVisualStudio_HiddenVSU3RTMV1_7.0.20620.1,en,7.0.20620.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\JavaScriptLanguageService_Hidden_14.0.25527,en,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\JavaScriptProjectSystem_Hidden_14.0.25527,en,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.MVC_VisualStudio14_Tooling_CHS,v4
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.MVC_VisualStudio14_Tooling_ENU,v4
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebFrameworksAndTools_VisualStudio14_CHS,v5
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebFrameworksAndTools_VisualStudio14_ENU,v5
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebPages_VisualStudio14_Tooling_CHS,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebPages_VisualStudio14_Tooling_ENU,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Build.FileTracker.Msi,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_amd64_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnostics,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsAR,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsARRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsXD,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsXDRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.AzureServices_VS140_2052,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.AzureServices_VS_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Common_VS_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Common_VS_14.0_2052,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Notifications_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.community.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Diagnostics.PerfDebuggerWebViews_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Diagnostics.PerfDebuggerWebViews_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.Collection_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.Collection_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.LP_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfToolsRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfToolsRES_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfTools_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfTools_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCSharp.BreadcrumbRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ModernBlend.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPackLP_chs_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPackLP_enu_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPack_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.SDKLP_chs_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.SDK_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.TypeScript.SDK
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VisualStudio.FileHandler.Msi_x64,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VisualStudio.FileHandler.Msi_x86,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VisualStudio.MinShell.Msi,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VisualStudio.MinShell.Msi.Resources_chs,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VisualStudio.Setup.Configuration,v15
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BlendWPFSDK,v45
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Bliss_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Bliss_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.CodeAnalysis_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.communitycore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.communitycoreres_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.devenv,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.devenvlp_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Espc,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpSDKLP,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpVSLP,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Help3,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Help3_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Microsoft.VS.Espc_Res_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MinShellCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.minshellinterop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MinShellRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.ModernBlend_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.ModernBlend_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NETCoreSDK,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPack,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPack,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackCore,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackCoreLP_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackLP_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackLP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PerformanceCollectionTools_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PerformanceCollectionTools_amd64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP_LP_chs
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP_LP_chs,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Prerequisites_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Prerequisites_x64_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Profiling.tool_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools35,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools35_lp_chs,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools_lp_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools_lp_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TeamExplorerCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TeamExplorerCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestExecCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestExecCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestToolsCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestToolsCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSOfficeIntegrationLP_x64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSOfficeIntegration_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSStoryboardingLP_x64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSStoryboarding_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Common,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Common_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Pro_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Pro_Plus_Res,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Debugger,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Debugger_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_DIASDK,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_Core_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditional_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditional_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeDebug_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimum_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimum_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VSGraphics_EnableGraphicsTools,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk.vscore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk.vscore_fullres_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServices,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServicesLP_CHS,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServicesLP_ENU,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WebTools_EnableAspNet,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VSGraphics_VSGA.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VsVerification.sdk_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitDirectXx64Remote.x64.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitDirectXx86Remote.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitforWindowsStoreAppsDirectXx64Remote.x64.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitforWindowsStoreAppsDirectXx86Remote.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsAzure.Mobile.SDK,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\patch_KB3165756
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\TypeScript_SDK,1.8
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\vsupdate_KB3022398
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{00C5024D-925C-4E9E-A8E6-F9B84ABE0DA0}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{050d4fc8-5d48-4b8f-8972-47c82c46020f}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{064E4EE4-4052-417B-A99F-CBB94C296235}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{0A3B508E-5638-4471-BCC9-954E1868CB86}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{0f8bbc41-a65c-4ba1-af69-aacd12d13f5b}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{107518BF-43A3-4CB6-B571-9C5A241F9586}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{128C1654-3B9E-4959-8BFB-CE6F09C0A01D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{13FD7E30-D2F1-498D-ABC2-A4242DB6610E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1876B129-D2ED-3D5E-836C-8D4C23802659}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1A8A9739-BAD7-491F-B5B9-A79A2B965422}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1B87EE82-EB1D-442C-90A3-D86B08E9B7A1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{20185BDA-D396-4C93-95C7-ECD0FB397FF7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{23BA7BC5-8051-4568-A899-0FA5AAA4A1F5}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{24C81BA2-0AB3-4E88-AFDA-9AE37CDBCA85}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{25F2D0A2-897D-4C10-B89A-CB70E785BBB5}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{25FE7797-105C-482B-B8F8-CBCB3EA5DA0B}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2889C948-F002-4992-815F-DBE0AFB5DC6E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2A56910C-69C8-495D-8ED8-9080F0A14E58}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2D170B66-A905-385C-93E0-20A47812B777}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2FB312D3-E28F-3094-B6ED-47000F25D193}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2FD40264-796F-406E-89F3-FEE38419DFD2}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{314d4c01-f54b-4125-a71f-1e2722c29050}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3196EC29-B75D-4EE3-8AB0-46418BC31483}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{339E5049-CC0C-4227-8968-A467D0BAED31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{33d1fd90-4274-48a1-9bc1-97e33d9c2d6f}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{36AFFE18-F001-4170-AF7B-DFB3A9555623}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3838bcad-6df2-4f08-8add-a6217bd229d6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3882E617-A19F-38D0-8ED9-6F0DBC348A34}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3EE9BFF7-1F15-3CC1-9227-EE874A4398AC}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3FEAC561-1CF6-41D6-B0F3-BECDD9C88A1B}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{436A18DD-5F2C-4B3C-985E-AD3C13B0CC25}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{44FBA327-8528-4B29-B99C-A8F9BD232B11}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{463d5540-8dfd-4eef-92e5-b729b3b73cfb}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{47e285fc-2ff5-479e-9c14-4258d9954215}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{527F6645-0366-4984-B71D-803C478D302D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{54da9769-2364-4bd3-8139-6400500778b3}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{56E962F0-4FB0-3C67-88DB-9EAA6EEFC493}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{579B7F13-BCE2-3FCC-9273-40DC54D0B281}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5984D8DA-C1AF-4284-9C88-D7150425B315}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{599702AA-91EB-38C1-B994-CDE35C57E007}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5A28A95C-E5CF-413F-92D9-910129D088B8}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5BBB44D5-3CC0-4434-AA0C-5883B975E45E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5CBFF3F3-2D40-34EE-BCA5-A95BC19E400D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5EA8B971-01B1-3031-B61C-58A70F379120}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{60018889-9E0F-43E8-9B89-29E8C828B40A}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{603DCF17-E958-3A31-AFED-919086709DB6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{67E6ED45-5185-4B51-9CB1-DCB337D3A704}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6884D818-9E0E-4984-A6CA-B17757DCB8FA}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6a3b46d3-fbf1-4b22-8b42-48b675de6b81}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6E3610B2-430D-4EB0-81E3-2B57E8B9DE8D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6e8f74e0-43bd-4dce-8477-6ff6828acc07}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6FAC699B-7992-4C62-9839-4783564CAEDD}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{703527D4-EC56-43C3-B9B8-DADD81E653B1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{76722C36-3BF4-4326-9ADF-A56ABA50AA9F}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{77645CA0-D312-4E04-9A69-9CCB3D5C31C1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{79B9B6C9-3FAF-4F50-96A9-C1651EA0DD31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{79EB78D3-3EDD-420A-AE81-F0BF14ED0B8E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{7F68B9F8-9A17-4DBC-9522-8E414F5E6C05}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8070d64c-b4fe-4142-8e61-588a58a82ec7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{815F0BC1-7E54-300C-9ACA-C9460FDF6F78}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8485EB38-ED66-4188-BAC5-67320F627EFA}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{88FBE598-C041-4F28-988C-A8F52C3B3A10}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8A1AD070-269F-4A15-AAB5-76AB896EF195}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8C26982F-B345-3C87-8D17-5E88ADDAFFF6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8D5486F7-743A-46AE-9127-16BE5D25E2EE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8e70e4e1-06d7-470b-9f74-a51bef21088e}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8F15E32A-FAD1-49E3-9378-C8EE0530E192}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{93CC1063-02A1-4F25-A13A-C351A10D84DD}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{94E1227C-08A9-4962-B388-1F05D89AEA75}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9779473E-16D9-476C-B8AB-BF9A3BAE5348}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9890DF1A-10E9-4236-94B1-1EFAA4099F13}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{98AA8BB0-0C0A-411A-BB43-1265CA769155}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9B2232F4-9BA1-4A17-B5FD-A48C1343068A}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9bd48a22-fe5a-457c-8f10-da6c2be89eee}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9BD51EE7-D308-4FBC-92F4-934882FA340F}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9F429DF7-F8DD-4980-9673-E6DACA012F6C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A219D036-0D55-4844-8DD0-4E76B7ED3DF8}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A341BB17-AA72-45F1-9AC4-AF54CA6C0EC0}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A4495E4F-5218-48FB-8AD2-F3076011B9E1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A5E4C619-FA9E-36D6-AC52-74FE71831612}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A7059477-891A-48E4-B01E-34E3B0770A44}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AB3DF932-C990-34D4-BF43-970F760DA3CD}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AD132FA6-AEDF-48AA-A0BA-D31A32D399B9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{B2918D01-1D89-34D3-87EF-A28121BC6EB7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{b64ca997-b626-4abb-a046-5ca2d92ed659}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{BCDE6B0E-6EF6-49BF-96F6-1283D3182163}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C5A4ABA3-1ABA-3EF8-B2D5-C3FA37F59738}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C6A4A3DF-5A1E-4825-8D38-E5B00C196B31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{ca67548a-5ebe-413a-b50c-4b9ceb6d66c6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CDD5B213-0C36-4965-9EE1-817449DB57AC}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CFB2DA39-A693-3FE0-8129-DC55549ABF8C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CFEF48A8-BFB8-3EAC-8BA5-DE4F8AA267CE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D1E9367F-5F7C-4019-96B7-45967FD60DB4}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D6B752F0-CDE3-43C1-93CA-29FBD3F1A251}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D833831F-6814-4F42-87A5-55B491A16C20}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{DEAC33A4-FB05-32C6-8AAD-7FB26A8767E6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E1C0D2D2-0821-4C16-A442-3BAB61F26A3C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{e2803110-78b3-4664-a479-3611a381656a}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E8F893CE-1CB2-4B96-8789-FA1F9516B6C1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{EA418F63-68D3-4513-ACC9-BE9FF6A2DBB9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{ED4CC1E5-043E-4157-8452-B5E533FE2BA1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F152E951-440E-3B0F-AB63-2D8674C50092}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F42771F5-F03F-4BC3-9065-7D637F022697}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{f65db027-aff3-4070-886a-0d87064aabb1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F7E8A494-97B6-4786-9E2C-A42A082483EB}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FC4F00B2-F0DA-4E49-8424-C94C42115879}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FCC71A20-D265-4235-8957-5257F095E0C3}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FF56EA13-152D-44E5-920E-4223D2469485}




HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Assemblies
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Components
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Features
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Patches
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Products
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\UpgradeCodes
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Win32Assemblies
```
```
cp936
```
```
936
```
```
BodyName          : gb2312
EncodingName      : 简体中文(GB2312)
HeaderName        : gb2312
WebName           : gb2312
WindowsCodePage   : 936
IsBrowserDisplay  : True
IsBrowserSave     : True
IsMailNewsDisplay : True
IsMailNewsSave    : True
IsSingleByte      : False
EncoderFallback   : System.Text.InternalEncoderBestFitFallback
DecoderFallback   : System.Text.InternalDecoderBestFitFallback
IsReadOnly        : True
CodePage          : 936
```

Wait for the fixes update!  thanks a lot !",bundle bundle en en en da true true true true false true wait update thanks lot,issue,positive,positive,positive,positive,positive,positive
447551265,"HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}
```    (默认)    REG_SZ    {d992c12e-cab2-426f-bde3-fb8c53950b0d}
    Version    REG_SZ    14.0.24215.1
    DisplayName    REG_SZ    Microsoft Visual C++ 2015 Redistributable (x64) - 14.0.24215
```
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}\Dependents

HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\VisualStudio\14.0\VC\Runtimes\x64
```
    Version    REG_SZ    v14.12.25810.00
    Installed    REG_DWORD    0x1
    Major    REG_DWORD    0xe
    Minor    REG_DWORD    0xc
    Bld    REG_DWORD    0x64d2
    Rbld    REG_DWORD    0x0
```
",version visual version major minor,issue,negative,positive,neutral,neutral,positive,positive
447213581,"ok cool, was just wondering. thanks for reply.",cool wondering thanks reply,issue,positive,positive,positive,positive,positive,positive
446921271,"It should have a preview. There is probably a bug in there somewhere.

This won't be immediately fixed as training section of code is currently being refactored, so this will be handled there.",preview probably bug somewhere wo immediately fixed training section code currently handled,issue,negative,positive,neutral,neutral,positive,positive
446167158,"Thanks, this is useful information. Glad you got it working.",thanks useful information glad got working,issue,positive,positive,positive,positive,positive,positive
446154345,"Hi, I already finished the installation by manually setup. But here is the test results.

PS D:\DL> [System.Text.Encoding]::Default
>>
>> reg query HKLM\SOFTWARE\Classes\Installer\Dependencies
>>
>> reg query HKLM\SOFTWARE\Classes\Installer
>>
>> Next open up your virtual environment and post the output of these 2 commands:
>>
>> python -c ""import locale; print(locale.getpreferredencoding())""
>>
>> python -c ""from ctypes import cdll; print(str(cdll.kernel32.GetACP()))""


```BodyName          : gb2312
EncodingName      : 简体中文(GB2312)
HeaderName        : gb2312
WebName           : gb2312
WindowsCodePage   : 936
IsBrowserDisplay  : True
IsBrowserSave     : True
IsMailNewsDisplay : True
IsMailNewsSave    : True
IsSingleByte      : False
EncoderFallback   : System.Text.InternalEncoderBestFitFallback
DecoderFallback   : System.Text.InternalDecoderBestFitFallback
IsReadOnly        : True
CodePage          : 936
```


```HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\,,amd64,14.0,bundle
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\,,x86,14.0,bundle
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AndroidNDK11C_64_V1,en,11.3
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AndroidNDK11C_V1,en,11.3
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AndroidNDKV1,en,10.2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AndroidNDK_64_V1,en,10.2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Ant
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\AppInsightsToolsVisualStudio_HiddenVSU3RTMV1_7.0.20620.1,en,7.0.20620.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\ClickOnceV1,en,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\E_MDDCPlusPlus_Android_V7,zh-CHS,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\E_MDDCPlusPlus_iOS_V7,zh-CHS,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\GitHubVSV1,en,1.0.0.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\JavaScriptLanguageService_Hidden_14.0.25527,en,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\JavaScriptProjectSystem_Hidden_14.0.25527,en,1.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\MDDJSV11,en,1.0.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.MVC_VisualStudio14_Tooling_CHS,v4
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.MVC_VisualStudio14_Tooling_ENU,v4
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebFrameworksAndTools_VisualStudio14_CHS,v5
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebFrameworksAndTools_VisualStudio14_ENU,v5
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebPages_VisualStudio14_Tooling_CHS,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ASP.NET.WebPages_VisualStudio14_Tooling_ENU,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_amd64,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_amd64_enu,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_amd64_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_x86_enu,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_LP_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_x86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.BuildTools.MSBuild_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnostics,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsAR,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsARRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsWindowsXD,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsXD,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ClientDiagnosticsXDRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.AzureServices_VS140_2052,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.AzureServices_VS_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Common_VS_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Common_VS_14.0_2052,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CloudTools.Notifications_14.0,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CodedUITest81.sdk_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.CodedUITestUAP.sdk_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.community.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Diagnostics.PerfDebuggerWebViews_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Diagnostics.PerfDebuggerWebViews_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.Collection_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.Collection_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub.LP_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.DiagnosticsHub_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfToolsRES_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfToolsRES_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfTools_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.JSPerfTools_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus.Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus.CoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus.CoreX64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus_iOS.Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus_iOS.CoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCPlusPlus_iOS.CoreX64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDCSharp.BreadcrumbRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MDDDebugger.Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.MobileIntellisense.SDK,10.0.14393.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.ModernBlend.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPackLP_chs_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPackLP_enu_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.MTPack_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.SDKLP_chs_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.NetFx.SDK_4.6.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.OneCoreMobile.SDK,10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.OneCoreMobile.SDK,10.0.14393.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.OneCoreMobile.SDK.ARM,10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.OneCoreMobile.SDK.ARM,10.0.14393.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.PythonTools,v2.2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.TypeScript.SDK
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.UAPSDKAddOn.SDK,10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BehaviorsXaml,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BehaviorsXamlPhone,v1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BlendPhoneSDK,v8
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BlendSLSDK,v5
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.BlendWPFSDK,v45
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Bliss_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Bliss_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.CodeAnalysis_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.communitycore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.communitycoreres_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.devenv,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.devenvlp_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Espc,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpSDK,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpSDKLP,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpVS,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.FSharpVSLP,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Help3,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Help3_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.LibraryWPCore,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Microsoft.VS.Espc_Res_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MinShellCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.minshellinterop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MinShellRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MobileTools_AddInCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.MobileTools_AddInCore_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.ModernBlend_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.ModernBlend_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NETCoreSDK,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPack,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPack,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackCore,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackCoreLP_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackLP_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.NetFx_MTPackLP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PerformanceCollectionTools_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PerformanceCollectionTools_amd64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_professionalcore,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_professionalcore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_professionalcoreres,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_professionalcoreres,v14,chs
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_sharedcore,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_sharedcore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_sharedcoreres,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_sharedcoreres,v14,chs
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.phoneaddon_winexpresscore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP_LP_chs
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.PortableLibrary_DTP_LP_chs,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Prerequisites_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Prerequisites_x64_LP_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Profiling.tool_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools35,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools35_lp_chs,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools_lp_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.sdk_tools_lp_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TeamExplorerCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TeamExplorerCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestExecCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestExecCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestToolsCore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TestToolsCoreRes_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSOfficeIntegrationLP_x64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSOfficeIntegration_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSStoryboardingLP_x64_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.TFSStoryboarding_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompiler,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompiler86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompiler86Res_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerRes_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64Arm,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64ArmRes_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64Nat,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64NatRes_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64X86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcCompilerX64X86Res_chs,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Common,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Common_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Pro_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Pro_Plus_Res,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Core_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Debugger,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Debugger_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_DskX_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_DskX_Plus_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_MFC,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_MFC_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Option_Desktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Option_MFC,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Option_XP,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Pro_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_Pro_Plus_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_WinX_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcIDE_x64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcItems_Pro_Plus,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcItems_Pro_Plus_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_ATL_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_ATL_Source,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_ATL_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_ATL_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_Appx,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_Appx_Res_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_ARM_Desktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_ARM_OneCoreDesktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_ARM_Redist,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_ARM_Store,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_Headers,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_Redist_Res_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_Source,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X64_Desktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X64_OneCoreDesktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X64_Redist,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X64_Store,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X86_Desktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X86_OneCoreDesktop,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X86_Redist,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_CRT_X86_Store,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_DIASDK,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_MFC_Headers,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_MFC_MBCS,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_MFC_Source,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_MFC_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_MFC_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_PGO_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_PGO_Headers,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_PGO_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcLibrary_PGO_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_ARM_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_ARM_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_ARM_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_Nat,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_Nat_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X64_X86_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_ARM_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_Nat,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_Nat_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcPremTools_X86_X64_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTemplates_Pro,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTemplates_Pro_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTemplates_Pro_Windows_81,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTemplates_Pro_Windows_81_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTemplates_Pro_Windows_UAP_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_Core,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_Core_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_MSBuild_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_ARM_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_Nat,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_Nat_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_X86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X64_X86_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_ARM,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_ARM_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Base,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Base_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Nat,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_Nat_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_X64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VcTools_X86_X64_Res_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditionalVSU_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditional_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeAdditional_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeDebug_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeDebug_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_amd64,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v12
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimumVSU_x86,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimum_amd64,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VC_RuntimeMinimum_x86,v11
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VSGraphics_EnableGraphicsTools,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk.vscore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk.vscore_fullres_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.vssdk_fullres_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VSTemplates_professionalcoreres,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VSTemplates_win81wp81_communitycoreres,v14,chs
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.VSTemplates_windowsexpresscoreres,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServices,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServicesLP_CHS,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WcfDataServicesLP_ENU,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WebTools_EnableAspNet,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Win81DevTools,v14,x86
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Win81DevToolsRes,chs,v14,x86
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Win81Graphics,v14,x86
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.Win8DevTools,v12,x86
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.windows_buildcore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.windows_buildcoreres,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.windows_toolscore,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.windows_toolscoreres,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WinXPSupport,v11,amd64
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VS.WinXPSupport,v11,x86
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VSGraphics_VSGA.finalizer,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VsVerification.sdk.coreres_x86_chs,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.VsVerification.sdk_x86_enu,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.KitsConfigurationInstaller.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTExtensionSDK.x86.10.10150
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTExtensionSDK.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTExtensionSDK.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTExtensionSDK.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTHeadersLibrariesandSources.x86.10.10150
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTHeadersLibrariesandSources.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTHeadersLibrariesandSources.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTHeadersLibrariesandSources.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTRedistributable.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTToolsx64.x64.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalCRTToolsx86.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalGeneralMIDIDLSExtensionSDK.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalGeneralMIDIDLSExtensionSDK.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.UniversalGeneralMIDIDLSExtensionSDK.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinAppDeploy.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDK.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDK.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDK.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDKContracts.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDKContracts.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsDesktopExtensionSDKContracts.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDK.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDK.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDK.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDKContracts.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDKContracts.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIoTExtensionSDKContracts.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsIPOverUSB.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsRuntimeIntellisenseContent-zh-cn.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDK.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDesktopHeadersLibsMetadata.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDesktopHeadersLibsMetadata.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDesktopHeadersLibsMetadata.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDesktopTools.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDirectXx64Remote.x64.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKDirectXx86Remote.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKEULA.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKEULA.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKEULA.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreApps.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsContracts.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsContracts.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsContracts.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsDirectXx64Remote.x64.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsDirectXx86Remote.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsHeadersLibs.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsHeadersLibs.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsHeadersLibs.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKforWindowsStoreAppsTools.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKModernVersionedDeveloperTools.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSDKRedistributables.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKit.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitDirectXx64Remote.x64.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitDirectXx86Remote.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitforWindowsStoreApps.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitforWindowsStoreAppsDirectXx64Remote.x64.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsSoftwareDevelopmentKitforWindowsStoreAppsDirectXx86Remote.x86.8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDK.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDK.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDK.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDKContracts.x86.10.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDKContracts.x86.10.10586
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WindowsTeamExtensionSDKContracts.x86.10.14393
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseDesktop-en-us.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseDesktop-OtherLanguages.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseIoT-en-us.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseIoT-OtherLanguages.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisensePPI-en-us.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisensePPI-OtherLanguages.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseUAP-en-us.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseUAP-OtherLanguages.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseXboxLiveExtensionSDK-en-us.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.Windows.WinRTIntellisenseXboxLiveExtensionSDK-OtherLanguages.x86.10
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsAzure.Mobile.SDK,v2
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsPhone.WP_SDK_ARM,v8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsPhone.WP_SDK_Desktop,v10.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsPhone.WP_SDK_Desktop,v8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsPhone.WP_SDK_x64,v8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WindowsPhone.WP_SDK_x86,v8.1
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Microsoft.WinJS,v14
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\patch_KB3165756
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\PowerShellToolsV1,en,3.0.0
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\PythonToolsForVisualStudioV8,en,2.2.6
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\TypeScript_SDK,1.8
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\vsupdate_KB3022398
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\VS_Extensibility_TemplatesV5,en,14.10.28.58685
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\VS_SDKV5,en,2.0.3
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Win10SDK_10.0.10586.212,en,10.0.10586.212
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Win10SDK_10.0.14393.33,en,10.0.14393.33
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Win10SDK_Hidden_10.0.10240,en,10.0.10240
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\Win10_VSTools_14.0.25527,zh-CHS,14.0.25527
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{00C5024D-925C-4E9E-A8E6-F9B84ABE0DA0}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{02213A81-CB13-7262-5ABE-1FFA2C75559F}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{050d4fc8-5d48-4b8f-8972-47c82c46020f}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{064E4EE4-4052-417B-A99F-CBB94C296235}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{0A3B508E-5638-4471-BCC9-954E1868CB86}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{0f8bbc41-a65c-4ba1-af69-aacd12d13f5b}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{107518BF-43A3-4CB6-B571-9C5A241F9586}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{128C1654-3B9E-4959-8BFB-CE6F09C0A01D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{13FD7E30-D2F1-498D-ABC2-A4242DB6610E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{165ac150-ebe0-4892-b196-8d794e54357f}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1876B129-D2ED-3D5E-836C-8D4C23802659}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1A8A9739-BAD7-491F-B5B9-A79A2B965422}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1B87EE82-EB1D-442C-90A3-D86B08E9B7A1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{1BF61473-F34C-4DDA-AC79-3C08795AD925}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{23BA7BC5-8051-4568-A899-0FA5AAA4A1F5}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{24C81BA2-0AB3-4E88-AFDA-9AE37CDBCA85}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{25F2D0A2-897D-4C10-B89A-CB70E785BBB5}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{25FE7797-105C-482B-B8F8-CBCB3EA5DA0B}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{26F71396-D769-39A3-A38F-92F9E1790733}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{29b63284-2755-4dde-82a3-32ba7245febe}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2A56910C-69C8-495D-8ED8-9080F0A14E58}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2D170B66-A905-385C-93E0-20A47812B777}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2D22C607-69FC-4650-BDC5-F2B6197ABD05}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2F8F489A-0476-3129-857B-A553F38B192D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2FB312D3-E28F-3094-B6ED-47000F25D193}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{2FD40264-796F-406E-89F3-FEE38419DFD2}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3196EC29-B75D-4EE3-8AB0-46418BC31483}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{327A0959-29EC-401E-8874-09A3F80B275C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{339E5049-CC0C-4227-8968-A467D0BAED31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{33d1fd90-4274-48a1-9bc1-97e33d9c2d6f}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{349264A6-46CE-3B55-A779-655B69745BB2}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{36AFFE18-F001-4170-AF7B-DFB3A9555623}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3838bcad-6df2-4f08-8add-a6217bd229d6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3882E617-A19F-38D0-8ED9-6F0DBC348A34}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3CB4E2E8-04EB-371A-9433-4CA0D934B260}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3EE9BFF7-1F15-3CC1-9227-EE874A4398AC}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3FA063D7-EDC1-AFA8-54AF-0563C7DEE070}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{3FEAC561-1CF6-41D6-B0F3-BECDD9C88A1B}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{4218FF0A-5703-45DA-B513-81B7BA202A80}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{436A18DD-5F2C-4B3C-985E-AD3C13B0CC25}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{43d9f43d-c90b-4fdf-9dfe-ecf9990bfa2a}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{44FBA327-8528-4B29-B99C-A8F9BD232B11}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{463d5540-8dfd-4eef-92e5-b729b3b73cfb}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{47e285fc-2ff5-479e-9c14-4258d9954215}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{489FABEE-1D4B-4C54-B72A-899D11E8AE2B}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{48A8F171-52F2-372B-8414-EA50617708BE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{491D1B4D-F605-3C92-A313-5B9A05681E23}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{4eeeb36b-8694-4237-a72a-46d956b353e6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{4F0EC958-0B8A-4C18-8EF0-DB8617C2238C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{527F6645-0366-4984-B71D-803C478D302D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{53D3ECD8-0D2B-4995-AF49-FA53620C6893}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{56E962F0-4FB0-3C67-88DB-9EAA6EEFC493}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{572AF35B-C6DF-4854-B028-79645F21DBA6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{579B7F13-BCE2-3FCC-9273-40DC54D0B281}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5984D8DA-C1AF-4284-9C88-D7150425B315}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{599702AA-91EB-38C1-B994-CDE35C57E007}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5A2177BF-FB73-4E7F-89F9-A06BF4058B4C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5A28A95C-E5CF-413F-92D9-910129D088B8}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5CBFF3F3-2D40-34EE-BCA5-A95BC19E400D}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5D8DD6A8-C4D7-4554-93F9-F1CC28C72600}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{5EA8B971-01B1-3031-B61C-58A70F379120}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{60018889-9E0F-43E8-9B89-29E8C828B40A}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{603DCF17-E958-3A31-AFED-919086709DB6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{604E67D5-3F68-32A9-AA06-624C7595C9EF}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{605FFCBB-EC5A-485C-B27E-189F1C8A96E5}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{62910715-63E3-0AB0-0B29-99140DE1C15E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{67E6ED45-5185-4B51-9CB1-DCB337D3A704}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6a3b46d3-fbf1-4b22-8b42-48b675de6b81}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{6D905B13-4FA5-3E18-BDD7-A54F4445E4F6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{703527D4-EC56-43C3-B9B8-DADD81E653B1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{76722C36-3BF4-4326-9ADF-A56ABA50AA9F}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{77645CA0-D312-4E04-9A69-9CCB3D5C31C1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{77E2D875-FD9E-3DEE-9A84-C34FDECB4ECA}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{79B9B6C9-3FAF-4F50-96A9-C1651EA0DD31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{79d24cbf-fc9a-4798-85d8-67c3ae54f1a7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{79EB78D3-3EDD-420A-AE81-F0BF14ED0B8E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{7F68B9F8-9A17-4DBC-9522-8E414F5E6C05}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8070d64c-b4fe-4142-8e61-588a58a82ec7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{815F0BC1-7E54-300C-9ACA-C9460FDF6F78}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8485EB38-ED66-4188-BAC5-67320F627EFA}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{84D88F57-4130-30FE-A0B6-1E04428FE1F6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{88FBE598-C041-4F28-988C-A8F52C3B3A10}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8A1AD070-269F-4A15-AAB5-76AB896EF195}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8C26982F-B345-3C87-8D17-5E88ADDAFFF6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8D5486F7-743A-46AE-9127-16BE5D25E2EE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{8F15E32A-FAD1-49E3-9378-C8EE0530E192}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{93CC1063-02A1-4F25-A13A-C351A10D84DD}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{94E1227C-08A9-4962-B388-1F05D89AEA75}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9779473E-16D9-476C-B8AB-BF9A3BAE5348}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9890DF1A-10E9-4236-94B1-1EFAA4099F13}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9B2232F4-9BA1-4A17-B5FD-A48C1343068A}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9BD51EE7-D308-4FBC-92F4-934882FA340F}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9F429DF7-F8DD-4980-9673-E6DACA012F6C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{9F5B0C35-2109-4BAA-84D2-A8B50D9B90A8}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A219D036-0D55-4844-8DD0-4E76B7ED3DF8}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A341BB17-AA72-45F1-9AC4-AF54CA6C0EC0}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A4495E4F-5218-48FB-8AD2-F3076011B9E1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A4FD9407-81A3-4919-B9FF-D5D8D4981713}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A5E4C619-FA9E-36D6-AC52-74FE71831612}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A7059477-891A-48E4-B01E-34E3B0770A44}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A7E87388-3512-4D9C-9BBA-284C3577CBE9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{a8819d3f-c77c-4542-8d49-492fb6da0895}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{A8C402D5-7FFE-43BB-9522-4374119A05EB}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AAFF73AD-3432-3575-ABD1-14E48EF2F4CB}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AB3DF932-C990-34D4-BF43-970F760DA3CD}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AD132FA6-AEDF-48AA-A0BA-D31A32D399B9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{AF61914E-EB84-401F-BFEB-08C30CF625BE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{B2918D01-1D89-34D3-87EF-A28121BC6EB7}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{B3E86AAF-5701-4862-90F5-A68BF640D131}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{b64ca997-b626-4abb-a046-5ca2d92ed659}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{B8488F06-2901-4BCA-89EA-52969FEEEDA4}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{B8E14C55-53F6-3693-A74A-77A3C6B96041}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{BCDE6B0E-6EF6-49BF-96F6-1283D3182163}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{BF4D68A5-4785-4D99-992A-101F79DBA826}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C596D608-3E74-3232-8CA5-DF1DCB9F10DE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C5A4ABA3-1ABA-3EF8-B2D5-C3FA37F59738}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C6A4A3DF-5A1E-4825-8D38-E5B00C196B31}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{C74C87F5-49E8-4C53-BA41-40CFDEE0D93E}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{ca67548a-5ebe-413a-b50c-4b9ceb6d66c6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CB2EF90F-5E77-4516-9026-4F43B1E3D901}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CDD5B213-0C36-4965-9EE1-817449DB57AC}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CFB2DA39-A693-3FE0-8129-DC55549ABF8C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{CFEF48A8-BFB8-3EAC-8BA5-DE4F8AA267CE}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D11F66FF-82B3-DDB8-1146-525370552BE1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D1E9367F-5F7C-4019-96B7-45967FD60DB4}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D21B5F75-8042-3B39-80A1-F1D56D6DB4AB}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D42681AA-BC16-3C84-949E-45F05D2AA997}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D6B752F0-CDE3-43C1-93CA-29FBD3F1A251}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D6DEA3AD-637E-368A-BD00-501D443F5E86}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D73F0D67-9122-4B9A-BF36-FFAF8C046010}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D833831F-6814-4F42-87A5-55B491A16C20}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D86ACC91-714D-3D3D-B9D5-1051A17002E1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{D8828D7B-8323-3845-80C1-F42D33D53BC9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{da78a187-c216-4b8f-b2ff-f6f254e2e26e}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{DC8FA8B0-9EBA-38F2-934D-001BD21EACB6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{DEAC33A4-FB05-32C6-8AAD-7FB26A8767E6}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E164652A-0EB8-430B-AB4C-8814B7234997}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E1C0D2D2-0821-4C16-A442-3BAB61F26A3C}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E1CD0852-A08F-4980-84E6-94BE9F60CBEB}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{e2803110-78b3-4664-a479-3611a381656a}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E5CAE8D2-9F9F-3BEA-AA0F-B5B40611C704}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E5F6360C-819A-38E6-B108-221BB458A6DF}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{e7a0c8b6-b0e9-41e2-8a0a-a6784f88d1d4}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{E8F893CE-1CB2-4B96-8789-FA1F9516B6C1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{EA418F63-68D3-4513-ACC9-BE9FF6A2DBB9}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{ED4CC1E5-043E-4157-8452-B5E533FE2BA1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F152E951-440E-3B0F-AB63-2D8674C50092}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{f23f94c5-8bba-4202-85ad-c83d4402cdc1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F42771F5-F03F-4BC3-9065-7D637F022697}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{f65db027-aff3-4070-886a-0d87064aabb1}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F7BC1DF3-6FA8-408D-BD32-67830D65F619}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{F9C5C871-7A8A-9013-DE11-070544F66220}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FA782BB7-7210-4A69-9BAA-FCBA087565AA}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FC4F00B2-F0DA-4E49-8424-C94C42115879}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FCC71A20-D265-4235-8957-5257F095E0C3}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FCC95978-2484-4DE0-90C1-0937E838DA70}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FF56EA13-152D-44E5-920E-4223D2469485}
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies\{FFC6E93A-B9AD-3F20-9B06-EE20E24AAEAF}
```

```HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Assemblies
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Components
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Dependencies
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Features
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Patches
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Products
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\UpgradeCodes
HKEY_LOCAL_MACHINE\SOFTWARE\Classes\Installer\Win32Assemblies
```

Next : 无法将“Next”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确
，然后再试一次。
所在位置 行:7 字符: 1
+ Next open up your virtual environment and post the output of these 2  ...
+ ~~~~
    + CategoryInfo          : ObjectNotFound: (Next:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException

```cp936```

```936```


If you need the translation for the chinese, let me know",hi already finished installation manually setup test reg query reg query next open virtual environment post output python import locale print python import print true true true true false true bundle bundle en en en en en en en en en en en en en en en en en ae next next next open virtual environment post output next string need translation let know,issue,positive,positive,positive,positive,positive,positive
446149195,"Ok, that's strange on the invalid command. I'm fairly sure this is a fixable character encoding issue.

Would you mind running some tests for me?

Open up a Windows Powershell session and post the output of each of these:
```[System.Text.Encoding]::Default```

```reg query HKLM\SOFTWARE\Classes\Installer\Dependencies```

```reg query HKLM\SOFTWARE\Classes\Installer```

Next open up your virtual environment and post the output of these 2 commands:

```python -c ""import locale; print(locale.getpreferredencoding())""```

```python -c ""from ctypes import cdll; print(str(cdll.kernel32.GetACP()))""```

Thanks",strange invalid command fairly sure fixable character issue would mind running open session post output reg query reg query next open virtual environment post output python import locale print python import print thanks,issue,positive,positive,positive,positive,positive,positive
446099159,"> Could you open up a command prompt and post the output of the following commands:
> `chcp`
> 
> `reg query HKLM\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}`
> 
> `reg query HKLM\SOFTWARE\WOW6432Node\Microsoft\VisualStudio\14.0\VC\Runtimes\x64""`
> 
> Thanks

I got the same problem.
chcp
xxxxx: 936  (xxxx is chinese, I guess you dont need them)

reg query HKLM\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}
invalide command (I dont know why)

reg query HKLM\SOFTWARE\WOW6432Node\Microsoft\VisualStudio\14.0\VC\Runtimes\x64
Version    REG_SZ    v14.0.24215.01
    Installed    REG_DWORD    0x1
    Major    REG_DWORD    0xe
    Minor    REG_DWORD    0x0
    Bld    REG_DWORD    0x5e97
    Rbld    REG_DWORD    0x1
",could open command prompt post output following reg query reg query thanks got problem guess dont need reg query command dont know reg query version major minor,issue,negative,positive,neutral,neutral,positive,positive
446089712,"> Firstly, I'm afraid it's highly unlikely you will be able to run FS with your gfx card. You really need a minimum of 2GB VRAM for it to work. You can try, but I'm afraid it's unsupported.
> 
> As for the above issue, You have both the CPU and GPU versions of Tensorflow installed:
> 
> ```
> tensorflow==1.12.0
> tensorflow-gpu==1.12.0
> ```
> Remove the CPU version:
> `pip uninstall tensorflow`
> 
> or (as may be more relevant in your case) remove the GPU version and use a different detector/aligner:
> `pip uninstall tensorflow-gpu`

Thanks dude, I try to run FS with another PC, gfx 1050.， use detector with dlib-cnn, and
Aligner with dlib,  It works well,thanks.
",firstly afraid highly unlikely able run card really need minimum work try afraid unsupported issue remove version pip may relevant case remove version use different pip thanks dude try run another use detector aligner work well thanks,issue,positive,negative,neutral,neutral,negative,negative
445855379,"Could you open up a command prompt and post the output of the following commands:
```chcp```

```reg query HKLM\SOFTWARE\Classes\Installer\Dependencies\{d992c12e-cab2-426f-bde3-fb8c53950b0d}```

```reg query HKLM\SOFTWARE\WOW6432Node\Microsoft\VisualStudio\14.0\VC\Runtimes\x64""```

Thanks",could open command prompt post output following reg query reg query thanks,issue,negative,positive,neutral,neutral,positive,positive
445773871,"Firstly, I'm afraid it's highly unlikely you will be able to run FS with your gfx card. You really need a minimum of 2GB VRAM for it to work. You can try, but I'm afraid it's unsupported.

As for the above issue, You have both the CPU and GPU versions of Tensorflow installed:
```
tensorflow==1.12.0
tensorflow-gpu==1.12.0
```
 Remove the CPU version:
```pip uninstall tensorflow```

or (as may be more relevant in your case) remove the GPU version and use a different detector/aligner:
```pip uninstall tensorflow-gpu```


",firstly afraid highly unlikely able run card really need minimum work try afraid unsupported issue remove version pip may relevant case remove version use different pip,issue,negative,negative,neutral,neutral,negative,negative
445772693,"> Sorry dude. Missed that. Will check

thank you so much！",sorry dude check thank,issue,negative,negative,negative,negative,negative,negative
445771784,"> This is not the crash report.
> 
> This is the crash report:
> 
> > 12/10/2018 11:01:19 CRITICAL An unexpected crash has occurred. Crash report written to G:\AI\faceswap-staging\crash_report.2018.12.10.110119210247.log

The log file is in the attachment above。
[crash_report.2018.12.10.110119210247.log](https://github.com/deepfakes/faceswap/files/2662776/crash_report.2018.12.10.110119210247.log)
",crash report crash report critical unexpected crash crash report written log log file attachment log,issue,negative,positive,neutral,neutral,positive,positive
445767577,"This is not the crash report.

This is the crash report:

> 12/10/2018 11:01:19 CRITICAL An unexpected crash has occurred. Crash report written to G:\AI\faceswap-staging\crash_report.2018.12.10.110119210247.log",crash report crash report critical unexpected crash crash report written log,issue,negative,positive,neutral,neutral,positive,positive
445657833,"Loading...
12/10/2018 10:52:49 INFO     Log level set to: INFO
12/10/2018 10:52:51 INFO     Output Directory: G:\AI\A\faceA
12/10/2018 10:52:51 INFO     Input Directory: G:\AI\A\OutA
12/10/2018 10:52:51 INFO     Loading Detect from Mtcnn plugin...
12/10/2018 10:52:51 INFO     Loading Align from Fan plugin...
12/10/2018 10:52:51 INFO     NB: Parallel processing disabled.You may get faster extraction speeds by enabling it with the -mp switch
12/10/2018 10:52:51 INFO     Starting, this may take a while...
12/10/2018 10:52:51 INFO     Initializing MTCNN Detector...
12/10/2018 10:52:53 WARNING  Using CPU


2018-12-10 10:52:52.618271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce GTX 550 Ti major: 2 minor: 1 memoryClockRate(GHz): 1.82
pciBusID: 0000:01:00.0
totalMemory: 1.00GiB freeMemory: 866.89MiB
2018-12-10 10:52:52.618271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1482] Ignoring visible gpu device (device: 0, name: GeForce GTX 550 Ti, pci bus id: 0000:01:00.0, compute capability: 2.1) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.7.
2018-12-10 10:52:52.618271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:52:52.618271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2018-12-10 10:52:52.618271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
12/10/2018 10:56:19 INFO     Initializing Face Alignment Network...
12/10/2018 10:56:26 ERROR    Caught exception in child process: 5160
2018-12-10 10:56:22.021249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:
name: GeForce GTX 550 Ti major: 2 minor: 1 memoryClockRate(GHz): 1.82
pciBusID: 0000:01:00.0
totalMemory: 1.00GiB freeMemory: 866.89MiB
2018-12-10 10:56:22.021249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1482] Ignoring visible gpu device (device: 0, name: GeForce GTX 550 Ti, pci bus id: 0000:01:00.0, compute capability: 2.1) with Cuda compute capability 2.1. The minimum required Cuda capability is 3.7.
2018-12-10 10:56:22.021249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-10 10:56:22.021249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
2018-12-10 10:56:22.021249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
2018-12-10 10:56:26.428501: E tensorflow/core/common_runtime/executor.cc:623] Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC on device type CPU
[[{{node fa/avg_pool}} = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 2, 2], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](fa/Add_1)]]
12/10/2018 11:01:19 ERROR    Got Exception on main handler:
Traceback (most recent call last):
File ""G:\AI\faceswap-staging\lib\cli.py"", line 90, in execute_script
process.process()
File ""G:\AI\faceswap-staging\scripts\extract.py"", line 51, in process
self.run_extraction(save_thread)
File ""G:\AI\faceswap-staging\scripts\extract.py"", line 150, in run_extraction
self.plugins.launch_aligner()
File ""G:\AI\faceswap-staging\scripts\extract.py"", line 348, in launch_aligner
raise ValueError(""Error initializing Aligner"")
ValueError: Error initializing Aligner
12/10/2018 11:01:19 CRITICAL An unexpected crash has occurred. Crash report written to G:\AI\faceswap-staging\crash_report.2018.12.10.110119210247.log. Please verify you are running the latest version of faceswap before reporting
Process exited.",loading log level set output directory input directory loading detect loading align fan parallel may get faster extraction switch starting may take detector warning found device name ti major minor visible device device name ti bus id compute capability compute capability minimum capability device interconnect strength edge matrix face alignment network error caught exception child process found device name ti major minor visible device device name ti bus id compute capability compute capability minimum capability device interconnect strength edge matrix executor create kernel invalid argument default device type node valid error got exception main handler recent call last file line file line process file line file line raise error aligner error aligner critical unexpected crash crash report written log please verify running latest version process,issue,negative,positive,neutral,neutral,positive,positive
445657088,"


> Please checkout the staging branch, try again and if it fails post your crash report.
> 
> Thanks
I checkout staging branch ,this is my crash report.
[crash_report.2018.12.10.110119210247.log](https://github.com/deepfakes/faceswap/files/2661434/crash_report.2018.12.10.110119210247.log)

",please staging branch try post crash report thanks staging branch crash report log,issue,negative,positive,positive,positive,positive,positive
445531556,"Get the latest version of the code and try again. You can try to set logging to debug (or even trace if you're brave), but you may not glean much more information as logging is not yet fully implemented for training.

Generally, when it silently freezes, it's a memory allocation issue, which has silently failed in the background without raising the error, so you could try lowering your batch size to 16 and going from there.

Otherwise, as this seems to be quite a user specific issue, you can try looking for help on the Discord server where there may be someone who has a similar setup:
https://discord.gg/FdEwxXd
",get latest version code try try set logging even trace brave may glean much information logging yet fully training generally silently memory allocation issue silently background without raising error could try lowering batch size going otherwise quite user specific issue try looking help discord server may someone similar setup,issue,positive,positive,positive,positive,positive,positive
445192692,"Please checkout the staging branch, try again and if it fails post your crash report.

Thanks",please staging branch try post crash report thanks,issue,negative,positive,positive,positive,positive,positive
445121032,"> You either don't have a GPU or you are using the CPU version of tensorflow.
> 
> Either way FAN does not currently support CPU, so either use dlib aligner or install tensorflow-gpu.

I installed tensorflow-gpu-1.12.0 already。there is the same problem",either version either way fan currently support either use aligner install problem,issue,negative,neutral,neutral,neutral,neutral,neutral
445120867,"> Initializing Face Alignment Network...
> 2018-11-13 18:17:11.114608: E tensorflow/core/common_runtime/executor.cc:630] Executor failed to create kernel. Invalid argument: Default AvgPoolingOp only supports NHWC on device type CPU
> [[{{node fa/avg_pool}} = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 2, 2], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](fa/Add_1)]]
> Process SpawnProcess-3:
> Traceback (most recent call last):
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1292, in _do_call
> return fn(*args)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1277, in _run_fn
> options, feed_dict, fetch_list, target_list, run_metadata)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1367, in _call_tf_sessionrun
> run_metadata)
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC on device type CPU
> [[{{node fa/avg_pool}} = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 2, 2], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](fa/Add_1)]]
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 258, in _bootstrap
> self.run()
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 93, in run
> self._target(*self._args, **self._kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 60, in align
> super().align(*args, **kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align_base.py"", line 70, in align
> self.initialize(*args, **kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 53, in initialize
> verbose=self.verbose, ratio=tf_ratio)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 213, in **init**
> self.session = self.set_session(ratio)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 238, in set_session
> session.run(self.output, feed_dict={self.input: placeholder})
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 887, in run
> run_metadata_ptr)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1110, in _run
> feed_dict_tensor, options, run_metadata)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1286, in _do_run
> run_metadata)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1308, in _do_call
> raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC on device type CPU
> [[{{node fa/avg_pool}} = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 2, 2], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](fa/Add_1)]]
> 
> Caused by op 'fa/avg_pool', defined at:
> File """", line 1, in 
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 105, in spawn_main
> exitcode = _main(fd)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"", line 118, in _main
> return self._bootstrap()
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 258, in _bootstrap
> self.run()
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 93, in run
> self._target(*self._args, **self._kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 60, in align
> super().align(*args, **kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align_base.py"", line 70, in align
> self.initialize(*args, **kwargs)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 53, in initialize
> verbose=self.verbose, ratio=tf_ratio)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 210, in **init**
> self.graph = self.load_graph()
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\plugins\extract\align\fan.py"", line 226, in load_graph
> tf.import_graph_def(graph_def, name=""fa"")
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
> return func(*args, **kwargs)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\importer.py"", line 442, in import_graph_def
> _ProcessNewOps(graph)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\importer.py"", line 234, in _ProcessNewOps
> for new_op in graph._add_new_tf_operations(compute_devices=False): # pylint: disable=protected-access
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3438, in _add_new_tf_operations
> for c_op in c_api_util.new_tf_operations(self)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3438, in 
> for c_op in c_api_util.new_tf_operations(self)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3297, in _create_op_from_tf_operation
> ret = Operation(c_op, self)
> File ""C:\Users\10580\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1768, in **init**
> self._traceback = tf_stack.extract_stack()
> 
> InvalidArgumentError (see above for traceback): Default AvgPoolingOp only supports NHWC on device type CPU
> [[{{node fa/avg_pool}} = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 2, 2], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](fa/Add_1)]]
> 
> Traceback (most recent call last):
> File ""faceswap.py"", line 36, in 
> ARGUMENTS.func(ARGUMENTS)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\lib\cli.py"", line 81, in execute_script
> process.process()
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\scripts\extract.py"", line 47, in process
> self.run_extraction(save_thread)
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\scripts\extract.py"", line 113, in run_extraction
> self.plugins.launch_aligner()
> File ""C:\Users\10580\Desktop\workspasce\faceswap-master\scripts\extract.py"", line 303, in launch_aligner
> raise ValueError(""Error inititalizing Aligner"")
> ValueError: Error inititalizing Aligner

hello~I also encountered the same problem, how can I deal with this problem?
I try to work it on GTX 550Ti 
thanks",face alignment network executor create kernel invalid argument default device type node valid process recent call last file line return file line file line default device type node valid handling exception another exception recent call last file line file line run file line align super file line align file line initialize file line ratio file line file line run file line file line file line raise type message default device type node valid defined file line file line file line return file line file line run file line align super file line align file line initialize file line file line fa file line return file line graph file line file line self file line self file line ret operation self file line see default device type node valid recent call last file line file line file line process file line file line raise error aligner error aligner also problem deal problem try work ti thanks,issue,negative,positive,neutral,neutral,positive,positive
444177826,"I'm not clear what your issue is. That issue was resolved.

You're better off getting support on the Discord:
https://discord.gg/FdEwxXd

If you can't get on Discord/Still have issues then check out the staging branch and post your crash log to a new issue.
",clear issue issue resolved better getting support discord ca get check staging branch post crash log new issue,issue,positive,positive,positive,positive,positive,positive
444122626,"found the same issue like what other facing before
[https://github.com/deepfakes/faceswap/issues/529
](url)

current tensorflow version is 1.12",found issue like facing current version,issue,negative,neutral,neutral,neutral,neutral,neutral
443734603,"Make sure you are on latest repo and your packages are up to date with latest requirements.txt

You can check out the (alpha) logging branch and provide a crash log if you are still having issues",make sure latest date latest check alpha logging branch provide crash log still,issue,negative,positive,positive,positive,positive,positive
443699125,"after upgrade to 1.12 it become below error

ImportError: cannot import name 'abs'",upgrade become error import name,issue,negative,neutral,neutral,neutral,neutral,neutral
443690290,"
Name: tensorflow
Version: 1.5.0
Summary: TensorFlow helps the tensors flow
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: c:\users\ruah1\appdata\local\programs\python\python36\lib\site-packages
Requires: six, protobuf, wheel, absl-py, tensorflow-tensorboard, numpy
Required-by: keras-vggface",name version summary flow author license apache location six wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
443687206,"Latest pull, using faceswap.py gui extract

Loading...
Output Directory: D:\data_dst\aligned
Input Directory: D:\data_dst
Loading Detect from Mtcnn plugin...
Loading Align from Fan plugin...

NB: Parallel processing disabled.
You may get faster extraction speeds by enabling it with the -mp switch

Starting, this may take a while...
Initializing MTCNN Detector...Process SpawnProcess-2:

Traceback (most recent call last):
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 258, in _bootstrap
self.run()
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 93, in run
self._target(*self._args, **self._kwargs)
File ""C:\Users\ruah1\Downloads\faceswap-master (3)\faceswap-master\plugins\extract\detect\mtcnn.py"", line 100, in detect_faces
super().detect_faces(*args, **kwargs)
File ""C:\Users\ruah1\Downloads\faceswap-master (3)\faceswap-master\plugins\extract\detect\_base.py"", line 80, in detect_faces
self.initialize(*args, **kwargs)
File ""C:\Users\ruah1\Downloads\faceswap-master (3)\faceswap-master\plugins\extract\detect\mtcnn.py"", line 73, in initialize
alloc = int(sess.run(tf.contrib.memory_stats.BytesLimit()) /
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\memory_stats\python\ops\memory_stats_ops.py"", line 36, in BytesLimit
return gen_memory_stats_ops.bytes_limit()
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\contrib\memory_stats\ops\gen_memory_stats_ops.py"", line 64, in bytes_limit
""BytesLimit"", name=name)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3162, in create_op
compute_device=compute_device)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 3208, in _create_op_helper
set_shapes_for_outputs(op)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2427, in set_shapes_for_outputs
return _set_shapes_for_outputs(op)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2400, in _set_shapes_for_outputs
shapes = shape_func(op)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2330, in call_with_requiring
return call_cpp_shape_fn(op, require_shape_fn=True)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shape_fn
require_shape_fn)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
input_tensors_as_shapes, status)
File ""C:\Users\ruah1\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'BytesLimit' in binary running on DESKTOP-3J7UVPN. Make sure the Op and Kernel are registered in the binary running in this process.
Terminating Process...
Terminated
Process exited.",latest pull extract loading output directory input directory loading detect loading align fan parallel disabled may get faster extraction switch starting may take detector process recent call last file line file line run file line super file line file line initialize file line return file line file line file line file line file line return file line file line return file line file line status file line type registered binary running make sure kernel registered binary running process process process,issue,positive,positive,positive,positive,positive,positive
443659622,"Your convert command looks wrong. Please either look for help on https://github.com/deepfakes/faceswap-playground/issues

Or ask for help in the Discord:
https://discord.gg/FdEwxXd
",convert command wrong please either look help ask help discord,issue,negative,negative,negative,negative,negative,negative
443358179,"Nice, I can't wait to see it. Has anything been produced a model that can produce as much as the face as DFaker? Nothing I've trialed quite compares to it.",nice ca wait see anything produced model produce much face nothing quite,issue,negative,positive,positive,positive,positive,positive
443356818,"This version has.

A new port is in development and has been tested working, but I'm a little short of time to finish it. 

It will be coming though, hopefully before the end of the year

Dfaker training in FS:
![dfaker in faceswap](https://cdn.discordapp.com/attachments/487268792636801034/510382022104186891/unknown.png)
",version new port development tested working little short time finish coming though hopefully end year training,issue,negative,negative,neutral,neutral,negative,negative
443150686,"Have you already trained? If not, you can ignore the error.",already trained ignore error,issue,negative,neutral,neutral,neutral,neutral,neutral
443142815,"it don't generate empty model ,but it generate error message
",generate empty model generate error message,issue,negative,negative,neutral,neutral,negative,negative
443137861,"Did you expect that it would find the file? Have you trained before? If not, then of course it cannot be found and it will create a blank model (and it will start training).",expect would find file trained course found create blank model start training,issue,negative,neutral,neutral,neutral,neutral,neutral
442778503,This is a Windows/Anaconda bug I'm looking at soon. In the meantime you can still use mtcnn if you remove the `-mp` flag,bug looking soon still use remove flag,issue,negative,neutral,neutral,neutral,neutral,neutral
442702535,"I am having a similiar problem with mtcnn. Have a 1080 ti.  dlib-cnn works, but mtcnn gives this long error message:


2018-11-28 23:26:44.170261: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.188978: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.189442: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.190009: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.209144: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.209598: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
Extracting faces:   0%|          | 0/5681 [00:00<?, ?it/s]Initializing Face Alignment Network...
Initialized Face Alignment Network.
2018-11-28 23:26:44.231224: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.231952: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.232425: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.255365: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.256106: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2018-11-28 23:26:44.256571: E tensorflow/stream_executor/cuda/cuda_dnn.cc:373] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
Exception in thread Thread-5:
Traceback (most recent call last):
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
return fn(*args)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node pnet/conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 916, in _bootstrap_inner
self.run()
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 864, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 121, in detect_thread
faces, points = detect_face(current_image, **self.kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 548, in detect_face
out = pnet(img_y)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 500, in <lambda>
feed_dict={'pnet/input:0': img})
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
run_metadata_ptr)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _run
feed_dict_tensor, options, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1328, in _do_run
run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1348, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'pnet/conv1/Conv2D', defined at:
File ""<string>"", line 1, in <module>
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 105, in spawn_main
exitcode = _main(fd)
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 118, in _main
return self._bootstrap()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 258, in _bootstrap
self.run()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 93, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 100, in detect_faces
super().detect_faces(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\_base.py"", line 80, in detect_faces
self.initialize(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 68, in initialize
pnet, rnet, onet = create_mtcnn(sess, self.model_path)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 487, in create_mtcnn
pnet = PNet({'data': data})
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 259, in __init__
self.setup()
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 418, in setup
.conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 236, in layer_decorated
layer_output = operator(self, layer_input, *args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 351, in conv
output = convolve(inp, kernel)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 345, in <lambda>
convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding) # noqa
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 1044, in conv2d
data_format=data_format, dilations=dilations, name=name)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
return func(*args, **kwargs)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 3274, in create_op
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 1770, in __init__
self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]


Exception in thread Thread-1:
Traceback (most recent call last):
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
return fn(*args)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node pnet/conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 916, in _bootstrap_inner
self.run()
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 864, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 121, in detect_thread
faces, points = detect_face(current_image, **self.kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 548, in detect_face
out = pnet(img_y)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 500, in <lambda>
feed_dict={'pnet/input:0': img})
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
run_metadata_ptr)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _run
feed_dict_tensor, options, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1328, in _do_run
run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1348, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'pnet/conv1/Conv2D', defined at:
File ""<string>"", line 1, in <module>
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 105, in spawn_main
exitcode = _main(fd)
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 118, in _main
return self._bootstrap()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 258, in _bootstrap
self.run()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 93, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 100, in detect_faces
super().detect_faces(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\_base.py"", line 80, in detect_faces
self.initialize(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 68, in initialize
pnet, rnet, onet = create_mtcnn(sess, self.model_path)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 487, in create_mtcnn
pnet = PNet({'data': data})
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 259, in __init__
self.setup()
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 418, in setup
.conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 236, in layer_decorated
layer_output = operator(self, layer_input, *args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 351, in conv
output = convolve(inp, kernel)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 345, in <lambda>
convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding) # noqa
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 1044, in conv2d
data_format=data_format, dilations=dilations, name=name)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
return func(*args, **kwargs)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 3274, in create_op
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 1770, in __init__
self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Exception in thread Thread-4:
Traceback (most recent call last):
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
return fn(*args)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node pnet/conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 916, in _bootstrap_inner
self.run()
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 864, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 121, in detect_thread
faces, points = detect_face(current_image, **self.kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 548, in detect_face
out = pnet(img_y)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 500, in <lambda>
feed_dict={'pnet/input:0': img})
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 929, in run
run_metadata_ptr)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1152, in _run
feed_dict_tensor, options, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1328, in _do_run
run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1348, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'pnet/conv1/Conv2D', defined at:
File ""<string>"", line 1, in <module>
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 105, in spawn_main
exitcode = _main(fd)
File ""c:\users\sean\anaconda3\Lib\multiprocessing\spawn.py"", line 118, in _main
return self._bootstrap()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 258, in _bootstrap
self.run()
File ""c:\users\sean\anaconda3\Lib\multiprocessing\process.py"", line 93, in run
self._target(*self._args, **self._kwargs)

File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 100, in detect_faces
super().detect_faces(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\_base.py"", line 80, in detect_faces
self.initialize(*args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 68, in initialize
pnet, rnet, onet = create_mtcnn(sess, self.model_path)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 487, in create_mtcnn
pnet = PNet({'data': data})
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 259, in __init__
self.setup()
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 418, in setup
.conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 236, in layer_decorated
layer_output = operator(self, layer_input, *args, **kwargs)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 351, in conv
output = convolve(inp, kernel)
File ""H:\faceswap\plugins\extract\detect\mtcnn.py"", line 345, in <lambda>
convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding) # noqa
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 1044, in conv2d
data_format=data_format, dilations=dilations, name=name)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\util\deprecation.py"", line 488, in new_func
return func(*args, **kwargs)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 3274, in create_op
op_def=op_def)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\framework\ops.py"", line 1770, in __init__
self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node pnet/conv1/Conv2D (defined at H:\faceswap\plugins\extract\detect\mtcnn.py:345)  = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]


Exception in thread Thread-2:
Traceback (most recent call last):
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1334, in _do_call
return fn(*args)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1319, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File ""C:\Users\Sean\Envs\fakes\lib\site-packages\tensorflow\python\client\session.py"", line 1407, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node pnet/conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](pnet/conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, pnet/conv1/weights/read)]]
[[{{node pnet/prob1/_107}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_107_pnet/prob1"", tensor_type=DT_FLOAT, _device=""/job:localhost/rException in thread Thread-1:
Traceback (most recent call last):
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 916, in _bootstrap_inner
self.run()
File ""c:\users\sean\anaconda3\Lib\threading.py"", line 864, in run
self._target(*self._args, **self._kwargs)
File ""H:\faceswap\scripts\extract.py"", line 76, in load_images
load_queue.put((filename, image))
File ""<string>"", line 2, in put
File ""c:\users\sean\anaconda3\Lib\multiprocessing\managers.py"", line 756, in _callmethod
conn.send((self._id, methodname, args, kwds))
File ""c:\users\sean\anaconda3\Lib\multiprocessing\connection.py"", line 206, in send
self._send_bytes(_ForkingPickler.dumps(obj))
File ""c:\users\sean\anaconda3\Lib\multiprocessing\connection.py"", line 290, in _send_bytes
nwritten, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] The pipe has been ended

Process exited.

",problem ti work long error message could create handle could create handle could create handle could create handle could create handle could create handle face alignment network face alignment network could create handle could create handle could create handle could create handle could create handle could create handle exception thread recent call last file line return file line file line get convolution algorithm probably initialize try looking see warning log message printed node valid node handling exception another exception recent call last file line file line run file line file line file line lambda file line run file line file line file line raise type message get convolution algorithm probably initialize try looking see warning log message printed node defined valid node defined file string line module file line file line return file line file line run file line super file line file line initialize sess file line data file line file line setup file line operator self file line output convolve kernel file line lambda convolve lambda file line file line file line return file line file line see get convolution algorithm probably initialize try looking see warning log message printed node defined valid node exception thread recent call last file line return file line file line get convolution algorithm probably initialize try looking see warning log message printed node valid node handling exception another exception recent call last file line file line run file line file line file line lambda file line run file line file line file line raise type message get convolution algorithm probably initialize try looking see warning log message printed node defined valid node defined file string line module file line file line return file line file line run file line super file line file line initialize sess file line data file line file line setup file line operator self file line output convolve kernel file line lambda convolve lambda file line file line file line return file line file line see get convolution algorithm probably initialize try looking see warning log message printed node defined valid node exception thread recent call last file line return file line file line get convolution algorithm probably initialize try looking see warning log message printed node valid node handling exception another exception recent call last file line file line run file line file line file line lambda file line run file line file line file line raise type message get convolution algorithm probably initialize try looking see warning log message printed node defined valid node defined file string line module file line file line return file line file line run file line super file line file line initialize sess file line data file line file line setup file line operator self file line output convolve kernel file line lambda convolve lambda file line file line file line return file line file line see get convolution algorithm probably initialize try looking see warning log message printed node defined valid node exception thread recent call last file line return file line file line get convolution algorithm probably initialize try looking see warning log message printed node valid node thread recent call last file line file line run file line image file string line put file line file line send file line err true pipe ended process,issue,positive,positive,neutral,neutral,positive,positive
439650268,"I had the same issue when training with OriginalHighRes rc4, changing line 72 of Model.py to disable K.Function fixed it:  ""USE_K_FUNCTION = False.""  If that doesn't fix it for you, switch to the Plugin_OriginalHighResRC4fix branch.  No K.Function = no red or white ""screen of death.""      ",issue training line disable fixed false fix switch branch red white screen death,issue,negative,negative,neutral,neutral,negative,negative
439629887,"after running multiple training sessions on a 1080ti for 192x @ bs 4, bs 8, bs 16, it all shoots up to loss levels of around .4 and the training preview squares become all either red or white.",running multiple training session ti loss around training preview become either red white,issue,negative,neutral,neutral,neutral,neutral,neutral
439602437,"Is it possible to run faceswap with Intel HD Graphics card **or** Intel core i3 CPU @ 2.13GHz?
Can I use either a GPU or a CPU for face swap or is there any barriers???
![image_98](https://user-images.githubusercontent.com/44738527/48659414-a16b3b80-ea76-11e8-99a2-0d9eb3afea60.png)
![image_99](https://user-images.githubusercontent.com/44738527/48659415-a3cd9580-ea76-11e8-982c-c5e12ae162f6.png)
",possible run graphic card core use either face swap,issue,negative,neutral,neutral,neutral,neutral,neutral
439547399,"My mistake. With all these extraction tests, with dlib and mtcnn, I had a screwed up alignments file. 

I understood when I saw that the other converted images had strange landmarks.

I re-extracted with mtcnn and it all fell into place.",mistake extraction screwed file understood saw converted strange fell place,issue,negative,negative,neutral,neutral,negative,negative
439442086,I'd you haven't already you should try the manual tool for fixing screwy alignments or detecting on faces that weren't found,already try manual tool fixing screwy found,issue,negative,neutral,neutral,neutral,neutral,neutral
439378307,"It works with rotation at 90, but the overall result is largely worse than mtcnn (and slower too).

dlib-cnn detects one or two more faces with tricky angles than mtcnn, but it screws up the landmarks a lot more than mtcnn. The dataset I sent you is a testament to that mess.

Those ""tricky angles"" actually take a lot more training time to be swapped, anyway.

So, I'll stick with mtcnn for future sets and drop dlib, unless there's a face I absolutely want to swap that mtcnn does not detect;",work rotation overall result largely worse one two tricky lot sent testament mess tricky actually take lot training time anyway stick future drop unless face absolutely want swap detect,issue,negative,negative,neutral,neutral,negative,negative
439237781,"God I hate dlib. It ran out of vram for no discernible reason other than it likes to be completely inconsistent.

I've adjusted the resizing down by 128px and it seems to run through ok now as long as you keep rotation at increments of 90 degrees (i.e. `-r on`). 

However there is still a bug.... When an image is rotated by a non-standard amount, extra padding has to be added to the image to fit it into a rectangular frame, which pushes the dimensions outside of the set threshold. 

I'm going to have to put this on the backburner as I'm not sure of the best way to squash this bug, as the frame size is set per image, not per rotation, so it effects the detector scale, and therefore the correct placement of the landmarks on the face. 

Bizarrely, and just to add further to the dlib misery, it seems to be failing on a frame with dimensions (1920, 1319) which is within the threshold, and despite having already successfully detected frames of dimensions (2206, 2381) and (2381, 2206).

Also, as this is a cuda failure, it is not easy to capture the error and handle appropriately. 

tldr; checkout latest commit and keep rotation set at `-r 90`
",god hate ran discernible reason completely inconsistent run long keep rotation however still bug image rotated amount extra padding added image fit rectangular frame outside set threshold going put sure best way squash bug frame size set per image per rotation effect detector scale therefore correct placement face bizarrely add misery failing frame within threshold despite already successfully also failure easy capture error handle appropriately latest commit keep rotation set,issue,negative,positive,positive,positive,positive,positive
439150411,"Almost! It goes further but still stops dead at 92%:
```

(cface) C:\Users\Kirin\faceswap>python c:\users\kirin\faceswap\faceswap.py extra
ct -i H:\Fakes\pldg-sue -o H:\Fakes\pldg-sue\aligned.dlib-cnn -A fan -D dlib-cnn
 -r 15 -mp -v
Output Directory: H:\Fakes\pldg-sue\aligned.dlib-cnn
Input Directory: H:\Fakes\pldg-sue
Using json serializer for alignments
Alignments filepath: H:\Fakes\pldg-sue\alignments.json
Loading Detect from Dlib_Cnn plugin...
Loading Align from Fan plugin...
GeForce GTX 1060 6GB - 5915MB free of 6144MB
Starting, this may take a while...
Initializing Face Alignment Network...
Using device GeForce GTX 1060 6GB with 5915MB free of 6144MB
Reserving 2240MB for face alignments
Initializing Face Alignment Network model...
2018-11-15 19:38:10.829926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
411] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.71GiB
2018-11-15 19:38:10.838927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
490] Adding visible gpu devices: 0
2018-11-15 19:38:11.668974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
71] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-15 19:38:11.673974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
77]      0
2018-11-15 19:38:11.676974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
90] 0:   N
2018-11-15 19:38:11.680975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 wit
h 2240 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bu
s id: 0000:01:00.0, compute capability: 6.1)
Initialized Face Alignment Network.
Initializing Dlib-CNN Detector...
DLib is compiled to use CUDA
Using device GeForce GTX 1060 6GB with 3344MB free of 6144MB
Processing in batches of 4
Initialized Dlib-CNN Detector...
Extracting faces:   0%|                                | 0/126 [00:00<?, ?it/s]B
atch has inconsistently sized images. Processing one image at a time
found face(s) by rotating image 30 degrees
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:   4%|?                       | 5/126 [01:26<59:04, 29.29s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:   9%|██                     | 11/126 [01:28<13:54,  7.26s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  10%|██?                    | 13/126 [03:55<51:15, 27.21s/it]W
arning: No faces were detected in image: Pdlg0414.jpg
Extracting faces:  12%|██?                    | 15/126 [04:03<37:18, 20.17s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  16%|███?                   | 20/126 [04:19<16:58,  9.61s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  25%|█████?                 | 32/126 [05:25<08:43,  5.57s/it]W
arning: No faces were detected in image: Pdlg0508.jpg
Extracting faces:  26%|██████                 | 33/126 [05:40<12:50,  8.29s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  27%|██████?                | 34/126 [05:46<11:46,  7.68s/it]W
arning: No faces were detected in image: Pdlg0510.jpg
found face(s) by rotating image 135 degrees
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:  31%|███████                | 39/126 [06:08<08:38,  5.96s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  41%|█████████?             | 52/126 [07:29<09:57,  8.08s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  43%|█████████?             | 54/126 [07:46<09:56,  8.28s/it]W
arning: No faces were detected in image: Pdlg0606.jpg
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:  48%|██████████?            | 60/126 [08:01<05:29,  4.99s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  51%|███████████?           | 64/126 [08:18<04:53,  4.74s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  54%|████████████?          | 68/126 [08:32<03:56,  4.08s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  56%|████████████?          | 70/126 [08:59<07:46,  8.33s/it]W
arning: No faces were detected in image: Pdlg0621.jpg
Warning: No faces were detected in image: Pdlg0622.jpg
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:  60%|█████████████?         | 76/126 [09:13<04:08,  4.98s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  63%|███████████████        | 80/126 [09:32<03:55,  5.12s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  67%|███████████████?       | 84/126 [09:52<03:37,  5.17s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  70%|████████████████       | 88/126 [10:09<02:55,  4.62s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  73%|████████████████?      | 92/126 [10:29<02:50,  5.03s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  76%|██████████████████     | 96/126 [10:48<02:34,  5.16s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  79%|█████████████████?    | 100/126 [11:05<02:00,  4.64s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  83%|██████████████████?   | 104/126 [11:25<01:50,  5.02s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  86%|██████████████████?   | 108/126 [11:42<01:25,  4.74s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  89%|████████████████████  | 112/126 [12:02<01:10,  5.07s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  92%|████████████████████? | 116/126 [12:21<00:51,  5.15s/it]

(cface) C:\Users\Kirin\faceswap>
```",almost go still dead python extra fan output directory input directory loading detect loading align fan free starting may take face alignment network device free face face alignment network model found device name major minor visible device interconnect strength edge matrix device wit memory physical device name bu id compute capability face alignment network detector use device free detector inconsistently sized one image time found face rotating image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time image inconsistently sized one image time inconsistently sized one image time image inconsistently sized one image time image found face rotating image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time image warning image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time,issue,positive,positive,positive,positive,positive,positive
439054709,"Still no dice. It actually starts, contrary to before your squashing, but stops at the 68th image for whatever reason. Even though it says that it's processing 1 image at a time.

And it still has a different behavior if verbose or not. 

Without verbose, it actually says why it crashed:

```
(cface) C:\Users\Kirin\face>python c:\users\kirin\faceswap\faceswap.py extract -
i H:\Fakes\pldg-sue -o H:\Fakes\pldg-sue\aligned.dlib-cnn -A fan -D dlib-cnn -r
15 -mp
Output Directory: H:\Fakes\pldg-sue\aligned.dlib-cnn
Input Directory: H:\Fakes\pldg-sue
Loading Detect from Dlib_Cnn plugin...
Loading Align from Fan plugin...
Starting, this may take a while...
Initializing Face Alignment Network...
Initialized Face Alignment Network.
Initializing Dlib-CNN Detector...
Initialized Dlib-CNN Detector...
Extracting faces:  54%|████████████?          | 68/126 [08:30<04:35,  4.74s/it]
Process SpawnProcess-3:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 258, in
_bootstrap
    self.run()
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 93, in r
un
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\plugins\extract\detect\dlib_cnn.py"", line 80, in
 detect_faces
    processed)
  File ""c:\users\kirin\faceswap\plugins\extract\detect\dlib_cnn.py"", line 165, i
n process_rotations
    batch_detected = self.detector(reprocess, 0)
RuntimeError: Images in list must all have the same dimensions.
```

With verbose, il crashes at the same point (68 image), but without message and it doesn't make sense: 

```
(cface) C:\Users\Kirin\face>python c:\users\kirin\faceswap\faceswap.py extract -
i H:\Fakes\pldg-sue -o H:\Fakes\pldg-sue\aligned.dlib-cnn -A fan -D dlib-cnn -r
15 -mp -v
Output Directory: H:\Fakes\pldg-sue\aligned.dlib-cnn
Input Directory: H:\Fakes\pldg-sue
Using json serializer for alignments
Alignments filepath: H:\Fakes\pldg-sue\alignments.json
Loading Detect from Dlib_Cnn plugin...
Loading Align from Fan plugin...
GeForce GTX 1060 6GB - 5915MB free of 6144MB
Starting, this may take a while...
Initializing Face Alignment Network...
Using device GeForce GTX 1060 6GB with 5915MB free of 6144MB
Reserving 2240MB for face alignments
Initializing Face Alignment Network model...
2018-11-15 14:14:38.455602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
411] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.71GiB
2018-11-15 14:14:38.464602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
490] Adding visible gpu devices: 0
2018-11-15 14:14:39.271648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
71] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-15 14:14:39.277649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
77]      0
2018-11-15 14:14:39.280649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
90] 0:   N
2018-11-15 14:14:39.283649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 wit
h 2240 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bu
s id: 0000:01:00.0, compute capability: 6.1)
Initialized Face Alignment Network.
Initializing Dlib-CNN Detector...
DLib is compiled to use CUDA
Using device GeForce GTX 1060 6GB with 3344MB free of 6144MB
Processing in batches of 4
Initialized Dlib-CNN Detector...
Extracting faces:   0%|                                | 0/126 [00:00<?, ?it/s]B
atch has inconsistently sized images. Processing one image at a time
found face(s) by rotating image 30 degrees
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:   4%|?                       | 5/126 [01:24<58:28, 29.00s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:   9%|██                     | 11/126 [01:25<19:15, 10.05s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  10%|██?                    | 13/126 [03:45<52:41, 27.98s/it]W
arning: No faces were detected in image: Pdlg0414.jpg
Extracting faces:  13%|██?                    | 16/126 [03:45<35:57, 19.61s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  16%|███?                   | 20/126 [04:09<19:04, 10.80s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  25%|█████?                 | 32/126 [05:18<09:09,  5.85s/it]W
arning: No faces were detected in image: Pdlg0508.jpg
Extracting faces:  26%|██████                 | 33/126 [05:32<13:04,  8.43s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  27%|██████?                | 34/126 [05:39<12:26,  8.12s/it]W
arning: No faces were detected in image: Pdlg0510.jpg
found face(s) by rotating image 135 degrees
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:  31%|███████                | 39/126 [06:01<08:56,  6.17s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  41%|█████████?             | 52/126 [07:22<09:54,  8.03s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  43%|█████████?             | 54/126 [07:39<09:52,  8.23s/it]W
arning: No faces were detected in image: Pdlg0606.jpg
Batch has inconsistently sized images. Processing one image at a time
Extracting faces:  48%|██████████?            | 60/126 [07:57<05:55,  5.39s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  51%|███████████?           | 64/126 [08:16<05:27,  5.27s/it]B
atch has inconsistently sized images. Processing one image at a time
Extracting faces:  54%|████████████?          | 68/126 [08:30<04:06,  4.25s/it]

(cface) C:\Users\Kirin\face>",still dice actually contrary th image whatever reason even though image time still different behavior verbose without verbose actually python extract fan output directory input directory loading detect loading align fan starting may take face alignment network face alignment network detector detector process recent call last file line file line un file line file line reprocess list must verbose point image without message make sense python extract fan output directory input directory loading detect loading align fan free starting may take face alignment network device free face face alignment network model found device name major minor visible device interconnect strength edge matrix device wit memory physical device name bu id compute capability face alignment network detector use device free detector inconsistently sized one image time found face rotating image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time image inconsistently sized one image time inconsistently sized one image time image inconsistently sized one image time image found face rotating image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time image batch inconsistently sized one image time inconsistently sized one image time inconsistently sized one image time,issue,positive,positive,neutral,neutral,positive,positive
438959052,"I finally got the time to test the fix, and it still crashes but in two different ways, depending if I add the verbose flag or not! (which makes it hard to diagnose what's wrong:

With the -v at the end:
```
(cface) C:\Users\Kirin\face>python c:\users\kirin\faceswap\faceswap.py extract -
i H:\Fakes\pldg-sue -o H:\Fakes\pldg-sue\aligned.dlib-cnn -A fan -D dlib-cnn -r
15 -mp -v
Output Directory: H:\Fakes\pldg-sue\aligned.dlib-cnn
Input Directory: H:\Fakes\pldg-sue
Using json serializer for alignments
Alignments filepath: H:\Fakes\pldg-sue\alignments.json
Loading Detect from Dlib_Cnn plugin...
Loading Align from Fan plugin...
GeForce GTX 1060 6GB - 5885MB free of 6144MB
Starting, this may take a while...
Initializing Face Alignment Network...
Using device GeForce GTX 1060 6GB with 5885MB free of 6144MB
Reserving 2240MB for face alignments
Initializing Face Alignment Network model...
2018-11-15 09:16:04.878004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
411] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.69GiB
2018-11-15 09:16:04.889004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
490] Adding visible gpu devices: 0
2018-11-15 09:16:06.975124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
71] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-15 09:16:06.994125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
77]      0
2018-11-15 09:16:06.999125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:9
90] 0:   N
2018-11-15 09:16:07.018126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 wit
h 2240 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bu
s id: 0000:01:00.0, compute capability: 6.1)
Initialized Face Alignment Network.
Initializing Dlib-CNN Detector...
DLib is compiled to use CUDA
Using device GeForce GTX 1060 6GB with 3314MB free of 6144MB
Processing in batches of 4
Initialized Dlib-CNN Detector...
Extracting faces:   0%|                                | 0/126 [00:00<?, ?it/s]B
atch has inconsistently sized images. Processing one image at a time
Process SpawnProcess-3:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 258, in
_bootstrap
    self.run()
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 93, in r
un
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\plugins\extract\detect\dlib_cnn.py"", line 80, in
 detect_faces
    processed)
  File ""c:\users\kirin\faceswap\plugins\extract\detect\dlib_cnn.py"", line 166, i
n process_rotations
    if self.verbose and any(item.any() for item in batch_detected):
  File ""c:\users\kirin\faceswap\plugins\extract\detect\dlib_cnn.py"", line 166, i
n <genexpr>
    if self.verbose and any(item.any() for item in batch_detected):
AttributeError: 'dlib.mmod_rectangles' object has no attribute 'any'
```

Without the verbose, it extracts rrrrrrrreally slowly (9 minutes for 68 images) and then just stops halfway without any message:

```
(cface) C:\Users\Kirin\face>python c:\users\kirin\faceswap\faceswap.py extract -
i H:\Fakes\pldg-sue -o H:\Fakes\pldg-sue\aligned.dlib-cnn -A fan -D dlib-cnn -r
15 -mp
Output Directory: H:\Fakes\pldg-sue\aligned.dlib-cnn
Input Directory: H:\Fakes\pldg-sue
Loading Detect from Dlib_Cnn plugin...
Loading Align from Fan plugin...
Starting, this may take a while...
Initializing Face Alignment Network...
Initialized Face Alignment Network.
Initializing Dlib-CNN Detector...
Initialized Dlib-CNN Detector...
Extracting faces:  54%|████████████?          | 68/126 [08:53<05:01,  5.19s/it]

(cface) C:\Users\Kirin\face>
```

mtcnn works like a charm.",finally got time test fix still two different way depending add verbose flag hard diagnose wrong end python extract fan output directory input directory loading detect loading align fan free starting may take face alignment network device free face face alignment network model found device name major minor visible device interconnect strength edge matrix device wit memory physical device name bu id compute capability face alignment network detector use device free detector inconsistently sized one image time process recent call last file line file line un file line file line item file line item object attribute without verbose slowly halfway without message python extract fan output directory input directory loading detect loading align fan starting may take face alignment network face alignment network detector detector work like charm,issue,positive,positive,neutral,neutral,positive,positive
438733504,This repro (and DeepFaceLab) were written for CUDA 9 and the GTX series 10 cards.  Nvidia apparently made some hardware changes in the RTX series that require changes in the current extract code.  But the error can't be fixed easily without a developer having an RTX series card to work with.   ,written series apparently made hardware series require current extract code error ca fixed easily without developer series card work,issue,negative,positive,positive,positive,positive,positive
438725028,"But this is work when use  GTX 1060 before , the error is flow when only after replace the display card. 

Howeven, after i update FS, it flow another error when extract:

**mtcnn**
2018-11-15 00:23:54.764227: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-11-15 00:23:55.344866: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties:
name: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.74
pciBusID: 0000:09:00.0
totalMemory: 8.00GiB freeMemory: 6.57GiB
2018-11-15 00:23:55.345506: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce RTX 2070, pci bus id: 0000:09:00.0, compute capability: 7.5)
Initializing MTCNN Detector...Process SpawnProcess-3:

Traceback (most recent call last):
File ""C:\Users\Mark\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 258, in _bootstrap
self.run()
File ""C:\Users\Mark\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 93, in run
self._target(*self._args, **self._kwargs)
File ""E:\Faceswap\faceswap-master(5)\plugins\extract\detect\mtcnn.py"", line 100, in detect_faces
super().detect_faces(*args, **kwargs)
File ""E:\Faceswap\faceswap-master(5)\plugins\extract\detect\_base.py"", line 81, in detect_faces
self.initialize(*args, **kwargs)
File ""E:\Faceswap\faceswap-master(5)\plugins\extract\detect\mtcnn.py"", line 73, in initialize
alloc = int(sess.run(tf.contrib.memory_stats.BytesLimit()) /
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\contrib\memory_stats\python\ops\memory_stats_ops.py"", line 36, in BytesLimit
return gen_memory_stats_ops.bytes_limit()
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\contrib\memory_stats\ops\gen_memory_stats_ops.py"", line 64, in bytes_limit
""BytesLimit"", name=name)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\ops.py"", line 3162, in create_op
compute_device=compute_device)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\ops.py"", line 3208, in _create_op_helper
set_shapes_for_outputs(op)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\ops.py"", line 2427, in set_shapes_for_outputs
return _set_shapes_for_outputs(op)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\ops.py"", line 2400, in _set_shapes_for_outputs
shapes = shape_func(op)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\ops.py"", line 2330, in call_with_requiring
return call_cpp_shape_fn(op, require_shape_fn=True)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shape_fn
require_shape_fn)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
input_tensors_as_shapes, status)
File ""E:\Faceswap\faceswap-master(5)\env\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'BytesLimit' in binary running on DESKTOP-HELDK0A. Make sure the Op and Kernel are registered in the binary running in this process.

Command : E:\Faceswap\faceswap-master(5)\env\Scripts\python.exe E:\Faceswap\faceswap-master(5)\faceswap.py extract -i E:\InputA -o E:\alignA -l 0.6 -v --serializer json -D mtcnn -A dlib -mtms 20 -mtth 0.6 0.7 0.7 -mtsc 0.709 -sz 256 -ae





",work use error flow replace display card update flow another error extract binary use found device name major minor device device name bus id compute capability detector process recent call last file line file line run file line super file line file line initialize file line return file line file line file line file line file line return file line file line return file line file line status file line type registered binary running make sure kernel registered binary running process command extract,issue,negative,positive,positive,positive,positive,positive
438693340,"g0147, FS = this repro.  Upgrade to the latest version, if you have not done so already, and try again.  PR = Pull Request: suggested code changes by a python coder who has an RTX card to troubleshoot the problem.  ",upgrade latest version done already try pull request code python coder card problem,issue,negative,positive,positive,positive,positive,positive
438671221,"> Looking at your cli it looks like you are running an older version of FS, so you can update and see if that fixes it.
> 
> Unfortunately I do not have a next gen Nvidia card to test on, so if there are still issues, most likely someone else will have to raise a PR to fix this.

what is FS? Faceswap?",looking like running older version update see unfortunately next gen card test still likely someone else raise fix,issue,negative,positive,neutral,neutral,positive,positive
438329777,"You either don't have a GPU or you are using the CPU version of tensorflow.

Either way FAN does not currently support CPU, so either use dlib aligner or install tensorflow-gpu.",either version either way fan currently support either use aligner install,issue,positive,neutral,neutral,neutral,neutral,neutral
438054523,Upgrade keras. Also pip install --upgrade - r requirements.txt,upgrade also pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
437869633,"Now in Master

On my (ever growing) todo list, I want to add the option to merge alignments.

The options for skip-existing has been changed now, and a new option for skip-faces has been added. A combination of these may get the results you're looking for.

Incidentally, you should join the discord group, as your input would be welcome there:
https://discord.gg/u8wEDa

You'll also be able to see what we have on the horizon, and maybe help sway priorities.
",master ever growing list want add option merge new option added combination may get looking incidentally join discord group input would welcome also able see horizon maybe help sway,issue,positive,positive,positive,positive,positive,positive
437867508,"I will test that asap.

By the way, I wish there was a way to mix (or concatenate ?) results from different extractors. 

dlib-cnn and mtcnn yield different results and sometimes one or the other is better for the same image for tricky angles. But as of now, the alignments.json can only be mixed and matched manually.

Maybe a switch like ""-D all"" which would try every extractor in succession (unloading the previous one before), regardless of if a previous one found a face.

Maybe it's not convenient for videos with thousands of frames, but it would be useful for people like me who are working with a few hundred (or even less) high quality photo sets.",test way wish way mix concatenate different yield different sometimes one better image tricky mixed manually maybe switch like would try every extractor succession previous one regardless previous one found face maybe convenient would useful people like working hundred even le high quality photo,issue,positive,positive,neutral,neutral,positive,positive
437862664,"Ok, I've implemented a fix.

The images are resized to fit into a specific frame, but their original dimensions are maintained which is not compatible with dlib batching.

If frames with different dimensions are now discovered within a batch, the images for that batch will be processed one at a time. You will lose the speed benefit of batching (for that specific batch) in this instance, but it will process.

Fix in staging. I have another bug to squash and then will push to master.

",fix fit specific frame original compatible different discovered within batch batch one time lose speed benefit specific batch instance process fix staging another bug squash push master,issue,positive,positive,positive,positive,positive,positive
437801295,"Yes, I have a batch of images of different sizes. 

And yes, from what I understood, it should standardize the size (by some padding or resize) before extracting.",yes batch different size yes understood standardize size padding resize,issue,positive,neutral,neutral,neutral,neutral,neutral
437706183,"Actually it should resize them. I'll take a look. You are using different sized images though, yes?",actually resize take look different sized though yes,issue,negative,neutral,neutral,neutral,neutral,neutral
437706112,"I assume you have different size images? Images have to be all the same size for dlib batching to work.

I can look to add an option to turn off batching for dlib-cnn. It will, of course, be slower.",assume different size size work look add option turn course,issue,negative,neutral,neutral,neutral,neutral,neutral
436225954,"This has been obsoleted by #522 

Use skip-existing to have the desired effect (skip existing now skips any frames in the alignments file, regardless of whether a face was found or not, so frames will not be re-extracted).",use desired effect skip file regardless whether face found,issue,negative,neutral,neutral,neutral,neutral,neutral
435686913,"No movement on this for a long time, and plugin structure has changed significantly, so closing. If anyone wants to adapt and PR this, please feel free.",movement long time structure significantly anyone adapt please feel free,issue,positive,positive,positive,positive,positive,positive
435224290,"ffmpeg problems are out of scope. Your best bet is to go to the Discord group where people will be able to help you.

https://discord.gg/FdEwxXd
",scope best bet go discord group people able help,issue,positive,positive,positive,positive,positive,positive
433717584,"FYI: I converted the model myself using tf 1.10. I'm guessing there must be a bug in tf1.8.

Thanks for the feedback.",converted model guessing must bug thanks feedback,issue,negative,positive,positive,positive,positive,positive
433717436,"Speed of extraction is pretty good. Better than before the addition of FAN actually. It initializes faster. When I pulled the commit (just before this issue), it downloaded a big file, so I guess a reference for FAN.

And this file was probably made for tf 1.8.0, because it took only a few seconds to initialize (but then it crashed later because of ""Optype not registered..""), contrary to tf 1.6.0 or tf 1.11.0.

Other versions than 1.8.0 of tf must be doing something with it the first time, so it takes longer and blows the 60 secs timeout.",speed extraction pretty good better addition fan actually faster commit issue big file guess reference fan file probably made took initialize later registered contrary must something first time longer,issue,positive,positive,positive,positive,positive,positive
433716388,"Ok, that's good to know. I'll look to bump the default time-out and investigate the initial delay.

How are your speeds?",good know look bump default investigate initial delay,issue,negative,positive,positive,positive,positive,positive
433705112,"It actually worked after setting event.wait to 300.  It started to extract after 3/4 minutes.

But then, what's odd is that the following attempts, it took under 10 seconds. Even after reboot. So it was just the first time that took forever, for some unknown reason. 

Is it compiling/converting/upgrading something the first time? And the next times, it doesn't need to? 

It's the only logical explanation I have.",actually worked setting extract odd following took even first time took forever unknown reason something first time next time need logical explanation,issue,negative,positive,neutral,neutral,positive,positive
433699703,"Ok, well that's annoying. We have it working on a GTX 1080 and a 1070Ti.

Just to eliminate the possibility that it is just taking a long time to initialize (I doubt it, mine inititalizes in under 10 seconds), could you edit the following line, and wait the 5 minutes to see if it times out again?

scripts/extract.py line 298 from:
```
        event.wait(60)
```
to:
```
        event.wait(300)
```

Either way I will look to get this fixed before it makes it's way to Master.

",well annoying working ti eliminate possibility taking long time initialize doubt mine could edit following line wait see time line either way look get fixed way master,issue,negative,negative,negative,negative,negative,negative
433698455,"I only have a single GPU, a GTX 1060 6Gb. 

It doesn't work, it times out during initialization of FAN:

With tensorflow-gpu==1.11.0:

```
(cface) C:\Users\Kirin\cface\Scripts>python c:\users\kirin\faceswap\faceswap.py
extract -i H:\Fakes\Tessa -o H:\Fakes\Tessa\aligned.mtcnn -A fan -D mtcnn -r on
-mtms 100 -mp -v
Output Directory: H:\Fakes\Tessa\aligned.mtcnn
Input Directory: H:\Fakes\Tessa
Using json serializer
Alignments filepath: H:\Fakes\Tessa\alignments.json
Loading Detect from Mtcnn plugin...
Loading Align from Fan plugin...
GeForce GTX 1060 6GB - 4718MB free of 6144MB
Starting, this may take a while...
Initializing Face Alignment Network...
Using device GeForce GTX 1060 6GB with 4718MB free of 6144MB
Reserving 2240MB for face alignments
Initializing Face Alignment Network model...
2018-10-28 12:47:54.016560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
411] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.55GiB
2018-10-28 12:47:54.029561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
490] Adding visible gpu devices: 0
Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 81, in execute_script
    process.process()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 47, in process
    self.run_extraction(save_thread)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 108, in run_extraction

    self.plugins.launch_aligner()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 300, in launch_aligner

    raise ValueError(""Error inititalizing Aligner"")
ValueError: Error inititalizing Aligner
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 94, in save_faces
    item = save_queue.get()
  File ""<string>"", line 2, in get
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 73, in load_images
    load_queue.put((filename, image))
  File ""<string>"", line 2, in put
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
```",single work time fan python extract fan output directory input directory loading detect loading align fan free starting may take face alignment network device free face face alignment network model found device name major minor visible recent call last file line module file line file line process file line file line raise error aligner error aligner exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line item file string line get file line kind result file line file line raise exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line image file string line put file line kind result file line file line raise,issue,positive,positive,positive,positive,positive,positive
433690865,"Ok, we went through these exact issues in testing. You are correct that the first issue is a tensorflow version issue. The FAN model is saved into a protocol buffer, so taking it out will be a bit of a pain, I'll see if I can but otherwise I'll look to update TF requirements to >= 1.10

The second issue we found was because FAN is timing out during initialization (I'm assuming you had to wait 60 seconds before the error?). In our test instance this was because of the machine having multiple GPUs. Is this the case for you? Unfortunately I only have a single GPU so putting a fix in for this is tricky, but I'll see what we can do. In the interim could you please run again with tf1.11 and the -v flag so I can see the TF initialization messages.

Assuming you do have multiple GPUs, if you disable all GPUs except for the one you want to use, it should work.",went exact testing correct first issue version issue fan model saved protocol buffer taking bit pain see otherwise look update second issue found fan timing assuming wait error test instance machine multiple case unfortunately single fix tricky see interim could please run flag see assuming multiple disable except one want use work,issue,negative,positive,neutral,neutral,positive,positive
433683419,"Doesn't work it seems.

I'm not sure it's related, but the error changes according to the tensorflow-gpu version. I downgraded it from 1.11.0 to 1.8.0 and 1.6.0 and I obtain different errors.

With tensorflow-gpu-1.8.0, it seems to initialize the FAN, but crashes with something about ""Op type not registered 'BytesLimit'"" when initializing the detector.

With tensorflow-gpu-1.6.0, or the latest (1.11.0) it crashes earlier, as above, at ""Initializing Face Alignment Network"".

tensorflow-gpu==1.8.0

```
(faceenv) C:\Users\Kirin>python c:\users\kirin\faceswap\faceswap.py extract -i H
:\Fakes\Tessa -o H:\Fakes\Tessa\aligned.mtcnn -A fan -D mtcnn -r on -mtms 100 -m
p
Output Directory: H:\Fakes\Tessa\aligned.mtcnn
Input Directory: H:\Fakes\Tessa
Using json serializer
Alignments filepath: H:\Fakes\Tessa\alignments.json
Loading Detect from Mtcnn plugin...
Loading Align from Fan plugin...
Starting, this may take a while...
Initializing Face Alignment Network...
Initialized Face Alignment Network.
Initializing MTCNN Detector...
ERROR: Op type not registered 'BytesLimit' in binary running on UTENA. Make sure
 the Op and Kernel are registered in the binary running in this process. while b
uilding NodeDef 'BytesLimit'
Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 81, in execute_script
    process.process()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 47, in process
    self.run_extraction(save_thread)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 109, in run_extraction

    self.plugins.launch_detector()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 339, in launch_detecto
r
    raise ValueError(""Error inititalizing Detector"")
ValueError: Error inititalizing Detector
Process SpawnProcess-2:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 94, in save_faces
    item = save_queue.get()
  File ""<string>"", line 2, in get
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
BrokenPipeError: [WinError 109] Le canal de communication a été fermé
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 73, in load_images
    load_queue.put((filename, image))
  File ""<string>"", line 2, in put
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError


During handling of the above exception, another exception occurred:


Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\plugins\extract\align\fan.py"", line 62, in align

    item = self.queues[""in""].get()
  File ""<string>"", line 2, in get
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 258, in
_bootstrap
    self.run()
  File ""c:\program files\python36\Lib\multiprocessing\process.py"", line 93, in r
un
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\plugins\extract\align\fan.py"", line 73, in align

    item[""exception""] = True
UnboundLocalError: local variable 'item' referenced before assignment
```

With tensorflow-gpu==1.11.0 or 1.6.0:

```
(cface) C:\>python c:\users\kirin\faceswap\faceswap.py extract -i H:\Fakes\Tessa
 -o H:\Fakes\Tessa\aligned.mtcnn -A fan -D mtcnn -r on -mtms 100 -mp
Output Directory: H:\Fakes\Tessa\aligned.mtcnn
Input Directory: H:\Fakes\Tessa
Using json serializer
Alignments filepath: H:\Fakes\Tessa\alignments.json
Loading Detect from Mtcnn plugin...
Loading Align from Fan plugin...
Starting, this may take a while...
Initializing Face Alignment Network...
Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 81, in execute_script
    process.process()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 47, in process
    self.run_extraction(save_thread)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 108, in run_extraction

    self.plugins.launch_aligner()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 300, in launch_aligner

    raise ValueError(""Error inititalizing Aligner"")
ValueError: Error inititalizing Aligner
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 94, in save_faces
    item = save_queue.get()
  File ""<string>"", line 2, in get
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 73, in load_images
    load_queue.put((filename, image))
  File ""<string>"", line 2, in put
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
```",work sure related error according version obtain different initialize fan something type registered detector latest face alignment network python extract fan output directory input directory loading detect loading align fan starting may take face alignment network face alignment network detector error type registered binary running make sure kernel registered binary running process recent call last file line module file line file line process file line file line raise error detector error detector process recent call last file line err true exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line item file string line get file line kind result file line file line raise canal de communication exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line image file string line put file line kind result file line file line raise handling exception another exception recent call last file line align item file string line get file line kind result file line file line raise handling exception another exception recent call last file line file line un file line align item exception true local variable assignment python extract fan output directory input directory loading detect loading align fan starting may take face alignment network recent call last file line module file line file line process file line file line raise error aligner error aligner exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line item file string line get file line kind result file line file line raise exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line image file string line put file line kind result file line file line raise,issue,positive,positive,positive,positive,positive,positive
433662174,"Ok, I've pushed a commit which *should* fix this as well as a couple of other minor bugfixes.",commit fix well couple minor,issue,positive,negative,neutral,neutral,negative,negative
433636543,"No, you can still use -r on.

It's called Windows being a massive pain in the ass with multiprocessing.

Will investigate asap.",still use massive pain as investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
433620649,"Nope. I created a brand new virtualenv and this is the result:

```
(newface) C:\Users\Kirin\newface\Scripts>python c:\users\kirin\faceswap\faceswap
.py extract -i H:\Fakes\Tessa -o H:\Fakes\Tessa\aligned.mtcnn -A fan -D mtcnn -r
 15 -mtms 100 -mp
Output Directory: H:\Fakes\Tessa\aligned.mtcnn
Input Directory: H:\Fakes\Tessa
Using json serializer
Alignments filepath: H:\Fakes\Tessa\alignments.json
Loading Detect from Mtcnn plugin...
Loading Align from Fan plugin...
Starting, this may take a while...
Initializing Face Alignment Network...
Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 81, in execute_script
    process.process()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 48, in process
    self.run_extraction(save_thread)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 109, in run_extraction

    self.plugins.launch_aligner()
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 302, in launch_aligner

    raise ValueError(""Error inititalizing Aligner"")
ValueError: Error inititalizing Aligner
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 74, in load_images
    load_queue.put((filename, image))
  File ""<string>"", line 2, in put
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 312,
in _recv_bytes
    nread, err = ov.GetOverlappedResult(True)
BrokenPipeError: [WinError 109] Le canal de communication a été fermé

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\program files\python36\Lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""c:\program files\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 95, in save_faces
    item = save_queue.get()
  File ""<string>"", line 2, in get
  File ""c:\program files\python36\Lib\multiprocessing\managers.py"", line 757, in
 _callmethod
    kind, result = conn.recv()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 250,
in recv
    buf = self._recv_bytes()
  File ""c:\program files\python36\Lib\multiprocessing\connection.py"", line 321,
in _recv_bytes
    raise EOFError
EOFError
```",nope brand new result python extract fan output directory input directory loading detect loading align fan starting may take face alignment network recent call last file line module file line file line process file line file line raise error aligner error aligner exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line image file string line put file line kind result file line file line raise exception thread recent call last file line err true canal de communication handling exception another exception recent call last file line er file line run file line item file string line get file line kind result file line file line raise,issue,positive,positive,positive,positive,positive,positive
433620256,"Ah. Maybe. It looks likes this parameter changed.

I'll test.",ah maybe parameter test,issue,negative,neutral,neutral,neutral,neutral,neutral
433619856,"Hi Kirin-kun,
I think it's the parameter  ""r "", it only works with degree specification and not with on or off. So -R 15, that's 15 degrees, you want multiple twists, then -R 1, 5, 15, 30, 45...
Maybe you should study the help, ""Python faceswap.py extract -H"", should help also works with train, convert ....
",hi think parameter work degree specification want multiple maybe study help python extract help also work train convert,issue,positive,neutral,neutral,neutral,neutral,neutral
433372105,"```
pip install -r requirements.txt
```
Make sure to install all the requirements.",pip install make sure install,issue,negative,positive,positive,positive,positive,positive
433371728,"@torzdf HI there can you help please! i am running the extract python command on CPU (I dont have GPU). And am receiving the following message:
![capture](https://user-images.githubusercontent.com/33531280/47562608-f9e76700-d916-11e8-8d7c-2ea206315e32.PNG)





",hi help please running extract python command dont following message capture,issue,positive,neutral,neutral,neutral,neutral,neutral
433090213,"This should be do-able now in the extract_mp branch (I will look to merge to staging soon).

The -s and (new) -sf options no longer look at the output folder, but instead look at the alignments file. If you specify a different output folder on your second run, you should be good to go.",branch look merge staging soon new longer look output folder instead look file specify different output folder second run good go,issue,negative,positive,positive,positive,positive,positive
432957417,"I've tested it of course, but you probably want someone else to confirm it.
I'd also change the command to prevent jupyter notebook from starting automatically when the container starts, since jupyter isn't necessary. It's rather annoying to be honest. It requires a second terminal in order to run bash commands and you can't shut down jupyter either, because it is the main process that keeps the container alive. In that case it wouldn't be necessary to forward the container ports either.

If were to be approved, I could help clean up the docker commands.
It might also be useful to include ffmpeg in the docker image.",tested course probably want someone else confirm also change command prevent notebook starting automatically container since necessary rather annoying honest second terminal order run bash ca shut either main process container alive case would necessary forward container either could help clean docker might also useful include docker image,issue,positive,positive,neutral,neutral,positive,positive
432362497,"I don't use docker. Can someone who does please confirm this PR.

Thanks",use docker someone please confirm thanks,issue,positive,positive,positive,positive,positive,positive
432234609,"@kilroythethird  I'm guessing you're using CPU as MTCNN isn't built with Keras? The optimizations are purely GPU based (except, maybe dlib-hog, but I didn't benchmark that). You could probably force better cpu utilization by ammending `plugins/extract/detect/mtcnn.py` `line 78` (`alloc = 2048`) to something sensible for your system.

I'd be interested to know if it makes a difference, as I may go in and make it more dynamic.

I'll go check blur threshold and push a commit",guessing built purely based except maybe could probably force better utilization line something sensible system interested know difference may go make dynamic go check blur threshold push commit,issue,positive,positive,positive,positive,positive,positive
432194761,"There seem to be a bug with -bt

> Extracting faces:   0%|                                                                                                                                                                                               | 0/135 [00:00<?, ?it/s]
> Traceback (most recent call last):
>   File ""/media/data/home/nope/workspace/faceswap/faceswap.py"", line 36, in <module>
>     ARGUMENTS.func(ARGUMENTS)
>   File ""/media/data/home/nope/workspace/faceswap/lib/cli.py"", line 81, in execute_script
>     process.process()
>   File ""/media/data/home/nope/workspace/faceswap/scripts/extract.py"", line 48, in process
>     self.run_extraction(save_thread)
>   File ""/media/data/home/nope/workspace/faceswap/scripts/extract.py"", line 128, in run_extraction
>     self.post_process.do_actions(faces)
>   File ""/media/data/home/nope/workspace/faceswap/scripts/fsmedia.py"", line 274, in do_actions
>     action.process(output_item)
>   File ""/media/data/home/nope/workspace/faceswap/scripts/fsmedia.py"", line 310, in process
>     face.landmarksXY(),
> TypeError: 'list' object is not callable

Otherwise looks good, but using MTCNN and dlib as aligner i get ~ 0.2 it/s less than with the current version (Can't use FAN because i am using an AMD card and plaidml.keras).
I'll see if i can write my own aligner supporting Keras directly, but i understand that AMD uses are not official supported by this project.",seem bug recent call last file line module file line file line process file line file line file line process object callable otherwise good aligner get le current version ca use fan card see write aligner supporting directly understand official project,issue,positive,positive,positive,positive,positive,positive
429656187,"I'm using 250 frames extracted from a very short video for A, with subject A looking only straight forward and down, to keep things simple for a first test.

I'm using 1500 frames extracted from a longer video for B (5000 original frames, of which I removed 3500 that were not matching orientation or expressions of the 250 in video B).

Each and every single of the 250 aligned crops for input A is converting well in the previews, but not in the merged result.

[Links Removed]

NOTE: I think it's an issue with FakeApp 1.1. Since my first post above, I tried using the open-sourced OpenFaceSwap, and results are almost as good as the previews, very satisfied result for a first (now second) test :)))",extracted short video subject looking straight forward keep simple first test extracted longer video original removed matching orientation video every single input converting well result link removed note think issue since first post tried almost good satisfied result first second test,issue,positive,positive,positive,positive,positive,positive
429630485,Well your input data is pretty crappy. That’s probably what’s wrong. There’s a lot of noise and it’s blurry.,well input data pretty probably wrong lot noise blurry,issue,negative,negative,negative,negative,negative,negative
429627898,"Did you find a solution to this problem with FakeApp?

I'm having the same issue, previews during training look great with loss less than a 0.01, but the merged/converted pics look like a monster. 

[Links Removed]
",find solution problem issue training look great loss le look like monster link removed,issue,positive,positive,positive,positive,positive,positive
428907333,"It isn't... Aligner shouldn't be the bottleneck though, Face Detection takes longer than alignment (assuming you're running on GPU).

Either way, Extractor is currently being reworked to offer speed increases (depending on GPU) and better parallelization, so I recommend holding tight for a week or two and keeping an eye on the staging branch. I may re-implement the old aligner as an option too.",aligner bottleneck though face detection longer alignment assuming running either way extractor currently reworked offer speed depending better parallelization recommend holding tight week two keeping eye staging branch may old aligner option,issue,positive,positive,positive,positive,positive,positive
427790103,"This is a cool feature, but I haven't had a chance to test it (and am unlikely to in the near future).

If anyone else is using this, please could you feedback with your results.",cool feature chance test unlikely near future anyone else please could feedback,issue,positive,negative,neutral,neutral,negative,negative
427789936,"Ok, I do understand the reasoning, I'm just not sure that I like a process that deletes files from the hard disk (I struggle to think of another application which does this). I think a better option would be to expand out from skip-existing, to have two options (skip-existing-faces and skip-existing-frames).

Either way, I would hold fire on this, as I am currently improving extract which may obsolete this. People can still checkout this PR, but I would rather not add a cli option only to remove it again shortly afterwards.",understand reasoning sure like process hard disk struggle think another application think better option would expand two either way would hold fire currently improving extract may obsolete people still would rather add option remove shortly afterwards,issue,positive,positive,positive,positive,positive,positive
427583776,"I agree that having this option would be very useful. Imagine you have 5000 images to extract, you launch the extractor and it crashes mid-way (e.g. I use a remote machine with timeout constraints). Now the only option is to relaunch the entire process from scratch; `--skip-existing` should prevent double-work , BUT this does not apply to images that had no faces/did not match the filter. As such, you may very well spend hours on re-checking empty images. Hope this makes the use case clearer, thanks to both!",agree option would useful imagine extract launch extractor use remote machine option relaunch entire process scratch prevent apply match filter may well spend empty hope use case clearer thanks,issue,positive,positive,neutral,neutral,positive,positive
427038087,I haven't done a through test of all calls to Keras but running a cursory test of functionality + training seems to be working well,done test running cursory test functionality training working well,issue,negative,neutral,neutral,neutral,neutral,neutral
426966476,"I guess it'd come in handy for some people that have a mountain of images to extract. This would delete the file whenever it's done (or only if it found a face). Maybe it isn't very useful, but it might be to some people.",guess come handy people mountain extract would delete file whenever done found face maybe useful might people,issue,negative,positive,positive,positive,positive,positive
426644379,"@Torzdf Thanks! I will check it out. I have problems to get anything else but the trainer to run right now.  Seems to be related to my python version, and how strings should be written in the code. ",thanks check get anything else trainer run right related python version written code,issue,negative,positive,positive,positive,positive,positive
426635328,"@Eleganze 

You can check latest staging branch out to see if this PR helps you:
https://github.com/deepfakes/faceswap/pull/516
",check latest staging branch see,issue,negative,positive,positive,positive,positive,positive
426545738,"> 
> 
>  FS has the ability to do manual alignments, but it crashes when I try to run it.

@gessyoo Do you have any further info on this? I would like it to not be crashing!

@Eleganze I'm currently working on Landmark smoothing which may go some way to sort your issue.",ability manual try run would like currently working landmark smoothing may go way sort issue,issue,positive,neutral,neutral,neutral,neutral,neutral
426476508,"I'm also training 192x192 now, 12,000 iterations and about 0.02638 loss. I've used DFL as well.  Have you tried model H128?  Here's one: https://youtu.be/Cs1SkB_8PEo.  FS has the ability to do manual alignments, but it crashes when I try to run it.   

",also training loss used well tried model one ability manual try run,issue,negative,neutral,neutral,neutral,neutral,neutral
426453557,"Running 192x192 with two cards now (processing on both) bs 64 and activated DSSIM loss. I will leave it running for a day, and see how the results are. After 32 minutes, I’m at 850 iterations and down to around 0,035.",running two loss leave running day see around,issue,negative,neutral,neutral,neutral,neutral,neutral
426451359,"They are configured as non sli. I think I read somewhere that SLI would not work. With two identical cards, training is all good. I have mainly done my testing with Deepfacelab, and the dfaker model. Trained one model 250000 iterations, and down to 0,007 loss. It’s mindblowing, and I can’t tell the difference between the original and the generated image. The limit is actually in the  landmarks. A tiny bit off, and the frame will never convert very well. So it would be great to have a tool where I could manually edit each and every point. ",non think read somewhere would work two identical training good mainly done testing model trained one model loss tell difference original image limit actually tiny bit frame never convert well would great tool could manually edit every point,issue,positive,positive,positive,positive,positive,positive
426448530,"I've got a 1080ti and a 1070, but 2 gpus (-g 2) only seems to work with extracting, not with training.  Are you running the two 1080ti's in SLI?  I thought SLI was needed to train with 2 GPUs.  ",got ti work training running two ti thought train,issue,negative,neutral,neutral,neutral,neutral,neutral
426438166,"Gessyoo, thanks a lot! Got it to work. I had a program running in the background stealing memory - my bad.
I got 192 to work with bs 32, but only when activating 1 gpu. The weird thing is that when I watch the GPU usage, it shows full memory usage from both cards, but only processing usage on 1 of them. Not sure if this is normal, or if its something with the load distribution.

I got 256x256 up and running with bs 8, but it crashed after 40 iterations.
",thanks lot got work program running background stealing memory bad got work weird thing watch usage full memory usage usage sure normal something load distribution got running,issue,negative,positive,neutral,neutral,positive,positive
426422922,"Eleganze, image size 192x192 works on a single 1080ti, with -bs 32.  Need to change line 70 in Model.py:   IMAGE_SHAPE = 192, 192 # image shape (or 256, 256, defaults to 128, 128).

",image size work single ti need change line image shape,issue,negative,negative,neutral,neutral,negative,negative
426418540,"Hi,

Tried the 256 version on a dual 1080ti, but only got OOM. Tried adjusting batch size down to 16, with no luck.  Not sure if I did everything right, though. (Changed encoder from original to highres)

Let me know and I will be happy to try out whatever setup you like.

",hi tried version dual ti got tried batch size luck sure everything right though original let know happy try whatever setup like,issue,positive,positive,positive,positive,positive,positive
426194321,"requirements.txt also will need updating, and testing for Keras version bump everywhere it is used will need to be performed.",also need testing version bump everywhere used need,issue,negative,neutral,neutral,neutral,neutral,neutral
425728942,"Ok, I'll get this pushed to staging soon. I just realised that you authored pynvx (presumably just for this purpose!), so thanks for that.


",get staging soon presumably purpose thanks,issue,negative,positive,positive,positive,positive,positive
425722461,"@torzdf No functionality is missing for faceswap,  the only reason is that pynvx has not been widely tested on Linux and Windows, so I want to minimize impact to Linux and Windows users. Maybe we can switch to pynvx when it is fully tested.",functionality missing reason widely tested want minimize impact maybe switch fully tested,issue,negative,negative,negative,negative,negative,negative
425710426,"@1132719438 Looking at your code it looks like pynvx does everything that pynvml does for the purposes of faceswap.

In principal, presumably having used both, do you see any reason not to just drop pynvml altogether and switch to pynvx? Was there any functionality you found missing?",looking code like everything principal presumably used see reason drop altogether switch functionality found missing,issue,negative,negative,negative,negative,negative,negative
425353779,Great work! I can test this from a non-macOS perspective. ,great work test perspective,issue,positive,positive,positive,positive,positive,positive
424178730,"@torzdf  now, the url status is ""invite invaild"".  Can you give me some your experience ?",status invite give experience,issue,negative,neutral,neutral,neutral,neutral,neutral
423729722,"Closed as OriginalHiRes is implemented.

@andenixa feel free to open new issues for your new models.",closed feel free open new new,issue,positive,positive,positive,positive,positive,positive
423217291,Please try it out as Original 256x mode was highly requested of me.,please try original mode highly,issue,positive,positive,positive,positive,positive,positive
423179133,"@torzdf I think line 22 in the `.gitignore` file may un-ignore the nested __pycache__.

Perhaps changing the commit such that it would apply to all __pycache__ directories would be better, i.e. as suggested [here](https://github.com/github/gitignore/blob/master/Python.gitignore):
```python
__pycache__/
```",think line file may perhaps commit would apply would better python,issue,positive,positive,positive,positive,positive,positive
423136016,Well my git client showed the temporary files as unstaged. It's also not in the `.gitignore` yet.,well git client temporary unstaged also yet,issue,negative,neutral,neutral,neutral,neutral,neutral
422246292,"@torzdf Thanks for your answering . I upgrade the keras version form 2.2.1 to 2.2.0, now , it can  work well.",thanks upgrade version form work well,issue,positive,positive,positive,positive,positive,positive
422202229,"We don't use keras-contrib.

Faceswap is confirmed working on keras 2.2.0 (as per requirements.txt). Checking the Keras repo, normalize_data_format was moved in 2.2.1, so downgrade to 2.2.0",use confirmed working per downgrade,issue,negative,positive,positive,positive,positive,positive
422092609,"I think the latest version keras version, 2.2 is incompatible with keras-contrib 2.08, see https://stackoverflow.com/questions/51652690/importerror-cannot-import-name-normalize-data-format.  Try running: pip install --upgrade keras==2.1.6 and pip install --upgrade keras-contrib==2.08.",think latest version version incompatible see try running pip install upgrade pip install upgrade,issue,negative,positive,positive,positive,positive,positive
421794617,"I've looked to add this to the alignment tool. You can check it out from Staging and run:

`python tools.py alignments -j sort-x -a <path_to_alignments_file> -fc <path_to_faces_dir>`

Please feedback so I can look to add this to Master.

From help:
```
'sort-x' - Re-index the alignments from left to
        right. For alignments with multiple faces this will
        ensure that the left-most face is at index 0        
        Optionally pass in a faces folder (-fc) to also
        rename extracted faces.
'sort-y' - Re-index the alignments from top to
        bottom. For alignments with multiple faces this will
        ensure that the top-most face is at index 0
        Optionally pass in a faces folder (-fc) to also
        rename extracted faces.
```",add alignment tool check staging run python please feedback look add master help left right multiple ensure face index optionally pas folder also rename extracted top bottom multiple ensure face index optionally pas folder also rename extracted,issue,positive,positive,positive,positive,positive,positive
419075327,"I also am in the middle of extracting a video. While it was extracting I deleted pictures of other faces I didn't need.
And when I run extract again it will redo those frames even when they are still in the alignments file.",also middle video need run extract redo even still file,issue,negative,neutral,neutral,neutral,neutral,neutral
419045380,"I have implemented a new cli option to hold back more VRAM from DLib, implemented in this commit:

3c83a068ffbd991b69c81dac9ea1f8b9e881b217

Upping the amount of MBs held back should solve any issues with running out of VRAM with DLib.

```
 -dbf DLIB_BUFFER, --dlib-buffer DLIB_BUFFER
                        This should only be increased if you are having issues
                        extracting with DLib-cnn. The calculation of RAM
                        required is approximate, so some RAM is held back in
                        reserve (64MB by default). If this is not enough
                        increase this figure by providing an integer
                        representing the amount of megabytes to reserve.
                        (DLIB-CNN Only)
```",new option hold back commit upping amount back solve running calculation ram approximate ram back reserve default enough increase figure providing integer amount reserve,issue,positive,negative,neutral,neutral,negative,negative
418797086,"Ach. That's bad news for me :/ 

I'll look to implement a more long term fix, but it looks like DLIB doesn't scale vram useage like I thought.",ach bad news look implement long term fix like scale like thought,issue,negative,negative,negative,negative,negative,negative
418792783,"Great! this buffer = 2048 did the trick!
now the dlib-cnn extraction is working!",great buffer trick extraction working,issue,positive,positive,positive,positive,positive,positive
418791718,"Also, just to eliminate it as a possibility, could you go into the file:
`lib/face_alignment/vram_allocation.py`
and edit line 122 from:

`buffer = 64 # 64MB overhead buffer`

to

`buffer = 2048 # 2GB overhead buffer`

try running, and let me know if that fixes it.",also eliminate possibility could go file edit line buffer overhead buffer buffer overhead buffer try running let know,issue,negative,neutral,neutral,neutral,neutral,neutral
418772857,"nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017
Cuda compilation tools, release 9.0, V9.0.176",compiler driver copyright corporation built compilation release,issue,negative,neutral,neutral,neutral,neutral,neutral
418772218,"```
python E:\faceswap\faceswap.py extract -i D:/swap/input -o D:/swap/output --serializer json -D dlib-cnn -mtms 20 -mtth 0.6 0.7 0.7 -mtsc 0.709 -l 0.6 -v
Using TensorFlow backend.
Output Directory: D:\swap\output
Input Directory: D:\swap\input
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: D:\swap\input\alignments.json
Starting, this may take a while...
  0%|                                                                                        | 0/11838 [00:00<?, ?it/s]
----- Initial GPU Stats -----
GPU Driver:       399.07
GPU Device count: 1
GPU Devices:      ['GeForce GTX 1080 Ti']
GPU VRAM:         [11264.0]
GPU VRAM free:    10631.18359375
-----------------------------

Initializing keras model...
2018-09-05 18:15:08.260852: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-09-05 18:15:08.267139: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645
pciBusID: 0000:09:00.0
totalMemory: 11.00GiB freeMemory: 9.06GiB
2018-09-05 18:15:08.271707: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2018-09-05 18:15:08.918413: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-09-05 18:15:08.921478: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0
2018-09-05 18:15:08.923430: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N
2018-09-05 18:15:08.925520: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2304 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)
GPU VRAM free:    7969.3046875
DLib IS compiled to use CUDA
Initializing DLib for frame size 4324x4324
Adding DLib - CNN detector
Failed to extract from image: xxxxx.png. Reason: Error while calling cudnnConvolutionForward( context(), &alpha, descriptor(data), data.device(), (const cudnnFilterDescriptor_t)filter_handle, filters.device(), (const cudnnConvolutionDescriptor_t)conv_handle, (cudnnConvolutionFwdAlgo_t)forward_algo, forward_workspace, forward_workspace_size_in_bytes, &beta, descriptor(output), output.device()) in file xxxxxx\dlib\dlib\cuda\cudnn_dlibapi.cpp:1007. code: 3, reason: CUDNN_STATUS_BAD_PARAM
```",python extract output directory input directory loading extract starting may take initial driver device count ti free model binary use found device name ti major minor visible device interconnect strength edge matrix device memory physical device name ti bus id compute capability free use frame size detector extract image reason error calling context alpha data beta output file code reason,issue,positive,positive,positive,positive,positive,positive
418385926,"I'd still need the *full* -v output and the command run, preferably from the latest staging branch (it has a bit more verbose information).

That last error tends to look like a problem with your CUDA/CuDNN install, but I can't be sure.",still need full output command run preferably latest staging branch bit verbose information last error look like problem install ca sure,issue,negative,positive,positive,positive,positive,positive
418342698,"Same here dlib-cnn does not work, 
Adding DLib - CNN detector
Failed to extract from image: xxxxx.png. Reason: Error while calling cudnnConvolutionForward( context(), &alpha, descriptor(data), data.device(), (const cudnnFilterDescriptor_t)filter_handle, filters.device(), (const cudnnConvolutionDescriptor_t)conv_handle, (cudnnConvolutionFwdAlgo_t)forward_algo, forward_workspace, forward_workspace_size_in_bytes, &beta, descriptor(output), output.device()) in file xxxxxx\dlib\dlib\cuda\cudnn_dlibapi.cpp:1007. code: 3, reason: CUDNN_STATUS_BAD_PARAM
",work detector extract image reason error calling context alpha data beta output file code reason,issue,negative,neutral,neutral,neutral,neutral,neutral
418315304,"I had a video of 3000 frames and after the first run, I sorted through all of them etc. And then I noticed some frames were missing.

So I want to run it again and add the frames to the same alignments file.

Only I don't want to have to sort the whole 3000 frames again just for the 100 or something that were new. So I set the output folder to `../extracted_2`.",video first run sorted missing want run add file want sort whole something new set output folder,issue,negative,positive,neutral,neutral,positive,positive
418303791,"I'll have to think about this one, because it changes the way it currently works. 

I don't use skip existing, but I *think* that the general use case is for people to be able to extract faces to the same alignments file in batches

`-s, --skip-existing   Skips frames that have already been extracted`

I'd need to play around with it a bit to see how it's meant to work and what the desired outcome would be.",think one way currently work use skip think general use case people able extract file already extracted need play around bit see meant work desired outcome would,issue,positive,positive,positive,positive,positive,positive
418299627,"Let's say you've extracted 2000 frames, and sorted through all them to only get your target person.
When you want to run another extract for the frames you've missed, I think you'd want to extract them to a different folder, so you can focus on only sorting the new frames.

In that case, it skips no items because the new folder would be empty.

What my PR does is look at which frames are in alignments.json and skip those too.",let say extracted sorted get target person want run another extract think want extract different folder focus new case new folder would empty look skip,issue,negative,positive,neutral,neutral,positive,positive
418298694,"Sorry, I'm confused by what is being attempted to be achieved here.

My understanding of skip existing is to add faces to alignments file where some faces have already been extracted, so you wouldn't want to remove files from the alignments folder.",sorry confused understanding skip add file already extracted would want remove folder,issue,negative,negative,negative,negative,negative,negative
418074719,"NVML is kind of integral to extract. It may be that we may have to add some kind of manual config for macOS, but unfortunately it's not a priority right now. I will look into it when I have a chance (or someone else can raise a PR).

In the meantime you can rollback to the last pre-nvml build (https://github.com/deepfakes/faceswap/tree/f90cd92ec36a0860c58a75631f762069419149de)",kind integral extract may may add kind manual unfortunately priority right look chance someone else raise rollback last build,issue,positive,positive,positive,positive,positive,positive
418073842,"That was run from Master branch, but it wouldn't hurt to try staging. I've just tested staging myself, and it works.",run master branch would hurt try staging tested staging work,issue,negative,neutral,neutral,neutral,neutral,neutral
418073109,"Are you running latest commit? Just tested:
```
python tools.py alignments -j missing-frames -a /mnt/fakes/Masters/A/test/frames/25fps/alignments.json  -fr /mnt/fakes/Masters/A/test/frames/25fps  -o console -v
Please backup your data and/or test the tool you want to use with a smaller data set to make sure you understand how it works.

[ALIGNMENT DATA]
Alignments file exists at /mnt/fakes/Masters/A/test/frames/25fps/alignments.json
Destination format set to json
Loading alignments from /mnt/fakes/Masters/A/test/frames/25fps/alignments.json
32821 items loaded

[FRAMES DATA]
Folder exists at /mnt/fakes/Masters/A/test/frames/25fps
Loading file list from /mnt/fakes/Masters/A/test/frames/25fps
32821 items loaded

[CHECK FRAMES]
No frames were found meeting the criteria
```",running latest commit tested python console please backup data test tool want use smaller data set make sure understand work alignment data file destination format set loading loaded data folder loading file list loaded check found meeting criterion,issue,positive,positive,positive,positive,positive,positive
416876029,`idx` should loop through all the images. Not restart and fill every bucket with the same set of images.,loop restart fill every bucket set,issue,negative,neutral,neutral,neutral,neutral,neutral
416875336,Oh that is well odd. I think it'd be a good idea to split it up some day.,oh well odd think good idea split day,issue,negative,positive,positive,positive,positive,positive
416874767,"I think you were using it for the wrong purpose.... depending whether you supply a frames dir or a faces dir, items changes.

For frames items is just a list of filenames, for faces, it is those 4 items listed above.

Missing Alignments is meant for checking against frames, not faces. By removing ""exit(0)"" from line 565 you basically allowed it to accept a faces folder, hence the crash.",think wrong purpose depending whether supply list listed missing meant removing exit line basically accept folder hence crash,issue,negative,negative,negative,negative,negative,negative
416873777,"item has been changed to a list of 4 items, the alignment name, extention, filename, and frame index",item list alignment name frame index,issue,negative,neutral,neutral,neutral,neutral,neutral
415906058,"> Please could you run with the -v switch and post your command and output.
",please could run switch post command output,issue,negative,neutral,neutral,neutral,neutral,neutral
415827573,"Download and install VS 2015 Community Edition or Visual Studio 2015 Build Tools
Open a command prompt with Admin. rights
Change to your preferred directory
git clone https://github.com/davisking/dlib.git
cd dlib
python setup.py install -G ""Visual Studio 14 2015"" --yes DLIB_USE_CUDA
If all goes well, you should see DLIB WILL USE CUDA message.
  ",install community edition visual studio build open command prompt change preferred directory git clone python install visual studio yes go well see use message,issue,positive,neutral,neutral,neutral,neutral,neutral
415775093,"Yeah it's not compiled for CUDA:

>>> dlib.DLIB_USE_CUDA
False

Stupid question, but how do you compile it to use it?

I googled it and for Linux you run something like this (not even sure that's it)
sudo python3.5 setup.py install --yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA --set CMAKE_PREFIX_PATH=/usr/local/cuda --set CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda/bin/ --clean

but for Windows, what are the parameters and paths?
thanks!
",yeah false stupid question compile use run something like even sure python install yes yes set set clean thanks,issue,positive,negative,neutral,neutral,negative,negative
415772996,"same thing here, mtcnn works when extracting with the most recent Master, but dlib-cnn doesn't work anymore, used to before",thing work recent master work used,issue,negative,neutral,neutral,neutral,neutral,neutral
415703260,"Make sure dlib is compiled for GPU use:
- Open a python terminal 
- post the output from:
```
>>> import dlib
>>> dlib.DLIB_USE_CUDA
```

I suspect DLIB is not compiled for Cuda, in which case you could either rebuild it, or use the MTCNN extractor (which uses TensorFlow, not DLIB)

If you still have issues, run Extract with the -v flag and post the output here please.
",make sure use open python terminal post output import suspect case could either rebuild use extractor still run extract flag post output please,issue,negative,positive,positive,positive,positive,positive
415683077,"In [this article](https://www.alanzucconi.com/2018/03/14/create-perfect-deepfakes/), under the section Training for Low-End GPU's, it says that it helps to split faces into frontal, three quarter and side views. But wouldn't that help for high end GPU's as well, as it should give a model that has a better fit?

I'd love to take a crack at adding a feature like this, but I am ""not very well versed"" in Python (read: never done Python). I have a feeling that the data is already there, since we already have the meshes and it should be a case of calculating the angle between the eyes or something like that. If someone could give me a pointer on where to get started I could try this. Though I think it might be semi-trivial for someone more experienced. :)",article section training split frontal three quarter side would help high end well give model better fit love take crack feature like well versed python read never done python feeling data already since already case calculating angle something like someone could give pointer get could try though think might someone experienced,issue,positive,positive,positive,positive,positive,positive
415643035,"python faceswap.py extract -i [my folder with the sequence of frames] -o [the folder with the extracted frames] -D dlib-cnn -ae 
",python extract folder sequence folder extracted,issue,negative,neutral,neutral,neutral,neutral,neutral
415640614,Please give us the exact parameters you are using.  We can't troubleshoot without knowing what options you've selected.,please give u exact ca without knowing selected,issue,negative,positive,positive,positive,positive,positive
414979993,"Essentially reverting this bad change
![image](https://user-images.githubusercontent.com/11540531/44457187-dea06880-a602-11e8-9d2f-9b0747e9ccb6.png)
",essentially bad change image,issue,negative,negative,negative,negative,negative,negative
414237874,"This isn't really the best place for these kinds of questions.

See: https://github.com/deepfakes/faceswap-playground/issues/164
",really best place see,issue,positive,positive,positive,positive,positive,positive
414165852,"@torzdf Sorry that I'd like to ask one more question:
In these training modes, origin, original high res, gan, gan 128. Which one gets the best performance?

After tried origin and origin high res, I found it's harder to train origin high res than origin....: (
Does this mean I need more data for origin high res than origin?",sorry like ask one question training origin original high gan gan one best performance tried origin origin high found harder train origin high origin mean need data origin high origin,issue,positive,positive,positive,positive,positive,positive
414122412,"@telecast-git The alignments tool currently in PRs (and soon to be merged to staging) allows to re-extract faces. If you were to point the frames directory at your output folder rather than the source frames, it would output the swapped faces.

I haven't used it for this purpose, but it should work fine. Any feedback is appreciated.

Closing this for now, as any other action is unlikely to be taken.",tool currently soon staging point directory output folder rather source would output used purpose work fine feedback action unlikely taken,issue,negative,positive,neutral,neutral,positive,positive
414121724,"Two ways, which ultimately boil down to the same thing: Manually remove the false positives from the extracted faces folder.

You can then set the `-a` (`--input-aligned-dir`) flag to point at your extracted folder and it will skip any deleted faces.

There is also an alignment tool coming (check the PRs) which should make finding false positives a little easier, by identifying frames with multiple images. You can then use the same tool to remove false positives from the alignment file permanently. ",two way ultimately boil thing manually remove false extracted folder set flag point extracted folder skip also alignment tool coming check make finding false little easier multiple use tool remove false alignment file permanently,issue,negative,negative,negative,negative,negative,negative
414063301,"It won't impact training, but MTCNN tends to find more faces than DLIB",wo impact training find,issue,negative,neutral,neutral,neutral,neutral,neutral
414062359,"@torzdf Thank you for your advice!
By the way, if I use MTCNN instead of dlib-cnn, will the final results be better?",thank advice way use instead final better,issue,positive,positive,positive,positive,positive,positive
414043723,"We should probably bump the version.

Basically the command keepdims was called keep_dims in older versions of tensorflow. You can do one of 2 things:

1) Upgrade tensorflow to the latest version

or

2) Go into the file `lib/face_alignment/mtcnn.py` and do a find/replace for `keepdims` changing it to `keep_dims` (lines 215 and 217)

I would recommend doing 1) so that you don't need to change the code whenever you upgrade",probably bump version basically command older one upgrade latest version go file would recommend need change code whenever upgrade,issue,negative,positive,positive,positive,positive,positive
414039864,"@torzdf For the first issue, my tensorflow version is 1.4.0 from `tensorflow.__version__`.
In the setup.py, the required tensorflow version is 1.4.0.
I don't think it's an old version problem...",first issue version version think old version problem,issue,negative,positive,positive,positive,positive,positive
413928003,"For your first issue, it looks like you are running an old version of TensorFlow. Try upgrading.

-- align-eyes won't impact performance, it just does a further alignment at the end of the extract process, you can try it with or without to see which you prefer. To be honest, the difference will probably be minor.

With the -w switch, the image will save with every save iteration (every 100 iterations at default)",first issue like running old version try wo impact performance alignment end extract process try without see prefer honest difference probably minor switch image save every save iteration every default,issue,positive,positive,positive,positive,positive,positive
413810383,"@torzdf And I have the third question: If I train with the -w switch, how often would save image once ?
Thank you soooooooo much!",third question train switch often would save image thank much,issue,positive,positive,neutral,neutral,positive,positive
413809651,"@torzdf And I'm wondering if I set `--align-eyes` to True, performance would be better ?",wondering set true performance would better,issue,positive,positive,positive,positive,positive,positive
413809272,"@torzdf I'm not sure if I'm doing what you asked correctly.
Here's the output.
And I noticed there is a mistake :
Reason: reduce_max() got an unexpected keyword argument 'keepdims' 
Thank you for your help.
![image](https://user-images.githubusercontent.com/25877709/44258586-f1512100-a241-11e8-866d-04b29d8edc54.png)
![image](https://user-images.githubusercontent.com/25877709/44258628-08900e80-a242-11e8-9b2f-afab58041793.png)

",sure correctly output mistake reason got unexpected argument thank help image image,issue,negative,positive,positive,positive,positive,positive
413750267,"In my case, mtcnn doesn't work. But my dlib-cnn works fine. 
When using default mtcnn, no face can be detected.
But dlib-cnn can detect the same image. Weird.",case work work fine default face detect image weird,issue,negative,negative,neutral,neutral,negative,negative
412516099,"It will be cool if I can to export only faceswap (or may be mask-alpha channel) area for post-production stage (Nuke, AE, etc)",cool export may channel area stage nuke ae,issue,negative,positive,positive,positive,positive,positive
412344349,"Actually I was thinking that, it would be added only to the swap area, as the the other area in the frame has already original noise or other compress artifacts.",actually thinking would added swap area area frame already original noise compress,issue,negative,positive,positive,positive,positive,positive
412330632,"This could be written as a post-processing tool. I assume Noise would be added to the whole frame, not just the swap area. As @tryzombie501 says, this could currently be done by batch processing by a human in GIMP or Photoshop. 

If anyone were to write this as a tool, it would get merged, but it isn't a priority for me.",could written tool assume noise would added whole frame swap area could currently done batch human gimp anyone write tool would get priority,issue,negative,positive,neutral,neutral,positive,positive
412326677,"Noise could help but it might also ruin some photos. (For example if the photos are really clear) This is something that should be done by a human if they wanted to give it a more realistic feeling.

Devices save images differently with different types of noise. This seems like more work than what it's worth in my view.",noise could help might also ruin example really clear something done human give realistic feeling save differently different noise like work worth view,issue,positive,positive,positive,positive,positive,positive
412227477,"I am away for a few days but will when I get the chance

Sent from my iPhone

> On Aug 10, 2018, at 4:00 AM, torzdf <notifications@github.com> wrote:
> 
> Please could you run with the -v switch and post your command and output.
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",away day get chance sent wrote please could run switch post command output thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
412221347,I have tested the new build and the tool seems to be working as per normal,tested new build tool working per normal,issue,negative,positive,positive,positive,positive,positive
411693166,"I had the same problem while calling ""faceswap convert"", but I was using GPU mode.
After trying the latest staging branch, now I can convert faces using GPU mode.",problem calling convert mode trying latest staging branch convert mode,issue,negative,positive,positive,positive,positive,positive
411198438,"Without being able to dig into the dlib code, I guess we'll never know. Mtcnn and dlib work differently.

Thanks for the feedback, I'll push to master ",without able dig code guess never know work differently thanks feedback push master,issue,negative,positive,positive,positive,positive,positive
411102043,"Maybe, like?
Parameters
----------
image : ndarray
    Input image data. Will be converted to float.
mode : str
    One of the following strings, selecting the type of noise to add:

    'gauss'     Gaussian-distributed additive noise.
    'poisson'   Poisson-distributed noise generated from the data.
    's&p'       Replaces random pixels with 0 or 1.
    'speckle'   Multiplicative noise using out = image + n*image,where
                n is uniform noise with specified mean & variance.


import numpy as np
import os
import cv2
def noisy(noise_typ,image):
   if noise_typ == ""gauss"":
      row,col,ch= image.shape
      mean = 0
      var = 0.1
      sigma = var**0.5
      gauss = np.random.normal(mean,sigma,(row,col,ch))
      gauss = gauss.reshape(row,col,ch)
      noisy = image + gauss
      return noisy
   elif noise_typ == ""s&p"":
      row,col,ch = image.shape
      s_vs_p = 0.5
      amount = 0.004
      out = np.copy(image)
      # Salt mode
      num_salt = np.ceil(amount * image.size * s_vs_p)
      coords = [np.random.randint(0, i - 1, int(num_salt))
              for i in image.shape]
      out[coords] = 1

      # Pepper mode
      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))
      coords = [np.random.randint(0, i - 1, int(num_pepper))
              for i in image.shape]
      out[coords] = 0
      return out
  elif noise_typ == ""poisson"":
      vals = len(np.unique(image))
      vals = 2 ** np.ceil(np.log2(vals))
      noisy = np.random.poisson(image * vals) / float(vals)
      return noisy
  elif noise_typ ==""speckle"":
      row,col,ch = image.shape
      gauss = np.random.randn(row,col,ch)
      gauss = gauss.reshape(row,col,ch)        
      noisy = image + image * gauss
      return noisy",maybe like image input image data converted float mode one following type noise add additive noise noise data random multiplicative noise image image uniform noise mean variance import import o import noisy image gauss row col mean sigma gauss mean sigma row col gauss row col noisy image gauss return noisy row col amount image salt mode amount pepper mode amount return image noisy image float return noisy speckle row col gauss row col gauss row col noisy image image gauss return noisy,issue,negative,negative,negative,negative,negative,negative
411037858,"It works now, so I guess I'll close this one. It extracts faces normally.

Still, it doesn't explain how rotating a picture busts VRAM with dlib.

And that it doesn't happen with mtcnn.",work guess close one normally still explain rotating picture happen,issue,negative,positive,positive,positive,positive,positive
410232209,Please try latest commit in staging branch,please try latest commit staging branch,issue,positive,positive,positive,positive,positive,positive
409937237,"It doesn't convert very well. Some GAN implementations look to fix this with masking, but it isn't implemented too well here.",convert well gan look fix well,issue,negative,neutral,neutral,neutral,neutral,neutral
409936976,Try latest commit in staging branch,try latest commit staging branch,issue,negative,positive,positive,positive,positive,positive
409842251,@Kirin-kun. Sorry for the delay. This should now be fixed in staging. Please could you test if you have a chance.,sorry delay fixed staging please could test chance,issue,negative,negative,negative,negative,negative,negative
409643822,I can confirm that this issue happens with the latest version.,confirm issue latest version,issue,negative,positive,positive,positive,positive,positive
406871599,"Awesome sauce. Thank you. 

Sent from my iPhone

> On Jul 22, 2018, at 10:09 AM, Artem Ivanov <notifications@github.com> wrote:
> 
> @kellurian my bad, done now but so far it would only support INPUT_SIZE of
> 
> 64, 64
> 128, 128
> 256, 256
> I have to look into the code if the trainer library supports intermediate values here, i.e. 176x176
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",awesome sauce thank sent wrote bad done far would support look code trainer library intermediate reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
406869433,"@kellurian my bad, done now but so far it would only support `INPUT_SIZE` of 
- 64, 64
- 128, 128
- 256, 256
I have to look into the trainer library code to see if it supports intermediate values here, i.e. 160x160",bad done far would support look trainer library code see intermediate,issue,negative,negative,negative,negative,negative,negative
406823627,"Works fine for me at 128x128, still get error ""ValueError: Error when checking input: expected input_4 to have shape (256, 256, 3) but got array with shape (128, 128, 3)"" when I change to 256, but you might not have implemented any changes for increasing the training resolution.
",work fine still get error error input shape got array shape change might increasing training resolution,issue,negative,positive,positive,positive,positive,positive
405173709,"Well, I couldn't figure out how to modify the extractor script, so for the moment I just wrote a short extraction script that will isolate individual facial features, kick out a 256x256 jpeg, along with a json file with the coordinates to re-composite after training/conversion. The json file feeds into a second ""replacer"" script to recomposite the extracted face part after it's been altered.

Linking to the [repo](https://github.com/rosenb0rg/feature_extractor) here if anyone in the future is trying something similar and closing the issue.
",well could figure modify extractor script moment wrote short extraction script isolate individual facial kick along file file second replacer script extracted face part linking anyone future trying something similar issue,issue,negative,neutral,neutral,neutral,neutral,neutral
405009989,"Ok so in extract.py the ""resized_face"" output come from Extract_Align.py, whose ""extract"" function in turn calls aligner.py. So it should be the facial landmarks in there that determine what part of the face gets cropped?

It looks like the mean_face_x and mean_face_y values in aligner.py are referencing the last 51 facial landmarks (i.e. everything but the jawline). I tried modifying alignery.py after line 24 so it only uses the last 20 landmarks (i.e. just the mouth region), and then passing only the last 20 detected facial landmarks into umeyama. 

```
mean_face_y = mean_face_y[-20:]
mean_face_x = mean_face_x[-20:]

landmarks_2D = numpy.stack( [ mean_face_x, mean_face_y ], axis=1 )

def get_align_mat(face, size, should_align_eyes):
    mat_umeyama = umeyama(numpy.array(face.landmarks_as_xy()[-20:]), landmarks_2D, True)[0:2]

    if should_align_eyes is False:
        return mat_umeyama
```

This modification gets a working output (no more matrix dimension mismatch errors), but I just get the same result as with the unmodified script. I would expect this to crop just around the mouth area, but I'm not getting anything different. When I play around with the parameters - using the last 10 landmarks, or 5 random landmarks in the middle, sometimes the output will rotate, or crop slightly - but I can't isolate a single feature.



",output come whose extract function turn facial determine part face like last facial everything tried line last mouth region passing last facial face size true false return modification working output matrix dimension mismatch get result unmodified script would expect crop around mouth area getting anything different play around last random middle sometimes output rotate crop slightly ca isolate single feature,issue,positive,negative,neutral,neutral,negative,negative
404834733,Yeah. You'll need to play around with lib\aligner.py. It expect 68 landmarks,yeah need play around expect,issue,positive,neutral,neutral,neutral,neutral,neutral
404800920,"I get this:

Failed to extract from image: C:\local\src\deepfakes\test\test.jpg. Reason: shapes (2,51) and (2,2) not aligned: 51 (dim 1) != 2 (dim 0)

Traceback (most recent call last):
  File ""faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""C:\local\src\deepfakes\lib\cli.py"", line 81, in execute_script
    process.process()
  File ""C:\local\src\deepfakes\scripts\extract.py"", line 43, in process
    self.extract_single_process()
  File ""C:\local\src\deepfakes\scripts\extract.py"", line 56, in extract_single_process
    filename, faces = self.process_single_image(filename)
  File ""C:\local\src\deepfakes\scripts\extract.py"", line 94, in process_single_image
    for idx, face in process_faces]
  File ""C:\local\src\deepfakes\scripts\extract.py"", line 94, in <listcomp>
    for idx, face in process_faces]
  File ""C:\local\src\deepfakes\scripts\extract.py"", line 115, in process_single_face
    self.faces.align_eyes)
  File ""C:\local\src\deepfakes\plugins\Extract_Align.py"", line 11, in extract
    alignment = get_align_mat(face, size, align_eyes)
  File ""C:\local\src\deepfakes\lib\aligner.py"", line 29, in get_align_mat
    mat_umeyama = umeyama(numpy.array(face.landmarks_as_xy()[17:]), landmarks_2D, True)[0:2]
  File ""C:\local\src\deepfakes\lib\umeyama.py"", line 49, in umeyama
    A = np.dot(dst_demean.T, src_demean) / num
ValueError: shapes (2,51) and (2,2) not aligned: 51 (dim 1) != 2 (dim 0)",get extract image reason dim dim recent call last file line module file line file line process file line file line face file line face file line file line extract alignment face size file line true file line dim dim,issue,negative,positive,positive,positive,positive,positive
404799645,"In scripts/extract.py, line 101 insert raise to get the traceback. You should be able to trace the issue from there,

that is change the block to:
```

        except Exception as err:
            if self.args.verbose:
                print(""Failed to extract from image: ""
                      ""{}. Reason: {}"".format(filename, err))
                raise  #  << Insert this
return retval
```
",line insert raise get able trace issue change block except exception err print extract image reason err raise insert return,issue,negative,positive,positive,positive,positive,positive
404772160,"Thanks - I'm a little confused about this.

It seems like I'd want to modify ""process_single_image"" in extract.py so that instead of pulling an entire face, it just pulls the region around landmarks 49 to 68. This leads to ""get_faces"" in fsmedia.py, which in turn leads to ""detect_faces"" in faces_detect.py. Here I tried this modification at line 17 to use only the mouth subset of the landmarks:

for face in face_detect.landmarks:
ax_x, ax_y = face[0][0], face[0][1]
right, bottom = face[0][2], face[0][3]
landmarks = face[1]
**landmarks = landmarks[49:68]**

but i get the following error:

`failed to extract from image <image path> Reason: shapes (2,51) and (2,2) not aligned: 51 (dim 1) != 2 (dim0)`

",thanks little confused like want modify instead entire face region around turn tried modification line use mouth subset face face face right bottom face face face get following error extract image image path reason dim dim,issue,negative,positive,neutral,neutral,positive,positive
404676100,"You can easily do that by modifying the extract to focus only on the points around the mouth. Feel free to use the landmarks around the mouth (49-68) instead of the landmarks that are used now.
a good place to start:
https://stackoverflow.com/questions/41794191/dlib-facial-landmark-starting-index",easily extract focus around mouth feel free use around mouth instead used good place start,issue,positive,positive,positive,positive,positive,positive
404279669,"Just a guess, should this be on the other deleted image ""r"": 1 ? and not the same as the correct face image?",guess image correct face image,issue,negative,neutral,neutral,neutral,neutral,neutral
404278272,"05874.png has the right face artifact,
but 05875.png has an extra artifact that is deleted from the aligned faces as it was garbage and now it shows up in the converted images.

  ""05874.png"": [
    {
      ""r"": 0,
      ""x"": 187,
      ""w"": 212,
      ""y"": -5,
      ""h"": 234,
      ""landmarksXY"": [
        [
          205,
          142
        ],
        [
          223,
          160
        ],
        [
          241,
          178
        ],
        [
          259,
          189
        ],
        [
          280,
          207
        ],
        [
          301,
          214
        ],
        [
          319,
          217
        ],
        [
          344,
          217
        ],
        [
          373,
          207
        ],
        [
          391,
          185
        ],
        [
          394,
          164
        ],
        [
          398,
          146
        ],
        [
          398,
          125
        ],
        [
          394,
          100
        ],
        [
          384,
          82
        ],
        [
          376,
          60
        ],
        [
          359,
          42
        ],
        [
          216,
          114
        ],
        [
          219,
          100
        ],
        [
          230,
          85
        ],
        [
          241,
          78
        ],
        [
          251,
          74
        ],
        [
          291,
          46
        ],
        [
          301,
          39
        ],
        [
          312,
          28
        ],
        [
          323,
          24
        ],
        [
          337,
          24
        ],
        [
          294,
          89
        ],
        [
          305,
          103
        ],
        [
          316,
          117
        ],
        [
          323,
          128
        ],
        [
          312,
          146
        ],
        [
          319,
          142
        ],
        [
          330,
          139
        ],
        [
          334,
          132
        ],
        [
          337,
          125
        ],
        [
          244,
          121
        ],
        [
          248,
          110
        ],
        [
          259,
          103
        ],
        [
          269,
          103
        ],
        [
          262,
          110
        ],
        [
          251,
          117
        ],
        [
          312,
          74
        ],
        [
          316,
          64
        ],
        [
          326,
          57
        ],
        [
          334,
          57
        ],
        [
          330,
          64
        ],
        [
          319,
          71
        ],
        [
          312,
          178
        ],
        [
          319,
          167
        ],
        [
          330,
          153
        ],
        [
          337,
          150
        ],
        [
          344,
          146
        ],
        [
          359,
          142
        ],
        [
          369,
          142
        ],
        [
          366,
          157
        ],
        [
          362,
          171
        ],
        [
          355,
          178
        ],
        [
          344,
          182
        ],
        [
          330,
          182
        ],
        [
          316,
          178
        ],
        [
          334,
          164
        ],
        [
          341,
          157
        ],
        [
          348,
          153
        ],
        [
          366,
          142
        ],
        [
          355,
          160
        ],
        [
          348,
          167
        ],
        [
          337,
          171
        ]
      ]
    }
  ],
  ""05875.png"": [
    {
      ""r"": 0,
      ""x"": 186,
      ""w"": 208,
      ""y"": 0,
      ""h"": 227,
      ""landmarksXY"": [
        [
          201,
          143
        ],
        [
          218,
          164
        ],
        [
          235,
          178
        ],
        [
          253,
          189
        ],
        [
          274,
          206
        ],
        [
          295,
          216
        ],
        [
          316,
          216
        ],
        [
          340,
          216
        ],
        [
          368,
          209
        ],
        [
          385,
          185
        ],
        [
          389,
          164
        ],
        [
          392,
          147
        ],
        [
          392,
          126
        ],
        [
          389,
          101
        ],
        [
          382,
          84
        ],
        [
          371,
          63
        ],
        [
          354,
          46
        ],
        [
          211,
          115
        ],
        [
          218,
          101
        ],
        [
          229,
          88
        ],
        [
          239,
          81
        ],
        [
          249,
          77
        ],
        [
          288,
          49
        ],
        [
          298,
          39
        ],
        [
          305,
          32
        ],
        [
          319,
          28
        ],
        [
          333,
          28
        ],
        [
          291,
          91
        ],
        [
          302,
          105
        ],
        [
          312,
          119
        ],
        [
          319,
          129
        ],
        [
          309,
          147
        ],
        [
          316,
          143
        ],
        [
          326,
          140
        ],
        [
          330,
          133
        ],
        [
          333,
          126
        ],
        [
          239,
          122
        ],
        [
          246,
          112
        ],
        [
          253,
          105
        ],
        [
          267,
          105
        ],
        [
          260,
          112
        ],
        [
          249,
          119
        ],
        [
          305,
          77
        ],
        [
          312,
          67
        ],
        [
          323,
          60
        ],
        [
          330,
          56
        ],
        [
          326,
          67
        ],
        [
          316,
          74
        ],
        [
          312,
          182
        ],
        [
          316,
          171
        ],
        [
          326,
          157
        ],
        [
          333,
          154
        ],
        [
          340,
          147
        ],
        [
          354,
          143
        ],
        [
          364,
          147
        ],
        [
          364,
          161
        ],
        [
          357,
          171
        ],
        [
          350,
          182
        ],
        [
          340,
          185
        ],
        [
          326,
          185
        ],
        [
          312,
          182
        ],
        [
          330,
          164
        ],
        [
          337,
          161
        ],
        [
          347,
          154
        ],
        [
          361,
          147
        ],
        [
          350,
          161
        ],
        [
          344,
          168
        ],
        [
          333,
          175
        ]
      ]
    },
    {
      ""r"": 0,
      ""x"": 515,
      ""w"": 579,
      ""y"": 79,
      ""h"": 661,
      ""landmarksXY"": [
        [
          521,
          196
        ],
        [
          501,
          205
        ],
        [
          491,
          355
        ],
        [
          501,
          225
        ],
        [
          501,
          345
        ],
        [
          531,
          504
        ],
        [
          541,
          533
        ],
        [
          561,
          563
        ],
        [
          620,
          603
        ],
        [
          561,
          583
        ],
        [
          998,
          146
        ],
        [
          630,
          186
        ],
        [
          918,
          643
        ],
        [
          928,
          663
        ],
        [
          650,
          235
        ],
        [
          1057,
          434
        ],
        [
          888,
          603
        ],
        [
          531,
          196
        ],
        [
          908,
          315
        ],
        [
          630,
          225
        ],
        [
          640,
          225
        ],
        [
          640,
          235
        ],
        [
          1008,
          444
        ],
        [
          988,
          474
        ],
        [
          1037,
          265
        ],
        [
          610,
          196
        ],
        [
          1077,
          305
        ],
        [
          620,
          374
        ],
        [
          888,
          623
        ],
        [
          1107,
          335
        ],
        [
          630,
          355
        ],
        [
          571,
          285
        ],
        [
          571,
          285
        ],
        [
          571,
          295
        ],
        [
          531,
          394
        ],
        [
          590,
          295
        ],
        [
          571,
          265
        ],
        [
          571,
          265
        ],
        [
          580,
          265
        ],
        [
          610,
          275
        ],
        [
          590,
          285
        ],
        [
          571,
          285
        ],
        [
          918,
          613
        ],
        [
          928,
          613
        ],
        [
          948,
          424
        ],
        [
          561,
          255
        ],
        [
          918,
          623
        ],
        [
          918,
          613
        ],
        [
          640,
          225
        ],
        [
          571,
          215
        ],
        [
          521,
          205
        ],
        [
          521,
          205
        ],
        [
          471,
          404
        ],
        [
          610,
          255
        ],
        [
          690,
          563
        ],
        [
          670,
          513
        ],
        [
          759,
          -131
        ],
        [
          590,
          215
        ],
        [
          630,
          225
        ],
        [
          630,
          215
        ],
        [
          640,
          215
        ],
        [
          541,
          265
        ],
        [
          521,
          255
        ],
        [
          670,
          504
        ],
        [
          720,
          533
        ],
        [
          749,
          -62
        ],
        [
          561,
          235
        ],
        [
          580,
          205
        ]
      ]
    }
  ],",right face artifact extra artifact garbage converted,issue,negative,positive,positive,positive,positive,positive
404225251,"Just an update. I know the issue here. Unfortunately my server has just died, so I'm having to fix that before I can upload a fix.",update know issue unfortunately server fix fix,issue,negative,negative,negative,negative,negative,negative
403895577,"Fail...  it extracts a single one at the start, then nothing. Something is not initialized correctly.

```
Adding DLib - CNN detector
Resizing image from 2000x3000 to 1802x2703.
  1%|?                                         | 1/170 [00:18<51:12, 18.18s/it]G
PU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 2000x3000 to 138x207.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 3000x2000 to 207x138.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 2000x3000 to 138x207.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 3000x2000 to 207x138.
Warning: No faces were detected.
  1%|?                                         | 2/170 [00:18<26:21,  9.41s/it]G
PU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 2000x3000 to 138x207.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 3000x2000 to 207x138.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 2000x3000 to 138x207.
Warning: No faces were detected.
GPU VRAM free:    388.5390625
Initializing DLib for frame size 207x207
Resizing image from 3000x2000 to 207x138.
Warning: No faces were detected.
  2%|?                                         | 3/170 [00:19<18:03,  6.49s/it]G
```

It resizes the image to a ridiculously small size then doesn't detect anything.",fail single one start nothing something correctly detector image pu free frame size image warning free frame size image warning free frame size image warning free frame size image warning pu free frame size image warning free frame size image warning free frame size image warning free frame size image warning image ridiculously small size detect anything,issue,negative,positive,positive,positive,positive,positive
403791363,"@Kirin-kun I have updated the way that DLib detects faces. It now scales all images to fit a square based on available VRAM. This should mitigate the rotating issues. This is currently in the staging branch pending testing.

It also means it *should* detect more faces too, as DLib does not have an option to set the threshold for a positive match, so enlarging the source image is the only way to increase the potential for positives.

My main concern is that enlarging all the images will slow down extraction, so I need to get some real world testing put through, to see whether I will need to add it as an option rather than as default.

If you get a chance, please could you checkout the staging branch and see if it works as expected/fixes your issue.
",way scale fit square based available mitigate rotating currently staging branch pending testing also detect option set threshold positive match enlarging source image way increase potential main concern enlarging slow extraction need get real world testing put see whether need add option rather default get chance please could staging branch see work issue,issue,positive,positive,positive,positive,positive,positive
403548461,"I'm going to look at extract again. I'm thinking of running 2 passes on the data (one for detection, one for landmarks) rather than the single pass we currently use, as I am having to tread a fine line on VRAM allocation. Hopefully that will fix this issue, but I need to look at timings.


> So... no ""out of memory"", but it got resized on the fly (because it wouldn't fit in memory?).

Yes. DLib CNN is fairly linear in terms of VRAM required vs pixels in image, so when it hits a threshold, dictated by available vram, it will resize the image down.

What is strange in my example is that I still have 1.9GB free after it process the first pass of the image. Rotating the image from portrait to landscape immediately gobbles this up for no discernible reason, but landscape to portrait is fine.

If this persists after splitting out images it will need to be factored into the code.
",going look extract thinking running data one detection one rather single pas currently use tread fine line allocation hopefully fix issue need look memory got fly would fit memory yes fairly linear image threshold available resize image strange example still free process first pas image rotating image portrait landscape immediately discernible reason landscape portrait fine splitting need code,issue,positive,positive,positive,positive,positive,positive
403497621,"I made some further tests and I'm a bit puzzled.

python.exe crashes at the end (""program ceased to function..."") with a single 3000x2000 image  and rotation on. It also crashes at the end with a second one. But if I add a third one (or more), it doesn't crashes and the process exits cleanly!

If I don't add ""-r on"", it becomes even stranger: if there's between 1 and 7 images, it crashes at the end. If I add a 8th one, it exits cleanly...

WTF?

If I use 2000x3000 images with rotation, it stops with an OOM immediately.

Also, for the hell of it, I resized the blank image to 3000x3000. I got this:

```
Adding DLib - CNN detector
GPU VRAM free:    3433.41796875
Resizing image from 3000x3000 to 2512x2512.
Warning: No faces were detected.
Resizing image from 3000x3000 to 2512x2512.
Warning: No faces were detected.
Resizing image from 3000x3000 to 2512x2512.
Warning: No faces were detected.
Resizing image from 3000x3000 to 2512x2512.
Warning: No faces were detected.
100%|████████████████████████████████████████████| 1/1 [00:20<00:00, 20.06s/it]
Writing alignments to: H:\Fakes\lili\alignments.json
-------------------------
Images found:        1
Faces detected:      0
-------------------------
Done!
```

So... no ""out of memory"", but it got resized on the fly (because it wouldn't fit in memory?).",made bit puzzled end program function single image rotation also end second one add third one process cleanly add becomes even stranger end add th one cleanly use rotation immediately also hell blank image got detector free image warning image warning image warning image warning writing found done memory got fly would fit memory,issue,negative,positive,positive,positive,positive,positive
403445838,"Meaning you reproduced the issue? 

Phew, I was afraid it would be something in my configuration. 

I had 1067x1600 pictures in this set and they were rotated fine, so I guess there's a threshold at which the problem occurs.",meaning issue phew afraid would something configuration set rotated fine guess threshold problem,issue,negative,negative,neutral,neutral,negative,negative
403442940,"This is stumping me at the moment. I'll continue to look into it, but it only seems to occur if the image starts as portrait and rotates to landscape.  If the image goes in as 3000x2000 then it works fine.

Portrait images seem to take an additional 2-4MB of VRAM, but this wouldn't push it over the edge, and it certainly looks like it isn't over allocating VRAM.

This is putting in  a 3500*2500 image. It allocates the VRAM on first pass, leaving 1943MB free. When it rotates it uses another 2MB but never uses more.
```
Adding DLib - CNN detector
GPU VRAM free:    5470.5625
[5470.5625]
Warning: No faces were detected.
[1942.5625]
Warning: No faces were detected.
[1940.5625]
Warning: No faces were detected.
[1940.5625]
Warning: No faces were detected.
```

Putting it in as 2500*3500 and I get:
```
GPU VRAM free:    5470.5625
[5470.5625]
Warning: No faces were detected.
[1944.5625]
Failed to extract from image: /home/matt/fake/test/dlib_test/Untitled.jpg. Reason: Error while calling cudaMalloc(&data, n) in file /tmp/pip-install-teoe75q2/dlib/dlib/cuda/cuda_data_ptr.cpp:28. code: 2, reason: out of memory
```
So for some reason it is using up the available 1945MB of VRAM rotating from portrait to landscape.

Like I say, I will continue to investigate.",moment continue look occur image portrait landscape image go work fine portrait seem take additional would push edge certainly like image first pas leaving free another never detector free warning warning warning warning get free warning extract image reason error calling data file code reason memory reason available rotating portrait landscape like say continue investigate,issue,positive,positive,positive,positive,positive,positive
403377708,"@fat-tire  That's really a cool idea to use pre-trained model for this task. I ran this model from scratch on the cloud but it gets stopped after 18,100 epochs. I tested face swap in that trained model and the result is not that convincing.  Training a GAN model on pre-trained weights is a time saver and if you able to share sample code, it would be a great help for us or please upload/share your pre-trained model.",really cool idea use model task ran model scratch cloud stopped tested face swap trained model result convincing training gan model time saver able share sample code would great help u please model,issue,positive,positive,positive,positive,positive,positive
403288574,"@andenixa 
thanks. now i got you. the value specified with option -e seems to be the number of pixels from the outer edge of the mask. now i understand that what you meant is the border width which is removed from the mask outer edge - and that's what is meant by erosion. 
Thanks again!
Just one wish for the future:
Can you provide these specifications in the --help ?",thanks got value option number outer edge mask understand meant border width removed mask outer edge meant erosion thanks one wish future provide help,issue,positive,positive,positive,positive,positive,positive
403288038,"@agilebean 
I just specify erosion and smooth via cmdline option and look at the merged results until borders take approx. 15% of mask size. The actual absolute values vary depending on the image size and Model used.",specify erosion smooth via option look take mask size actual absolute vary depending image size model used,issue,negative,positive,positive,positive,positive,positive
403285107,"@andenixa sorry could your clarify your answer:

> Hello @agilebean,
> I apologize for confusion there is no actual way at the moment to to supply parameters in percent.
> As of now you could only supply erosion kernel in pixels. What I meant is an approximate amount > > obtained by visual comparison of the results. I make in approximately about 15% of the overall face > dimensions (20% in some difficult cases) by eye comparison.

So concretely, how do you specify the erosion kernel in pixels?
Do you specify a matrix, and if yes, in which format? If not, is is absolute amount of pixels?
Sorry to bother again, but there is nothing in the online help that specifies exactly how you specify each option. ",sorry could clarify answer hello apologize confusion actual way moment supply percent could supply erosion kernel meant approximate amount visual comparison make approximately overall face difficult eye comparison concretely specify erosion kernel specify matrix yes format absolute amount sorry bother nothing help exactly specify option,issue,negative,negative,negative,negative,negative,negative
403267735,"No need to provide a test image. You can create easily a blank image (thus, no face to be detected) of dimensions 2000x3000. Or you can use any image of these dimensions with no detectable face by dlib. I 100% reproduced the crash with a single image of this type.",need provide test image create easily blank image thus face use image detectable face crash single image type,issue,negative,negative,neutral,neutral,negative,negative
403246031,Can you provide your test image please,provide test image please,issue,negative,neutral,neutral,neutral,neutral,neutral
403223169,"@andenixa ""due to initial initialization with random pattern which propagates all layers and mask ""thinks"" this pattern is actual a part of the deal"" -> That sounds quite right.

I'm not an expert on this field so there are limitations on what I can do now. I'm still learning.

Good luck with whatever you are doing now. I've noticed that you've made a lot of contributions to this repo. Thanks! ",due initial random pattern mask pattern actual part deal quite right expert field still learning good luck whatever made lot thanks,issue,positive,positive,neutral,neutral,positive,positive
403222822,"@tjdwo13579 I think the moire pattern is due to initial initialization with random pattern which propagates all layers and mask ""thinks"" this pattern is actual a part of the deal since Shaonlu mixes mask with the results and there is no separate (as far as I know) loss function for it. You could make different weights initializations as a temporary fix. I could play with it actually, but not sure if PR would ever get accepted.",think moire pattern due initial random pattern mask pattern actual part deal since mask separate far know loss function could make different temporary fix could play actually sure would ever get accepted,issue,positive,negative,neutral,neutral,negative,negative
403222607,@andenixa  Oops sorry I didn't read your post thoroughly.,sorry read post thoroughly,issue,negative,negative,negative,negative,negative,negative
403222419,"@andenixa Ah I see. Thanks for the reply.

I thought this was solved since there was a 3 month period.

So the result you showed on the Donald trump -> Cage video is using Shaonlu's repository?",ah see thanks reply thought since month period result trump cage video repository,issue,negative,positive,positive,positive,positive,positive
403222217,@tjdwo13579 I don't want to overshadow Shaonlu's work in any way. But as far as I know at FaceSwap none ever got satisfactory results with GAN2.1 (64x nor 128x). I trained it for a week with no conclusive results. If you really want to see whats going on perhaps it would be wise to train it for 150-200k epochs since it has lots of layers.,want overshadow work way far know none ever got satisfactory gan trained week conclusive really want see whats going perhaps would wise train since lot,issue,negative,positive,positive,positive,positive,positive
403220481,"So the moire pattern problem is still not solved right?
Cause I've witnessed this after 60k iterations with 32 batch

![image](https://user-images.githubusercontent.com/36047765/42411891-7e037b0c-823f-11e8-8913-0fe0e3ba77f2.png)

Or am I using the wrong repository??
I used the GAN128 on the master branch
",moire pattern problem still right cause batch image wrong repository used gan master branch,issue,negative,negative,negative,negative,negative,negative
403047113,"Hello @agilebean,
I apologize for confusion there is no actual way at the moment to to supply parameters in percent. 
As of now you could only supply erosion kernel in pixels. What I meant is an approximate amount obtained by visual comparison of the results. I make in approximately about 15% of the overall face dimensions (20% in some difficult cases) by eye comparison. 

Perhaps its would be a good feature request though I am not sure if its fair because @torzdf is the one who does converter re-factoring. I am not sure if they have time for it.",hello apologize confusion actual way moment supply percent could supply erosion kernel meant approximate amount visual comparison make approximately overall face difficult eye comparison perhaps would good feature request though sure fair one converter sure time,issue,positive,positive,positive,positive,positive,positive
402705923,"Hello @andenixa and @HelpSeeker,
thanks so much for your tips. 
The histogram matching and seamless options made a big difference.
As for mask erosion with the -e option, how do you specify 15%? 
`-e .15`or `-e 15` or else? ",hello thanks much histogram matching seamless made big difference mask erosion option specify else,issue,negative,positive,positive,positive,positive,positive
402457684,"For the moment, I'm not doing videos. 

I use photos as source material. It's a lot better looking than flickering videos and it's possible to adjust convert parameters easier than with a video with thousands of frames with different zooming on the faces. I tried to do videos, but I had mixed results (with just about all models). In the end, still pictures of models posing gives the best visually seamless faceswap.

I trained more on the same dataset, from 130k to 150k iterations, and the changes are really minute on the converted faces. When comparing, the differences are barely visible.

Further improvements I see are, eventually, the pupils looking more lifelike and also a way to handle, at convert time, the obstacles, like glasses, hair, hand, hats, etc, that cover parts of the destination face.",moment use source material lot better looking flickering possible adjust convert easier video different tried mixed end still posing best visually seamless trained really minute converted barely visible see eventually looking lifelike also way handle convert time like glass hair hand cover destination face,issue,positive,positive,positive,positive,positive,positive
402447200,"@Kirin-kun thank you for your feedback. I think we essentially would need to add mask for eyes to work.
Batch size of `16` has nothing to do with that as it pretty sufficient. For now if you are doing something to produce a video, not just testing the model, I'd suggest to run the training to 300epochs. I know its an overkill but that would probably make the situation a little better with pupils and eye positions.",thank feedback think essentially would need add mask work batch size nothing pretty sufficient something produce video testing model suggest run training know would probably make situation little better eye,issue,negative,positive,positive,positive,positive,positive
402104959,"I tested OriginalHighres with a small dataset and it looks really good. The faces are more detailed and have more depth/defined features than with Original.

A few differences: 

- OriginalHighRes seem to learn gaze direction better
- OriginalhighRes pupils are a little blurrier than Original and the color is lighter/grayish
- OriginalHighRes conversion seem to blend colors better. I had some patches of lighter skin on the cheeks for Original, but OriginalHighres gave better skin tone overall (same convert params)
- OriginalHighRes seem to have difficulties learning Half-open/Closed eyes and Open/Smiling mouth. I'm at 130k iterations and the smiles just start to look like the ones produced much faster by Original.

In then end, the only caveats are the pupils that look a little too like lifeless gray circles, in Original, they are more black so it's less visible. And eventually the smiles showing teeth that look blurred, but I will see if it improves after training more.

Overall, I'm really satisfied with this model. It might become my preferred model. And its memory management is amazing. With a GTX 1060 6gb, I can manage a batch size of 16

",tested small really good detailed original seem learn gaze direction better little original color conversion seem blend color better lighter skin original gave better skin tone overall convert seem learning mouth start look like produced much faster original end look little like lifeless gray original black le visible eventually showing teeth look blurred see training overall really satisfied model might become preferred model memory management amazing manage batch size,issue,positive,positive,positive,positive,positive,positive
402075646,"No, it's unlikely to be the scaling. Landmark detection is done on a 256x256 sample of the original image.

Either way, it isn't directly related to the MTCNN detector, but within the existing landmark detection code. It's something I will probably look at down the line, but as it's not directly related to MTCNN implementation I will shelve it for a future 'improve landmarks detection' project.",unlikely scaling landmark detection done sample original image either way directly related detector within landmark detection code something probably look line directly related implementation shelve future detection project,issue,negative,negative,neutral,neutral,negative,negative
402070915,"Well, DeepFaceLab finds relatively correct landmarks along the jawline with mtcnn and produces a valid aligned face upon extraction:

![450290_04big_debug](https://user-images.githubusercontent.com/36699120/42210717-020d1962-7eb2-11e8-8207-98e7e5870728.png)

![image](https://user-images.githubusercontent.com/36699120/42210786-2dcc70fc-7eb2-11e8-8eca-27d97dab6764.png)

It must be doing something different to achieve its result.

Maybe the upscaling.
",well relatively correct along valid face upon extraction image must something different achieve result maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
402059278,"Ok, the reason this happens is that whilst the face is detected correctly, the fact that the face is mainly obscured means that the landmark detection goes screwy and places most of the landmarks in the wrong place.

These landmarks are then used to align the images, and the process expects a certain landmark layout. The fact that they are all over the place leads to a strange image alignment.

To illustrate, the highlighted landmarks below should be along the jawline:
![image](https://user-images.githubusercontent.com/36920800/42208750-da4db02e-7ea4-11e8-8cd0-e59355b2a2aa.png)


As you can see, they clearly aren't!

As this is edge case, it is not a priority to look into fixing this, so I am closing this issue. As always, unobscured faces will always work best.",reason whilst face correctly fact face mainly landmark detection go screwy wrong place used align process certain landmark layout fact place strange image alignment illustrate along image see clearly edge case priority look fixing issue always unobscured always work best,issue,positive,positive,positive,positive,positive,positive
401738124,"I'm going to look into this. The bounding box comes out of mtcnn correctly `rectangle(296,164,428,378)`, but somewhere in face-alignment it goes wrong",going look bounding box come correctly rectangle somewhere go wrong,issue,negative,negative,negative,negative,negative,negative
401727046,"It's better now.

I still have that case, where Deepfacelab works, but faceswap fails (both with mtcnn):

Difference in the rescaling of the image?",better still case work difference image,issue,negative,positive,positive,positive,positive,positive
401719463,I'll close this one and test. If there's other problems. I'll report.,close one test report,issue,negative,neutral,neutral,neutral,neutral,neutral
401717285,"There was a bug which actually affected all detectors (only generating alignments for the last face of all faces found). 

This has now been squashed in latest commit. I have tested against your dataset and it seems to work as intended, albeit, you get 2 false positives along with the 2 faces. You should be able to eliminate this by tweaking settings (specifically minsize. I found that setting this to 100 eliminated the false positives in your images).

Obviously this value is specific to the images that are being fed in.

Any further feedback is appreciated.",bug actually affected generating last face found latest commit tested work intended albeit get false along able eliminate specifically found setting false obviously value specific fed feedback,issue,negative,positive,neutral,neutral,positive,positive
401701752,"Thanks for this, it's useful. I'll take a look. 

*edit* yep looks like a bug. Will investigate.
",thanks useful take look edit yep like bug investigate,issue,positive,positive,positive,positive,positive,positive
401696349,"A picture is worth a thousand words. So, explain this:

Two pics (mostly SFW). These faces are REALLY easy to detect. Even hog is able to. I used all 4 extractors (dlib-cnn, dlib-hog, mtcnn-faceswap, mtcnn-iperov).

But the mtcnn faceswap (aligned.mtcnn directory) was the only one unable to find the faces. It only found the patterns on the dress -_-;

That's why I think there's a problem somewhere.",picture worth thousand explain two mostly really easy detect even hog able used directory one unable find found dress think problem somewhere,issue,negative,positive,positive,positive,positive,positive
401637911,"The implementation should be exactly the same. MTCNN is MTCNN. It detects faces. It definitely detects more than one face in an image (easy enough to verify),

The only difference from a quick scan of Iperov's code is that he has hardcoded the parameters, whilst faceswap allows these to be adjustable by the user, with the default values left as those provided in the source (facenet).

FWIW, Iperov has amended them to:
mtcnn-minsize - 80.64 (actually calculated by multiplaying scale factor by 0.042. See below)
mtcnn-threshold - 0.7 0.85 0.6
mtcnn-scalefactor - 0.95

Iperov's code also resizes ALL images that go through extraction, regardless of size, to fit to1920px along their longest edge (1850px for dlib). The implementation in faceswap only sizes an image DOWN using the best scaling algorithm available if VRAM is at a premium and it is required. An image will never be upscaled. If you pass in the -v flag it will tell you what your image is being scaled to (if it is being scaled),

I'm not passing judgement on whether one way or the other is better, but my preference is only to resize an image if it needs to be resized... and if it must then to use INTER_AREA interpolation for downsizing.",implementation exactly definitely one face image easy enough verify difference quick scan code whilst adjustable user default left provided source actually calculated scale factor see code also go extraction regardless size fit along edge implementation size image best scaling algorithm available premium image never pas flag tell image scaled scaled passing whether one way better preference resize image need must use interpolation,issue,positive,positive,positive,positive,positive,positive
401622655,"Okay, it works now.

Though, after testing, I must say the mtcnn detector has a lot of problems. It finds faces where there's none and some easy to find faces (that even hog found) are not found/replaced by weird frames containing the whole body, but tilted.

I have a hunch this mtcnn extractor stops when it thinks it has found a single face, even if it's a false positive, when actually there was a real simple-to-find face just a few pixels away.

I don't know how the implementations of mtcnn extractor differ, but the one made by Iperov is better. 

Detected by faceswap mtcnn:
![450290_04big_0](https://user-images.githubusercontent.com/36699120/42137144-b0610b3c-7d67-11e8-8f0a-f128eb48450d.jpg)

Detected by Deepfaceswap mtcnn:
![450290_04big_0](https://user-images.githubusercontent.com/36699120/42137155-c336ba0e-7d67-11e8-9b5f-e10f8091f2e9.png)

I know it's edge case because of the hair, but still...",work though testing must say detector lot none easy find even hog found weird whole body hunch extractor found single face even false positive actually real face away know extractor differ one made better know edge case hair still,issue,positive,positive,neutral,neutral,positive,positive
401619570,That's because I'm an idiot and left a line of testing code in. Sorry about that! Re-pull and try again,idiot left line testing code sorry try,issue,negative,negative,negative,negative,negative,negative
401609425,"staging doesn't work.

For some reason, it stops at the first picture in the folder. I tried with all extractors: same results.
```

(faceenv) C:\Users\Kirin\faceswap>python c:\users\kirin\faceswap\faceswap.py ext
ract -i H:\Fakes\rachel -o H:\Fakes\rachel\aligned -D mtcnn
Using TensorFlow backend.
Output Directory: H:\Fakes\rachel\aligned
Input Directory: H:\Fakes\rachel
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: H:\Fakes\rachel\alignments.json
Starting, this may take a while...
  0%|                                                   | 0/64 [00:00<?, ?it/s]
Writing alignments to: H:\Fakes\rachel\alignments.json
-------------------------
Images found:        64
Faces detected:      1
-------------------------
Done!
```
The  1 face detected is actually the one in the first picture in the directory.

Whereas, in master, with the same pictures, it works, no problem (except the crash at the end):

```
(faceenv) C:\Users\Kirin\faceswap>python c:\users\kirin\faceswap\faceswap.py ext
ract -i H:\Fakes\rachel -o H:\Fakes\rachel\aligned -D cnn
Using TensorFlow backend.
Output Directory: H:\Fakes\rachel\aligned
Input Directory: H:\Fakes\rachel
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: H:\Fakes\rachel\alignments.json
Starting, this may take a while...
  0%|                                                   | 0/64 [00:00<?, ?it/s]I
nfo: initializing keras model...
100%|██████████████████████████████████████████| 64/64 [00:36<00:00,  1.76it/s]
Writing alignments to: H:\Fakes\rachel\alignments.json
-------------------------
Images found:        64
Faces detected:      52
-------------------------
Done!
```",staging work reason first picture folder tried python output directory input directory loading extract starting may take writing found done face actually one first picture directory whereas master work problem except crash end python output directory input directory loading extract starting may take model writing found done,issue,negative,positive,neutral,neutral,positive,positive
401606345,"No offense intended but that could be a conformation bias. I know you know loads more about software than me but I am a hardware guy. I have built countless systems from the ground up and have not seen this error in using the pcie bus before despite massive gpu loads. In addition, while you could be correct in that there are errors that occur between the seating, the error I am seeing is not what is described in your link. I don’t get corruption of the video. I get complete wipeout of the image. Also, people seem to get it a lot with dfaker and that is extremely low batch sizes typically. Also, when face swap was used on my system up until about late March I never had the issue despite using up to 280 batch sizes without problems. It happened after I updated my version to the github repo at that time. I suppose it’s moot anyway since if your right I can’t do anything about it- I did try to replicate it with moving around the cards and wiggling them- it didn’t change anything.  I checked all your recommendations-gpu temp, physically undoing the gpu bridge and disabling the sli option in nvidia software and it still happened with the original model. No overclocking here either. I also used extreme testing in sisoft for hours and no errors. It is probably a two-hit scenario- something in the code is overdoing certain motherboard buses

Sent from my iPhone

> On Jul 1, 2018, at 2:07 AM, bryanlyon <notifications@github.com> wrote:
> 
> I've run the original model to over 400k iterations. It didn't show this problem. However, as soon as I wiggled the GPU in the socket it corrupted similar to this. Other errors similar to this have always been tracked down to hardware issues.
> 
> tensorflow/tensorflow#3912
> 
> We also had someone who had their image turning green, his problem was traced down to hardware issues caused by a factory overclock set by the manufacturer which was fine for gaming, but caused corruption in cuda compute. I highly recommend running your boards at stock (nvidia) speeds only, checking your connection with your motherboard, and making sure that the power supply is sufficient.
> 
> The fact that your lower batch sizes fixed it pretty much confirms (to me) that it's a ram/bus issue since you're now sending FAR less data per pulse across the bus to the ram. Feel free to use Original/highres if that works for you though.
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub, or mute the thread.
",offense intended could conformation bias know know hardware guy built countless ground seen error bus despite massive addition could correct occur seating error seeing link get corruption video get complete image also people seem get lot extremely low batch size typically also face swap used system late march never issue despite batch size without version time suppose moot anyway since right anything try replicate moving around change anything checked temp physically undoing bridge option still original model either also used extreme testing probably something code certain sent wrote run original model show problem however soon socket corrupted similar similar always tracked hardware also someone image turning green problem hardware factory set manufacturer fine gaming corruption compute highly recommend running stock connection making sure power supply sufficient fact lower batch size fixed pretty much issue since sending far le data per pulse across bus ram feel free use work though state reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
401605987,"Try the version in staging and see if it still happens. Extract got refactored, with MTCNN added, so if it fixes your issue, this can be closed. (see #453 for reference)",try version staging see still extract got added issue closed see reference,issue,negative,negative,neutral,neutral,negative,negative
401585349,"I've run the original model to over 400k iterations.  It didn't show this problem.  However, as soon as I wiggled the GPU in the socket it corrupted similar to this.  Other errors similar to this have always been tracked down to hardware issues.

https://github.com/tensorflow/tensorflow/issues/3912

We also had someone who had their image turning green, his problem was traced down to hardware issues caused by a factory overclock set by the manufacturer which was fine for gaming, but caused corruption in cuda compute.  I highly recommend running your boards at stock (nvidia) speeds only, checking your connection with your motherboard, and making sure that the power supply is sufficient.

The fact that your lower batch sizes fixed it pretty much confirms (to me) that it's a ram/bus issue since you're now sending FAR less data per pulse across the bus to the ram.  Feel free to use Original/highres if that works for you though.",run original model show problem however soon socket corrupted similar similar always tracked hardware also someone image turning green problem hardware factory set manufacturer fine gaming corruption compute highly recommend running stock connection making sure power supply sufficient fact lower batch size fixed pretty much issue since sending far le data per pulse across bus ram feel free use work though,issue,positive,positive,positive,positive,positive,positive
401579548,"I haven't used dfaker yet, mainly just faceswap.  I am sure it would
probably happen to me.  I don't really believe its the bus, I think its
something software related, because I can run the originalhighres and I
have not had it happen yet.

On Sat, Jun 30, 2018 at 10:35 PM, Picslook <notifications@github.com> wrote:

> Alright. On my part I only get it using dfaker; all other trainers work
> fine. Makes it difficult to reuse a model since it breaks before it reaches
> an acceptable level of progress. If I do a whole new model it breaks only
> after 2-3 days. Really don't know what's going on and how it could be
> related to the GPU bus, but thanks anyway.
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/310#issuecomment-401578883>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AibL7V8THgElLBvTreqBh-pMAiLTvvgmks5uCDV0gaJpZM4S5nDj>
> .
>
",used yet mainly sure would probably happen really believe bus think something related run happen yet sat wrote alright part get work fine difficult reuse model since acceptable level progress whole new model day really know going could related bus thanks anyway state reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
401578883,"Alright. On my part I only get it using dfaker; all other trainers work fine. Makes it difficult to reuse a model since it breaks before it reaches an acceptable level of progress. If I do a whole new model it breaks only after 2-3 days. Really don't know what's going on and how it could be related to the GPU bus, but thanks anyway.",alright part get work fine difficult reuse model since acceptable level progress whole new model day really know going could related bus thanks anyway,issue,positive,positive,neutral,neutral,positive,positive
401286897,"Thanks so much for replying, but could you please further explain the transparency(alpha) channel means? And what is the purpose to use it here?",thanks much could please explain transparency alpha channel purpose use,issue,positive,positive,positive,positive,positive,positive
401282921,"The way I see it, it's to have a different activation function for the alpha (transparency) channel than for the rgb channels and then concatenate the convolution kernels.",way see different activation function alpha transparency channel concatenate convolution,issue,negative,neutral,neutral,neutral,neutral,neutral
400788665,"Not really, though I haven’t had it happen with the original high res trainer. Bryanlyon thinks it is some issue with the communication between my gpu and the bus. 

Sent from my iPhone

> On Jun 27, 2018, at 1:48 PM, Picslook <notifications@github.com> wrote:
> 
> Did you ever figure out how to prevent this? I am still getting this same issue with dfaker
> 
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub, or mute the thread.
",really though happen original high trainer issue communication bus sent wrote ever figure prevent still getting issue state reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
400771764,Did you ever figure out how to prevent this? I am still getting this same issue with dfaker,ever figure prevent still getting issue,issue,negative,neutral,neutral,neutral,neutral,neutral
400655126,"Those are options during the conversion, not the training. -mh activates histogram matching and with -e you can set the erosion kernel size.",conversion training histogram matching set erosion kernel size,issue,negative,neutral,neutral,neutral,neutral,neutral
400649215,"@andenixa thanks a lot - forgive me to ask again, how did you 
- enable histogram matching
- mask erosion
- smoothing
with the faceswap.py command? I didn't see these options, the closest was perceptual loss...",thanks lot forgive ask enable histogram matching mask erosion smoothing command see perceptual loss,issue,negative,positive,positive,positive,positive,positive
400622175,"@eziohonor I don't think you need `-pl` since Original models do not support it. I would also add `-ag` (allow growth) as it generally helps with OOM situations (though it won't work with multi GPU scenarios), and last, `-bs 24` is more than enough to train autoencoders. I should say `-bs 128` is suboptimal for most cases (if you can do `-bs 128` you can just use a more sophisticated model instead).",think need since original support would also add allow growth generally though wo work last enough train say suboptimal use sophisticated model instead,issue,positive,positive,positive,positive,positive,positive
400603404,OriginalHiRes uses a lot of VRAM even on a 1080. It is highly unlikely it would run at batch size 128 (although @andenixa  could clarify). Reduce the batchsize down and you should be able to get it to run.,lot even highly unlikely would run batch size although could clarify reduce able get run,issue,negative,neutral,neutral,neutral,neutral,neutral
400602597,"@torzdf  it's gtx 1080.Well,I think it's enough to run batch size128",think enough run batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
400600768,"What gfx card are you using?

Either way, I think you'd need to significantly lower your batch size,",card either way think need significantly lower batch size,issue,negative,positive,positive,positive,positive,positive
400485824,"output_dir.mkdir hasn't been touched since February 1st (c3e15089fe355d8783a8b00b2a4d8b89e4f90870), so it's likely the problem is with your install, I'm afraid.

You could try using Python 3.5 which is the version that faceswap is developed in",touched since st likely problem install afraid could try python version,issue,negative,negative,negative,negative,negative,negative
400418023,"So when I delete an image from aligned images folder, like some extract image that is not a face, this object will show up as a blur/articfact in the converted image. This used to work, but with the latest releases in github this is a problem.

Steps to reproduce, delete a extra image(like something that is not a face) from aligned images, convert image.
",delete image folder like extract image face object show converted image used work latest problem reproduce delete extra image like something face convert image,issue,negative,positive,positive,positive,positive,positive
400330263,"@agilebean its regular seamless mode on the left and masked with slight smoothing at the right side.
Both modes use histogram matching. I use a slight mask erosion (about 10-15%). That's pretty much everything. 
I suggest to not use any sharpening parameter to avoid the mask to be visible.",regular seamless mode left masked slight smoothing right side use histogram matching use slight mask erosion pretty much everything suggest use parameter avoid mask visible,issue,negative,positive,neutral,neutral,positive,positive
400292013,"Yes, I can confirm that the last reported bug (json expects str or bytes) is fixed.
OriginalHighRes works!
Thanks a lot to @andenixa and @torzdf for this extremely short turnaround time, really incredible.",yes confirm last bug fixed work thanks lot extremely short turnaround time really incredible,issue,positive,positive,positive,positive,positive,positive
400288700,"Dear @andenixa, your video looks incredible.
How did you achieve this nearly seamless face replacement?
No matter which model I use, the superimposed mask looks clearly above the background body.
Did you use any smoothing algorithm?",dear video incredible achieve nearly seamless face replacement matter model use superimposed mask clearly background body use smoothing algorithm,issue,positive,positive,positive,positive,positive,positive
400286293,"It works - wonderful!
It definitely renders better than results than the Original trainer with 10.000 iterations.
Great job @andenixa !!!",work wonderful definitely better original trainer great job,issue,positive,positive,positive,positive,positive,positive
400271790,"@tjess78 in my experience any 128x model is able to generate realistic consistent eyeballs.

To achieve that all that is needed to:
- raise `Dense layer` dimensions by about 50%
- add additional `Conv2d layer` before to the last one.
- train your Net at `-bs 16` or higher for ~120k epochs 

This [video](https://www.youtube.com/watch?v=j7KMep1PC2U) was made by me using a Non-GAN autoencoder model using the instructions above. The video is SFW.

Prerequisites for `data set -B` is that it shall:
- consist of crystal crisp frames with no blur or smudges
- should not contain pics with partially obscured faces 
- have even lighting conditions, i.e. no blinds shadows overlapping the face
- have approximately same number of frames for every angle with very similar shots removed to expedite the training
",experience model able generate realistic consistent achieve raise dense layer add additional layer last one train net higher video made model video data set shall consist crystal crisp blur contain partially even lighting face approximately number every angle similar removed expedite training,issue,negative,positive,neutral,neutral,positive,positive
400223529,"Either way this looks like a local install problem rather than a faceswap problem. Closing.

Please re-open if you have more information.",either way like local install problem rather problem please information,issue,negative,neutral,neutral,neutral,neutral,neutral
400222848,"There was a bug introduced in a recent commit. this should have been fixed in f90cd92ec36a0860c58a75631f762069419149de

Re-pull.",bug recent commit fixed,issue,negative,positive,neutral,neutral,positive,positive
400124951,"**GAN v2.2 release**

2018-06-25 Model update: faceswap-GAN v2.2 has been released. The main improvements of v2.2 model are its capability of generating realistic and consistent eyeballs (results are shown below, or Ctrl+F for eyeballs), as well as its higher quality of video results with face alignment.

[Faceswap-GAN](https://github.com/shaoanlu/faceswap-GAN)

",gan release model update main model capability generating realistic consistent shown well higher quality video face alignment,issue,negative,positive,positive,positive,positive,positive
400008274,Try latest commit. Looks like a bug was introduced with a recent model change,try latest commit like bug recent model change,issue,positive,positive,positive,positive,positive,positive
399935640,Thanks for the feedback. Effmpeg for the gui is in alpha/beta at the moment. We will look at this as soon as we can.,thanks feedback moment look soon,issue,negative,positive,positive,positive,positive,positive
399916261,"OS Version: Windows 10
command generated: python C:\faceswap\tools.py effmpeg -a extract -i input -fps -1.0 -ef .png -s 00:00:00 -e 00:00:00 -d 00:00:00 -sc 1920x1080
pip-freeze: C:\Users\kwg20>pip freeze
absl-py==0.2.2
astor==0.6.2
bleach==1.5.0
click==6.7
cloudpickle==0.5.3
cmake==3.11.0
cycler==0.10.0
dask==0.18.0
decorator==4.3.0
dlib==19.13.1
face-recognition==1.2.2
face-recognition-models==0.3.0
ffmpy==0.2.2
gast==0.2.0
grpcio==1.12.1
h5py==2.8.0
html5lib==0.9999999
Keras==2.2.0
Keras-Applications==1.0.2
Keras-Preprocessing==1.0.1
kiwisolver==1.0.1
Markdown==2.6.11
matplotlib==2.2.2
networkx==2.1
numpy==1.14.5
opencv-python==3.4.1.15
pathlib==1.0.1
Pillow==5.1.0
protobuf==3.6.0
pyparsing==2.2.0
python-dateutil==2.7.3
pytz==2018.4
PyWavelets==0.5.2
PyYAML==3.12
scandir==1.7
scikit-image==0.14.0
scipy==1.1.0
six==1.11.0
tensorboard==1.8.0
tensorflow-gpu==1.5.0
tensorflow-tensorboard==1.5.1
termcolor==1.1.0
toolz==0.9.0
tqdm==4.23.4
Werkzeug==0.14.1",o version command python extract input pip freeze,issue,negative,neutral,neutral,neutral,neutral,neutral
399672197,@agilebean shall be fixed in the next merge today. Thanks for providing the valuable feedback thus I could further deploy models without these issues.,shall fixed next merge today thanks providing valuable feedback thus could deploy without,issue,positive,positive,positive,positive,positive,positive
399505887,"@torzdf can you re-open this issue?
Tried latest commit, the PosixPath problem seems to be fixed, but now convert.py throws a JSON error. 
Strack trace:
```
Using TensorFlow backend.
Output Directory: /home/agilebean/faceswap/output
Input Directory: /home/agilebean/faceswap/input_images
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: /home/agilebean/faceswap/input_images/alignments.json
Aligned directory not specified. All faces listed in the alignments file will be converted
Loading Model from Model_OriginalHighRes plugin...
Traceback (most recent call last):
  File ""faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""/home/agilebean/faceswap/lib/cli.py"", line 81, in execute_script
    process.process()
  File ""/home/agilebean/faceswap/scripts/convert.py"", line 42, in process
    model = self.load_model()
  File ""/home/agilebean/faceswap/scripts/convert.py"", line 70, in load_model
    if not model.load(self.args.swap_model):
  File ""/home/agilebean/faceswap/plugins/Model_OriginalHighRes/Model.py"", line 125, in load
    state = ser.unmarshal(fp.read())
  File ""/home/agilebean/faceswap/lib/Serializer.py"", line 54, in unmarshal
    return json.loads(input_string)
  File ""/usr/lib/python3.5/json/__init__.py"", line 312, in loads
    s.__class__.__name__))
TypeError: the JSON object must be str, not 'bytes'
```",issue tried latest commit problem fixed error strack trace output directory input directory loading extract directory listed file converted loading model recent call last file line module file line file line process model file line file line load state file line return file line object must,issue,negative,positive,positive,positive,positive,positive
399400526,@torzdf will this Windows 10 fix also fix the different problem on Ubuntu? ,fix also fix different problem,issue,negative,neutral,neutral,neutral,neutral,neutral
399368579,"More information required.

Platform, pip-freeze, command you were running etc.",information platform command running,issue,negative,neutral,neutral,neutral,neutral,neutral
399368312,"Yes, someone needs to develop a model that can handle it.
",yes someone need develop model handle,issue,negative,neutral,neutral,neutral,neutral,neutral
399303353,"That mean’s It is no solution at now, please need to wait for new function development for handler the occlusion training?

",mean solution please need wait new function development handler occlusion training,issue,positive,negative,neutral,neutral,negative,negative
399299969,"It's not a bug, try selecting a different video/images instead.",bug try different instead,issue,negative,neutral,neutral,neutral,neutral,neutral
399299514,Would you explain more details for action step by step?It is look like difficult...,would explain action step step look like difficult,issue,negative,negative,negative,negative,negative,negative
399294621,"This is not a bug, it's a model limitation,  It may try to remove any occlusions, but it's trained to recreate a source accurately so it will keep occlusions.  We'd need to define a new loss function to enable occlusions removal without losing things like expression and lighting, which we want to keep.",bug model limitation may try remove trained recreate source accurately keep need define new loss function enable removal without losing like expression lighting want keep,issue,negative,positive,positive,positive,positive,positive
399102559,"@torzdf @agilebean 
Quite so, I am working at bringing DF model to faceswap. I am not sure if outperformed term applies here. DF is a full-face model which faceswap is lacking. I would't presume it necessarily has better quality, perhaps better result because of more face coverage. From my experience deepfakes.clup is isn't inhabited by the most technically savvy people.",quite working model sure term model presume necessarily better quality perhaps better result face coverage experience inhabited technically savvy people,issue,positive,positive,positive,positive,positive,positive
399095184,I think @andenixa is working on a new version of this,think working new version,issue,negative,positive,positive,positive,positive,positive
399093343,"it seems this pull request was abandoned.
is anybody working to resolve the conflicts? 
it would be great as the dfaker plugin [outperformed faceswap](https://www.deepfakes.club/best-hardware-software-deepfakes/#Faceswap_versus_dfaker_competition), so this would merge would substantially close the gap!",pull request abandoned anybody working resolve would great would merge would substantially close gap,issue,positive,positive,positive,positive,positive,positive
399049350,"@AbysmalBiscuit This is now synced with master. Could you resolve the conflicts please.

Thanks",master could resolve please thanks,issue,positive,positive,positive,positive,positive,positive
398957221,All devs are currently busy on our own priorities.  We welcome PRs if you add support.,currently busy welcome add support,issue,positive,positive,positive,positive,positive,positive
398882286,"There is no neural model to morph segments of one face to other face . For example area of skin of source face smaller than target face, and target face has more hair. You think autoencoder will draw more skin and hair ? No.
Therefore subj is not relevant.
",neural model morph one face face example area skin source face smaller target face target face hair think draw skin hair therefore relevant,issue,negative,positive,positive,positive,positive,positive
398873090,"any updates on this?
i think a better face segmentation would greatly improve results for visual perception and higher versatility!",think better face segmentation would greatly improve visual perception higher versatility,issue,positive,positive,positive,positive,positive,positive
398691007,Glad you got a solution that works 👍 ,glad got solution work,issue,positive,positive,positive,positive,positive,positive
398689378,"Dear @torzdf, for your tips I want to [buy you a coffee](https://www.buymeacoffee.com) - if you have an account please send it to me. 

For everyone who is desperate for automation:
I found a workaround without preview that works!
It waits (wait $!) for the process to finish (&), and then just continues.
```
python3 faceswap.py train -A  $INPUT_FACE_DIR -B  $STYLE_FACE_DIR -ep $NUM_EPOCHS &
wait $!
```
",dear want buy coffee account please send everyone desperate found without preview work wait process finish python train wait,issue,negative,negative,negative,negative,negative,negative
398684986,"I'd guess that you don't have an x-server installed. You can either install an x-server, which will hopefully fix your issue, or try xvnc, which should act as an x-server for vnc (I haven't used it for a while).
https://www.hep.phy.cam.ac.uk/vnc_docs/xvnc.html

To install a minimal X11 on Ubuntu Server Edition enter the following:

`sudo apt install xorg`

You can test whether your x-server is working by installing  x11-apps:
`sudo apt install x11-apps`

launching vnc4server (as above) and then:

`DISPLAY=:3 ; xclock`
If you can connect to the vnc-server then it should have popped a clock. Even if you can't connect, you should know whether it works because you will either get the X server error, or you won't.

As for your second point, I don't think most people use the epoch flag. The current solution is far from ideal, but having to wait for epochs to finish after pressing enter would not be ideal.
",guess either install hopefully fix issue try act used install minimal server edition enter following apt install test whether working apt install connect clock even ca connect know whether work either get server error wo second point think people use epoch flag current solution far ideal wait finish pressing enter would ideal,issue,positive,positive,positive,positive,positive,positive
398679100,"Thanks again for the tip. 
I deeply appreciate your great spirit to help!
And that's why I am even more sad that I couldn't get it running. Your instructions with piping to vncserver worked, but as before, the models are not saved. I tried it three times to be sure. The model folder only contains the encoder files `encoder.h5  encoder.h5.bk`.

Any ideas here? I included the stack trace below. The only hint I see is `cannot connect to X server .23394` which may or may not be related to vncserver...

Apart from that, would you consider any modifications to the source code so the training stops by CTR+C, Enter *AND* after finishing the specified number of epochs? I think that would be a small step but a great improvement because it allows to automate the whole process. 


```
/home/agilebean/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Model A Directory: /home/agilebean/faceswap/input_faces
Model B Directory: /home/agilebean/faceswap/style_faces
Training data directory: models
Loading data, this may take a while...
Using live preview.
Press 'ENTER' on the preview window to save and quit.
Press 'S' on the preview window to save model weights immediately
Loading Model from Model_Original plugin...
WARNING:tensorflow:From /home/agilebean/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /home/agilebean/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
Failed loading existing training data.
""Can't open attribute (can't locate attribute: 'weight_names')""
Loading Trainer from Model_Original plugin...
: cannot connect to X server .23394, loss_B: 0.18140
8: line 155: 24356 Segmentation fault      (core dumped) python3 faceswap.py train -A $INPUT_FACE_DIR -B $STYLE_FACE_DIR -ep $NUM_EPOCHS -p
```",thanks tip deeply appreciate great spirit help even sad could get running piping worked saved tried three time sure model folder included stack trace hint see connect server may may related apart would consider source code training enter finishing number think would small step great improvement whole process conversion second argument float future float import model directory model directory training data directory loading data may take live preview press preview window save quit press preview window save model immediately loading model warning calling removed future version use instead warning calling removed future version use instead loading training data ca open attribute ca locate attribute loading trainer connect server line segmentation fault core python train,issue,positive,positive,positive,positive,positive,positive
398368262,As @andenixa says. Anyone is welcome to open a PR to port other models.,anyone welcome open port,issue,negative,positive,positive,positive,positive,positive
398367837,"What do you mean that the models are not saved with the -p flag set? They should be. It should act just like the command line, just with generating a preview. Actually, it may be like you say, because it can't generate the preview.

to pipe the display, first launch vnc4server on an unused display (in my example I'lll use display 3):

`vnc4server :3`

Then launch faceswap pointing at that display:

`DISPLAY=:3 ; python faceswap.py ...`

The added advantage of this is that you can connect via vnc client to see how the preview is getting on.

For added security I usually run all of this in a screen session so it carries on if I lose connection




",mean saved flag set act like command line generating preview actually may like say ca generate preview pipe display first launch unused display example use display launch pointing display python added advantage connect via client see preview getting added security usually run screen session lose connection,issue,positive,negative,neutral,neutral,negative,negative
398331606,I have been try his work. And result looks good .Just hope if we have gui version and put all together inside here as a team. ,try work result good hope version put together inside team,issue,positive,positive,positive,positive,positive,positive
398324524,"@ruah1984 I don't want do put you off as we might actually port some of these models eventually.
But if you are really interested in testing Iperov's models I may suggest just using his fork for the purpose as everything is already in place there.

@Kirin-kun Iperov says he doesn't mind if some of his work is to be ported to faceswap. I actually asked his permission twice and he said I don't need his permission.",want put might actually port eventually really interested testing may suggest fork purpose everything already place mind work ported actually permission twice said need permission,issue,positive,positive,neutral,neutral,positive,positive
398314674,"Since it's open source, I suppose anyone, with proper credit given, can port Iperov ideas here. 

But don't expect him to help.",since open source suppose anyone proper credit given port expect help,issue,positive,neutral,neutral,neutral,neutral,neutral
398310993,"Thanks for the tip -
very unfortunately the models are not saved with the -p flag set.
maybe because I'm running headless ubuntu?
@torzdf was that the reason you told me to run vnc4server? 
and how would I pipe the preview - right after the `faceswap.py train ... -p | <pipe into sth>` ?
",thanks tip unfortunately saved flag set maybe running headless reason told run would pipe preview right train pipe,issue,positive,negative,neutral,neutral,negative,negative
398263718,"can any one integrate  Iperov DeepFacelab to here? Because i think Deepfakes master here should include all kind of faceswap model study .  i not sure what will be the different but , i hope master here can include all different deepfakes model such as DFaker, original model, low memory model , LIAEF128YAW (5GB+)",one integrate think master include kind model study sure different hope master include different model original model low memory model,issue,positive,positive,positive,positive,positive,positive
397950643,"@AbysmalBiscuit is working on the effmpeg code at the moment.

Please feel free to raise a PR for multilanguage support. If you need any pointers you can ask in discord",working code moment please feel free raise support need ask discord,issue,positive,positive,positive,positive,positive,positive
397936983,"So excited about the GUI V3.0.0.a. I tried it but the effmpeg didn't work when I clicked the output folder
https://s1.ax1x.com/2018/06/18/CxDO5n.png

I input manually and clicked the effmepg, the windows closed. 

I tried Extract, train, and convert, it works fine. 
I used Windows7

May I ask if I could translate the GUI language?

",excited tried work output folder input manually closed tried extract train convert work fine used may ask could translate language,issue,negative,positive,positive,positive,positive,positive
397893073,You're also welcome to patch out the waiting for enter in your copy.  See previous requests for this feature for details.,also welcome patch waiting enter copy see previous feature,issue,negative,positive,positive,positive,positive,positive
397865961,"This is a slightly frustrating quirk of how the process waits for Enter to terminate. There is no obvious way to bypass it at the moment if you don't generate a preview (as you will have noticed, it reaches the target epoch then just waits for CTRL+C or ENTER).

However, there is a workaround. If you use the -p flag to show a preview, when it reaches the target epoch, the preview will close and training will terminate.

From train.py:

```
        # TODO: how to catch a specific key instead of Enter?
        # there isn't a good multiplatform solution:
        # https://stackoverflow.com/questions/3523174
        # TODO: Find a way to interrupt input() if the target iterations are reached.
        # At the moment, setting a target iteration and using the -p flag is
        # the only guaranteed way to exit the training loop on hitting target
        # iterations.
```

If you are running headless, you could run something like vnc4server and pipe the preview to an unused display

Also see #330",slightly quirk process enter terminate obvious way bypass moment generate preview target epoch enter however use flag show preview target epoch preview close training terminate catch specific key instead enter good solution find way interrupt input target moment setting target iteration flag way exit training loop target running headless could run something like pipe preview unused display also see,issue,positive,positive,positive,positive,positive,positive
397794905,"@linkoid What screen resolution are you running? Have you any strange DPI settings? I've just fired it up in windows 10 and it displays fine for me. Could you provide a screengrab?

Thanks",screen resolution running strange fired fine could provide thanks,issue,negative,positive,positive,positive,positive,positive
397787716,"People who are short on vram can adjust the settings.

```
ENCODER_DIM = 512

x = Dense(dense_shape * dense_shape * 1024)(x)
x = Reshape((dense_shape, dense_shape, 1024))(x)

x = self.upscale(512, kernel_initializer=RandomNormal(0, 0.02))(inpt)
x = self.upscale(256, kernel_initializer=RandomNormal(0, 0.02))(x)

```
I trained up to 100k with it(-bs 8). the quality is still better than the original 64. The speed is also acceptable. ",people short adjust dense reshape trained quality still better original speed also acceptable,issue,positive,positive,positive,positive,positive,positive
397677868,"@tjess78 seems to be a genuine OOM. What batch size do you use and are there any other programs that use video memory are running in the background?
I generally test with a clean environment and a dedicated card. You might probably want to disable Aero theme and switch to basic altogether. Also close any applications such as web browser that highly utilize video memory. You should be able to run it with batch sizes 8-13 (depending on free ram).",genuine batch size use use video memory running background generally test clean environment card might probably want disable aero theme switch basic altogether also close web browser highly utilize video memory able run batch size depending free ram,issue,positive,positive,positive,positive,positive,positive
397633127,"Narf, I don't get it. No matter what I do, it will not run on my 1060 6GB. 
Here is the error. tried it with last push from gui 3.0 and andenixa patch 1, 2 and 2-1. Could it be an error in my eviroment? 

Exception in thread Thread-1:
Traceback (most recent call last):
File ""d:\ProgramData\Anaconda3\envs\gui\lib\threading.py"", line 914, in _bootstrap_inner
self.run()
File ""d:\ProgramData\Anaconda3\envs\gui\lib\threading.py"", line 862, in run
self._target(*self._args, **self._kwargs)
File ""D:\faceswap-and\scripts\train.py"", line 97, in process_thread
raise err
File ""D:\faceswap-and\scripts\train.py"", line 89, in process_thread
self.run_training_cycle(model, trainer)
File ""D:\faceswap-and\scripts\train.py"", line 124, in run_training_cycle
trainer.train_one_step(epoch, viewer)
File ""D:\faceswap-and\plugins\Model_OriginalHighRes\Trainer.py"", line 39, in train_one_step
loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
File ""d:\ProgramData\Anaconda3\envs\gui\lib\site-packages\keras\engine\training.py"", line 1220, in train_on_batch
outputs = self.train_function(ins)
File ""d:\ProgramData\Anaconda3\envs\gui\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2661, in __call__
return self._call(inputs)
File ""d:\ProgramData\Anaconda3\envs\gui\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2631, in _call
fetched = self._callable_fn(*array_vals)
File ""d:\ProgramData\Anaconda3\envs\gui\lib\site-packages\tensorflow\python\client\session.py"", line 1454, in __call__
self._session._session, self._handle, args, status, None)
File ""d:\ProgramData\Anaconda3\envs\gui\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 519, in __exit__
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[65536,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[[Node: training_1/Adam/gradients/model_1/dense_1/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[""loc:@training_1/Adam/gradients/model_1/dense_1/MatMul_grad/MatMul""], transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_1/flatten_1/Reshape, training_1/Adam/gradients/model_1/dense_2/MatMul_grad/MatMul)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

",get matter run error tried last push patch could error exception thread recent call last file line file line run file line raise err file line model trainer file line epoch viewer file line file line file line return file line fetched file line status none file line tensor shape type float allocator node hint want see list add current allocation,issue,negative,neutral,neutral,neutral,neutral,neutral
397612749,@andenixa you should join https://discord.gg/FdEwxXd is useful for bouncing around ideas / communicating with the other devs,join useful bouncing around communicating,issue,positive,positive,positive,positive,positive,positive
397606960,"@Kirin-kun 
The OriginalHighRes encoder is no more mine than its just a revamp of faceswap's original model to a new size. Besides you need to use use DeepFaceLab for to use H128 which is a very good repo, but it isn't faceswap.

I should think Iperov models are better, specially *LIAEF128 ones. Definitely faster with his new K.function design.  But I don't know for sure because I never used his H128.",mine revamp original model new size besides need use use use good think better specially definitely faster new design know sure never used,issue,positive,positive,positive,positive,positive,positive
397605741,"@Jasas9754 
1) I think shaoanlu has better generalization, but you are not required to use it.
2. conv_sep takes less memory, but the final result is not different from conv, though it might be slower to catch up at later stages. Encoder dim is very important specially with unmasked auto-encoders. In fact its plays a great role for both learning, clarity, and better reconstruction. Though we don't always have the luxury to make it big enough because of video memory.",think better generalization use le memory final result different though might catch later dim important specially unmasked fact great role learning clarity better reconstruction though always luxury make big enough video memory,issue,positive,positive,positive,positive,positive,positive
397603313,"@andenixa 
1.What are the benefits of 'shaoanlu' type? I don't think it's learning faster than the original, or clearer. What's the advantage?
2. You have raised encoder dim to 1024(not 512) and changed conv to conv_sep. Do you think encoder dim is more important?

Thank you",type think learning faster original clearer advantage raised dim think dim important thank,issue,positive,positive,positive,positive,positive,positive
397601436,"I tested it. Seems to be learning rather well both performance and quality-wise.
Further increasing of image size would require a mask otherwise it won't converge because of the background and Dense limitations (due to memory).
You may expect increase of both image quality as there is much room for the improvement. I might also be implementing re-loading of old saved weights and re-sizing it to fit the new topology if that is reasonably practical.",tested learning rather well performance increasing image size would require mask otherwise wo converge background dense due memory may expect increase image quality much room improvement might also old saved fit new topology reasonably practical,issue,positive,positive,positive,positive,positive,positive
397596736,"hmn, latest push still says OOM in both modes, even with batch size 2 on GTX 1060 6Gb",latest push still even batch size,issue,negative,positive,positive,positive,positive,positive
397596351,"Is your original encoder 128 better than, or equivalent to, Iperov's H128?

I got pretty good results with his model.",original better equivalent got pretty good model,issue,positive,positive,positive,positive,positive,positive
397577448,"@Kirin-kun I apologize for not testing with 6Gb card prior to making a PR.
Currently I made a PR with the fixed model to staging; you are very welcome to test.
ATM I am able run the training with geforce gtx 9800 ti (6GB) and maximum batch size of 12. 
That should be sufficient for good results. 

I could squeeze memory requirements much further, but my intentions were to provide a full scale 128x128 model and I don't want to make a crippled version of it. 

As for Shaoanlu encoder its probably off-limits for 6GB, however it has not been proven that it has better results, but mostly opinion based. ORIGINAL autoencoder is set to default from now on.",apologize testing card prior making currently made fixed model staging welcome test able run training ti maximum batch size sufficient good could squeeze memory much provide full scale model want make version probably however proven better mostly opinion based original set default,issue,positive,positive,positive,positive,positive,positive
397576218,"Latest commit:
Fix issue with graphing when commencing training (@LordOEQJen )
Bump matplotlib version to hopefully fix issues with the navigation toolbar (You will need to update your matplotlib to at least version 2.2.2 if you are having issues)
Fix Progress bar for sort/tools
Merge @andenixa 6GB memory fix for highres model",latest commit fix issue training bump version hopefully fix navigation need update least version fix progress bar merge memory fix model,issue,positive,positive,neutral,neutral,positive,positive
397575115,"@Kirin-kun thats confirmed for 6GB cards. Shall be fixed ASAP.
PS: Don't even try batch sizes like 2. If it doesn't work at least with 4 that pretty much proves it.",thats confirmed shall fixed even try batch size like work least pretty much,issue,negative,positive,positive,positive,positive,positive
397563897,"I added a warning to the help text in c3a047559b516fae6a7f26535b1131d991ab2398. In the absence of a better solution, I'm closing this issue.",added warning help text absence better solution issue,issue,positive,positive,positive,positive,positive,positive
397562628,"Please keep model 128 talk to issue #385, thanks",please keep model talk issue thanks,issue,positive,positive,positive,positive,positive,positive
397562191,"@linkoid, you raise some interesting ideas. If you are able to create a working model, then please submit to the repo. We can even put it in staging if it's not fully working and you want other people to help.

In the meantime, I'm closing this issue, but feel free to re-open if you make any progress.",raise interesting able create working model please submit even put staging fully working want people help issue feel free make progress,issue,positive,positive,positive,positive,positive,positive
397561277,"I agree, that would be useful, but it isn't a minor undertaking, so it's certainly not a priority for me.

Anyone is welcome to implement such a feature though and raise a PR. In the meantime, I will tag this with feature request and close. ",agree would useful minor undertaking certainly priority anyone welcome implement feature though raise tag feature request close,issue,positive,positive,positive,positive,positive,positive
397537216,Better not commit this to master yet.,better commit master yet,issue,positive,positive,positive,positive,positive,positive
397536901,"Pretty unusable with a GTX 1060 6Gb. 

Even with a batch size of **2** it crashed with OOM.

It's untestable.",pretty unusable even batch size untestable,issue,negative,positive,positive,positive,positive,positive
397525757,"Sweet, I'll check it out.

El vie., 15 de jun. de 2018 12:40 a. m., torzdf <notifications@github.com>
escribió:

> Updated with latest Original 128 mode from @andenixa
> <https://github.com/andenixa>
> tools.py bug fixed (should execute now)
> ffmpeg potentially fixed (needs testing)
>
> Some reworking of the code done, so please report any new bugs.
>
> Thanks
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/412#issuecomment-397459643>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAAGgq7T_JuKmTNoG0YvglFN8s7ngccaks5t8uZKgaJpZM4UYCzG>
> .
>
",sweet check el de de latest original mode bug fixed execute potentially fixed need testing code done please report new thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
397479389,"There have been a lot of improvements.  Whether they fit what you want, you'll have to check for yourself.  Future questions like this should be posted in https://github.com/deepfakes/faceswap-playground",lot whether fit want check future like posted,issue,positive,positive,positive,positive,positive,positive
397459643,"Updated with latest Original 128 mode from @andenixa 
tools.py bug fixed (should execute now)
ffmpeg potentially fixed (needs testing)

Some reworking of the code done, so please report any new bugs.

Thanks",latest original mode bug fixed execute potentially fixed need testing code done please report new thanks,issue,positive,positive,positive,positive,positive,positive
396947922,"@scarecrow2415 what version of matplotlib are you using? Try re-installing the latest version of matplotlib. I'll bump the version requirements.

",scarecrow version try latest version bump version,issue,negative,positive,positive,positive,positive,positive
396810243,"python faceswap.py gui
Traceback (most recent call last):
  File ""faceswap.py"", line 36, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\cli.py"", line 79, in execute_script
    script = self.import_script()
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\cli.py"", line 28, in import_script
    module = import_module(mod)
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 665, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 678, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\scripts\gui.py"", line 11, in <module>
    from lib.gui import CurrentSession, CommandNotebook, Config, ConsoleOut
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\gui\__init__.py"", line 2, in <module>
    from lib.gui.display import DisplayNotebook
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\gui\display.py"", line 10, in <module>
    from .display_analysis import Analysis
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\gui\display_analysis.py"", line 8, in <module>
    from .display_graph import SessionGraph
  File ""C:\Users\kwg20\Desktop\test\pythondf\pythondf\python-3.6.3.amd64\faceswap-gui-v3.0\lib\gui\display_graph.py"", line 14, in <module>
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
ImportError: cannot import name 'NavigationToolbar2Tk'

why is this happening?",python recent call last file line module file line script file line module file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file line module import file line module import file line module import analysis file line module import file line module import import name happening,issue,negative,neutral,neutral,neutral,neutral,neutral
396806990,"That's the point, when it comes to the sorting tool. Sorting by hist-dissim (histogram dissimilarity), deleting all pictures at the end of the directory.

Btw.: Why is in faceswap's sorting tool the option ""group"" existing ? Only know that one from Iperov's script",point come tool histogram dissimilarity end directory tool option group know one script,issue,negative,neutral,neutral,neutral,neutral,neutral
396591572,"@tjess78 
One thing when testing, regardless the common opinion that both sets ought to be huge, its better to keep set B (your target face) rather small and clean. No more than 2000-3000 crisp shots that would include diverse directions, lighting and expressions. Shots which are too similar don't help the learning but rather slow it down.",one thing testing regardless common opinion ought huge better keep set target face rather small clean crisp would include diverse lighting similar help learning rather slow,issue,positive,positive,neutral,neutral,positive,positive
396588340,"@andenixa thanks for the response! Good to know, I will test both modes with several data-sets",thanks response good know test several,issue,positive,positive,positive,positive,positive,positive
396582888,"@tjess78 sure. Basically apart from GAN which ain't performing too well Shaoanlu uses a unique activation with Convolution layers which is different from LeakyRelu used by most if not all Autoencoder models. 
I did several experiments and in many cases Shaoanlu activation provides better generalization at an increased memory and computational cost. So by default OriginalHighRes model uses Shaoanlu Encoder's and decoder (minus mask and GAN part, obviously). If you are getting Recourse Exhausted exceptions or just find the training is taking too long you could switch to `ENCODER = EncoderType.ORIGINAL` in `Model.py` file which is far less computationally extensive. It might even give you a better result depending on the data-sets.",sure basically apart gan ai well unique activation convolution different used several many activation better generalization memory computational cost default model minus mask gan part obviously getting recourse exhausted find training taking long could switch file far le extensive might even give better result depending,issue,positive,positive,positive,positive,positive,positive
396550969,"@andenixa nice to hear! 
Could you please explain what you mean with Shaoanlu mode? I know Shaoanlu only for his GAN-specific experiments.
Thanks!",nice hear could please explain mean mode know thanks,issue,positive,positive,positive,positive,positive,positive
396541140,"@torzdf 
I apologize for somewhat unorthodox PR format. The whole 3 PRs are for updated OriginalHighRes model should be treated as a single PR.
Thank you.",apologize somewhat unorthodox format whole model single thank,issue,negative,positive,neutral,neutral,positive,positive
396538127,"@torzdf not sure if its still a thing but I am fished with the new Original 128 model.
For one its rather fast. I don't recommend raising dense layer size. I'd try batch_size 16 and lower though.

It features two different modes: Original (HgihRes) and Shaonlu (not GAN). I personally think Shaonlu's has more generalization, but that's debatable.",sure still thing fished new original model one rather fast recommend raising dense layer size try lower though two different original gan personally think generalization debatable,issue,positive,positive,positive,positive,positive,positive
395820761,"Here's latest pull of dlib (19.13.99) compiled for Windows 7 x64 and CUDA 9.0/cudnn 7.0.5

[dlib-19.13.99-cp36-cp36m-win_amd64.whl (3 MB)](https://owncloud.dspnet.fr/index.php/s/4dkQtdIn7GlnI3A/download)

As for a how-to, there's nothing special to do, really. I installed cmake and Microsoft Build Tools 2015 (visualcppbuildtools_full.exe) on top of Cuda 9.0 and Cudnn 7.0.5

Then python setup.py build then install.

Newer version of Visual Studio 2017 doesn't seem to work.",latest pull nothing special really build top python build install version visual studio seem work,issue,negative,positive,positive,positive,positive,positive
395766171,"Kirin-kun, your wheel works for me on Win 10 x64 and Ananconda 3.6, thanks.  I've had mixed results compiling dlib from source.  Compilation under VS 2017 15.7.3 is still buggy I think and not working with CUDA 9.1 or 9.2.  If you don't mind, an updated wheel or a brief how-to guide would be appreciated. ",wheel work win thanks mixed source compilation still buggy think working mind wheel brief guide would,issue,positive,positive,positive,positive,positive,positive
395572612,"@Kirin-kun I am going to make it slightly faster. I wouldn't watch for loss as its not really an objective measurement of completion. If you can see the predictor output (the rightmost image in the 1st and second triplet cols) to have eyes with clearly visible pupil (better if you see eyelashes), and facial expression follows the original during convert then the training is finished. As for moire I shall try to get rid of it.

Once I trained a net at 50k epochs I had all blurry silhouette of teeth and eyes with 0.04 loss, at 200k epochs I had crisp eyes and every tooth visible with clear tongue and.. well loss was still 0.04",going make slightly faster would watch loss really objective measurement completion see predictor output rightmost image st second triplet clearly visible pupil better see facial expression original convert training finished moire shall try get rid trained net blurry silhouette teeth loss crisp every tooth visible clear tongue well loss still,issue,positive,positive,positive,positive,positive,positive
395470678,"@Kirin-kun I found your wheel elsewhere and saved me a bunch of time.

Works just fine on Windows 2016 + Tensorflow 1.8 + Python 3.6.5. 

Any chance you can update it to 19.13? 

",found wheel elsewhere saved bunch time work fine python chance update,issue,positive,positive,positive,positive,positive,positive
395465846,"I switched to Ubuntu for performance enhancement, but in the past I used Win10.

I cloned dlib from https://github.com/davisking/dlib
And run python setup.py install --yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA",switched performance enhancement past used win run python install yes yes,issue,positive,positive,positive,positive,positive,positive
395405765,"I compiled dlib on windows 7 with CUDA support and made a wheel of it some time ago:

[dlib-19.10.99-cp36-cp36m-win_amd64.whl](https://owncloud.dspnet.fr/index.php/s/f3EYLma84LKsBLw/download)

Up to you to test it on Windows 10 with `pip install dlib-19.10.99-cp36-cp36m-win_amd64.whl`

And scan it for malicious software too, because one can never be too cautious.

Eventually, report if it answers True to dlib.DLIB_USE_CUDA",support made wheel time ago test pip install scan malicious one never cautious eventually report true,issue,positive,positive,positive,positive,positive,positive
395404040,"@Kirin-kun still doesent work I reinstalled everything and still this, any link where i can follow instruction step by step to install dependecies in the right order thanks.
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import dlib
>>> dlib.DLIB_USE_CUDA
False
>>>",still work everything still link follow instruction step step install right order thanks python default bit win type help copyright license information import false,issue,positive,positive,positive,positive,positive,positive
395391247,"I tried OriginalHighRes and it takes a lot longer to train, but it's expected.

But it seems to develop a moire pattern too. I'm around 0.03x loss though, so I'll see if it improves when loss goes down.",tried lot longer train develop moire pattern around loss though see loss go,issue,negative,neutral,neutral,neutral,neutral,neutral
395380466,">>> import dlib
>>> dlib.DLIB_USE_CUDA
False
thanks man",import false thanks man,issue,negative,negative,negative,negative,negative,negative
395354069,"Yeah, it's merged with @andenixa 128 work. He may want to push more changes, but I will merge both to master when I have squashed the bugs next week,",yeah work may want push merge master next week,issue,negative,neutral,neutral,neutral,neutral,neutral
395353984,"Your dlib probably doesn't support CUDA.

Launch a python interpreter and type:
```
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import dlib
>>> dlib.DLIB_USE_CUDA
True
>>>
```

If there's an error instead of ""True"", it means your dlib is not compiled properly.",probably support launch python interpreter type python default bit win type help copyright license information import true error instead true properly,issue,positive,positive,positive,positive,positive,positive
395222330,"```
Loading...
Please backup your data and/or test the tool you want to use with a smaller data set to make sure you understand how it works.
Traceback (most recent call last):
File ""C:\Users\Administrator\faceswap\tools.py"", line 40, in <module>
ARGUMENTS.func(ARGUMENTS)
File ""C:\Users\Administrator\faceswap\lib\cli.py"", line 79, in execute_script
script = self.import_script()
File ""C:\Users\Administrator\faceswap\lib\cli.py"", line 28, in import_script
Process exited.module = import_module(mod)

File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scripts.sort'

```

Sort doesn't work.",loading please backup data test tool want use smaller data set make sure understand work recent call last file line module file line script file line process file line return name level package level file frozen line file frozen line file frozen line module sort work,issue,positive,positive,positive,positive,positive,positive
395188221,"@torzdf negative on the GUI DPI, its still upscaled at MS Windows, but probably for the best.
That way at least the layout is preserved.",negative still probably best way least layout,issue,negative,positive,positive,positive,positive,positive
395160326,"@torzdf Effmpeg tab gets stuck (but I see that this is a known bug), but everything is working on Windows 2016",tab stuck see known bug everything working,issue,negative,neutral,neutral,neutral,neutral,neutral
395158893," @torzdf The landmarks are a mess.

 CUDA 8 & 9, cuDNN 6 & 75 and NVidia Driver 385.54.

But I just found out it was related to using TESLA V100

Exact same stack in Pascal works like a charm.",mess driver found related exact stack work like charm,issue,negative,positive,neutral,neutral,positive,positive
395106836,"FYI, I'm not going to be able to work on this until next week, but please keep reporting bugs. Thanks!",going able work next week please keep thanks,issue,positive,positive,positive,positive,positive,positive
395105166,"Yeah, I've seen that too. Normally if I kill training and start again it goes away. I'd imagine it's to do with attempting to calculate the polynormal when there isn't enough data. I'll look to fix this",yeah seen normally kill training start go away imagine calculate enough data look fix,issue,negative,positive,neutral,neutral,positive,positive
395093365,"Sometimes when I start training, the graph won't show up. Error message:

/home/USER//faceswapNewGui/env/lib/python3.6/site-packages/numpy/lib/polynomial.py:584: RuntimeWarning: invalid value encountered in true_divide
  lhs /= scale
Exception in Tkinter callback
Traceback (most recent call last):
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 1705, in __call__
    return self.func(*args)
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 749, in callit
    func(*args)
  File ""/home/USER/faceswapNewGui/lib/gui/display_page.py"", line 211, in <lambda>
    self.after(waittime, lambda t=waittime: self.update_page(t))
  File ""/home/USER/faceswapNewGui/lib/gui/display_page.py"", line 210, in update_page
    self.load_display()
  File ""/home/USER/faceswapNewGui/lib/gui/display_page.py"", line 221, in load_display
    self.display_item_process()
  File ""/home/USER/faceswapNewGui/lib/gui/display_command.py"", line 157, in display_item_process
    selections=[""raw"", ""trend""])
  File ""/home/USER/faceswapNewGui/lib/gui/stats.py"", line 214, in __init__
    self.refresh()
  File ""/home/USER/faceswapNewGui/lib/gui/stats.py"", line 220, in refresh
    self.get_calculations()
  File ""/home/USER/faceswapNewGui/lib/gui/stats.py"", line 302, in get_calculations
    self.stats[key] = method(raw)
  File ""/home/USER/faceswapNewGui/lib/gui/stats.py"", line 334, in calc_trend
    fit = np.polyfit(x_range, data, 3)
  File ""/home/USER/faceswapNewGui/env/lib/python3.6/site-packages/numpy/lib/polynomial.py"", line 585, in polyfit
    c, resids, rank, s = lstsq(lhs, rhs, rcond)
  File ""/home/USER/faceswapNewGui/env/lib/python3.6/site-packages/numpy/linalg/linalg.py"", line 2041, in lstsq
    0, work, lwork, iwork, 0)
ValueError: On entry to DLASCL parameter number 4 had an illegal value

Status remains:""Waiting for graph""",sometimes start training graph wo show error message invalid value scale exception recent call last file line return file line file line lambda lambda file line file line file line raw trend file line file line refresh file line key method raw file line fit data file line rank file line work entry parameter number illegal value status remains waiting graph,issue,negative,negative,negative,negative,negative,negative
394962676,"Updated the environment and changed conda to virtualenv:

```
absl-py                 0.2.2
astor                   0.6.2
bleach                  1.5.0
click                   6.7
cloudpickle             0.5.3
cycler                  0.10.0
dask                    0.17.5
decorator               4.3.0
dlib                    19.10.9
face-recognition        1.2.2
face-recognition-models 0.3.0
ffmpy                   0.2.2
gast                    0.2.0
grpcio                  1.12.1
h5py                    2.8.0
html5lib                0.99999
Keras                   2.1.6
kiwisolver              1.0.1
Markdown                2.6.11
matplotlib              2.2.2
networkx                2.1
numpy                   1.14.3
opencv-python           3.4.1.1
pathlib                 1.0.1
Pillow                  5.1.0
pip                     10.0.1
protobuf                3.5.2.p
pyparsing               2.2.0
python-dateutil         2.7.3
pytz                    2018.4
PyWavelets              0.5.2
PyYAML                  3.12
scandir                 1.7
scikit-image            0.14.0
scipy                   1.1.0
setuptools              39.2.0
six                     1.11.0
tensorboard             1.8.0
tensorflow-gpu          1.8.0
termcolor               1.1.0
toolz                   0.9.0
tqdm                    4.23.4
Werkzeug                0.14.1
wheel                   0.31.1
```

Still having the same issue, even though face_recogntion works just fine.",environment astor bleach click cycler decorator gast markdown pillow pip six wheel still issue even though work fine,issue,negative,positive,positive,positive,positive,positive
394849131,"Thanks for the feedback.

I'll add a minimum requirement version for matplotlib, they changed the naming convention for NavigationToolbar2Tk

What OS are you using? It displays differently in different OSes, so I'll try to set the geometry for the OS that requires the most space.",thanks feedback add minimum requirement version naming convention o differently different try set geometry o space,issue,negative,positive,neutral,neutral,positive,positive
394840099,"I got this error when I tried to use it at first:
```
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
ImportError: cannot import name 'NavigationToolbar2Tk'
```
I had to uninstall and reinstall matplotlib again and it worked.
Nothing seems to be an issue now, but I figured I should mention it so you could add a note about it or something.

However, on a separate note if the settings window isn't wide enough, you can't see the scroll bar. The version in the master branch acts this way as well. I have to resize that window every time I reopen the gui to see it.
",got error tried use first import import name reinstall worked nothing issue figured mention could add note something however separate note window wide enough ca see scroll bar version master branch way well resize window every time reopen see,issue,negative,positive,neutral,neutral,positive,positive
394191937,"@torzdf sure I shall test it ASAP.
Thank you",sure shall test thank,issue,positive,positive,positive,positive,positive,positive
394155561,"@andenixa I implemented your DPI fix pretty much exactly as you stated, but can't test. Could you let me know if it works. Thanks
",fix pretty much exactly stated ca test could let know work thanks,issue,positive,positive,positive,positive,positive,positive
393037725,@andenixa looking for your new idea. You can apply here for try. ,looking new idea apply try,issue,negative,positive,positive,positive,positive,positive
392552918,"I had several working experiments with a great help of @iperov, however I still haven't figured how to seamlessly apply filters to the whole image.",several working great help however still figured seamlessly apply whole image,issue,positive,positive,positive,positive,positive,positive
392552493,"@ruah1984 I have a good idea, I need slightly more time to study TF.
Perhaps it might be the best idea ever seen in face swap and alike.",good idea need slightly time study perhaps might best idea ever seen face swap alike,issue,positive,positive,positive,positive,positive,positive
392323998,@luiscosio not at the moment but I hope we'd be able to put it together.,moment hope able put together,issue,negative,positive,positive,positive,positive,positive
392310658,@andenixa you contribute here Whatever think it help . ,contribute whatever think help,issue,negative,neutral,neutral,neutral,neutral,neutral
392299738,@andenixa You are working on hollywood quality face swapping :)?,working quality face swapping,issue,negative,neutral,neutral,neutral,neutral,neutral
392262084,"Actually @iperov was generous to provide me with 256x Model. That is when I realized that further increasing of output matrix dimensions is redundant.

There is 2-3 potential steps needed to create an ultra HD face swaps.

1) Train a regular full-face, perhaps with DF model.
2) (optional) Depending on the crispness you can optionally train a de-blur filter. Since you have your original high-res sources that would work. De-blur could be very efficient if used with similar content it was trained on.
3) Train additional super-resolution x2 or x4 tensor depending on your demands. It could be even x8 (I am not kidding). I recommend the simplest sr x4 algorithm trained on both A and B data-sets. Its fast enough for training on CPU(s).
Apply 2) and 3) to your result and use CUBIC sampling to fit it back to a face hull.

That should give you Hollywood quality face swapping videos.",actually generous provide model increasing output matrix redundant potential create ultra face train regular perhaps optional depending crispness optionally train filter since original would work could efficient used similar content trained train additional tensor depending could even recommend algorithm trained fast enough training apply result use cubic sampling fit back face hull give quality face swapping,issue,positive,positive,neutral,neutral,positive,positive
392254333,"@Jasas9754 with LIAEF128 you need to give it slightly more Dense, probably 512, and make Encoder to look like 128->384->768->1024. You also need a crystal crisp data-set with no blurry input or output.
In my experience it would learn eyes in that configuration given enough (~60k) epochs

Note that faceswap dense starting at 1024 and up (I would use >=2048 when I used faceswap).

@ruah1984 actually we can't as I think LIAEF128 highly depends on both A and B sets to have alignments on a per file basis (actually embedded in png files DeepFaceLab fork). As well as people claim dlib has different face feature maps (I didn't test it myself). Besides its main success is also a very smart masking with a separate loss function.",need give slightly dense probably make look like also need crystal crisp blurry input output experience would learn configuration given enough note dense starting would use used actually ca think highly per file basis actually fork well people claim different face feature test besides main success also smart separate loss function,issue,positive,positive,neutral,neutral,positive,positive
392237239,"@andenixa LIAEF128 model learns faster than any model. That's something to learn. But i'm not still sure about eyeball tracking. Is this because of low dense(256)? Well, maybe nobody knows. If you want to experiment with something, but you don't have enough time, give us any experimental code. We'll test it out. Maybe you'd better use your own fork for feedback too. ",model faster model something learn still sure eyeball low dense well maybe nobody want experiment something enough time give u experimental code test maybe better use fork feedback,issue,positive,positive,positive,positive,positive,positive
392232159,"@Jasas9754 I did make additional releases up to v8 then I realized I am doing what others already had done long ago. In general plain, unmasked autoencoder model has surprisingly low convergence as well very high memory demands. Its also needs to be trained for a few days. I am surprised to learn that @iperov fork has a variety of 128x models that are trained over several hours. I feel like reinventing a wooden wheel in the light of that.",make additional already done long ago general plain unmasked model surprisingly low convergence well high memory also need trained day learn fork variety trained several feel like wooden wheel light,issue,positive,positive,neutral,neutral,positive,positive
391928052,"No tensorflor-gpu on the system I'm using Extract -j [x], and -D hog gives me the same error as well.
I'm running it on a VM, with multiple cores, but a VM nonetheless. I'm assuming this would be the issue then?",system extract hog error well running multiple nonetheless assuming would issue,issue,negative,neutral,neutral,neutral,neutral,neutral
391907415,Did you install the tensorflow-GPU?  If you use the GPU version then you can't use -j for multiple threads.,install use version ca use multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
391897575,"I've just tested on cpu with -j 4 and it works fine for me (both CNN and HOG), so can't replicate to fix.
CNN is slow on cpu anyway, so you could try:
`-D hog`",tested work fine hog ca replicate fix slow anyway could try hog,issue,negative,positive,neutral,neutral,positive,positive
391833650,Get the latest version. I believe this was bugfixed in 80cde77a6de03aaef6bd5e6e4691341f04290227,get latest version believe,issue,negative,positive,positive,positive,positive,positive
391830532,"thanks!
I'm now getting a different issue:

> python .\tools.py sort -h

faceswap-master\scripts\gui.py:27: UserWarning:
This call to matplotlib.use() has no effect because the backend has already
been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,
or matplotlib.backends is imported for the first time.

The backend was *originally* set to 'Qt5Agg' by the following code:
  File "".\tools.py"", line 6, in <module>
    from scripts.gui import TKGui
  File ""faceswap-master\scripts\gui.py"", line 18, in <module>
    from matplotlib import pyplot as plt
  File ""C:\ProgramData\Anaconda3\lib\site-packages\matplotlib\pyplot.py"", line 72, in <module>
    from matplotlib.backends import pylab_setup
  File ""C:\ProgramData\Anaconda3\lib\site-packages\matplotlib\backends\__init__.py"", line 14, in <module>
    line for line in traceback.format_stack()


  matplotlib.use('TkAgg')
Traceback (most recent call last):
  File "".\tools.py"", line 6, in <module>
    from scripts.gui import TKGui
ImportError: cannot import name 'TKGui'
",thanks getting different issue python sort call effect already chosen must first time originally set following code file line module import file line module import file line module import file line module line line recent call last file line module import import name,issue,negative,positive,positive,positive,positive,positive
391765748,"It's not meant to be launched directly. Go into your root faceswap folder and type:
`python tools.py sort -h`
",meant directly go root folder type python sort,issue,negative,positive,neutral,neutral,positive,positive
390483306,"I noticed lr=1e-04 sometimes contributes to long lasting moire patterns (beats me why) (instead of 5e-05 in faceswap) and since GAN has additional mask layer it reinforces that pattern and sometimes embeds it as a ""valid"" outcome.
I can observe the same pattern with Adam lr=1e-4 at my mask-less Model though it tends to vanish with time.",sometimes long lasting moire instead since gan additional mask layer pattern sometimes valid outcome observe pattern model though vanish time,issue,negative,negative,neutral,neutral,negative,negative
390358608,@kvrooman any news? I'm burning for a test 'cause GAN works best with 2 of my facesets until moiré kicks in,news burning test gan work best,issue,positive,positive,positive,positive,positive,positive
390335301,"I just tried @iperov 's fork (https://github.com/iperov/OpenDeepFaceSwap),
and the seamless conversion runs very fast. 

Taking a look at the GPU-Monitor (watch nvidia-smi) while converting with faceswap:
The gpu doesn't seem to do anything, Vram is in Usage, but gpu volatile stucks at 0%, while exactly 1 CPU core is performing at 100%.
Conversion with disabled ""seamless"" gets the gpu volatile at 30%, and the conversion is running fast.


EDIT: Finally got it working, its running fast now. I just edited the versions of requirements in requirements.txt
```

pathlib==1.0.1
scandir==1.6
h5py==2.7.1
Keras==2.1.6
opencv-python==3.4.0.12
scikit-image
cmake
dlib
face-recognition
tqdm
matplotlib
ffmpy==0.2.2

# tensorflow is included within the docker image.
# If you are looking for dependencies for a manual install,
# you may want to install tensorflow-gpu==1.4.0 for CUDA 8.0 or tensorflow-gpu>=1.5.0 for CUDA 9.0

# cmake needs to be installed before compiling dlib.

```
Only Keras and opencv-python have been edited versions (taken from @iperov 's requirements.txt).

Can't say if everything is working fine, but finally conversion with fast seamless cloning works.",tried fork seamless conversion fast taking look watch converting seem anything usage volatile exactly core conversion disabled seamless volatile conversion running fast edit finally got working running fast included within docker image looking manual install may want install need taken ca say everything working fine finally conversion fast seamless work,issue,negative,positive,positive,positive,positive,positive
390274569,"Yeah, seamless is hideously inefficient. If anyone wants to take a look, be my guest.",yeah seamless hideously inefficient anyone take look guest,issue,negative,positive,neutral,neutral,positive,positive
390019621,"There is already a supported way to do this.  See https://devblogs.nvidia.com/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/

This works on Windows and Linux.  We decided not to duplicate it in faceswap due to complications such as MultiGPU systems, virtual GPUs, and other problems that occur in edge cases.  Please use the CUDA_VISIBLE_DEVICES for this functionality.",already way see work decided duplicate due virtual occur edge please use functionality,issue,negative,negative,negative,negative,negative,negative
389955819,"I'll like the idea of storing the landmarks in the metadata. I'll definitely look into that.

As far as just pushing the landmark data into the model and trainer other than through the alpha channel (such as encoding it into the upper right corner of the shape) I didn't think that would be very effective because of the way convolution networks expand. As far as my understanding of the model works, in the first and maybe second layer of the expansion neighboring pixels bare more significance to the neurons and in the first layer there may not even be a neuron connecting the upper right corner to the lower left corner, and if there is, not as many as a neighboring pixel. I could be wrong about this so if anyone knows better I'd love to hear about it.

Another note to add is that the shape would have to be expanded in some way like adding another channel anyways (I suppose you could extend the y axis 1 pixel and put it in the bottom row), and I'm also uncertain of how easily the network will be able to learn that a 1 digit change in the bottom row of the image could completely change the rest of the image.

",like idea definitely look far pushing landmark data model trainer alpha channel upper right corner shape think would effective way convolution expand far understanding model work first maybe second layer expansion neighboring bare significance first layer may even neuron upper right corner lower left corner many neighboring could wrong anyone better love hear another note add shape would expanded way like another channel anyways suppose could extend axis put bottom row also uncertain easily network able learn digit change bottom row image could completely change rest image,issue,positive,positive,positive,positive,positive,positive
389891268,"Been playing with your model and works pretty well. I'll test your update
as soon as you release it.

On Thu, May 17, 2018, 1:09 AM kvrooman <notifications@github.com> wrote:

> Going to post a model update in a day or so with an improvement that
> should alleviate or solve this issue by implementing ICNR initialization of
> the convolution kernels.
>
> See this paper by the same authors of Pixel Shuffle for an overview
> https://arxiv.org/ftp/arxiv/papers/1707/1707.02937.pdf
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/339#issuecomment-389755581>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AAAGgmTBFadZl08-NiiH1WLJI4o0zwsjks5tzRQKgaJpZM4TOI7X>
> .
>
",model work pretty well test update soon release may wrote going post model update day improvement alleviate solve issue convolution see paper shuffle overview reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
389827204,"Sorry, incorrect branches for pull request",sorry incorrect pull request,issue,negative,negative,negative,negative,negative,negative
389755581,"Going to post a model update in a day or so with an improvement that should alleviate or solve this issue by implementing ICNR initialization of the convolution kernels.

See this paper by the same authors of Pixel Shuffle for an overview
https://arxiv.org/ftp/arxiv/papers/1707/1707.02937.pdf",going post model update day improvement alleviate solve issue convolution see paper shuffle overview,issue,positive,neutral,neutral,neutral,neutral,neutral
389627590,@iperov is it you who creates the bundle or a separate person who maintains it? I've visited the link. There a number of posts by totally clueless people. Very few success stories by casual users attempting perform face swap with office GPUs meant for word processing. That's why I asked if you want to contribute a good model to faceswap as it gets wider audience. Could get you the recognition you deserve.,bundle separate person link number totally people success casual perform face swap office meant word want contribute good model audience could get recognition deserve,issue,positive,positive,positive,positive,positive,positive
389624672,@iperov it sounds reasonable yet there are no batch files mentioned exist in the repo.,reasonable yet batch exist,issue,negative,positive,positive,positive,positive,positive
389600805,"GUI creates one more window. So there will be total 3 windows : GUI, console, preview.
If hide console and embed it to GUI, then if you close GUI window, child processes will not be closed gracefully due to python limitations of OS manipulations.
Therefore better work without GUI for me.

bat files is fine enough
![explorer_2018-05-16_21-27-35](https://user-images.githubusercontent.com/8076202/40133141-f13a3a20-594f-11e8-95ec-ead1ba66fee5.jpg)

",one window total console preview hide console embed close window child closed gracefully due python o therefore better work without bat fine enough,issue,positive,positive,positive,positive,positive,positive
389588506,"@iperov when a wise man claims something is possible they are probably right. When they say otherwise they might be mistaken. Two years is an awfully long time to those whose lack of patience only rivaled by the lack of health. Thanks for the council nevertheless. Your models are superb.

PS: Actually it ain't much work to come up with some GUI with PyQT if you don't mind an additional dependency.",wise man something possible probably right say otherwise might mistaken two awfully long time whose lack patience lack health thanks council nevertheless superb actually ai much work come mind additional dependency,issue,positive,positive,positive,positive,positive,positive
389542248,"@andenixa you mean grayscale to rgb ? of course. NN will work as colorizer using average color of samples.

64->128 works like imaginator which produces jittering.
Forget about 256 for 2 years :)",mean course work average color work like imaginator forget,issue,negative,negative,negative,negative,negative,negative
389528891,"@iperov do you think if less bits are used for colors, perhaps 15 bits it could be manageable to fit 256 vectors? Or utilize 128->256 dfaker approach (it uses 64->128 I think).",think le used color perhaps could manageable fit utilize approach think,issue,negative,positive,positive,positive,positive,positive
389522844,half face controls an avatar. Goal is B half face will control A avatar,half face goal half face control,issue,negative,negative,negative,negative,negative,negative
389522494,@iperov what is an avatar model. How is it different from the regular one?,model different regular one,issue,negative,neutral,neutral,neutral,neutral,neutral
389522238,"I trying to make avatar model last 8 hours, but no success.
![python_2018-05-16_17-37-48](https://user-images.githubusercontent.com/8076202/40120398-21c7ef72-5930-11e8-8c28-b30abe1f5774.jpg)
",trying make model last success,issue,positive,positive,positive,positive,positive,positive
389521782,masked trainer idea I got from dfaker repo.,masked trainer idea got,issue,negative,neutral,neutral,neutral,neutral,neutral
389521435,"@iperov but I can't release the model that uses your masked approach right? Just to be clear.

(actually I think I am going to try 256x256x3 vectors, I have a feeling it could be squeezed somehow at least to 8GB GPUs)",ca release model masked approach right clear actually think going try feeling could somehow least,issue,negative,positive,neutral,neutral,positive,positive
389521170,"of course you can use it. Why opensourcing then? :)

My windows binary has convenient .bat files and manual in Russian, so I dont need GUI absolutely.",course use binary convenient manual dont need absolutely,issue,negative,positive,positive,positive,positive,positive
389520453,"@iperov I see, but I still can use it for my personal use, right?

The thing with **faceswap** is that it has wider audience specially with the emergence of the GUI which is very important for ""layman"".",see still use personal use right thing audience specially emergence important layman,issue,negative,positive,positive,positive,positive,positive
389519577,"@andenixa
> Do you want to contribute your idea to faceswap repo?

no :) Before forking I was contributing to faceswap. It is time wasting.",want contribute idea time wasting,issue,negative,neutral,neutral,neutral,neutral,neutral
389519271,"@iperov 
Do you want to contribute your idea to faceswap repo?
I can adapt OriginalHighRes model to use the mask, but I can't release it without your permission as its going to be pretty derivative on your work.",want contribute idea adapt model use mask ca release without permission going pretty derivative work,issue,negative,positive,positive,positive,positive,positive
389518530,"I dont think so. 256 = 128 x 4 times bigger.

also mask very important. Model predicts mask smoothly instead of using source frame mask which much jittering.",dont think time bigger also mask important model mask smoothly instead source frame mask much,issue,negative,positive,positive,positive,positive,positive
389517626,@iperov but your approach works brilliantly and it is scalable. I am not sure to what extent mask is really necessary but without a mask H256 could fit to GPU.,approach work brilliantly scalable sure extent mask really necessary without mask could fit,issue,positive,positive,positive,positive,positive,positive
389516914,"@andenixa not enough ram even for 128. It is like 'low mem' model. So may be after 2 years with new videocards we will try 256.
or as an option to train on CPU 40-80 days :D",enough ram even like mem model may new try option train day,issue,negative,positive,neutral,neutral,positive,positive
389515864,@iperov absolutely fantastic results and the approach to remove res blocks as well! Could you aim for H256 which I think it always was about? You could try SepConv2D to reduce memory consumption.,absolutely fantastic approach remove well could aim think always could try reduce memory consumption,issue,positive,positive,positive,positive,positive,positive
389483371,"@iperov thanks for the heads-up. I shall check it out.

Guys we should seriously stop using presidents for our testing purposes before they pass legislations banning the use or development of any face swapping technologies.",thanks shall check seriously stop testing pas banning use development face swapping,issue,negative,negative,neutral,neutral,negative,negative
389466525,"I pushed big update of OpenDeepFaceSwap. Quality significantly increased.

about avatar model, I mean 64 half face matching 256 avatar. 
![00000](https://user-images.githubusercontent.com/8076202/40110907-493dcd24-5912-11e8-9066-a80ce844d33b.png)
",big update quality significantly model mean half face matching,issue,negative,negative,neutral,neutral,negative,negative
389452247,"@iperov if you mean one-to-many I have several thoughts but it would need testing.

It has to be a full-face for sure. For the net I would add one or more Conv layers to cover more face specific features and increase number of Neurons at the Dense layer proportionally. Perhaps by 25%-50% per additional Convolution layer depending on how diverse the training set.
If you know the approximate number of features you expect adding a Pool with Dropout helps at least according to some articles.

Target faces might benefit from additional pre-processing.
- Slightly de-saturate the samples to make them less colorful. That reduces net preference by color instead of shape. Perhaps you might know a better solution for that.
- Normalize the luminance / brightness to equalize lighting conditions.
- Increase random transformation by a factor of 1.1 - 1.5

PS: Not sure how Keras training optimizers are exactly managing its _learning rate_ but I found that reducing it slightly at higher epochs helps the convergence. Adam optimizer has learning rate decay but I think its done by subtracting a specified value each epoch which isn't very helpful. Learning rate should decrease non linearly. I would set several thresholds for that for the lack of a better solution.
",mean several would need testing sure net would add one cover face specific increase number dense layer proportionally perhaps per additional convolution layer depending diverse training set know approximate number expect pool dropout least according target might benefit additional slightly make le colorful net preference color instead shape perhaps might know better solution normalize luminance brightness equalize lighting increase random transformation factor sure training exactly found reducing slightly higher convergence learning rate decay think done value epoch helpful learning rate decrease non linearly would set several lack better solution,issue,positive,positive,neutral,neutral,positive,positive
389354392,Is it not possible to extend the scope of application to the range of hair other than parts of the face?,possible extend scope application range hair face,issue,negative,neutral,neutral,neutral,neutral,neutral
389252036,"It would be possible to identify frames without faces by parsing the alignments.json file. There is no tool to do that, currently, although I started working on one that did various actions based on the content of the file. When I've finished my GUI revamp, I may revisit it.",would possible identify without file tool currently although working one various based content file finished revamp may revisit,issue,negative,neutral,neutral,neutral,neutral,neutral
389250916,"You can, but I've never really seen the point (nor used it, so can't be sure if it works correctly).

Frames that don't have faces will not be converted anyway, assuming that you have an alignments.json, so they are just copied 'as is', so really shouldn't slow the process down.

In terms of the -fr and -d option. The above code:
`-fr 0001-10758 -d`

Means that you want to process all frames in the range 0001-10758. I assume that this is your entire dataset, so that will have no effect. You are effectively telling it to process the entire range.

Let's say you just wanted to process frames 100-300, you would put:
`-fr 0100-0300`

This would faceswap on those faces and frames 0001 to 0099 and 0301-10758 would be written out as is. If you added in the -d flag then the frames outside of the range that you have specified would just be skipped altogether.

As @Kirin-kun says, if you're going to identify frames without faces for passing into the command line, then you might as well just remove them from source.",never really seen point used ca sure work correctly converted anyway assuming copied really slow process option code want process range assume entire effect effectively telling process entire range let say process would put would would written added flag outside range would altogether going identify without passing command line might well remove source,issue,positive,positive,neutral,neutral,positive,positive
389247518,"There's no such option.  If no faces are found in a frame, it's just copied as-is. If you don't want them, remove them from the source.",option found frame copied want remove source,issue,negative,neutral,neutral,neutral,neutral,neutral
389125804,"@iperov faceswap serves my purpose to some extent. It also doesn't have any working 128 model thus though I could provide one. Still not sure if my ""concoction"" works good enough (though its gotten much better now). Perhaps you could donate some of your code to create a basic H128 with decent quality and speed for faceswap repo.",purpose extent also working model thus though could provide one still sure concoction work good enough though gotten much better perhaps could donate code create basic decent quality speed,issue,positive,positive,positive,positive,positive,positive
389123754,"@iperov I am not exactly aiming to create fakes but rather to have one-to-many model where I merge multiple faces in the target data-set to catch unique features of each face. I have been successful with the basic Model by adding extra Conv layer(s) and increasing neuron count at dense layers. The problem of poor generalization and over-fitting still persists. It needs some learning rate decay and a lot of training epochs and still sucks quality-wise.
The major problem is also that the approach faceswap uses puts too much emphasis at matching the color rather than shape which makes it difficult to ""melt"" multiple sets.",exactly aiming create rather model merge multiple target catch unique face successful basic model extra layer increasing neuron count dense problem poor generalization still need learning rate decay lot training still major problem also approach much emphasis matching color rather shape difficult melt multiple,issue,negative,positive,neutral,neutral,positive,positive
389122834,"H128 has more details vs full face 128, but doesnt cover one cheek and beard.
Half face good for women fakes whose cheeks occluded by hair.",full face doesnt cover one cheek beard half face good whose hair,issue,negative,positive,positive,positive,positive,positive
389121804,"@iperov sounds fascinating if you can make it happen. In fact perhaps we should aim for H256 next. I very excited to give your H128 a try just need a time to time to make a training set. 

Are H128 considerably different from full-face? For regular faceswap its just a matter of adjusting the margin matrix and of course training it to catch more ""space"". I actually changed new HighRes model to cover most of the face which is going to be in the next revision.

",fascinating make happen fact perhaps aim next excited give try need time time make training set considerably different regular matter margin matrix course training catch space actually new model cover face going next revision,issue,positive,positive,positive,positive,positive,positive
389084803,No I'm saying it isn't discarding anything at all. i want it to discard all frames with no faces from the entirety of the source folder - ie the whole clip. What command should i use to output only those frame with faces?,saying anything want discard entirety source folder ie whole clip command use output frame,issue,negative,positive,positive,positive,positive,positive
389059642,"Hey, this is an interesting idea, but wouldn't it be possible/have you tried to just embed the information as metadata into the images, or to have it read from the `alignments.json` file if available (although perhaps this may need the models to be adjusted to use the data supplied in such a way)?

I'm not sure if such an approach would slow down the training process, but it would allow for avoiding the issues you mentioned with how the alpha channel will get treated. Python dictionaries support random access so I don't think that it should cause too much of a slowdown.

The only big issue I can think of is when you have a data-set made from many videos/images, hence you don't have an `alignments.json` file for the combined dataset, so a tool that lets you merge/modify `alignments.json` files could be useful (@torzdf had started developing one a while ago, but since there wasn't much interest it was never finished).",hey interesting idea would tried embed information read file available although perhaps may need use data way sure approach would slow training process would allow alpha channel get python support random access think cause much slowdown big issue think made many hence file combined tool could useful one ago since much interest never finished,issue,positive,positive,positive,positive,positive,positive
388899791,"He already has. You can test it by checking out the staging branch https://github.com/deepfakes/faceswap/tree/staging
",already test staging branch,issue,negative,neutral,neutral,neutral,neutral,neutral
388888919,"@andenixa I made best H128, without suxx residual blocks. I removed res blocks from all models. New super update for all models upcoming...
",made best without residual removed new super update upcoming,issue,positive,positive,positive,positive,positive,positive
388840003,"Ok, I haven't got time to test this at the moment, but I will merge it into staging.

If anyone wants to checkout the staging branch, give it a go and report back their findings that would be appreciated.
",got time test moment merge staging anyone staging branch give go report back would,issue,negative,neutral,neutral,neutral,neutral,neutral
388839255,"The process isn't really built for that.

The best way would probably be to perform a swap on the full frames, and then apply some kind of masking between the frames with something like Adobe Premiere.

In all honesty, it would be quite a lot of work.",process really built best way would probably perform swap full apply kind something like adobe premiere honesty would quite lot work,issue,positive,positive,positive,positive,positive,positive
388756445,"Raise a PR to master and I'll push it.

Thanks",raise master push thanks,issue,negative,positive,positive,positive,positive,positive
388734310,"Hi  torz, I updated [my fork](https://github.com/DKingCN/faceswap) about [docker related info](https://github.com/DKingCN/faceswap/commit/9fdbac094b7f9b091d250d53597b3276f42ab03b). Would you like me to send a new PR or you manually merge from a quick [patch](https://github.com/DKingCN/faceswap/commit/9fdbac094b7f9b091d250d53597b3276f42ab03b.patch)?",hi fork docker related would like send new manually merge quick patch,issue,negative,positive,positive,positive,positive,positive
388720234,"Hey,

The `-d` option discards frames not within the range given by `-fr`. 

Do you mean that it outputs more frames than 0001-10758? i.e. do you have more frames in the input folder and it copies all of them to the output folder?",hey option within range given mean input folder output folder,issue,negative,negative,negative,negative,negative,negative
388632180,"@iperov I think its slightly faster and less accurate with colors as it processes color layers separately (presumably sequentially). It consumes less memory though it probably has worse convergence in general. I try to squeeze more layers while having reasonable training speed and Ram requirements. Also ideally the first conv layers it has to be 2x the retina side size yet I think it's unfeasible with Conv2D memory wise. 
If you can fix a proper 128x HalfFace using the regular Conv2D I'd appreciate it.

PS: The reason I can't use OpenFaceSwap it's not compatible with current training sets and I have a lot of manually crafted sets.",think slightly faster le accurate color color separately presumably sequentially le memory though probably worse convergence general try squeeze reasonable training speed ram also ideally first retina side size yet think unfeasible memory wise fix proper regular appreciate reason ca use compatible current training lot manually,issue,positive,positive,positive,positive,positive,positive
388628065,@andenixa is SeparableConv useful ? what benefits it provides? have you comparison against regular idea with residual layers ?,useful comparison regular idea residual,issue,negative,positive,positive,positive,positive,positive
388626361,@torzdf  I've updated my PR for the new model. It seems to be rather sane and stable. It takes some time to train and resource consumption is around 5gb per 24 batch_size. The clarity is rather good with a nice data-set. It seems to work for multi-gpu model as well.,new model rather sane stable time train resource consumption around per clarity rather good nice work model well,issue,positive,positive,positive,positive,positive,positive
388614823,"@AbysmalBiscuit 

> As an alternative we could add a gui.py or faceswap-gui.py file to the root directory and then keep the faceswap.py and tools.py as cli only (I've tested commenting out the gui stuff from them and it works fine as cli only).

As the options have now been moved to dicts, my plan is to remove the gui specific code from cli.py, faceswap.py and sort.py and just import the dicts straight into gui.py
",alternative could add file root directory keep tested stuff work fine plan remove specific code import straight,issue,negative,positive,positive,positive,positive,positive
388614541,"And actually, having a quick review, this adds the tools to the main faceswap code. There are arguments to be made either way on whether this is desired, but @Clorr and others were not so keen on this, wishing to separate out the main faceswap workflow from helper functions. I'd prefer to respect their wishes on this, and maybe review again in future.",actually quick review main code made either way whether desired keen wishing separate main helper prefer respect maybe review future,issue,positive,positive,positive,positive,positive,positive
388614187,"I appreciate the help on this guys, but I'd advise that you hold fire for now.

As I tend to do, I have pretty much rewritten the GUI from the ground up, so the structure is significantly different. If there is a burning requirement for this, it can get merged, but it is likely to be overwritten when I implement the next version.",appreciate help advise hold fire tend pretty much ground structure significantly different burning requirement get likely implement next version,issue,positive,positive,neutral,neutral,positive,positive
388606036,"It works. There are some small things that I would change that will make it easier to maintain/extend in the future, I'll do a code review to point them out.

The reason why initially tools were put into a separate file was because the collaborators wanted to keep the main faceswap functionality and the tools separate.
@Clorr (and other collaborators) are you fine with merging both the core faceswap functionality and tools into one command file?
As an alternative we could add a `gui.py` or `faceswap-gui.py` file to the root directory and then keep the `faceswap.py` and `tools.py` as cli only (I've tested commenting out the gui stuff from them and it works fine as cli only).",work small would change make easier future code review point reason initially put separate file keep main functionality separate fine core functionality one command file alternative could add file root directory keep tested stuff work fine,issue,positive,positive,positive,positive,positive,positive
388605684,"Simplely updating the file name is enough to fix it.
Dont forget it while merging staging branch, which has not been fixed.

That dockerfile should work cos I even successfully built that on docker hub.",file name enough fix dont forget staging branch fixed work co even successfully built docker hub,issue,positive,positive,positive,positive,positive,positive
388593481,~~~@DKingCN could you look to push a fix for this?~~~ Scrap that. Should be a straightforward name change. Have pushed a fix. If someone could confirm this works (I don't use Docker) that would be appreciated,could look push fix scrap straightforward name change fix someone could confirm work use docker would,issue,negative,positive,positive,positive,positive,positive
388592508,"They changed the structure with last update.

In version before command for docker install was :
```
COPY ./requirements-python35.txt .
RUN pip3 --no-cache-dir install -r ./requirements-python35.txt
```
As there were different requirement-files they now have been bundled in a single file called ""requirements.txt""
I would suggest to simply replace ""requirements-docker.txt"" with ""requirements.txt"" in the docker-file(s). ",structure last update version command docker install copy run pip install different single file would suggest simply replace,issue,negative,negative,neutral,neutral,negative,negative
388546759,"Still working on the model. The clarity is fascinating now, but the target vectors sometimes match wrongly aligned faces. I am trying to reduce number of deep layers to see if it helps that but I shall leave the high clarity (very-deep) Encoder in the code as well for those who want to experiment.",still working model clarity fascinating target sometimes match wrongly trying reduce number deep see shall leave high clarity code well want experiment,issue,positive,positive,neutral,neutral,positive,positive
388145630,"Tested working on:
Ubuntu (Cuda + AVX)
Windows 10 (AVX)
macOS High Sierra (AVX)

This is getting merged to staging. I may review the instructions, but that can be done after the merge.

I haven't tested Docker, but if any issues get raised we can look at then.

Good work.",tested working high sierra getting staging may review done merge tested docker get raised look good work,issue,negative,positive,positive,positive,positive,positive
388107014,"Yeah, you've done good. I'm going to run tests through linux, Windows and macOS. Because it is such a fundamental change, I just want to make sure that it works fully as expected before merging. ",yeah done good going run fundamental change want make sure work fully,issue,positive,positive,positive,positive,positive,positive
388087352,"Error() contains exit(1)
Remove tensorflow==custom case cos it's l actually useless.

So. I think we are done?",error exit remove case co actually useless think done,issue,negative,negative,negative,negative,negative,negative
388047167,"yeah. pip compiles dlib from source ([pypi](https://pypi.org/project/dlib/#files), only `tar.gz` provided, which means it always compile from source) and its homepage points to [github.com/davisking/dlib](https://github.com/davisking/dlib).

So I just ask user whether to compile with cuda, if so, add arguments to pipmain. That pipmain actually invoke `python3 setup.py install dlib --yes USE_AVX` to compile dlib.",yeah pip source provided always compile source ask user whether compile add actually invoke python install yes compile,issue,positive,neutral,neutral,neutral,neutral,neutral
388023743,">  Does compiling dlib for Cuda work from pip without downloading source from https://github.com/davisking/dlib?

Scrap that, I've tested and it does. I'm doing some testing and fixing a couple of bugs, then I'll raise a PR  against your repo for you to review/submit the changes",work pip without source scrap tested testing fixing couple raise,issue,negative,neutral,neutral,neutral,neutral,neutral
387991369,Nice. I'll look to check this today. Does compiling dlib for Cuda work from pip without downloading source from https://github.com/davisking/dlib?,nice look check today work pip without source,issue,negative,positive,positive,positive,positive,positive
387961157,Not in our control.  We think that Github has tripped this requirement on their end.  You can set up a fork on your own account if you want to access it without login.,control think requirement end set fork account want access without login,issue,negative,neutral,neutral,neutral,neutral,neutral
387942756,"cmake is added in req.txt as it's required to compile dlib and dlib has no compiled binary whl file.


Tested:
- [x] Fix typos
- [X] Compile dlib against avx+cuda
- [X] Automatically install packages and Detect permission to decide install location.
- [X] Test 4 scenes
- [X] Rebase commits",added compile binary file tested fix compile automatically install detect permission decide install location test rebase,issue,negative,neutral,neutral,neutral,neutral,neutral
387895443,"If you want to check my commit works with docker, resolve the conflicts, adjust the cmake position and make the Enable_Docker() change, I can look to getting this merged.",want check commit work docker resolve adjust position make change look getting,issue,positive,neutral,neutral,neutral,neutral,neutral
387855512,"@torzdf I appreciate for allowing this, going to repost it to playground after I make a few updates",appreciate going repost playground make,issue,negative,neutral,neutral,neutral,neutral,neutral
387820500,"I'm going to close this, as it's probably better placed in faceswap_playground",going close probably better,issue,negative,positive,positive,positive,positive,positive
387820308,"Ok, I'm closing this as #373 has now been pushed to staging with a view to merging to master in the next few days. Any issues, please let me know, but thanks for looking into this.",staging view master next day please let know thanks looking,issue,positive,positive,neutral,neutral,positive,positive
387819226,"Ok, I'm finally merging this. There are some tweaks I would make, but nothing that is breaking. Good job man 👍 ",finally would make nothing breaking good job man,issue,negative,positive,positive,positive,positive,positive
387755719,I just fixed some typos and added the pip install to actually install the packages and pushed it to your repo. I don't know if this will cause Docker issues. Could you check please.,fixed added pip install actually install know cause docker could check please,issue,negative,positive,neutral,neutral,positive,positive
387752736,As a hotfix this PR is good; until #373 is merged to staging and then staging to master (which I have no idea how long it will take). ,good staging staging master idea long take,issue,negative,positive,positive,positive,positive,positive
387421925,"@torzdf I've fixed the issues. While looking for where the image extensions list was I stumbled across some other small problems in a few files, so I fixed those as well.

Edit: I have also tested terminating train in GUI and it seems to stop without any issues (since I have moved the last terminating try/catch block inside the if, elif, else block).",fixed looking image list across small fixed well edit also tested train stop without since last block inside else block,issue,positive,negative,neutral,neutral,negative,negative
387380257,"@torzdf sure, I am just trying to see if its not worse than the previous one considering decreased learning speed and raised memory demands. I am also trying a sliced bread design with dropout layer in the middle because  previous 64x model (which is the basis for HighResv2) overtrained because of increased number of Conv2D layers. 
I shall credit the ideas I might have borrowed from other contributes of course. 
Generally I just want a working 128x tensor with HD quality;)",sure trying see worse previous one considering learning speed raised memory also trying sliced bread design dropout layer middle previous model basis number shall credit might course generally want working tensor quality,issue,negative,negative,neutral,neutral,negative,negative
387372832,"I've reformatted it so it is no longer dependent on `psutil`, by having it start effmpeg as a group subprocess (via a list of commands that should be treated as group subprocesses, hence allowing for easy future extension).

However I discovered a bug wherein the faceswap.py functions don't recognize `.bmp` files as images, hence I want to add `.bmp` as a valid file extension before commiting and pushing.",longer dependent start group via list group hence easy future extension however discovered bug wherein recognize hence want add valid file extension pushing,issue,negative,positive,positive,positive,positive,positive
387298641,"No worries about the delay. 

I'll look into it today. `psutil` just makes it really easy to get all the child processes' IDs, but I could probably write a method that would retrieve it.",delay look today really easy get child could probably write method would retrieve,issue,negative,positive,positive,positive,positive,positive
387181086,I'll leave it open as a pr for now. Let me know when you think it's ready for merging. ,leave open let know think ready,issue,negative,positive,neutral,neutral,positive,positive
387146153,"Thanks to @iperov I am currently testing another revision of HighRes model adopting their re-scaling idea.
Memory consumption is somewhat high though but you guys with 6 to 8Gb should be fine. Training speed is slower as there is much more deep layers in Encoder. When I get a model with somewhat good clarity I shall adjust it for more face coverage.",thanks currently testing another revision model idea memory consumption somewhat high though fine training speed much deep get model somewhat good clarity shall adjust face coverage,issue,positive,positive,positive,positive,positive,positive
387059376,@andenixa model experiments with result comparison are much welcome.,model result comparison much welcome,issue,negative,positive,positive,positive,positive,positive
387042069,"@iperov looks excellent. Do you think its possible to preserve TARGET faces details, freckles, perhaps through another special layer? Do you feel that additional conv layers (for Encoder) contribute to better detail preservation? I also want to try deep-deep approach with additional Dense+Dropout layer in the middle of Encoder.",excellent think possible preserve target perhaps another special layer feel additional contribute better detail preservation also want try approach additional layer middle,issue,positive,positive,positive,positive,positive,positive
387033006,@iperov I shall try your interleaved Upscale/ResBlock approach on decoder if you don't mind. I also like the face extractor you are using. I want to create something akin to H128 yet maskless. I noticed you reduce memory consumption by using smaller batch sizes. Does it play well for diverse (different lighting condition) data-sets? I noticed bugger batches contribute to more accurate / generalized models. I wasn't able to refine anything with bs < ~45-48,shall try approach mind also like face extractor want create something akin yet reduce memory consumption smaller batch size play well diverse different lighting condition bugger contribute accurate generalized able refine anything,issue,positive,positive,positive,positive,positive,positive
387029126,@andenixa Thanks for adding the conversion code! I'll try it out now.,thanks conversion code try,issue,negative,positive,positive,positive,positive,positive
387026890,"@tjdwo13579 you might be right I have forgotten to add conversion code. I did a PR yet I weren't able to test it with the latest git version. 
Somehow new releases became less Windows path friendly specially if you are using SMB paths like in my case.
@iperov I shall be sure to check it. Thanks.",might right forgotten add conversion code yet able test latest git version somehow new le path friendly specially like case shall sure check thanks,issue,positive,positive,positive,positive,positive,positive
387010227,"Yeah, no problem. I'll close this one, so just resubmit when you're ready.",yeah problem close one resubmit ready,issue,negative,positive,positive,positive,positive,positive
387005757,"@torzdf yes so it seems, I think I'd rather remove this pr and re-do the alteration if that is an option.",yes think rather remove alteration option,issue,negative,neutral,neutral,neutral,neutral,neutral
387004749,"It looks like you are using a version prior to the scripts refactor, so you may want to do your amendments against the latest code.",like version prior may want latest code,issue,negative,positive,positive,positive,positive,positive
386990519,"Ok, I've finally got around to testing this. My first environment was Windows, but unfortunately it isn't working...

![image](https://user-images.githubusercontent.com/36920800/39691512-ae2e78c6-51d5-11e8-84bb-21dbe7c76289.png)

I setup a new basic virtualenv, but it is telling me my requirements are met, when they are not.",finally got around testing first environment unfortunately working image setup new basic telling met,issue,negative,negative,neutral,neutral,negative,negative
386985230,"Sorry for the delay, been a bit busy of late.

Is there any way to implement this without importing psutil? I'm just a bit wary of the growing list of non-standard imports.",sorry delay bit busy late way implement without bit wary growing list,issue,negative,negative,negative,negative,negative,negative
386965355,"I'm not trying to nitpick but is conversion not possible with this model?

I've tried adding the ""-t OriginalHighRes"" on the conversion code but it's not working.

It says:
Reason: Error when checking : expected input_4 to have shape (None, 128, 128, 3) but got array with shape (1, 64, 64, 3)

Was this commit only meant for training as of now?
Mind my ignorance.. I'm not an expert in this field
",trying conversion possible model tried conversion code working reason error shape none got array shape commit meant training mind ignorance expert field,issue,negative,neutral,neutral,neutral,neutral,neutral
386868829,"Hopefully in the next week or two. It's quite a significant overhaul (2000 lines added, 1000 removed so far), and I have 2 of the biggest tasks to do, but I'm considering scrapping job queue for now.",hopefully next week two quite significant overhaul added removed far biggest considering scrapping job queue,issue,positive,positive,positive,positive,positive,positive
386852729,"Thanks @torzdf  looks like you are kicking ass on v0.3.0! any idea when you'll release?

I'll close this now since its a non issue",thanks like kicking as idea release close since non issue,issue,positive,positive,positive,positive,positive,positive
386804462,"I experience the same behaviour like mentioned here https://github.com/deepfakes/faceswap/issues/184#issuecomment-364935845 
When ""seamless"" is used, there's no gpu usage and the process of conversion runs extremly slow.
With ""seamless"" disabled it works like a charm.

Dlib selfcompiled with ""--yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA""
Face-Recognition with cnn works great (that didn't work well without selfcompiled dlib)",experience behaviour like seamless used usage process conversion slow seamless disabled work like charm yes yes work great work well without,issue,positive,positive,neutral,neutral,positive,positive
386802491,"I actually wanted to merge it with staging on the main repo, sorry for that.",actually merge staging main sorry,issue,negative,negative,negative,negative,negative,negative
386800198,"Still tuning the Net. Memory consumption is modest even for middle-level cards. Speed is quite good, but I can't get a crisp picture even for decoder.",still tuning net memory consumption modest even speed quite good ca get crisp picture even,issue,negative,positive,positive,positive,positive,positive
386533732,"Yeah, as @Kirin-kun said, full previewing for GAN isn't yet supported in GUI. It will be available in the next release. You can track the project progress here:
https://github.com/torzdf/faceswap/projects/1

",yeah said full gan yet available next release track project progress,issue,positive,positive,positive,positive,positive,positive
386506648,"@torzdf 
I might be making a PR to Staging as you've suggested. Perhaps someone could get better result either by getting better data-set and giving more it training or tweaking the model itself while I work at my version. 
Though I am yet to see consistent results that would at least outstretch GAN128. I am pretty happy with its learning ability, but the result it generates is a little ""low-fi"". On a good side it doesn't create aberrations such as twisted lines out of nowhere (the major reason I started making this one over GAN128 trainer).",might making staging perhaps someone could get better result either getting better giving training model work version though yet see consistent would least outstretch gan pretty happy learning ability result little good side create twisted nowhere major reason making one gan trainer,issue,positive,positive,positive,positive,positive,positive
386237663,"Excellent. Well, whenever your ready, please raise a PR pointing at the Staging branch. Thanks!",excellent well whenever ready please raise pointing staging branch thanks,issue,positive,positive,positive,positive,positive,positive
386237435,"If anyone who uses Docker can test this, that would be appreciated. I will look to test the rest of the code over the next few days.",anyone docker test would look test rest code next day,issue,negative,neutral,neutral,neutral,neutral,neutral
386211196,"@torzdf  yes its in in a state which I can share it. The major issue is to see if it has any meaningful results and since 128 models train longer  I am still looking if it can perform at the level of Original quality-wise. At this stage it learns rather well but decoder part significantly lags behind the encoder and I can't predict its limitations.
Funny part I can run it with ENCODER_DIM of ~3k and batch size ~42 (there is no -bs size limitation such as even numbers only or has to be power of 2) and it still fits 9080ti memory.
PS: I shamelessly picked how GAN128 is implemented, but my model doesn't share its architecture. I only use some GAN128 tricks to conserve GPU RAM.",yes state share major issue see meaningful since train longer still looking perform level original stage rather well part significantly behind ca predict funny part run batch size size limitation even power still ti memory shamelessly picked gan model share architecture use gan conserve ram,issue,positive,positive,positive,positive,positive,positive
386207606,"@andenixa we can test it, i believe 1080TI can support your request. ",test believe ti support request,issue,negative,neutral,neutral,neutral,neutral,neutral
386036257,"I'm willing to test it.  Is the Dfaker plugin/model still planned for integration at some point?  I can run the Original model with no issues, but can't get the proposed Dfaker code here to work.      ",willing test still integration point run original model ca get code work,issue,negative,positive,positive,positive,positive,positive
385939286,"Yeah, I think it's worth it. If you can add a new model, then choice is good.

If it's in a state you can share, then please raise a Pull Request so others can test.

Thanks 👍 ",yeah think worth add new model choice good state share please raise pull request test thanks,issue,positive,positive,positive,positive,positive,positive
385934188,@mansonami models are trained in the faceswap app and then uploaded and shared between users. The site does the conversion part of the faceswap app. ,trained site conversion part,issue,negative,neutral,neutral,neutral,neutral,neutral
385882440,"Sure I will. I don't fully understand the theory though a highres data-set may contain more details for reconstruction (and more face coverage as well). I also work on idea if a concatenated Conv2d tensors with different kernels could preserve facial features such as wrinkles, freckles, and moles.",sure fully understand theory though may contain reconstruction face coverage well also work idea different could preserve facial,issue,positive,positive,positive,positive,positive,positive
385879368,How do you train the model? with whole frame to whole frame?,train model whole frame whole frame,issue,negative,positive,positive,positive,positive,positive
385879098,"Post results eventually. 

Something like a short clip before and after. So we can judge if it's worth it?

I think the main problem isn't the resolution, but the averaging.",post eventually something like short clip judge worth think main problem resolution,issue,negative,positive,positive,positive,positive,positive
385652170,"Actually I hadn't fully thought it through, and it will be fairly simple to explain in the help doc how it works.

It will be something along the lines of:
```python
arguments_list.append({
""opts"": ('-tr', '--transpose'),
""choices"": (""(0, 90CounterClockwise&VerticalFlip)"", 
            ""(1, 90Clockwise)"", ""(2, 90CounterClockwise)"", 
            ""(3, 90Clockwise&VerticalFlip)"", ""None""),
""action"": HandleTranspose,
""dest"": ""transpose"",
""default"": ""None"",
""help"": """"""Transpose the video. If transpose is 
           set, then rotate will be ignored. For cli
           you can enter either the number or the
           long command name, e.g. to use (1, 90Clockwise)
           -tr 1 or -tr 90Clockwise""""""
})
```",actually fully thought fairly simple explain help doc work something along python transpose counterclockwise clockwise counterclockwise clockwise none action transpose default none help transpose video transpose set rotate enter either number long command name use clockwise clockwise,issue,positive,positive,neutral,neutral,positive,positive
385619236,"> I have come up with a solution and will make another patch. Although it may make explaining the cli a bit more confusing.

I wouldn't worry too much. Cli should always take priority",come solution make another patch although may make explaining bit would worry much always take priority,issue,negative,positive,positive,positive,positive,positive
385613371,"@torzdf I've fixed the issues you had found.

As for putting the full name of the effect for transpose, I have come up with a solution and will make another patch. Although it may make explaining the cli a bit more confusing.",fixed found full name effect transpose come solution make another patch although may make explaining bit,issue,negative,positive,positive,positive,positive,positive
385313274,"@torzdf thanks for testing! 
I'll push a commit today fixing the bugs you found.",thanks testing push commit today fixing found,issue,positive,positive,positive,positive,positive,positive
385289323,"Thanks everyone for you feedback. 

I realized while I was ""tweaking"" the Original model that GAN encoder doesn't have enough memory/neurons to hold the data (encoded_dim). GAN is also one Conv2d layer big to be trainable. My experiments shown that these kind of architecture can converge relatively well with 5 Conv2D layers which is 1 more than Original and one less than GAN. Also my unproven speculation that initial Conv2D layers should have a bigger windows which should span horizontal (something like (5,6) they are inverted). I haven't tested this yet, but I can see results are too generalized on horizontal features, but that yet to be proven.

PS: My current Original model tweak is times faster than GAN and gives a better result. It converges even with different versions of face such as 3D, photos, sketches, and drawings mixed together as target_B. My Original model tweak also plays nice with one-to-many approach. Only problem I found it gives too much preference to colors in favor of the shape (ie it would try to match, say, yellowish targets with photos taken in sunlight). If someone knows how to modify this part that would be very welcome. In general its OK, but the emphasys is a little to big.

PSS: I am aware that isn't a chat. The latest findings also that batch size should not be a power of 2 it has to be even (though not every model requires that neither) and it has to be smaller than number of samples (which can be overcame with a few lines of code). In fact decreasing-train-restoring back batch size can make net trainable again as it re-arranges its clusters positions.",thanks everyone feedback original model gan enough hold data gan also one layer big trainable shown kind architecture converge relatively well original one le gan also unproven speculation initial bigger span horizontal something like inverted tested yet see generalized horizontal yet proven current original model tweak time faster gan better result even different face mixed together original model tweak also nice approach problem found much preference color favor shape ie would try match say yellowish taken sunlight someone modify part would welcome general little big aware chat latest also batch size power even though every model neither smaller number code fact back batch size make net trainable,issue,positive,positive,positive,positive,positive,positive
385242637,"Is this definitely not false positives? The extractor used should have no effect on how the alignments are produced.

There was a push committed today to fix a bug in rotate, so you may want to test again.",definitely false extractor used effect produced push today fix bug rotate may want test,issue,negative,negative,negative,negative,negative,negative
385242368,"So, I'm testing on the GUI.

- General -  I suggest you use the -hide_banner flag to suppress some of the unneeded ffmpeg build info. Also Terminate has no effect.

- Extract - All good.
- gen-vid - All good.
- get-info - All good.
- get-fps - Is this meant to output to the console? It doesn't for me.
![image](https://user-images.githubusercontent.com/36920800/39405632-546e0832-4ba0-11e8-904a-d3ef63f847bb.png)
- mux-audio: Traceback error:
```
Loading...
Please backup your data and/or test the tool you want to use with a smaller data set to make sure you understand how it works.
Traceback (most recent call last):
File ""/home/matt/fake/faceswap/tools.py"", line 40, in <module>
ARGUMENTS.func(ARGUMENTS)
File ""/home/matt/fake/faceswap/tools/effmpeg.py"", line 446, in process_arguments
self.process()
File ""/home/matt/fake/faceswap/tools/effmpeg.py"", line 460, in process
action(**kwargs)
File ""/home/matt/fake/faceswap/tools/effmpeg.py"", line 553, in mux_audio
ff = FFmpeg(inputs=_inputs, outputs=_outputs)
File ""/home/matt/fake/env/lib/python3.5/site-packages/ffmpy.py"", line 56, in __init__
self.cmd = subprocess.list2cmdline(self._cmd)
File ""/usr/lib/python3.5/subprocess.py"", line 751, in list2cmdline
needquote = ("" "" in arg) or (""\t"" in arg) or not arg
TypeError: argument of type 'DataItem' is not iterable
Process exited.
```
![image](https://user-images.githubusercontent.com/36920800/39405742-1bbfcd34-4ba2-11e8-8bcc-468215f2a49b.png)

- rescale - All good
- rotate - All good, although my preference would be to explicitly state names rather than numbers for transpose, but understand this may be difficult to implement for cli reasons
- slice - All good






",testing general suggest use flag suppress unneeded build also terminate effect extract good good good meant output console image error loading please backup data test tool want use smaller data set make sure understand work recent call last file line module file line file line process action file line file line file line argument type iterable process image good rotate good although preference would explicitly state rather transpose understand may difficult implement slice good,issue,positive,positive,positive,positive,positive,positive
385169660,"When I resolved the merge conflicts I introduced a few small bugs, I'll quickly sort them out and push a new commit.",resolved merge small quickly sort push new commit,issue,negative,positive,neutral,neutral,positive,positive
385116758,"@AbysmalBiscuit, would it be possible to sort the conflicts? I would like to test and merge this before my upcoming GUI release (in the next week or so). Thanks.",would possible sort would like test merge upcoming release next week thanks,issue,positive,positive,neutral,neutral,positive,positive
385115932,"I don't think there is an issue here, but if there is, please feel free to re-open",think issue please feel free,issue,positive,positive,positive,positive,positive,positive
385115838,"Actually it will use the detector selected (detector is a cross script option), but yeah, it's recommended to run extract yourself for the reasons @Kirin-kun  says.",actually use detector selected detector cross script option yeah run extract,issue,negative,neutral,neutral,neutral,neutral,neutral
385032771,"And yeah, the alignments.json is built in memory, be it in the single extract command or the extract->convert command. In the single extract command, it's saved at the end though.

But I don't recommend ignoring the ""extract"" step because you don't have any control over the extraction process if it's launched from the convert command, as it will use the default options.

Notably, it will use the default extractor (hog) and not try to rotate, which means it may detect less faces depending on your images.",yeah built memory single extract command convert command single extract command saved end though recommend extract step control extraction process convert command use default notably use default extractor hog try rotate may detect le depending,issue,positive,positive,positive,positive,positive,positive
385029774,"You'd have to ask that to @torzdf he's the one who wrote the code.

Let the whole process run through. As long as the progress bar moves, it's doing something.",ask one wrote code let whole process run long progress bar something,issue,negative,positive,neutral,neutral,positive,positive
385021975,@Kirin-kun Are the faces then I guess held in memory or a temp dir until they are all enumerated and an alignment file can be made? I'm seeing disk activity but nothing in /tmp.,guess memory temp alignment file made seeing disk activity nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
384927026,"You don't need the alignments file to build the model. You just need faces.

The procedure has always been:

- extract the faces in both A and B
- train on these extracted faces
- convert using the information included in the alignements.json file to know WHERE to place the face. 

The recent change just extract before converting if it doesn't find the alignments file, because otherwise it wouldn't know where to place the face. It just doesn't save the extracted faces.",need file build model need procedure always extract train extracted convert information included file know place face recent change extract converting find file otherwise would know place face save extracted,issue,negative,neutral,neutral,neutral,neutral,neutral
384926476,"No, I think you're missing the point.

For what ever reason you do not have an alignments.json file. This is fine, you don't have to have one, but one must be generated.

So, you can do one of 2 things:

1) Do as @Kirin-kun  suggests, run extract first then run convert 
2) Just run convert

If you just run convert, then extract will be run at default settings to generate the alignments.json.

This is what you are seeing here:
```

Alignments file not found. Generating at default values...
Output Directory: /home/luke/Desktop/bonder
Input Directory: /home/luke/Desktop/bond
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: /home/luke/Desktop/bond/alignments.json
Starting, this may take a while...
```

At this point, **No files will be output** it is just reading the images to generate the alignments file.

Once that process is complete, it will automatically move on to convert when it will start generating your output.",think missing point ever reason file fine one one must one run extract first run convert run convert run convert extract run default generate seeing file found generating default output directory input directory loading extract starting may take point output reading generate file process complete automatically move convert start generating output,issue,negative,positive,positive,positive,positive,positive
384925884,So we now have to run an extract to build the model and then one again for conversion? That seems a bit overkill.,run extract build model one conversion bit,issue,negative,neutral,neutral,neutral,neutral,neutral
384925841,"Then you can re-launch your convert command:

python /home/luke/faceswap/faceswap.py convert -b 15 -e 10 -i '/home/luke/Desktop/bond' -o '/home/luke/Desktop/bonder' -m '/home/luke/Videos/my own deepfakes/kendrickmodel'

And we will see how it goes.",convert command python convert see go,issue,negative,neutral,neutral,neutral,neutral,neutral
384925282,"python /home/luke/faceswap/faceswap.py extract -i '/home/luke/Desktop/bond' -o '/home/luke/Desktop/bond/aligned' -D cnn -ae

It should extract the faces and create an alignments.json

Review the ""aligned"" directory to see if there's any false positive.",python extract extract create review directory see false positive,issue,positive,negative,neutral,neutral,negative,negative
384923234,"alright so assuming I'm in the directory with my frames to be converted, what commands would I now run to both generate a alignments file and convert the pictures? Assuming that the directory is just full of sequencially named frames - not faces.(I've already built the model)",alright assuming directory converted would run generate file convert assuming directory full already built model,issue,negative,positive,positive,positive,positive,positive
384922596,"""Alignments file not found. Generating at default values...""

It doesn't find ""/home/luke/Desktop/bond/alignments.json"" so it starts by extracting.",file found generating default find,issue,negative,neutral,neutral,neutral,neutral,neutral
384921985,"Of course I extracted - didn't you see the

""0%|▏ | 35/8615 [00:23<1:37:11, 1.47it/s]""

?

Its clearly seeing the 8615 photos but not converting them.",course extracted see clearly seeing converting,issue,negative,positive,positive,positive,positive,positive
384920478,"@fetchlister Have you waited for the process to complete? As @Kirin-kun  says, it looks like you didn't extract first. This is fine, but it's now a 2 step process if you don't have an alignments file.

1) Extract alignments (there will be no output at this stage, so the destination directory will be empty)
2) Perform conversion (this is when the output directory will start filling up)

This change was implemented because in the past conversion without an alignments file would lead to Out of Memory failures.",process complete like extract first fine step process extract output stage destination directory empty perform conversion output directory start filling change past conversion without file would lead memory,issue,negative,positive,neutral,neutral,positive,positive
384911093,"It looks likes you didn't extract before converting. So the program is trying to extract first. It should convert ""on the fly"" though.

Could you extract the faces from /home/luke/Desktop/bond so it generates an alignments.json prior to converting, so as to know at what step the problem might be?",extract converting program trying extract first convert fly though could extract prior converting know step problem might,issue,negative,positive,positive,positive,positive,positive
384909378,By the way - training works perfectly fine.,way training work perfectly fine,issue,positive,positive,positive,positive,positive,positive
384909161,"This is what I get. In the past it worked just fine - until the latest clone. The deprecation stuff I never worried about because It just worked.

python /home/luke/faceswap/faceswap.py convert -b 15 -e 10 -i '/home/luke/Desktop/bond' -o '/home/luke/Desktop/bonder'  -m  '/home/luke/Videos/my own deepfakes/kendrickmodel' -v


/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Output Directory: /home/luke/Desktop/bonder
Input Directory: /home/luke/Desktop/bond
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: /home/luke/Desktop/bond/alignments.json
Aligned directory not specified. All faces listed in the alignments file will be converted
Alignments file not found. Generating at default values...
Output Directory: /home/luke/Desktop/bonder
Input Directory: /home/luke/Desktop/bond
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: /home/luke/Desktop/bond/alignments.json
Starting, this may take a while...
  0%|                                                  | 0/8615 [00:00<?, ?it/s]Info: initializing keras model...
2018-04-27 04:52:11.949540: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-27 04:52:12.005466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-04-27 04:52:12.005943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Quadro M2200 major: 5 minor: 2 memoryClockRate(GHz): 1.036
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.83GiB
2018-04-27 04:52:12.005977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Quadro M2200, pci bus id: 0000:01:00.0, compute capability: 5.2)
WARNING:tensorflow:From /usr/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
  0%|▏                                      | 35/8615 [00:23<1:37:11,  1.47it/s]",get past worked fine latest clone deprecation stuff never worried worked python convert conversion second argument float future float import output directory input directory loading extract directory listed file converted file found generating default output directory input directory loading extract starting may take model binary use successful node read negative value must least one node node zero found device name major minor device device name bus id compute capability warning calling removed future version use instead,issue,negative,positive,neutral,neutral,positive,positive
384890799,Can you run with the -v flag and say whether there is any output.,run flag say whether output,issue,negative,neutral,neutral,neutral,neutral,neutral
384577205,"As it is an edge case, I don't think it's worth it.

Maybe add a mention in the help for the extract command that the filter and/or nfilter images should contain a single face.",edge case think worth maybe add mention help extract command filter contain single face,issue,positive,positive,positive,positive,positive,positive
384576145,"I guess that's technically a bug, so if you want to raise an issue, go ahead :)",guess technically bug want raise issue go ahead,issue,negative,neutral,neutral,neutral,neutral,neutral
384568028,"Yup, tested again and it's because it gets two faces in that pic. One in front and one blurry in the back.",tested two pic one front one blurry back,issue,negative,neutral,neutral,neutral,neutral,neutral
384565616,"No, no. It's  a png. It's a face extracted previously, but there's another face in the background. 

I actually wanted to make a second extraction pass so it doesn't extract that second face at all.",face extracted previously another face background actually make second extraction pas extract second face,issue,negative,negative,neutral,neutral,negative,negative
384565061,"list(map(lambda im: face_recognition.face_encodings(im)[0], images))

Is probably expecting a single face. When it gets more, it errors.",list map lambda probably single face,issue,negative,negative,neutral,neutral,negative,negative
384564824,"This actually excludes files which don't exist, but it does it silently:
`list(filter(lambda fnc: Path(fnc).exists(), filter_files)`
Maybe it's because it's a jpg rather than a png? I've never actually dug into the filter file code.",actually exist silently list filter lambda path maybe rather never actually dug filter file code,issue,negative,neutral,neutral,neutral,neutral,neutral
384564251,"And btw, there's no check if the filter files actually exist. If they don't exist, it proceeds happily.
",check filter actually exist exist proceeds happily,issue,positive,positive,positive,positive,positive,positive
384564010,"After various tries, I think it comes from my filter file. 

It detects two faces in it (which is the case) , so it crashes.

Sorry, I'm an edge cases specialist :grinning: ",various think come filter file two case sorry edge specialist grinning,issue,negative,negative,negative,negative,negative,negative
384558242,"Old code:
```
def load_filter(self):
        nfilter_files = self.arguments.nfilter
        if not isinstance(self.arguments.nfilter, list):
            nfilter_files = [self.arguments.nfilter]
        nfilter_files = list(filter(lambda fn: Path(fn).exists(), nfilter_files))
        filter_files = self.arguments.filter
        if not isinstance(self.arguments.filter, list):
            filter_files = [self.arguments.filter]
        filter_files = list(filter(lambda fn: Path(fn).exists(), filter_files))
        
        if filter_files:
            import_FaceFilter()
            print('Loading reference images for filtering: %s' % filter_files)
            return FaceFilter(filter_files, nfilter_files, self.arguments.ref_threshold)
```
New code:
```
    def load_face_filter(self):
        """""" Load faces to filter out of images """"""
        facefilter = None
        filter_files = [self.set_face_filter(filter_type)
                        for filter_type in ('filter', 'nfilter')]

        if any(filters for filters in filter_files):
            facefilter = FaceFilter(filter_files[0], filter_files[1], self.args.ref_threshold)
        return facefilter

    def set_face_filter(self, filter_list):
        """""" Set the required filters """"""
        filter_files = list()
        filter_args = getattr(self.args, filter_list)
        if filter_args:
            print(""{}: {}"".format(filter_list.title(), filter_args))
            filter_files = filter_args
            if not isinstance(filter_args, list):
                filter_files = [filter_args]
            filter_files = list(filter(lambda fnc: Path(fnc).exists(), filter_files))
        return filter_files

```
So, as far as I can see it builds in the same way, except that it now also loads if only nfilter is provided.",old code self list list filter lambda path list list filter lambda path print reference filtering return new code self load filter none return self set list print list list filter lambda path return far see way except also provided,issue,negative,positive,positive,positive,positive,positive
384553381,"Does that file exist? The double backslash appears because python is escaping the backslash in the Windows path, but it should still work.",file exist double python path still work,issue,negative,neutral,neutral,neutral,neutral,neutral
384553104,"Ok, I just tested and I don't have this issue. It may be a Windows path thing...
```
python faceswap.py extract -i /mnt/fakes/Masters/A/white/frames/hope/25fps -o ~/fake/tmptest/hope -D cnn -ae -r on -f /mnt/fakes/Masters/A/white/faces/hope/1fps/hope_1fps_000039_0.png
/home/user/fake/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Output Directory: /home/user/fake/tmptest/hope
Input Directory: /mnt/fakes/Masters/A/white/frames/hope/25fps
Loading Extract from Extract_Align plugin...
Filter: ['/mnt/fakes/Masters/A/white/faces/hope/1fps/hope_1fps_000039_0.png']
Using json serializer
Alignments filepath: /mnt/fakes/Masters/A/white/frames/hope/25fps/alignments.json
Starting, this may take a while...
  0%|                                                                                                                                                                          | 0/1092 [00:00<?, ?it/s]Info: initializing keras model...
WARNING:tensorflow:From /home/user/fake/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
  0%|▋                                                                                                                                                               | 5/1092 [00:28<1:44:28,  5.77s/it]No face encodings found
No face encodings found
  1%|▉                                                                                                                                                               | 6/1092 [00:29<1:30:16,  4.99s/it]No face encodings found
No face encodings found
  1%|█                                                                                                                                                               | 7/1092 [00:30<1:20:04,  4.43s/it]
```
etc. I don't suppose you have traceback kicking around that outputs the filter file name pre-change? I don't have a Windows testbox up at the moment.",tested issue may path thing python extract conversion second argument float future float import output directory input directory loading extract filter starting may take model warning calling removed future version use instead face found face found face found face found suppose kicking around filter file name moment,issue,negative,neutral,neutral,neutral,neutral,neutral
384537190,"https://github.com/iperov/OpenDeepFaceSwap has an optional feature allowing to place the landmarks manually if the face is not detected.

I played with it and it's really cool. Add in the fact that you can work on a subset of frames because the landmarks are embedded in the aligned pngs in that fork and it becomes easy to get the faces you missed.

Your solution involves looking at the pictures in a sliding time window and besides it only applies to video, whereas extraction can apply to random pictures. And it would add faces where there's no one.",optional feature place manually face really cool add fact work subset fork becomes easy get solution looking sliding time window besides video whereas extraction apply random would add one,issue,positive,positive,neutral,neutral,positive,positive
384459493,"Ok, that's weird. I tested both of these options and they worked fine... will check,",weird tested worked fine check,issue,negative,negative,neutral,neutral,negative,negative
384402905,"When the size of the kernel and stride don't play well with each other it can lead to checkerboard-like convolution artifacts in the resulting image. [This article](https://distill.pub/2016/deconv-checkerboard/) can give some insight into why this happens. 
I am thinking that perhaps the line of code below is why we are seeing the moire patterns. 
``x = SeparableConv2D(f, kernel_size=3, strides=2, kernel_initializer=conv_init, use_bias=False, padding=""same"")(x)``
Line 66 of plugins/Model_GAN128/Model.py
",size kernel stride play well lead convolution resulting image article give insight thinking perhaps line code seeing moire line,issue,positive,neutral,neutral,neutral,neutral,neutral
384393746,"Is the filter/nfilter function broken?

```
C:\Users\Kirin\face>python c:\users\kirin\faceswap\faceswap.py extract -i H:\Fak
es\reach -o H:\Fakes\reach\aligned -D cnn -ae -r on -f h:\fakes\reach0306_0.png

C:\Program Files\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning:
Conversion of the second argument of issubdtype from `float` to `np.floating` is
 deprecated. In future, it will be treated as `np.float64 == np.dtype(float).typ
e`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Output Directory: H:\Fakes\reach\aligned
Input Directory: H:\Fakes\reach
Loading Extract from Extract_Align plugin...
Filter: ['h:\\fakes\\reach0306_0.png']
Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 32, in <module>
    ARGUMENTS.func(ARGUMENTS)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 37, in execute_script
    process = script(*args)
  File ""c:\users\kirin\faceswap\scripts\extract.py"", line 19, in __init__
    self.faces = Faces(self.args)
  File ""c:\users\kirin\faceswap\scripts\fsmedia.py"", line 160, in __init__
    self.filter = self.load_face_filter()
  File ""c:\users\kirin\faceswap\scripts\fsmedia.py"", line 184, in load_face_filt
er
    facefilter = FaceFilter(filter_files[0], filter_files[1], self.args.ref_thre
shold)
  File ""c:\users\kirin\faceswap\lib\FaceFilter.py"", line 14, in __init__
    self.encodings = list(map(lambda im: face_recognition.face_encodings(im)[0],
 images))
  File ""c:\users\kirin\faceswap\lib\FaceFilter.py"", line 14, in <lambda>
    self.encodings = list(map(lambda im: face_recognition.face_encodings(im)[0],
 images))
IndexError: list index out of range
```

Same thing happens with nfilter.",function broken python extract conversion second argument float future float import output directory input directory loading extract filter recent call last file line module file line process script file line file line file line er file line list map lambda file line lambda list map lambda list index range thing,issue,negative,negative,neutral,neutral,negative,negative
384362998,"This has been somewhat mitigated by the latest refactor. I agree that hanging for input is not ideal, but ctrl+c will also terminate the training loop, so there are options, until something better comes along.

This code is now also somewhat behind the current repo, so I'm closing for now. Feel free to re-open against the latest base.",somewhat latest agree hanging input ideal also terminate training loop something better come along code also somewhat behind current feel free latest base,issue,positive,positive,positive,positive,positive,positive
384328205,Thanks a lot a I shall report with my findings,thanks lot shall report,issue,negative,positive,positive,positive,positive,positive
384317276,"Actually, it's already been done for small areas, with the PatchMatch algorithm.

https://github.com/matthew-cox/PatchMatch-CUDA

Needed to implement: remove the pupil and the teeth and let a tool replace them according to a reference image like the one in the preview.",actually already done small algorithm implement remove pupil teeth let tool replace according reference image like one preview,issue,negative,negative,negative,negative,negative,negative
384287944,Fixed in latest commit for preview mode,fixed latest commit preview mode,issue,negative,positive,positive,positive,positive,positive
384246355,"I tried a GAN (64) training with batch size 128 and the preview window is even bigger. 

I can't see the bottom of the window.",tried gan training batch size preview window even bigger ca see bottom window,issue,negative,neutral,neutral,neutral,neutral,neutral
384202033,"lol. I haven't done GAN128. Like I say, it will be dynamically resized in v0.3.0. If that still isn't workable I'll look to adding scrollbars/pop out.",done gan like say dynamically still workable look,issue,positive,neutral,neutral,neutral,neutral,neutral
384199919,"With GAN128 and a batch size of 20, the preview is so huge that it doesn't fit on a 1600x1200 screen anyway.

That's why I suggested to detach them. Or make them scrollable?",gan batch size preview huge fit screen anyway detach make,issue,positive,positive,positive,positive,positive,positive
384199129,"> And the preview tab actually contains only part of the original window, which is not very useful


Actually, it contains it all. You may need to resize the window or shrink the console/command frame.",preview tab actually part original window useful actually may need resize window shrink frame,issue,positive,positive,positive,positive,positive,positive
384198837,"In gui 0.3.0 the other previews will be added and the preview window will dynamically resize.

See here for status: #352 

Those marked with [x] I have implemented, the rest are outstanding, but you can follow progress.
",added preview window dynamically resize see status marked rest outstanding follow progress,issue,positive,positive,positive,positive,positive,positive
384196878,"And the preview tab actually contains only part of the original window, which is not very useful.

Maybe the preview windows should be detached and not in a tab.",preview tab actually part original window useful maybe preview detached tab,issue,positive,positive,positive,positive,positive,positive
384187694,Thanks for your feedback @Kirin-kun I made some minor amends from your feedback #374. This has now been merged to the master branch,thanks feedback made minor amends feedback master branch,issue,negative,positive,neutral,neutral,positive,positive
384032873,"It shouldn't eat more VRAM. 

It will probably eat more VRAM than the pre-staging version, because it removes the hacky fix to only load dlib modules when required (#315)... but this was a hack and far from ideal.

That should be mitigated by the fact that it now only loads modules for the script that is running. The version before the 'hack' used to load every module for every task, regardless of whether you were using that task or not. The current version only load modules related to that task, so DLIB will get loaded for extract/convert but not for Train.

Ultimately the refactor needs to go deeper, loading and unloading VRAM items when they're required, but it's one step at a time.

Ultimately, if this failed to work in every instance, then I would re-instate the hack, but hacks are not good, and it's better to fix at source, which i could hopefully do after this got merged.",eat probably eat version hacky fix load hack far ideal fact script running version used load every module every task regardless whether task current version load related task get loaded train ultimately need go loading one step time ultimately work every instance would hack good better fix source could hopefully got,issue,positive,positive,positive,positive,positive,positive
384030841,"Well, if your refactor eats more VRAM than before, it's hardly an improvement in that regard. Some people with the 2Gb adapters will be out.",well eats hardly improvement regard people,issue,positive,negative,negative,negative,negative,negative
384030461,"Oh, sorry. Didn't see that it worked.

Ok, maybe it's edge case. Ultimately GPU loading/unloading needs to be improved, for sure. Hopefully this issue doesn't re-occur when purely using faceswap.",oh sorry see worked maybe edge case ultimately need sure hopefully issue purely,issue,positive,positive,neutral,neutral,positive,positive
384029128,"I'm not sure it will make any difference, to be honest, but I can't test. 

If it doesn't, then I'll probably have to dive into FaceLandmarksExtractor and only load the dlib components when they're requested.",sure make difference honest ca test probably dive load,issue,positive,positive,positive,positive,positive,positive
384028607,"Also, if you get a chance could you try this:

in convert.py, remove from the top:

`from scripts.extract import Extract`

and insert it here (line 54):
```
    def generate_alignments(self):
        """""" Generate an alignments file if one does not already
        exist. Does not save extracted faces """"""
        print('Alignments file not found. Generating at default values...')
        from scripts.extract import Extract
        extract = Extract(self.args)
        extract.export_face = False
        extract.process()
```",also get chance could try remove top import extract insert line self generate file one already exist save extracted print file found generating default import extract extract extract false,issue,positive,positive,neutral,neutral,positive,positive
384028195,"Strangely, this time, I closed a browser where there was a video running and it passed.

```
python c:\users\kirin\faceswap\faceswap.py convert -v --inpu
t-dir H:\fakes\pldg-sue --output-dir h:\fakes\pldg-sue\merged -m H:\Fakes\modelo
.00src_data.pldg-sue -b 4 -e 2 -S -D cnn -a h:\fakes\pldg-sue\aligned
C:\Program Files\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning:
Conversion of the second argument of issubdtype from `float` to `np.floating` is
 deprecated. In future, it will be treated as `np.float64 == np.dtype(float).typ
e`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Output Directory: h:\fakes\pldg-sue\merged
Input Directory: H:\fakes\pldg-sue
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: H:\fakes\pldg-sue\alignments.json
Alignments filepath: H:\fakes\pldg-sue\alignments.json
Loading Model from Model_Original plugin...
2018-04-24 20:03:59.449570: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.65GiB
2018-04-24 20:03:59.459570: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-24 20:04:00.055604: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1
edge matrix:
2018-04-24 20:04:00.062605: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:917]      0
2018-04-24 20:04:00.066605: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:930] 0:   N
2018-04-24 20:04:00.069605: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:
0/task:0/device:GPU:0 with 5439 MB memory) -> physical GPU (device: 0, name: GeF
orce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
loaded model weights
Loading Convert from Convert_Masked plugin...
100%|████████████████████████████████████████| 126/126 [00:43<00:00,  2.90it/s]
-------------------------
Images found:        126
Faces detected:      118
-------------------------
Done!
```

Only difference I see:

totalMemory: 6.00GiB freeMemory: 5.54GiB
vs now:
totalMemory: 6.00GiB freeMemory: 5.65GiB

So, maybe it pushed the memory consumption just over the edge. Something you didn't see because you have a 1080.",strangely time closed browser video running python convert conversion second argument float future float import output directory input directory loading extract loading model found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability loaded model loading convert found done difference see maybe memory consumption edge something see,issue,negative,negative,neutral,neutral,negative,negative
384023325,"It does print twice, I'll look to fix that. Once when it checks whether you have alignments and the other when it loads them. Basically it loads face alignments twice, which isn't necessary.

I don't see that you should be running out of memory though. Can you run the -v flag on staging so it generates the tensorflow debug
",print twice look fix whether basically face twice necessary see running memory though run flag staging,issue,negative,neutral,neutral,neutral,neutral,neutral
384016511,"filter.jpg won't appear, as I changed the default to None. It didn't make sense having a default of a file that doesn't exist. ",wo appear default none make sense default file exist,issue,negative,neutral,neutral,neutral,neutral,neutral
384013306,Maybe something is loaded twice and eats memory.,maybe something loaded twice eats memory,issue,negative,neutral,neutral,neutral,neutral,neutral
384012735,"Conversion on staging branch is broken, at least on my config. When I switched back to master, it worked.

Staging:
```
python c:\users\kirin\faceswap\faceswap.py convert --input-d
ir H:\fakes\pldg-sue --output-dir h:\fakes\pldg-sue\merged -m H:\Fakes\modelo.00
src_data.pldg-sue -b 4 -e 2 -S -D cnn -a h:\fakes\pldg-sue\aligned
C:\Program Files\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning:
Conversion of the second argument of issubdtype from `float` to `np.floating` is
 deprecated. In future, it will be treated as `np.float64 == np.dtype(float).typ
e`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Output Directory: h:\fakes\pldg-sue\merged
Input Directory: H:\fakes\pldg-sue
Loading Extract from Extract_Align plugin...
Using json serializer
Alignments filepath: H:\fakes\pldg-sue\alignments.json
Alignments filepath: H:\fakes\pldg-sue\alignments.json
Loading Model from Model_Original plugin...
loaded model weights
Loading Convert from Convert_Masked plugin...
  2%|?                                         | 2/126 [00:00<00:15,  8.13it/s]2
018-04-24 19:10:35.493314: E T:\src\github\tensorflow\tensorflow\stream_executor
\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: C
UDA_ERROR_OUT_OF_MEMORY
2018-04-24 19:10:35.500314: F T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1

```
On master branch:

```
git checkout master
Switched to branch 'master'
Your branch is up to date with 'origin/master'.

python c:\users\kirin\faceswap\faceswap.py convert --input-d
ir H:\fakes\pldg-sue --output-dir h:\fakes\pldg-sue\merged -m H:\Fakes\modelo.00
src_data.pldg-sue -b 4 -e 2 -S -D cnn -a h:\fakes\pldg-sue\aligned
Input Directory: H:\fakes\pldg-sue
Output Directory: h:\fakes\pldg-sue\merged
Filter: filter.jpg
Using json serializer
Starting, this may take a while...
Loading Model from Model_Original plugin...
C:\Program Files\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning:
Conversion of the second argument of issubdtype from `float` to `np.floating` is
 deprecated. In future, it will be treated as `np.float64 == np.dtype(float).typ
e`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2018-04-24 19:11:11.048347: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 5.54GiB
2018-04-24 19:11:11.059348: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-24 19:11:11.690384: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1
edge matrix:
2018-04-24 19:11:11.697385: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:917]      0
2018-04-24 19:11:11.701385: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:930] 0:   N
2018-04-24 19:11:11.706385: I T:\src\github\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:
0/task:0/device:GPU:0 with 5331 MB memory) -> physical GPU (device: 0, name: GeF
orce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
loaded model weights
Loading Convert from Convert_Masked plugin...
Reading alignments from: H:\fakes\pldg-sue\alignments.json
100%|████████████████████████████████████████| 126/126 [01:00<00:00,  2.08it/s]
-------------------------
Images found:        126
Faces detected:      118
-------------------------
Done!
```

There's a double line ""Alignments filepath""? The filter.jpg doesn't appear?",conversion staging branch broken least switched back master worked staging python convert conversion second argument float future float import output directory input directory loading extract loading model loaded model loading convert error polling event status query event unexpected event status master branch git master switched branch branch date python convert input directory output directory filter starting may take loading model conversion second argument float future float import found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability loaded model loading convert reading found done double line appear,issue,negative,negative,neutral,neutral,negative,negative
383967448,"Yeah, I noticed that. #won't fix. May look at in the future.

I have pull 'all' back in for detectors. It got pulled out because I merged the extract and convert options together where possible. Extract had the 'all' option and convert did not. I happened to select the convert arguments.

I have pushed a fix, so you can re-pull if you need the all option.",yeah wo fix may look future pull back got extract convert together possible extract option convert select convert fix need option,issue,negative,neutral,neutral,neutral,neutral,neutral
383966208,"Also, on extraction, there's a cosmetic problem. Not really important though.

```
Starting, this may take a while...
  0%|                                                  | 0/126 [00:00<?, ?it/s]I
nfo: initializing keras model...
100%|████████████████████████████████████████| 126/126 [01:06<00:00,  1.89it/s]
```",also extraction cosmetic problem really important though starting may take model,issue,negative,positive,positive,positive,positive,positive
383927236,"Problem seems to be on my side. I checked out staging, it said it's up to date but the scripts are those of master. 

And when I pulled, it said:

```
C:\Users\Kirin\faceswap>git status
On branch staging
nothing to commit, working tree clean

C:\Users\Kirin\faceswap>git pull
There is no tracking information for the current branch.
```

I recloned a clean repo and it seems really up to date now. 

```
C:\Users\Kirin\faceswap>git status
On branch staging
Your branch is up to date with 'origin/staging'.

nothing to commit, working tree clean

C:\Users\Kirin\faceswap>git pull
Already up to date.
```

Color me confused.

",problem side checked staging said date master said git status branch staging nothing commit working tree clean git pull information current branch clean really date git status branch staging branch date nothing commit working tree clean git pull already date color confused,issue,negative,positive,positive,positive,positive,positive
383919176,"self.faces_to_swap is set to None if either no aligned directory is provided or there are no faces in the aligned directory

if self.faces_to_swap returns None then skip_face returns false

So this should work fine. Can you provide a traceback?

",set none either directory provided directory none false work fine provide,issue,negative,positive,neutral,neutral,positive,positive
383914384,"@torzdf 

I'll look into these issues, no worries about me having to open a new PR.

I hadn't yet added ffmpy to the dependencies/dependency checks similar to the gui since this was just an alpha test to help me find bugs that I may have missed. :)

As for the video generation I'll try to figure it out. The issue is limited only to gui since this is a tkinter file selection thing.
I was wondering, do you think if I instead of prompting the user to load a file, I used file saving to create a dummy file that ffmpeg will overwrite is a decent fix, or is it too hacky?

Edit: I actually just realized that I could create and then right away remove the dummy file, since all I need is the path, not the file. I'll add in the fixes and changes and open a new PR either today or tomorrow.",look open new yet added similar since alpha test help find may video generation try figure issue limited since file selection thing wondering think instead user load file used file saving create dummy file overwrite decent fix hacky edit actually could create right away remove dummy file since need path file add open new either today tomorrow,issue,positive,positive,neutral,neutral,positive,positive
383913023,"Erm..

I switched to staging and I still have the problem where if I don't give the -a parameter at convert time, I have a ""NoneType"" error.

In convert.py (in staging), I see:

```
def check_skipface(self, filename, face_idx):
        """""" Check whether face is to be skipped """"""
        if self.faces_to_swap is None:
            return False
        face_name = ""{}_{}{}"".format(Path(filename).stem, face_idx, Path(filename).suffix)
        face_file = Path(self.args.input_aligned_dir) / Path(face_name)
        skip_face = face_file not in self.faces_to_swap
        if skip_face:
            print(""face {} for frame {} was deleted, skipping"".format(
                face_idx, os.path.basename(filename)))
return skip_face
```
I misread or it's still using the parameter, even if it's ""None""?",switched staging still problem give parameter convert time error staging see self check whether face none return false path path path path print face frame skipping return misread still parameter even none,issue,negative,negative,negative,negative,negative,negative
383902706,Got GUI working in docker. Why do we need to configure linux now :laughing: ,got working docker need configure laughing,issue,negative,neutral,neutral,neutral,neutral,neutral
383900024,"Ok, well that's slightly concerning, but still an improvement on before I think. Before it wasn't possible to convert at all without having an alignments file.

Ultimately I would like to get back to the position where it gets faces on the fly when it converts without an alignments file, but that will require further refactoring, and this is just a step towards that.",well slightly concerning still improvement think possible convert without file ultimately would like get back position fly without file require step towards,issue,positive,positive,positive,positive,positive,positive
383899387,Thanks for this. I'll review when I have a bit more time :),thanks review bit time,issue,negative,positive,positive,positive,positive,positive
383899228,"What graphics card do you have?

I'm using a GTX1080, and this change means that it can extract and convert without generating OOM. It's still not perfect, but it's better than it was before.

Ultimately not extracting the faces is a deliberate choice, as if you want the faces to exist then you are far better off running extract, as you have far more control over how they are extracted and can review prior to running convert. 

I would guess that in 90% of cases, anyone running convert without an alignments file already present is just looking to quickly generate swapped image with little care for keeping the extracted faces.

Either way, this change **should** make it easier to add an option to save the extracted faces at the convert stage in the future. This was my end goal here, rather than adding more options at this stage.",graphic card change extract convert without generating still perfect better ultimately deliberate choice want exist far better running extract far control extracted review prior running convert would guess anyone running convert without file already present looking quickly generate image little care keeping extracted either way change make easier add option save extracted convert stage future end goal rather stage,issue,positive,positive,positive,positive,positive,positive
383894098,"I stand corrected. It doesn't save any aligned face. But I actually wanted it to... :/

My scenario:  I had a directory with more pictures of B (celeb), but I didn't have an alignments.json nor an aligned directory.

I decided to test swapping (BtoA) on these pictures, so I directly ran convert, telling it to store the result in a ""merged"" subdirectory. 

It noticed there wasn't an alignments.json, so proceeded to create an empty ""aligned"" directory and started to convert and save them in the merged directory.

Now, I think it would have been useful if it really extracted the faces, so I could re-use them eventually.

Also, when I checked the ""cnn"" extractor on this occasion, I had:

`Failed to convert image: H:\Fakes\00SRC_DATA\200205121016267.JPG. Reason: Error while calling cudaGetLastError() in file C:\Users\Kirin\AppData\Local\Temp\pip-install-v8ubmnln\dlib\dlib\dnn\gpu_data.cpp:117. code: 2, reason: out of memory`

So I had to rerun my ""convert"" with hog which detects less faces.",stand corrected save face actually scenario directory directory decided test swapping directly ran convert telling store result create empty directory convert save directory think would useful really extracted could eventually also checked extractor occasion convert image reason error calling file code reason memory rerun convert hog le,issue,positive,positive,neutral,neutral,positive,positive
383881454,"Ok, I'm confused...

It does create the output_dir for the merged folder at extract stage, but that is just an effect of the get_folder function which creates a folder if it doesn't exist.

The extract function still uses this if called from convert, but ultimately does not save any faces into it, as the convert function explicitly tells it not to save faces.

The created folder is then used when convert is run when it saves the converted faces to it. I don't really see this as a problem, as ultimately the folder is used, it's just a question of when it is created (prior to the extract or convert).

Ultimately the empty 'aligned' directory IS the final merged folder. This is because input_dir/output_dir is used for both the extract and convert functions. The extra coding required to ultimately reach the same end goal doesn't seem worth it.",confused create folder extract stage effect function folder exist extract function still convert ultimately save convert function explicitly save folder used convert run converted really see problem ultimately folder used question prior extract convert ultimately empty directory final folder used extract convert extra ultimately reach end goal seem worth,issue,positive,negative,neutral,neutral,negative,negative
383877640,It shouldn't save faces at all if it's generating alignments.json from convert. I will take a look. Thanks!,save generating convert take look thanks,issue,positive,positive,positive,positive,positive,positive
383870206,"Found a bug in ""Convert - Change what happens when there is no alignments.json.""

If you attempt to convert when there isn't an alignments.json, then it launches an extract.

BUT, it creates an empty ""aligned"" directory and proceeds to extract faces to... the ""merged"" directory you just specified on the command line, where you intended to put the converted faces.

I understand it uses the defaults options for extraction, but if it creates a directory, then it should use it.",found bug convert change attempt convert extract empty directory proceeds extract directory command line intended put converted understand extraction directory use,issue,negative,negative,neutral,neutral,negative,negative
383819358,"Required_Packages should be parsed from requirements-docker.txt. 
Next time when the pkg list changes, no more need to update the install script.

EDIT: smart load now.",next time list need update install script edit smart load,issue,negative,positive,positive,positive,positive,positive
383748882,Next time I'll try testing prior to merging into staging so a new PR isn't required,next time try testing prior staging new,issue,negative,positive,neutral,neutral,positive,positive
383701342,"ok I'm done. Cross-platform install guide. Tested on two systems. 

It's a tool that detects environment and provides advice so I guess I cant make it a setuptools script as you mentioned above. The tool can't make decisions for users. It's used to give reliable helps according to the environment.",done install guide tested two tool environment advice guess cant make script tool ca make used give reliable according environment,issue,negative,neutral,neutral,neutral,neutral,neutral
383698944,"To be clear. Skip is still in there, I just removed backward compatibility for old naming convention.

Yes, alignments.json is generated entirely if it doesn't pre exist... But only if it doesn't pre exist. This would need to happen anyway if the info was embedded in the pngs",clear skip still removed backward compatibility old naming convention yes entirely exist exist would need happen anyway,issue,positive,positive,neutral,neutral,positive,positive
383679783,"I agree we should look into it, but I don't think we should remove skip, since sometimes you want to rerun extract.  I would want to keep that as default since skip is already available on it's own.",agree look think remove skip since sometimes want rerun extract would want keep default since skip already available,issue,negative,positive,positive,positive,positive,positive
383678138,"For the alignments.json not present, your fix extracts the faces as if an extract command had been run before?

That's where I think iperov's idea would be useful: embedding the landmarks information in the png of the extracted face. He didn't want to keep the alignments.json compatibility so ""stormed out"", but it was a nice idea anyway. I can see no downside to it. It would remove the need for ""skipface"", the alignments.json would become optional and it would help with the port of DFaker model that uses the landmarks for src AND dst.",present fix extract command run think idea would useful information extracted face want keep compatibility nice idea anyway see downside would remove need would become optional would help port model,issue,positive,positive,positive,positive,positive,positive
383554697,I've rolled back for now. It will be when it first creates the model,rolled back first model,issue,negative,positive,positive,positive,positive,positive
383545882,"Nope, it's broken. I pulled it and tried to train (with good args this time):
```

Loading data, this may take a while...
Loading Model from Model_Original plugin...
Failed loading existing training data.
Unable to open file (unable to open file: name = 'H:\Fakes\modelo.src_data.gamer
\encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0,
 o_flags = 0)
Loading Trainer from Model_Original plugin...
Starting. Press ""Enter"" to stop training and save model
Exception in thread Thread-5:.19475, loss_B: 0.20574
Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""C:\Program Files\Python36\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\train.py"", line 225, in processThread
    raise e
  File ""c:\users\kirin\faceswap\scripts\train.py"", line 207, in processThread
    model.save_weights()
  File ""c:\users\kirin\faceswap\plugins\Model_Original\AutoEncoder.py"", line 37,
 in save_weights
    backup_file(model_dir, model)
  File ""c:\users\kirin\faceswap\lib\utils.py"", line 41, in backup_file
    os.rename(origfile, backupfile)
FileNotFoundError: [WinError 2] Le fichier spécifié est introuvable: 'H:\\Fakes\
\modelo.src_data.gamer\\encoder.h5' -> 'H:\\Fakes\\modelo.src_data.gamer\\encode
r.h5.bk'
```

It shows a preview window, but it seems it can't save.

It seems it doesn't create the files if they don't exist?",nope broken tried train good time loading data may take loading model loading training data unable open file unable open file name error message file directory loading trainer starting press enter stop training save model exception thread recent call last file line er file line run file line raise file line file line model file line preview window ca save create exist,issue,positive,negative,neutral,neutral,negative,negative
383540905,This has been taken out of staging for now pending a new PR,taken staging pending new,issue,negative,positive,positive,positive,positive,positive
383540243,"Lol. It's all good. If I'd paid closer attention, I would have realised that it was right there in your very first post ;)

> python c:\users\kirin\faceswap\faceswap.py convert -i **H:\fakes\data_B** -o h:\fakes\data_B\merged -m H:\Fakes\model -S -b 4 -e 2 -D cnn
> Input Directory: H:\fakes\data_B",good closer attention would right first post python convert input directory,issue,negative,positive,positive,positive,positive,positive
383539169,"FCK.

I've been inverting my arguments. I checked an old cmd and indeed I swapped the A and B for the training. I don't know what came over me.

I need a new brain. 

Thanks for your time (well, at least I found a bug in the skipface thx to this, so it's not *totally* wasted).",checked old indeed training know came need new brain thanks time well least found bug totally wasted,issue,negative,negative,neutral,neutral,negative,negative
383537365,"So it should be:

`train -A <Original Face> -B <Replacement Face>`

`convert -i <Original Frames, where A came from> -m <A to B model>`",train original face replacement face convert original came model,issue,positive,positive,positive,positive,positive,positive
383536354,"Wait, what? Your source frames are wrong, aren't they?

That source frame looks like it's from B...

> To train:
> python c:\users\kirin\faceswap\faceswap.py train -A H:\Fakes\%1\aligned -B H:\Fakes\%2\aligned -m H:\Fakes\modelo.%1.%2 -p -bs 64 -ag
> 
> To convert:
> python c:\users\kirin\faceswap\faceswap.py convert -i H:\fakes\%2 -o h:\fakes\%2\merged -m H:\Fakes\modelo.%1.%2 -b 4 -e 2 -S -D cnn -a h:\fakes\%2\aligned

The convert should be:
`python c:\users\kirin\faceswap\faceswap.py convert -i H:\fakes\%1 -o h:\fakes\%2\merged -m H:\Fakes\modelo.%1.%2 -b 4 -e 2 -S -D cnn -a h:\fakes\%2\aligned`

Your convert command is inputting frames from B and passing the A>B model to it, when you should be passing in frames from A.
",wait source wrong source frame like train python train convert python convert convert python convert convert command passing model passing,issue,negative,negative,negative,negative,negative,negative
383535222,"Yes, I have .bk files in the model dir.

I just made a small training session with random new facesets and checked convert: it puts A face on B when I specify ""-s"" to swap.

Train window looks like this, which is OK in my book:

![train1](https://user-images.githubusercontent.com/36699120/39122199-6ef1e6ca-46f4-11e8-9a1d-c9ed6bb170fc.png)

But with the conversion (without the -s), it gives this:

![face1](https://user-images.githubusercontent.com/36699120/39122351-eb4cee9a-46f4-11e8-94d3-3f25bb944ea3.png)

Which is obviously B->B

So, without -s, I have B -> B and with -s I have A -> B

Just, WHY?",yes model made small training session random new checked convert face specify swap train window like book train conversion without face obviously without,issue,positive,negative,negative,negative,negative,negative
383530560,"Ok, this is frustrating!

Seeing as no one else seems to be having this issue, then I can only assume it must be at your end. The issue must be occurring in training though, as you successfully converted with an old model :(

I will probably still push my backup fix, as it resolves the issue with losing any files stored in your model dir, and it should stop the Windows permission error.

Could you confirm that you now have .bk files inside your model_dir after running from my PR?",seeing one else issue assume must end issue must training though successfully converted old model probably still push backup fix issue losing model stop permission error could confirm inside running,issue,negative,positive,positive,positive,positive,positive
383529902,"I tested conversion both with your PR and with 9dc151e and it still insists on putting face B to B.

It's maddening. I'm sure my arguments are good, because I just made two shell scripts, one for training and one for conversion and I feed them the exact same arguments: A faceset name and B faceset name. 

And the preview looks ok.

To train:
`python c:\users\kirin\faceswap\faceswap.py train -A H:\Fakes\%1\aligned -B H:\Fakes\%2\aligned -m H:\Fakes\modelo.%1.%2 -p -bs 64 -ag
`

To convert:
`python c:\users\kirin\faceswap\faceswap.py convert -i H:\fakes\%2 -o h:\fakes\%2\merged -m H:\Fakes\modelo.%1.%2 -b 4 -e 2 -S -D cnn -a h:\fakes\%2\aligned`

But then, at convert time, it reconstructs B face on output frame instead of A face.

I'm stumped.

I'm going to try with completely different face sets and start from scratch.",tested conversion still face maddening sure good made two shell one training one conversion feed exact name name preview train python train convert python convert convert time face output frame instead face going try completely different face start scratch,issue,negative,positive,positive,positive,positive,positive
383522976,"Ok, I have raised a PR to hopefully fix this issue #371 

Please could you test, and if it works I will push it.",raised hopefully fix issue please could test work push,issue,positive,neutral,neutral,neutral,neutral,neutral
383516344,"That's exactly what I'm doing. Great men think alike :smile: 

I just reverted to 9dc151e

I reused the same model files and suddenly, instead of 0.017, the loss shot up to 0.03x, even though the preview almost looks like how it looked at 0.017

I see hope!",exactly great men think alike smile model suddenly instead loss shot even though preview almost like see hope,issue,positive,positive,positive,positive,positive,positive
383515289,"That first issue **should** be fixed in my refactor that I hope to push to staging today.

I'm still working on the assumption that it is the backup function that is somehow corrupting your model, so I'm going to work on a fix (I'm going to keep the backups within the model_dir. This will also mean that any additional files placed there won't be deleted)

It would be really useful to me if you could pull the last commit prior to the backup being implemented and test in the meantime (so pull this commit: 9dc151e5b58abb5f8862d2aa84124ed86156e0b8)",first issue fixed hope push staging today still working assumption backup function somehow corrupting model going work fix going keep within also mean additional wo would really useful could pull last commit prior backup test pull commit,issue,positive,positive,neutral,neutral,positive,positive
383511100,"Ok, I'm going to rollback this commit for now, as there are one or two minor bugs/changes required, so please raise a new PR.

I tested this solely in the GUI.

- ffmpy needs adding to requirements files
- When running gen-vid I am not able to specify a new video name, I have to select an existing video
- when running extract I get the follwing error, despite setting an output directory:
```
Traceback (most recent call last):
File ""/home/user/fake/faceswap/tools.py"", line 41, in <module>
arguments.func(arguments)
File ""/home/user/fake/faceswap/tools/effmpeg.py"", line 371, in process_arguments
""{}"".format(self.output.path))
ValueError: The chosen action requires a directory as its output, but you entered: None
```
",going rollback commit one two minor please raise new tested solely need running able specify new video name select video running extract get error despite setting output directory recent call last file line module file line chosen action directory output none,issue,negative,positive,positive,positive,positive,positive
383502295,Still have the problem with my conversion being swapped though. It's driving me mad.,still problem conversion though driving mad,issue,negative,negative,negative,negative,negative,negative
383502116,"In the current master, I narrowed down the error about ""expected str, bytes or os.PathLike object, not NoneType"" down to the skipface function.

```
   def check_skipface(self, filename, face_idx):
        aligned_face_name = '{}_{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
        aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(aligned_face_name)
        # TODO: Remove this temporary fix for backwards compatibility of filenames
        bk_compat_aligned_face_name = '{}{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
        bk_compat_aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(bk_compat_aligned_face_name)
        return aligned_face_file not in self.input_aligned_dir and bk_compat_aligned_face_file not in self.input_aligned_dir
```

The problem is obvious I think? The line:

`aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(aligned_face_name)`

uses the ""self.arguments.input_aligned_dir"", which is None if no -a option has been given, so BOOM!

Workaround is to specify -a",current master error object function self path path path path remove temporary fix backwards compatibility path path path path return problem obvious think line path path none option given boom specify,issue,negative,neutral,neutral,neutral,neutral,neutral
383415154,"I'm looking at the histories of 

plugins/Convert_Masked.py, 
plugins/Model_Original/
scripts/convert.py

and I can't see any changes that would effect a swap. I also did a ton of training and converting yesterday (in excess of 50k frames) and everything ran smoothly... :confused:",looking ca see would effect swap also ton training converting yesterday excess everything ran smoothly confused,issue,negative,negative,negative,negative,negative,negative
383414219,"Yeah, I use the original model. 

But I think it swaps somewhere it shouldn't.",yeah use original model think somewhere,issue,positive,positive,positive,positive,positive,positive
383413097,"Which model are you using? There was a change implemented recently for swapping on IAE, although it looks like you are using the Original Model, so I doubt it's that (7aa6ba5b5e0bcf4aceec73168c1cf69b4f4d2193).

Looking at your errors, It looks like it doesn't like moving the model to a pre-existing back up folder (on Windows at least). This is strange, and I can't see why this would corrupt your model.

I'll look at this code tomorrow, to see if something more robust can be created for backing up, which... ironically... was to protect against model corruption!

",model change recently swapping although like original model doubt looking like like moving model back folder least strange ca see would corrupt model look code tomorrow see something robust backing ironically protect model corruption,issue,positive,negative,neutral,neutral,negative,negative
383412201,"lool.. I trained the older model for a few minutes, it saved, and now it puts B -> B face as above.

It destroyed my good files -_-

I think something is inverted somewhere, but I don't know where.",trained older model saved face good think something inverted somewhere know,issue,positive,positive,positive,positive,positive,positive
383411621,"I unearthed older trained model h5 files that I was satisfied with, using the same A face, and it converted normally. I didn't train so it's not ""perfect"", but the result is there.

So... is there some inversion of the layers here?",unearthed older trained model satisfied face converted normally train perfect result inversion,issue,positive,positive,positive,positive,positive,positive
383409466,"I tried to convert with the same model files to another target and as expected, it put the face of B on which I trained on the target. Why? I don't want that face. I want the face of A.

Maybe something weird happens because of the backup?

Edit: another bug. When I stopped the training right now (without gui), with Enter, it errored: 

```
Exit requested! The trainer will complete its current cycle, save the models and
 quit (it can take up a couple of seconds depending on your training speed). If
you want to kill it now, press Ctrl + c
Exception in thread Thread-5:.01816, loss_B: 0.01909
Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\shutil.py"", line 544, in move
    os.rename(src, real_dst)
FileExistsError: [WinError 183] Impossible de créer un fichier déjà existant: 'H
:\\Fakes\\model' -> 'H:\\Fakes\\model_bk'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\threading.py"", line 916, in _bootstrap_inn
er
    self.run()
  File ""C:\Program Files\Python36\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\kirin\faceswap\scripts\train.py"", line 225, in processThread
    raise e
  File ""c:\users\kirin\faceswap\scripts\train.py"", line 216, in processThread
    model.save_weights()
  File ""c:\users\kirin\faceswap\plugins\Model_Original\AutoEncoder.py"", line 38,
 in save_weights
    shutil.move(model_dir,  model_dir + ""_bk"")
  File ""C:\Program Files\Python36\lib\shutil.py"", line 555, in move
    symlinks=True)
  File ""C:\Program Files\Python36\lib\shutil.py"", line 315, in copytree
    os.makedirs(dst)
  File ""C:\Program Files\Python36\lib\os.py"", line 220, in makedirs
    mkdir(name, mode)
PermissionError: [WinError 5] Accès refusé: 'H:\\Fakes\\model_bk
```

There's something fishy here, but I can't understand what.",tried convert model another target put face trained target want face want face maybe something weird backup edit another bug stopped training right without enter exit trainer complete current cycle save quit take couple depending training speed want kill press exception thread recent call last file line move impossible de un handling exception another exception recent call last file line er file line run file line raise file line file line file line move file line file line name mode something fishy ca understand,issue,negative,negative,neutral,neutral,negative,negative
383409140,"It gets weirder and weirder. 

Actually, it DOES convert. but it puts reconstructed original face at almost the exact same place, so I had to flip between extracted frame and converted frame to notice it that it indeed modified the image.

I tried to swap (-s) and then it placed something else as the face, but it's something that doesn't look much like the preview, more like something not properly learned.

I'm pretty sure I trained with the good -A and -B, because the preview is normal, with AAB, AAB, BBA, BBA on each line and a loss of 0.017",actually convert reconstructed original face almost exact place flip extracted frame converted frame notice indeed image tried swap something else face something look much like preview like something properly learned pretty sure trained good preview normal line loss,issue,positive,positive,positive,positive,positive,positive
383405588,I'm going to reset my environment. Uninstall/Reinstall python and all the dependencies and get a fresh clone of faceswap.,going reset environment python get fresh clone,issue,negative,positive,positive,positive,positive,positive
383401696,"Ok, this is just weird. Could you roll back to an earlier known working commit and let me know if the issue goes away?

If so, please let me know which commit it is so I can see what might have changed, because I can't replicate the issue.",weird could roll back known working commit let know issue go away please let know commit see might ca replicate issue,issue,positive,negative,negative,negative,negative,negative
383401420,"Yes. 
Imma install cuda cudnn on windows, and install dep from clean python to decide pkgs. They looks simple cos on windows everything seems to be packed well...",yes install install clean python decide simple co everything well,issue,positive,positive,positive,positive,positive,positive
383401176,"I even renamed the ""aligned"" directory, so it would convert everything eventually, but it did nothing.",even directory would convert everything eventually nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
383401053,"I rebooted, nothing changed. The target frames are left as-is.

BUT, for the false positive I mentioned above, with verbose, it printed:

```
Reading alignments from: H:\fakes\data_B\alignments.json
  1%|?                                       | 13/1988 [00:08<22:20,  1.47it/s]Note: Found more than one face in an image! File: H:\fakes\data_B\pic0012.png
```

And it just put garbage at the ""second face"" place, while leaving the ""normal face"" untouched.

WTF?",nothing target left false positive verbose printed reading note found one face image file put garbage second face place leaving normal face untouched,issue,positive,negative,neutral,neutral,negative,negative
383400797,"No problem. Hopefully Mac won't be too problematic as it's Unix based anyway, and I'd imagine that it is the smallest user base, mainly because most Macs don't have Nvidia GPUs",problem hopefully mac wo problematic based anyway imagine user base mainly,issue,negative,negative,negative,negative,negative,negative
383400411,"I thought about py guide for cross-platform just before PR, but the script is originally designed for linux user to solve massive dependency issues. I think user on Windows has no big problem on it. Well yes I made a mistake to delete req.txt so windows/mac user now dont have one reference for pip.

Short answer: Yes I can manage to do that on Windows. It's just that I need to find other ways to detect libraries. Update in 24h later I guess.

However I dont have a Mac so I cant test errors of the script. All I can do is based on your document.",thought guide script originally designed user solve massive dependency think user big problem well yes made mistake delete user dont one reference pip short answer yes manage need find way detect update later guess however dont mac cant test script based document,issue,negative,positive,neutral,neutral,positive,positive
383396310,"I really appreciate the work you've put into this, but I'm loathe to implement a linux only solution when we definitely have a lot of cross platform users.

Would there be any way to re-implement this as a cross-platform Python solution rather than a linux only bash script (along the lines of https://github.com/davisking/dlib/blob/master/setup.py )",really appreciate work put loathe implement solution definitely lot cross platform would way python solution rather bash script along,issue,positive,positive,neutral,neutral,positive,positive
383395374,"^^ I'm guessing you should get a load of ""Failed to convert image: {}. Reason: {}"" errors.
I will look to implement proper logging at some point to easier diagnose these types of issues.
",guessing get load convert image reason look implement proper logging point easier diagnose,issue,negative,neutral,neutral,neutral,neutral,neutral
383394953,"I don't understand. I re-extracted everything and tried to convert: it just copied the source images untouched, EXCEPT a false positive, where it just added some garbage.

![gamer0012](https://user-images.githubusercontent.com/36699120/39097430-58c5fd52-465c-11e8-9d82-2104bc623d57.png)
",understand everything tried convert copied source untouched except false positive added garbage,issue,positive,negative,neutral,neutral,negative,negative
383392002,"I fetched your pull request, and I don't have the ""expected str..."" messages anymore, but Masked converter is broken: it doesn't convert anything.

I added ""-c Adjust"" and it then started to put new faces on the merged faces (though it's really ugly).

So, something is broken in Masked?",fetched pull request masked converter broken convert anything added adjust put new though really ugly something broken masked,issue,negative,negative,negative,negative,negative,negative
383390348,"Since every model saves files prefixed with the model name (except the original), I sometimes used the same directory to store the files for a specific dataset to compare result between models.

With this problem, all my previous trainings with other models would have been wiped out. 

In general, assuming the directory is dedicated to this training session is a bad idea, because it deletes unrelated files without the user's knowledge.",since every model prefixed model name except original sometimes used directory store specific compare result problem previous would general assuming directory training session bad idea unrelated without user knowledge,issue,negative,negative,neutral,neutral,negative,negative
383389576,"I get what you're saying, it's a fairly edge case though. ",get saying fairly edge case though,issue,negative,positive,positive,positive,positive,positive
383389113,"Well, that's a bug to me. 

Instead of moving everything in the bk directory, it should only move relevant files.",well bug instead moving everything directory move relevant,issue,negative,positive,positive,positive,positive,positive
383388730,"FYI this has been merged into the staging branch. To test this and any other new features that will hopefully make their way into Master, please clone the staging branch of this repo.

https://github.com/deepfakes/faceswap/tree/staging

Feedback, either good or bad, is appreciated as it enables us to get it as correct as possible prior to merging into Master.",staging branch test new hopefully make way master please clone staging branch feedback either good bad u get correct possible prior master,issue,positive,positive,neutral,neutral,positive,positive
383387922,"Oh, yeah. You'll lose them in the model files for sure. The process now backs #349 up the old model before saving the new model, so at a save iteration your fsw file will have been moved to model_bk, then at the next iteration it would have been removed entirely.",oh yeah lose model sure process old model saving new model save iteration file next iteration would removed entirely,issue,positive,positive,positive,positive,positive,positive
383387025,Is there some house cleaning on startup that would remove it?,house cleaning would remove,issue,negative,neutral,neutral,neutral,neutral,neutral
383386966,Maybe it's because I saved it in the same directory than the model files?,maybe saved directory model,issue,negative,neutral,neutral,neutral,neutral,neutral
383385990,"I've seen this before but can't remember the issue....

If at all possible, could you test with this PR #367 as that whole section has been rewritten, so rather than hunt down a bug in potentially obsolete code, it may be fixed in this future commit.

Alternatively you can clone from the refactor branch in my repo, which is the same code, if you would like to keep it separate. NB, this is beta, but I did a lot of converting yesterday with no issues.",seen ca remember issue possible could test whole section rather hunt bug potentially obsolete code may fixed future commit alternatively clone branch code would like keep separate beta lot converting yesterday,issue,negative,positive,neutral,neutral,positive,positive
383385655,"The file shouldn't be touched, so there must be something else going on.

A file object is only created twice: Once when it is opened to read the data, and once when it is opened to save. Other than that it is not touched.",file touched must something else going file object twice read data save touched,issue,negative,neutral,neutral,neutral,neutral,neutral
383376433,"@torzdf sure I'd be happy to give your changes a look.

From the changes I've made to `lib/cli.py` the only ones needed to make the gui and effmpeg function properly are the classes I have added to extend the `FullPaths` class (`DirFullPaths`, `FileFullPaths` and `ComboFullPaths`), and the addition of `""action"": FileFullPaths,` to the `alignments_file` argument in the general argument processing class found in `lib/cli.py`.",sure happy give look made make function properly class added extend class addition action argument general argument class found,issue,negative,positive,positive,positive,positive,positive
383373807,"Again, I'm closing this as it has been several months with no progress. If this is problematic, please feel free to reopen.",several progress problematic please feel free reopen,issue,positive,positive,positive,positive,positive,positive
383373728,"I'm closing this, as it seems no one has the time/inclination to create pre-built packages, and also @deepfakesclub  has picked up a bit of the slack on deepfakes.club.

Feel free to re-open if any progress is likely to be made.",one create also picked bit slack feel free progress likely made,issue,positive,positive,positive,positive,positive,positive
383373405,"@LLALLA0925 I have a PR currently up for testing (#367) that finishes training when target epochs are reached. It only works, however, if the -p (preview) flag is enabled. Feel free to test.",currently testing training target work however preview flag feel free test,issue,positive,positive,positive,positive,positive,positive
383373268,"I'm closing this for now, as I will pick up the locale issue with my next GUI version. @frosty3907 if you are still having problems, please open another issue.",pick locale issue next version frosty still please open another issue,issue,negative,neutral,neutral,neutral,neutral,neutral
383368612,I was thinking about this myself. I will add it to the 0.3.0 feature list.,thinking add feature list,issue,negative,neutral,neutral,neutral,neutral,neutral
383320354,"Thanks for this, going to start testing tomorrow.

I've actually completely re-written the lib.cli and scripts section, so I'm going to try to merge both of these into staging at the same time. I would like to get your thoughts on my changes (will raise the PR tomorrow), as whilst I think it's a significant improvement, I've got to the point where I can't see the wood from the trees, so there is likely scope to improve more.
",thanks going start testing tomorrow actually completely section going try merge staging time would like get raise tomorrow whilst think significant improvement got point ca see wood likely scope improve,issue,positive,positive,positive,positive,positive,positive
383275916,"Try screen tool,works great on me!
1.sudo apt install screen
2.screen -S name
3.Run the training ,ctl + a then press d
4.if you want to see the progress,screen -r -d
",try screen tool work great apt install screen name training press want see progress screen,issue,positive,positive,positive,positive,positive,positive
383275757,"Are you training cpu? if so, probably weeks.

You want to be aiming for less than 0.02 in both loss_A and loss_B

10k iterations at 64 batch size would probably be the bare minimum to get close, depending on the sources.",training probably want aiming le batch size would probably bare minimum get close depending,issue,negative,positive,neutral,neutral,positive,positive
383130409,"and there https://github.com/YuvalNirkin/face_segmentation/issues/8 man report fail on side faces

also latest best segmentation nn is https://github.com/sadeepj/crfasrnn_keras , currently only cpu version",man report fail side also latest best segmentation currently version,issue,negative,positive,positive,positive,positive,positive
383085263,There is no examples of side faces and how mask will flickering in video.,side mask flickering video,issue,negative,neutral,neutral,neutral,neutral,neutral
383008587,"@frosty3907 I'd say that this is a different issue than the first one raised.

That first issue should be catchable, but without a traceback it's a little hard to diagnose. At some point it may be worth implementing logging to better support these kind of bugs.

The second one is strange as, afaik gpus has never been a required positional argument",frosty say different issue first one raised first issue catchable without little hard diagnose point may worth logging better support kind second one strange never positional argument,issue,positive,positive,positive,positive,positive,positive
382941377,I wonder if this is due to incorrect upgrade procedure? I basically just git cloned the url into the winpython /faceswap folder and i've just tried restoring the previous version archive I had used to get the functionality back but now it doesn't work either (TypeError: __init__() missing 1 required positional argument: 'gpus'),wonder due incorrect upgrade procedure basically git folder tried previous version archive used get functionality back work either missing positional argument,issue,negative,negative,negative,negative,negative,negative
382937700,"I'm getting similar error using portable winpython install after git clone to new version with convert:
Failed to convert image: D:\faceswap\data_A\sbla0305.png. Reason: expected str, bytes or os.PathLike object, not NoneType

edit: I've tried changing all back/forward slash no difference, it 'processes' images that it can't find a face in, but anything with a face fails.

edit 2: my code page is 850",getting similar error portable install git clone new version convert convert image reason object edit tried slash difference ca find face anything face edit code page,issue,negative,positive,neutral,neutral,positive,positive
382881832,"If you just want to solve this issue though, and go with cpu dlib, then

`pip3 install cmake`

should have you covered",want solve issue though go pip install covered,issue,negative,neutral,neutral,neutral,neutral,neutral
382377080,"To be honest, I do not know what to do. However, my image file names are all numbers.",honest know however image file,issue,positive,positive,positive,positive,positive,positive
382321319,"Thanks for the bug report. This is now fixed in commit 8004a72bbdd2ecf63874fce8963d1001c1f0612a
",thanks bug report fixed commit,issue,positive,positive,positive,positive,positive,positive
382293345,"@torzdf I'm already a contributor, so no worries about that. :)

I'm also finishing up some small improvements for the GUI and a new tool that will be an ffmpeg wrapper for the common tasks that have to be done for faceswapping, so I'll be contributing quite a bit shortly.",already contributor also finishing small new tool wrapper common done quite bit shortly,issue,negative,negative,negative,negative,negative,negative
382207822,"Missed a spot in my ugly hacking. Need to also delete this line to drop the mask during conversion:

new_face = mask * new_face + (1 - mask) * normalized_face
",spot ugly hacking need also delete line drop mask conversion mask mask,issue,negative,negative,negative,negative,negative,negative
381924979,"I will look into a locale fix for the next release
",look locale fix next release,issue,negative,neutral,neutral,neutral,neutral,neutral
381924587,"Normally, the / is automatically translated to \ when in Windows by the path functions. But in this instance, it's translated to Won.

I guess the OP could use the Won symbol on his keyboard to specify the directory separator in the gui.

However,  I think it should be up to the program to use unicode in the os.path functions and not assume the locale is UTF-8. The problem could show up in Linux too with other locales and accents in the filepaths. I already noticed that faceswap crashes if there are accents in the images filenames. That's easily solved by renaming the files, but for the directory separator it's another story.

",normally automatically path instance guess could use symbol keyboard specify directory separator however think program use assume locale problem could show already easily directory separator another story,issue,negative,positive,positive,positive,positive,positive
381878405,"It looks like a codepage problem. I think your cmd is set with a Korean double byte codepage which allows you to display Korean characters in the consoles. However, the Korean code page puts the Won symbol at the backslash position. The Japanese codepage is the same with the Yen symbol.

Type ""chcp"" in your console. You'll probably see something like 949 or some large number.

The gui is probably using unicode but the backslash character is translated to a won symbol when interpreted by the exec function.

See https://msdn.microsoft.com/en-us/library/dd317748%28v=vs.85%29.aspx for more information from Microsoft.

Eventually, before launching the gui in the console, try to set the codepage to an international one, like 850 or 437.

""chcp 850"" or ""chcp 437"". 

It can be changed permanently in the language settings of the system for non unicode programs.",like problem think set double display however code page symbol position yen symbol type console probably see something like large number probably character symbol function see information eventually console try set international one like permanently language system non,issue,positive,positive,neutral,neutral,positive,positive
381822926,"Yes, final fit is critical.  Without that, you won't get good results at all.  Expressions, eyes, mouth and general sharpness will all suffer.  You'll end up with something that looks like a blurry mask made by a kindergartner.

Many A to single B reduces time in additional training, but does not remove the need to do that second training.  You must train for every face you want to swap.",yes final fit critical without wo get good mouth general sharpness suffer end something like blurry mask made kindergartner many single time additional training remove need second training must train every face want swap,issue,negative,positive,positive,positive,positive,positive
381821961,"@bryanlyon Very thanks for your share!! You have already tried the many A-single B method, right? 
The ""final fit"" for A -> B is a must step? What if without the final fit, will get poor result? 
  ",thanks share already tried many method right final fit must step without final fit get poor result,issue,positive,positive,positive,positive,positive,positive
381821789,@xiangcong can share the result photo with occlusion ?? ,share result photo occlusion,issue,negative,neutral,neutral,neutral,neutral,neutral
381821167,"@ruah1984  Do you mean ""Masked"" or ""Adjust"" of ""--converter"" parameter? I use the default ""masked"" version.",mean masked adjust converter parameter use default masked version,issue,negative,negative,negative,negative,negative,negative
381808862,"I get the same behavior. The results are much cleaner if I drop the mask: 

new_image = numpy.copy( image[:,:,:3] )

masked_fake_output = rgb

masked_fake_output = rgb

fake = fake_rgb

Sorry for the poor quality diff, the formatting gets bad if I paste it with the +/-.",get behavior much cleaner drop mask image fake sorry poor quality bad paste,issue,negative,negative,negative,negative,negative,negative
381794535,"Thank you for reply. Even though I did change those forward slashes in the paths to backslashes, I still get results like the following image. For reference, the folder before updating to the gui version works well without any problems. I hope my case will help you.

command line image : https://imgur.com/AD3Z6WM",thank reply even though change forward still get like following image reference folder version work well without hope case help command line image,issue,negative,neutral,neutral,neutral,neutral,neutral
381790969,"@andykdy Your changes are fine, I was referring to the changes I recommended to @LLALLA0925 of removing the input() line.  That change will work with his use case, but hurt everyone else's.  Your changes are fine so I'm going to merge them into staging for people to experiment with and verify.

I've merged this into staging. Closing it here, since it's in staging and will get promoted if there are no issues.",fine removing input line change work use case hurt everyone else fine going merge staging people experiment verify staging since staging get,issue,negative,positive,positive,positive,positive,positive
381790443,"I've merged this into staging. Closing it here, since it's in staging and will get promoted if there are no issues.",staging since staging get,issue,negative,neutral,neutral,neutral,neutral,neutral
381788274,I've updated the branch with the merges so it's using the same base.  It should show correct now.,branch base show correct,issue,negative,negative,negative,negative,negative,negative
381785357,"There are more diffs now since #349 was merged in.  There was only one line changed in my original, the bugfix is only the line (face_A,face_B) = (inter_AH5, inter_BH5) if not swapped else (inter_BH5, inter_AH5)",since one line original line else,issue,negative,positive,positive,positive,positive,positive
381784738,"It would undoubtedly not.  Even with many A-single B you have to do a final ""fit"" train with the A face to get the NN to know that face, it's just that it will (probably) be faster to do that final fit train than training a model from scratch.   This is useful for Nic Cage for example where the goal is to put Nic in every movie, they can train the NN to put Nic's face on another actor's body faster than running from scratch.

It still requires training and the initial model takes a LOT longer (My experience shows (N/2)^2 with N face sources) to build than a specific model and requires a very carefully selected initial set of faces.",would undoubtedly even many final fit train face get know face probably faster final fit train training model scratch useful cage example goal put every movie train put face another actor body faster running scratch still training initial model lot longer experience face build specific model carefully selected initial set,issue,positive,positive,positive,positive,positive,positive
381784233,"Sounds good to me. I'll sync up staging to master tomorrow (it's getting late here), and look to get some of the outstanding PRs put into there. As I said in another PR, I'm doing a fairly hefty re-factoring of the scripts section, so it would give me a bit of piece of mind if it wasn't coming straight out of my repo and into master.",good sync staging master tomorrow getting late look get outstanding put said another fairly hefty section would give bit piece mind coming straight master,issue,positive,positive,positive,positive,positive,positive
381783841,"I'm okay with that.  Create the branch and I'll only commit to the staging.  I think we'll need to run fairly rapid merges to master at least for the next few weeks, until people get used to the split branches and we get Master working more stable.",create branch commit staging think need run fairly rapid master least next people get used split get master working stable,issue,positive,positive,positive,positive,positive,positive
381783792,"Nah, it's all good. Just playing devil's advocate to an extent. :) I reckon you should go ahead and chuck this in.

I like the idea of saving the model architecture, to be honest, the Machine Learning part of the code is still just dark arts to me at the moment ;)

I'm currently in the process of rewriting the scripts/cli section as we have some mammouth classes and functions that are becoming fairly unmanageable, mainly along the lines of separating out the arguments from the actual functions and conforming more towards the PEP 8 standard. Hopefully this isn't treading on anyone's toes.",good devil advocate extent reckon go ahead chuck like idea saving model architecture honest machine learning part code still dark moment currently process section class becoming fairly unmanageable mainly along separating actual towards pep standard hopefully treading anyone,issue,positive,positive,positive,positive,positive,positive
381783383,"It shouldn't interfere with #349 at all.  That PR only touches the save and this PR only touches the load.  It doesn't even change the files, it simply makes sure that when swap is enabled it loads A as B and B as A.  In fact, both sets of code should never run in a single operation since only convert uses the swap flag and it doesn't ever save.  This is actually how swap is handled in all other models, it was just incorrectly broken in IAE.",interfere save load even change simply sure swap fact code never run single operation since convert swap flag ever save actually swap handled incorrectly broken,issue,positive,positive,neutral,neutral,positive,positive
381782990,"I don't know if you've solved this, but I would suspect that it is not a gui specific issue as the GUI is just a frontend to call the command line arguments. I'd be interested to know if it is though, as I would like to hunt the issue down if that is the case.",know would suspect specific issue call command line interested know though would like hunt issue case,issue,negative,positive,positive,positive,positive,positive
381782815,"I understand, and I wrote this code for that eventuality.  It can be left in indefinitely with no ill effects even if it is forgotten to be removed.  Honestly, I would prefer to completely refactor the whole model system with the model architecture saved along with the weights.  This is something that is much bigger than would be feasible in a single PR.  This change was just to prevent the few errors that come from misusing the weights from a wrong model.",understand wrote code eventuality left indefinitely ill effect even forgotten removed honestly would prefer completely whole model system model architecture saved along something much bigger would feasible single change prevent come wrong model,issue,negative,negative,neutral,neutral,negative,negative
381782725,"People have been experimenting with using lots of different faces in A to train the algorithm to learn what a face is and using a single face in B. I've never tried it myself though, so I'm not sure if it would have the desired result.",people lot different train algorithm learn face single face never tried though sure would desired result,issue,negative,positive,positive,positive,positive,positive
381782146,"@xiangcong No, it cannot be used to replace someone with another person, it's only for use with swapping A and B.",used replace someone another person use swapping,issue,negative,neutral,neutral,neutral,neutral,neutral
381674126,"Would that be the case with my changes? 
When '\n' is pressed the thread will change 'self.stop' to True which will save the weights and stop training. 
If that's not the case, how could I change the code to accommodate the issue?",would case thread change true save stop training case could change code accommodate issue,issue,positive,positive,positive,positive,positive,positive
381649221,"Sorry, I don't use Windows. You may want to change those forward slashes in the paths to backslashes, because the output there is telling you that the alignments directory (J:/__now_working/faceA_gui/) is empty and that it can't find the alignments file in J:/__now_working/faceA_source_gui/",sorry use may want change forward output telling directory empty ca find file,issue,negative,negative,negative,negative,negative,negative
381645558,"I got the same error when I run the Serializer and Alignments file empty.

So I ran commandline. The result is shown in the image below. Please refer to it. Thank you.

command line image: https://imgur.com/B5d1I05
",got error run file empty ran result shown image please refer thank command line image,issue,negative,negative,neutral,neutral,negative,negative
381636825,"In the first instance, I'd try leaving the Serializer and Alignments file blank and run again. I *think* there's a bug where if you specify alignment file, then it fails. Please confirm if this is the case and I'll look into it.

If that doesn't work, what happens if you try to run from the commandline:
`
python faceswap.py convert -i J:/__now_working/faceA_source_gui/ -o J:/__now_working/output -v -m models -a J:/__now_working/faceA_gui/ -t GAN128 -b 20 -S -M facehull -e 20`

(You may want to double check that before executing)

",first instance try leaving file blank run think bug specify alignment file please confirm case look work try run python convert gan may want double check,issue,negative,positive,neutral,neutral,positive,positive
381526513,"Of course, it's also impossible to mitigate against every occurrence. For example if someone selected the lowmem option and accidentally selected their original model folder, it would rename and overwrite their original model.

My personal opinion (and it is my opinion, it's probably not correct!), is that I don't like implementing code that you know needs to be removed down the line, because it invariably gets forgotten.",course also impossible mitigate every occurrence example someone selected option accidentally selected original model folder would rename overwrite original model personal opinion opinion probably correct like code know need removed line invariably forgotten,issue,negative,positive,neutral,neutral,positive,positive
381525257,"This commit removes the backup model directory from #349 

Although in retrospect, I think backup model dir should probably be a util that gets called to reduce redundancy",commit backup model directory although retrospect think backup model probably reduce redundancy,issue,negative,neutral,neutral,neutral,neutral,neutral
381523393,"My thinking is that Master gets baselined now (or when staging is started), and does not get updated unless it is an urgent bugfix, which should be applied to both branches anyhow. 

PRs get merged into staging, tested, fixed, removed etc there then the staging branch is merged with master and everything is in sync again.

Of course it only works if everyone merging follows the same process. 

And development never really goes as planned ;)",thinking master staging get unless urgent applied anyhow get staging tested fixed removed staging branch master everything sync course work everyone process development never really go,issue,negative,neutral,neutral,neutral,neutral,neutral
381452879,"If you look around, you can find lots of results and examples posted in the various issues and on the web.  We do not directly support sharing results, as we encourage and develop faceswap for personal use only.",look around find lot posted various web directly support encourage develop personal use,issue,positive,positive,neutral,neutral,positive,positive
381452685,"I am fine with it exiting when it reaches the target epoch when the epoch is selected, but that change will also disable the ability to press ""enter"" to exit training for people not using epoch training.",fine target epoch epoch selected change also disable ability press enter exit training people epoch training,issue,negative,positive,positive,positive,positive,positive
381452491,"I've always supported the idea, and as a contributor, you are welcome to run whatever branches you want.  The problem is that it'll be up to you to keep it up to date if there are issues.  I don't see any issues though.",always idea contributor welcome run whatever want problem keep date see though,issue,negative,positive,positive,positive,positive,positive
381434281,"Ok, I think we should merge then, we can always revert if there are issues. It's one of the reasons why I think it would be useful to have a Staging branch though.",think merge always revert one think would useful staging branch though,issue,negative,positive,positive,positive,positive,positive
381430019,This is unfortunately not feasible due to how much data most be synchronized between each client code every epoch.  This is even the bottleneck with multiple gpus in one system.  I'd suggest having each node working on different models and just giving it time.,unfortunately feasible due much data synchronized client code every epoch even bottleneck multiple one system suggest node working different giving time,issue,negative,negative,neutral,neutral,negative,negative
381429812,"I haven't tested (and can't due to vram) but changing the output names explicitly makes sense.  This bug was completely preventing execution, so if it executes, it should be a good add.",tested ca due output explicitly sense bug completely execution good add,issue,negative,positive,positive,positive,positive,positive
381429537,"I'd be fine with that myself, but I've found very few people read here, and we don't have good documentation, so renaming by default seemed like the cleanest option.",fine found people read good documentation default like option,issue,positive,positive,positive,positive,positive,positive
381420534,This should be fixed in PR #349. If your model is corrupted then you can pull the last saved version out of the model_bk folder,fixed model corrupted pull last saved version folder,issue,negative,positive,neutral,neutral,positive,positive
381419134,Graphing added with PR #352 . Please open a new issue if looking to extend functionality.,added please open new issue looking extend functionality,issue,negative,positive,neutral,neutral,positive,positive
381412744,"@iperov  Yeah, I'm just curious about the model dfaker used. Wanner to know the difference between the dfaker model and the models in this project. Because it seems that the last video is quite good~ ",yeah curious model used wanner know difference model project last video quite,issue,positive,negative,neutral,neutral,negative,negative
381398636,"Would it not be better to just change the filenames for lowmem and be done with it? The worst case scenario is that it will just start training the model again with the new filenames, but their old model files will still exist as they won't have been overwritten. If/when the user realises this, they can just change the names manually on their originally trained model.",would better change done worst case scenario start training model new old model still exist wo user change manually originally trained model,issue,negative,positive,neutral,neutral,positive,positive
381398164,"Exactly. But how the images end up in the list depends on the operating system and maybe even the file system. As I'm using Linux and the files lie on an ext4 partition, it might possibly work with e. g. Windows and ntfs... ",exactly end list operating system maybe even file system lie partition might possibly work,issue,negative,positive,positive,positive,positive,positive
381397547,"Ok, thanks, I figured as much, so I figure it was just trimming random frames before. I guess this feature can't be used too much if no one noticed ;)",thanks figured much figure trimming random guess feature ca used much one,issue,negative,positive,neutral,neutral,positive,positive
381397330,"The frame range parameter, when specified as `-fr a-b`, only processes the ath to the bth frame - however the order of the frames was completely arbitrary before I sorted the list of images.

The script would just trim the list of images as such: `imgs[a:b]` which doesn't give any benefit if you don't know the order in which the images are read. ",frame range parameter frame however order completely arbitrary sorted list script would trim list give benefit know order read,issue,negative,negative,neutral,neutral,negative,negative
381396853,Can someone with multi gpus test this? I only have one unfortunately.,someone test one unfortunately,issue,negative,negative,negative,negative,negative,negative
381396820,"I don't use the frame range parameter. What was the effect prior to sorting images, and what does this fix do?",use frame range parameter effect prior fix,issue,negative,neutral,neutral,neutral,neutral,neutral
381354280,"Just cleaning up issues. I'm not sure this is yet in a position where it can be used in this project, but please feel free to request to reopen if you believe otherwise.",cleaning sure yet position used project please feel free request reopen believe otherwise,issue,positive,positive,positive,positive,positive,positive
381353250,"Unless I'm mistaken, this is going off topic, so closing.",unless mistaken going topic,issue,negative,neutral,neutral,neutral,neutral,neutral
381353023,"Just out of interest, is there any reason why you wouldn't want the process to exit when it reaches the target epoch?",interest reason would want process exit target epoch,issue,positive,neutral,neutral,neutral,neutral,neutral
381343663,"In fairness, it isn't obvious. Strange that my High Sierra seemed to come with it (unless it got installed with something else). I'm going to look into why it locks up on macOS and see if I can push a fix in this release.",fairness obvious strange high sierra come unless got something else going look see push fix release,issue,negative,positive,neutral,neutral,positive,positive
381331404,"Ah, I think you may need to install xquartz https://www.xquartz.org/

Could you try that and let me know if it works

More info here:
https://support.apple.com/en-gb/HT201341
",ah think may need install could try let know work,issue,negative,neutral,neutral,neutral,neutral,neutral
381331163,"Ok, that's weird. What about:

`echo $DISPLAY`

from the command line?

Also, from the Python Interactive shell, could you also get the output of:

`print(os.environ)`

",weird echo display command line also python interactive shell could also get output print,issue,negative,negative,negative,negative,negative,negative
381330590,"Could you do me a favour. Could you fire up terminal in macOS and return the results from each of the following from within the environment that you're running faceswap:

`echo $DISPLAY`

next launch a Python Interactive Shell

`python`
or 
`python3`

import the os module:

`import os`

and enter each of the following returning the results:

`print(os.name)`

`print(os.environ['DISPLAY'])`

As an example, my output looks like this:

![screen shot 2018-04-14 at 14 44 21](https://user-images.githubusercontent.com/36920800/38768948-034204e4-3ff3-11e8-89c4-021c12b761a0.png)


",could could fire terminal return following within environment running echo display next launch python interactive shell python python import o module import o enter following print print example output like screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
381325715,"Hmmm, that's strange. I'm testing on macOS 10.13.2, albeit on hackintosh, and it loads (although tends to lock up). When did you clone, as I pushed some changes late last night?",strange testing albeit although lock clone late last night,issue,negative,negative,negative,negative,negative,negative
381306811,@dfaker hm but mask result not same. So i have to include mask decoder.,mask result include mask,issue,negative,neutral,neutral,neutral,neutral,neutral
381305623,"@dfaker 
my dssim loss which work with embedded alpha mask
```
class penalized_loss(object):
            def __init__(self,lossFunc):
                self.lossFunc = lossFunc
                
            def __call__(self,y_true, y_pred):            
                
                tr, tg, tb, ta = tf.split(y_true, 4, 3 )
                pr, pg, pb, pa = tf.split(y_pred, 4, 3 )
   
                t = tf.concat([tr, tg, tb], 3)*ta
                p = tf.concat([pr, pg, pb], 3)*ta

                return self.lossFunc (t,p)
```
works same :) but model size less.
Just now launched it with IAE 128 and super improved df full face match warper",loss work alpha mask class object self self ta pa ta ta return work model size le super full face match warper,issue,negative,positive,positive,positive,positive,positive
381291358,"Finally found it! I somehow ended up with multiple versions of dlib installed next to each other... :man_facepalming: 

Thanks for your time!

This issue can safely be closed now.",finally found somehow ended multiple next thanks time issue safely closed,issue,positive,positive,neutral,neutral,positive,positive
381288281,"I had a similar problem with a different solution.
For me, it turned out to be a broken version of a dlib extension module in the main 'site-packages' folder. Once I removed that, the good version of dlib in 'site-packages/dlib-[version]' is able to be called correctly, and everything works.",similar problem different solution turned broken version extension module main folder removed good version version able correctly everything work,issue,negative,positive,positive,positive,positive,positive
381284590,"Latest version in Master: 

- Fixed warning message when generating graph on first iteration
- Windows version now saves the model when terminating training

If nothing else comes up in the next 24 hours I will raise a PR for this.",latest version master fixed warning message generating graph first iteration version model training nothing else come next raise,issue,negative,positive,positive,positive,positive,positive
381264553,"Yeah, you should raise a PR. Bit concerned that all of the collaborators may have gone awol though",yeah raise bit concerned may gone though,issue,negative,neutral,neutral,neutral,neutral,neutral
381264073,"I had a similar issue a while back, and it turned out something had gone wrong with my CUDA install, so I had to blow it all away and reinstall CUDA and cuDNN. It might be worth checking the CUDA Samples and making sure that they build correctly:

https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html#verify-installation

",similar issue back turned something gone wrong install blow away reinstall might worth making sure build correctly,issue,negative,positive,neutral,neutral,positive,positive
381254323,"Okay, I reinstalled dlib with CUDA support - nothing changed.

According to nvidia-smi, python is using 3.6 GB of my VRAM (however GPU-util is only between 0% and 10%), so I guess it's running on the GPU(?).

Is there a way to check if dlib is running on the GPU or CPU?",support nothing according python however guess running way check running,issue,negative,neutral,neutral,neutral,neutral,neutral
381250239,"I did, with CUDA support. I used the cnn extractor from https://github.com/dfaker/df before and had an extraction rate of about 3 it/s. But I will verify that everything is still setup up correctly...",support used extractor extraction rate verify everything still setup correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
381249054,Did you compile DLIB yourself? If not then you are probably using the CPU for extraction. See here: https://github.com/davisking/dlib/issues/909,compile probably extraction see,issue,negative,neutral,neutral,neutral,neutral,neutral
381238547,@torzdf I did implement just that (only locally so far). I can send a pull request if wanted.,implement locally far send pull request,issue,negative,positive,neutral,neutral,positive,positive
381214910,"I've pushed an update to rewrite the graphing area. There a couple of minor bugs (listed in original post), but nothing that can't wait until version 0.3.0. GAN graphing is now split into separate graphs:

![splitgraph](https://user-images.githubusercontent.com/36920800/38750336-84a9f0ac-3f4c-11e8-959a-544f52384030.png)

I will add the requests to the todo list for the next release.
",update rewrite area couple minor listed original post nothing ca wait version gan split separate add list next release,issue,negative,positive,positive,positive,positive,positive
381127919,I would think not until the extraction problem is fixed.,would think extraction problem fixed,issue,negative,positive,neutral,neutral,positive,positive
381101641,"Thank you for your efforts.
Btw there's a bug in gan128 preview. Raw and masked previews are switched. So if you are gonna implement it be sure to swap those outputs.",thank bug gan preview raw masked switched gon na implement sure swap,issue,positive,positive,positive,positive,positive,positive
381100728,"A couple of feature requests: :)
- For the GAN trainer, add Preview tabs for: Masked, Raw, and Mask Previews
- Keep a continuous graph of all training activity (maybe store data in a sqlite db?)
- Current session, and all time spent training record (e.g.  24 hours current session ; 160 hours total)",couple feature gan trainer add preview masked raw mask keep continuous graph training activity maybe store data current session time spent training record current session total,issue,negative,negative,neutral,neutral,negative,negative
381098157,"@johnc2k Thanks for the confirmation. The current implementation is a little too 'hard-coded' for my liking, so I'm going to rework it. I'm probably going to split Loss D and Loss G into separate graphs as I notice that their ranges are quite different.",thanks confirmation current implementation little liking going rework probably going split loss loss separate notice quite different,issue,negative,positive,neutral,neutral,positive,positive
381097152,"@ruah1984 Rotations changed with this PR: #309 

It still supports the old method, so you could enter either:
`on`
or
`90`
for it to perform as before (these will both check for faces at 90 degree image rotations) ",still old method could enter either perform check degree image,issue,negative,positive,neutral,neutral,positive,positive
381078074,"the pre-trained result video https://youtu.be/LtrKri27za0
as can be seen, is not so good as https://www.youtube.com/watch?v=BU9YAHigNx8 （at 1 minute）
don't know why = = ",result video seen good know,issue,negative,positive,positive,positive,positive,positive
381077044,"IAE is particular. There's been a lot of discussion about it. It produces ""interesting"" faces.

See #283 ",particular lot discussion interesting see,issue,negative,positive,positive,positive,positive,positive
381076250,"Sorry to bother again.
I just tried tried model of [Link Removed]
The result is not so good as the following result.
https://www.youtube.com/watch?v=BU9YAHigNx8

Not sure what's the reason? model is too simple?(I'm trying IAE)  small trying dataset? ",sorry bother tried tried model link removed result good following result sure reason model simple trying small trying,issue,negative,positive,neutral,neutral,positive,positive
381065512,"The models are different. You can't use model files from Fakeapp with Faceswap and vice-versa. As it is closed source, there's no way to tell for sure, but I think that it's a fork of the older original model published in Reddit. I seem to recall it uses the face alignment lib of Adrian Bulat to detect face landmarks, with maybe some tuning. 

I've read here and there that FakeApp was essentially a java gui and packaging of this project, but it's a bit unfair because obviously it has its own features in term of face detection and model.

As for the Fakeapp software, it's not been updated for months, so I don't know if it's dead or if the author is taking his time before releasing something new. 

But at the moment, it's clearly lagging behind this repo.",different ca use model closed source way tell sure think fork older original model seem recall face alignment detect face maybe tuning read essentially project bit unfair obviously term face detection model know dead author taking time something new moment clearly lagging behind,issue,negative,positive,neutral,neutral,positive,positive
381054598,"The patch for the GAN Trainer appears to be working fine; Attached is a session from overnight:

<img width=""816"" alt=""gangraph"" src=""https://user-images.githubusercontent.com/11442993/38722971-9a493fd0-3ef7-11e8-8763-d7cc4602057c.png"">
",patch gan trainer working fine attached session overnight,issue,negative,positive,positive,positive,positive,positive
380985228,"in GUI mode  under extract tab, how i should use the rotation image. something i need to fill up into the blank>??",mode extract tab use rotation image something need fill blank,issue,negative,neutral,neutral,neutral,neutral,neutral
380976029,"Ok, I've pushed a patch for this to my dev_gui branch.

I'm not particularly happy with it, although it works. I'll probably clean it up a bit tomorrow and push it over to master, but it should be graphing GAN fine now.",patch branch particularly happy although work probably clean bit tomorrow push master gan fine,issue,positive,positive,positive,positive,positive,positive
380955802,"Some example output of the GAN trainer:

```
[22:52:31] [0/num_epochs][7] Loss_DA: 0.161376 Loss_DB: 0.208782 Loss_GA: 0.175283 Loss_GB: 0.184821
[22:52:33] [0/num_epochs][8] Loss_DA: 0.174376 Loss_DB: 0.212959 Loss_GA: 0.179937 Loss_GB: 0.181621
[22:52:36] [0/num_epochs][9] Loss_DA: 0.179386 Loss_DB: 0.198652 Loss_GA: 0.183544 Loss_GB: 0.181443
[22:52:39] [0/num_epochs][10] Loss_DA: 0.187953 Loss_DB: 0.201906 Loss_GA: 0.178671 Loss_GB: 0.186508
[22:52:41] [0/num_epochs][11] Loss_DA: 0.172193 Loss_DB: 0.203566 Loss_GA: 0.180436 Loss_GB: 0.182778
[22:52:44] [0/num_epochs][12] Loss_DA: 0.158577 Loss_DB: 0.203690 Loss_GA: 0.176769 Loss_GB: 0.185355
```",example output gan trainer,issue,negative,neutral,neutral,neutral,neutral,neutral
380951231,I haven't tested GAN. I'll need to check the console outputs and see if I can implement.,tested gan need check console see implement,issue,negative,neutral,neutral,neutral,neutral,neutral
380920715,Graph does not appear to work with the GAN trainer,graph appear work gan trainer,issue,negative,neutral,neutral,neutral,neutral,neutral
380906340,If you have save&quit option its ok. Actually I think I can bundle faceswap into an executable so there is no need to install python and dependencies for every OS that runs cudnn (with all faceswap code fully exposed). I wonder if its legal to bundle NVIDIA libraries as well.,save quit option actually think bundle executable need install python every o code fully exposed wonder legal bundle well,issue,positive,positive,neutral,neutral,positive,positive
380904391,"> Please whatever you do don't make it corrupt the saves

It definitely doesn't corrupt saves under Linux (well, no more than the standard scripts do anyway). Unfortunately I can't run training on my windows test VM as it doesn't have enough power to get going... well it might do, I just got bored waiting for it to get through it's first iteration!

I always save a copy of my model before stopping training these days (wait until it gets just passed a save iteration then copy it somewhere else). Corrupt models are devastating.",please whatever make corrupt definitely corrupt well standard anyway unfortunately ca run training test enough power get going well might got waiting get first iteration always save copy model stopping training day wait save iteration copy somewhere else corrupt devastating,issue,positive,negative,negative,negative,negative,negative
380900797,"That's true about not making it OS specific; sadly DPI thing is kind of manifests at Vista/7 (perhaps 8.1) unless you use QT5.
Sure I will edit my clone to see if I can think of something useful. I perhaps shall wait for your PR first. Please whatever you do don't make it corrupt the saves. It takes enormous amount of time to train anything with a single 9800ti.
Thanks for your work.",true making o specific sadly thing kind perhaps unless use sure edit clone see think something useful perhaps shall wait first please whatever make corrupt enormous amount time train anything single ti thanks work,issue,positive,positive,positive,positive,positive,positive
380900377,"Thanks for the tip. I'm going to see if I can find a more platform agnostic way first, as I'm trying to avoid OS specific code as much as possible.

Feel free to edit your clone and let me know if this works though, because I may end up having to go with it.",thanks tip going see find platform agnostic way first trying avoid o specific code much possible feel free edit clone let know work though may end go,issue,positive,positive,positive,positive,positive,positive
380896754,"I am actually running only 1440p (which is probably be 2k). There is no problem with GUI, but preview would also be upscaled which is undesirable. When I had 1080p I still used 125% at MS Windows thus the same issue with upscaling.

Perhaps there is a fancier way, but the most straightforward would be (should go before GUI initialization):

```python
import sys
import ctypes

mswindows = sys.platform=='win32'

if mswindows:    
    from ctypes import*
    user32 = ctypes.WinDLL('user32')
    user32.SetProcessDPIAware(True)
```

PS: Thank's a lot for doing all that. Saved me so much trouble of creating the GUI myself. I already started and like a miracle your commit appears few hours after.",actually running probably problem preview would also undesirable still used thus issue perhaps fancier way straightforward would go python import import import user true thank lot saved much trouble already like miracle commit,issue,positive,positive,positive,positive,positive,positive
380894607,"@andenixa 

> Also could you add video->img and img->video tabs (through ffmpeg). I am not sure what GUI engine you use, but I could add the code for invoking those.

These are scheduled for v0.3.0 :)",also could add video sure engine use could add code,issue,negative,positive,positive,positive,positive,positive
380891127,"Also I think this very minor trick would be found useful by most.
Convert while aligning is super memory intensive specially with cnn and would fail at high resolution. While two step operation of:

1. Find faces&write alignments file
2. Do the conversion step

would never run out of memory.",also think minor trick would found useful convert super memory intensive specially would fail high resolution two step operation find write file conversion step would never run memory,issue,negative,positive,positive,positive,positive,positive
380890683,"I will look into that. I assume you're running at 4k? I only have 1080p, so will have difficulty testing. Is it so small as to be unusable?

Either way, if I find a way it probably won't be implemented until the next release",look assume running difficulty testing small unusable either way find way probably wo next release,issue,negative,negative,negative,negative,negative,negative
380888993,"Could you make it DPIAware @ MS Windows? Even the base version of GUI is supercool but a bit ""blurry"" at high DPI settings.
Also could you add video->img and img->video tabs (through ffmpeg). I am not sure what GUI engine you use, but I could add the code for invoking those.",could make even base version supercool bit blurry high also could add video sure engine use could add code,issue,negative,negative,neutral,neutral,negative,negative
380777740,"I have added the changes to `tools.py` and `tools/sort.py` to @torzdf's branch, so they will be merged in when he releases his new gui.

I'll close this PR.",added branch new close,issue,negative,positive,positive,positive,positive,positive
380445597,"Haha, I suppose this is the typical: ""welcome to free software development, where the same problem gets solved many times by different people."" :p

Some of my changes can be rebased onto your branch, so I'll submit a PR to your branch then for them.
(Things like the import handling.)

Otherwise I'll keep the changes to `tools.py` and `tools/sort.py`; and I'll drop all the gui changes except for:
```python
for command in self.opts.keys():
```
since that's the only change that is needed to allow using the gui with `tools.py`. From looking at your re-write the compatibility will be builtin in the new version, so I don't see it as much of an issue. :)",suppose typical welcome free development problem many time different people onto branch submit branch like import handling otherwise keep drop except python command since change allow looking compatibility new version see much issue,issue,positive,positive,positive,positive,positive,positive
380437028,"NB: It's still buggy and not fully functional, but hope to have it in a working state soon. Any help is always appreciated :)

![image](https://user-images.githubusercontent.com/36920800/38616998-bc7a68b0-3d8d-11e8-93f3-b525664fe4f8.png)
",still buggy fully functional hope working state soon help always image,issue,positive,neutral,neutral,neutral,neutral,neutral
380432048,"You may want to hold fire on the GUI commits. I'll be pushing another version in a couple of days which addresses a lot of these, and has refactored the code significantly (https://github.com/torzdf/faceswap/tree/dev_gui)",may want hold fire pushing another version couple day lot code significantly,issue,negative,positive,positive,positive,positive,positive
380279150,isn't this going to create issues with tensorflow? I use the official pip that requires 9.0,going create use official pip,issue,negative,neutral,neutral,neutral,neutral,neutral
380274221,Install cuda 9.1 as well.  Cuda supports multiple parallel installations.,install well multiple parallel,issue,negative,neutral,neutral,neutral,neutral,neutral
380144070,Im using the same card. set -bs to 32. and it will work. if you kill Xserver it will run better but not necessary. ,card set work kill run better necessary,issue,negative,positive,positive,positive,positive,positive
379921475,Arggh. Annoyingly I found this issue when testing today. I have raised a PR that should fix this. #338 ,annoyingly found issue testing today raised fix,issue,negative,negative,negative,negative,negative,negative
379916558,"I am still getting the message ""Could not detect a display. The GUI has been disabled"" on Windows 10.
Im assuming I need to define the $DISPLAY variable in Windows?",still getting message could detect display disabled assuming need define display variable,issue,negative,negative,negative,negative,negative,negative
379908943,And this is fixed now so I'm going to close it.  Thanks!,fixed going close thanks,issue,negative,positive,positive,positive,positive,positive
379774618,"Previously the scripts worked using 2gb gtx960. But after using the latest commit, I can't even extract the image even by resizing the image to 500x500, the memory seems to be used up by something else.",previously worked latest commit ca even extract image even image memory used something else,issue,negative,positive,positive,positive,positive,positive
379709401,"You are correct. Its a bit of a misnomer the way training is currently implemented. An epoch is batches over the entire dataset. In order to use the epochs arg as true epochs in training the training.py for each model plugin would need to be adapted to use model.fit rather than train_on_batch. This is fairly easy to implement I just havent gotten around to.

model.fit gives us access to keras callbacks which can dynamically adjust the training rate but has issues with resuming training as the new training rate cannot be saved. Ideally we should use fit_generator and utilizing keras built in image augmentation",correct bit misnomer way training currently epoch entire order use true training model would need use rather fairly easy implement havent gotten around u access dynamically adjust training rate training new training rate saved ideally use built image augmentation,issue,positive,positive,positive,positive,positive,positive
379574945,"@bryanlyon @Clorr Is it possible to merge this, as it's a bugfix that will effect anyone using faceswap.py in an headless environment?

I was hoping to get v0.2.0 out tomorrow, but I think it's likely to be a few more days.

Thanks",possible merge effect anyone headless environment get tomorrow think likely day thanks,issue,negative,positive,neutral,neutral,positive,positive
379569950,"Hmm, there seem to be some workarounds, but I only have a single GPU so it will be hard to test for me. Thanks for the heads-up.

https://github.com/keras-team/keras/issues/8123

https://stackoverflow.com/questions/47210811/can-not-save-model-using-model-save-following-multi-gpu-model-in-keras?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa",seem single hard test thanks,issue,negative,negative,neutral,neutral,negative,negative
379563621,Model.save is unfortunately not compatible with the multi GPU model we're using.  Please make sure that you keep a check for this in your implementation.,unfortunately compatible model please make sure keep check implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
379563169,"Only lowmem can work on 2gb of vram.  Also, it requires the full 2gb, so you cannot be running anything else like window managers or graphics like compiz or aero.  Even just a framebuffer might be too much.  When dealing with that little vram, it's very hard to fit all the data needed for training.

The original is not currently working in 4gb of vram either.",work also full running anything else like window graphic like aero even might much dealing little hard fit data training original currently working either,issue,positive,positive,positive,positive,positive,positive
379560856,"I ran the script  with  gtx750ti 2Gb . I can run the extract script correct ,but when I run the train script , the oom happens. I tried run the script in the text command line and with the -bs 32 or -bs 16.But it’s not working.",ran script run extract script correct run train script tried run script text command line working,issue,negative,neutral,neutral,neutral,neutral,neutral
379552517,"working on a model change that I'll likely post later today or tomorrow where everything is ported to use fit_generator. Its not strictly required but it allows you to easily use model.save instead of model.save_weights. 

 This combined with load_model ( instead of load_weights ) allows you to save the model architecture, the loss history, the optimizer architecture, and the current optimizer state. Saving the optimizer state allows you to restore training progress exactly as you left off.

Also one of the nice things that fit_generator allows is callbacks which have dynamic saving, ie. only save if the training loss or any other metric has improved. You can also save much more frequently as the callback is handled by a process while the gpu continues training uniterrupted.
",working model change likely post later today tomorrow everything ported use strictly easily use instead combined instead save model architecture loss history architecture current state saving state restore training progress exactly left also one nice dynamic saving ie save training loss metric also save much frequently handled process training,issue,positive,positive,positive,positive,positive,positive
379508774,"Makes sense.  I could have sworn that at some point the training outputted the loss as it went along but now all i'm seeing is ""Model saved."" over and over.  <shrug>",sense could sworn point training loss went along seeing model saved shrug,issue,negative,neutral,neutral,neutral,neutral,neutral
379508393,"I'm trying to avoid faceswap.py having any dependencies on the GUI, or faceswap.py having to have any code to specifically support it. Obviously there is only so far I can go with this approach!

I will look into tensorboard, but in the meantime I'm just looking to generate a graph with matplotlib based on the loss values output to console, as these are trivial to hook into. Saving the graph from the GUI should be straightforward, but it won't work without the GUI. Porting the code to some kind of file writer as part of train.py should be straightforward though, so it could be looked into if we decided that was the way to go.",trying avoid code specifically support obviously far go approach look looking generate graph based loss output console trivial hook saving graph straightforward wo work without code kind file writer part straightforward though could decided way go,issue,negative,positive,positive,positive,positive,positive
379507956,Looking forward to it!   Request:  could you add a flag to output that graph to a file?   Request #2-- I think [tensorboard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) counts as GUI right? Maybe add a flag to dump a log every so often so TB can be attached and progress monitored that way too?  Cheers!,looking forward request could add flag output graph file request think right maybe add flag dump log every often attached progress way,issue,negative,positive,positive,positive,positive,positive
379506233,"Glad to hear it!

I'm hoping to have another PR in the next couple of days, with console and graph added to the GUI, which will no doubt lead to a whole host more issues ;)",glad hear another next couple day console graph added doubt lead whole host,issue,negative,positive,positive,positive,positive,positive
379506132,"I *think* it worked!  :+1:

Didn't try every permutation but w/o GUI or DISPLAY set it seems to continue on its merry way...",think worked try every permutation display set continue merry way,issue,positive,neutral,neutral,neutral,neutral,neutral
379505990,"Hopefully latest commit got it. Annoyingly I would have caught that I had forgotten to split the GUI check from the DISPLAY check if I'd tested. I only include the GUI check to spit out a useful error message.

I still can't test, but please let me know :)",hopefully latest commit got annoyingly would caught forgotten split check display check tested include check spit useful error message still ca test please let know,issue,positive,negative,neutral,neutral,negative,negative
379505355,Thanks for the feedback. Annoyingly it was the one thing I couldn't test (although I did echo $DISPLAY on a headless machine to see what I would get).  Full Traceback is useful.,thanks feedback annoyingly one thing could test although echo display headless machine see would get full useful,issue,positive,positive,neutral,neutral,positive,positive
379504908,"I don't think you have to go that far.  Assume that gui is not enabled unless proven otherwise, then:

if any parameter == ""gui"" and 'DISPLAY' in environ:
    (now import gui stuff and create object...)

",think go far assume unless proven otherwise parameter environ import stuff create object,issue,negative,positive,neutral,neutral,positive,positive
379503921,One way to fix this would be to encase the call in a try except block.  Make sure you're only capturing the errors that match and let the other errors through.,one way fix would encase call try except block make sure match let,issue,negative,positive,positive,positive,positive,positive
379503917,but all fine even on 2gb original model,fine even original model,issue,negative,positive,positive,positive,positive,positive
379501812,"I'm still seeing this error w/o $DISPLAY set:

```
Traceback (most recent call last):
  File ""faceswap.py"", line 30, in <module>
    subparser, guiparsers, parser, ""gui"", ""Launch the Faceswap Graphical User Interface."")
  File ""/content/faceswap/scripts/gui.py"", line 430, in __init__
    self.root = FaceswapGui(self.opts, self.parser)
  File ""/content/faceswap/scripts/gui.py"", line 49, in __init__
    self.gui = tk.Tk()
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 2020, in __init__
    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)
_tkinter.TclError: no display name and no $DISPLAY environment variable
```

It looks like check_display() only returns if DISPLAY is set [in cases where ""gui"" is the first argument](https://github.com/torzdf/faceswap/blob/gui/scripts/gui.py#L41).  In a headless server-type situation, you would NOT include ""gui"" as an argument, so check_display() always returns True (when gui isn't invoked, if that makes sense.)  In other words, in a headless situation, the check fails checking for ""gui"".  You shouldn't require ""gui"" to check for the DISPLAY being set.  put yet another way, the default behavior right now is to assume that DISPLAY *is* set unless proven otherwise by saying ""gui"" and NOT setting DISPLAY.

You might want to check if gui is any argument rather than just the first BTW.

Finally-- even when I DO add gui as an argument (hoping it would fail due to lack of DISPLAY) to force the check, I get failure on the DISPLAY check:

```
Traceback (most recent call last):
  File ""faceswap.py"", line 30, in <module>
    subparser, guiparsers, parser, ""gui"", ""Launch the Faceswap Graphical User Interface."")
  File ""/content/faceswap/scripts/gui.py"", line 425, in __init__
    if not check_display(cmd) or not import_tkinter(cmd):
  File ""/content/faceswap/scripts/gui.py"", line 41, in check_display
    if command == 'gui' and not environ['DISPLAY']:
  File ""/usr/lib/python3.6/os.py"", line 669, in __getitem__
    raise KeyError(key) from None
KeyError: 'DISPLAY'
```

Might you have meant `environ.get('DISPLAY')` rather than `environ['DISPLAY']`?  You can check if it's set to `None` to avoid this crash.  You might debug this by trying something other than DISPLAY (like TESTDISPLAY) that you know has NOT been set.

You can also say

`IF 'DISPLAY' not in environ:`
    (disable gui)

Hope this helps.
",still seeing error display set recent call last file line module parser launch graphical user interface file line file line file line interactive sync use display name display environment variable like display set first argument headless situation would include argument always true sense headless situation check require check display set put yet another way default behavior right assume display set unless proven otherwise saying setting display might want check argument rather first finally even add argument would fail due lack display force check get failure display check recent call last file line module parser launch graphical user interface file line file line command environ file line raise key none might meant rather environ check set none avoid crash might trying something display like know set also say environ disable hope,issue,negative,positive,neutral,neutral,positive,positive
379496124,"@iperov sounds good, the failings of the warping were one of the things I was least pleased with, a delaunay triangulation with fixed background points sounds like a perfect solution!

I wish my working notes and other suggestions from the wiki hadn't been lost when the subreddit wen down. but they were mostly focused on refinements to the src->dst transformation which by the sounds of it you can simplify.
 
If you're saying you merged the two output channels into a single 4 channel output, I'd warn caution, in my original tests that tended to mess with the other channels in unexpected ways.",good warping one least triangulation fixed background like perfect solution wish working lost wen mostly transformation simplify saying two output single channel output warn caution original mess unexpected way,issue,positive,positive,positive,positive,positive,positive
379493755,"@dfaker hard to  explain due to lack of my english 
1) your face warper doesnt warps to points of dst face exactly. 
2) your points randomizer can produce mash with background

I fixed it in my upcoming global refactoring the best brand new platform for deepfaceswapping and programmers :D 
I use DelaunayTriangles for morph , and points
Also dst->src warp not needed, because why overfit NN with unusable data, if I swap only src->dst, so I just randomizing dst with itself.
Also I dont use DSSIM loss, because mask layer is part of input and output.

I will release whole fork after several tests.

Check my topics in playground.
https://github.com/deepfakes/faceswap-playground/issues/122
https://github.com/deepfakes/faceswap-playground/issues/120
https://github.com/deepfakes/faceswap-playground/issues/125
https://github.com/deepfakes/faceswap-playground/issues/126",hard explain due lack face warper doesnt face produce mash background fixed upcoming global best brand new platform use morph also warp overfit unusable data swap also dont use loss mask layer part input output release whole fork several check playground,issue,positive,positive,positive,positive,positive,positive
379492252,"@iperov wonderful, I'd love to see the bugs, any chance you could issue a PR or have an annotated fork of where you found issues?",wonderful love see chance could issue fork found,issue,positive,positive,positive,positive,positive,positive
379426107,"Ahh, I think I see what you mean @LLALLA0925 
You want the entire process to be chained one after the other so that the entire pipeline is traversed automatically. 
Like bryanlyon said, I don't think that's within the scope of this repository and you'll have to make the change yourself",think see mean want entire process chained one entire pipeline traversed automatically like said think within scope repository make change,issue,negative,negative,negative,negative,negative,negative
379424959,"@LLALLA0925 If you want to make it work just for you, remove the input() line.  It's not something we'll add to the main code, but it'll make yours run like you want.  I'm not sure you'll love the results on epoch only, but that at least will get you working.",want make work remove input line something add main code make run like want sure love epoch least get working,issue,positive,positive,positive,positive,positive,positive
379399051,"Thanks andykdy!! I used this new change. 
  for epoch in range(0, self.arguments.epochs):

                save_iteration = epoch % self.arguments.save_interval == 0

                trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)

                if save_iteration:
                    model.save_weights()

                if self.stop:
                    break

                if self.save_now:
                    model.save_weights()
                    self.save_now = False
            model.save_weights()
            exit(0)
        except KeyboardInterrupt:
            try:
                model.save_weights()
            except KeyboardInterrupt:
                print('Saving model weights has been cancelled!')
            exit(0)
        except Exception as e:
            raise e
            exit(1)
I think this changes only def processThread(self):
but I want to finish all train.py to start convert.py and to fffmpeg automatically.

Someone said the reason why train.py not finish is 
train.py  is waiting ""ENTER"" or ""ctrl + c""
maybe here part :
def process(self):
        self.stop = False
        self.save_now = False

        thr = threading.Thread(target=self.processThread, args=(), kwargs={})
        thr.start()

        if self.arguments.preview:
            print('Using live preview')
            while True:
                try:
                    with self.lock:
                        for name, image in self.preview_buffer.items():
                            cv2.imshow(name, image)

                    key = cv2.waitKey(1000)
                    if key == ord('\n') or key == ord('\r'):
                        break
                    if key == ord('s'):
                        self.save_now = True
                except KeyboardInterrupt:
                    break
        else:
            input() # TODO how to catch a specific key instead of Enter?
            # there isnt a good multiplatform solution: https://stackoverflow.com/questions/3523174/raw-input-in-python-without-pressing-enter

        print(""Exit requested! The trainer will complete its current cycle, save the models and quit (it can take up a couple of seconds depending on your training speed). If you want to kill it now, press Ctrl + c"")
        self.stop = True
        thr.join() # waits until thread finishes

I made cmd command (ffmpeg -> extract -> **train -> convert** -> ffmpeg) sequence
but sequence of ( ... **train -> convert** .. ) doesn't work.. 
you change and original code are just waiting key enter or ctrl+c...

can u help me??",thanks used new change epoch range epoch epoch else none break false exit except try except print model exit except exception raise exit think self want finish start automatically someone said reason finish waiting enter maybe part process self false false print live preview true try name image name image key key key break key true except break else input catch specific key instead enter good solution print exit trainer complete current cycle save quit take couple depending training speed want kill press true thread made command extract train convert sequence sequence train convert work change original code waiting key enter help,issue,positive,positive,neutral,neutral,positive,positive
379298932,thanks bryan i thought that was an odd suggestion...,thanks thought odd suggestion,issue,negative,positive,neutral,neutral,positive,positive
379297480,"Ramdisk will definitely fail during a power outage, it's not really an appropriate solution for the issue here.",definitely fail power outage really appropriate solution issue,issue,negative,neutral,neutral,neutral,neutral,neutral
379212547,"@ruah1984 I got the scripts to completely work and pump out some converted images. You'll probably beat me to producing decent content as I only had the training going for 12 hrs and won't be able to spare the pc to train for awhile, I'll be back to this later. But fyi the faces produced after only 12 hours of training on a 1080 at 16 batch were excellent but they didn't seem to mask correctly over data A. As in it looks like the faces haven't 'stretched' correctly over the data A faces. I assume 12 hours isn't enough time and/or not enough training data, being that DFaker model is much more complex. I'll come back to this later, at this point I was only trying to get all the scripts working. 
",got completely work pump converted probably beat decent content training going wo able spare train awhile back later produced training batch excellent seem mask correctly data like correctly data assume enough time enough training data model much complex come back later point trying get working,issue,positive,positive,positive,positive,positive,positive
379193177,"I'm going to add a fairly basic loss graph to the GUI. Of course tensorboard will be able to do a lot more than I'll be able to do, but at least it will be something.",going add fairly basic loss graph course able lot able least something,issue,negative,positive,positive,positive,positive,positive
379192907,"lol.

Well, it's just because I pull the command name in and use that. Maybe I'll change it to Executing:",well pull command name use maybe change,issue,negative,neutral,neutral,neutral,neutral,neutral
379192425,"@fat-tire 

> Aside from that this looks like a cool addition. Nice job. Any reason you're not using a prettier toolkit? Doesn't qt look native in Linux/Windows/Mac OS these days?

Yeah, there are definitely prettier tools out there. tkInter is used as it is part of the standard Distribution. I wanted to avoid adding more requirements where necessary. Whether it should still be part of the standard distro is another question. Ultimately, though, it gets the job done, even if it looks like it was built for WindowsXP ;)

Of course, if someone wants to make a GUI in qt, there is nothing stopping them adding another option ;)",aside like cool addition nice job reason look native o day yeah definitely used part standard distribution avoid necessary whether still part standard another question ultimately though job done even like built course someone make nothing stopping another option,issue,positive,positive,positive,positive,positive,positive
379191071,"Ok, thanks, I'll look to push commits to squash these today",thanks look push squash today,issue,negative,positive,positive,positive,positive,positive
379189594,"@clouders1111 i yet trying this model, not sure what will be the result. you can share once you complete @Clorr have fork this repo. you can refer here
https://github.com/Clorr/faceswap/tree/dev/dfaker

hi @Clorr 

the double pass is for what purpose?? 
>  parser.add_argument(""--double-pass"",
>                             action=""store_true"",
>                             dest=""double_pass"",
>                             default=False,
> help=""Double Pass (DFaker converter only)"")

",yet trying model sure result share complete fork refer hi double pas purpose double pas converter,issue,positive,positive,positive,positive,positive,positive
379154120,Thanks ruah1984. It's all working now. What is the 'warped' window in training supposed to be for? I'm assuming it's applying the model of the face back onto the image so the user can judge whether the model is any good? ie. clear and faultless images mean the models are effective and distorted images mean the model is not complete?,thanks working window training supposed assuming model face back onto image user judge whether model good ie clear faultless mean effective distorted mean model complete,issue,positive,positive,positive,positive,positive,positive
379145600,"GUI also breaks faceswap.py if you aren't currently in the faceswap directory, which was never a requirement before.
`_tkinter.TclError: couldn't open ""icons/open_folder.png"": no such file or directory`",also currently directory never requirement could open file directory,issue,negative,neutral,neutral,neutral,neutral,neutral
379136312,"Also might not want to use the exact phrase ""running train"" as that's slang, for [well, er... ummm](https://www.urbandictionary.com/define.php?term=Running%20train)  <cough> maybe just ""_training..._"" works?

(See #334 for more.  Must say this is a really nice addition)",also might want use exact phrase running train slang well er cough maybe work see must say really nice addition,issue,positive,positive,positive,positive,positive,positive
379131630,How about logging periodically so tensorboard can show all kinds of info beyond loss?,logging periodically show beyond loss,issue,negative,neutral,neutral,neutral,neutral,neutral
379119788,"For what it's worth, something got borked with my install. After blowing everything away and re-installing everything is working as expected. If at all possible, I'd suggest trying to do the same, as you may be trying to hunt a problem that isn't there.",worth something got install blowing everything away everything working possible suggest trying may trying hunt problem,issue,negative,positive,positive,positive,positive,positive
379112555,"@clouders1111, use -t DFaker if not it will load the default - original model.",use load default original model,issue,negative,positive,positive,positive,positive,positive
379109693,"Just make changes to the same branch and it'll automatically update here.

My only suggestion is to remove the print, since the save_weights() already writes out a success message.",make branch automatically update suggestion remove print since already success message,issue,positive,positive,positive,positive,positive,positive
379109284,"That makes sense. This is my first time making a PR
Can I edit this PR to include that change? ",sense first time making edit include change,issue,negative,positive,positive,positive,positive,positive
379097810,"Makes sense. It would probably be worth also changing:

>                  if self.stop:
>                      model.save_weights()
>                      exit()

to

>                  if self.stop:
>                      break

",sense would probably worth also exit break,issue,negative,positive,positive,positive,positive,positive
379089830,"I believe if you stop via CTRL+C and give it sufficient time to save, it'll save even those in-between iterations.",believe stop via give sufficient time save save even,issue,positive,neutral,neutral,neutral,neutral,neutral
379083794,"I haven't tested this but it should work. 
First time submitting a PR.",tested work first time,issue,negative,positive,positive,positive,positive,positive
379083432,"I've been going running through the code again to see exactly what is causing this issue for me.

Your changes seem fine to me and should work as it did before but clearly something is missing somewhere. Just trying to see if I can find a fix.",going running code see exactly causing issue seem fine work clearly something missing somewhere trying see find fix,issue,negative,positive,positive,positive,positive,positive
379071711,"Hey guys attempting to convert now but getting this error. 

**python faceswap.py convert -i ""D:\pythondf\settings\faceswap\data\data_A\img"" -o ""D:\pythondf\settings\faceswap\data\data_A\img\output"" -m ""D:\pythondf\setti
ngs\faceswap\model"" -c DFaker -m DFaker -S**

getting this error:

Failed loading existing training data.
You are trying to load a weight file containing 16 layers into a model with 4 layers.
Model Not Found! A valid model must be provided to continue!

I'm not sure why there would be a layers issue, I let the scripts make its own training files when I started training.",hey convert getting error python convert getting error loading training data trying load weight file model model found valid model must provided continue sure would issue let make training training,issue,negative,positive,positive,positive,positive,positive
378935210,"^^ Ignore this. I've just rolled back to a version from long ago and I'm now having issues with previously working framesets. 

I think there must be something wrong with my install. Going to blow away my VM and start again, but I will continue to test",ignore rolled back version long ago previously working think must something wrong install going blow away start continue test,issue,negative,negative,negative,negative,negative,negative
378899618,"Ok, I've just hit a similar issue, but it's weird. On my version it extracted no faces. Then I ran on a rollbacked version, and it extracted so many false positives it was unreal. I tried again, and I got a ton of unspecified CUDA errors. 

I rebooted and then rollbacked version didn't extract any faces either.

I'm figuring the issue is with the CUDA install somewhere, or with the frames, because on another frameset it is extracting just fine.

I'm going to try some stuff to see if I can identify the issue, but at the moment it's looking like it isn't related specifically to this PR. I now need to find if it's specific to my/your install, the frames or something else.
",hit similar issue weird version extracted ran version extracted many false unreal tried got ton unspecified version extract either issue install somewhere another fine going try stuff see identify issue moment looking like related specifically need find specific install something else,issue,negative,positive,neutral,neutral,positive,positive
378827497,"I researched DFaker data generator and it has several bugs.
I fixed and adapted it to my prog.

my improved Original 64:
![38213384-0745abba-36d2-11e8-9e99-7eb8fa146067 1](https://user-images.githubusercontent.com/8076202/38348898-97b3e920-38b5-11e8-8c05-7421aed78ef6.png)

Fullface 128:
![fsviewer_2018-04-05_09-36-37](https://user-images.githubusercontent.com/8076202/38348901-9fc975da-38b5-11e8-9300-7bda415e03cd.png)


",data generator several fixed prog original fullface,issue,negative,positive,positive,positive,positive,positive
378798315,"I cant reproduce the issue either.
extract -D cnn -r on, extract -D cnn -r on -bt 8, sort -s face-cnn, all worked fine on a unmodified faceswapmaster I downloaded like two hours ago.",cant reproduce issue either extract extract sort worked fine unmodified like two ago,issue,positive,positive,positive,positive,positive,positive
378785410,"> @clouders1111 Is it possible that one of the folders has no valid images in it/no alignment data/not the correct alignment data for the images?

Nope it was all set up correctly, it worked correctly after a computer reset. ",possible one valid alignment correct alignment data nope set correctly worked correctly computer reset,issue,negative,neutral,neutral,neutral,neutral,neutral
378783187,@clouders1111 Is it possible that one of the folders has no valid images in it/no alignment data/not the correct alignment data for the images?,possible one valid alignment correct alignment data,issue,negative,neutral,neutral,neutral,neutral,neutral
378777560,"it shouldn't slow things down too much if it isn't updated too often - there's no need to save every 15 seconds or whatever, every 15 minutes would be fine.",slow much often need save every whatever every would fine,issue,positive,positive,positive,positive,positive,positive
378777228,"neat I'll give those a try, didn't see them in the -h output so I didn't know they existed.",neat give try see output know,issue,negative,neutral,neutral,neutral,neutral,neutral
378761481,"**ISSUE SOLVED: Nevermind it's now working after a computer reset, but no idea why.... I'll keep this post up in case someone else gets this error**

Had another issue come up. It was all working. I tried changing the training data with different faces to use on the model and now when I try to train I'm getting this array error. I re-extracted for new json files and am using the aligned faces. It was working on ~5k images at 16 batch so I've tried to bring it down to ~3.5k at 4 batch to see if it was too many images. I've also tried using a new model. Not sure why it would stop working I can't think of anything I'm doing differently.....

loaded model weights
Loading Trainer from Model_DFaker plugin...
100%|████████████████████████████████████████████████████████████████████████████| 3569/3569 [00:00<00:00, 3871.08it/s]
100%|████████████████████████████████████████████████████████████████████████████| 3569/3569 [00:00<00:00, 3830.57it/s]
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""D:\pythondf\python-3.6.3.amd64\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""D:\pythondf\python-3.6.3.amd64\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\df\scripts\train.py"", line 181, in processThread
    raise e
  File ""C:\df\scripts\train.py"", line 153, in processThread
    trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
  File ""C:\df\plugins\Model_DFaker\Trainer.py"", line 74, in __init__
    images_A[:,:,:3] += images_B[:,:,:3].mean( axis=(0,1,2) ) - images_A[:,:,:3].mean( axis=(0,1,2) )
IndexError: too many indices for array

**ISSUE SOLVED: Nevermind it's now working after a computer reset, but no idea why.... I'll keep this post up in case someone else gets this error**",issue working computer reset idea keep post case someone else error another issue come working tried training data different use model try train getting array error new working batch tried bring batch see many also tried new model sure would stop working ca think anything differently loaded model loading trainer exception thread recent call last file line file line run file line raise file line trainer trainer model file line many index array issue working computer reset idea keep post case someone else error,issue,negative,positive,positive,positive,positive,positive
378761004,"To be honest, I'm just throwing it out there. I tend to leave that part of the code well alone ;)",honest throwing tend leave part code well alone,issue,negative,positive,positive,positive,positive,positive
378760231,"Not exactly a rolling backup, but that should work just fine.  Just so long as we make sure all files are written before being moved, since partial weight changes would be just as corrupting the whole model.",exactly rolling backup work fine long make sure written since partial weight would corrupting whole model,issue,negative,positive,positive,positive,positive,positive
378759633,"We could implement a rolling backup, as I've had several models corrupt too.

copy model > model_backup
save current to model.

I don't know how much this would slow things down though
",could implement rolling backup several corrupt copy model save current model know much would slow though,issue,negative,negative,negative,negative,negative,negative
378758505,"Woah, really. Lol, I've done quite a significant code rework since this push. 

No biggy, I'll roll back to this version and continue development from there.

On the plus side, I should have a whole load of new bug testers now ;)

Thanks!
",really done quite significant code rework since push roll back version continue development plus side whole load new bug thanks,issue,positive,positive,positive,positive,positive,positive
378753887,"This was done exactly right and after testing it several times (including faking up some new arguments) I feel that this is good to add.  Thanks for doing it with so few modifications, since that makes me confident enough to commit it right away.",done exactly right testing several time new feel good add thanks since confident enough commit right away,issue,positive,positive,positive,positive,positive,positive
378752452,"The files written are very large (hundreds of megabytes) and depending on your storage speed can take anywhere from 2-40 seconds to write out, power loss any time during this will cause corruption.  It's a very large amount of time for a power failure to happen,. especially with fast cards, which may save every couple minutes.  This is not something that we can fix in the app as it's a simple matter of not enough time to write it out to disk.

I've run into damaged outputs quite often (due to writing to a file across the network), so I wrote a script that saves a backup of the file every hour.  I recommend doing something similar if you're having a very bad time of it.",written large depending storage speed take anywhere write power loss time cause corruption large amount time power failure happen especially fast may save every couple something fix simple matter enough time write disk run quite often due writing file across network wrote script backup file every hour recommend something similar bad time,issue,negative,negative,neutral,neutral,negative,negative
378751371,"I find that no single filter image will ever work perfectly.  The goal is to reduce the time you spend pruning your extract folder.  I recommend getting at least a few pictures of everyone in the video and using -n like @Kirin-kun said on all the faces you don't want.

Unless you're just trying to build your images for training, then I use the -k with a couple photos of your target face.",find single filter image ever work perfectly goal reduce time spend pruning extract folder recommend getting least everyone video like said want unless trying build training use couple target face,issue,positive,positive,positive,positive,positive,positive
378667185,"Did you try with the nfilter? See #262 

You can add a pic of the person you do not want (-n)",try see add pic person want,issue,negative,neutral,neutral,neutral,neutral,neutral
378583498,"I do plan to add that. 

I just want to get basic functionality tested and merged first, then I will be looking to add on a few bells and whistles. Graphing loss is high on the list.",plan add want get basic functionality tested first looking add loss high list,issue,negative,positive,positive,positive,positive,positive
378581075,"Since you're going that way, I petition for implementing #153 ie, add graph depicting epoch vs loss. The assignee of that issue seems to be AWOL. I was even thinking of doing it myself, but unfortunately, I lack time.

I've been doing some training with GAN and I'm under the impression the loss isn't going down at all. It would help to visualize if the model is progressing or not. ",since going way petition ie add graph epoch loss assignee issue even thinking unfortunately lack time training gan impression loss going would help visualize model,issue,negative,negative,negative,negative,negative,negative
378518740,Ok its working it was because I didn't re extract. Stupid mistake it just didn't click because I had been using these json files with dfaker fine and forgot it's required in the training process for these scripts. ,working extract stupid mistake click fine forgot training process,issue,negative,negative,negative,negative,negative,negative
378504327,"Yep I pulled the entire branch and named that folder C:\df, so it wasn't that. But thanks you've at least confirmed it's not because I was working out of the portable python. 

Now I feel stupid I didn't re extract for new json files, I bet it's that and will report on it when I've tried. ",yep entire branch folder thanks least confirmed working portable python feel stupid extract new bet report tried,issue,negative,negative,neutral,neutral,negative,negative
378483004,"I pulled the entire branch and it works fine with the portable python install.

Did you copy selective files over manually? I was trying to add the changes one by one to figure out what was going on, but I kept getting errors and gave up. Just pulled the whole thing and it works.

Use the extract within the new pull, and manually copy the alignments.json over to the training data directory.

You can switch the extract back to face-alignment and it works fine, but you need to include the minor alterations done in this pull, like add the ""cropped"" parameter.",entire branch work fine portable python install copy selective manually trying add one one figure going kept getting gave whole thing work use extract within new pull manually copy training data directory switch extract back work fine need include minor done pull like add parameter,issue,positive,positive,positive,positive,positive,positive
378460330,"**EDIT: This error has been solved. I didn't re-extract to get new json files before training.**

I am wondering if anyone knows what this error below could mean? I can't seem to train on your scripts. I can train on the original Dfaker scripts fine but I'm trying to use your merged dfaker-faceswap scripts. I've put your scripts into C:\df which is why its referencing it. I'm using powershell from the portable python installs which is working out of pythondf folder. I can use faceswap scripts fine, Dfaker fine, I just can't get it to use your merged Dfaker-faceswap scripts.

**(envs) PS C:\df> python faceswap.py train -A ~/faceswap/data/testA -B ~/faceswap/data/testB -m ~/faceswap/testmodelsdf/
-p -bs 16 -t DFaker**
Model A Directory: D:\pythondf\settings\faceswap\data\testA
Model B Directory: D:\pythondf\settings\faceswap\data\testB
Training data directory: D:\pythondf\settings\faceswap\testmodelsdf
Loading data, this may take a while...
Using live preview
Loading Model from Model_DFaker plugin...
C:\envs\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
WARNING:tensorflow:From C:\envs\lib\site-packages\keras\backend\tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From C:\envs\lib\site-packages\keras\backend\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
2018-04-04 12:12:32.636112: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-04-04 12:12:32.936404: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties:
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.771
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2018-04-04 12:12:32.941632: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
loaded model weights
Loading Trainer from Model_DFaker plugin...
  0%|                                                                                         | 0/5007 [00:00<?, ?it/s]Exception in thread Thread-1:
Traceback (most recent call last):
  File ""D:\pythondf\python-3.6.3.amd64\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""D:\pythondf\python-3.6.3.amd64\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\df\scripts\train.py"", line 181, in processThread
    raise e
  File ""C:\df\scripts\train.py"", line 153, in processThread
    trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
  File ""C:\df\plugins\Model_DFaker\Trainer.py"", line 68, in __init__
    images_A, landmarks_A = load_images_aligned(fn_A[:minImages])
  File ""C:\df\plugins\Model_DFaker\utils.py"", line 23, in load_images_aligned
    faces = alignments[original]
TypeError: list indices must be integers or slices, not list

any advice?

**EDIT: This error has been solved. I didn't re-extract to get new json files before training.**",edit error get new training wondering anyone error could mean ca seem train train original fine trying use put portable python working folder use fine fine ca get use python train model directory model directory training data directory loading data may take live preview loading model conversion second argument float future float import warning calling removed future version use instead warning calling removed future version use instead binary use found device name major minor device device name bus id compute capability loaded model loading trainer exception thread recent call last file line file line run file line raise file line trainer trainer model file line file line original list index must list advice edit error get new training,issue,negative,positive,positive,positive,positive,positive
378217074,"Idiot me removed the actual script execution in final testing before pushing. This has been re-inserted.

GUI is currently successfully running a train.

![image](https://i.imgur.com/wSJfO1H.png)",idiot removed actual script execution final testing pushing currently successfully running train image,issue,negative,negative,neutral,neutral,negative,negative
378207706,"I wouldn't save every 5 iterations, that seems way too low. It defaults to every 100 iterations, and that should be fine.

If you stop training it saves it's current progress. Training will always resume from the last saved point (barring corruption).",would save every way low every fine stop training current progress training always resume last saved point barring corruption,issue,positive,positive,positive,positive,positive,positive
378207020,"Try:
Run with low-mem model (if not already).
Kill X-Server entirely and run from console.",try run model already kill entirely run console,issue,negative,neutral,neutral,neutral,neutral,neutral
377869937,"@Kirin-kun thanks for the sharing, base on YuvalNirkin quote at important note:

"" In our paper we used a different network for our face segmentation. In the process of converting it to the Caffe model used in our [end-to-end face swap distribution ](https://github.com/YuvalNirkin/face_swap)we notices some performance drop. We are working to fix this. We therefore ask that you please check here soon for updated on this Caffe model.""

Paper to share
https://arxiv.org/pdf/1704.06729v1.pdf

We can get the good model, but converting (faceswap) will be the big problem .

Guys any idea? 

",thanks base quote important note paper used different network face segmentation process converting model used face swap distribution performance drop working fix therefore ask please check soon model paper share get good model converting big problem idea,issue,positive,positive,neutral,neutral,positive,positive
377817328,"@reconnais I'm not sure what you mean by ""regular faceswap algorithm"" the networks are substantially different so they're obviously not interchangeable.",sure mean regular algorithm substantially different obviously interchangeable,issue,negative,positive,neutral,neutral,positive,positive
377815822,"That's actually a cool idea-- to create a universal faceswap starter module based on a generalized face training dataset (trained from contributions from the community?)  There's no reason these modules have to be hosted at google, right?  Could use something like:

` embed = hub.Module(""https://github.com/deepfakes/releases/swapmodel-GAN128/1"")`

or whatever.  As someone with an older GPU that doesn't even support CUDA, this would save hours of training I'd assume.


 ",actually cool idea create universal starter module based generalized face training trained community reason right could use something like embed whatever someone older even support would save training assume,issue,positive,positive,positive,positive,positive,positive
377809441,"A ""simpler"" alternative that fits the current pipeline would be for somebody to train the current algorithms (original, gan, whatever) for 1 week on the CelebA dataset and share the resulting models with everyone. It's doable... just some shell scripts to rotate through 10K training images at a time. CelebA is ~200K total.

I set out to do this but realized that the CelebA dataset is largely a waste of time for basic faceswapping after looking through it. (Maybe useful for other training such as superresolution.)

It is derived from celebrity photos, which contain very few angles other than standard portrait poses. If you do not have enough images, what you are lacking is usually a variety of poses. Throwing in more of the same front face poses doesn't help.

At the other end of the spectrum, some people re-use old models for new faces. I hate this, as the results are always contaminated with the old facial features. Some people pre-train 10 faces into a starting model, which probably helps a bit, but I don't think 10 faces is enough.

Videos are a better source material to extract faces with all angles and expressions in volume. I wanted to compile a universal starting model using a better curated training data set. But first, this would require a good way to sort and maximize face diversity in image sets.",simpler alternative current pipeline would somebody train current original gan whatever week share resulting everyone doable shell rotate training time total set largely waste time basic looking maybe useful training derived celebrity contain standard portrait enough usually variety throwing front face help end spectrum people old new hate always old facial people starting model probably bit think enough better source material extract volume compile universal starting model better training data set first would require good way sort maximize face diversity image,issue,positive,positive,neutral,neutral,positive,positive
377735369,"If this works, will the model trained using the dfaker plugin be compatible with the regular faceswap algorithm? I expect not, but if they are incompatible, why not try to merge the advantages of both rather than expend resources to keep both separate?",work model trained compatible regular algorithm expect incompatible try merge rather expend keep separate,issue,negative,neutral,neutral,neutral,neutral,neutral
377718163,"No no download :)  this is something new as of yesterday that google announced, though it may require Tensorflow 1.7 to support it- not sure.  It's brand new.  I'll submit a PR if I have a chance to poke at it, but of course anyone else is welcome to try it out and see how it works, how well and fast it trains etc compared to starting from scratch.

(And hopefully it wouldn't d/l anything unless the plugin was pulled in/active.)",something new yesterday though may require support sure brand new submit chance poke course anyone else welcome try see work well fast starting scratch hopefully would anything unless,issue,positive,positive,positive,positive,positive,positive
377716463,"Of course, and if you issue a PR which provides an option to download that, we can use it.  My only concern was that you were meaning to include the actual model in the package, which would be a large binary file in the git repo.  Even just including it as a default ""add on"" through a script would give the project excessively long downloads when most people wouldn't be using it.

We'd also need to make sure that the model architecture they're using matched our GAN128 (or another module if necessary).  Since a model trained on a different shape would be useless if we don't match it's shape.",course issue option use concern meaning include actual model package would large binary file git even default add script would give project excessively long people would also need make sure model architecture gan another module necessary since model trained different shape would useless match shape,issue,negative,positive,neutral,neutral,positive,positive
377715988,"Fair enough.  Just wanted to put this on everyone's radar.  Didn't mean to imply it would replace the current models, just that it might be added to the `/plugins`  as an option to start training with the common face module from Google and build off that.

I don't think the model size is a big deal, as the module is *not* included in the repository-- the ""mod"" concept is comparable in some way to a library in regular programming-- it's external to the main program.  The video describes that it's downloaded at runtime/buildtime (I'm assuming cached locally) and only a simple link to the module is included in the code.

If I get a chance I'll try it out, but wanted to at least put it out there that this is an option now.",fair enough put everyone radar mean imply would replace current might added option start training common face module build think model size big deal module included repository concept comparable way library regular external main program video assuming locally simple link module included code get chance try least put option,issue,positive,negative,neutral,neutral,negative,negative
377709197,"That said, you are welcome to download the pretrained model and experiment with it.  If you find good results, let us know, we can include a link to it in the instructions.",said welcome model experiment find good let u know include link,issue,positive,positive,positive,positive,positive,positive
377707919,"Pretrained models are generally more work than starting a specific model from scratch.  While there are some gains in ""generic"" I.E. Many faces to one (like done with Cage), it is less useful for one to one faceswapping due to the amount of extra training they require.  Remember, also that any model that is used will be stuck to that model so we can't experiment with other model shapes with a pretrained.  Finally, most models are hundreds of megabytes in size, and including such large binaries would make the project very difficult to download and share.  For these reasons, I doubt that we will use pretrained modules as a major part of this project soon, but if we find a good use for them, I see no reason why we would exclude them.",generally work starting specific model scratch gain generic many one like done cage le useful one one due amount extra training require remember also model used stuck model ca experiment model finally size large would make project difficult share doubt use major part project soon find good use see reason would exclude,issue,positive,positive,neutral,neutral,positive,positive
377707185,"I made a mistake T_T.. I'm using Original trainer. Image sets used were different, please forget about 
> hist_match gives much better results

Should I close this issue? Maybe this would be accidentally helpful for GAN users.",made mistake original trainer image used different please forget much better close issue maybe would accidentally helpful gan,issue,positive,positive,positive,positive,positive,positive
377700360,yeah seems like a bug. although `mask ` is used only for GAN convert and this bug shouldn't have any effect on other trainers. Which trainer did you tried it with?,yeah like bug although mask used gan convert bug effect trainer tried,issue,positive,neutral,neutral,neutral,neutral,neutral
377200526,"Also, shaoanlu has ported  [YuvalNirkin/face_segmentation](https://github.com/YuvalNirkin/face_segmentation) from caffe to keras some time ago. https://github.com/shaoanlu/face_segmentation_keras

I think it would be helpful to implement occlusion masks.",also ported time ago think would helpful implement occlusion,issue,negative,neutral,neutral,neutral,neutral,neutral
377116392,@bryanlyon please don't wait up for me! I don't think adding masks to other models would interfere with anything in the gan stuff anyway.,please wait think would interfere anything gan stuff anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
376936398,I believe that this is ready to merge.  It helps run the Original model on 4gb cards.,believe ready merge run original model,issue,positive,positive,positive,positive,positive,positive
376818063,"Run extract again for existing trainset is absolutely no problem, especially if you have sorttool to sort target quickly.

99% users dont collecting trainsets, they just trying to swap face in some videos with not good result, and they leaves this idea.
I collecting GBs of trainsets, and I have no problem to extract again, if I will get better results in future, because I have all source videos. 
But you guys cant understand this. You are thinking too narrowly. 

I cant fight for every pr, so I decided to leave you. I already regretted that ported face_alignment to keras, you are not worthy of it.  I going to fully refactor crap faceswap architecture from scratch, and remove most of suxx unusable things from it. Users of my windows release will extract faces again with no problem.

@Clorr please dont use code from this pr for your dfaker impromevents.

Bye all, and P.S. sorry bad english.",run extract absolutely problem especially sort target quickly dont trying swap face good result leaf idea problem extract get better future source cant understand thinking narrowly cant fight every decided leave already ported worthy going fully crap architecture scratch remove unusable release extract problem please dont use code bye sorry bad,issue,negative,negative,neutral,neutral,negative,negative
376803540,I agree with @bryanlyon. Embedding data in png's is useful but removing alignment.json all together is a little bit extreme. It would be better if it's optional.,agree data useful removing together little bit extreme would better optional,issue,positive,positive,positive,positive,positive,positive
376802943, please never use my code from this pr,please never use code,issue,negative,neutral,neutral,neutral,neutral,neutral
376802229,"You could change method with format. Store in tExt for PNG and in EXIF for JPGs. I don't think it would be that expensive (but it's up to you, or to someone else who wants to implement it anyway). The piexif lib seem to be able to do that.

But I'm cool with removing the need of a serialization file. Faceswap is a work in progress anyway.",could change method format store text think would expensive someone else implement anyway seem able cool removing need serialization file work progress anyway,issue,positive,positive,positive,positive,positive,positive
376797984,"@iperov the VHS cassette reference made me feel pretty old. :p

<s>I think that they may be</s> They are referring to people's private datasets.

A compromise solution that I can see would be to add an option/functionality that could read an `alignments.json` file and embed the data inside it into the images that the data should be embedded in.  It could also have the functionality of reading a bunch of images and extracting the embedded data into an `alignments.json` file.

Also to maybe allow the choice of how the data should be saved, alignments file or embedding (or both?).

It seems @bryanlyon beat me to explaining this. :)",reference made feel pretty old think may people private compromise solution see would add could read file embed data inside data could also functionality reading bunch data file also maybe allow choice data saved file beat explaining,issue,positive,positive,positive,positive,positive,positive
376797262,"I don't mean downloaded datasets, I mean datasets people are using right now, removing support for those datasets is not an acceptable option.

This PR will force everyone to run extraction in all their source data again.  It will force all users to keep large pngs, even when they don't want the aligned faces at all.  It will reduce tool choice and increase complexity of any tools that want to edit the alignments.  It's also very poorly tested and not ready to implement.

I like the png embedded option, but it's not vastly superior and certainly not ready to replace the alignment files that exist now.  I support it as an option, not as a replacement.

Send a PR with it as an option or saving/loading both at once and I'll support it, until then, I think this PR is premature and more of a negative than a positive.",mean mean people right removing support acceptable option force everyone run extraction source data force keep large even want reduce tool choice increase complexity want edit also poorly tested ready implement like option vastly superior certainly ready replace alignment exist support option replacement send option support think premature negative positive,issue,positive,positive,neutral,neutral,positive,positive
376793253,"So is anyone else able to replicate? I have tested extensively now and all seems fine.

Can we merge or close please.",anyone else able replicate tested extensively fine merge close please,issue,negative,positive,positive,positive,positive,positive
376792441,"Datasets which can be downloaded from reddit, such as Cageset and other - contains NO alignments.json file.

Also these aligned 256x256 photos are useless, because contains no aligned landmarks inside. 
They are like obsolete ""VHS"" cassette, while we are walking to DVD future.

",file also useless inside like obsolete walking future,issue,negative,negative,negative,negative,negative,negative
376790462,"It's not just a matter of backwards compatibility, it's also about jpg support and keeping things simple, editable, and concise.  I agree with the png embedded data, but it should not come at the experience of portability and workflow.

There are edits that I have done that are only possible with a single alignment file.  There are methods and techniques that I see which are only possible with an alignments file.  There are hundreds of datasets with an alignments file.

I'm not saying we can't use embedded png data, just that we shouldn't be abandoning the current system, especially not without a migration plan.",matter backwards compatibility also support keeping simple concise agree data come experience portability done possible single alignment file see possible file file saying ca use data current system especially without migration plan,issue,positive,positive,neutral,neutral,positive,positive
376776518,"with alignments.json I have to manually delete excess faces in data_B\aligned folder, because I cannot rename them by sort tool. This is especially big problem with videos with large amount of faces.",manually delete excess folder rename sort tool especially big problem large amount,issue,negative,positive,positive,positive,positive,positive
376775926,"@bryanlyon 
i see no reason to use alignments.json. It is like ballast. 
Backward compatibility? Are we making OS here? Why collect and support old non-effective solutions?",see reason use like ballast backward compatibility making o collect support old,issue,positive,positive,neutral,neutral,positive,positive
376759297,"Well, it somehow seems related to batch size. as long as I stay below 256 it doesn't happen. Don't know what that is.  Thanks for the help guys looking into this. If I find anything else, I'll post.  I'll go ahead and close this now.",well somehow related batch size long stay happen know thanks help looking find anything else post go ahead close,issue,positive,positive,neutral,neutral,positive,positive
376750421,"@iperov Did you try to train the model with ""-bs 16""? I found using smaller batch size can improve the result on some cases.",try train model found smaller batch size improve result,issue,negative,neutral,neutral,neutral,neutral,neutral
376710605,"While I like the PNG storage feature, I do not like removing alignments.json to get it.  I see no reason that we have to get rid of the alignment.json to add this feature.",like storage feature like removing get see reason get rid add feature,issue,positive,neutral,neutral,neutral,neutral,neutral
376593505,"Actually I did not work much on this lately. The only blocking part is the one with the extract of the data because here, the alignments are needed for the input files. I would like to have a simple solution for that, which could come with embedding landmarks in the input files currently on discussion in https://github.com/deepfakes/faceswap-playground/issues/115",actually work much lately blocking part one extract data input would like simple solution could come input currently discussion,issue,negative,negative,neutral,neutral,negative,negative
376404009,Following this with interest. Any closer to getting this working successfully?,following interest closer getting working successfully,issue,positive,positive,positive,positive,positive,positive
376370704,"@Clorr if you're asking me, yes, as far as I know it's ready to merge.",yes far know ready merge,issue,positive,positive,positive,positive,positive,positive
376341742,"And I just tested with the latest commits merged in, just in case, and I still get a successful extract. To be honest, I'm not sure why anything I've changed should impact on those two switches.",tested latest case still get successful extract honest sure anything impact two,issue,positive,positive,positive,positive,positive,positive
376340211,"@JayantPythonLover I can't replicate. Can you print console output please, this is what I get:
```
(env) user@user-ubuntuVM:~/fake/faceswap_torzdf$ python faceswap.py extract -i /mnt/fakes/Masters/B/subject/test/ -o /mnt/fakes/Masters/B/subject/test_faces -D all -ae
Input Directory: /mnt/fakes/Masters/B/subject/test
Output Directory: /mnt/fakes/Masters/B/subject/test_faces
Filter: filter.jpg
Using json serializer
Starting, this may take a while...
Loading Extract from Extract_Align plugin...
  0%|                                                                                                                                                        | 0/15 [00:00<?, ?it/s]/home/user/fake/env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. Infuture, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Info: initializing keras model...
2018-03-27 00:03:14.734894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-03-27 00:03:14.745142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1331] Found device 0 with properties:
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:05:00.0
totalMemory: 7.93GiB freeMemory: 5.99GiB
2018-03-27 00:03:14.745202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1410] Adding visible gpu devices: 0
2018-03-27 00:03:16.426265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-03-27 00:03:16.426862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2018-03-27 00:03:16.426895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2018-03-27 00:03:16.427638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5780 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:05:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/user/fake/env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:39<00:00,  2.66s/it]
Alignments filepath: /mnt/fakes/Masters/B/subject/test/alignments.json
Writing alignments to: /mnt/fakes/Masters/B/subject/test/alignments.json
-------------------------
Images found:        15
Faces detected:      15
-------------------------
Done!
```

Output folder has 15 faces in it.",ca replicate print console output please get user python extract input directory output directory filter starting may take loading extract conversion second argument float float import model successful node read negative value must least one node node zero found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability warning calling removed future version use instead writing found done output folder,issue,negative,positive,neutral,neutral,positive,positive
376249055,"@torzdf 

I found an issue. Extracting with ""-D all"" and ""-ae"" does not initialize the keras model and hence as a result, the images are read but the faces are not detected.

Can you look in to this please? Thank you.",found issue initialize model hence result read look please thank,issue,positive,neutral,neutral,neutral,neutral,neutral
376213332,"Fixed on latest update, not found side effect issue except a little slow on no face scene.
THANKS ALL !!!
This issue can be closed.",fixed latest update found side effect issue except little slow face scene thanks issue closed,issue,negative,positive,neutral,neutral,positive,positive
376177280,@modelsex also try latest commit,also try latest commit,issue,negative,positive,positive,positive,positive,positive
376173396,Closing due to lack of interest/until I have more time to expand functionality,due lack time expand functionality,issue,negative,negative,negative,negative,negative,negative
376127154,"@iperov Thanks a lot for your guidance, I have tired increase or decrease scale_to, also tired re-scale original 960x544 to 1280x720, seem don't work to improve. ",thanks lot guidance tired increase decrease also tired original seem work improve,issue,positive,negative,neutral,neutral,negative,negative
376068094,"we can fix subj, if make extracting with 2 passes.
First pass detecting rects by dlib with higher scale_to value. Save rects to temp.json. Keras model never loaded.
Second pass detect landmarks from rect in temp.json by keras model, dlib never loaded.",fix make first pas higher value save model never loaded second pas detect rect model never loaded,issue,positive,positive,positive,positive,positive,positive
376064522,"@modelsex try increase

scale_to in FaceLandmarksExtractor.py

#scale_to=2048 with dlib upsamples=0 for 3GB VRAM Windows 10 users        
def extract(input_image, detector, verbose, all_faces=True, input_is_predetected_face=False, scale_to=2048):",try increase extract detector verbose,issue,negative,neutral,neutral,neutral,neutral,neutral
375999305,"Tested this just now, and it turns out that the new `rotate_image` using `getRotationMatrix` is (surprisingly) 30-40% faster than the old flip/transpose method.  This is a nice result, because it means there is no need to special-case 90 degree rotations!

I also switched the convention to use positive value = clockwise rotation, for backwards compatibility.  So, existing alignments.json files should work correctly with the new method.",tested turn new surprisingly faster old method nice result need degree also switched convention use positive value clockwise rotation backwards compatibility work correctly new method,issue,positive,positive,positive,positive,positive,positive
375998199,"@iperov I don't know why you're so against those imports, they're all perfectly reasonable and understandable.  While a refactor would be cleaner, it's a long way out.  An unplanned refactor is worse than hacking.",know perfectly reasonable understandable would cleaner long way unplanned worse hacking,issue,negative,negative,neutral,neutral,negative,negative
375995890,"@Clorr @oatssss @gdunstone 
I suggest close all PRs and start global refactoring.
Lets stop ruining the code such as this PR.

my eyes are bleeding
```
 if face_recognition is None:
            import_face_recognition()

    def sort_face_dissim(self):
        if face_recognition is None:
            import_face_recognition()
        
    def sort_face_cnn(self):
        if FaceLandmarksExtractor is None:
            import_FaceLandmarksExtractor()

```",suggest close start global stop code bleeding none self none self none,issue,negative,neutral,neutral,neutral,neutral,neutral
375993828,"This PR is currently the best solution we have to a horrible set of problems.  Ideally, we'd be importing as needed into each module.  Python explicitly allows you to import in logic, and as long as everything is kept near the top, I have no problem with avoiding imports that aren't necessary until later in the code.  I almost did the same for the multi_gpu_model when I implemented it, but found that it was a minimal effect when -g wasn't called.

In this case, dlib immediately grabs control of the GPU and loads it up with quite a bit of nonsense (In my running it's actually closer to 340MB though it varies from time to time.  On a 4gb card, that's 10% of the memory and makes running the original model impossible on those cards.  Seeing as the Original model was designed for 4gb of vram, I believe that a solution is needed.  Unless we refactor the entire project (including measures such as moving the argument parsing into it's own module file with no imports of external modules) this is the best solution available to us.

I support this PR.  I also recommend we undergo planning for a refactor of the main code.",currently best solution horrible set ideally module python explicitly import logic long everything kept near top problem necessary later code almost found minimal effect case immediately control quite bit nonsense running actually closer though time time card memory running original model impossible seeing original model designed believe solution unless entire project moving argument module file external best solution available u support also recommend undergo main code,issue,positive,positive,positive,positive,positive,positive
375990649,"@JayantPythonLover 

> There are various parts of the code that handle memory in a horrendous fashion and need dealing with.
> 
> I cannot test out the code right now but from what I see of the changes, you seem to be on the right track.
> 
> 

In fairness, if I were building from scratch, this certainly isn't how I would go about approaching this problem, however, my end goal was to be able to run more than one faceswap instance (one for gpu task and one for non-gpu) and to do this with the minimum amount of code change.

If someone wants to go ahead and fix the code in a more robust manner (which should probably be the end goal), then please be my guest. In the mean time this is a band-aid, which works.",various code handle memory horrendous fashion need dealing test code right see seem right track fairness building scratch certainly would go approaching problem however end goal able run one instance one task one minimum amount code change someone go ahead fix code robust manner probably end goal please guest mean time work,issue,negative,positive,positive,positive,positive,positive
375981853,"JayantPythonLover , nop, I dont like only fixes that looks like sewn six finger :D",dont like like sewn six finger,issue,negative,neutral,neutral,neutral,neutral,neutral
375979232,"@iperov I often find you being so extremely rude to people trying to contribute -- especially if you don't agree with the changes. There is a nicer way of saying things if you disagree. You need to learn how to do that and not behave like a tantrum throwing child.

In simpler words you might understand, stop being a fucking idiot.

@torzdf 

I like what you are trying to do. As someone who has a Titan and still faces OOM issues, I most certainly welcome the optimizations. There are various parts of the code that handle memory in a horrendous fashion and need dealing with.

I cannot test out the code right now but from what I see of the changes, you seem to be on the right track.

I'll run for all situations later and see if any more changes need to be made. Good job so far.",often find extremely rude people trying contribute especially agree way saying disagree need learn behave like tantrum throwing child simpler might understand stop idiot like trying someone still certainly welcome various code handle memory horrendous fashion need dealing test code right see seem right track run later see need made good job far,issue,negative,positive,positive,positive,positive,positive
375962338,"**GTX 1080 on linux server**
lol, and still not enough ram? 

Yes, architecture of faceswap is bad, but you make it worse",server still enough ram yes architecture bad make worse,issue,negative,negative,negative,negative,negative,negative
375962171,"LOLOLOLOLOL. I'm running a GTX 1080 on linux server.

But, ok. Making the programme generate errors just passing the help command is definitely a fantastic user experience. I bow to your vastly superior design ethic.",running server making generate passing help command definitely fantastic user experience bow vastly superior design ethic,issue,positive,positive,positive,positive,positive,positive
375961903,"You just ruining the code **and make it hard to develop new additions.**
We are in constant developing and researching new features, why optimising ?

Just buy 4GB card, or disable aero in windows 10, if you dont have last 100mb vram.

wonderful world of programming:
![5687759 1](https://user-images.githubusercontent.com/8076202/37874282-6798bbd8-303d-11e8-82f8-ec7170bae591.jpg)
",code make hard develop new constant new buy card disable aero dont last wonderful world,issue,negative,positive,positive,positive,positive,positive
375961636,So. Nothing constructive to add. There's a surprise.,nothing constructive add surprise,issue,negative,neutral,neutral,neutral,neutral,neutral
375961527,"so you won +100mb of VRAM by sacrificing **consistency** of the code ?

this is sucks:
```
+face_recognition = None
+FaceLandmarksExtractor = None
+
+def import_face_recognition():
+    ''' Import the face_recognition module only when it is required '''
+    global face_recognition
+    import face_recognition
+
+def import_FaceLandmarksExtractor():
+    ''' Import the FaceLandmarksExtractor module only when it is required '''
+    global FaceLandmarksExtractor
+    import lib.FaceLandmarksExtractor
+    FaceLandmarksExtractor = lib.FaceLandmarksExtractor

     def sort_face_cnn(self):
+        if FaceLandmarksExtractor is None:
+            import_FaceLandmarksExtractor()
```
",sacrificing consistency code none none import module global import import module global import self none,issue,negative,neutral,neutral,neutral,neutral,neutral
375961318,"Console 1:
`DISPLAY=:3 python faceswap.py train -A ./job/faces_a -B ./job/faces_b -m ./job/model_IAE -t IAE -p`

Console 2:
`python faceswap.py -h`

Without fix:
```
Traceback (most recent call last):
  File ""faceswap.py"", line 8, in <module>
    from lib.cli import FullHelpArgumentParser
  File ""/home/user/fake/faceswap/lib/cli.py"", line 7, in <module>
    from lib.FaceFilter import FaceFilter
  File ""/home/user/fake/faceswap/lib/FaceFilter.py"", line 3, in <module>
    import face_recognition
  File ""/home/user/fake/env/lib/python3.5/site-packages/face_recognition/__init__.py"", line 7, in <module>
    from .api import load_image_file, face_locations, batch_face_locations, face_landmarks, face_encodings, compare_faces, face_distance
  File ""/home/user/fake/env/lib/python3.5/site-packages/face_recognition/api.py"", line 24, in <module>
    cnn_face_detector = dlib.cnn_face_detection_model_v1(cnn_face_detection_model)
RuntimeError: Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file /home/user/fake/dlib/dlib/dnn/gpu_data.cpp:195. code: 2, reason: out of memory
```
With fix:
```
usage: faceswap.py [-h] {extract,train,convert} ...

positional arguments:
  {extract,train,convert}
    extract             Extract the faces from a pictures.
    train               This command trains the model for the two faces A and
                        B.
    convert             Convert a source image to a new one with the face
                        swapped.

optional arguments:
  -h, --help            show this help message and exit

```


Anything else useful you want to add?",console python train console python without fix recent call last file line module import file line module import file line module import file line module import file line module error calling data float file code reason memory fix usage extract train convert positional extract train convert extract extract train command model two convert convert source image new one face optional help show help message exit anything else useful want add,issue,positive,positive,positive,positive,positive,positive
375961035,stop messing code please,stop messing code please,issue,negative,neutral,neutral,neutral,neutral,neutral
375947144,"I decreased the batch size back down to 128 and haven't had the problem all day. Maybe that is the issue. Will keep training and update. Maybe its a memory overheating issue with the vram in the cards or something, though they are water cooled and such....",batch size back problem day maybe issue keep training update maybe memory issue something though water,issue,negative,neutral,neutral,neutral,neutral,neutral
375919302,"I haven't benchmarked either, but it seems like a safe assumption that the old method would be faster.  Also just noticed that the new `rotate_image` uses positive for counter-clockwise (same as getRotationMatrix), but the old `rotate_image` used positive for clockwise.  I'll do a speed check and update the new function so it is consistent with the old one tonight.",either like safe assumption old method would faster also new positive old used positive clockwise speed check update new function consistent old one tonight,issue,positive,positive,positive,positive,positive,positive
375918050,"The only problem is that the new rotations will either make everything take 4x as long (force check all 90 degree angles) or require attention to specify the angle specifically.

Ideally, I'd like a super fast face detection that may not include landmarks to give a range and angle to feed into a proper face recognition with landmarks to ensure we find all faces.",problem new either make everything take long force check degree require attention specify angle specifically ideally like super fast face detection may include give range angle feed proper face recognition ensure find,issue,positive,positive,positive,positive,positive,positive
375913796,"I would guess that is because that face is rotated 90 degrees. At current implementation rotation only kicks in if it doesn't find a face, but it already found the male face which is upright.

There's some work going on with rotations at the moment, if this isn't covered, I may look to extend functionality to capture all faces. In the meantime, using the filter flag may help.",would guess face rotated current implementation rotation find face already found male face upright work going moment covered may look extend functionality capture filter flag may help,issue,positive,neutral,neutral,neutral,neutral,neutral
375913560,"I will. There's only a couple which need moving really. Already made a start. Not fussed about all of them, just those that utilize the GPU.",couple need moving really already made start utilize,issue,negative,positive,positive,positive,positive,positive
375913414,"I agree that could be helpful, but traversing a while file for all the imports is a tad annoying.   Can you keep them at the top through a function or something so that they're easy to find.",agree could helpful traversing file tad annoying keep top function something easy find,issue,positive,positive,neutral,neutral,positive,positive
375905501,@kvrooman there is a conflict here because `plugins/Extract_Crop.py` was removed in a previous commit. Anyhow this file did not need an update. Can you update the PR so that I can merge?,conflict removed previous commit anyhow file need update update merge,issue,negative,negative,negative,negative,negative,negative
375892021,"dont merge this PR, I decided it is only for testing, because whole architecture must be refactored first.",dont merge decided testing whole architecture must first,issue,negative,positive,positive,positive,positive,positive
375892012,"Yeah, I am running 4k with SLI and CUDA enabled and the bridge is a hard bridge, and I usually keep it enabled. The weird thing is that is that it just started happening. I have let it go a few hours afterward (usually cause I left it in place and didn't notice, and it doesn't seem to want to improve, just continue to stay the same. It doesn't seem to want to try to refit the model, just stays a red blank for both the A and B autoencoders).  I used to let it run for days and have gotten it down to .009 without problems, but just this last week or two it seems to do this. I am not sure exactly what day it started because I am not training every day, but I have seen it on the last one or two weeks of model. Could it be something about the input (model A) data? We've been changing so many things (eye alignment etc) that I wonder if that could be the case? I really just wanted to know if anyone else was seeing this as well or if it was just me... I will look at getting some model data to check it to post to you if I can. The IAE model doesn't seem to do this, but I don't like the results so I switched back to the original, but there again I may not have trained this down to the same level.",yeah running bridge hard bridge usually keep weird thing happening let go afterward usually cause left place notice seem want improve continue stay seem want try refit model stay red blank used let run day gotten without last week two sure exactly day training every day seen last one two model could something input model data many eye alignment wonder could case really know anyone else seeing well look getting model data check post model seem like switched back original may trained level,issue,positive,positive,neutral,neutral,positive,positive
375874490,"It's good to see functionality extended.

Quick question. I chose to use flip/transpose on 90 degree rotations because it performs faster than getRotationMatrix. I believe it's marginal, but when you apply over thousands of images it will stack.

Does moving everything to getRotationMatrix cause slow down (unfortunately I can't test at the moment)? It may not, but if it does, it may be worth keeping the original method for 90 degree rotations.",good see functionality extended quick question chose use degree faster believe marginal apply stack moving everything cause slow unfortunately ca test moment may may worth keeping original method degree,issue,positive,positive,positive,positive,positive,positive
375868690,"@bryanlyon I managed to get decent masked results with refinement. I shared the options I used in this post https://github.com/deepfakes/faceswap-playground/issues/98#issuecomment-375811981
Someone should do a benchmark with our GAN and original with same options and iterations to see that if output is the same or not. It probably won't be the same and I think it is because we are using a different data generator
",get decent masked refinement used post someone gan original see output probably wo think different data generator,issue,negative,positive,positive,positive,positive,positive
375851911,I got red preview when experimented with number of conv layers.,got red preview experimented number,issue,negative,neutral,neutral,neutral,neutral,neutral
375851743,"No, model overfit will usually just make the model poor at conversion, not turn it all straight red.  That seems to be a different problem.",model overfit usually make model poor conversion turn straight red different problem,issue,negative,negative,neutral,neutral,negative,negative
375851582,"> preview windows for both the autoencoders go completely monocolor-red

model overfitted ?",preview go completely model,issue,negative,positive,neutral,neutral,positive,positive
375849312,"It's certainly possible to add it.  Honestly, the only reason I haven't worked on adding masks to other models, is that I am waiting for @oatssss to get GAN fully working (with good conversion results) before I work on remaking the wheel.  I agree that the Original model is more stable, and that is something I don't want to mess with until the feature we want to add is well understood and working.  No point in adding a broken feature until we get it all working with GAN.",certainly possible add honestly reason worked waiting get gan fully working good conversion work wheel agree original model stable something want mess feature want add well understood working point broken feature get working gan,issue,positive,positive,positive,positive,positive,positive
375849178,"Hmmm, that is odd.  That isn't something that I've seen and I can't think of any reason that your situation will be fundamentally different than mine.

Can you give me more info.  I see you're using the original model with a BS of 256. I sthis always what you're running when you see this problem?  Have you gotten anywhere else with the model once it happens or is it just done forever then?  Are you running the 4k monitor while the problem happens?  Have you tried running it at a lower resolution during the training?  Are the drives connected with an SLI bridge?  What kind (flex, hard, or High Bandwidth)?

My thoughts are that this is some sort of overflow or ram corruption. I'd suggest trying smaller batch sizes and with a lower resolution framebuffer.  There are also some potential corruption issues I've run into when using SLI and CUDA.  I suggest you disable SLI when training (possibly even remove any bridges).

If you're willing to share your models and data, I'd love to check it to see what is happening.",odd something seen ca think reason situation fundamentally different mine give see original model always running see problem gotten anywhere else model done forever running monitor problem tried running lower resolution training connected bridge kind flex hard high sort overflow ram corruption suggest trying smaller batch size lower resolution also potential corruption run suggest disable training possibly even remove willing share data love check see happening,issue,negative,positive,positive,positive,positive,positive
375848828,"I looked at thus quickly, mostly there but please make ""-r on"" default to 90 degrees rotations around the circle so that current operation is unchanged?",thus quickly mostly please make default around circle current operation unchanged,issue,negative,positive,positive,positive,positive,positive
375840881,"Sure, I can modify -r instead.  Do you want to keep the ""rotate in increments of size [arg] up to 360 degrees"" behavior?  If so, we'll need to distinguish between -r 90 meaning ""90, 180, 270"" and -r 90 meaning ""90 only"" -- not hard to do, but want to double-check that is the intention.  (I suspect it will generally be more useful for the user to enumerate the angles they want to check, but I can see an argument for the other way too.)",sure modify instead want keep rotate size behavior need distinguish meaning meaning hard want intention suspect generally useful user enumerate want check see argument way,issue,negative,positive,positive,positive,positive,positive
375840381,"I like the idea behind this PR, it's where I wanted the rotation feature to go in the first place, but we made sure that the -r command should be able to handle all the features you have here.  Just add your features to the existing -r command.

In other words, please modify your PR to use - r 90 for specific rotations and some other notation with -r (maybe comma separated) for a list of rotations.

I really appreciate the work as this was on my list to work in very soon.",like idea behind rotation feature go first place made sure command able handle add command please modify use specific notation maybe comma list really appreciate work list work soon,issue,positive,positive,positive,positive,positive,positive
375696633,"@AbysmalBiscuit 

alignments_yaw_personA.json and alignments_yaw_personX.json

whats this ?

my folder structure:
```
workspace
  data_src
    alignments_yaw.json
    aligned
      256x256faces*.png
  data_dst
    videoimages*.png
    alignments.json
    alignments_yaw.json
    aligned
      256x256faces*.png
  model
```
alignments.json for data_src absolutely useless and unused in production

alignments.json for data_dst actually need only for merge to detect rect in videoimages*.png where need to change face.",whats folder structure model absolutely useless unused production actually need merge detect rect need change face,issue,negative,negative,negative,negative,negative,negative
375691935,"@iperov I tested the commit and it works fine now. :)

Any ideas about the other things I mentioned? Or should I also just go ahead and fork and have a go at implementing them. :p",tested commit work fine also go ahead fork go,issue,negative,positive,positive,positive,positive,positive
375681243,"As I said - fork from this fork, and do what you want.",said fork fork want,issue,negative,neutral,neutral,neutral,neutral,neutral
375671658,"@iperov We certainly got off on the wrong foot, what you're doing here is fantastic work and something I hesitated to approach on my own. I misunderstood you intended to store in the alignments_yaw.json as no actual yaw data is saved, but rather a sorted list. I was able to get the last commit to run on a small batch of images so it seems to be functioning as intended.

One thing I noticed is your yaw values range from positive to negative (left or right gaze) but the `random_transform` in the generator can flip the image causing ""duplicate"" poses in your batch. This may or may not be a bad thing depending on how targeted you want your training data to be but it led me to my next thought.

I'm investigating sorting by absolute yaw and producing pairs of mirrored test images. This would allow left or right yaw images to be used for both pose directions in training, while also addressing missing pose information (i.e. training data has all left facing images and no right). What are your thoughts?",certainly got wrong foot fantastic work something approach misunderstood intended store actual yaw data saved rather sorted list able get last commit run small batch intended one thing yaw range positive negative left right gaze generator flip image causing duplicate batch may may bad thing depending targeted want training data led next thought investigating absolute yaw mirrored test would allow left right yaw used pose training also missing pose information training data left facing right,issue,negative,positive,neutral,neutral,positive,positive
375659634,"Yes we have many possibilities here ;-) The thing is that after having checked many different setups, I think updating PixelShuffler or switching to upsample2d will only bring small improvments, so I'm still trying new architectures.

The tiramisu paper seems interesting but is a bit above my understanding for now, but I'll check the FCN approach, it seems very interesting",yes many thing checked many different think switching bring small still trying new paper interesting bit understanding check approach interesting,issue,positive,positive,positive,positive,positive,positive
375634006,"@iperov haha, yeah I did have a feeling that it may not work on widows from when I read the Python documentation while trying to fix it. :p

I'll give the latest commit a check. ",yeah feeling may work read python documentation trying fix give latest commit check,issue,positive,positive,positive,positive,positive,positive
375622400,"@AbysmalBiscuit now its not working on windows :)
`FileNotFoundError: [WinError 2] The system cannot find the file specified`

```
>>> args
['E:FaceSwap_internalbinpython.exe', 'E:FaceSwap_internalbinfaceswaplibyaw_sorter.py', 'E:\\FaceSwap\\workspace\\data_dst\\aligned', 'E:\\FaceSwap\\workspace\\data_dst\\aligned\\..\\alignments_yaw.json']
```",working system find file,issue,negative,neutral,neutral,neutral,neutral,neutral
375619113,"@iperov I've fixed it by using the `shlex` module to prepare the arguments for the subprocess, here's a gist with my changes:
https://gist.github.com/AbysmalBiscuit/5dfed6d29c014f8bb74906acea79bb51

The tracebacks always led to `subprocess` having trouble with processing the argument string, so I think this is a safer way of doing it. :)

I have a few ideas for how the new yaw preparation functionality can be improved (if you like them I can handle the implementation):
1) Allow users to specify via cli the paths to `alignments_yaw.json`.

2) Instead of using a generic `alignments_yaw.json` file, perhaps use something like `alignments_yaw_personA.json` and `alignments_yaw_personX.json`. (Where personA is the data directory given by the user for -A and personX is given by -B.)
This way you could keep the alignments_yaw files. By keeping them you can save time by avoiding having to reload and sort them.
The issue of adding and/or removing faces from the data directory can be handled by checking if all faces in the data directory are in the alignments_yaw file corresponding to that directory (which will be a lot faster than reloading all the images as a default).

2.1) If images were removed from the data directory you could simply delete them from the alignments_yaw file and save the new file.

2.2) If images were added; this is trickier and would mean a change to how the alignments_yaw file is saved and processed after being read. My idea would be that after you regularize the images, you sort the image list  to match it and save the image list. You could save it in the same format, here's what I mean:
Right now it's a list of lists:
 `[[<path to img1>, <path to img2>], [<path to img1>]]`
Using img_list, list of lists of lists:
 `[[[<path to img1>, nparray, face_pitch, face_yaw], [<path to img2>, nparray, face_pitch, face_yaw]], [[<path to img3>, nparray, face_pitch, face_yaw]]]`
This way when you add new images you have most of the data ready and you only need to load the extra images and resort (with the rest being read from the saved file), which can save time. 
Then when you need the alignments_yaw file to be formatted as it is now, you can just reformat it in memory to be of the form that the rest of train expects. Alternitavely you could change the other parts of the train process to get the file path from the lists.

3) You said that the point of sorting by face isn't to sort 1 face from many, but to group similar  positions of 1 face, so would you be willing to add back in the dlib method as sorting by face-dlib since it can be quite useful for when you extract from a video where there are a lot of faces (like a movie scene with people in the background)? This way it wouldn't be the default face method, but it would still be there for those who need it.",fixed module prepare gist always led trouble argument string think way new yaw preparation functionality like handle implementation allow specify via instead generic file perhaps use something like persona data directory given user given way could keep keeping save time reload sort issue removing data directory handled data directory file corresponding directory lot faster default removed data directory could simply delete file save new file added would mean change file saved read idea would regularize sort image list match save image list could save format mean right list path path path list path path path way add new data ready need load extra resort rest read saved file save time need file memory form rest train could change train process get file path said point face sort face many group similar face would willing add back method since quite useful extract video lot like movie scene people background way would default face method would still need,issue,positive,positive,neutral,neutral,positive,positive
375586013,"`it loads the interactive Python shell for some reason`
fixed",interactive python shell reason fixed,issue,negative,positive,neutral,neutral,positive,positive
375584128,"@AbysmalBiscuit you got FileNotFoundError because
`execute_yaw_sorter` was not executed for some reason, so no file created.
Can you debug why `execute_yaw_sorter` not executing?",got executed reason file,issue,negative,neutral,neutral,neutral,neutral,neutral
375552039,architecture of faceswap not so good to make new improvements absolutely clear and logical,architecture good make new absolutely clear logical,issue,positive,positive,positive,positive,positive,positive
375550988,"@h1vem1nd85, also, offer a solution. 
Fork from my fork, and make better.
If you cannot offer a solution, then you have to stop flood and leave this PR.

Am I wrong, @Clorr  ?",also offer solution fork fork make better offer solution stop flood leave wrong,issue,negative,neutral,neutral,neutral,neutral,neutral
375548674,"h1vem1nd85, so you purposely came to flood ?
FIRST read the code and understand the logic of the program, before make conclusion.

@Clorr , this man doesnt help at all at this PR. He just flooding.",purposely came flood first read code understand logic program make conclusion man doesnt help flooding,issue,negative,positive,positive,positive,positive,positive
375487723,"I seriously dont know what set you off on your power trip, but Ive lurked this repo for quite some time and have read enough of your comments to know that you dont accept criticism.

Discussions are meant to be point : counterpoint, not point: nope youre wrong, I'm, right leave

The landmark data you are producing already exists in the original image alignments as XY pixel coords. It isnt unreasonable to have sorttool read and coord transform those coords to the aligned image space, then writing the yaw outputs as you intended.",seriously dont know set power trip quite time read enough know dont accept criticism meant point counterpoint point nope wrong right leave landmark data already original image unreasonable read transform image space writing yaw intended,issue,positive,negative,neutral,neutral,negative,negative
375451631,"> sort faces by extracting landmarks again 

srsly ?

if you cannot help, just leave this pr, dont flood.",sort help leave dont flood,issue,negative,neutral,neutral,neutral,neutral,neutral
375448763,"> impossible, because we gather thousands of faces from various sources and filter them through sorttool.

Your current implementation **is** redundant. Workflow is:
Raw images > extract faces + landmarks > sort faces by extracting landmarks **again** > batch loader

You've also made the alignments_yaw.json a requirement for **any** training. If your intention is to run sorttool independently from training I strongly suggest this be a separate generator.

> can you debug the problem? because I cannot reproduce the bug

Process runs face detection on 923 aligned faces and writes alignments_yaw.json with no actual data just filenames. Begins Regularization with no data to process, CPU and memory usage locked at 13% 194,412K (single thread, 8 cores). This is a using a direct clone of your repo.",impossible gather various filter current implementation redundant raw extract sort batch loader also made requirement training intention run independently training strongly suggest separate generator problem reproduce bug process face detection actual data regularization data process memory usage locked single thread direct clone,issue,negative,negative,neutral,neutral,negative,negative
375435980,"> Face-Cnn (here the default face-sort) works badly on image collections of many people
> I recommend keeping the old face mode since it provides functionality not replicated by face-cnn.

rejected
--sort-by face was not created to filter one face from many people
use 'hist' instead

sort by face was created to group together similar positions of ONE face",default work badly image many people recommend keeping old face mode since functionality replicated face filter one face many people use instead sort face group together similar one face,issue,negative,positive,neutral,neutral,positive,positive
375433385,"**Sort Tool:**
Face-Cnn (here the default face-sort) works badly on image collections of many people. I find it lumps together different faces a lot and provides less stable results than the old face-detection. This is not unique to this pull request and was already the case for me on the regular build. I recommend keeping the old face mode since it provides functionality not replicated by face-cnn.",sort tool default work badly image many people find together different lot le stable old unique pull request already case regular build recommend keeping old face mode since functionality replicated,issue,negative,positive,neutral,neutral,positive,positive
375427273,"regardless of whether the upsample2d is better or not that sub-pixel shuffling, I was also thinking of suggesting using the official keras.contrib version rather than our Pixel Shuffler custom code. better dependencies , testing, and update reliance... if the quality turns out to be comparable",regardless whether better shuffling also thinking suggesting official version rather shuffler custom code better testing update reliance quality turn comparable,issue,positive,positive,positive,positive,positive,positive
375425698,"yup, he's added a lot to keras.contrib .  I'm almost done implementing a tweak of his version of FCN-densenet ( from the 100 layer tiramisu paper) as a faceswap autoencoder. have high expectations of improvements

we really need to move the models over to using fit() as well so we can create Tensorboards on them",added lot almost done tweak version layer paper high really need move fit well create,issue,positive,positive,positive,positive,positive,positive
375415655,"Thanks. Been a bit snowed at work, but will hopefully update in next couple of days",thanks bit work hopefully update next couple day,issue,positive,positive,neutral,neutral,positive,positive
375415409,"`Would it be less redundant to gather this information at the extraction step?`
impossible, because we gather thousands of faces from various sources and filter them through sorttool.

`Also, the code you provided seems to stall at the Regularizing step unless I've done something horribly wrong between point A and point B.`
can you debug the problem? because I cannot reproduce the bug",would le redundant gather information extraction step impossible gather various filter also code provided stall step unless done something horribly wrong point point problem reproduce bug,issue,negative,negative,negative,negative,negative,negative
375399427,"Hey, my PR was merged so you'll have to update your branch to work with tools.py (my gist, or sort.py should work as decent templates). :)

I haven't had an extensive look at your commits, but they seem to be good.",hey update branch work gist work decent extensive look seem good,issue,negative,positive,positive,positive,positive,positive
375397641,"Would it be less redundant to gather this information at the extraction step? Or possibly reading the existing alignments.json landmarks and processing from there? Running the aligned images back through the face detector to get landmarks a second time seems wasteful from an overall workflow perspective.

Also, the code you provided seems to stall at the Regularizing step unless I've done something horribly wrong between point A and point B.",would le redundant gather information extraction step possibly reading running back face detector get second time wasteful overall perspective also code provided stall step unless done something horribly wrong point point,issue,negative,negative,negative,negative,negative,negative
375329177,"The guy @titu1994 who posted https://github.com/keras-team/keras/issues/3940 is incredible, he has many implementations of common architectures in keras, it is awesome!",guy posted incredible many common awesome,issue,positive,positive,positive,positive,positive,positive
375328091,"Note that i'm currently experimenting different setups for the decoder part, you can check [my dedicated branch ](https://github.com/Clorr/faceswap/commits/dev/retrain). It did not give much success for now, but at least it enables me to learn different things about NNs",note currently different part check branch give much success least learn different,issue,positive,neutral,neutral,neutral,neutral,neutral
375285250,"training with 23400 source faces, 

rare side angles training fine:
![python_2018-03-22_16-19-51](https://user-images.githubusercontent.com/8076202/37770242-338c3fa6-2ded-11e8-81e8-19ccf370e173.png)
",training source rare side training fine,issue,negative,positive,positive,positive,positive,positive
375074863,"@iperov if you want to add a new file in `tools/` , it is ok. What is 'regularizer' for?",want add new file,issue,negative,positive,positive,positive,positive,positive
375069956,Feel free to make a correction directly in Github,feel free make correction directly,issue,positive,positive,positive,positive,positive,positive
374952478,"but with new architecture too hard to integrate something new.
All like welded together.
This is why I hate optimizations.",new architecture hard integrate something new like together hate,issue,negative,negative,negative,negative,negative,negative
374886551,@deepfakesclub interesting paper you suggest here. I was thinking about [that one](https://arxiv.org/pdf/1704.04086.pdf) but it only generates frontal view which is not really the hardest to find usually. However the approach was interesting and the 2 pathway decoder was also somewhat interesting,interesting paper suggest thinking one frontal view really find usually however approach interesting pathway also somewhat interesting,issue,positive,positive,positive,positive,positive,positive
374886321,"@Clorr 
I have written a unittest script that tests all the options and possible combinations of options. 
Everything passed with OK, so as far as I see it, it is ready to be merged.",written script possible everything far see ready,issue,negative,positive,positive,positive,positive,positive
374847374,"trained GAN (64)
and merged without mask

```
new_face = fake_output[:,:,:, 1:]
# new_face = mask * new_face + (1 - mask) * normalized_face
new_face = numpy.clip((new_face[0] + 1) * 255 / 2, 0, 255).astype( image.dtype )
```

![out00168 4](https://user-images.githubusercontent.com/8076202/37697410-2ef8969e-2cf6-11e8-9668-439ad8b60e92.png)

background much better

May be someone can create dfaker 2.0 based on GAN? :)",trained gan without mask mask mask background much better may someone create based gan,issue,positive,positive,positive,positive,positive,positive
374768985,I amended the previous commit since it didn't get signed for some reason.,previous commit since get reason,issue,negative,negative,negative,negative,negative,negative
374763858,"I refactored and redesigned the program.
I wrote something like a very basic test file to check that all the option permutations work, and it seems to be ok.

Original functionality is exactly the same as before (to sort by renaming with hist as the sorting method):
`python tools.py sort -i <input_dir>`

To sort by one method and group by another:
`python tools.py sort -i <input_dir> -o <output_dir> -k -f folders -s face -g hist`",program wrote something like basic test file check option work original functionality exactly sort hist method python sort sort one method group another python sort face hist,issue,positive,positive,positive,positive,positive,positive
374623539,"@ Clorr, sounds alright. Fine with the compromise of switching the order of the RGB and BGR image list and sending both to the detector. ( also cleaning up the naming ). I'll modify the PR tonight and resubmit",alright fine compromise switching order image list sending detector also cleaning naming modify tonight resubmit,issue,negative,positive,positive,positive,positive,positive
374608840,"""Would there be a way to augment a faceset with transforms not present in the original set?""

In the image data batch generator, in addition to the current transforms , randomly select a landmark alignment from the .json file of either Face_A or Face_B.  Invert a random normalized face using this randomized warp to get a variety of poses ( just like we would do when we're converting... there will be some distortion as every frontal face is not in the same ""frontal"" pose as the current alignment is not perfect)However, apply a random scalar ( 0<x<1 ) that is initially capped at a low value ( i.e.0.05 ) to the magnitude of the warping to keep the faces mostly frontal. Over many epochs, increase the cap value to 1. You can maintain stability but also get a larger faceset with all poses in your training set.",would way augment present original set image data batch generator addition current randomly select landmark alignment file either invert random face warp get variety like would converting distortion every frontal face frontal pose current alignment perfect however apply random scalar initially capped low value magnitude warping keep mostly frontal many increase cap value maintain stability also get training set,issue,positive,positive,neutral,neutral,positive,positive
374599283,"Would there be a way to augment a faceset with transforms not present in the original set?

For example, if we have lots of faces of Cage, but very few, if any, of them with a widely opened mouth, then the model is having problems matching with the Trump faces where he's shouting. Which leads to lip sync problems. Also, the original chin may show because the face is bigger when shouting.

Maybe we could introduce transforms pertaining to the mouth and chins (or other face features), from a given dataset, to create several faces matching the ones in the second dataset. Not only angles. It would be a way to diversify the training set.

And if it can give some unrealistic faces, there would be a manual step to choose which ones are usable in training.",would way augment present original set example lot cage widely mouth model matching trump shouting lip sync also original chin may show face bigger shouting maybe could introduce pertaining mouth face given create several matching second would way diversify training set give unrealistic would manual step choose usable training,issue,positive,positive,neutral,neutral,positive,positive
374578556,"@AbysmalBiscuit
It couldn't detect faces on those images. It logged ""No faces were detected"" during sorting.
Yes I'm testing on Windows. No I see the folders but they stayed empty for awhile, this problem occurred because I used keep option. And I had to wait the copy operation but without indicator I assumed it bugged out",could detect logged yes testing see stayed empty awhile problem used keep option wait copy operation without indicator assumed,issue,negative,negative,neutral,neutral,negative,negative
374570760,"@iperov I have actually found a bug in the face-cnn method when grouping by folders, but it was a 1 line fix (wrong score calculating method was being called).

I did start to test it extensively and found a problem where the grouping doesn't work very well if the data isn't pre-sorted. I know how to fix this, which should greatly improve how well the program groups into folders, but it will take me a few hours to change it and to test it.
As an aside the fix that I came up with is actually what I wanted to do right from the start with the grouping by folders, but couldn't think of how to implement it back then. :)

So I'd rather wait just a little longer until I sort this out. (Pun not intended)

@Apollo122 I understand the concern for inexperienced/non-programmer users. The best thing I can think of would be to put a disclaimer/warning message when you use `tools.py` or `sort` that tells people to backup their data and/or to test the tool on a small set of data to make sure they understand how it works.

Could you please elaborate on what you mean by having missed 80-100 images; is it that it didn't group them at all, or they were put into individual forlders?

When the program is running it should display the progress of the stage it's on, i.e. Loading, Sorting or Grouping, and last Moving.
To me it sounds like you're on Windows, and explorer has a tendency not to refresh quickly when new files/folders are added.
I mostly use GNU/Linux, so I don't have that problem, in the sense that files appear instantly in the folders after they are moved.",actually found bug method grouping line fix wrong score calculating method start test extensively found problem grouping work well data know fix greatly improve well program take change test aside fix came actually right start grouping could think implement back rather wait little longer sort pun intended understand concern best thing think would put message use sort people backup data test tool small set data make sure understand work could please elaborate mean group put individual program running display progress stage loading grouping last moving like explorer tendency refresh quickly new added mostly use problem sense appear instantly,issue,positive,positive,positive,positive,positive,positive
374560935,"Landmarks are what is used at convert time. But the landmarks are not hard truth, they are often inferred by the face detector, like shown [here.](https://github.com/deepfakes/faceswap/issues/270#issuecomment-372133604)

And the destination face isn't cut before applying new face. That's why, when using really high blur value, the original face features shows through.

So, maybe there's some work to do to mask occlusions and background at convert time, to know what belongs to the face and what doesn't.",used convert time hard truth often face detector like shown destination face cut new face really high blur value original face maybe work mask background convert time know face,issue,positive,positive,neutral,neutral,positive,positive
374556626,"That's what we were talking about in #270 

Do you have the debug landmarks of source face?

I think dlib's cnn detected larger face than it is really.",talking source face think face really,issue,negative,positive,positive,positive,positive,positive
374544375,why we cant cut face from yellow background and overlay it with alpha ?,cant cut face yellow background overlay alpha,issue,negative,neutral,neutral,neutral,neutral,neutral
374518670,"> face is totally unrecognizable

same problem

Source:
![01484](https://user-images.githubusercontent.com/8076202/37644268-a6d7b2ea-2c3c-11e8-97a0-f7e93f6a11bf.png)

Dest:
![out00168 3](https://user-images.githubusercontent.com/8076202/37644216-7889c9be-2c3c-11e8-9c45-d623e0ed9b83.png)

Original (hist match, seamless):
![out00168](https://user-images.githubusercontent.com/8076202/37644122-3671d1c0-2c3c-11e8-8dd7-a5082e2d280e.png)

IAE:
![out00168 2](https://user-images.githubusercontent.com/8076202/37644124-37662252-2c3c-11e8-942e-c4d8578b9131.png)

converted IAE face not similar to source face, it more like dest face

but of course common facial features of both faces are present",face totally unrecognizable problem source original hist match seamless converted face similar source face like face course common facial present,issue,negative,positive,neutral,neutral,positive,positive
374516196,"Apollo122 just dont use this tool, if it too dangerous to you.",dont use tool dangerous,issue,negative,negative,negative,negative,negative,negative
374511225,"@AbysmalBiscuit I'm not asking it for myself as I change the defaults before using it. Rename option will be problematic for inexperienced users. He will sort his images and get renamed files and during convert he will have problems with alignment file. Then we'll see lots of issue posts.

It was a basic command tools.py sort -i whatever -o whatever/sorted -k -by face-cnn (grouping default)
Note that I sorted 16k png's and it missed 80-100 of them. I was weird because I got those images using cnn. Also at the end of the sorting, created folders remained empty for awhile I guess it was still copying the files. After a minute or two I saw the files. Although folder 0 remained empty. A message would be useful for the situations like this, letting the user know he should wait a little after script is done",change rename option problematic inexperienced sort get convert alignment file see lot issue basic command sort whatever grouping default note sorted weird got also end empty awhile guess still minute two saw although folder empty message would useful like user know wait little script done,issue,negative,negative,neutral,neutral,negative,negative
374502162,"@Apollo122 'rename' is the default because @iperov is the author of the original and wrote half the tool, so if he wants it to be that way then I don't really see an issue with that. :)
Also there is the `-k/--keep` option that allows you to keep all the original files and the `-o/--output` option for outputting the sorted/grouped files to a different directory. The two combined mean that you input files are untouched and you get your sorted/grouped files.

Can you please provide the command you used for grouping by face-cnn along with the console output/any traceback messages you received?
When I tested it it worked.

@iperov I think this comes back to the issue that people want to use sort after they have extracted 2000 faces from several minutes of video, or in their folders where they put all the faces that they have extracted, which could also be in the 1000s of images.
However I don't see this as an issue since as I said above, there are options to avoid any risk.",default author original wrote half tool way really see issue also keep option keep original output option different directory two combined mean input untouched get please provide command used grouping along console received tested worked think come back issue people want use sort extracted several video put extracted could also however see issue since said avoid risk,issue,negative,positive,neutral,neutral,positive,positive
374479751,"I think there are two different problems:

1) The training spends more time training 0-10 degrees, since the images are drawn randomly for each batch of training. The 90 degree angle will train roughly 10x more slowly. The model will also bias towards the more common example (open eyes vs closed eyes).

2) During conversion, your model has poor quality for 20-80 degrees of face A -> face B. Even if you solve problem 1, problem 2 may still be present.

Problem 1 maybe can be fixed by adjusting batch sampling to take into account angle distributions if image numbers >> batch size. If image numbers ~ batch size, like in your example, that is interesting, I don't know.  If there is exactly one 90 degree face, and it appears multiple times in one batch, would that actually improve the training? I guess it could, because the face is warped, so you are training on different multiple warps at once?

Problem 2 maybe can be fixed by what @kvrooman suggested, or similar idea in that other issue https://github.com/deepfakes/faceswap/issues/300

I think @iperov is more asking about problem 1?
",think two different training time training since drawn randomly batch training degree angle train roughly slowly model also bias towards common example open closed conversion model poor quality face face even solve problem problem may still present problem maybe fixed batch sampling take account angle image batch size image batch size like example interesting know exactly one degree face multiple time one batch would actually improve training guess could face warped training different multiple problem maybe fixed similar idea issue think problem,issue,negative,negative,neutral,neutral,negative,negative
374477603,"I think [this paper](https://www.openu.ac.il/home/hassner/projects/augmented_faces/Masietal2017rapid.pdf) (pdf link) is basically doing a variant of what @dfaker suggests. It uses generic 3D models to rapidly construct alternative angle views.

I believe there is a github with code for this, or a similar one. Couldn't find it at the moment. The issue was that it only generates 5-6 fixed angles of rotation (along yaw), and they didn't release the full generic 3D models for generating arbitrary angles.",think paper link basically variant generic rapidly construct alternative angle believe code similar one could find moment issue fixed rotation along yaw release full generic generating arbitrary,issue,negative,positive,neutral,neutral,positive,positive
374464066,"The training loss jumps because the current weights in the frontal face trained NN generalize poorly to the single profile face. Also setting the batch size very small can over-fit as the NN attempts to adjust itself for each batch and it ping-pongs back and forth.

I think your larger question is...
Does the extra information provided by the ""profile/eyes closed"" face improve the fit on the ""frontal/eyes open"" faces and vice versa.

Yes, but you either need lots of examples of both to work well or you need to be able to map the two cases to each other in ways the NN can pool information about the two cases, i.e. ears will train the same neuron/feature/filter regardless if its a profile or frontal.

We're accomplishing the first with the image data generator to augment the dataset with random translations, rotations, zooms/scale, flips in order to generate more variance in the training data set. You could also introduce a skew, yaw, and pitch transform to give more made-up ""profile"" examples to train the autoencoder.  Introducing illumination and color shifts would also likely reduce our histogram matching issues.

The second method involves a technique called Spatial Transformer Networks.  Very crudely explained, put an affine transform in front of a convolution and give it its own weight for each DoF/dimension of the affline.  As the NN trains, it can warp the image by itself by training that weight. Here's a recent paper.
http://www.robots.ox.ac.uk/~joao/publications/henriques_icml2017.pdf
https://arxiv.org/pdf/1703.06211.pdf

Example image
![image](https://user-images.githubusercontent.com/3772434/37635017-26ad262e-2bc7-11e8-93b1-f31cd66e9b4b.png)
",training loss current frontal face trained generalize poorly single profile face also setting batch size small adjust batch back forth think question extra information provided closed face improve fit open vice yes either need lot work well need able map two way pool information two train regardless profile frontal first image data generator augment random order generate variance training data set could also introduce skew yaw pitch transform give profile train illumination color would also likely reduce histogram matching second method technique spatial transformer crudely put affine transform front convolution give weight warp image training weight recent paper example image image,issue,positive,negative,neutral,neutral,negative,negative
374396279,"A good high level summary of the issue and why the sub-pixel shuffle was implemented
https://distill.pub/2016/deconv-checkerboard/

Note: I haven't really read through which method is implemented in Pixel_Shuffler.py  There have been dozens of suggested improvements since the original paper came out.

In this thread
https://github.com/keras-team/keras/issues/3940
someone found that standard keras ( Upsample2D followed by a Conv2D ) was superior to the ( Conv2D then Pixel Shuffle ) approach

One potential paper discussing the concepts in a bit more detail as well as a potential upgrade
https://arxiv.org/ftp/arxiv/papers/1707/1707.02937.pdf

Honestly, the best practices should likely be lifted from the winners of the NTIRE 2017 Super-Resolution Challenge ",good high level summary issue shuffle note really read method since original paper came thread someone found standard superior shuffle approach one potential paper bit detail well potential upgrade honestly best likely challenge,issue,positive,positive,positive,positive,positive,positive
374374175,"Yeah, I've tried the facial reconstruction from the link and it doesn't really reconstruct the face properly, like you would get a nose or chin that are too big or small and it ends up with model results that don't look like the person",yeah tried facial reconstruction link really reconstruct face properly like would get nose chin big small model look like person,issue,positive,negative,neutral,neutral,negative,negative
374373524,"or for example , there are too few faces with closed eyes, so result is constantly opened eyes",example closed result constantly,issue,negative,negative,neutral,neutral,negative,negative
374367659,You shouldn't be training on faces that are very different from all the others.  It confuses the model.  All faces should be aligned to each other before training.,training different model training,issue,negative,neutral,neutral,neutral,neutral,neutral
374363524,maybe I poorly explained. This is not align related.,maybe poorly align related,issue,negative,negative,negative,negative,negative,negative
374359815,"First, sorry for accidentally closing this issue.

Align during extract should make all faces line up the same way.  If you have a face that is coming in sideways, that is the same as a general false positive and should be deleted manually.  If you really want that face, you can try running extract again it with -r on.  Right now, it'll likely find the bad face again, without aligning it properly, but it might do it properly.",first sorry accidentally issue align extract make line way face coming sideways general false positive manually really want face try running extract right likely find bad face without properly might properly,issue,negative,negative,neutral,neutral,negative,negative
374348872,"I don't think you'd need to generate full new voxel clouds just to generate new angles we don't care about a useful model, just new angles to enrich the samples. 

It'd be possible to take an average 3d face (a simple 3d model), rotate it, then project the 2d face points onto it face-aligned noting the X and Y positions from the non-font-aligned viewing angle, that'd give you two sets of points F being a 2d font-on points from he original image and P the transformed positions of where that face point would be if you rotated the head, feed F and P into cv2.remap to get a transformed face and paste that back over the original background.

Pre-calculation of a set of F and P pairs would make this very fast.",think need generate full new generate new care useful model new enrich possible take average face simple model rotate project face onto angle give two original image face point would rotated head feed get face paste back original background set would make fast,issue,positive,positive,positive,positive,positive,positive
374345455,"This issue would perhaps be better off in the playground repo.

Anyways, I tried playing around with this tool a long time ago, as well as a bunch of other software packages for 3D face reconstruction. For the .obj files, I think MeshLab was the free viewer I used that supports textures.

The bottom line is that I don't think the quality is good enough to use except for very specialized and lucky/random cases. I see great results for 3DMM in papers, but when I try out various published code, the results look like crap unless you carefully choose your examples. They don't seem very robust.

Also, none of these tools are quite ""programmatic"" enough. The github ones are all a pain to build or run (proprietary expensive matlab...). The free software packages I tried were very hands-on. Both the free and commercial packages also looked too ""cartoony"" to me.

If you are doing manual work, there are probably better methods for data augmentation.  For example, you can find similar faces with the required pose. You need to carefully blend the faces, kind of like a DJ, so you don't overpower the desired face B. You can also do the classic -  train both autoencoders on face A, then switch one to face B. That is easy, but I personally hate it, as the new face always looks too contaminated by face A.

The most promising 3D reconstruction tools usually didn't release their code or looked way too complicated for me to try. Some of the more sophisticated ones like the GANs mentioned by Clorr or somebody elsewhere might work.",issue would perhaps better playground anyways tried around tool long time ago well bunch face reconstruction think free viewer used bottom line think quality good enough use except specialized see great try various code look like crap unless carefully choose seem robust also none quite programmatic enough pain build run proprietary expensive free tried free commercial also manual work probably better data augmentation example find similar pose need carefully blend kind like overpower desired face also classic train face switch one face easy personally hate new face always face promising reconstruction usually release code way complicated try sophisticated like somebody elsewhere might work,issue,positive,positive,positive,positive,positive,positive
374328576,"I didnt test folders, so all fine for me.

> I would make 'folders"" default option of grouping. It's safer than changing the name because of alignment file.

is this dangerous ? just restart align. Source files never touched.

",didnt test fine would make default option grouping name alignment file dangerous restart align source never touched,issue,negative,negative,neutral,neutral,negative,negative
374321001,"@ruah1984, like everything else in @dfaker project, I find it very relevant.

I also tried this reconstruction project - using output results from 1 photo does not gives useful results, Some face features are simply missing - like using frontal photo, you will never get nostrils, chin etc.

There are some commercial software which can do some part of the job - facegen or facial studio which can reconstruct from 2 photos and apply morphing.

",like everything else project find relevant also tried reconstruction project output photo useful face simply missing like frontal photo never get chin commercial part job facial studio reconstruct apply,issue,positive,positive,neutral,neutral,positive,positive
374320471,"I'm grouping faces by face-cnn and getting many ""No faces were detected"" messages. I extracted those faces with cnn.",grouping getting many extracted,issue,negative,positive,positive,positive,positive,positive
374303333,"I would make 'folders"" default option of grouping. It's safer than changing the name because of alignment file.",would make default option grouping name alignment file,issue,negative,neutral,neutral,neutral,neutral,neutral
374296557,"@Clorr as far as I see it, it should be ready to merge. But it could be worthwhile to wait until @iperov has a look at it to make sure.",far see ready merge could wait look make sure,issue,positive,positive,positive,positive,positive,positive
374243087,"Thanks for all of the feedback.

I've just pushed a commit to fix these bugs:

- Traverse alignments in reverse order to mitigate changing index numbers following a delete
- Rename aligned faces to match their new index numbers (i.e if face xxxx_0.png gets deleted, after running this process any files named xxxx_1.png etc will no longer match with the alignments file, so they need to be renamed)
- Assumption that the original file will have the same extension as the aligned face is incorrect.

I'm going to look at your code now and will look to implement where I can.

Cheers
",thanks feedback commit fix traverse reverse order mitigate index following delete rename match new index face running process longer match file need assumption original file extension face incorrect going look code look implement,issue,positive,positive,positive,positive,positive,positive
374223036,"I've made a gist with all the changes I suggested:
https://gist.github.com/AbysmalBiscuit/81f81252fcf2c769b70a15a0b9f22726

You can run it directly by:
`python alignments.py alignments -j remove -a <path to alignments file> -f <path to aligned dir>`

I did port it to work with `tools.py` though, hence why it's somewhat different in terms of layout.
It adds the option to change the serializer.",made gist run directly python remove path file path port work though hence somewhat different layout option change,issue,negative,positive,neutral,neutral,positive,positive
374193486,Let me know when it's ready to merge,let know ready merge,issue,negative,positive,positive,positive,positive,positive
374181907,"Yeah, this is an early draft, thrown together in about half an hour. There are issues, and I am modifying the code at the moment to iron out a few bugs, and refactor a fair bit.

I only work with committed code, so if/when that PR gets committed, I'll make the necessary changes. to comply. 

I wouldn't edit this yet as I'm still actively working on this (today at least), so will publish changes intermittently.

A couple of things I'm currently fixing:

- Traverse alignments in reverse order to mitigate changing index numbers following a delete
- Rename aligned faces to match their new index numbers (i.e if face xxxx_0.png gets deleted, after running this process any files named xxxx_1.png etc will no longer match with the alignments file, so they need to be renamed)
- Assumption that the original file will have the same extension as the aligned face is incorrect.

Please let me know of anything obvious which stands out to you, as I can go in and fix. High level is fine.
",yeah early draft thrown together half hour code moment iron fair bit work code make necessary comply would edit yet still actively working today least publish intermittently couple currently fixing traverse reverse order mitigate index following delete rename match new index face running process longer match file need assumption original file extension face incorrect please let know anything obvious go fix high level fine,issue,positive,positive,neutral,neutral,positive,positive
374168764,"As @ruah1984 points out this will not be at all compatible with `tools.py` as the main tools calling script.

I have had a look at this PR and I like what you're trying to do, however I tried running the program and it doesn't work. There are a lot of problems and mistakes all throughout the program, which makes sense since it's an early upload.

However it would take more time to explain everything and provide suggestions via code review than to just fix them myself. 
@torzdf if you would like after I'm done, I could submit a PR to your PR with my changes/fixes, or I could open a new PR. :)",compatible main calling script look like trying however tried running program work lot throughout program sense since early however would take time explain everything provide via code review fix would like done could submit could open new,issue,positive,positive,positive,positive,positive,positive
374165079,As i know the imageGapsScanner may require both.json files for data A and B.  ,know may require data,issue,negative,neutral,neutral,neutral,neutral,neutral
374145109,"There's this script in dfaker's repo - I saw this earlier somewhere else- Maybe we can get missing positions using this script.

https://github.com/dfaker/df/blob/master/imageGapsScanner.py",script saw somewhere maybe get missing script,issue,negative,negative,negative,negative,negative,negative
374140540,"@iperov, this just help to simulate different angle of face, base on 3D face reconstruction. but i think unless we can know which angle we don't have,  if not we actually create more dataset for each 2D face.",help simulate different angle face base face reconstruction think unless know angle actually create face,issue,positive,negative,negative,negative,negative,negative
374125094,"face-cnn-dissim:

```
    def process_face_cnn_dissim(self):
        from lib import FaceLandmarksExtractor

        input_dir = self.arguments.input_dir
        output_dir = self.arguments.output_dir

        print (""Sorting by face-cnn dissimilarity..."")

        img_list = []
        for x in tqdm( self.find_images(input_dir), desc=""Loading""):
            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True)
            img_list.append( [x, np.array(d[0][1]) if len(d) > 0 else np.zeros ( (68,2) ), 0 ] )

        img_list_len = len(img_list)
        for i in tqdm ( range(0, img_list_len-1), desc=""Sorting""):
            score_total = 0
            for j in range(i+1,len(img_list)):
                if i == j:
                    continue
                fl1 = img_list[i][1]
                fl2 = img_list[j][1]
                score_total += np.sum ( np.absolute ( (fl2 - fl1).flatten() ) )

            img_list[i][2] = score_total

        print (""Sorting..."")
        img_list = sorted(img_list, key=operator.itemgetter(2), reverse=True)
        self.process_final_rename (output_dir, img_list)

        print (""Done."")
```",self import print dissimilarity loading true else range range continue print sorted print done,issue,negative,positive,positive,positive,positive,positive
374069759,"i think when extract, off the --skip existing, it may help. ",think extract skip may help,issue,negative,neutral,neutral,neutral,neutral,neutral
374066385,"The object files aren't too detailed- I looked at them in simplify3d to see about printing some and they are kinda messy. Still having trouble getting any .png files from them. It's not a a to b conversion, and the site doesn't have, that I can find, a spot to output .png files from the obj files. Let me know if you see a solution.
",object see printing messy still trouble getting conversion site find spot output let know see solution,issue,negative,negative,negative,negative,negative,negative
374064872,"Look at the messages during the convert, it'll tell you any files it doesn't convert and why.  Usually, yes, it's because it doesn't find faces.  One thing you can do is run extract again with --skip-existing and different options selected to try to find more faces.  CNN works better than hog and finds more faces.  Rotation also night help.  Try different options to find more faces and figure out what works for you.",look convert tell convert usually yes find one thing run extract different selected try find work better hog rotation also night help try different find figure work,issue,positive,positive,neutral,neutral,positive,positive
374001954,"the site itself has a renderer - not that hard to dumps some pngs from there, and in terms of limited in size- well we're only looking at 128x128px",site renderer hard limited well looking,issue,negative,negative,negative,negative,negative,negative
374000474,"Its not a bad idea, getting the OBJ files to either JPG or PNG without uploading would be the trick. In addition, the ""faces"" it produces do seem rather limited in size. I have thought about this for 3d printing several times. ",bad idea getting either without would trick addition seem rather limited size thought printing several time,issue,negative,negative,negative,negative,negative,negative
373927667,Extract in this PR uses an old mechanism. I will revert it as I still have to solve the question of alignment.json that is not handled properly,extract old mechanism revert still solve question handled properly,issue,negative,positive,neutral,neutral,positive,positive
373926305,"I trained it like I do every time I start a new model. I first trained both A and B on my training data set which is around 21,000 faces from 15 different people for around 24 hours so the model gets exposed to a lot of different face angles and shapes. Then I replaces A and B with there target data sets and train on them for around 12-24 hours before running the convert. I have found at least with the Original model this is the best way to get the best results. I have no idea if this works for this model.

I also noticed when using cnn to do the extraction in this PR I was getting some really strange rotations I was not getting if I use the cnn from master. I have set to -r off during both of these so I am not sure why it was not aligning them the same.
 For example the first one below was extracted using CNN from master. The one below that was done with this PR.
![2017-07-14 00 31 26 1558491504597643697_26190125_0](https://user-images.githubusercontent.com/36505807/37556792-512250f2-29d1-11e8-8d89-96ccf7479261.jpg)
![2017-07-14 00 31 26 1558491504597643697_26190125_0](https://user-images.githubusercontent.com/36505807/37556795-5b44b1ba-29d1-11e8-986e-45bc96bbfe41.jpg)

",trained like every time start new model first trained training data set around different people around model exposed lot different face target data train around running convert found least original model best way get best idea work model also extraction getting really strange getting use master set sure example first one extracted master one done,issue,positive,positive,positive,positive,positive,positive
373924344,"@DLSauron The alignments of some of those faces are clearly way off, and completely outside the face alignment I'd expect the network to have been presented with at training time.

If I can get a bit camera need here:

4 is interesting in the respect that it's showing not a difference in angle but in angle of view, It looks like the network has been consistently trained with a images from a much narrower angle of view (longer lenses from further away) so when it's presented with a  image with a wider angle of view (short lenses from close up) that kind of distortion appears.

I can't comment on how it's supposed to account of these sort of discrepancies perhaps in the pre-processing ""extract"" phase or boring old manual human guidance.",clearly way completely outside face alignment expect network training time get bit camera need interesting respect showing difference angle angle view like network consistently trained much narrower angle view longer away image angle view short close kind distortion ca comment supposed account sort perhaps extract phase boring old manual human guidance,issue,positive,positive,neutral,neutral,positive,positive
373891891,"@Clorr Thanks That fixed it. I also updated the PowerShell GUI I created for myself so that if I select the DFaker Model it will change the convert type as well.

After finishing a test covert I can say some of the images look really good, but it really appears to have trouble with faces that are just a little bit off center

![2017-04-01 21 46 33 1483753780335724088_26190125](https://user-images.githubusercontent.com/36505807/37551356-a0504006-2974-11e8-94d2-1b5f52d3fa0d.jpg)
![2017-05-01 13 51 05 1505259582674296395_26190125](https://user-images.githubusercontent.com/36505807/37551359-a3204678-2974-11e8-928c-2cf8bd66e11c.jpg)
![2017-07-26 19 37 41 1567765735583812242_26190125](https://user-images.githubusercontent.com/36505807/37551360-a5c5563e-2974-11e8-9a46-9f7f1e344c1d.jpg)
![2017-08-01 23 36 26 1572234556755582831_26190125](https://user-images.githubusercontent.com/36505807/37551362-a9b574d6-2974-11e8-83d8-5c445b4b400c.jpg)
![2017-09-16 05 52 35 1605038790408172807_26190125](https://user-images.githubusercontent.com/36505807/37551363-abe1d682-2974-11e8-9773-3b648cb46676.jpg)
![2017-10-26 06 02 53 1634034273394659809_26190125](https://user-images.githubusercontent.com/36505807/37551364-ad7888ec-2974-11e8-8dda-48ceb0a270cb.jpg)



",thanks fixed also select model change convert type well finishing test covert say look really good really trouble little bit center,issue,positive,positive,neutral,neutral,positive,positive
373887056,"Sadly, shufflenet is not faster to train than a ""normal"" model.  In fact, it takes additional work after the model is trained.

To do this on a phone is simply impossible.  To do this on a computer without GPUs is simply not feasible.  Unfortunately, CPUs just don't have the speed necessary to train models in reasonable time.  If you want to train a model without GPUs, you're welcome to use faceswap as it is, simply install the CPU requirements instead of the GPU, but note that it'll take upwards of months to train a single model using just the CPU.",sadly faster train normal model fact additional work model trained phone simply impossible computer without simply feasible unfortunately speed necessary train reasonable time want train model without welcome use simply install instead note take upwards train single model,issue,negative,negative,neutral,neutral,negative,negative
373854885,"@bryanlon  You have a very good point, the training process will take a lot of time, and no one will train the models on mobile phones.so the shuffle net may bring very little benefits. But for someone who don't have good gpus on their computers, if they have an option that using shuffle to train their models and do the inferences, it may save them a lot of time. ",good point training process take lot time one train mobile shuffle net may bring little someone good option shuffle train may save lot time,issue,positive,positive,positive,positive,positive,positive
373810325,"@iperov the side face errors there are interesting, by the looks of it the landmarks are chopping off the nose, perhaps some padding on the mask at extreme angles would make sense.",side face interesting chopping nose perhaps padding mask extreme would make sense,issue,negative,positive,positive,positive,positive,positive
373808817,@Clorr in doublePass the values returned by the network should be in the range 0.0-1.0 so shouldn't need to be divided again before being passed back in for the second pass.,returned network range need divided back second pas,issue,negative,neutral,neutral,neutral,neutral,neutral
373798918,"Trying to do a test convert with the new commit and it just spits out the below error over and over for every image.

**python faceswap.py convert -i ""D:\Fakes\Data\DataSet_A"" -o ""D:\Fakes\Convert\DfakerTest"" -m ""d:\Fakes\Models\DFaker"" -t DFaker -S -e 2  -D cnn** 

OpenCV Error: Assertion failed (src.cols > 0 && src.rows > 0) in cv::warpAffine, file C:\projects\opencv-python\opencv\modules\imgproc\src\imgwarp.cpp, line 5880
Failed to convert image: D:\Fakes\Data\DataSet_A\2016-08-05 15.27.19 1310344341365053947_26190125.jpg. Reason: C:\projects\opencv-python\opencv\modules\imgproc\src\imgwarp.cpp:5880: error: (-215) src.cols > 0 && src.rows > 0 in function cv::warpAffine",trying test convert new commit error every image python convert error assertion file line convert image reason error function,issue,negative,positive,positive,positive,positive,positive
373786383,"converted video:
[result.zip](https://github.com/deepfakes/faceswap/files/1820204/result.zip)
vs fakeapp https://www.youtube.com/watch?v=Va9JLpkCUBs

Dfaker full face conversion of course better. But poor in 90 angles
",converted video full face conversion course better poor,issue,negative,positive,positive,positive,positive,positive
373766572,"```
Traceback (most recent call last):
  File ""E:\FaceSwap\_internal\bin\faceswap\scripts\convert.py"", line 257, in con
vert
    image = converter.patch_image(image, face, 64 if ""128"" not in self.arguments
.trainer else 128)
  File ""E:\FaceSwap\_internal\bin\faceswap\plugins\Convert_Masked.py"", line 37,
in patch_image
    image_mask = self.get_image_mask( image, new_face, face_detected.landmarksAs
XY(), mat, image_size )
  File ""E:\FaceSwap\_internal\bin\faceswap\plugins\Convert_Masked.py"", line 151,
 in get_image_mask
    cv2.warpAffine( face_src, mat, image_size, face_mask, cv2.WARP_INVERSE_MAP |
 cv2.INTER_CUBIC, cv2.BORDER_TRANSPARENT )
cv2.error: C:\projects\opencv-python\opencv\modules\imgproc\src\imgwarp.cpp:5880
: error: (-215) src.cols > 0 && src.rows > 0 in function cv::warpAffine
```",recent call last file line con vert image image face else file line image mat file line mat error function,issue,negative,neutral,neutral,neutral,neutral,neutral
373766459,"suggest to fix traceback in conver.py:

```
except Exception as e:
            import traceback
            traceback.print_exc()
            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
```
",suggest fix except exception import print convert image reason,issue,negative,neutral,neutral,neutral,neutral,neutral
373765851,"I see no problem with this PR.  I am not sure it encourages correct development though, since many people will use it solely for import and lead to imports not being where they are used.",see problem sure correct development though since many people use solely import lead used,issue,negative,positive,positive,positive,positive,positive
373765330,"ShuffleNet is an optimization for running Neural Networks on a phone or other portable low power device.  This is not going to help what we're attempting to do with faceswap since we are spending our time training a model, not just running one.  Due to the fact that almost all effort is spent on training, a shufflenet is not an appropriate solution.",optimization running neural phone portable low power device going help since spending time training model running one due fact almost effort spent training appropriate solution,issue,positive,positive,neutral,neutral,positive,positive
373764683,"Both Convert and Extract do capture exceptions, but those are exceptions whose results are known and so should not stop all execution.  Instead they provide the basic information such as 'Failed to extract from image: {}. Reason: {}'.format(filename, e) which will say that this particular image was not converted and give the error it got for it.  (which will usually be not found or permission) and should give all the information needed to solve for it.

train.py was capturing all exceptions in the whole model and/or trainer and swallow them.  The difference in implementation here is huge, the ones in convert and extract are properly capturing and dealing with the exception, train.py was only intending to capture KeyboarInterrupt (and in a lesser sin, the preview sample) but was swallowing all other exceptions.

I agree that all of our exception handling could be improved, but for now, these train.py exceptions are the only ones causing problems with debugging.",convert extract capture whose known stop execution instead provide basic information extract image reason say particular image converted give error got usually found permission give information solve whole model trainer swallow difference implementation huge convert extract properly dealing exception intending capture lesser sin preview sample agree exception handling could causing,issue,negative,positive,neutral,neutral,positive,positive
373763272,"Training is unchanged. For you error, you should provide a traceback so i can see where it comes from.",training unchanged error provide see come,issue,negative,neutral,neutral,neutral,neutral,neutral
373756497,"I pushed a commit, feel free to review",commit feel free review,issue,positive,positive,positive,positive,positive,positive
373751435,"Also a question: In ""doublePass"" block, you pass `new_face_rgb` without dividing by 255.0 . Is that correct? Predicted image is 0...255 range and should be divided, isn't it?",also question block pas without dividing correct image range divided,issue,negative,neutral,neutral,neutral,neutral,neutral
373750227,"Hmm you're pointing a potential bug in my code. 

You did:
```
    new_face_rgb,new_face_m = autoencoder.predict( [face / 255.0,zmask] )

    if doublePass:
      ...
      new_face_rgb,_ = autoencoder.predict( [new_face_rgb,zmask] )

_,other_face_m = otherautoencoder.predict( [face / 255.0,zmask] )
```
And I'm doing:
```
    new_face_rgb,new_face_m = encoder_A.predict( [face / 255.0,zmask] )

    if doublePass:
      ...
      new_face_rgb,_ = encoder_B.predict( [new_face_rgb,zmask] )

_,other_face_m = encoder_A.predict( [face / 255.0,zmask] )
```
So `other_face_m` is actually same as `new_face_m`

I'm fixing this....",pointing potential bug code face face face face actually fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
373690794,"Just to add my experience with this model, I got vastly superior results using IAE compared to original.

A contains about 2000 faces of the same person ripped at 1fps from various 720p videos. B contains about 500 pics, of my target face with less varied angles.

Original model was trained for about 24 hours (GTX 1080). A got down to about 0.017, B to about 0.025. I can never get B down much lower with this particular data set :/. Final output is more of a hybrid of A and B with some serious issues at difficult angles (understandable, given the data set).

IAE was trained for about 12 hours, and got down to about 0.020 and 0.030 for A and B respectively. It seemed to have plateaued at this point, so I though I'd give it a go, not expecting much. 

The results on IAE were for more like the target B face, despite the higher loss values. There are still issues at difficult angles, but they are no way near as pronounced.",add experience model got vastly superior original person various target face le varied original model trained got never get much lower particular data set final output hybrid serious difficult understandable given data set trained got respectively point though give go much like target face despite higher loss still difficult way near pronounced,issue,positive,positive,neutral,neutral,positive,positive
373689583,"Very nice PR. Fits well into my work flow. And the good thing is it has the options to retain the file names which is important because that info is used in the alignment data.

Seems to have no issues so far with the rest of the code.",nice well work flow good thing retain file important used alignment data far rest code,issue,positive,positive,positive,positive,positive,positive
373682861,"@kvrooman thanks for testing this in details. I don't think this subject deserves so much work though. AFAIK [the source of dlib specifies RGB input](https://github.com/davisking/dlib/blob/09f36dbf4771947c01514a160c70d8a6d1a02aa7/tools/python/src/cnn_face_detector.cpp#L37
) which was already what was done before, but with bad naming. `cv2.imread` [loads in BGR](https://www.learnopencv.com/why-does-opencv-use-bgr-color-format/) and the revert of channels does a RGB. And on that, I agree with your PR.

On the question whether we should loop over multiple channels or not, I think that this is not **needed** but can still help in some cases. My **intuition** on this is that, whatever the channels order, you will have a prediction, and mixing the channel will give you different result on edge cases.

My conclusion is that, by respect for the original work, we should keep the 2 channels, but named correctly. If the speed increase really matters to you, I would suggest to handle this as an option such as --detector-channels, where we can specify RGB, BGR, RGB+BGR. Also this way, anyone who thinks his config works best can still use it.",thanks testing think subject much work though source input already done bad naming revert agree question whether loop multiple think still help intuition whatever order prediction channel give different result edge conclusion respect original work keep correctly speed increase really would suggest handle option specify also way anyone work best still use,issue,positive,positive,positive,positive,positive,positive
373673202,"Both convert and extract mask the exception, but I admit that if we did a raise here, it would stop completly the process and may be annoying as user wouldn't be able to process other valid items.

My second proposition was not to say to print a message instead of raising, it was more adding a message before raising. I was suggesting that because many users are scared by tracebacks and don't know which part to read. I agree that the error message is already at the end of the traceback, but newbies don't see it. 

However in my proposition, I agree that users would have to scroll to see the ""user friendly"" message and many won't do it as they will see the traceback and won't see anything else.",convert extract mask exception admit raise would stop process may annoying user would able process valid second proposition say print message instead raising message raising suggesting many know part read agree error message already end see however proposition agree would scroll see user friendly message many wo see wo see anything else,issue,negative,positive,positive,positive,positive,positive
373668776,"@fetchlister you can use LowMem by using `-t LowMem` on command line. Otherwise, you will have to modify the code. But if you don't know which model configuration was used to produce the file you have, it may be a hard guess work",use command line otherwise modify code know model configuration used produce file may hard guess work,issue,negative,negative,negative,negative,negative,negative
373659490,"I think the Original model uses 7 layers, and the standard LowMem model uses 6 layers. The LowMem model has removed line 57 from the Original, which is `x = self.conv(1024)(x)`.
If the LowMem model has too few layers to match the models you've been given, you can add in that line. If it has too many layers, you can comment out some `self.conv` lines with the number symbol #.",think original model standard model model removed line original model match given add line many comment number symbol,issue,positive,positive,positive,positive,positive,positive
373606412,"I can confirm that a model trained with LowMem will show an error like that when attempting to use the Original trainer. The 1024 is what the trainer is expecting, and the 512 is what the model has been trained with previously.
There could be other problems, like a number of layers mismatch, but it's the Encoder_Dim on line 15 of the Model.py that's causing that error specifically.",confirm model trained show error like use original trainer trainer model trained previously could like number mismatch line causing error specifically,issue,negative,positive,positive,positive,positive,positive
373553804,"Try LowMem model, maybe you can have luck with it. Otherwise note that FakeApp has options not documented and not available here so it possible that you can't use them with code from this repo",try model maybe luck otherwise note available possible ca use code,issue,negative,positive,positive,positive,positive,positive
373552719,It is possible to add as many plugins as we want so if you can implement something it can be added to the repository ,possible add many want implement something added repository,issue,negative,positive,positive,positive,positive,positive
373475946,"@Apollo122 Yeah I had issues with this, that's the reason I took the combination of the masks from both Autoencoders A and B to build the mask looks like the code here is using A twice as `other_face_m` is still using enoder_A in: 

`_,other_face_m = self.encoder_A...`",yeah reason took combination build mask like code twice still,issue,positive,neutral,neutral,neutral,neutral,neutral
373462417,"Just flipped the single line in the current master code
```
input_images = [input_image, input_image_bgr]
```
to
```
input_images = [ input_image_bgr, input_image]
```
and re-ran on my test set

py faceswap.py extract -i E:\shots\testing -o E:\shots\testing\faces_reverse_order -D cnn
6,663 faces found in 10,000 frames --- 35:23 time --- 4.71 it/s

So the BGR image does provide some small value...a 0.105% increase in faces over just the RGB alone. Could change based on dataset, of course. Interestingly enough the 7 faces obtained above in addition from running just the RGB alone were shots of someone in very reflective sunglasses ( i.e. green/blue blobs over their eyes )

**so the choices we have**
1.current code ( run BGR first, then quit if face found, else run RGB )
       ...6,599 faces found in 10,000 frames --- 37:49 time --- 4.41 it/s 
2.PR code ( run just RGB )
       ...6,656 faces found in 10,000 frames --- 30:22 time --- 5.49 it/s
3.swap image_list order in current code (( run RGB first, then quit if face found, else run BGR )
       ...6,663 faces found in 10,000 frames --- 35:23 time --- 4.71 it/s

I'm biased to 2 and the speed-up but I'll defer to the community's thoughts.",single line current master code test set extract found time image provide small value increase alone could change based course interestingly enough addition running alone someone reflective code run first quit face found else run found time code run found time order current code run first quit face found else run found time defer community,issue,negative,positive,neutral,neutral,positive,positive
373454110,@dfaker do you have any idea about how to keep mask inside the borders of face? During my tests I also encountered that mask ends just above the chin for some cases. I mean we know the face's borders why can't we use those values during merge to keep the mask on face only? ,idea keep mask inside face also mask chin mean know face ca use merge keep mask face,issue,negative,negative,negative,negative,negative,negative
373440053,"I haven't looked at the code too much but perhaps the model was trained using the LowMem model and you're trying to use the original converter. 
I believe fakeapp 1.1 is quite dated now (don't quote me on that) so I suggest training on the most recent commit. 
",code much perhaps model trained model trying use original converter believe quite quote suggest training recent commit,issue,positive,positive,positive,positive,positive,positive
373425987,"I'd guess that's probably due to having little variation in your source images, more variation in the sources will cause low detail backgrounds to be output but that's an unintended side-effect, the network will not attempt to optimize the background - this is as designed.",guess probably due little variation source variation cause low detail output unintended network attempt optimize background designed,issue,negative,negative,negative,negative,negative,negative
373422049,I just want same result as on your main page. But in my train no background transfer to 3rd column :(,want result main page train background transfer column,issue,negative,positive,positive,positive,positive,positive
373419271,"One of the main ideas here is that the network trains to produce a mask of just the core face area and also doesn't waste time on attempting to train the background through masking the loss function. 

What did you want to use the extraneous background data for?",one main network produce mask core face area also waste time train background loss function want use extraneous background data,issue,negative,negative,neutral,neutral,negative,negative
373400443,"@iperov that looks pretty good aside from the slight color bias.

The original attempts not to use he background as far as it can, as that is thrown away on merge. So that could conceivably be correct depending on you inputs.",pretty good aside slight color bias original use background far thrown away merge could conceivably correct depending,issue,positive,positive,positive,positive,positive,positive
373367072,"@Clorr @iperov I have added the renaming/moving logging using a json file.
I have also fixed the issue I had with importing from the tools directory, now it's possible to import from it directly (I had to create an empty `__init__.py` file in the tools directory).

As far as I see it, it's all done and ready to be commited. :)

I'm going to use a separate branch for submitting my pull request.",added logging file also fixed issue directory possible import directly create empty file directory far see done ready going use separate branch pull request,issue,negative,positive,neutral,neutral,positive,positive
373301454,"pupil color can be affected by the lighting environment, like shadow over the face, especially for clear eyes, so a bulk replacement with a single reference pupil would probably produce sometimes unnatural pupils. 

So, ideally, you'd have to first analyze the lighting condition of the unmodified target eye of A and adapt the original eye from B face to it before replacing. Can be tricky if A and B have really different eye colors (dark vs clear). And that would probably be very expensive at convert time.

But personally, I don't mind long convert time if the result is more lifelike.",pupil color affected lighting environment like shadow face especially clear bulk replacement single reference pupil would probably produce sometimes unnatural ideally first analyze lighting condition unmodified target eye adapt original eye face tricky really different eye color dark clear would probably expensive convert time personally mind long convert time result lifelike,issue,positive,positive,neutral,neutral,positive,positive
373272818,"may be there is some mistake in porting df ?

![python_2018-03-15_10-16-23](https://user-images.githubusercontent.com/8076202/37447180-4a983ef6-283a-11e8-859d-8fa8e80c55a8.png)

I thought background of third column must train to be like background on first column, as shown on df page:

![chrome_2018-03-15_10-17-47](https://user-images.githubusercontent.com/8076202/37447209-6d86ae52-283a-11e8-9ac2-157fcf51f478.png)
",may mistake thought background third column must train like background first column shown page,issue,negative,positive,positive,positive,positive,positive
373269274,"same problem
`Reason: The model expects 2 arrays, but only received one array. Found: array with shape (1, 64, 64, 3)`",problem reason model received one array found array shape,issue,negative,neutral,neutral,neutral,neutral,neutral
373267676,"@Clorr 
Yeah, I was thinking of additional loss functions (or metrics, similar idea) for faceswapping. It's kind of difficult, because there is no ground truth, unlike warping. For my benchmarking, I just ended up doing face_recognition distance measurements, but it is still unsatisfactory.

Basically, it would be nice to have the faceswap procedure itself be subject to selection.

I did think of one metric with an absolute ground truth.

X = faceA.
Y = swapBtoA(swapAtoB(X))

You can now compare X and Y directly with MSE, SSIM, etc type metrics.

Possible issues:
- You have to avoid the trivial identity solution. Any other trivial solutions? Like some weird intermediate representation that doesn't look like a faceswap but gives the identity solution when applied forwards and backwards? I guess this is avoided by the original loss function being present already.
- I'm not sure if the X -> Y mapping is well-defined or whatever mathematical term is used, because there could be many possible paths. However, there is an absolute final correct answer, so perhaps this doesn't matter. The original loss function also adds a constraint on the path.",yeah thinking additional loss metric similar idea kind difficult ground truth unlike warping ended distance still unsatisfactory basically would nice procedure subject selection think one metric absolute ground truth compare directly type metric possible avoid trivial identity solution trivial like weird intermediate representation look like identity solution applied forward backwards guess original loss function present already sure whatever mathematical term used could many possible however absolute final correct answer perhaps matter original loss function also constraint path,issue,positive,positive,positive,positive,positive,positive
373246076,"Testing the convert and I am getting this error for every file it tries to merge.

Reading alignments from: D:\Fakes\DataSet_A\alignments.json
Failed to convert image: D:\Fakes\DataSet_A\2016-08-05 15.27.19 1310344341365053947_26190125.jpg. Reason: The model expects 2  arrays, but only received one array. Found: array with shape (1, 64, 64, 3)",testing convert getting error every file merge reading convert image reason model received one array found array shape,issue,negative,neutral,neutral,neutral,neutral,neutral
373220926,"Yeah, that's about the idea I had. I would build a pupil recognition system and replace the original eye into the target eye.",yeah idea would build pupil recognition system replace original eye target eye,issue,positive,positive,positive,positive,positive,positive
373219510,"Alternatively, fitting a 69th landmark for the pupil location and
performing the respective transforms and inverse transforms when
normalizing the faces would likely provide some improvement

On Wed, Mar 14, 2018 at 6:10 PM, bryanlyon <notifications@github.com> wrote:

> @Kirin-kun Yes, I really like the idea of adding eye replacement using the
> source image. Pupils really don't need to change that much due to lighting
> (we probably wont notice dilation). I can work on this idea once my plate
> is a little more clear.
>
> On Wed, Mar 14, 2018 at 2:49 PM, Kirin-kun <notifications@github.com>
> wrote:
>
> > We already have the pupils, from the source pictures. Since it's not
> > something that has to be warped, wouldn't it be possible to recolor the
> > visible portions using opencv?
> >
> > Or train a new NN for the eyes :)
> >
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/deepfakes/faceswap/issues/296#issuecomment-373186378
> >,
> > or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> ADEuwc2jqzPfWz7hWH24HnLxm5Z6XKTLks5teZBTgaJpZM4SrKsa>
>
> > .
> >
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/296#issuecomment-373205132>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADmQEhAWWyJR7gXlm7P3phvDsKnmjBcLks5teaNIgaJpZM4SrKsa>
> .
>
",alternatively fitting th landmark pupil location respective inverse would likely provide improvement wed mar wrote yes really like idea eye replacement source image really need change much due lighting probably wont notice dilation work idea plate little clear wed mar wrote already source since something warped would possible recolor visible train new thread reply directly view mute thread thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
373205132,"@Kirin-kun Yes, I really like the idea of adding eye replacement using the
source image.  Pupils really don't need to change that much due to lighting
(we probably wont notice dilation).  I can work on this idea once my plate
is a little more clear.

On Wed, Mar 14, 2018 at 2:49 PM, Kirin-kun <notifications@github.com> wrote:

> We already have the pupils, from the source pictures. Since it's not
> something that has to be warped, wouldn't it be possible to recolor the
> visible portions using opencv?
>
> Or train a new NN for the eyes :)
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/296#issuecomment-373186378>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuwc2jqzPfWz7hWH24HnLxm5Z6XKTLks5teZBTgaJpZM4SrKsa>
> .
>
",yes really like idea eye replacement source image really need change much due lighting probably wont notice dilation work idea plate little clear wed mar wrote already source since something warped would possible recolor visible train new thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
373199142,"As to your first concern, I agree we should make sure all code follows the proper pattern.  This patch fixes train.py since train.py is the only place this anti-pattern is used.

As to your second concern, I don't print a message, since the traceback already makes it very clear that it is an error message and what exactly the error is.  In fact, printing a separate error message would add no data because by it's nature, the traceback already includes the error and it's details.

Here is an example caused by a simple typo:

Exception in thread Thread-1:
Traceback (most recent call last):
  File ""c:\python\python36\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\python\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\Documents\GitHub\faceswap\scripts\train.py"", line 181, in processThread
    raise e
  File ""C:\Users\Documents\GitHub\faceswap\scripts\train.py"", line 147, in processThread
    model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
  File ""C:\Users\Documents\GitHub\faceswap\plugins\Model_GAN\Model.py"", line 54, in __init__
    self.netGA, self.netGB = self.build_generator()
  File ""C:\Users\Documents\GitHub\faceswap\plugins\Model_GAN\Model.py"", line 112, in build_generator
    encoder = Encoderr()
NameError: name 'Encoderr' is not defined

This is an error that would be squashed by the current handling and would only return:

NameError: name 'Encoderr' is not defined

Note that the full traceback is just as clear as the print, but includes all the exact information needed to fix the problem right away.  Other errors could be far more insidious such as.

PermissionError: [Errno 13] Permission denied
or 
io.UnsupportedOperation: not writable

What was denied?  Without a traceback we'd have to hunt to find this problem ourselves.  Traceback is a deliberate part of Python and it's error handling.  Actually changing that may cause confusion to anyone who has seen a Python error before.

Printing added information for the user is one thing, but trying to catch an exception here to do that is not the right time since you'll not be able to actually give them any more useful information (except MAYBE a link to the github to report problems) and will only make it more difficult to debug and understand.",first concern agree make sure code proper pattern patch since place used second concern print message since already clear error message exactly error fact printing separate error message would add data nature already error example simple typo exception thread recent call last file line file line run file line raise file line model trainer file line file line name defined error would current handling would return name defined note full clear print exact information fix problem right away could far insidious permission writable without hunt find problem deliberate part python error handling actually may cause confusion anyone seen python error printing added information user one thing trying catch exception right time since able actually give useful information except maybe link report make difficult understand,issue,negative,positive,positive,positive,positive,positive
373186378,"We already have the pupils, from the source pictures. Since it's not something that has to be warped, wouldn't it be possible to recolor the visible portions using opencv?

Eye tracking is easy with opencv.

Or train a new NN for the eyes :)

http://thume.ca/projects/2012/11/04/simple-accurate-eye-center-tracking-in-opencv/",already source since something warped would possible recolor visible eye easy train new,issue,negative,positive,positive,positive,positive,positive
373186056,"(Seems to be from SRGAN, but I couldn't find the theoric part around it. Some links pointed to tf.space_to_depth so maybe it does not introduce noise but it is more like a reshape. If you have more info I'd be glad to learn more about it)",could find theoric part around link pointed maybe introduce noise like reshape glad learn,issue,positive,positive,positive,positive,positive,positive
373182159,"Also has anyone an idea about what PixelShuffler does? AFAIK it brings some noise which prevents overfitting, but do we know how much noise this is? Couldn't this perturbate the reconstruction as it is on each upscale layer?",also anyone idea noise know much noise could perturbate reconstruction upscale layer,issue,negative,positive,positive,positive,positive,positive
373181321,"@iperov I have updated my gist with the hist-dissim and face-dissim methods; 'dissim' because it's dissimilarity and not unsimilarity. :)

Both methods work, but because I'm pretty tired at the moment I'm not sure if I have converted the face-dissim to work correctly, could you have a look and tell me what you think?

I still need to add the renaming logger option.

Edit: I forgot to add that the dissimilarity methods don't make much sense when organising things into distinct groups, so I have added logic to make it so that if someone uses the dissim methods with grouping by folders it defaults to the ordinary method:
E.g. `python tools.py sort -g folders -by face-dissim` is the same as `python tools.py sort -g folders -by face`",gist dissimilarity unsimilarity work pretty tired moment sure converted work correctly could look tell think still need add logger option edit forgot add dissimilarity make much sense distinct added logic make someone grouping ordinary method python sort python sort face,issue,negative,positive,positive,positive,positive,positive
373179496,"You can check this too. Last commit 4 months ago, implemented in Keras
https://github.com/titu1994/Image-Super-Resolution",check last commit ago,issue,negative,neutral,neutral,neutral,neutral,neutral
373178856,You might also be able to combine 2 JSON files in PowerShell with the ConvertFrom-Json and ConvertTo-Json cmdlets,might also able combine,issue,negative,positive,positive,positive,positive,positive
373177375,"In the crowd of super resolution nets, [this one](https://github.com/jormeli/srcnn-keras) could be very simple to test as it is implemented in keras.",crowd super resolution one could simple test,issue,positive,positive,positive,positive,positive,positive
373177078,You probably know but perception loss helps with realistic eye movements -so it's said in gan repo anyways.,probably know perception loss realistic eye said gan anyways,issue,negative,positive,positive,positive,positive,positive
373176191,"@Clorr That is actually great work. I can see the pupils inside the irises in most of them. Definitely a step in the right direction to addressing this issue.

I'll take a look at the model and some papers to see if there is anything we can do to address these issues. Fixing these will monumentally increase the quality of the output imo.",actually great work see inside definitely step right direction issue take look model see anything address fixing monumentally increase quality output,issue,positive,positive,positive,positive,positive,positive
373176040,Please reopen in playground if necessary,please reopen playground necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
373175793,"2 things here:
- If we make a move, we should do it in every place it would help so we should handle other scripts
- I would do a `print(""You encountered an error : {} . See below for details"" % e)` or something like that to help not experienced users to have the basic message",make move every place would help handle would print error see something like help experienced basic message,issue,positive,positive,positive,positive,positive,positive
373174748,"I played a bit with loss function and res_blocks to get better details, however I had not much luck. In this try, however I got [better defined eyes](https://github.com/deepfakes/faceswap/issues/247#issuecomment-372017633)",bit loss function get better however much luck try however got better defined,issue,positive,positive,positive,positive,positive,positive
373168931,can we integrate alignment info into PNG file by using `tEXt` chunk ? https://www.w3.org/TR/PNG/#11tEXt,integrate alignment file text chunk,issue,negative,neutral,neutral,neutral,neutral,neutral
373150823,"@Clorr or grep A and B folders for anything like alignment*json and run through them all, then it's just a case of dropping any additional images and alignments files into the A or B folder.",anything like alignment run case dropping additional folder,issue,negative,neutral,neutral,neutral,neutral,neutral
373150357,"I've always kept the alignments.json extracted from my target video untouched, but for the copies in the A and B folders appending to them as you add new source stills or frames is fine.",always kept extracted target video untouched add new source fine,issue,negative,positive,positive,positive,positive,positive
373150162,Wouldn't it be better to add an option to have multiple input folders?,would better add option multiple input,issue,negative,positive,positive,positive,positive,positive
373148975,"Joining alignment.json files is obviously usable, but I don't recommend it because some models will rely on each convert process being all one video file.  Joiniing multiple alignment files is going to lead to issues with those models.  It makes more sense to get used to using something else to join the videos after individual convert.  ffmpeg can do this easily, so can any number of tools.

Of course, there are other good reasons to join alignment files (like breaking up extract across multiple PCs to make it faster) and I appreciate the link to that tool.",joining obviously usable recommend rely convert process one video file multiple alignment going lead sense get used something else join individual convert easily number course good join alignment like breaking extract across multiple make faster appreciate link tool,issue,positive,positive,positive,positive,positive,positive
373147728,@bryanlyon converting separately and then merging them with https://stedolan.github.io/jq/ or a text editor has been my approach.,converting separately text editor approach,issue,negative,neutral,neutral,neutral,neutral,neutral
373144636,"Ah. I hadn't seen that. ^_^
The file paths issue with imports brought up in that thread was the reason why I wanted to use a root dir command script as well. :p

From experimenting earlier today with integrating sort into `faceswap.py`, I had re-written the `sort.py` cli parsing approach to more or less match `scripts/train.py`, so I have also just made a  `tools.py`.

However there is an issue, since if there is a `tools.py` file and a directory called `tools`, the interpreter seems to always pick the file as the target for the import, do you know a way around this besides renaming one of them?
For now I have renamed the `tools` directory to `extra_tools`.

Here is a gist for `tools.py`:
https://gist.github.com/AbysmalBiscuit/391cc9e38ef452210a446b91faac559d

I have also updated my sort.py gist so that it can be used with tools.py. 
I have added the sort -by face-cnn method, but it doesn't seem to group properly into folders, and I haven't yet figured out why. Sorting by renaming works really well though, <s>so it seems thatthe issue is something to do with how I group the images together/threshold values I have tried.</s> the problem was the threshold values I was using, as the scores that get calculated are much bigger than 0.5.
I still have to add face-unsim, hist-unsim and a file renaming logger.",ah seen file issue brought thread reason use root command script well today sort approach le match also made however issue since file directory interpreter always pick file target import know way around besides one directory gist also gist used added sort method seem group properly yet figured work really well though issue something group problem threshold get calculated much bigger still add file logger,issue,negative,positive,neutral,neutral,positive,positive
373143151,"Convert now works and I'm getting quite good results. This model works really well for details.

Good work !

I think the convert might need some tweaking because the mask sometimes cover outside the face and is visible. Also I'm getting some weird colors and shadows on the merged face. Does the match histogram option in convert works with this plugin ?",convert work getting quite good model work really well good work think convert might need mask sometimes cover outside face visible also getting weird color face match histogram option convert work,issue,positive,positive,positive,positive,positive,positive
373140067,"Like I said I was never going to convert with that data set, just train.",like said never going convert data set train,issue,negative,neutral,neutral,neutral,neutral,neutral
373137850,You should convert each set with an alignments.json separately then use a traditional editor to combine them.  You shouldn't run a monolithic convert.,convert set separately use traditional editor combine run monolithic convert,issue,negative,neutral,neutral,neutral,neutral,neutral
373122928,"@Clorr cheers for explaining the general direction of the project and intention for `faceswap.py`.  :)
I guess I do mostly have an end user perspective.

Would you be open to the idea of having something like a `faceswap-tools.py` or `tools.py` file? Since this would allow for a clear separation of the machine learning aspects while allowing for easy integration and usage of end user tools/features (maybe also integrating some of the more commonly used ffmpeg commands).

@iperov I'll add it in.",explaining general direction project intention guess mostly end user perspective would open idea something like file since would allow clear separation machine learning easy integration usage end user maybe also commonly used add,issue,positive,positive,positive,positive,positive,positive
373121544,"Ya having to have the alignments.json sucks when you try and combine more than one data set as there is no good easy way I know to merge the alignments.json. I have a data set of 16K faces I use for basic face training, but since I was never planing on running a convert from it all I kept was the extracted faces and none of the alignments files (not that I have an easy way to merge them if I did).",ya try combine one data set good easy way know merge data set use basic face training since never running convert kept extracted none easy way merge,issue,positive,positive,positive,positive,positive,positive
373112937,"I trying putting the target face on any person I present to the model. Original is not bad already, but I'm trying to refine (see left columns of my images in #247 ).",trying target face person present model original bad already trying refine see left,issue,negative,negative,neutral,neutral,negative,negative
373111606,"When you say ""many-to-one"", you mean making an average face, like [this](https://www.learnopencv.com/average-face-opencv-c-python-tutorial/)? 

Or the reverse, putting the same face on multiple persons? Because the original model can do that partially already.",say mean making average face like reverse face multiple original model partially already,issue,positive,negative,neutral,neutral,negative,negative
373110341,"Yes it is something that I [discussed with @dfaker ](https://github.com/dfaker/df/issues/28). Before starting training we have to generate an alpha mask, which is based on aligned + alignments.json but it has a couple of drawbacks

I will do another extract that creates png with embedded masks",yes something starting training generate alpha mask based couple another extract,issue,negative,neutral,neutral,neutral,neutral,neutral
373110104,"also why it needs source alignments ??

>     alignments = json.loads( open(alignments).read() )
> FileNotFoundError: [Errno 2] No such file or directory: 'E:\\FaceSwap\\workspace\\data_src\\aligned\\alignments.json'",also need source open file directory,issue,negative,neutral,neutral,neutral,neutral,neutral
373109031,"I rerun extract, but train try to load alignments from aligned folder??
![explorer_2018-03-14_21-29-37](https://user-images.githubusercontent.com/8076202/37419987-2745b926-27cf-11e8-8af0-724027c80d9b.png)
",rerun extract train try load folder,issue,negative,neutral,neutral,neutral,neutral,neutral
373108823,"The ""can't create frames"" thing seems to be out of MyFakeApp when it's attempting to remake the original video. It's the application mentioned in #201 (which should be closed by the way)

I don't think you will get support on this side project here. Radek stopped developping it and the scripts it uses are outdated (cf https://radek350.wordpress.com/2018/02/17/myfakeapp-fakeapp-alternative/)",ca create thing remake original video application closed way think get support side project stopped outdated,issue,positive,negative,neutral,neutral,negative,negative
373089020,"Ah ok, the align_eyes added new params... This should be fixed, but I can't test as i have a train in progress",ah added new fixed ca test train progress,issue,negative,positive,positive,positive,positive,positive
373086063,"I preformed a fresh extract of 2 datasets one with hog the other I was able to do with cnn. I moved to alignments.json into the folders with the extracted faces and then tried to train. Not sure if I am missing something.

**python faceswap.py train -A ""D:\Fakes\Data\DataSet_A\cnn"" -B ""D:\Fakes\Data\DataSet_B\hog"" -m ""d:\Fakes\Models\DFaker"" -p -s 100 -bs 20 -t DFaker**

Traceback (most recent call last):
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\train.py"", line 153, in processThread
    trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\Trainer.py"", line 68, in __init__
    images_A, landmarks_A = load_images_aligned(fn_A[:minImages])
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\utils.py"", line 28, in load_images_aligned
    mat = get_align_mat( detected_face )
TypeError: get_align_mat() missing 2 required positional arguments: 'size' and 'should_align_eyes'

",preformed fresh extract one hog able extracted tried train sure missing something python train recent call last file line file line run file line trainer trainer model file line file line mat missing positional,issue,negative,positive,positive,positive,positive,positive
373079861,"During creation of your issue, the following messages were in the textbox by default.  We need the information to help.  Please read it and fill it out completely.

**Note: Please only report bugs in this repository. Just because you are getting an error message does not automatically mean you have discovered a bug. If you don't have a lot of experience with this type of project, or if you need for setup help and other issues in using the faceswap tool, please refer to the [faceswap-playground](https://github.com/deepfakes/faceswap-playground/issues) instead. The faceswap-playground is also an excellent place to ask questions and submit feedback.**

## Expected behavior

*Describe, in some detail, what you are trying to do and what the output is that you expect from the program.*

## Actual behavior

*Describe, in some detail, what the program does instead. Be sure to include any error message or screenshots.*

## Steps to reproduce

*Describe, in some detail, the steps you tried that resulted in the behavior described above.*

## Other relevant information
- **Command lined used (if not specified in steps to reproduce)**: faceswap.py ...
- **Operating system and version:** Windows, macOS, Linux 
- **Python version:** 2.7, 3.5, 3.6.4, ...
- **Faceswap version:** commit hash or version number
- **Faceswap method:** CPU/GPU
- **Other related issues:** #123, #124...
- ... (for example, installed packages that you can see with `pip freeze`)
",creation issue following default need information help please read fill completely note please report repository getting error message automatically mean discovered bug lot experience type project need setup help tool please refer instead also excellent place ask submit feedback behavior describe detail trying output expect program actual behavior describe detail program instead sure include error message reproduce describe detail tried behavior relevant information command lined used reproduce operating system version python version version commit hash version number method related example see pip freeze,issue,positive,positive,positive,positive,positive,positive
373053709,"Regarding the more faces found... the current code will abort the code loop below and not evaluate the RGB image in the detector if ""any"" faces are found in the BGR image. I also found more faces in my test...
```
for current_detector, input_image in ((current_detector, input_image) for current_detector in dlib_detectors for input_image in input_images):
        detected_faces = current_detector(input_image, 0)
        if len(detected_faces) != 0:
            break
```
Potential scenarios that result in more faces found ( As I strongly suspect the RGB detector is more robust and accurate and 3 people have reported the PR finding more faces, one of the following is likely true )
1. The detector finds a foot in the BGR image and thinks its a face and quits the loop. The RGB detector would have found a foot and a face or just a face.
2. The detector finds a frontal face in the BGR image and quits the loop. The RGB detector would have found a frontal face and a profile face.
3. The detector finds a normal sized face in the BGR image and quits the loop. The RGB detector would have found a normal sized face and a tiny face and a large face.
4. The detector finds a face of Person A in the BGR image and quits the loop. The RGB detector would have found a face of Person A and Person B.

You can isolate for this test by flipping the order of the image list from
```
input_images = [input_image, input_image_bgr]
```
to
```
input_images = [ input_image_bgr, input_image]
```
Once again the ""input_image_bgr"" is the image actually in RGB format...
",regarding found current code abort code loop evaluate image detector found image also found test break potential result found strongly suspect detector robust accurate people finding one following likely true detector foot image face quits loop detector would found foot face face detector frontal face image quits loop detector would found frontal face profile face detector normal sized face image quits loop detector would found normal sized face tiny face large face detector face person image quits loop detector would found face person person isolate test order image list image actually format,issue,positive,positive,positive,positive,positive,positive
373037332,"Ok, thanks for trying. Still strange though... As the alignments.json changed you have to extract again, so the only option I have for you now is to use 'hog'",thanks trying still strange though extract option use,issue,negative,positive,neutral,neutral,positive,positive
373035551,"No even with the verbose flag in master  I do not get any memory errors

python faceswap.py extract -i ""D:\Fakes\Data\Dataset_A"" -o ""D:\Fakes\Data\Dataset_A\aligned"" -D cnn -r off -v
C:\Users\DLSauron\Envs\faceswap\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Input Directory: D:\Fakes\Data\Dataset_A
Output Directory: D:\Fakes\Data\Dataset_A\aligned
Filter: filter.jpg
Using json serializer
Starting, this may take a while...
Loading Extract from Extract_Align plugin...
  0%|                                                                                          | 0/544 [00:00<?, ?it/s]Info: initializing keras model...
2018-03-14 10:09:41.059642: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-03-14 10:09:41.063793: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties:
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 12.00GiB freeMemory: 8.09GiB
2018-03-14 10:09:41.067797: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From C:\Users\DLSauron\Envs\faceswap\lib\site-packages\keras\backend\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
 67%|█████████████████████████████████████████████████████▏                          | 362/544 [01:18<00:39,  4.63it/s]Warning: No faces were detected.
100%|████████████████████████████████████████████████████████████████████████████████| 544/544 [01:53<00:00,  4.81it/s]
Alignments filepath: D:\Fakes\Data\Dataset_A\alignments.json
Writing alignments to: D:\Fakes\Data\Dataset_A\alignments.json

 -------------------------
Images found:        544
Faces detected:      576

 -------------------------
Note:
Multiple faces were detected in one or more pictures.
Double check your results.

 -------------------------
Done!",even verbose flag master get memory python extract conversion second argument float future float import input directory output directory filter starting may take loading extract model binary use found device name major minor device device name bus id compute capability warning calling removed future version use instead warning writing found note multiple one double check done,issue,negative,positive,neutral,neutral,positive,positive
373034008,"@AbysmalBiscuit also add

hist-unsim

first places photos which maximum non similar with each other

```
    def process_hist_unsim(self):
        input_dir = self.arguments.input_dir
        
        print (""Sorting by histogram unsimilarity..."")
        
        img_list = [ [x, cv2.calcHist([cv2.imread(x)], [0], None, [256], [0, 256]), 0] for x in tqdm( self.find_images(input_dir), desc=""Loading"") ]

        img_list_len = len(img_list)
        for i in tqdm ( range(0, img_list_len), desc=""Sorting""):
            score_total = 0
            for j in range( 0, img_list_len):
                if i == j: continue
                score_total += cv2.compareHist(img_list[i][1], img_list[j][1], cv2.HISTCMP_BHATTACHARYYA)
            
            img_list[i][2] = score_total

        
        print (""Sorting..."")            
        img_list = sorted(img_list, key=operator.itemgetter(2), reverse=True)         
        self.process_final_rename (input_dir, img_list)
                
        print (""Done."")
```
also make same with face-unsim

example:

at first maximum non similar:
![fsviewer_2018-03-14_18-05-55](https://user-images.githubusercontent.com/8076202/37407287-b9cfae0e-27b2-11e8-9a6d-295e6947b0a1.png)

at end maximum similar:
![fsviewer_2018-03-14_18-06-09](https://user-images.githubusercontent.com/8076202/37407294-bbb05c64-27b2-11e8-8b22-7c4470cb1d78.png)
",also add first maximum non similar self print histogram unsimilarity none loading range range continue print sorted print done also make example first maximum non similar end maximum similar,issue,negative,positive,neutral,neutral,positive,positive
373025222,"The only thing that may change between master and here is that there is no `try : catch:` around extraction. But I thought OOM was a warning, while your post suggest it is an exception. It means that now, your extract is stopping while before the error was silent. anyhow this part is not meant to be in the final release but thanks for pointing out.

(If you want to be sure, you can enable the verbose mode in the master you should see the info)",thing may change master try catch around extraction thought warning post suggest exception extract stopping error silent anyhow part meant final release thanks pointing want sure enable verbose mode master see,issue,negative,positive,positive,positive,positive,positive
373022925,"@AbysmalBiscuit I don't want to add a new `sort` command to faceswap.py at least for now. You guys think in term of end user usage, and in that case I understand your point: there is a workflow where you `extract`, `sort`, `train` and then `convert` things. On my side, I don't think in term of end user usage, I do think in term of Machine Learning constraints. 

The extract is not just extracting faces, it is also a preprocessing (for now align only, but we could some other that mask the background or generate different types of alignment) of images that have an impact on how the model is trained.

The convert is also specific as it takes output of the model (which can include mask, or other information) and post-processes images.

Sorting has no impact on model training, it is just here to make easier the cleanup process of extraction that is not perfect. If at some point the sorting or filtering or clustering of images can improve the model, we will see it coming and if it can't be made at extraction, I could consider adding another step, however for now, I'm just waiting until there is a need for that.",want add new sort command least think term end user usage case understand point extract sort train convert side think term end user usage think term machine learning extract also align could mask background generate different alignment impact model trained convert also specific output model include mask information impact model training make easier cleanup process extraction perfect point filtering clustering improve model see coming ca made extraction could consider another step however waiting need,issue,positive,positive,positive,positive,positive,positive
373021411,"I can confirm if I run this command with the master branch it runs through all 500+ images just fine, but if I run it with this pull request I get OOM errors. I cannot be sure, but was the resize code that iperov added removed from the extractor?

**python faceswap.py extract -i ""D:\Fakes\Data\DataSet_A"" -o ""D:\Fakes\Data\DataSet_A\aligned"" -D cnn -r off**


Traceback (most recent call last):
  File ""faceswap.py"", line 29, in <module>
    arguments.func(arguments)
  File ""C:\Users\DLSauron\source\repos\faceswap\lib\cli.py"", line 87, in process_arguments
    self.process()
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\extract.py"", line 106, in process
    filename, faces = self.processFiles(filename)
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\extract.py"", line 113, in processFiles
    return filename, self.handleImage(image, filename)
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\extract.py"", line 131, in handleImage
    process_faces = [(idx, face) for idx, face in faces]
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\extract.py"", line 131, in <listcomp>
    process_faces = [(idx, face) for idx, face in faces]
  File ""C:\Users\DLSauron\source\repos\faceswap\lib\cli.py"", line 164, in get_faces
    for face in faces:
  File ""C:\Users\DLSauron\source\repos\faceswap\lib\faces_detect.py"", line 6, in detect_faces
    face_locations = face_recognition.face_locations(frame, model=model)
  File ""C:\Users\DLSauron\Envs\faceswap\lib\site-packages\face_recognition\api.py"", line 114, in face_locations
    return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, ""cnn"")]
  File ""C:\Users\DLSauron\Envs\faceswap\lib\site-packages\face_recognition\api.py"", line 98, in _raw_face_locations
    return cnn_face_detector(img, number_of_times_to_upsample)
RuntimeError: Error while calling cudaMalloc(&data, n) in file C:\Users\DLSauron\AppData\Local\Temp\pip-build-0mfs1ycn\dlib\dlib\dnn\cuda_data_ptr.cpp:28. code: 2, reason: out of memory
",confirm run command master branch fine run pull request get sure resize code added removed extractor python extract recent call last file line module file line file line process file line return image file line face face file line face face file line face file line frame file line return face file line return error calling data file code reason memory,issue,negative,positive,positive,positive,positive,positive
373015604,@DLSauron there is nothing really specific to extract here (just a modified call) so your OOM is likely not related to this PR. Can you confirm?,nothing really specific extract call likely related confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
373014273,No I am getting the OOM error when doing face extraction not training. Unless I am missing something there is no batch size for extraction.,getting error face extraction training unless missing something batch size extraction,issue,negative,negative,negative,negative,negative,negative
373007953,"@kcimit I'll add a log feature.

@iperov can you explain in what way the `img_list` creation code is duplicated? 
It only occurs once in the `process_hist_folders()` method, and besides missing two formatting spaces it's the exact same method used in the `process_hist()` method.

I will add the `-by face-cnn` method.

@torzdf I think it would be better to add it to faceswap.py as an additional main command so as to have: `extract, train, convert, sort`. The way the sort tool parses the cli arguments would have to be modified but it's doable.",add log feature explain way creation code method besides missing two exact method used method add method think would better add additional main command extract train convert sort way sort tool would doable,issue,negative,positive,positive,positive,positive,positive
373007928,"Thanks for the feedback!
Also you are right OOM comes from a too high batch-size.
For convert it is not yet implemented, as this is a draft, I'm still on the extract + preprocess part.
I'll keep you posted for the convert (note you should be able to convert with previous DFaker scripts but using same h5 files, I think)",thanks feedback also right come high convert yet draft still extract part keep posted convert note able convert previous think,issue,negative,positive,positive,positive,positive,positive
373006814,"It seems really promising. I managed to resume training with your plugin a previously trained model with original DFaker. I justed renamed the original model files and rerun the extract command on my A & B sets to get a correct alignements.json. 

To avoid the OOM errors during training, I added a ""-bs 16"" argument (I have a GTX 1080 Ti), it might work with a batch size of 32, i haven't tried it yet.

Unfortunately, I haven't succeeded yet to convert because I keep getting the same error on every face I try to convert.


> Failed to convert image: C:\Projects\dfaker\data\video\imagename1511.jpg. Reason: The model expects 2  arrays, but only received one array. Found: array with shape (1, 64, 64, 3)

Do you have an idea where that error could be coming from ?",really promising resume training previously trained model original original model rerun extract command get correct avoid training added argument ti might work batch size tried yet unfortunately yet convert keep getting error every face try convert convert image reason model received one array found array shape idea error could coming,issue,negative,positive,neutral,neutral,positive,positive
372979094,"Since I'm trying to do a many-to-one face model, I was thinking of adding a face recognition step in the loss, maybe this could help? (I didn't check how resource intensive it is though...)",since trying face model thinking face recognition step loss maybe could help check resource intensive though,issue,negative,neutral,neutral,neutral,neutral,neutral
372972911,There is a 5th argument added by #242 but it seems you're using an older version of `scripts/extract.py`,th argument added older version,issue,negative,positive,positive,positive,positive,positive
372971331,(and this way your imports will be relative to root folder),way relative root folder,issue,negative,neutral,neutral,neutral,neutral,neutral
372970615,"Fair enough for a utility. If you want to make better architecture, you can add a tools.py at the root and make it run with a `tools.py sort`",fair enough utility want make better architecture add root make run sort,issue,positive,positive,positive,positive,positive,positive
372969173,"You can add it as an import (just tested).

add the import as normal, and execute the command from the faceswap dir as:

`python -m tools.sort`

I admit, it's not perfect and we may need to update some documentation, but it is doable.",add import tested add import normal execute command python admit perfect may need update documentation doable,issue,positive,positive,positive,positive,positive,positive
372968035,"@iperov you have to use:
`from ..lib.foo import foo, bar`
You have to add `.` in front of path to go to upper dir",use import foo bar add front path go upper,issue,negative,neutral,neutral,neutral,neutral,neutral
372965049,"@AbysmalBiscuit 
also I suggest to add -by face-cnn

it uses FaceLandmarksExtractor.

example:

```
def process_face(self):
        input_dir = self.arguments.input_dir
        
        print (""Sorting by face similarity..."")
        
        from lib import FaceLandmarksExtractor
        
        img_list = []
        for x in tqdm( self.find_images(input_dir), desc=""Loading""):
            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True)
            img_list.append( [x, np.array(d[0][1]) if len(d) > 0 else np.zeros ( (68,2) ) ] )

        img_list_len = len(img_list)
        for i in tqdm ( range(0, img_list_len-1), desc=""Sorting""):
            min_score = 9999999
            j_min_score = i+1
            for j in range(i+1,len(img_list)):
            
                fl1 = img_list[i][1]
                fl2 = img_list[j][1]
                score = np.sum ( np.absolute ( (fl2 - fl1).flatten() ) )                
                
                if score < min_score:
                    min_score = score
                    j_min_score = j            
            img_list[i+1], img_list[j_min_score] = img_list[j_min_score], img_list[i+1]
            
        self.process_final_rename (input_dir, img_list)
                
        print (""Done."")
```",also suggest add example self print face similarity import loading true else range range score score score print done,issue,negative,positive,positive,positive,positive,positive
372955745,"Ok, I ran some tests, and got some fairly unexpected results, to be honest. On the whole I would say that this is a positive change, but I would like to see some more results, because this looks fairly inconclusive to me right now. I can't help but think there may be some other factors at play in my set up, but here they are anyway, run with:
` -D cnn -r on`

```
                |Time                   |Frames
Title   Frames  |Old     New    Diff    |Old    New     Diff
psp1    3996    |24:39   22:35   2:04   |3959   3985    26 
psp2    2122    |12:45   19:04  -6:19   |1959   1962    3
plow    4496    |30:43   25:23   5:20   |3903   3904    1 
sb      552     |03:06   03:07  -0:01   |552    552     0
----------------|-----------------------|------------------
TOTAL   11166   |71:13   70:09   1:04   |10373  10403   30
----------------|-----------------------|------------------
```
I'm surprised to see that, for the most part, this appears to detect *more* faces.
",ran got fairly unexpected honest whole would say positive change would like see fairly inconclusive right ca help think may play set anyway run title new new plow total see part detect,issue,positive,positive,positive,positive,positive,positive
372954303,@Yuxishan2 This PR is more made to use one or more image sas a filter faces at extract time. Sorting is done in sorttool (#278 and #254 ) ,made use one image filter extract time done,issue,negative,neutral,neutral,neutral,neutral,neutral
372943034,"We can close this, as any further discussion would deviate anyway.",close discussion would deviate anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
372942433,Would it be possible to create a log renames.log containing list [new file name];[original filename],would possible create log list new file name original,issue,positive,positive,positive,positive,positive,positive
372919155,"This issue is missing critical information, please read the instructions and at the requested information.  We can't help you without knowing what is happening.",issue missing critical information please read information ca help without knowing happening,issue,negative,negative,neutral,neutral,negative,negative
372913912,"also there is code duplication

`img_list = [ [x, cv2.calcHist([cv2.imread(x)], [0], None, [256], [0, 256])] for x in tqdm(self.find_images(input_dir), desc=""Loading"") ]`
        
",also code duplication none loading,issue,negative,neutral,neutral,neutral,neutral,neutral
372907913,Can somebody give me a quick explanation how to run the experimental retrain model or post the code?  I tried inserting the experimental code in a cloned Original Model directory but got error messages.    ,somebody give quick explanation run experimental retrain model post code tried experimental code original model directory got error,issue,negative,positive,positive,positive,positive,positive
372901321,"Also I have noticed I am getting OOM memory errors when I run extract, but do not get those when I run the same extraction in master.",also getting memory run extract get run extraction master,issue,negative,neutral,neutral,neutral,neutral,neutral
372894061,"@Kirin-kun  I agree you want auto-insertion, and that will be good enough for 90% of the users. But for the best results, you will have to do manual editing at some point, even if that means just deleting a really bad frame and redoing it or something.

After Effects has auto face outline tracking, I believe, and a much more powerful workflow for editing video. You can combine automated merging with manual correction on frames you desire. I'm no expert, and only tested some very basic function during a brief free trial.

GIMP is free and can do automated batch image processing with an extremely large number of functions. You need the free BIMP plugin. It can do batch sharpening, color correction, almost any filter it normally uses. GIMP also takes python/scripting, although I never played around with it. The downside is that the batch processing is slow, as I doubt it uses the GPU or is particularly optimized.

@Apollo122 Yes... I have my eye on a couple superresolution/post-processing scripts as well.
",agree want good enough best manual point even really bad frame something effect auto face outline believe much powerful video combine manual correction desire expert tested basic function brief free trial gimp free batch image extremely large number need free batch color correction almost filter normally gimp also although never around downside batch slow doubt particularly yes eye couple well,issue,positive,positive,positive,positive,positive,positive
372878740,"I agree with the changes of model names, but not with this PR and I think it shouldn't be done until we have a model system like my proposed project in the project tab.

Since Clorr has said this is good and my check shows it all works I will merge it.",agree model think done model system like project project tab since said good check work merge,issue,positive,positive,positive,positive,positive,positive
372874983,"Try a few model for GAN, unable to get a good result after convert. Preview is good, but after convert the result is bad ",try model gan unable get good result convert preview good convert result bad,issue,negative,positive,neutral,neutral,positive,positive
372870511,"Tested 10,000 frames from multiple movies containing multiple scenes with differing lighting, zoom levels, poses, and profiles shots.

**Current Master Code:**
py faceswap.py extract -i E:\shots\testing -o E:\shots\testing\faces_master -D cnn

6,599 faces found in 10,000 frames --- 37:49 time --- 4.41 it/s
manually sorted through and found 65 false positives

**Proposed PR Code:**
py faceswap.py extract -i E:\shots\testing -o E:\shots\testing\faces_PR -D cnn

6,656 faces found in 10,000 frames --- 30:22 time --- 5.49 it/s
manually sorted through and found 75 false positives

false positives are mostly zoomed out shots with a whole person in the frame of the picture.
Haven't evaluated landmark / alignment file yet but assume there will also be minor adjustments as mentioned previously. 
",tested multiple multiple lighting zoom current master code extract found time manually sorted found false code extract found time manually sorted found false false mostly whole person frame picture landmark alignment file yet assume also minor previously,issue,negative,negative,negative,negative,negative,negative
372866817,It's automatic when you use the converter with a gan trained model. I haven't been getting good results with gan though. The kinks still need to be worked out.,automatic use converter gan trained model getting good gan though still need worked,issue,negative,positive,positive,positive,positive,positive
372863334,"We have IAE ,  VAE-GAN , GAN, XGAN, WGAN from others (Shaoanlu). prefix the name will be better. ",gan prefix name better,issue,negative,positive,positive,positive,positive,positive
372861805,"For clarity reasons we could add something like an AE prefix to Original and all modifications of it like AE_Original, AE_LowMem, AE_Intermediate so users would know it's a similar model",clarity could add something like ae prefix original like would know similar model,issue,positive,positive,positive,positive,positive,positive
372858575,"I actually have been thinking about this, there is a way to load the model
from the folder no matter how the model is structured, we just need to
build a mechanism to save the whole model and reload it.  It's obviously a
big step though, so it'll probably be a good option for a project.

On Mar 13, 2018 4:47 PM, ""Clorr"" <notifications@github.com> wrote:

> @bryanlyon <https://github.com/bryanlyon> I understand your point, but it
> is quite different than a multi_gpu_model. Here we modify the layers
> structure so it is not so generic.
>
> We could go in a parameter for layers as FakeApp did, but I think it will
> lead to problems as a model can't be reloaded if it does not have the same
> layer configuration so people may lose their work by thinking they can play
> freely with params. The question is also the same for ENCODER_DIM. If we
> make this a param some people who don't understand the importance of the
> param they will loose their saved models.
>
> I prefer that people advanced enough start doing manual modifications and
> endorse the responsibility of it than adding a param and having issues that
> says that one can't reload his model and has to be told that he lost it's
> work
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/292#issuecomment-372857300>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuwSxB55I5JhEb8ES7CdfB-KXysxN2ks5teFqbgaJpZM4SomPB>
> .
>
",actually thinking way load model folder matter model structured need build mechanism save whole model reload obviously big step though probably good option project mar wrote understand point quite different modify structure generic could go parameter think lead model ca layer configuration people may lose work thinking play freely question also make param people understand importance param loose saved prefer people advanced enough start manual endorse responsibility param one ca reload model told lost work reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
372857591,One thing though is that I would like to modify the name of the models so they are different than the original. I'm thinking about something with a prefix like for IAE,one thing though would like modify name different original thinking something prefix like,issue,positive,positive,positive,positive,positive,positive
372857300,"@bryanlyon I understand your point, but it is quite different than a multi_gpu_model. Here we modify the layers structure so it is not so generic. 

We could go in a parameter for layers as FakeApp did, but I think it will lead to problems as a model can't be reloaded if it does not have the same layer configuration so people may lose their work by thinking they can play freely with params. The question is also the same for ENCODER_DIM. If we make this a param some people who don't understand the importance of the param they will loose their saved models. 

I prefer that people advanced enough start doing manual modifications and endorse the responsibility of it than adding a param and having issues that says that one can't reload his model and has to be told that he lost it's work",understand point quite different modify structure generic could go parameter think lead model ca layer configuration people may lose work thinking play freely question also make param people understand importance param loose saved prefer people advanced enough start manual endorse responsibility param one ca reload model told lost work,issue,positive,positive,positive,positive,positive,positive
372856409,may i know this balance-loss to train option have merge with the master?  the latest repo train not found this option . ,may know train option merge master latest train found option,issue,negative,positive,positive,positive,positive,positive
372854105,"no conflict at all, i actually use copy and paste yesterday. ",conflict actually use copy paste yesterday,issue,negative,neutral,neutral,neutral,neutral,neutral
372853641,"I agree on principle, I haven't checked this PR, but if it works, I support
it.  My only concern is that maybe low memory should be a configuration on
original instead of its own model.  That is something that needs a better
architecture to do though so this is a good solution for now.

On Mar 13, 2018 3:45 PM, ""Clorr"" <notifications@github.com> wrote:

> Thanks for the PR!
>
> Note that previous LowMem was using files from Original plugin. However
> I'm fine with this PR because it makes sure that a modification on Original
> (which shouldn't happen normally) won't break the LowMem. If everyone is
> fine with that, we can merge it without further discussion
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/292#issuecomment-372844404>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuweP6N11GwblzHpnLY9jK2nxrRyGBks5teEwfgaJpZM4SomPB>
> .
>
",agree principle checked work support concern maybe low memory configuration original instead model something need better architecture though good solution mar wrote thanks note previous original however fine sure modification original happen normally wo break everyone fine merge without discussion thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
372853150,"I'll do an assert instead of just doing single.  I'll update this soon.

On Mar 13, 2018 3:51 PM, ""Clorr"" <notifications@github.com> wrote:

> *@Clorr* commented on this pull request.
> ------------------------------
>
> In plugins/Model_GAN128/Model.py
> <https://github.com/deepfakes/faceswap/pull/288#discussion_r174309405>:
>
> > @@ -42,7 +44,7 @@ class GANModel():
>
>      def __init__(self, model_dir, gpus):
>          self.model_dir = model_dir
> -        self.gpus = gpus
> +        self.gpus = 1 #See https://github.com/deepfakes/faceswap/issues/287
>
> I'd prefer you let the original line and put below it an assert, with a
> failure message pointing to the issue you mention in the comment
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/288#pullrequestreview-103642316>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuwSMSpUasRSv9pOCXK3D3oQ4zwUnJks5teE1WgaJpZM4Sn7zW>
> .
>
",assert instead single update soon mar wrote pull request class self see prefer let original line put assert failure message pointing issue mention comment assigned reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
372852812,"Sure, I'll send another PR and remove it from this one.

On Mar 13, 2018 3:52 PM, ""Clorr"" <notifications@github.com> wrote:

> *@Clorr* commented on this pull request.
> ------------------------------
>
> In scripts/train.py
> <https://github.com/deepfakes/faceswap/pull/288#discussion_r174309672>:
>
> > @@ -178,7 +178,7 @@ def processThread(self):
>                  print('Saving model weights has been cancelled!')
>              exit(0)
>          except Exception as e:
> -            print(e)
> +            raise e
>
> Somehow I agree that the print(e) is not convenient as it make a more
> readable error message but that masks the details. However I would be
> prefere this to be made in another PR
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/288#pullrequestreview-103642630>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuwYpN3v2yY1HokynxvCy-KeE2800Vks5teE2ygaJpZM4Sn7zW>
> .
>
",sure send another remove one mar wrote pull request self print model exit except exception print raise somehow agree print convenient make readable error message however would made another assigned reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
372849352,"No problem, close this PR if you don't think it is relevant",problem close think relevant,issue,negative,positive,positive,positive,positive,positive
372848593,"Sadly it is a bad habit of mine to do a last untested modification before pushing ^^
Here I forgot the ':' . I pushed a fix but the code is still untested as I have not my test machine at hand....",sadly bad habit mine last untested modification pushing forgot fix code still untested test machine hand,issue,negative,negative,negative,negative,negative,negative
372846851,@kvrooman I think splitting your PR is a good move. Did you submit another one? or is the 2nd part dependent of this one?,think splitting good move submit another one part dependent one,issue,negative,positive,positive,positive,positive,positive
372844703,"@oatssss feel free to merge it by yourself when you are fine with it, it is just a fix",feel free merge fine fix,issue,positive,positive,positive,positive,positive,positive
372844404,"Thanks for the PR!

Note that previous LowMem was using files from Original plugin. However I'm fine with this PR because it makes sure that a modification on Original (which shouldn't happen normally) won't break the LowMem. If everyone is fine with that, we can merge it without further discussion",thanks note previous original however fine sure modification original happen normally wo break everyone fine merge without discussion,issue,positive,positive,positive,positive,positive,positive
372843590,"If you notice problem in install.md or any other documentation, please try to improve. You can edit directly the files on github, even without any knowledge of git. When editing directly on Github, this will take care of making a PR for you",notice problem documentation please try improve edit directly even without knowledge git directly take care making,issue,positive,positive,neutral,neutral,positive,positive
372826670,"@Kirin-kun I have optimized the group matching, set sane threshold defaults and explained the the threshold better. 
When you have the time take a look and tell me what you think. :)",group matching set sane threshold threshold better time take look tell think,issue,negative,positive,positive,positive,positive,positive
372815802,"@Kirin-kun After optimizing the face method (and concequently familirizing myself with the library used for it), I know why it found the same face but looking in different directions.
It's because that's what it's meant to do. It is meant to find the same face in a variety of conditions.

Hence I have come up with a sample workflow:
1. Extract video that will have a variety of faces (A, B, C, D).
2. Sort them by face.
3. Sort each face by hist, as that will be sensitive to changes such as lighting, angle, etc...

Edit: I have messed about with a dataset of about 150 images of multiple faces and have deterimined sane defaults for the threshold value. I will update the description as well.",face method library used know found face looking different meant meant find face variety hence come sample extract video variety sort face sort face hist sensitive lighting angle edit multiple sane threshold value update description well,issue,positive,positive,neutral,neutral,positive,positive
372806772,"The Install.md is severely outdated, or inaccurate. You should install the requirements from requirements-gpu-python36-cuda9.txt (do you actually have an NVidia adapter?)

And I have a hunch you're trying to run it on OSX? I think you face an uphill struggle, It's missing the tools to build dlib.

There's something on google about typing `xcode-select --reset` or `xcode-select --install` to install the tools needed to build software on OSX.

",severely outdated inaccurate install actually adapter hunch trying run think face uphill struggle missing build something reset install install build,issue,negative,negative,negative,negative,negative,negative
372794384,"@Kirin-kun Thanks a lot for the response! So I downloaded and redid the link you gave me following https://github.com/deepfakes/faceswap/blob/master/INSTALL.md

First issue was trying to run 'pip3 install -r requirements.txt'. Since wasn't any 'requirements.txt', I'd get an error. 

So instead I ran 'pip3 install -r requirements-python36.txt'. When I did though, it eventually returned this toward the end:
____________________________________________________________________________________
Failed building wheel for scandir
  Running setup.py clean for scandir
  Running setup.py bdist_wheel for dlib ... error
  Complete output from command /usr/local/opt/python/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" bdist_wheel -d /var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/tmpwj_n5gzxpip-wheel- --python-tag cp36:
  running bdist_wheel
  running build
  running build_py
  package init file 'dlib/__init__.py' not found (or not a regular file)
  running build_ext
  Invoking CMake setup: 'cmake /private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/tools/python -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/build/lib.macosx-10.10-x86_64-3.6 -DPYTHON_EXECUTABLE=/usr/local/opt/python/bin/python3.6 -DCMAKE_BUILD_TYPE=Release'
  -- The C compiler identification is unknown
  -- The CXX compiler identification is unknown
  -- Check for working C compiler: /usr/bin/cc
  -- Check for working C compiler: /usr/bin/cc -- broken
  CMake Error at /usr/local/lib/python3.6/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.10/Modules/CMakeTestCCompiler.cmake:52 (message):
    The C compiler
  
      ""/usr/bin/cc""
  
    is not able to compile a simple test program.
  
    It fails with the following output:
  
      Change Dir: /private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/build/temp.macosx-10.10-x86_64-3.6/CMakeFiles/CMakeTmp
  
      Run Build Command:""/usr/bin/make"" ""cmTC_6eb5a/fast""
      xcrun: error: active developer path (""/Library/Developer/CommandLineTools"") does not exist
      Use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, or use `xcode-select --install` to install the standalone command line developer tools.
      See `man xcode-select` for more details.
  
  
  
  
    CMake will not be able to correctly generate this project.
  Call Stack (most recent call first):
    CMakeLists.txt
  
  
  -- Configuring incomplete, errors occurred!
  See also ""/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/build/temp.macosx-10.10-x86_64-3.6/CMakeFiles/CMakeOutput.log"".
  See also ""/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/build/temp.macosx-10.10-x86_64-3.6/CMakeFiles/CMakeError.log"".
  Traceback (most recent call last):
    File ""<string>"", line 1, in <module>
    File ""/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/setup.py"", line 238, in <module>
      'Topic :: Software Development',
    File ""/usr/local/lib/python3.6/site-packages/setuptools/__init__.py"", line 129, in setup
      return distutils.core.setup(**attrs)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/core.py"", line 148, in setup
      dist.run_commands()
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py"", line 955, in run_commands
      self.run_command(cmd)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/usr/local/lib/python3.6/site-packages/wheel/bdist_wheel.py"", line 204, in run
      self.run_command('build')
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/command/build.py"", line 135, in run
      self.run_command(cmd_name)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/distutils/dist.py"", line 974, in run_command
      cmd_obj.run()
    File ""/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/setup.py"", line 119, in run
      self.build_extension(ext)
    File ""/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/setup.py"", line 153, in build_extension
      subprocess.check_call(cmake_setup, cwd=build_folder)
    File ""/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py"", line 291, in check_call
      raise CalledProcessError(retcode, cmd)
  subprocess.CalledProcessError: Command '['cmake', '/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/tools/python', '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/dlib/build/lib.macosx-10.10-x86_64-3.6', '-DPYTHON_EXECUTABLE=/usr/local/opt/python/bin/python3.6', '-DCMAKE_BUILD_TYPE=Release']' returned non-zero exit status 1.
  
  ----------------------------------------
  Failed building wheel for dlib
  Running setup.py clean for dlib
Failed to build scandir dlib
Installing collected packages: scandir, h5py, pyyaml, Keras, opencv-python, tensorflow-tensorboard, tensorflow, dlib, Click, face-recognition-models, face-recognition, tqdm
  Running setup.py install for scandir ... error
    Complete output from command /usr/local/opt/python/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/scandir/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-blixhswu-record/install-record.txt --single-version-externally-managed --compile:
    running install
    running build
    running build_py
    creating build
    creating build/lib.macosx-10.10-x86_64-3.6
    copying scandir.py -> build/lib.macosx-10.10-x86_64-3.6
    running build_ext
    building '_scandir' extension
    creating build/temp.macosx-10.10-x86_64-3.6
    clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/usr/local/opt/openssl/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6/include/python3.6m -c _scandir.c -o build/temp.macosx-10.10-x86_64-3.6/_scandir.o
    xcrun: error: active developer path (""/Library/Developer/CommandLineTools"") does not exist
    Use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, or use `xcode-select --install` to install the standalone command line developer tools.
    See `man xcode-select` for more details.
    error: command 'clang' failed with exit status 1
    
    ----------------------------------------
Command ""/usr/local/opt/python/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/scandir/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-blixhswu-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /private/var/folders/xg/1dc_2ywj6052dcxm66j2jvcw0000gn/T/pip-build-r2ojh7_h/scandir/
__________________________________________________________________________________

When I try to run 'python3 faceswap.py -h'  anyways, I get ""ModuleNotFoundError: No module named 'face_recognition'"".

Would you have a workaround for any of this? Much appreciated!",thanks lot response link gave following first issue trying run install since get error instead ran install though eventually returned toward end building wheel running clean running error complete output command import open compile code running running build running package file found regular file running setup compiler identification unknown compiler identification unknown check working compiler check working compiler broken error message compiler able compile simple test program following output change run build command error active developer path exist use switch specify wish use command line developer use install install command line developer see man able correctly generate project call stack recent call first incomplete see also see also recent call last file string line module file line module development file line setup return file line setup file line file line file line run file line command file line file line run file line command file line file line run file line file line raise command returned exit status building wheel running clean build collected click running install error complete output command import open compile code install record compile running install running build running build running building extension clang error active developer path exist use switch specify wish use command line developer use install install command line developer see man error command exit status command import open compile code install record compile error code try run anyways get module would much,issue,negative,positive,neutral,neutral,positive,positive
372792562,"@ruah1984 

Clone the repo if you haven't yet; open a git bash terminal and run
``` git
$ git clone https://github.com/deepfakes/faceswap.git
$ cd faceswap
```

Checkout this PR's branch
``` git
$ git checkout -b oatssss/fix-convert-for-gan
```

Add the fork associated with the PR you want as a remote (JayantPythonLover's fork)
``` git
$ git remote add gh-JayantPythonLover https://github.com/JayantPythonLover/faceswap.git
$ git fetch gh-JayantPythonLover
```

Now also checkout JayantPythonLover's branch so you have it locally
``` git
$ git checkout -b JayantPythonLover/master gh-JayantPythonLover/master
```

Merge this PR's branch into your local copy of JayantPythonLover's branch
``` git
$ git merge oatssss/fix-convert-for-gan
```

Hopefully there aren't any merge conflicts cuz that's a whole other ordeal. It'll pop up an edit window so you can edit the merge commit's message. Just save the file as-is. How you save depends on the editor. Most likely it'll either be `vi` or `nano` that opens up. If you see at the bottom, labels for shortcut keys such as `^X` or `^G`, then it's nano and you can save by pressing `ctrl+x`, then `y`, then `enter`. Otherwise it's probably `vi` and you can save by pressing `esc` then `:`, `w`, `q`, and finally `enter`.

If it merges without any problems then you should have changes from both PRs.",clone yet open git bash terminal run git git clone branch git git add fork associated want remote fork git git remote add git fetch also branch locally git git merge branch local copy branch git git merge hopefully merge whole ordeal pop edit window edit merge commit message save file save editor likely either see bottom save pressing enter otherwise probably save pressing finally enter without,issue,positive,neutral,neutral,neutral,neutral,neutral
372791560,"@Kirin-kun I've added an option to keep the original files (-k, --keep) and improved the descriptions to be more verbose and to say the default values.

Can you take a look and tell me if it's clearer/better now?

I'll try working on improving the grouping now.",added option keep original keep verbose say default take look tell try working improving grouping,issue,positive,positive,positive,positive,positive,positive
372778295,"In general I've refactored the sort to match the code style and to be arranged symmetrically in terms of methods, with the original methods followed by are my folder methods.

@Kirin-kun It doesn't actually delete from the input dir, it moves the images to the grouped dirs.
This is because if I would need to move the images in the sorted directories into the aligned directory, I could write a short bash (shell) script that would do it for me, so I didn't see it as much of an issue.
However, I will add an option to keep the original files where they are. ^_^

I'll explain the thing with how it sorts when using face and hist, since it should help clear up the weird behavior (although I have no idea how to abbreviate this, so it seems that I'd have to write a man page for this :p ).
The way the original algorithm for 'face' and 'hist' works is by using a selection sort, which creates a smooth 'gradient' (like an increasing curve)  of differences between the images. To do this a score gets calculated comparing two images and the images are then sorted based on the score.
The way I group the images together is using the same score but instead checking it against the threshold value to decide if the image being checked should go into a given group (where each group has a reference image, which is the first image assigned to that group), and if no suitable group is found a new group is created.
If you're using the face method, images where no faces are detected are sorted out before being compared to the threshold.

Also while testing to get it to work I used 12 images, 4 of face A  and 4 of face B with both having tiny differences since they are sequential frames from a video, 3 images of a window/wall with rotations and effects, and 1 images of mountains. All scaled to 256x256px. So basically I haven't tested the threshold value enough to pick a good default.

I did just have a new idea how to better test whether an image belongs in a given group, although this may impact performance drastically.

I'll add the default values used to the cli options description and try to explain a bit better.

TL;DR:
I'will add the improvements you mentioned and try to improve the way it groups the images together.",general sort match code style symmetrically original folder actually delete input grouped would need move sorted directory could write short bash shell script would see much issue however add option keep original explain thing face hist since help clear weird behavior although idea abbreviate write man page way original algorithm work selection sort smooth like increasing curve score calculated two sorted based score way group together score instead threshold value decide image checked go given group group reference image first image assigned group suitable group found new group face method sorted threshold also testing get work used face face tiny since sequential video effect scaled basically tested threshold value enough pick good default new idea better test whether image given group although may impact performance drastically add default used description try explain bit better add try improve way together,issue,positive,positive,positive,positive,positive,positive
372766211,"@AbysmalBiscuit just did a quick test with simple args:

python sort.py -i h:\Fakes\data_A\aligned -o h:\Fakes\data_A\aligned\sorted -g folders -by face

And I just have a couple remarks: 

- Why delete from input dir? It defeats the purpose of later use of the aligned dir for merging, because you'd have to move back everything from the subfolders. The space saved by not duplicating isn't worth the trouble (disks are cheap!). I'd just need to remove unwanted faces and false positives. Maybe it could be optional.

- With just ""-by face"", I had in the same folder faces facing different directions (left, right, facing the camera) and sometimes I had a hard time differentiating why a face had landed in a different folder when it looks about the same :). I guess the problem is the threshold, because it's the face recognition library at work.

So, maybe an explanation of what values the thresholds can be for hist and blur respectively in the usage message.",quick test simple python face couple delete input purpose later use move back everything space saved worth trouble cheap need remove unwanted false maybe could optional face folder facing different left right facing camera sometimes hard time face landed different folder guess problem threshold face recognition library work maybe explanation hist blur respectively usage message,issue,negative,positive,neutral,neutral,positive,positive
372751198,"My work process is more or less the same as @Kirin-kun.

@iperov  I think there has been a misundurstanding about what each person needs the image sorting for. What I need it for is sorting the extracted 'faces', be it for training data or conversion data. If I'm not mistaken the people in this thread who want to be able to sort the faces into folders  are in the same use case as I am.

Here's a more detailed example to demonstrate my use case:
Let's say I extract 2000 'faces' (this includes false positives) from a 5 min video, the renaming approach wouldn't help me much since I'd still have to scroll through everything looking for when the groups change/unwanted images appear.
However,  if you sort the images into folders, and if the threshold used to determine similarity is discriminating enough, you will have folders that you can delete (if it's a folder of non-faces), or just pick a few images out of to get the lighting conditions/face angle/other criteria that you're looking for.

@Kirin-kun I have updated my gist to have the latest functionality from the repo, with the addition of my folder sorting:
https://gist.github.com/AbysmalBiscuit/03f34da39a6cf96d84312d9d309d9c8d 
Could you try downloading and testing it to see how it works for you?
The 'face' method also uses the threshold parameter. With the face method, folder 0 is always the non-face folder. Also it may not display a progress bar for everything if you're grouping into folders.
Also backup your data before you test it just in case. :p
",work process le think person need image need extracted training data conversion data mistaken people thread want able sort use case detailed example demonstrate use case let say extract false min video approach would help much since still scroll everything looking appear however sort threshold used determine similarity discriminating enough delete folder pick get lighting criterion looking gist latest functionality addition folder could try testing see work method also threshold parameter face method folder always folder also may display progress bar everything grouping also backup data test case,issue,positive,positive,positive,positive,positive,positive
372722464,"> Except that, by renaming the files, it defeats the functionality that allowed to not merge the faces deleted from the aligned directory, but present in the alignments file.

I dont use sorttool for dest data. Only for source data, where alignments absolutely unused.
",except functionality merge directory present file dont use data source data absolutely unused,issue,negative,positive,neutral,neutral,positive,positive
372709660,"The usual process, at least for me, is usually the following:

1 - Have neat B facesets ready. Sorted, various poses, etc...
2 - Extract all frames from target video
3 - Extract all the faces from all frames, in order to have an aligments.json ready
4 - Prune from the extracted faces the ""false positives"" (wasn't a face, wasn't the desired face, was a too small face...)
5 - Start training with all the remaining faces in A, because sorting them and creating manually a good training set is a PITA.
6 - Once the loss and preview look ok, merge a small framerange to see how it looks
7 - ????
8 - Profit

Now, point 5 is what @iperov attempted to address with his tool, which is a huge improvement, because the trainer wastes a lot of time learning very similar faces. I think that's one of the problems the IAE model has too. The GAN model seems to be affected also.

Except that, by renaming the files, it defeats the functionality that allowed to not merge the faces deleted from the aligned directory, but present in the alignments file. 

So, putting similar faces in different folders would allow to quickly build a set for training by choosing various poses/faces, while allowing to build also an aligned directory ready for conversion (just have to prune the false positives and wrong faces).",usual process least usually following neat ready sorted various extract target video extract order ready prune extracted false face desired face small face start training manually good training set pita loss preview look merge small see profit point address tool huge improvement trainer lot time learning similar think one model gan model affected also except functionality merge directory present file similar different would allow quickly build set training choosing various build also directory ready conversion prune false wrong,issue,positive,negative,neutral,neutral,negative,negative
372707333,"@iperov 

> you using bad test data.
> Use video with high amount of faces and high angles near 90 deg.

You cannot possibly know this,

I apologise for putting this here, but there is no appropriate place on github.

You cannot go around attacking everyone who wants to make any amendments to your code. What has been suggested here is entirely reasonable and is worthy of further investigation. It is neither an attack on you nor the excellent code that you have implemented. 

Downvoting and throwing tantrums whenever anyone wants to make changes only serves to discourage and drive people away from the project. Most people who work on projects like these are amateurs and are looking to improve themselves as well as the code base. No one comes here with the intention of making things worse. If you do not agree with a change, the onus is on you to articulate why rather than ranting at the contributor. Ideally then both parties walk away having learned something.

The nature of open source is that changes will be proposed, some will be accepted, some will be rejected, you will agree with some changes, you will disagree with others. Some of these changes will affect code that you have worked on. However, this is not your code. It is the project's code and it belongs to anyone and everyone who wants to work on or fork the project. This happened as soon as you submitted code to the project.

If this isn't agreeable to you, then maybe open source is not for you? Or perhaps you could create your own fork of the project where you have more control over what is or isn't accepted. Alternatively you can understand that anyone who submits code wants to improve the project. They won't always succeed, but everyone will appreciate feedback given in a constructive manner. I would ask that you try to take a more measured approach in future.

Back on topic, I plan to perform a sizeable amount of extractions today, so I will run with and without this PR and report back my findings.
",bad test data use video high amount high near deg possibly know appropriate place go around everyone make code entirely reasonable worthy investigation neither attack excellent code throwing whenever anyone make discourage drive people away project people work like looking improve well code base one come intention making worse agree change onus articulate rather ranting contributor ideally walk away learned something nature open source accepted agree disagree affect code worked however code project code anyone everyone work fork project soon code project agreeable maybe open source perhaps could create fork project control accepted alternatively understand anyone code improve project wo always succeed everyone appreciate feedback given constructive manner would ask try take measured approach future back topic plan perform sizeable amount today run without report back,issue,positive,positive,neutral,neutral,positive,positive
372693692,"The main advantages as I see it are:
1) It's more convenient in terms of having clear separations between how the images are grouped together. Especially when working with very large datasets like when you extract faces from several minutes of video.

2) It would also allow you to preserve the original filenames which would make it possible to use them for the aligned folder when converting.

3) It would also make it easier to delete the images that you don't want (since you can look inside the folder and see right away if it's not the face/angle/bluriness you want), which was something people in the thread were asking for.",main see convenient clear grouped together especially working large like extract several would also allow preserve original would make possible use folder would also make easier delete want since look inside folder see right away want something people thread,issue,positive,positive,positive,positive,positive,positive
372691816,also cannot understand why need work with additional folders,also understand need work additional,issue,negative,neutral,neutral,neutral,neutral,neutral
372691208,Thanks. yeah already got it working but this should be fix,thanks yeah already got working fix,issue,positive,positive,positive,positive,positive,positive
372688752,"@AbysmalBiscuit already told you , your version is outdated.",already told version outdated,issue,negative,negative,negative,negative,negative,negative
372688242,"Hi,

I've  extended the sorttool to now be able to sort images  into folders, both by  blur and similarity. It uses the same similarity and blur sorting  approaches as the the current version. I have also added the option of specifying  an output directory that defaults to the input directory if none is  given (which preserves the original functionality of the renaming  approach). 

The folder grouping by similarity takes an optional float 'minimum  score threshold' parameter, which acts as the minimum similarity score  for an image to be considered part of the group (right now the default  is 0.5, but I haven't tested it extensively). 

The folder grouping by blur takes an optional integer 'bins' to sort the images based on how blurry they are into bins.  If the number of images doesn't fit equally among the bins, the exess get added to the last folder (which is the bluriest).

@kcimit and @i5L4NDOF5T4BiLiTY  when sorted into folders you could just delete the unecessary folder(s). 

Here is a gist :
https://gist.github.com/AbysmalBiscuit/03f34da39a6cf96d84312d9d309d9c8d

If it's good enough, can I receive a pull request? 
(note: the code styling is for PEP8 and not the repo styling, I will reformat it to match the repo style)",hi extended able sort blur similarity similarity blur current version also added option output directory input directory none given original functionality approach folder grouping similarity optional float score threshold parameter minimum similarity score image considered part group right default tested extensively folder grouping blur optional integer sort based blurry number fit equally among get added last folder sorted could delete folder gist good enough receive pull request note code styling pep styling match style,issue,positive,positive,positive,positive,positive,positive
372661427,"Also, I'm not sure why it appears in blotches. That it would show on the edges of the merged face would be understandable, but why does it appear between the eyes or on the cheeks? And as blotches.",also sure would show face would understandable appear,issue,negative,positive,positive,positive,positive,positive
372652506,"Doing a comparison to 1adrianb and his face_alignment script https://github.com/1adrianb/face-alignment/blob/master/face_alignment/api.py which @iperov ported to Keras ( see 1adrianb code below )

```
def get_landmarks(self, input_image, all_faces=False):
        if isinstance(input_image, str):
            try:
                image = io.imread(input_image)
            except IOError:
                print(""error opening file :: "", input_image)
                return None
        else:
            image = input_image

        detected_faces = self.detect_faces(image)
```
Later on the same image is passed to the get_predictions function (i.e. landmarks )

He uses scimage (io.imread) to do the imread of the images. The scimage documentation states that it loads images as RGB format unlike the cv2.imread which loads in BGR format.  If we don't invert the channels before sending the resulting image to the face detector and the landmark predictor, this is an implementation change from 1adrianb. I can evaluate the differences in accuracy if we deviate from that implementation as we currently do, but ....

@iperov Was it your intention to change this when you ported his code or just an issue due to the cv2.imread and io.imread difference?

",comparison script ported see code self try image except print error opening file return none else image image later image function documentation format unlike format invert sending resulting image face detector landmark predictor implementation change evaluate accuracy deviate implementation currently intention change ported code issue due difference,issue,negative,negative,neutral,neutral,negative,negative
372632515,"Well, the main advantage of faceswap is that it does a lot of the job automatically. 

There are Photoshop tutorials out there that help to face swap ""realistically"" but it's a bit time consuming and most people won't take the time to do that (especially for video)

But I guess you could add a few lines in there to load ""new_image"" if it exists in a preset directory under a preset name.",well main advantage lot job automatically help face swap realistically bit time consuming people wo take time especially video guess could add load preset directory preset name,issue,positive,positive,neutral,neutral,positive,positive
372627311,"It seems the LowMem model hasn't been ported to the plugin infrastructure. But if you look at the code, the differences between LowMem and Original are very few. 

The ENCODER_DIM (aka nodes) variable is lowered to 512 and there's a commented line 
`x = self.conv(1024)(x)`

Really, that's about all. 

Create a new subdirectory in plugins, called ""Model_LOWMEM"", copy everything from Original in it and change the few lines. The faceswap script will detect this ""new"" trainer automatically.",model ported infrastructure look code original aka variable line really create new copy everything original change script detect new trainer automatically,issue,positive,positive,positive,positive,positive,positive
372624051,"I think you should create a directory somewhere and redo a clone of https://github.com/deepfakes/faceswap.git just to be safe.

Your repo seems to be mixed up with Davis King dlib's python examples or something.

https://github.com/davisking/dlib/blob/master/python_examples/face_recognition.py",think create directory somewhere redo clone safe mixed king python something,issue,positive,positive,positive,positive,positive,positive
372584255,"@3xtr3m3d Thanks a lot for the quick response! I just tried those. But unfortunately, all 3 of those still return the same message as I mentioned above:
""
Call this program like this:
   ./face_recognition.py shape_predictor_5_face_landmarks.dat dlib_face_recognition_resnet_model_v1.dat ../examples/faces
You can download a trained facial shape predictor and recognition model from:
    http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2
    http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2
""
Would you have any other ideas?
",thanks lot quick response tried unfortunately still return message call program like trained facial shape predictor recognition model would,issue,negative,positive,neutral,neutral,positive,positive
372582131,"@oatssss , can you teach me how to merge it both. locally merge it in my own desktop ?  ",teach merge locally merge,issue,negative,neutral,neutral,neutral,neutral,neutral
372576092,"use help as this

`python3 faceswap.py extract -h`
`python3 faceswap.py train -h`
`python3 faceswap.py convert -h`
",use help python extract python train python convert,issue,negative,neutral,neutral,neutral,neutral,neutral
372575312,@deepfakesclub yeah it would be useful. For example there is a technique I want to try -superResize. For that I need those converted faces beforehand,yeah would useful example technique want try need converted beforehand,issue,positive,positive,positive,positive,positive,positive
372567353,"Doing a diff/compare on the alignment .json files shows ~200k differences for the test example I used (985 faces) Looks like mostly single digit shifts ( i.e. 146 -> 147 or 92-> 91 ) in landmarks but there are also notable shifts in the bounding boxes for some faces. Interesting... I'll need to compare accuracy and try to read a copy of the gated Fan et al. paper, but most of the other academic papers use RGB as input to train their alignment models...",alignment test example used like mostly single digit also notable bounding interesting need compare accuracy try read copy gated fan al paper academic use input train alignment,issue,positive,positive,positive,positive,positive,positive
372561905,"Something that has been mentioned elsewhere - would it make sense to write the converted faces into files before merging, and then merge back into the original images in a separate step?

Other image and video editing packages are much better suited to doing custom modifications, or even handling the merging itself, rather than jury-rigging random image editing functions into faceswap itself. Once you move beyond basic merging, it feels like re-inventing a less polished wheel.",something elsewhere would make sense write converted merge back original separate step image video much better custom even handling rather random image move beyond basic like le polished wheel,issue,positive,positive,neutral,neutral,positive,positive
372561714,"My test data was with video with 90 degree faces.  I've now tested over
6000 images extracted with almost identical results.  BGR had one more
false positive than the RGB only where a blue-green curtain got recorded as
a face.

RGB only was consistently (slightly) faster.

I think this PR is proving that if for nothing else, it makes the code
clearer and a tiny bit faster (~10%).

On Mar 12, 2018 22:37, ""iperov"" <notifications@github.com> wrote:

> you using bad test data.
> Use video with high amount of faces and high angles near 90 deg.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/281#issuecomment-372552815>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ADEuwUGnF8aKZwolaPJ0hUOghF6lz0M4ks5td1swgaJpZM4SmKwH>
> .
>
",test data video degree tested extracted almost identical one false positive curtain got face consistently slightly faster think proving nothing else code clearer tiny bit faster mar wrote bad test data use video high amount high near deg reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
372555102,"@ruah1984 you can merge your clones of each branch locally, I can give you further instructions on how to do that if you need.",merge branch locally give need,issue,negative,neutral,neutral,neutral,neutral,neutral
372552815,"you using bad test data.
Use video with high amount of faces and high angles near 90 deg.",bad test data use video high amount high near deg,issue,negative,negative,neutral,neutral,negative,negative
372551146,"@oatssss , can you merge with this as well??
https://github.com/deepfakes/faceswap/pull/285

just start training some samples for GAN yesterday night, i can try to use both PR convert tonight.
",merge well start training gan yesterday night try use convert tonight,issue,negative,neutral,neutral,neutral,neutral,neutral
372550984,"Added another example with a different output video and a freshly trained model.

Also added comparison footages of No Sharpen and the two sharpen methods so you can see what can be achieved.",added another example different output video freshly trained model also added comparison sharpen two sharpen see,issue,negative,positive,positive,positive,positive,positive
372543254,"Testing with the 1,000 images found in https://github.com/deepfakes/faceswap/issues/233

Current Master Code:
py faceswap.py extract -i E:\shots\testing -o E:\shots\testing\faces_master -D cnn
1.  985 faces found in 1,000 frames   3:52 time --- 4.31 it/s
2.  985 faces found in 1,000 frames   3:53 time --- 4.29 it/s

Proposed PR Code:
py faceswap.py extract -i E:\shots\testing -o E:\shots\testing\faces_PR -D cnn
1.  985 faces found in 1,000 frames   3:33 time --- 4.68 it/s
2.  985 faces found in 1,000 frames   3:36 time --- 4.61 it/s

No difference in faces. Slight speed increase",testing found current master code extract found time found time code extract found time found time difference slight speed increase,issue,negative,negative,neutral,neutral,negative,negative
372540059,"@bryanlyon Thanks for pointing out the problem of iae. I will try to improve it 😄 

@DLSauron Could you share your dataset somehow? I myself didn't train iae with such many faces so sorry for it performs bad 😭 ",thanks pointing problem try improve could share somehow train many sorry bad,issue,negative,negative,negative,negative,negative,negative
372505171,"I was able to get that installed now getting a syntax error

Traceback (most recent call last):
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\train.py"", line 147, in processThread
    model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\PluginLoader.py"", line 14, in get_model
    return PluginLoader._import(""Model"", ""Model_{0}"".format(name))
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\PluginLoader.py"", line 23, in _import
    module = __import__(name, globals(), locals(), [], 1)
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\__init__.py"", line 7, in <module>
    from .Trainer import Trainer
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\Trainer.py"", line 95
    def show_warped(self, warped_A, warped_B)
                                             ^
SyntaxError: invalid syntax",able get getting syntax error recent call last file line file line run file line model trainer file line return model name file line module name file line module import trainer file line self invalid syntax,issue,negative,positive,positive,positive,positive,positive
372500047,"Ah you have to install keras_contrib, it is a new dependency ",ah install new dependency,issue,negative,positive,positive,positive,positive,positive
372492108,"@Apollo122 The examples shown above are with Seamless Clone and Match Histogram.

I always use those options so I made sure that this works without issues with both of those options enabled.",shown seamless clone match histogram always use made sure work without,issue,negative,positive,positive,positive,positive,positive
372491380,"Getting the below error then trying to train

Traceback (most recent call last):
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\users\DLSauron\appdata\local\programs\python\python36\Lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\DLSauron\source\repos\faceswap\scripts\train.py"", line 147, in processThread
    model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\PluginLoader.py"", line 14, in get_model
    return PluginLoader._import(""Model"", ""Model_{0}"".format(name))
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\PluginLoader.py"", line 23, in _import
    module = __import__(name, globals(), locals(), [], 1)
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\__init__.py"", line 6, in <module>
    from .Model import Model
  File ""C:\Users\DLSauron\source\repos\faceswap\plugins\Model_DFaker\Model.py"", line 13, in <module>
    from keras_contrib.losses import DSSIMObjective
ModuleNotFoundError: No module named 'keras_contrib'",getting error trying train recent call last file line file line run file line model trainer file line return model name file line module name file line module import model file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
372488071,"Thanks for the PR @JayantPythonLover . Could you add more output pictures? How does it look with other options enabled such as seamless clone, histogram match?",thanks could add output look seamless clone histogram match,issue,negative,positive,positive,positive,positive,positive
372480344,"I support this PR.  This is a well developed change and clearly demonstrated, while I don't need it myself, I can see definite benefits for others.  I appreciate that you made it an option and built in the context of the architecture.",support well change clearly need see definite appreciate made option built context architecture,issue,positive,positive,neutral,neutral,positive,positive
372468676,"How to sort them? Is there any skills to sort the images?When I extracted the faces, I found it hard to distinguish the faces of other person's from the ones which I want to extract.",sort sort extracted found hard distinguish person want extract,issue,negative,negative,negative,negative,negative,negative
372464657,I wonder if we can use the mask from GAN for color matching too. Since it's designed to help find these obstructions and minimize the facial changes.,wonder use mask gan color matching since designed help find minimize facial,issue,negative,neutral,neutral,neutral,neutral,neutral
372463987,"@oatssss it would probably be also useful with other kind of obstacles, like hair in front of eyes, hats covering eyebrows, scarves, in order to avoid for their color to spill on the color correction.

In @iperov 's case, it's the background that interferes with the histogram matching.",would probably also useful kind like hair front covering order avoid color spill color correction case background histogram matching,issue,positive,positive,positive,positive,positive,positive
372461769,"Maybe use `dlib.DLIB_USE_CUDA` to detect dlib using GPU and invalidate `-j` option. (I said ""maybe"" because I'm not sure of it but this could be a quick patch)",maybe use detect invalidate option said maybe sure could quick patch,issue,negative,positive,positive,positive,positive,positive
372460920,"Okay, I investigated the problem.  Here is the basic cause: when you use -j it actually just starts multiple copies of the extract script.  The extract scripts then ALL try to use the GPU.  But any one extract script uses all the ram on the GPU.  This makes all the others throw exceptions that they are out of memory.  Even if they don't throw the OOM exception, they can't use the GPU and fail, creating the black box problem.

This means that -j necessarily needs to be limited to CPU only.  Doing it from a environment variable is not the best way.  I'll work on this and create a patch that runs on the CPU only when -j is invoked.  That said, GPU will be MUCH faster than CPU only, especially if you're using CNN.  This is not yet multi gpu capable, but even a single GPU is significantly faster than a CPU (and an order of magnitude better an any NN based solutions).

So for now: don't use -j if you have GPUs it wont be faster than the GPU anyway.  If you do want to use -j on a GPU system, wait for the patch.  If you have a CPU only system, you can use -j but you will need to ensure you don't install CUDA or your dlib will try to access a nonexistant GPU (if you .already installed CUDA on a GPU less system, uninstall it then uninstall/reinstall dlib through pip to get a version compiled for your current layout).",problem basic cause use actually multiple extract script extract try use one extract script ram throw memory even throw exception ca use fail black box problem necessarily need limited environment variable best way work create patch said much faster especially yet capable even single significantly faster order magnitude better based use wont faster anyway want use system wait patch system use need ensure install try access le system pip get version current layout,issue,positive,positive,positive,positive,positive,positive
372456476,"I've added some logic to test if tensorflow has GPUs available in the extract script. If the user uses the -j argument and GPU are visible for TF, the program exits with a warning stating there's a way to force TF to use CPU only by using the CUDA_VISIBLE_DEVICES=-1 environment variable.

Disable GPU with environment variable:
https://github.com/tensorflow/tensorflow/issues/2175

Link to the commit on my fork:
[https://github.com/ppmdo/faceswap/commit/eb928c24212deed620ba0326387055a7631543a0](https://github.com/ppmdo/faceswap/commit/eb928c24212deed620ba0326387055a7631543a0)


I don't know if disabling CUDA for TF by exporting the environment variable within any of the scripts is worth looking at. That could allow the user to disable GPU processing within faceswap.py:

https://stackoverflow.com/questions/37893755/tensorflow-set-cuda-visible-devices-within-jupyter
",added logic test available extract script user argument visible program warning way force use environment variable disable environment variable link commit fork know environment variable within worth looking could allow user disable within,issue,negative,positive,positive,positive,positive,positive
372455710,"You're running the correct TensorFlow for Cuda 8 and Python 3.5.

What is your 
python3 -V

Did you install Cuda 8? 

I recommend you install all cudnn versions for Cuda 8 (they can exist independently).  All in your Cuda 8 folder.
cudnn-8.0-linux-x64-v5.1.tgz  cudnn-8.0-linux-x64-v6.0.tgz  cudnn-8.0-linux-x64-v7.1.tgz

I also recommend removing tensorflow 1.4.1 which you have installed, if you're not using it for anything else.

Also try using pip as a module

python3 -m pip -r requirements-gpu-python35-cuda8.txt",running correct python python install recommend install exist independently folder also recommend removing anything else also try pip module python pip,issue,positive,neutral,neutral,neutral,neutral,neutral
372453249,I can confirm that it works without CUDA on the dlib.  I use this myself on a server for most of my extraction tasks.,confirm work without use server extraction,issue,negative,neutral,neutral,neutral,neutral,neutral
372452865,it is something like `pip list` or `pip freeze` (or pip3 if you are using python3),something like pip list pip freeze pip python,issue,negative,neutral,neutral,neutral,neutral,neutral
372452324,"I know I installed the requirements.txt file for cuda8 in the beginning. But is there any way to verify it?

https://gist.github.com/Crypt1cBunny/f8599bb89df960d45b324d9f7beb6966",know file beginning way verify,issue,negative,neutral,neutral,neutral,neutral,neutral
372450161,"Did you install from the correct requirements.txt files?

Each version of Python and Cuda needs the matching file.

For Python 3.5 and Cuda 8 it is as follows:
requirements-gpu-python35-cuda8.txt
pathlib==1.0.1
scandir==1.6
h5py==2.7.1
Keras==2.1.2
opencv-python==3.3.0.10
tensorflow-gpu==1.4.0
scikit-image
dlib
face_recognition
tqdm

For Python 3.6 and Cuda 9 it is as follows:
requirements-gpu-python36-cuda9.txt
pathlib==1.0.1
scandir==1.6
h5py==2.7.1
Keras==2.1.2
opencv-python==3.3.0.10
tensorflow-gpu==1.5.0
scikit-image
dlib
face_recognition
tqdm

This might be the source of your problem, because if you are using different versions that haven't been tested, it might be loading the wrong libraries.",install correct version python need matching file python python might source problem different tested might loading wrong,issue,negative,negative,negative,negative,negative,negative
372448442,"After further inspection, I think this issue is related to Tensorflow using CUDA instead of Dlib. I have just tested the -j flag in an environment with Tensorflow compitled with CUDA and Dlib without it, and it works. It just crashes on with Out of Memory error. ",inspection think issue related instead tested flag environment without work memory error,issue,negative,neutral,neutral,neutral,neutral,neutral
372447450,"@Clorr Thanks for your clarification on the abstraction layer. I think the issue about the modifications being worthy is not up to me; I mean, I can do the coding for the json-db part, but if the benefits I see, are not beneficial for the rest of the users I think we could call this a dead end. ",thanks clarification abstraction layer think issue worthy mean part see beneficial rest think could call dead end,issue,positive,positive,neutral,neutral,positive,positive
372442591,"i think your intention is good. The thing is just that I don't want to rely on a db, that's why i prefer we can have the choice of JSON(default) or DB.

Also, what you did in db.py is not really an abstraction layer, it is just an interface (which is nice already). An abstraction layer is like a plugin architecture, it let's you switch between implementation classes seamlessly. We can do that already with your proposal, but we would still end up with some self.conn around and db related code outside db.py

Also, there are some lines that are not related to DB in your PR, like what resides in face_detect.py. This should be avoided because we can end up with big mess without knowing, if you think your modifications are worth it, you can do a separate PR",think intention good thing want rely prefer choice default also really abstraction layer interface nice already abstraction layer like architecture let switch implementation class seamlessly already proposal would still end around related code outside also related like end big mess without knowing think worth separate,issue,positive,positive,positive,positive,positive,positive
372442561,"Yes, however, before #233 we were using BGR only, which is not what CNN or HOG were designed for.  @iperov's change, to use RGB and BGR was helpful.  This PR is just saying that using RGB may have been all that was necessary and that using both RGB and BGR is unnecessary.

Here is an initial test of my own test data.

The command I ran is:
python3 faceswap.py extract -i content/ -o Testdata/bgr/ -j 20
and 
python3 faceswap.py extract -i content/ -o Testdata/nobgr/ -j 20

```
Without patch:
3271/3271 [21:11<00:00,  2.57it/s]
-------------------------
Images found:        3271
Faces detected:      3271
-------------------------
ls Testdata/bgr/ | wc
    965     965   26055
With patch:
100%| 3271/3271 [18:42<00:00,  2.91it/s]
-------------------------
Images found:        3271
Faces detected:      3271
-------------------------
ls Testdata/nobgr/ | wc
    965     965   26055

```
The detection was EXACTLY the same.  The exact same number of faces were found and each face was identical.  The folders were identical.  The only difference was in execution time. 21:11 without the patch and 18:42 with the patch.

Obviously, this is not complete.  I didn't test CNN (I don't have GPUs available right now) or a comprehensive set of data (literally impossible), but these results tell me that this PR has some merit, at least for further testing.  But I think it's likely that just using RGB instead of RGB and BGR makes sense.

Note also that there is currently a bug that says every image has exactly 1 detected face so I actually checked the folder itself.",yes however hog designed change use helpful saying may necessary unnecessary initial test test data command ran python extract python extract without patch found patch found detection exactly exact number found face identical identical difference execution time without patch patch obviously complete test available right comprehensive set data literally impossible tell merit least testing think likely instead sense note also currently bug every image exactly face actually checked folder,issue,positive,negative,neutral,neutral,negative,negative
372436801,"The weird part is that TensorFlow shows that only one GPU is found in the log you posted above, yet when run separately it's showing all the GPUs.

I'm checking this out to see what other troubleshooting or logs might help, but this seems to be caused outside of faceswap.

Can you try running again with first setting CUDA_VISIBLE_DEVICES=""0,1,2,3,4,5"" and see if that helps?",weird part one found log posted yet run separately showing see might help outside try running first setting see,issue,negative,negative,neutral,neutral,negative,negative
372436139,"Add a fix, and your name will live in an eternal glory as contributor to this repo ;-)",add fix name live eternal glory contributor,issue,positive,positive,positive,positive,positive,positive
372435482,"This PR adresses details that are beyond my understanding. What I can see here is that the proposed code is somewhat clean and should be respected. My thinking is:
- If this messes up things completely this should be seen and the PR won't be merged.
- If it highly improves things, this should also be seen and this could be merged.
- If the difference is very low, it does not deserves so much hard discussion, and we can talk about this calmly.

Also, @iperov, you should consider that if you say things that are too strong, it will deserve your credibility (although I'm sure you know what you are saying as this was discussed in #233 and it generated the #236 PR). So I'm sure this can be talked about calmly and with proper arguments... 

At some point #233 offers an interesting test case. As @iperov  showed that his modification have improved things, we should at least test that this PR does not bring regression on that test case. ",beyond understanding see code somewhat clean thinking completely seen wo highly also seen could difference low much hard discussion talk calmly also consider say strong deserve credibility although sure know saying sure calmly proper point interesting test case modification least test bring regression test case,issue,positive,positive,positive,positive,positive,positive
372433503,"I'd suggest merging now, this is bug fixing and doesn't do any feature adds.  (except for GAN128, which just brings it to parity with GAN).",suggest bug fixing feature except gan parity gan,issue,negative,neutral,neutral,neutral,neutral,neutral
372431721,There is a problem where dlib runs out of memory really easily. So I'm not sure but batch processing could run into that? Keep in mind that the project is supposed to be usable with people with lower end cards.,problem memory really easily sure batch could run keep mind project supposed usable people lower end,issue,negative,positive,positive,positive,positive,positive
372430719,"I am doing testing as well.  Testing on one person's system is helpful, but less so than running it on multiple sets and on multiple platforms.

Obviously @iperov is and @babilio are right, this needs to show improvement to be accepted, but a PR like this is the best way to show a wider audience that it is available and get that test data.

I would also like to work with you on the extract.  My focus is on multi-gpu support and right now, the extract chain is the hardest part to add that support to.  (except for CNN only, which I could add relatively easily, but it'd take me touching a half dozen files to get working in the same way as train/convert).",testing well testing one person system helpful le running multiple multiple obviously right need show improvement accepted like best way show audience available get test data would also like work extract focus support right extract chain part add support except could add relatively easily take touching half dozen get working way,issue,positive,positive,positive,positive,positive,positive
372429294,"@iperov You can be a bit more cordial, rather than just saying I suxx. I understand that I'm new to this and that you're passionate but I have the same goal as you ....

I am testing this further by the way. I posted this PR now at this stage for comment and review ( like I thought I was supposed to ? ) I don't understand why you're yelling to close this item when I've tried to logically explain why the code likely doesn't need some extra lines of code and extra calls to the detector to get the same performance/found faces. Sorry if I offended you by editing your implementation but I thought this was the whole point of open source code...?  

Btw, this was just an intermediate step on my way to vectorizing the whole extract chain as the dlib detector can take vectors of images as inputs and can process them as batches...",bit cordial rather saying understand new passionate goal testing way posted stage comment review like thought supposed understand yelling close item tried logically explain code likely need extra code extra detector get sorry offended implementation thought whole point open source code intermediate step way whole extract chain detector take process,issue,positive,positive,neutral,neutral,positive,positive
372427221,"Ok, that's fine for me. Do I merge now, or do you wait for feedback?",fine merge wait feedback,issue,negative,positive,positive,positive,positive,positive
372427145,"Yes for this type of changes there should be testing and proof. Ideally from person doing the PR. Specially cause @iperov wrote the original code and is opposing it. The level of detection is really good right now, so he shouldn't need to produce papers about BGR implementation. The new changes should show improvements and drawbacks clearly if any. This is clearly discouraging @iperov from all the work he did porting from pytorch, if there are clear benefits lets show'em and go for it but otherwise...

When it is a plugin that's optional and does it's own thing that is fine but when it's core code we can't just go off of theory.

There is a reason why that was put there and there is actual positive results that came from the changes #233 ",yes type testing proof ideally person specially cause wrote original code opposing level detection really good right need produce implementation new show clearly clearly discouraging work clear go otherwise optional thing fine core code ca go theory reason put actual positive came,issue,positive,positive,positive,positive,positive,positive
372426049,"Hi. I get the point of the DB overkill. In fact, @Clorr I've already included an abstraction layer in lib/db.py. I wouldn't expect the user to type or use SQL directly, so there are several write/read functions in that file to ease those tasks.

Anyway, I think the benefits of storing the status and results of the extract and convert scripts are worthy. So, If the idea is to stick to JSON, I can refactor the code to do that. What do you think?

To get a clear idea of what I'm intending by storing this data (in JSON or DB), this is what the data looks like after running Extract.py:

id     |     filename         |      extracted |  face_found | converted 
1      |     output_0767.jpg | true   |     true   |     false     
2      |    output_0710.jpg | true    |    true    |    false     
3      |    output_0028.jpg | true    |    false   |    false     
4      |     output_0002.jpg | true   |     false  |     false     
5      |     output_0713.jpg | true   |     true   |     false     
6      |     output_0701.jpg | true   |     true   |     false     
7      |     output_0026.jpg | true   |     false  |     false     
8      |     output_0020.jpg | true   |     false  |     false     
9      |     output_0008.jpg | true   |     false  |     false     
10    |     output_0715.jpg | true   |     true   |     false   

This allows, for example, to know:

1. Which frames failed to be extracted.
2. Which frames have a face. Which afterwards allows to run the convert script **only** in these frames.
3. Which frames have already been extracted or converted. Which allows to run the scripts **only** on the pending ones.

These increases the efficiency of the scripts by avoiding reprocessing of already extracted/converted frames; and by focusing on converting only those frames in which the extractor found a face.
",hi get point fact already included abstraction layer would expect user type use directly several file ease anyway think status extract convert worthy idea stick code think get clear idea intending data data like running id extracted converted true true false true true false true false false true false false true true false true true false true false false true false false true false false true true false example know extracted face afterwards run convert script already extracted converted run pending efficiency already converting extractor found face,issue,positive,negative,neutral,neutral,negative,negative
372425755,"Training is now working!

However, it is still highly beta, and also it uses a specific version of extract+alignments.json so you have to rerun extract to try...",training working however still highly beta also specific version rerun extract try,issue,negative,positive,neutral,neutral,positive,positive
372424118,I had an error thrown for me if i use the -mh flag after the -m flag when i convert.  Can't find model etc or something...  It worked if I put the -mh flag before the -m flag in the command line though. Might be useful to change the flag name to something more unique ( -MH ? ) or do you know why that would have happened for me?,error thrown use flag flag convert ca find model something worked put flag flag command line though might useful change flag name something unique know would,issue,negative,positive,positive,positive,positive,positive
372422344,"> /usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
>   from ._conv import register_converters as _register_converters
> Using TensorFlow backend.
> Model A Directory: /home/riggy/fakes/output/putin
> Model B Directory: /home/riggy/fakes/output/trump
> Training data directory: /home/riggy/fakes/models
> 2018-03-12 19:47:50.885142: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
> 2018-03-12 19:47:51.321063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2018-03-12 19:47:51.321929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
> name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.607
> pciBusID: 0000:01:00.0
> totalMemory: 10.91GiB freeMemory: 10.75GiB
> 2018-03-12 19:47:51.321949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
> Loading data, this may take a while...
> Loading Model from Model_Original plugin...
> To call `multi_gpu_model` with `gpus=6`, we expect the following devices to be available: ['/cpu:0', '/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3', '/device:GPU:4', '/device:GPU:5']. However this machine only has: ['/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0']. Try reducing `gpus`.

This is the output with the latest version of keras (master, did a checkout hour ago).",conversion second argument float future float import model directory model directory training data directory binary use successful node read negative value must least one node node zero found device name ti major minor device device name ti bus id compute capability loading data may take loading model call expect following available however machine try reducing output latest version master hour ago,issue,negative,positive,positive,positive,positive,positive
372421178,"> I would like to see tests that show this actually works as expected and doesn't lower results before we merge

agree. I already wrote: 100% PROOFS AND LONG TESTS WITH VARIOUS CONDITIONS

> sending the BGR might not do well

disagree. Sending BGR and RGB detect more faces.
https://www.deepfakes.club/best-hardware-software-deepfakes/ https://www.reddit.com/r/SFWdeepfakes/comments/82btao/portable_python_installs_of_faceswap_and_dfaker/dv94je7/
because there is only one thing in FaceSwap make difference from FakeApp is rgb-bgr scan.

Also FaceSwap extract performance better than FakeApp, thx for my pytorch port. Nobody need more performance.
Why we spending our time and energy to discuss this suxx ?

@Clorr please close it
",would like see show actually work lower merge agree already wrote long various sending might well disagree sending detect one thing make difference scan also extract performance better port nobody need performance spending time energy discus please close,issue,positive,positive,positive,positive,positive,positive
372420602,"This is strange, because it works for me in Windows and Ubuntu.

I don't think that this is a keras bug, since it's actually calling the backend (tensorflow) directly.  In fact, the bug that you submitted showed all the video cards detected, but not working due to showing a different name.  In your case, faceswap is not detecting additional video cards at all.

Can you post a log of the whole startup of faceswap through to the error?  That may help me discover what is happening.",strange work think bug since actually calling directly fact bug video working due showing different name case additional video post log whole error may help discover happening,issue,negative,positive,neutral,neutral,positive,positive
372419525,"Dfaker's full-face conversion is really great but I cant get rid of the mask outside the face and sometimes mask ends just above the chin. A side note, I used histogram match while merging and quality increased dramatically. Note that histogram match here is not perfect, there is already a issue post about that. But I recommend you try it.",conversion really great cant get rid mask outside face sometimes mask chin side note used histogram match quality dramatically note histogram match perfect already issue post recommend try,issue,positive,positive,positive,positive,positive,positive
372416684,"Looks like there is a bug in keras.

https://github.com/keras-team/keras/issues/8213

I can see someone forked and fixed it, however looks like it isn't in the latest version. I tried to edit the local files with this patch (dirty), but couldn't get it working yet.

Python is all new to me :-)",like bug see someone forked fixed however like latest version tried edit local patch dirty could get working yet python new,issue,negative,positive,neutral,neutral,positive,positive
372415118,"None of the articles (or the comment) you reference show any information about the BGR implementation.  Like I said, I would like to see tests that show this actually works as expected and doesn't lower results before we merge, but demanding it be closed simply because you don't think this is correct when initial results say it is inappropriate.

Nobody is saying we have to add this today or without testing, we want to make sure it actually helps, before it's added, but the initial results are promising and it makes sense that sending the BGR might not do well, especially with the CNN mode which is trained for RGB only data.  I understand that you have a concern that this might reduce quality of detection, but if it doesn't, then we should add it.  The only way to know is to test it.   @kvrooman has done some initial testing and shows improved speed with no loss in detection and that alone means that this is worth checking out to see if it's worthwhile.",none comment reference show information implementation like said would like see show actually work lower merge demanding closed simply think correct initial say inappropriate nobody saying add today without testing want make sure actually added initial promising sense sending might well especially mode trained data understand concern might reduce quality detection add way know test done initial testing speed loss detection alone worth see,issue,positive,positive,neutral,neutral,positive,positive
372414121,"@Clorr thx for your work, deepfakesclub wrote dfaker model gives best quality. ",work wrote model best quality,issue,positive,positive,positive,positive,positive,positive
372412009,"here comparison of face swappers
https://www.deepfakes.club/best-hardware-software-deepfakes/

deepfakesclub wrote: https://www.reddit.com/r/SFWdeepfakes/comments/82btao/portable_python_installs_of_faceswap_and_dfaker/dv94je7/
> It detects more correct faces overall

so if you merge this crap PR, faceswap will detect same amount of faces as FakeApp.

Conclusion:

STOP OFFER CHANGE FUNDAMENTALS OF FACE RECOGNITION WITHOUT **100% PROOFS** AND LONG TESTS WITH VARIOUS CONDITIONS

@Clorr please close this pr.",comparison face wrote correct overall merge crap detect amount conclusion stop offer change face recognition without long various please close,issue,negative,negative,negative,negative,negative,negative
372410994,"Yeah, after a few hours of training B with many different faces in A, the preview looks funky and the resulting conversion has nothing to do with the intended face.",yeah training many different preview funky resulting conversion nothing intended face,issue,negative,positive,positive,positive,positive,positive
372407761,Yeah I did a set then I tried changing A and keeping B the same and it didn't work. However I feel this model does perform better for expressions that are not matched across sets.,yeah set tried keeping work however feel model perform better across,issue,positive,positive,positive,positive,positive,positive
372405237,"If it's set to tensorflow, it should be seeing all the same GPUs as tensorflow since Keras literally just calls the fuction in tensorflow.  If your backend is set correctly, please make sure that you're not using sudo or virtualenv.

If that gives the same result, then try adding print(multi_gpu_model._get_available_devices()) to the model and posting the results from that.",set seeing since literally set correctly please make sure result try print model posting,issue,positive,positive,positive,positive,positive,positive
372393671,"Unfortunately, this is not a very good generic model.  This one especially needs the A and B to stay the same.  You'd be better off doing that with the Original model.",unfortunately good generic model one especially need stay better original model,issue,positive,positive,positive,positive,positive,positive
372392730,"I decided to try training both A and B at the same time with the same 16K faces. My hope is that by training it really well it will have a good idea what a ""face"" is and that it will allow me to create a really well trained ""template"" model that will be able to use as a base model for real faceswaps to speed up future training.",decided try training time hope training really well good idea face allow create really well trained template model able use base model real speed future training,issue,positive,positive,positive,positive,positive,positive
372386790,"I'm willing to believe that the previous error was a bug if the current testing is showing good results.  I can't test extraction right now, but if anyone else wants to test and respond with their results.  This is more of an ""optimization"" than a bug, so we can leave it in while we test for a bit.",willing believe previous error bug current testing showing good ca test extraction right anyone else test respond optimization bug leave test bit,issue,negative,positive,positive,positive,positive,positive
372386541,@oatssss any progress on seamless+hm ? I will train a new model with GAN and and curious what the results would be,progress train new model gan curious would,issue,positive,positive,neutral,neutral,positive,positive
372385942,"the ironic thing is that input_image_bgr is actually in RGB format and mislabelled. so unless you run the detector with that file, you get the subpar performance.",thing actually format unless run detector file get performance,issue,negative,neutral,neutral,neutral,neutral,neutral
372377560,"@Kirin-kun That's an interesting idea, we need a method to detect which landmarks weren't effectively detected though. Dlib [doesn't have this feature out-of-the-box](https://github.com/davisking/dlib/issues/718). We could do what you suggest and have some threshold for the ratio of distances between eyes/nose vs chin/mouth but this seems very specific to your use case where the mouth is covered. Training another classifier as suggested by the dlib author may be the way to go.",interesting idea need method detect effectively though feature could suggest threshold ratio specific use case mouth covered training another classifier author may way go,issue,positive,positive,positive,positive,positive,positive
372373075,"Unfortunately, IAE is a model with an implict limitation of being extremely ""overtrainable"".  If you overtrain it, then it will really look funky.  This is because it separates out the ""pose"" from the ""face"" completely and has no human intuition that it looks weird.  The model may benefit from some changes and adjustments, but for now, its design means you'll get best results from just a basic training, not a ""train until perfect"".  Think of IAE right now as more of a ""quick and dirty"" model unlike GAN (or even the original) which focus more on quality than speed.",unfortunately model limitation extremely overtrain really look funky separate pose face completely human intuition weird model may benefit design get best basic training train perfect think right quick dirty model unlike gan even original focus quality speed,issue,positive,positive,positive,positive,positive,positive
372371928,Even a basic test that the program can just start one of the extract/train/convert processes is good (those issues listed above would've been caught with this simple test).,even basic test program start one good listed would caught simple test,issue,negative,positive,positive,positive,positive,positive
372361748,"With Linux, please make sure that your backend ~/.keras/keras.json is using tensorflow.  It looks like it's using something else as it's backend.  Right now, mutli GPU support only works with the tensorflow backend,  By default it's using pytorch/theano and will only see 1 GPU.",please make sure like something else right support work default see,issue,positive,positive,positive,positive,positive,positive
372360238,"This PR seems reasonable, 2 questions though.

Have you tested this in a variety of situations?  Does it impact the odds of getting a ""hit"" on the face match?  I've thought of pruning this area of the code to improve face recognition, I'm not too worried about speed, since I usually have to run it multiple times with different inputs to get it working anyway.  I figured that even if the colors were wrong, that it might actually get a few additional hits this way, even with the colors mixed up, it can still run.

",reasonable though tested variety impact odds getting hit face match thought pruning area code improve face recognition worried speed since usually run multiple time different get working anyway figured even color wrong might actually get additional way even color mixed still run,issue,negative,negative,neutral,neutral,negative,negative
372352412,"> Could you elaborate on why you disagree?

sry no, 
1) too hard explain in english
2) fight for code in every pr is too exhaust me. I better leave project.",could elaborate disagree hard explain fight code every exhaust better leave project,issue,negative,positive,positive,positive,positive,positive
372351510,"@iperov I haven't completely looked into the code change, but the counter-argument @kvrooman gave seems completely reasonable. Could you elaborate on why you disagree?",completely code change gave completely reasonable could elaborate disagree,issue,negative,positive,positive,positive,positive,positive
372337183,I also went ahead and fixed the missing Multi GPU support for GAN128.  I hadn't been able to test it (and still can't) but at least it's there so it will run now instead of failing.  I invite anyone with multiple 6gb+ gpus to test it and let me know if there are any issues.  I believe it's likely to work though since it's so similar to GAN.,also went ahead fixed missing support gan able test still ca least run instead failing invite anyone multiple test let know believe likely work though since similar gan,issue,negative,positive,neutral,neutral,positive,positive
372333161,"Actually, yes, those variables are necessary.  At least for now.  https://keras.io/utils/#multi_gpu_model has the warning of ""To save the multi-gpu model, use .save(fname) or .save_weights(fname) with the template model (the argument you passed to multi_gpu_model), rather than the model returned by multi_gpu_model.""  In order for this to happen, we need to save the reference to the original model before the multi_gpu_model call.

The Original model avoided this issue by saving the decoder and encoder weights instead of saving the whole model.  I could modify the GAN model to use this method, but it would double the number of files used to save, and would invalidate all old model saves.  In order to avoid this, I could write a save/load module that loads any version of save and converts it.  In addition, I could make the module save data to a single file.  This was beyond the scope of a quick solution fix, since people relying on the GAN model with more than one GPU would have to wait on using the multi GPU support until I built the new module, which would take some time.",actually yes necessary least warning save model use template model argument rather model returned order happen need save reference original model call original model issue saving instead saving whole model could modify gan model use method would double number used save would invalidate old model order avoid could write module version save addition could make module save data single file beyond scope quick solution fix since people gan model one would wait support built new module would take time,issue,positive,positive,positive,positive,positive,positive
372327354,"PS - the current code is also mislabeled. As cv2.imread loads all images as BGR, we have to convert it to RGB in order for it to play well with Dlib. At the very least the original code 

input_image_bgr = input_image[:,:,::-1].copy()

should be changed to 

input_image_rgb = input_image[:,:,::-1].copy()

as it is incorrect and misleading",current code also convert order play well least original code incorrect misleading,issue,negative,positive,neutral,neutral,positive,positive
372326175,"Despite that comment in there, for some reason, both the RGB and the BGR versions of the image are still sent to the detector. See current code below. This is unnecessary as the BGR version is redundant and will perform worse than the RGB version. Parring down the loop to use just the RGB version is good practice and should speed things up?  @ iperov Is there a reason not to?

``
input_image_bgr = input_image[:,:,::-1].copy() 
input_images = [input_image, input_image_bgr]
 
    detected_faces = []
    for current_detector, input_image in ((current_detector, input_image) for current_detector in dlib_detectors for input_image in input_images):
        detected_faces = current_detector(input_image, 0)",despite comment reason image still sent detector see current code unnecessary version redundant perform worse version loop use version good practice speed reason,issue,negative,negative,neutral,neutral,negative,negative
372324414,"@DLSauron I'd rather put the 16K faces in the A side and train the model until it can put the B face on them. Then switch the data in A with your real target and retrain a bit.

That's how I understand it would do the trick though.",rather put side train model put face switch data real target retrain bit understand would trick though,issue,negative,positive,positive,positive,positive,positive
372322729,"I am also seeing some really weird results with IAE. Below you can see and example of the original (A) face then one example of the original model merged on to it and then the same done with IAE. Both where trained to below 0.02. 

Right now I am building a dataset of over 16K faces from 10 people and am going to train that for the B side before switching back to the original B dataset I was using to see if that helps.

I am wondering if I should use the same dataset and train the A side with it as well since it involves faces from  like 10 different people.

![example](https://user-images.githubusercontent.com/36505807/37288435-a46e3fde-25dd-11e8-82b1-d88ecbc74783.jpg)
",also seeing really weird see example original face one example original model done trained right building people going train side switching back original see wondering use train side well since like different people example,issue,positive,positive,positive,positive,positive,positive
372317450,"@Crypt1cBunny he means that you can launch 6 faceswap at the same time.

The env variable tells the library which GPU the process can bind to (0, 1, 2, 3, 4 or 5).",launch time variable library process bind,issue,negative,neutral,neutral,neutral,neutral,neutral
372316330,"@Crypt1cBunny 1 session per 1 gpu. 6 different folders with different data
set CUDA_VISIBLE_DEVICES=""0""
python faceswap.py ...

set CUDA_VISIBLE_DEVICES=""1""
python faceswap.py ...",session per different different data set python set python,issue,negative,neutral,neutral,neutral,neutral,neutral
372315024,What do you exactly mean 6 different models @iperov ? You mean one training session on 6GPU's ?,exactly mean different mean one training session,issue,negative,negative,negative,negative,negative,negative
372314613,"btw you can train 6 different models simultaneously
by set env var
CUDA_VISIBLE_DEVICES=""0"" 

",train different simultaneously set,issue,negative,neutral,neutral,neutral,neutral,neutral
372312336,I think this issue can be closed. Looks like the author got overwhelmed and doesn't plan to update it.,think issue closed like author got plan update,issue,negative,negative,neutral,neutral,negative,negative
372306135,"@iperov 
As a test I successfully enabled the 68 point model by directly putting face_recognition into the same directory as sorttool.py and changing the default predictor in api.py to ""large"".

`def face_encodings(face_image, known_face_locations=None, num_jitters=1):'
...
'raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model=""large"")`",test successfully point model directly directory default predictor large large,issue,negative,positive,positive,positive,positive,positive
372300917,"@Kirin-kun Like you pointed it out yourself, the problem with this method is that the kernel will work for a very limited type of images and in most cases will lead to a very harsh border or over darkened blacks to compensate for the sharpening requirement.

I've personally tried many methods of sharpening and none of them actually are good enough to work across varied data sets. At some point there needs to be manual input of kernel information for us to have any control on what the sharpness will result in.

----

A well trained model will not need a sharpening pass if you ask me. The data is mapped pixel per pixel and as long as the training data is good and the loss is minimal, the output should look almost as good as the original in terms of clarity.

---

The code works and anyone can give it a shot ... but you can actually simplify this by doing this.

```
kernel = numpy.ones((3, 3)) * (-1)
kernel[1, 1] = 9
new_image = cv2.filter2D(new_image, -1, kernel)
```

Yields more or less the same result and you can easily modify the kernel array information to achieve different levels of sharpening.",like pointed problem method kernel work limited type lead harsh border compensate requirement personally tried many none actually good enough work across varied data point need manual input kernel information u control sharpness result well trained model need pas ask data per long training data good loss minimal output look almost good original clarity code work anyone give shot actually simplify kernel kernel kernel le result easily modify kernel array information achieve different,issue,negative,positive,positive,positive,positive,positive
372296804,"I just launched a training session with several different people in face A (hopefully with variety)  same model files  

The loss A jumped back up to 0.5x. and it's slowly going back down. Loss B (same face than before, but with varied poses) seems pretty stable at 0.024 though.

I will see how it goes from there. Will keep you informed.",training session several different people face hopefully variety model loss back slowly going back loss face varied pretty stable though see go keep informed,issue,positive,negative,neutral,neutral,negative,negative
372294016,"Any model needs to be trained with a data set that has variety for it to be able to eventually perform well with data sets which have very similar images.

I used a data set which had variety and let the IAE train for a while. Once I achieved low loss values on that data set, I put up a data set with less variety and it is performing just as the original one does.

Just a matter of how well your model is trained.",model need trained data set variety able eventually perform well data similar used data set variety let train low loss data set put data set le variety original one matter well model trained,issue,negative,positive,positive,positive,positive,positive
372286538,"Ah no it's more a duplicate on filename...

Do we need this? Isn't it done already?",ah duplicate need done already,issue,negative,neutral,neutral,neutral,neutral,neutral
372286216,@iperov can we close this if your sort tool does it already?,close sort tool already,issue,negative,neutral,neutral,neutral,neutral,neutral
372285823,Plz make a PR so that people can test directly and give feedback,make people test directly give feedback,issue,negative,positive,neutral,neutral,positive,positive
372273739,"@Enyakk 5 point model used in faceencodings

```
def face_encodings(face_image, known_face_locations=None, num_jitters=1):
    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model=""small"")
```

there is no chance to use 68 point model outside the lib face_recognition.

Also I dont know how landmarks transformed to 128D vector for compare

https://github.com/davisking/dlib/blob/master/tools/python/src/face_recognition.cpp compute_face_descriptors",point model used small chance use point model outside also dont know vector compare,issue,negative,negative,negative,negative,negative,negative
372271695,"> Dlib only uses RGB, so no need to send both RGB and BGR image formats to the detector in extractor

-_-

did you read comment?

> #cv2 and numpy inputs differs in rgb-bgr order, this affects chance of dlib face detection",need send image detector extractor read comment order chance face detection,issue,negative,neutral,neutral,neutral,neutral,neutral
372268096,"According to https://keras.io/utils/#multi_gpu_model , keras should behave well with that much gpus. Check if you have the equivalent in keras of the `list_local_devices`.

FYI source of keras multi gpu is [here](https://github.com/keras-team/keras/blob/master/keras/utils/multi_gpu_utils.py), maybe you will find a way to see where your error comes from. Keep us posted if you find",according behave well much check equivalent source maybe find way see error come keep u posted find,issue,negative,positive,positive,positive,positive,positive
372258525,"Looks like a problem with keras, according to google.

And holy shit. 6 GTX 1080ti? Even if it's a cloud provided rig, that must cost an arm and a leg.",like problem according holy ti even cloud provided rig must cost arm leg,issue,negative,neutral,neutral,neutral,neutral,neutral
372254970,"Thanks for the link, seems very interesting I'll try to read this ASAP. Note you can post this kind of info in faceswap-model repo, it is more dedicated to gather this kind of paper.

I totally agree that the loss is the problem now. The first layers are trained well, we just now have a problem on the very last layers that don't get the right info to adjust correctly. I'm currently trying simple solutions because I don't think we need very complicated solutions. In style transfer GAN, folks try to generate images for which they don't have a ground truth so creating a discriminator is a must. But here we have one, so the model should converge to this very ground truth...",thanks link interesting try read note post kind gather kind paper totally agree loss problem first trained well problem last get right adjust correctly currently trying simple think need complicated style transfer gan try generate ground truth discriminator must one model converge ground truth,issue,positive,positive,positive,positive,positive,positive
372245861,Thnaks for testing and providing a solution. I'm just wondering: are you sure you need 2 new vars? Because they seem to reference the same objects as the original vars so maybe the fix is just displacing the `multi_gpu_model` call?,testing providing solution wondering sure need new seem reference original maybe fix call,issue,positive,positive,positive,positive,positive,positive
372243488,"I noticed that the -by face sorting has problems with faces (side profiles, low angles) originally aligned+detected by CNN, resulting in a semi-random order. That is because face_recognition by default uses ""hog"" for face_encodings, so those ""CNN-exclusive"" faces fail when re-detected by HOG.

I was unsuccessful to modify face_recognition to engage CNN-mode. Maybe it's possible to re-use the alignments.json or do they not contain the necessary information?",face side low originally resulting order default hog fail hog unsuccessful modify engage maybe possible contain necessary information,issue,negative,negative,neutral,neutral,negative,negative
372217034,I think maybe this is because I've installed the wrong components in Visual Studio? There's dozens of options and I've tried installing all the likely suspects but still just keep getting the above error.,think maybe wrong visual studio tried likely still keep getting error,issue,negative,negative,negative,negative,negative,negative
372204570,"bryanlyon also other directories same warn.

better solution is move all prog to 
src\
then tools\ is ok",also warn better solution move prog,issue,positive,positive,positive,positive,positive,positive
372202670,"This is no different from any other linux program's directory layout; tools/ is implied to refer to self-contained tools that help the project without but other folders are usually utilities or sub-files used by the main program.  That said, a simple catchall added to files in scripts/ could warn users that they're not directly executable.",different program directory layout refer help project without usually used main program said simple catchall added could warn directly executable,issue,negative,positive,neutral,neutral,positive,positive
372200025,"I agree that unit tests would be invaluable.  The difficulty is in how we verify some of the result data, since much of our data is non-deterministic.  We could at least ensure that each command runs correctly.  We may be able to try loading/saving a model without processing it to ensure it's not changed (but models may be changed with random data on load).  No unit testing would be perfect, even with known models due to how the system works.

I do think we would benefit from a dev branch to test pulls/new features before they're promoted to master.  This would have at least stopped my recent error (fixed in #280 ) where I accidentally corrupted data during load from making it to the master branch.

I think #222 is different, since it's more a matter of cleaning our style and things like removing whitespace at the end of the line or turning tabs into spaces for consistent format.  I'm not arguing against it, just saying it's a different type of effort.

Various ""best practices"" could be used, but I think we need a dev willing to dedicate themselves to doing it, since poor unit tests are worse than no tests at all.",agree unit would invaluable difficulty verify result data since much data could least ensure command correctly may able try model without ensure may random data load unit testing would perfect even known due system work think would benefit dev branch test master would least stopped recent error fixed accidentally corrupted data load making master branch think different since matter cleaning style like removing end line turning consistent format saying different type effort various best could used think need dev willing dedicate since poor unit worse,issue,negative,positive,neutral,neutral,positive,positive
372133604,"On this frame, landmarks debug shows this:

![tae0256_0](https://user-images.githubusercontent.com/36699120/37256390-55b7a12e-255a-11e8-9b93-9232bf86e402.png)

I suppose the landmarks for mouth and chin are defaults calculated relatively to eyes and nose? The chin is much shorter than the real one.

Would there be a way to store in the alignments file which landmarks were effectively detected, and then at convert time, cut them out? I don't know if the face detector is able to output that information.",frame suppose mouth chin calculated relatively nose chin much shorter real one would way store file effectively convert time cut know face detector able output information,issue,negative,positive,positive,positive,positive,positive
372132708,"@Clorr i dont think it good idea, because following this logic, \scripts\ also can be run directly, but they cant",dont think good idea following logic also run directly cant,issue,negative,positive,positive,positive,positive,positive
372132443,"@Kirin-kun I dont know. It eats many vram, so works only with batch size=4 on my 6GB Card.
Also ""hi-res"" with IAE constructs absolutely new face, like transfer features A onto B face.",dont know eats many work batch card also absolutely new face like transfer onto face,issue,negative,positive,positive,positive,positive,positive
372131460,"Ok to merge this. One request though. Can you put this file in a `tools/` folder and name it a bit more explicitly (something like sort_extracted.py, or something you find relevant)?",merge one request though put file folder name bit explicitly something like something find relevant,issue,negative,positive,positive,positive,positive,positive
372129229,"Works even better than version 1, -by face to check no other faces sneaked in there, then -by blur to get rid of the trash, then -by hist to look over the dataset in all its optimised glory.",work even better version face check blur get rid trash hist look glory,issue,positive,positive,positive,positive,positive,positive
372128989,"@iperov the eyes you produced with your ""hi-res"" decoder are awesome. Any chance to add it to the repo?",produced awesome chance add,issue,positive,positive,positive,positive,positive,positive
372119435,"Hmm, that's odd. When I first started it, I had a message:

Unable to open file (unable to open file: name = 'H:\Fakes\modeld.iae\IAE_encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
Loading Trainer from Model_IAE plugin...

Then it stalled and didn't do anything. 

But I just retested, this time with a completely empty directory and it gave the same message, but started anyway. Maybe something on my end.

I guess it can be closed.

",odd first message unable open file unable open file name error message file directory loading trainer anything time completely empty directory gave message anyway maybe something end guess closed,issue,negative,negative,negative,negative,negative,negative
372118507,"It creates new files if no existing model is found. It gives you a warning for the same but continues to start training as expected. I just tested it. Seems to be working fine.

This could be something on your end. Please double check that the folder you are writing to has write permissions.
",new model found warning start training tested working fine could something end please double check folder writing write,issue,negative,positive,positive,positive,positive,positive
372118416,"Hmm, IAE should have the same behavior than other models. Also encoder file has the same behavior as other files so I don't see a reason why it would fail.

It will output a warning anyway but it shouldn't stop... I can't test right now, if someone else can give more feedback it would be nice...",behavior also file behavior see reason would fail output warning anyway stop ca test right someone else give feedback would nice,issue,negative,positive,positive,positive,positive,positive
372116414,"Important notice: I renamed the model files so that users who try this don't overwrite their original model

Reanme your existing IAE model files if you did train some models previously! (I added a ""IAE_"" prefix)",important notice model try overwrite original model model train previously added prefix,issue,negative,positive,positive,positive,positive,positive
372116283,"Your fix is merged

Important notice: I renamed the model files so that users who try this don't overwrite their original model",fix important notice model try overwrite original model,issue,negative,positive,positive,positive,positive,positive
372114938,"Here's what you can do to fix this.

Go to plugins/Model_IAE/ folder and open the Trainer.py file.

Replace

> def __init__(self, model, fn_A, fn_B, batch_size=64):

with 

> def __init__(self, model, fn_A, fn_B, batch_size, *args):

----

And yes, the model files for the IAE model are different from the original. So you will need to create a new folder for those and start the process anew.

I'm testing out the new model currently. So far the results have been pretty blurry but I think it will require some hours of proper training. I'll report back later.

----

I pushed a pull request for this fix. @Clorr ",fix go folder open file replace self model self model yes model model different original need create new folder start process anew testing new model currently far pretty blurry think require proper training report back later pull request fix,issue,positive,positive,neutral,neutral,positive,positive
372114079,"Thanks but just gets more errors:
S:\desktop\dlib-19.9\examples\build>cmake --build . --config Release
Error: could not load cache

follows
S:\desktop\dlib-19.9\examples\build>cmake ..
CMake Error in CMakeLists.txt:
  Failed to run MSBuild command:

    MSBuild.exe

  to get the value of VCTargetsPath:

    The system cannot find the file specified",thanks build release error could load cache error run command get value system find file,issue,negative,positive,positive,positive,positive,positive
372110522,"Ah I assumed it was ok, did not test. However that's not a bad thing as I will add a suffix to distinguish these model files from original at the same time of fixing ",ah assumed test however bad thing add suffix distinguish model original time fixing,issue,negative,negative,negative,negative,negative,negative
372109881,"you can load partial weights into Keras, haven't tested it 

https://keras.io/models/about-keras-models/

`model.load_weights(filepath, by_name=False): loads the weights of the model from a HDF5 file (created by  save_weights). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use by_name=True to load only those layers with the same name.`

try adding true at load_weights, https://github.com/deepfakes/faceswap/blob/master/plugins/Model_IAE/AutoEncoder.py",load partial tested model file default architecture unchanged load different architecture common use load try true,issue,negative,negative,neutral,neutral,negative,negative
372109061,"Also, should be mentioned it is not compatible with previously trained original model:

```
Failed loading existing training data.
You are trying to load a weight file containing 7 layers into a model with 4 layers.
```

Will have to start from scratch.",also compatible previously trained original model loading training data trying load weight file model start scratch,issue,negative,positive,positive,positive,positive,positive
372107213,I see you've already merged the IAE.  I went ahead and just added it here.  It's ready to merge whenever you are.,see already went ahead added ready merge whenever,issue,negative,positive,positive,positive,positive,positive
372105678,I could merge my patch for that model into this branch and have both closed at once if you want.,could merge patch model branch closed want,issue,negative,negative,neutral,neutral,negative,negative
372101177,"18 hours training (1080Ti) on cage/trump task:

![image](https://user-images.githubusercontent.com/1388563/37251399-686810ac-254a-11e8-9b5d-4c00740ea4eb.png)

![image](https://user-images.githubusercontent.com/1388563/37251400-71b88268-254a-11e8-852a-7d63612ff9f9.png)

Please merge this pull request when it's ok for you. I think it's time to let more people use and test this model ;)

@Clorr @ruah1984 Principally, if there are enough different faces for training, I think the encoder in iae can be an universal face encoder (extract facial expression and appearance from any face), and the decoder in iae can be an universal face decoder (reconstruct face image from arbitrary combination of facial expression and appearance). Then Yes we can train many intermediate layers for many people, and swap faces for any two of them 🤔 

@bryanlyon Thanks for adding multi gpu support for the model 👍 

@iperov I guess the difference is because the model need more faces of ""source man"" (with different facial expression) to help the model splits latent variables into ""facial expression"" and ""appearance“.
In your example, the unrecognizable man looks like a mix of source man and dest man, because the model failed to distinguish ""facial expression"" and ""appearance“ information, and categorized too much information to ""facial expression"" layer (for example, the mustache).",training ti task image image please merge pull request think time let people use test model principally enough different training think universal face extract facial expression appearance face universal face reconstruct face image arbitrary combination facial expression appearance yes train many intermediate many people swap two thanks support model guess difference model need source man different facial expression help model latent facial expression appearance example unrecognizable man like mix source man man model distinguish facial expression appearance information much information facial expression layer example mustache,issue,positive,positive,neutral,neutral,positive,positive
372099711,"@oatssss I don't know precisely. If we have an histogram of the colors, there should be a peak, compared to the dominant color, corresponding to the ""odd"" color(s). With setting a threshold, you could drop them before doing your matching.

Just a suggestion, I'm not knowledgeable enough in image processing to know if it's possible or not.",know precisely histogram color peak dominant color corresponding odd color setting threshold could drop matching suggestion knowledgeable enough image know possible,issue,negative,positive,neutral,neutral,positive,positive
372098365,"@Clorr I took care of conflicts that popped up and retested, this should be good to go",took care good go,issue,positive,positive,positive,positive,positive,positive
372095520,How do you detect that the color deviates too much though?,detect color much though,issue,negative,positive,positive,positive,positive,positive
372092765,"got much different result vs original in man to man conversion

source man:
![00075](https://user-images.githubusercontent.com/8076202/37250446-3f6a65a8-2516-11e8-896d-158dac92b2fa.png)

dest man:
![out00042](https://user-images.githubusercontent.com/8076202/37250447-43964822-2516-11e8-92ce-7e4154decac8.png)


Original:
![out00047](https://user-images.githubusercontent.com/8076202/37250424-ba01d036-2515-11e8-8766-7aa9a7e96aa2.png)

IAE:
![out00047 2](https://user-images.githubusercontent.com/8076202/37250425-bcfd8f8c-2515-11e8-97e5-dd11fe976237.png)

IAE constructs absolutely new unrecognizable man. Also it adds some mustach.",got much different result original man man conversion source man man original absolutely new unrecognizable man also,issue,positive,positive,positive,positive,positive,positive
372092528,"suggest fix
```
class DetectedFace(object):
    def __init__(self, image=None, r=0, x=None, w=None, y=None, h=None, landmarksXY=None):
        self.image = image
```",suggest fix class object self image,issue,negative,neutral,neutral,neutral,neutral,neutral
372089708,"I managed to recompile Dlib and OpenCV to use CUDA on Win 10 x64, hoping to speed up the extract/align process.  It boosted GPU use during training from about 50% to 65%.  But as stated above, with Dlib CUDA-enabled, adding the -j parameter to the command line crashes facewap.py, but the extract script runs fine if -j parameter is omitted, on a GTX 1070 with 8 Gb.  But there is only 1% or 2% GPU use and less than 20% CPU use during the extract/align process on a Ryzen 1700X.  ",recompile use win speed process use training stated parameter command line extract script fine parameter use le use process,issue,positive,positive,positive,positive,positive,positive
372087786,"This is still a good add.  I've modified it to support the new plugin loader, and the gan v2.0 update at https://github.com/bryanlyon/faceswap/tree/multi_gpu_iae .  I will create a pull request if desired, but it requires #272 to be merged first.",still good add support new loader gan update create pull request desired first,issue,positive,positive,positive,positive,positive,positive
372073971," the issue of the ""averaged face"" pose/eye gaze direction/blur is due to the way the loss function is designed. differences in alignment ( double eyebrows, eye gaze, distorted or zoomed features, incorrect expression or pose) are lumped together with differences in texture ( color, lighting, gamma, white balance ) in the single loss function.

was reading a paper with some very interesting ideas on loss functions and feedback from seperate items... 1. landmark error, 2. texture error of the frontal  flattened image, 3. percerputal error from the final warped image ( by similiarity functions or the return of a seperate CNN recognition model ) 

https://www.arxiv-vanity.com/papers/1701.04851/",issue face gaze due way loss function designed alignment double eye gaze distorted incorrect expression pose together texture color lighting gamma white balance single loss function reading paper interesting loss feedback landmark error texture error frontal image error final warped image return recognition model,issue,negative,positive,neutral,neutral,positive,positive
372066138,Thanks for all your work with this. It’s great to see all the free time you guys put into this. ,thanks work great see free time put,issue,positive,positive,positive,positive,positive,positive
372056177,"Ok, for me. I pulled the last commit and it converted without a hitch.

Can be closed.",last commit converted without hitch closed,issue,negative,negative,neutral,neutral,negative,negative
372053278,"I've put in a pull request to apply a default value of 0. Hopefully it will be added soon. Very quick test appears to have fixed the issue.

Any problems, let me know

Cheers.",put pull request apply default value hopefully added soon quick test fixed issue let know,issue,positive,positive,positive,positive,positive,positive
372049516,"Well, it can be useful to allow people to re-use their previously extracted data to continue a training session or try another trainer. I have a set of  training data on which I test original, gan and gan128 to see the differences and various convert settings.

And it can take a long time extracting from video frames.",well useful allow people previously extracted data continue training session try another trainer set training data test original gan gan see various convert take long time video,issue,positive,positive,neutral,neutral,positive,positive
372049347,"It is given a default value... if an alignments.json isn't present. 2 mins, I'll put in a fix
",given default value present put fix,issue,negative,neutral,neutral,neutral,neutral,neutral
372049191,Isn't it possible to give a default value? Or just to test for None?,possible give default value test none,issue,negative,neutral,neutral,neutral,neutral,neutral
372049026,"Basically the alignments.json file had to change a little bit. @Clorr would you like me to code something in? It seems a bit obsolete to handle backwards compatibility as there should only be a small window.

@Kirin-kun the easiest fix would be to open your alignments.json and do a find replace all:

Look for:

> [
>     {

Replace with:

> [
>     { ""r"": 0,

If you are using notepad++, go to find replace, check the box which says ""Extended(\n,\r,\t,\0,\x...)

and find:

> [\n    {\n

replace with:

> [\n    {\n      ""r"": 0,\n


Alternatively you can re-extract the frames to generate a new alignments.json
",basically file change little bit would like code something bit obsolete handle backwards compatibility small window easiest fix would open find replace look replace go find replace check box extended find replace alternatively generate new,issue,negative,negative,neutral,neutral,negative,negative
372048872,"Probably. I extracted yesterday, then this morning pulled the repo and tried to train : it errored as mentioned first in the PR.  I then reverted my repo and trained. 

I re-pulled it to test the earlier fix and restarted the training correctly, so I let it run.

Then I went on to convert: boom.",probably extracted yesterday morning tried train first trained test fix training correctly let run went convert boom,issue,negative,positive,positive,positive,positive,positive
372048067,Are you converting with frames you extracted with an older version?,converting extracted older version,issue,negative,positive,positive,positive,positive,positive
372048056,"Ah... Do you use a previously generated alignments.json? Because the rotation is likely to be missing. I can check how to handle that.

CC @torzdf ",ah use previously rotation likely missing check handle,issue,negative,negative,negative,negative,negative,negative
372047650,"python faceswap.py convert -i H:\Fakes\pics -o H:\Fakes\pics\merged -m H:\Fakes\model -b 20 -e 30 -D cnn

```
  0%|                                       | 11/4820 [00:00<00:47, 100.73it/s]Traceback (most recent call last):
  File ""c:\users\kirin\faceswap\faceswap.py"", line 29, in <module>
    arguments.func(arguments)
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 87, in process_arguments
    self.process()
  File ""c:\users\kirin\faceswap\scripts\convert.py"", line 199, in process
    self.convert(converter, item)
  File ""c:\users\kirin\faceswap\scripts\convert.py"", line 224, in convert
    for idx, face in faces:
  File ""c:\users\kirin\faceswap\lib\cli.py"", line 146, in get_faces_alignments
    if face.r != 0: image = rotate_image(image, face.r)
  File ""c:\users\kirin\faceswap\lib\utils.py"", line 37, in rotate_image
    if angle < 0: angle = sum((360, angle))
TypeError: '<' not supported between instances of 'NoneType' and 'int'
```",python convert recent call last file line module file line file line process converter item file line convert face file line image image file line angle angle sum angle,issue,negative,neutral,neutral,neutral,neutral,neutral
372046107,"Can you remove the `try: except:` in convert.py and provide the full exception message? Otherwise provide the command line options you are using, thx",remove try except provide full exception message otherwise provide command line,issue,negative,positive,positive,positive,positive,positive
372045609,"Reopening, because it breaks at conversion now: 

Failed to convert image: ...0255.png. Reason: '<' not supported between instances of 'NoneType' and 'int'",conversion convert image reason,issue,negative,neutral,neutral,neutral,neutral,neutral
372037414,"Ok, I see. So this is intended to be GAN specific? Would the context between frames also be applicable if frames have already been extracted.

The reason I ask is that I envisage a workflow similar to following (and I accept that I may be way off the mark here, just tossing some ideas around ;) )

Convert: 
- Input dir is provided (as currently) 
- if input is a movie file (e.g. mp4, mkv etc) then:
    - use ffmpy to read the movie file to gather fps, number of frames, resolution
    - pipe output from ffmpy, converted to pngs (resized down if necessary) through the standard convert process and pipe back in to an output movie file with the audio from the original video into your output.

This would mean that video would still follow the same process as currently exists, the only change would be reading the image from a pipe and passing it back to a pipe rather than from the disk. It would also mean that any bounding box improvements would benefit the standard process (it indeed it works that way).
 ",see intended gan specific would context also applicable already extracted reason ask envisage similar following accept may way mark tossing around convert input provided currently input movie file use read movie file gather number resolution pipe output converted necessary standard convert process pipe back output movie file audio original video output would mean video would still follow process currently change would reading image pipe passing back pipe rather disk would also mean bounding box would benefit standard process indeed work way,issue,positive,negative,neutral,neutral,negative,negative
372036672,It is part of the GAN port to this repo. You will see that there is a plugin GANBoundingBox. The improvment here is that the convert uses a context between frames to lower flicker. See GAN repo if you want more details (although I am not sure how much details there is there),part gan port see convert context lower flicker see gan want although sure much,issue,negative,positive,positive,positive,positive,positive
372035912,"Quick question, what's the intended workflow here? From a quick scan it looks like it assumes that you have already trained your model, and you are pointing a video at it and it is performing the swap on the frames within the video, to output a swapped video. Would this be correct?",quick question intended quick scan like already trained model pointing video swap within video output video would correct,issue,negative,positive,positive,positive,positive,positive
372026523,"bloody hell, @Clorr. That was quick!

Thanks!",bloody hell quick thanks,issue,negative,negative,neutral,neutral,negative,negative
372026208,"@Clorr should be fixed, so this should be good for pulling (I ran a quick test and all is fine and up to date).

@iperov I totally get where you are coming from, and if this was a more substantial change I would provide proof. However, I made this change mostly for myself. I have a deadline to hit so my dev box is currently running 24/7 performing converts (with the image rotator on as it happens). and I only have one usable gfx card, which is currently being utilized. Unfortunately the frames that are being generated cannot be shared in the public domain. 

I knew other people wanted this feature, so I raised this as a pull request knowing/hoping that other people would test it and confirm the results.

In an ideal world I would have provided an output, and if I commit a more substantial change in future, I will.

A general note:
Whilst this PR does not impact anyone else's code, just adds functionality, I should add that it will break backwards compatibility. Adding a new value to the alignments file (the image rotation) means that destination frames need to be extracted using this commit if you are planning to use an alignments file.

Cheers",fixed good ran quick test fine date totally get coming substantial change would provide proof however made change mostly deadline hit dev box currently running image rotator one usable card currently unfortunately public domain knew people feature raised pull request people would test confirm ideal world would provided output commit substantial change future general note whilst impact anyone else code functionality add break backwards compatibility new value file image rotation destination need extracted commit use file,issue,positive,positive,positive,positive,positive,positive
372019385,What's the status here? Can it be PRed? let me know when we can close this,status let know close,issue,negative,neutral,neutral,neutral,neutral,neutral
372019072,"Brings too few improvments. However if you have  solution for plotting and making code cleaner, it would be welcome",however solution plotting making code cleaner would welcome,issue,positive,positive,positive,positive,positive,positive
372019034,"Has pros and cons, tha fact it loads all files at the beginning is a problem, but you are right, we still can do better for that part...",tha fact beginning problem right still better part,issue,negative,positive,positive,positive,positive,positive
372018982,"I won't merge this in the main README however if you want to create a README-cn.md, it is ok for me. Also think of #163 ",wo merge main however want create also think,issue,negative,positive,positive,positive,positive,positive
372018339,"@oatssss sorry I removed the Extract_align folder as it was not relevant anymore with the removal of the aligner.py. However I see that you have modified it so it conflicts. Also I see you have a new align_eyes in lib. If allign_eyes is specific to extract, please recreate the folder and put both files (and more if relevant) in it. Thx",sorry removed folder relevant removal however see also see new specific extract please recreate folder put relevant,issue,negative,positive,neutral,neutral,positive,positive
372018041,"You have to make a new branch or tag. Here your pull request is for master and if you push on master this PR is updated automatically. If you do a new branch and make a PR for the branch, you can make separate PR",make new branch tag pull request master push master automatically new branch make branch make separate,issue,negative,positive,positive,positive,positive,positive
372017899,"Nice one ;-) I was also thinking modifying this was getting cumbersome because it makes conflicts everytime.

Just a note though, think about separating pull requests when they are not for the same purpose. Not a big deal here",nice one also thinking getting cumbersome note though think separating pull purpose big deal,issue,negative,positive,positive,positive,positive,positive
372017633,"I updated the code with DSSIM loss function and res_block. Not very big improvments, but still better than previous. This is the result:
![_sample_training](https://user-images.githubusercontent.com/873943/37240799-8cab0f8c-2450-11e8-89c0-e5aad2e09386.jpg)
",code loss function big still better previous result,issue,negative,positive,positive,positive,positive,positive
372015103,"I tested my changes and it was working fine before I made pull request. The detector was loading fine. I understand what would have happened if it didnt found the directory would have not been good. You went ahead and and forced to use 2 detection methods even though that is not what the command line argument says. No one got angry or upset over that. I tried to improve it. Then you found something wrong and suggested I improve, i did. That's how open source work. Not everyone here is a master programmer, we are trying to collaborate with ideas.

I don't think it is fair that you have to write things 2 times because someone erases them. People should be more careful when writing over stuff but also that is what pull requests are for so that everyone can review them.

It's an ongoing process, it is not perfect and it's not going to be always the way you want. I think you are very talented and have made great contributions. Even in professional teams people break stuff. So there is no need to get mad over a program.

On the other thread I was agreeing with you that people should submit proof of why their changes are better and I agree that it is not fair for you to write things twice but the project has become very awesome by having more people involved and with a little patience everything is going to be alright.",tested working fine made pull request detector loading fine understand would didnt found directory would good went ahead forced use detection even though command line argument one got angry upset tried improve found something wrong improve open source work everyone master programmer trying collaborate think fair write time someone people careful writing stuff also pull everyone review ongoing process perfect going always way want think talented made great even professional people break stuff need get mad program thread agreeing people submit proof better agree fair write twice project become awesome people involved little patience everything going alright,issue,positive,positive,positive,positive,positive,positive
372014705,"Hi, thanks for the PR. I also think the db is a bit overkill for now, but maybe someday it could be useful. However if you want to go that way, you should make an abstraction layer so that info is stored/read the same way, wether we have json or db. If you want more info on abstraction layer, let me know, I can explain more",hi thanks also think bit maybe someday could useful however want go way make abstraction layer way wether want abstraction layer let know explain,issue,positive,positive,positive,positive,positive,positive
372014084,"A proof would mean the committer has tested things in various conditions and shows it works in all the cases. This can be expected when you have some critical project with hard consequences.

Here, @torzdf is proposing an improvment, that is only an option. Maybe in some cases it works maybe in other it doesn't. The PR enables people to have a look and say wether this was useful to them or not or what behavior they encountered. I need absolutely no proof. If someone says ""Oh it helped me in some cases"", it is already good enough.

The only requirment for a PR is that the advantages overcome the drawbacks.",proof would mean committer tested various work critical project hard option maybe work maybe people look say wether useful behavior need absolutely proof someone oh already good enough overcome,issue,negative,positive,neutral,neutral,positive,positive
372013608,"It exhausts you because you put too much passion and expectations in the project. We don't care if this project fails here or here sometime, it is not rocket science or nuclear research.

It is just a collective effort to share some knowledge and if there is a defect someone who is bothered by the problem will fix it.

Some attention has to be given so that it does not go too bad though, but we are not perfect",put much passion project care project sometime rocket science nuclear research collective effort share knowledge defect someone problem fix attention given go bad though perfect,issue,positive,positive,positive,positive,positive,positive
372013065,"Yeah this I agree, this is a good practice actually",yeah agree good practice actually,issue,positive,positive,positive,positive,positive,positive
372012835,"`contributors should submit proof with their pull requests?`
absolutely",submit proof pull absolutely,issue,negative,positive,positive,positive,positive,positive
372012660,"Because I very mad !
Why I must check all PRs to detect ppl something erasing I wrote before ?
Latest repo commit also erased my batch size fix #236.
And your PR before my code review was tried to erase important code.
",mad must check detect something wrote latest commit also erased batch size fix code review tried erase important code,issue,negative,positive,neutral,neutral,positive,positive
372012468,So the results I reported is not enough? Or are you saying that contributors should submit proof with their pull requests?,enough saying submit proof pull,issue,negative,neutral,neutral,neutral,neutral,neutral
372012437,"`push a pr if necessary`
no thx, I so tired. Working in opensource much exhausting me. Its require to check all pr's, because ppl can erase something I wrote before as it happened with #236 and #259
Also https://github.com/deepfakes/faceswap/pull/253 man cannot provide proofs why his improve can detect more faces.",push necessary tired working much exhausting require check erase something wrote also man provide improve detect,issue,negative,negative,negative,negative,negative,negative
372011505,"yes man who changed structure didnt transfer content of Trainer
I so mad.",yes man structure didnt transfer content trainer mad,issue,negative,negative,negative,negative,negative,negative
372011274,"#236 has been merged. However due to structure changes it may have been lost. I'm on my phone so I can't check, but feel free to review and push a pr if necessary ",however due structure may lost phone ca check feel free review push necessary,issue,negative,positive,neutral,neutral,positive,positive
372011139,"for example
@torzdf extracted 100 faces, then he added rotations and extracted 105 faces - I want to see proofs",example extracted added extracted want see,issue,negative,neutral,neutral,neutral,neutral,neutral
372010745,"@Clorr where is batch size fix ? https://github.com/deepfakes/faceswap/pull/236
looks like batch fix in Original trainer has been erased :(",batch size fix like batch fix original trainer erased,issue,positive,positive,positive,positive,positive,positive
372009558,"@iperov this fix is not meant to catch glitches on this extraction, it's to be able to detect sideway faces or upside down faces. Dlib expects eyes to be above nose. So if the person is like laying down on the side or face is upside down it won't get detected without this fix.",fix meant catch extraction able detect sideway upside nose person like laying side face upside wo get without fix,issue,negative,positive,positive,positive,positive,positive
372005316,"@torzdf 
`All my converts have come out fine, and I'm not sure what this potential glitch is, but it would be good to know whether you have run into any unexpected issues on the final output, or whether it's as expected.`

so you dont know why your fix better, because you cannot provide any comparisons, and people have to test your fix ?",come fine sure potential would good know whether run unexpected final output whether dont know fix better provide people test fix,issue,positive,positive,positive,positive,positive,positive
371995085,"I try this yesterday night, is fast to get the clear and clean image compare to original model. Don't know if retrain decoder + IAE can be work together or not ",try yesterday night fast get clear clean image compare original model know retrain work together,issue,positive,positive,positive,positive,positive,positive
371994868,"@acsaga ,if each layer of encoder we manage different information , when all information merge and generate (decoder)new face, will have more lost?",layer manage different information information merge generate new face lost,issue,negative,positive,neutral,neutral,positive,positive
371991734,"after following the instructions https://github.com/deepfakes/faceswap/blob/master/INSTALL.md 
-pip uninstall dlib
-you're gonna need to install cmake: https://cmake.org/download/
-download dlib from here and run the commands shown from command prompt: http://dlib.net/compile.html
 notice the line line where you have to specify the version of visual studio you have",following gon na need install run shown command prompt notice line line specify version visual studio,issue,negative,neutral,neutral,neutral,neutral,neutral
371989657,How? Sorry I spent many hours installing various things to get this to work. The installation instructions seemed to miss out many key requirements.,sorry spent many various get work installation miss many key,issue,negative,positive,neutral,neutral,positive,positive
371989638,I am currently rewriting this to merge into the new master.  There is no point in merging this branch for now.,currently merge new master point branch,issue,negative,positive,neutral,neutral,positive,positive
371988528,Closing since this was merged alongside #217. I'll make a new branch/PR with a tool that strips deleted faces from the alignments file.,since alongside make new tool file,issue,negative,positive,positive,positive,positive,positive
371987957,"One note on how MultiGPU works, since it works by mirroring the model on all GPUS then splitting up the batches across all the GPUs, you want to increase the batch size by a multiple of the number of GPUs you are using.  I.E. if you can normally run batch sizes of 32 and use 2 gpus, you should increase the batch size to 64.  Otherwise, you're using all the GPUs, but you're leaving performance on the table.",one note work since work model splitting across want increase batch size multiple number normally run batch size use increase batch size otherwise leaving performance table,issue,positive,positive,neutral,neutral,positive,positive
371987616,Closing since this was merged alongside #217. I'll create a new PR with the histogram matching on top of seamless.,since alongside create new histogram matching top seamless,issue,negative,positive,positive,positive,positive,positive
371985478,"Alright, praying for the best. Hopefully this merge won't create too much confusion, I'll help where I can!",alright praying best hopefully merge wo create much confusion help,issue,positive,positive,positive,positive,positive,positive
371983496,"A database makes the system a lot more complicated and less portable.  SQLite is not as bad as others, but JSON is not a very big performance cost and is still easy to use.

In fact, from a quick look around, I think JSON is actually more efficient than SQLIte.  In general, the advice online is to stick with JSON unless you need ACID or relational data.  Neither of which is important to our use cases.  Honestly, I'd want to see some concrete reason why we need SQLite before I'd want to use it.

Sources:
http://jeromebelleman.gitlab.io/posts/devops/plain/
https://stackoverflow.com/questions/8652005/json-file-vs-sqlite-android
https://softwareengineering.stackexchange.com/questions/190482/why-use-a-database-instead-of-just-saving-your-data-to-disk
https://softwareengineering.stackexchange.com/questions/235707/using-a-relational-database-vs-json-objects-for-event-activity-data",system lot complicated le portable bad big performance cost still easy use fact quick look around think actually efficient general advice stick unless need acid relational data neither important use honestly want see concrete reason need want use,issue,negative,positive,neutral,neutral,positive,positive
371972945,I agree that #217 Should be the first merge.  It's a major update and will actually require rewriting many of the other PRs since it includes an architectural change.,agree first merge major update actually require many since architectural change,issue,negative,positive,positive,positive,positive,positive
371971136,"They were good I had a long video that had even upside down faces. Like 1500 out of 8000 that got picked by the rotation only. They got converted back nicely too. This is great, I have always struggled with the awkward angles and how to spot faces and bulk rotate before faceswapping, this is so much more convinient",good long video even upside like got picked rotation got converted back nicely great always awkward spot bulk rotate much,issue,positive,positive,positive,positive,positive,positive
371970541,"@babilio How are your results, by the way?

@iperov mentioned:

> have you example where your fix can detect more faces without flip-glitches by aligner?

All my converts have come out fine, and I'm not sure what this potential glitch is, but it would be good to know whether you have run into any unexpected issues on the final output, or whether it's as expected.",way example fix detect without aligner come fine sure potential would good know whether run unexpected final output whether,issue,positive,positive,positive,positive,positive,positive
371968914,"That's good to hear. 

In my opinion this is ready for merge if enough people are interested. I know @ppmdo and @Deadfishzzway showed interest in Issues. Tagging in case they want to test/feedback.",good hear opinion ready merge enough people interested know interest case want,issue,positive,positive,positive,positive,positive,positive
371965289,"Yeah I think that's a good solution. Thanks for putting messages only on verbose mode too btw! Also retested this for performance by itself and convert is working great. Barely drop in images per second, even with images upside down. ",yeah think good solution thanks verbose mode also performance convert working great barely drop per second even upside,issue,positive,positive,positive,positive,positive,positive
371962633,I got home tested this branch by itself. Works as expected and no drop on it/s. Sorry for all the comments. I support this PR,got home tested branch work drop sorry support,issue,negative,negative,negative,negative,negative,negative
371944956,@Kirin-kun if you use GAN converter it has been depreciated. I believe @oatssss will delete those converters. You should use masked converter. https://github.com/deepfakes/faceswap/pull/217#issuecomment-370146749,use gan converter believe delete use masked converter,issue,negative,neutral,neutral,neutral,neutral,neutral
371944130,"I think it's just the branch that has problems. I went to master and with the latest commits, I don't have the errors anymore.

But the conversion is just not working : I have just a transparent square over the original face.

And I was not using GAN128, but GAN.",think branch went master latest conversion working transparent square original face gan gan,issue,negative,positive,positive,positive,positive,positive
371942410,"I have tested and confirmed that conversion is safe as well with the multigpu.  This latest commit should enable -g --gpus on conversion as well.  No guarantees on how much that will actually speed things up.  But it shouldn't hurt anything.

Extract is still done with different techniques and requires a different implementation for multi GPU support.",tested confirmed conversion safe well latest commit enable conversion well much actually speed hurt anything extract still done different different implementation support,issue,positive,positive,positive,positive,positive,positive
371939858,"There was never a convert gan working for 128, I think. Masked is the recommended, (maybe that can be added to the param help?)",never convert gan working think masked maybe added param help,issue,negative,neutral,neutral,neutral,neutral,neutral
371938976,"@oatssss I didn't succeed to convert. The converter doesn't work (at least in the gan-v2.1 branch). When I tried the GAN converter, it complained about patch_image having too many arguments. It seems the GAN converter doesn't take size as argument. 

In the convert.py, there is 
`image = converter.patch_image(image, face, 64 if ""128"" not in self.arguments.trainer else 128) `

But in the Convert_GAN.py there is:
`def patch_image( self, original, face_detected ):`

Whereas in Convert_Masked.py there is:
`def patch_image( self, image, face_detected, size ):`

I tried to remove the size, but it then gave another message: 

Failed to convert, Reason: list indices must be integers or slices, not tuple

And the Masked Converter doesn't work with GAN models obviously, it doesn't find an encoder.h5",succeed convert converter work least branch tried gan converter many gan converter take size argument image image face else self original whereas self image size tried remove size gave another message convert reason list index must masked converter work gan obviously find,issue,negative,positive,positive,positive,positive,positive
371938110,"@Apollo122 It is not empty it is full of well aligned faces that do not need to be checked. 
It is not created automatically but is what newbies would use and if it is slow it would discourage use. 

I am just raising the issue because I ran this pull request among merges with others and it made my convert time really bad (even without seamless). I cannot say this is the culprit but I wanted to bring it up. For all I know it could have been a bad conflict resolution I made between pulls what caused this, so if it seems negligible to you all I don't want to hold back the merge of the PR. Thanks   ",empty full well need checked automatically would use slow would discourage use raising issue ran pull request among made convert time really bad even without seamless say culprit bring know could bad conflict resolution made negligible want hold back merge thanks,issue,negative,negative,negative,negative,negative,negative
371937020,"Go for it. No problem for other PRs, you did enough job already. If you merge this, can you ""squash and merge"" or you prefer otherwise?",go problem enough job already merge squash merge prefer otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
371936655,"Checking for the existence of a folder or a file will be negligible.  Unless you're accessing files over a network, you'll be able to verify hundreds or thousands of files a second without difficulty.  That said, this can be fixed so it only works if you use the -a option.  If you're not interested in the feature, don't include the aligned folder command line option.",existence folder file negligible unless network able verify second without difficulty said fixed work use option interested feature include folder command line option,issue,positive,positive,positive,positive,positive,positive
371936631,"If it's cool with everyone, I'll merge this in a few hours?? Seems like people are waiting on this one to do other stuff. I'm afraid it'll create a lot of conflicts in other PRs though.",cool everyone merge like people waiting one stuff afraid create lot though,issue,positive,negative,negative,negative,negative,negative
371936140,"@babilio Why would you have a empty folder named ""aligned"" if you don't want to use this feature? Also I don't think this folder named aligned is created automatically so I don't see the problem",would empty folder want use feature also think folder automatically see problem,issue,negative,negative,neutral,neutral,negative,negative
371935635,@Apollo122 I was experimenting with weakening the generator/discriminator. Kind of like what's done in https://github.com/deepfakes/faceswap/pull/246. I didn't fully explore it because it's hard to gauge a usable ratio between the 2. It was producing masks more similar to what I was getting with shaoanlu's but I can't say for the occlusion cuz I didn't check. It's in `oatssss:update-GAN-v2-tests`,weakening kind like done fully explore hard gauge usable ratio similar getting ca say occlusion check,issue,negative,positive,positive,positive,positive,positive
371934774,"So would the only way to not use this is to have my ""aligned"" folder named something else. Do you or anyone else have an idea of how this affects performance of convert?

I think the scenario I am thinking more of is like if I have a video of frontal, nicely extracted faces that I don't delete, it is inefficient to verify they exist in the align folder. Specially if it is looking for that folder ""under the hood"".

I definitely would like hear what others think. And I can run tests to compare performance too. ",would way use folder something else anyone else idea performance convert think scenario thinking like video frontal nicely extracted delete inefficient verify exist align folder specially looking folder hood definitely would like hear think run compare performance,issue,positive,positive,positive,positive,positive,positive
371934735,"I created this tool for myself, and its functionality enough for me.
Anyone can improve it after merge.",tool functionality enough anyone improve merge,issue,negative,neutral,neutral,neutral,neutral,neutral
371934667,"I did that exactly on some video -you can guess what the partial occlusion is. It didn't work for me. Im not saying it is not working for everyone but didn't see a comment about it. Have you get a proper mask?
You were experimenting with data-generator and said you got the proper mask preview, how did that work out?",exactly video guess partial occlusion work saying working everyone see comment get proper mask said got proper mask preview work,issue,negative,positive,neutral,neutral,positive,positive
371933406,Merge GAN first please. ,merge gan first please,issue,negative,positive,positive,positive,positive,positive
371931181,"@Apollo122 I don't think you should be training with faces that are partially occluded. If you do, I think you're telling it that partially occluded faces are acceptable. The more occluded faces you have in the training set, the more it'll think that's what you want. If you only have a few occluded faces, then yea the preview for those images even though they're in the training set should probably have proper occlusion masks since it should understand from all the other un-occluded faces that an occluded face isn't the norm. Where the masks should come into play is when you're _converting_ partially occluded faces. It should recognize the parts of the image that are face based on its training, and parts that aren't. I think the way you can gauge this through the preview is if it shows black for the background behind the face, then you know it understands some concept of what's face and what's not.",think training partially think telling partially acceptable training set think want yea preview even though training set probably proper occlusion since understand face norm come play partially recognize image face based training think way gauge preview black background behind face know concept face,issue,positive,negative,negative,negative,negative,negative
371927843,"@babilio this looks for an aligned folder in the default location, but if it doesn't find one, it runs with the original behaviour of just converting everything from the input (not aligned) directory. However, if it does find an aligned folder, but it's empty, it won't convert anything since it thinks you deleted everything from the aligned folder. I'll add a note in the usage message about this. If people really dislike that it tries to find an aligned folder by default we can make it not do that, but I think you'll really only run into a problem if you have an empty aligned folder, in which case why not just delete it?",folder default location find one original behaviour converting everything input directory however find folder empty wo convert anything since everything folder add note usage message people really dislike find folder default make think really run problem empty folder case delete,issue,negative,positive,positive,positive,positive,positive
371925790,@oatssss yeah man I know you have been busy with faceswap :) it's not about quality though mask feature doesn't work like it should be. It should handle occlusions not remove it. At least that's what I see on preview window. I know that you want to merge this we can do that and open another issue about mask. It wouldn't be ideal but lets do it if you are comfortable,yeah man know busy quality though mask feature work like handle remove least see preview window know want merge open another issue mask would ideal comfortable,issue,positive,positive,positive,positive,positive,positive
371921278,Great! It would be a nice feature. Seamless clone is useful except flickering but we can minimize it with hm,great would nice feature seamless clone useful except flickering minimize,issue,positive,positive,positive,positive,positive,positive
371921196,"@Apollo122 I haven't tried myself recently as I've been addressing other things that I think are also worthwhile for other models since not everyone is using gan. You were able to get good results with the trump/cage dataset right? I don't think any major changes to the model/trainer were implemented afterwards, so it leads me to believe that it's more an issue with the training data. It still doesn't explain why the same data set I used with shaoanlu's turned out worse here.

@Kirin-kun I think for face A, the 3rd column is what's actually used as the mask and for face B, the 2nd. Are your convert results looking good?",tried recently think also since everyone gan able get good right think major afterwards believe issue training data still explain data set used turned worse think face column actually used mask face convert looking good,issue,negative,positive,positive,positive,positive,positive
371918972,"@Apollo122 when seamless is on, seamless clone is the last step in the process to patch it back into the image. What I can do is if both seamless and histogram matching are on, after the seamless clone, pass it through to be color-corrected then hand it over to the regular facehull mask to patch it back in, instead of seamless cloning it in. Trying to seamless clone it back in after color-correction might just bring the flicker back, not sure so I'll experiment with it.",seamless seamless clone last step process patch back image seamless histogram matching seamless clone pas hand regular mask patch back instead seamless trying seamless clone back might bring flicker back sure experiment,issue,positive,positive,neutral,neutral,positive,positive
371918331,"I prefer using something a bit more high level than input().  I suggest something like

if cv2.waitKey(1) & 0xFF == 13:
        break

This will break the loop if the 'enter' key is pressed in the window but will not block on ctrl-c.",prefer something bit high level input suggest something like break break loop key window block,issue,negative,positive,neutral,neutral,positive,positive
371917118,"Ok, thanks. For #251, #260, #252, I think they are hot enough so if they stay a bit more, it won't be a big problem. Anyhow, I will possibly have also conflict so merging ""right now"" will likely take one or 2 days...",thanks think hot enough stay bit wo big problem anyhow possibly also conflict right likely take one day,issue,negative,positive,positive,positive,positive,positive
371915570,"I say we merge all the ones you've suggested as merge, as well as #260 and #252.  Though 252 should probably be in a ""tools"" folder.

One note, if we merge both #256 and #251 we'll need to patch the IAE model for Mutli GPU.  I've already done it in the https://github.com/bryanlyon/faceswap/tree/iae_multigpu but I am reluctant to submit a PR for something that relies on two existing PRs both being accepted.

I agree with all your closings.",say merge merge well though probably folder one note merge need patch model already done reluctant submit something two accepted agree,issue,positive,neutral,neutral,neutral,neutral,neutral
371915123,"@bryanlyon 

>  Obviously that isn't a huge deal, but changing the function of a command line switch is something we should avoid.

I've taken this on board, and changed the command line switch to an option (currently accepting on and off) so that I can more easily amend in future if needs be.

@babilio 

> The problem right now is that there is nothing that deletes the alignments after extraction

Indeed, so it seems unnecessary for now. However, changing the command to take arguments hopefully means that if a change moves in that direction, this could be amended fairly easily by adding more options.",obviously huge deal function command line switch something avoid taken board command line switch option currently easily amend future need problem right nothing extraction indeed unnecessary however command take hopefully change direction could fairly easily,issue,positive,positive,positive,positive,positive,positive
371910019,"I think you are right for now @torzdf. The problem right now is that there is nothing that deletes the alignments after extraction so if you do a run through with off, delete bad faces, run again with forced angle, it will have the bad entry in the alignments. So if you tried using skip extracted then it would get skipped anyways.",think right problem right nothing extraction run delete bad run forced angle bad entry tried skip extracted would get anyways,issue,negative,negative,negative,negative,negative,negative
371907704,"I'm not sure I follow your second point.

As to the first. the main issue with what your saying is that to detect all faces would mean rotating every single frame the full amount, which would lead to significant (and probably unacceptable) slowdown. It is still possible to use the --filter flag to filter faces with the image-rotator. I haven't used it myself, but if you are just looking to identify a particular face, this would seem to be the way to go, rather than looking to re-invent that functionality here. That way if the face you are looking for is not detected and another one is, then that face would be ignored, the rotation will be performed and it will scan again for the filtered face.

Ultimately I needed to make a trade-off between speed and effectiveness.  The best way to guarantee not to pick out a face you don't want is to mask the video prior to extracting faces.

That being said, I could change the command line flag to take options:
- off: default. Don't perform rotations (current faceswap behaviour)
- on : only rotate the image if a face isn't found (current rotator behaviour)
- force: rotate every frame all iterations (would capture all faces, and probably a lot more false positives, and would slow down the extract significantly)
- only-partial: Don't attempt to extract from upright frame, only perform rotations, stop when face is found
- only-full: Don't attempt to extract from upright frame, only perform rotations, but perform them all (again slow).

To be honest, this seems like overkill to me (I certainly would only ever use the 'on' option).

I'm interested to see what other people's use case would be though, before embarking on a code overhaul. At the minimum, though, I could change the flag to accept arguments (just on or off, default off), so I could easily add options down the line.",sure follow second point first main issue saying detect would mean rotating every single frame full amount would lead significant probably unacceptable slowdown still possible use filter flag filter used looking identify particular face would seem way go rather looking functionality way face looking another one face would rotation scan face ultimately make speed effectiveness best way guarantee pick face want mask video prior said could change command line flag take default perform current behaviour rotate image face found current rotator behaviour force rotate every frame would capture probably lot false would slow extract significantly attempt extract upright frame perform stop face found attempt extract upright frame perform perform slow honest like certainly would ever use option interested see people use case would though code overhaul minimum though could change flag accept default could easily add line,issue,positive,positive,positive,positive,positive,positive
371907166,"As for it being a separate tool the idea is that you can run it to clean up the actual alignment files. This can be useful not only for convert, but to perform extraction again with different detector or options, and for portability. So you could run the tool without having to do convert.",separate tool idea run clean actual alignment useful convert perform extraction different detector portability could run tool without convert,issue,positive,positive,positive,positive,positive,positive
371906062,"@bryanlyon I mostly agree with you the problem is that right now even if you don't provide the command line option it looks automatically for ""aligned"" folder and it's basically turned on. I might be misunderstanding the commits, so please do tell me if I'm wrong.

I think aligned commonly used folder name by people. So basically this is on by default.  I am not sure that the performance decrease is negligible since it does searching every time for the image on aligned folder. So as it is, with my understanding, I don't agree with the pull request. If it was 100% optional, I would be ok with it. If someone could test performance of convert with this and without this and it is negligible, I'd be ok with this. I can test it later today myself. 

I think this is a very awesome feature, but if I have a video where I don't have to delete faces I don't want the feature on if it adds to convert time.

Again my understanding might be off cause I can be kind of stupid, so let me know if my concern is invalid.",mostly agree problem right even provide command line option automatically folder basically turned might misunderstanding please tell wrong think commonly used folder name people basically default sure performance decrease negligible since searching every time image folder understanding agree pull request optional would someone could test performance convert without negligible test later today think awesome feature video delete want feature convert time understanding might cause kind stupid let know concern invalid,issue,positive,positive,positive,positive,positive,positive
371900728,"I would agree if we were in a company where everyone is similarly involved in the project, but it is a bit different here. This issue is exceptional as we had some old PR not reviewed and quite a lot of new PRs, plus the GAN that is long awaited.

In such an open source project, some PRs are popular and we know quite fast if it is ready or not, for the others, it is not really clear. And a test branch isn't really helpful in these cases because for some PRs, the decision is not to know if they are ready to be released or not, but to know if they have to be present in the project or not, and for that I need to take decisions.

The purpose of this issue is to make clear what actions I intend to take and I'm just waiting for feedback from people who disagree with my decisions.

And the 3 possibilities I have, for each PR is: merge, let it open, close. So I divided this into 3 categories:
For **To merge right now**, they will be merged unless someone convince me that it is not ready.
For **Still under consideration**, they will remain open and under discussion, until they are ready to merge (or are closed because no consensus is made), like any normal PR. So these one continue to live, and no specific action will be taken from my part.
For **To be closed**, they will be closed unless someones tells me it should be retained or merged.

Sorry if I was not clear enough, I understand this can be confusing.",would agree company everyone similarly involved project bit different issue exceptional old quite lot new plus gan long open source project popular know quite fast ready really clear test branch really helpful decision know ready know present project need take purpose issue make clear intend take waiting feedback people disagree merge let open close divided merge right unless someone convince ready still consideration remain open discussion ready merge closed consensus made like normal one continue live specific action taken part closed closed unless sorry clear enough understand,issue,positive,positive,neutral,neutral,positive,positive
371899641,"Apologies for the double post, but I came up with a way to make it work.  This could be adopted and in the future if we enable explicit rotate then ""auto rotate check"" could be enabled when no number is passed, but if a number is passed, the image will be explicitly rotated the degrees specified and then run through face recognition at that angle.",double post came way make work could adopted future enable explicit rotate auto rotate check could number number image explicitly rotated run face recognition angle,issue,negative,neutral,neutral,neutral,neutral,neutral
371898948,"In my experience, videos with tilted faces will have both an upright face and a tilted face.  The upright face is often not the face that is desired.  This PR solves the problem only if there is not upright face.

My main concern is that if this is added as it is, then future modification to enable that flexibility would harm backward compatibility with command line options.  Obviously that isn't a huge deal, but changing the function of a command line switch is something we should avoid.",experience upright face face upright face often face desired problem upright face main concern added future modification enable flexibility would harm backward compatibility command line obviously huge deal function command line switch something avoid,issue,negative,positive,positive,positive,positive,positive
371896974,"Ok, I see what you're saying. That should be a relatively straightforward add, but I think I would leave it as an improvement for after it gets merged, if it does, in its current form.

I may be wrong, but I envisage that most people will activate it when they know they have faces in their target video that may be problematic, so it makes sense to pass all frames in one go, rather than doing upright first and then doing a second pass to attempt to get rotated faces (it would be slower that way).

That said, adding options to the command line argument to check normal and rotated or just rotated may be something I could look to instigate down the line, but I don't see it as a must have. Ultimately it will only perform rotation on frames that it can't find a face on, so if a video is passed in with 99% upright faces, the slowdown will not be high. 

Telling it just to rotate would rotate every frame passed in, regardless of whether it was required or not.",see saying relatively straightforward add think would leave improvement current form may wrong envisage people activate know target video may problematic sense pas one go rather upright first second pas attempt get rotated would way said command line argument check normal rotated rotated may something could look instigate line see must ultimately perform rotation ca find face video upright slowdown high telling rotate would rotate every frame regardless whether,issue,negative,positive,neutral,neutral,positive,positive
371896700,"I disagree on this being a separate tool.  If you don't want to use it you wont provide the command line option.  This being a part of the conversion makes it most convenient as you know that it wont process deleted faces as long as the command line option is there.  If it's a separate tool then you'll have to remember to run that tool

Though I agree that the alignment.json should be modified too (if requested).

However, I would note that I find that a short training session on the faces on the actual video data (after completing general training on pictures excluding the target video) helps to create a better result.",disagree separate tool want use wont provide command line option part conversion convenient know wont process long command line option separate tool remember run tool though agree however would note find short training session actual video data general training excluding target video create better result,issue,positive,positive,neutral,neutral,positive,positive
371893609,"I apologize, my message was incomplete.  I mean rotate explicitly when told to.  As in don't try to check for faces upright first, but when given the -r command only try with rotation.  Since trying upright first may find the same (incorrect) face and then skip the rotate.  Perhaps even with explicit angles listed (-r 90, -r 180, or 270).",apologize message incomplete mean rotate explicitly told try check upright first given command try rotation since trying upright first may find incorrect face skip rotate perhaps even explicit listed,issue,negative,positive,neutral,neutral,positive,positive
371892270,"I agree that direct discussion should exist on the individual PRs.  This separate discussion is confusing, especially if we want to avoid discussing specific improvements for the individual PRs.

I believe that instead of an issue for merging a collection of PRs, which is obviously causing confusion, we should discuss them on the individual PRs and/or merge into a dev/test branch and then promote to master when appropriate as @babilio suggested.",agree direct discussion exist individual separate discussion especially want avoid specific individual believe instead issue collection obviously causing confusion discus individual merge branch promote master appropriate,issue,negative,positive,neutral,neutral,positive,positive
371891945,"It isn't automatic. It's run with the command line switch -r (--rotate-images), so is fully optional.

If the switch isn't specified, then no rotation will be attempted, and it will run as it always has",automatic run command line switch fully optional switch rotation run always,issue,negative,neutral,neutral,neutral,neutral,neutral
371891502,"Doesn't seem to have prominent issues, but 1.5.0 doesn't produce warning outputs. So, I'll revert back to 1.5.0",seem prominent produce warning revert back,issue,negative,positive,positive,positive,positive,positive
371891212,"I like this PR, especially with the recent --skip-existing RP.  However, I think that it should not be automatic, as sometimes you want to force a rotation or a rotation might find more false positives.  I recommend a command line switch on the extract.  This way, you can run it right side up, prune bad pictures and then run again on a rotation with the --skip-existing to merge with the already done extractions.",like especially recent however think automatic sometimes want force rotation rotation might find false recommend command line switch extract way run right side prune bad run rotation merge already done,issue,negative,negative,negative,negative,negative,negative
371889616,"@kcimit that's why it is in the **under consideration** section. It is open, and waits for feedback and improvments",consideration section open feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
371888489,"@bryanlyon Ok I understand but it was confusing.

If you are against the PR because the tool has a bug, I'm ok with that and you should tell it in the PR. As long as there are important bugs, the PR won't be merged. 

If you are against the tool in general, I can't agree as it is here for convenience. This can help people and I'm fine with that. But I now understand that it was not your point",understand tool bug tell long important wo tool general ca agree convenience help people fine understand point,issue,positive,positive,positive,positive,positive,positive
371887645,"@Clorr , I think this is what we are trying to achieve here, PR from @iperov could be considered as a good start, needs massaging though. But no need to demotivate contribuitors here - some people voiced for it.",think trying achieve could considered good start need though need people voiced,issue,negative,positive,positive,positive,positive,positive
371887115,"A separate tool is helpful, but should also (optionally) modify the alignments.json so that it works with converting the files and not just for training.",separate tool helpful also optionally modify work converting training,issue,negative,neutral,neutral,neutral,neutral,neutral
371885302,"@iperov Your loss balancing and sorting are both good.

Sorry, I was just speculating on a different kind of extreme sorting. Your loss balancing got me thinking about what other optimizations are possible.",loss balancing good sorry different kind extreme loss balancing got thinking possible,issue,negative,positive,positive,positive,positive,positive
371882559,"@iperov @bryanlyon @babilio no problem to integrate tool as it is, if someone disagree, plz discuss in the PR",problem integrate tool someone disagree discus,issue,negative,neutral,neutral,neutral,neutral,neutral
371879383,"Yeah @iperov I wrongly thought that creating the path would fail if it it didn't find the file but it's just a string. So I changed that.

I know that English is not your first language but I'm gonna ask you to be more cordial and friendly that just typing WTF! You can say, ""Please see this"" and it will have the same effect. We are all just trying to improve the tool. I can't tell if you get upset with people and their edits or if it's just language but in any case there is no need to be aggressive when everyone is working with the same goal.",yeah wrongly thought path would fail find file string know first language gon na ask cordial friendly say please see effect trying improve tool ca tell get upset people language case need aggressive everyone working goal,issue,negative,negative,neutral,neutral,negative,negative
371873998,"@babilio why not, but I'm not very familiar with that type of workflow, and I thought PRs are already handy as they can be checkout and locally tested by a pull

@kcimit yes, the PR comes with all main GAN versions AFAIK

@iperov I asked you to do a separate tool as you proposed a new command and I don't want to have new commands for too specific behaviors. However if `sort` can be integrated in the extract, it is even better because it will be integrated seamlessly in the process. But it is up to you to see and discuss with others if you all agree to a common workflow. Note that if there is no consensus about that, we still can just merge the separate tool",familiar type thought already handy locally tested pull yes come main gan separate tool new command want new specific however sort extract even better seamlessly process see discus agree common note consensus still merge separate tool,issue,positive,positive,positive,positive,positive,positive
371871986,"hi iperov, would be nice to have a possibility to remove or move all visually similar images, including blurred ones without renaming the rest.",hi would nice possibility remove move visually similar blurred without rest,issue,negative,positive,positive,positive,positive,positive
371871287,"#255 image sort tool - I wrote it as separated tool as you request @Clorr 
",image sort tool wrote tool request,issue,negative,neutral,neutral,neutral,neutral,neutral
371870810,"@Clorr what do you think of having a dev/test branch, in that case we could get PR requests in that branch quicker and maybe with less scrutiny, let devs test each other features and integrate them. Then, every so often just clone a good checkpoint to master? This could have less risk on what end users get.",think branch case could get branch maybe le scrutiny let test integrate every often clone good master could le risk end get,issue,negative,positive,positive,positive,positive,positive
371870498,Ok. I'll take a look into that and make a PR if possible.,take look make possible,issue,negative,neutral,neutral,neutral,neutral,neutral
371869932,"Note that there is a `dlib.DLIB_USE_CUDA` flag in Python, so we can rely on this to show a warning or to disable the multiprocess if someone uses CUDA in dlib",note flag python rely show warning disable someone,issue,negative,neutral,neutral,neutral,neutral,neutral
371863939,"Agreed, the detect with all detectors in dlib_detectors was unnecessarily reusing the less accurate hog model after running the computationally more intensitve cnn model even if the user specifys just the cnn. Good suggestion to add an -all flag to retain current code logic.

There are some other optimization issues I was looking at as well in the extractor ( scaling to 2048, upsampling, calling the dlib detector as a batch instead of with single images... )",agreed detect unnecessarily le accurate hog model running model even user good suggestion add flag retain current code logic optimization looking well extractor scaling calling detector batch instead single,issue,positive,positive,positive,positive,positive,positive
371863222,"best for me extract all faces, sort them, and delete unwanted.",best extract sort delete unwanted,issue,positive,positive,positive,positive,positive,positive
371860248,"@acsaga thanks for this information. 

I'm always fascinated to see how versatile NN are... How many faces do you think we could store in one model? Because in this case, we could add more intermediate layers for more people, don't you think?

Btw, if you have some inspiration, feel free to give more information in your __init.py__ about yourself, credits, license and so on...",thanks information always fascinated see versatile many think could store one model case could add intermediate people think inspiration feel free give information license,issue,positive,positive,positive,positive,positive,positive
371858063,"Traceback (most recent call last):
  File ""faceswap.py"", line 10, in <module>
    from scripts.extract import ExtractTrainingData
  File ""/superm/data/Projects/faceswap/scripts/extract.py"", line 7, in <module>
    from lib.cli import DirectoryProcessor
  File ""/superm/data/Projects/faceswap/lib/cli.py"", line 7, in <module>
    from lib.faces_detect import detect_faces, DetectedFace
  File ""/superm/data/Projects/faceswap/lib/faces_detect.py"", line 1, in <module>
    from lib import FaceLandmarksExtractor
  File ""/superm/data/Projects/faceswap/lib/FaceLandmarksExtractor/__init__.py"", line 1, in <module>
    from .FaceLandmarksExtractor import extract
  File ""/superm/data/Projects/faceswap/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py"", line 6, in <module>
    import keras
  File ""/local/lib/python3.5/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/local/lib/python3.5/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/local/lib/python3.5/site-packages/keras/utils/conv_utils.py"", line 3, in <module>
    from .. import backend as K
  File ""/local/lib/python3.5/site-packages/keras/backend/__init__.py"", line 80, in <module>
    from .theano_backend import *
  File ""/home/nikkelitous/.local/lib/python3.5/site-packages/keras/backend/theano_backend.py"", line 3, in <module>
    import theano",recent call last file line module import file line module import file line module import file line module import file line module import extract file line module import file line module import file line module import file line module import file line module import file line module import,issue,negative,neutral,neutral,neutral,neutral,neutral
371853434,"@Apollo122 Yes, this model use the same converter as the Original model.
@kellurian Thanks, I will add the multiGPU option and test it later.

@Clorr Yes, theoretically it can be interpreted as some kind of variational autoencoder. 

The intuitive idea behind this model is that: A face has two types of information - appearance and facial expression. 
What IAE model does is:
1. Extract face information from a face image. (Encoder)
2. Split the face information to two parts: facial expression and appearance. (intermediate layers, inter_A for appearance of face A, inter_B for appearance of face B, inter_both for facial expression of A and B)
3. Combine face_A's facial expression and face_B's appearance as new information. (Concatenate intermediate layers)
4. Generate new face image from new information. (Decoder)

Actually the original model does the same thing. IAE Model gets better result because it separates the steps into different layers. So that every layer focuses on only one task.
The original model mixes the steps: encoder does task No.1 and stores facial expressions. Decoder stores appearance and does task No.4. So it's hard to train.

",yes model use converter original model thanks add option test later yes theoretically kind variational intuitive idea behind model face two information appearance facial expression model extract face information face image split face information two facial expression appearance intermediate appearance face appearance face facial expression combine facial expression appearance new information concatenate intermediate generate new face image new information actually original model thing model better result separate different every layer one task original model task facial appearance task hard train,issue,positive,positive,positive,positive,positive,positive
371829230,"@Apollo122 I'm still training a GAN model, to see where it goes, as we speak and I have white columns on second column for face A and on third column for face B. I think they are mixed up somewhere.

![gan](https://user-images.githubusercontent.com/36699120/37212326-08966b02-23af-11e8-850e-49cd5d0347ae.png)

With these numbers:

![cmd](https://user-images.githubusercontent.com/36699120/37212394-480e7c8e-23af-11e8-9ed7-226870097b92.png)
",still training gan model see go speak white second column face third column face think mixed somewhere gan,issue,negative,neutral,neutral,neutral,neutral,neutral
371826640,@oatssss so you are not getting full white columns anymore on mask preview?,getting full white mask preview,issue,negative,positive,positive,positive,positive,positive
371822418,"@cagkanciloglu @Apollo122 I think people have reported mixed results with the mask. I haven't been able to find any differences between the model/trainer here and shaoanlu's.

@babilio keras_vggface is only required when you turn on preceptual loss. I will add it to the requirements doc with a note about the tensorflow-cpu/gpu issue.",think people mixed mask able find turn preceptual loss add doc note issue,issue,negative,positive,positive,positive,positive,positive
371822296,"A small example on how to use the knn-filtering. If you have example images of personA, personB, personC and personD and want to extract only personA faces:

    python3 faceswap.py extract -i video/ -o faces/ -f personA/204635.jpg personA/2015555.jpg -n personB/3266.jpg personC/463.jpg personD/653262.jpg",small example use example persona want extract persona python extract,issue,negative,negative,negative,negative,negative,negative
371794084,"Obviously, I'm biased, but I'd really like to see #253 added, so I can work on other areas. It's an optional flag, and I haven't had any issues with it. In the unlikely event that something does come up, I will be on hand to hotfix.

I should add, you're doing a great job, and it is probably a bit of a headache administrating all of this!

Cheers!",obviously really like see added work optional flag unlikely event something come hand add great job probably bit headache,issue,positive,positive,positive,positive,positive,positive
371787988,@oatssss can we use this together with seamless clone to remove the flicker? If we specify -seamless true and -mh true will it first use seamless clone then mh to correct the flicker?,use together seamless clone remove flicker specify true true first use seamless clone correct flicker,issue,positive,positive,positive,positive,positive,positive
371785358,Ok I meant the face filtering feature. Filter based on k-nearest neighbours.,meant face filtering feature filter based,issue,negative,neutral,neutral,neutral,neutral,neutral
371782352,"This looks fine to me.

On 9 Mar. 2018 9:48 pm, ""ruah1984"" <notifications@github.com> wrote:

> GAN 2.1 i think we shall test more to confirm
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/264#issuecomment-371779349>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEePQD8bRP2tDYtpu1Yc3XlXaY0Z6Xks5tcl3zgaJpZM4SkDXp>
> .
>
",fine mar wrote gan think shall test confirm thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
371780349,"after 18 hours of training there is no more loss changes (every 10 min):
![2018-03-09_13-45-59](https://user-images.githubusercontent.com/8076202/37203667-eb60baa8-23a7-11e8-9779-1112808dde68.png)


look at comparison video SFW
convert options same
[Link Removed]


at left - Original but my modified ""hi-res"" decoder:
```
def Decoder(self):
        input_ = Input(shape=(8, 8, 512))
        x = input_
        x = self.upscale(512)(x)
        x = self.upscale(256)(x)
        x = self.upscale(128)(x)
        x = self.upscale(64)(x)
        x = self.upscale(32)(x)
        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)
        x = NearestNeighborDownsampler()(x)
        x = BicubicDownsampler()(x)        
        return KerasModel(input_, x)
```
so I got more detailed eyes

at right - subj IAE 

now compare problem places:
[Images removed]
IAE better.

Now I will launch IAE but with ""hi-res"" decoder.





",training loss every min look comparison video convert link removed left original self input return got detailed right compare problem removed better launch,issue,negative,positive,positive,positive,positive,positive
371779349,GAN 2.1 i think we shall test more to confirm ,gan think shall test confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
371777385,this is good for cloud training like google colaboratory. please merge this,good cloud training like please merge,issue,positive,positive,positive,positive,positive,positive
371775722,"@acsaga for my knowledge, is there some theoritical background for this? or is it the result of your experiment? It is a kind of variational autoencoder, isn't it?",knowledge background result experiment kind variational,issue,positive,positive,positive,positive,positive,positive
371764263,Not sure why you have something related to theano. If confirmed please open an issue in faceswap-playground as this is more related to install,sure something related confirmed please open issue related install,issue,positive,positive,positive,positive,positive,positive
371761550,"Ill try lol, I have no idea what Im doing, I need to maybe get the blur score and do something with it hehe.",ill try idea need maybe get blur score something,issue,negative,negative,negative,negative,negative,negative
371761215,"Yeah, I made multiple tests and faceswap's CNN extractor is now a lot better than FA. And faster.

Actually, the warning about ""may fail on large images"" is obsolete I think (at least for middle range GPUs) : I fed it large jpg images (3177x4770), 16Mb on disk, from a camera and it extracted the faces without complaining and it gave really crisp 256x256 faces.

My adapter is a GTX 1060 6Gb and the extractor works really good now, since the corrections that have been made.

FakeApp (at least 2.2) is a huge memory hog. If there is normal RAM available, it will use everything.",yeah made multiple extractor lot better fa faster actually warning may fail large obsolete think least middle range fed large disk camera extracted without gave really crisp adapter extractor work really good since made least huge memory hog normal ram available use everything,issue,negative,positive,positive,positive,positive,positive
371759034,"i dont need this feature for myself, but you can implement it and create new PR after my PR will be merged",dont need feature implement create new,issue,negative,positive,positive,positive,positive,positive
371756858,"@iperov can I ask for feature request lol?
-by cull, its sort of like sort -by blur, but deletes all pics that fall below a set threshold for blur, its hard to make  decision of whats blurry or not when dealing with multiple sets. Id rather know Ive culled to the same standard of pics mathematically, from each different set rather than what my mind thinks is blurry.",ask feature request cull sort like sort blur fall set threshold blur hard make decision whats blurry dealing multiple id rather know standard mathematically different set rather mind blurry,issue,negative,negative,neutral,neutral,negative,negative
371750221,"Just my 2 cents: I think this would be better as a separate tool. In my use case, at least, I do not train on every face discovered in a 25fps+ video, therefore I have no need to keep the extracted faces after generating alignments.json. 

Ideally workflow would be:

- Extract all frames to generate alignments.json
- Manually delete unwanted faces from extracted faces folder
- Run tool to update alignments.json
- Delete all faces from the now unneeded faces folder

The proposed solution requires that faces are kept, when they are no longer required.

This is just my opinion for my use case, and either way it would certainly be useful. Motion tracking and masking (as I currently do) can be fiddly! ",think would better separate tool use case least train every face discovered video therefore need keep extracted generating ideally would extract generate manually delete unwanted extracted folder run tool update delete unneeded folder solution kept longer opinion use case either way would certainly useful motion currently,issue,positive,positive,positive,positive,positive,positive
371745930,"@babilio ,i run the shaoanlu jupyter notebook at the same env,  and it will install keras-vgg once you run it. and it doesn't create any issue for this repo. you can download here 
 https://github.com/rcmalli/keras-vggface
",run notebook install run create issue,issue,negative,neutral,neutral,neutral,neutral,neutral
371743468,"Hmmm, I did not notice any difference on convert. I found extract was slower if there were lots of images with no faces/at awkward angles, but that is expected.

Convert has to do less work: it checks the rotation from alignments.json, (which it already has loaded) and only rotates the image if a non zero value is found. Obviously if a non zero value is found, it needs to rotate the image to perform the swap and then rotate back to the correct orientation, but unless your video is made up of entirely upside down people, the speed loss should be marginal.

If there isn't an alignments.json, it should just default to 0 rotation, so would never rotate the image.

Would be interested if anyone else is having issues, I will test more, but am unable to replicate at the moment.

For what it's worth, I always have problems with convert being fairly slow, particularly if I'm using seamless when it is just ridiculous. Also the speed can vary significantly between different frame sets, with no obvious difference.",notice difference convert found extract lot awkward convert le work rotation already loaded image non zero value found obviously non zero value found need rotate image perform swap rotate back correct orientation unless video made entirely upside people speed loss marginal default rotation would never rotate image would interested anyone else test unable replicate moment worth always convert fairly slow particularly seamless ridiculous also speed vary significantly different frame obvious difference,issue,negative,negative,neutral,neutral,negative,negative
371742372,"People already tried this PR under the issue and GAN PR. @oatssss if you are comfortable you can merge it. Also I find this pretty useful, I'm fine with manually going over the frames and delete the ones I don't want.",people already tried issue gan comfortable merge also find pretty useful fine manually going delete want,issue,positive,positive,positive,positive,positive,positive
371741313,@oatssss how about mask bug? Has it been resolved? Last time I tired it just removed the obstacles,mask bug resolved last time tired removed,issue,negative,negative,negative,negative,negative,negative
371740518,"Does keras_vggface needs to be installed separately? Is it just for perception loss? We should add a note to readme or even the requirements? It was kind of tripping me up because the pip install would remove my tensorflow-gpu and just force tensorflow on cpu, which had to be uninstalled and reinstalled gpu version. ",need separately perception loss add note even kind tripping pip install would remove force uninstalled version,issue,negative,positive,positive,positive,positive,positive
371739794,"It is likely that the alignment files are different from fakeapp, as fakeapp is a kind of a black box I'm not sure how those are generated.

Regarding extraction, do you have a lot of frames without faces? If so this fix I made #259 might help once it is merged. 

Fakeapp as I far as I remember also for 1.1 used to jump up and down on gpu usage, here it is more stable, training goes way faster and will likely make up for the extra time spent on extract ;). People have been working on new training models that could make more use of your extra GPU resources. ",likely alignment different kind black box sure regarding extraction lot without fix made might help far remember also used jump usage stable training go way faster likely make extra time spent extract people working new training could make use extra,issue,positive,positive,neutral,neutral,positive,positive
371735956,"I'm happy with the state of this PR tbh, @Clorr if it's cool with you and there are no objections from others, we can merge it?",happy state cool merge,issue,positive,positive,positive,positive,positive,positive
371735496,"@iperov the folder structure change isn't specific to gan, it's really just to have it more organized as more people add models to the plugins directory. You're right though, we should have the change in master already, I'll try and do it tomorrow if nobody beats me to it",folder structure change specific gan really organized people add directory right though change master already try tomorrow nobody,issue,negative,positive,positive,positive,positive,positive
371735419,"thanks @iperov , i thought is something about the Neural network like K-neural network. i really like neural network right now. ",thanks thought something neural network like network really like neural network right,issue,positive,positive,positive,positive,positive,positive
371735225,"@iperov , actually i have try the GAN V2 , the training is good. should be not a big problem, this is the reason why Clorr are using @oatssss GAN PR to run and try it. I think @oatssss still working with some idea and improvement. Don't worry it will merge soon. i not a programmer, i also hope i can help to compile it all , what i can do now is test and feedback only with my ""heart"" ware(Hardware). I will try Clorr Model_IAE model tonight as well.  ",actually try gan training good big problem reason gan run try think still working idea improvement worry merge soon programmer also hope help compile test feedback heart ware hardware try model tonight well,issue,positive,positive,positive,positive,positive,positive
371735047,"there is nothing related to face recognition in changed files, only for face filtering",nothing related face recognition face filtering,issue,negative,neutral,neutral,neutral,neutral,neutral
371734643,"K-NN is an algorithm that searches for the K number of nearest results when deciding which would be the correct result.

In this case we are looking at K reference images which may be positive (of the actor we are interested in) or negative (some other similar looking actors). If most of the reference images that are close to the face we are looking at are positive, then we keep the face. Instead if there are some negative reference images that are closer to the current face, then we discard the image.",algorithm number nearest would correct result case looking reference may positive actor interested negative similar looking reference close face looking positive keep face instead negative reference closer current face discard image,issue,negative,positive,neutral,neutral,positive,positive
371734358,"@oatssss for example
https://github.com/deepfakes/faceswap/pull/251

Clorr wrote:

> I'm going to test it ASAP. Just a remark, we are moving to a new folder structure in the latest commits. You can check my repo to see how it is now. Recommended structure would be for you:
> 
> Create Model_IAE folder in plugins
> Create init.py like this one
> Put your files in this folder

he refers to new folder structure based on GAN PR, which still not merged.",example wrote going test remark moving new folder structure latest check see structure would create folder create like one put folder new folder structure based gan still,issue,positive,positive,positive,positive,positive,positive
371733398,"@babilio haha I literally just used iMovie to add a black box using picture-in-picture and then key-frame animated it to move with the face

@ruah1984 no worries, I'm not sad! I was really just curious why @iperov considers the gan PR a bottleneck. It's never a good thing if contributors feel like their work is being held up by something else. I tried to separate out things I added to the gan PR into separate PRs of their own, but is it cuz there's too much change going on with the gan stuff? What changes are these?",literally used add black box animated move face sad really curious gan bottleneck never good thing feel like work something else tried separate added gan separate much change going gan stuff,issue,negative,negative,negative,negative,negative,negative
371732078,"@oatssss i think @iperov  not means like this. currently we have about 20 pull request here, every people are working different thing to make things happen, and some may have some conflict, don't put it in your heart. we just need to have some one to organized all the request, then will be good. cheers UP ",think like currently pull request every people working different thing make happen may conflict put heart need one organized request good,issue,negative,positive,positive,positive,positive,positive
371731775,"@iperov as it is the tool you made doesn't work for convert because any faces you delete after sorting will still get patched on convert.

I am interested in using masks in source video though like you do what video editor would you recommend for this? When i used to use fakeapp i would go over and delete the 1,000s of faces of the other person manually haha",tool made work convert delete still get convert interested source video though like video editor would recommend used use would go delete person manually,issue,positive,positive,positive,positive,positive,positive
371730657,"@oatssss , sry I cannot, too complex and hard too test. Also @Clorr told to write it as separate tool, so I already rewrited it.
Also there are too many PRs including GAN which totally rework many files. 
GAN PR is bottleneck and awl in ass for anything new.",complex hard test also told write separate tool already also many gan totally rework many gan bottleneck awl as anything new,issue,negative,positive,neutral,neutral,positive,positive
371729621,"@bryanlyon that's a good idea, I'll work on that too.

@iperov I'm pretty comfortable with manually deleting all those bad faces, it gives me peace of mind that my dataset is good since I looked at each individual picture. Also, I never tried it, but I thought there was a face-filter feature here that tries to only extract faces matching an input face you specify. An alternate solution that I've done is with a video editor, cover the unwanted face with a black box. There's probably better programs that can track and blur a face too. As for your tool's renaming of files, maybe you can write your sort tool to also modify the alignments file with the changes it makes so nothing's out of sync. I was thinking of doing a similar sort, but not as a separate tool, as an actual step in extraction. Eventually I wanted to assign a face to 3 categories: left-profile, front, and right-profile. Since this would be done during extraction, we'd know which of the 3 folders the face would be going into and so can write it into the alignments file.",good idea work pretty comfortable manually bad peace mind good since individual picture also never tried thought feature extract matching input face specify alternate solution done video editor cover unwanted face black box probably better track blur face tool maybe write sort tool also modify file nothing sync thinking similar sort separate tool actual step extraction eventually assign face front since would done extraction know face would going write file,issue,positive,positive,positive,positive,positive,positive
371728562,"Sorry, but nothing useful.

I will try to explain (sry bad english).

Consider real case of usage.
We extracted 1500 frames from dst video. There are two faces in video.
Faces was extracted in random order such as [0][1][0][1] or [0][1][1][0] 
SO will you delete manually second face in 1500 frames ?? 
Me not. Its waste of time.
Also we cannot apply my sorttool https://github.com/deepfakes/faceswap/pull/255 for dst video, because its renaming files, then files will not match alignments.json.
So better is track mask in video editor and cut unwanted faces, or track main face mask and overlay it on original video.",sorry nothing useful try explain bad consider real case usage extracted video two video extracted random order delete manually second face waste time also apply video match better track mask video editor cut unwanted track main face mask overlay original video,issue,negative,negative,neutral,neutral,negative,negative
371728173,"This is working well and together with #259 that I created it works pretty fast on extraction 8,000 images ~ 40mins and about ~1500 where sideways or upside down and found with this. However the convert seems to be taking much longer. I have a local branch with this and #260 and it is taking 2hrs for convert, I am not sure if it is because of this pull request particularly. I can test more tomorrow. Thanks for creating this! ",working well together work pretty fast extraction sideways upside found however convert taking much longer local branch taking convert sure pull request particularly test tomorrow thanks,issue,positive,positive,positive,positive,positive,positive
371727358,"@iperov right now if you you have multiple faces or poorly detected faces and delete them from your aligned folder, when you run convert it will still patch all the faces that were detected when creating the alignments. This produces bad results. So this is helpful. See #208 However I don't think the that it should be on by default and look automatically for /aligned folder.  We should test how this impacts the performance. Right now I have a local merge of this + #253 and it is taking 2 hours to convert 8,000, it took me 40 mins to extract. I am not sure of which of the two could be causing this. I can test more tomorrow night.

Both are working as intended and as long as they are optional the performance is not a big issue I should add.",right multiple poorly delete folder run convert still patch bad helpful see however think default look automatically folder test performance right local merge taking convert took extract sure two could causing test tomorrow night working intended long optional performance big issue add,issue,negative,negative,neutral,neutral,negative,negative
371726622,"I would prefer a tool that removes deleted faces from the alignments.json file since that will make the collection more portable to other devices.  But otherwise, this functionality is incredibly useful, as the filter option is very frustrating.",would prefer tool file since make collection portable otherwise functionality incredibly useful filter option,issue,negative,positive,positive,positive,positive,positive
371726488,@deepfakesclub  cannot understand what you mean. So you agree or disagree with optional functions loss_balancing and sorting faces ?,understand mean agree disagree optional,issue,negative,negative,negative,negative,negative,negative
371724274,"It can't be used in extract, that is done outside of the models.  Perhaps another method could make the extract multi-GPU.  It's already able to do multiple CPU threads, but there is no way to force it to use CPU if you have a GPU enabled dlib.  That's something I might look at later, but it's a big change.  For my needs, I use a server with just CPUs to do the extract, so that my GPUs are free to train.  I can then use -j 24 to max out my dual 6 core CPUs.  CNN is a bit slow, but with the newest patch, you can --skip-existing to finish up the missed faces with CNN much quicker.

It can probably be moved to convert, but I haven't done enough testing, and in my experience, convert takes a less than 1/4 a second per picture, so actually might hit bandwidth limits before computation limits.",ca used extract done outside perhaps another method could make extract already able multiple way force use something might look later big change need use server extract free train use dual core bit slow patch finish much probably convert done enough testing experience convert le second per picture actually might hit computation,issue,positive,positive,neutral,neutral,positive,positive
371714229,"It looks like the issue was the Masked converter not working, which it seems you just fixed in the branch an hour ago :P 
Sorry for the confusion, I will check back if anything else occurs but it seems to work great!",like issue masked converter working fixed branch hour ago sorry confusion check back anything else work great,issue,positive,positive,neutral,neutral,positive,positive
371709083,#217 isn't merged yet so this one can go in separately if people want,yet one go separately people want,issue,negative,neutral,neutral,neutral,neutral,neutral
371707381,i thought it already merge in https://github.com/deepfakes/faceswap/pull/217 ?? any way thanks for everything ,thought already merge way thanks everything,issue,negative,positive,positive,positive,positive,positive
371703961,Looks good man.  I like what you did with this. Is it possible to bring this over to the convert and extract processes because these take uber long currently?,good man like possible bring convert extract take long currently,issue,positive,positive,positive,positive,positive,positive
371703752,"You can add the multiGpu model calls in your model files as well and they work fine, so when we get it all interposed into one model file it should work great. bryanlyon seems to be doing this well in #256 . I dowloaded and tested your model with my two GPU's and the multiGPU additons and holy crap do they run fast! Funny enough, the old model ran my GTX 980 TI's at about 40% but it was up and down, this model runs it at about 70% but it is a seems to be much more constant. But they don't work with a previously tested model @ruah1984, it'll start the training over. I like this new model idea!",add model model well work fine get one model file work great well tested model two holy crap run fast funny enough old model ran ti model much constant work previously tested model start training like new model idea,issue,positive,positive,neutral,neutral,positive,positive
371699682,"Kind of like your lossA/lossB balancing, sorting and getting rid of very similar faces probably saves time so your model isn't training the same angle to perfection, while other poses are only sampled rarely.

Basically, the ultimate version would be to bin faces by similarity (which takes into account the pose primarily, I think), calculate the loss on each subset, and then optimize by training on the worst subsets.

A simple example would be you notice that your side profiles are terrible while your full front face is very good. Out of 10,000 images, you probably have 5 side profiles and 5000 full front faces. Those side profiles are sampled rarely, so you would prioritize training the side profiles after the front view is good.

Some of us already do this at an unsophisticated level manually with data curation, but it could be done more systematically and automatically.

The pose bins would be based on the target replacement video. i.e. if there are no side poses in video A, there's no point in optimizing it.",kind like balancing getting rid similar probably time model training angle perfection rarely basically ultimate version would bin similarity account pose primarily think calculate loss subset optimize training worst simple example would notice side terrible full front face good probably side full front side rarely would training side front view good u already unsophisticated level manually data curation could done systematically automatically pose would based target replacement video side video point,issue,positive,positive,positive,positive,positive,positive
371688968,"@Apollo122 make a separate PR for the histogram matching? Yea I'll do that. The seamless option does histogram matching already, but I think sometimes it messes up lighting and flickers.

@cojosao @babilio I just tried the branch and convert is working for me, both the histogram matching and skipping deleted faces.",make separate histogram matching yea seamless option histogram matching already think sometimes lighting tried branch convert working histogram matching skipping,issue,negative,positive,neutral,neutral,positive,positive
371666312,I will reopen later ... waiting gan commit,reopen later waiting gan commit,issue,negative,neutral,neutral,neutral,neutral,neutral
371664455,Can the existing model train with this IE model again ?,model train ie model,issue,negative,neutral,neutral,neutral,neutral,neutral
371663651,"I've been doing some tests on this issue, I think it is caused by Dlib being compiled with cuda enabled.

Basically, if dlib is compiled with cuda flags, there's no way to disable cuda at runtime; hence the initialization error. 

I've reinstalled Dlib without cuda in my virtualenv and I was able to use multiprocessing, although the Extract script crashed with a MemoryError on 8GB RAM.

If anybody can confirm this. I think the -j parameter would be redundant for GPU enabled environments.",issue think basically way disable hence error without able use although extract script ram anybody confirm think parameter would redundant,issue,negative,positive,positive,positive,positive,positive
371663240,I have implemented this patch in pull request #241 along with the -g --gpu option on the command line.  This has been tested and works on all current models.,patch pull request along option command line tested work current,issue,negative,neutral,neutral,neutral,neutral,neutral
371662803,"I have added this feature with pull request #256 working in all existing models.  I have done it safely, added a command line option, and tested it.",added feature pull request working done safely added command line option tested,issue,negative,positive,positive,positive,positive,positive
371659977,"I tried this and left to train overnight and it was producing nice results. I had a smaller set of b that would normally get overfitted but with the balance gave me nice results. Any particular reason you closed this @iperov? Thanks for the work you have been doing by the way, your commits have been super useful.",tried left train overnight nice smaller set would normally get balance gave nice particular reason closed thanks work way super useful,issue,positive,positive,positive,positive,positive,positive
371608457,"Works great, really does, thought it was broken it was so fast.
-by blur, chuck out the trash, then -by similarity to get rid of obvious dupes.
Epic time saver.",work great really thought broken fast blur chuck trash similarity get rid obvious epic time saver,issue,negative,positive,positive,positive,positive,positive
371597128,"Ideally, a tool for making a face set would make a folder for each ""type"" of face and keep a single one in the original directory. Up to you afterward to move some interesting faces back to the training folder if you wish to use them.

When extracting a video, event at 1fps, you will end up with a few hundreds frames with some of them nearly identical, whereas the training process would ultimately not need them and just waste time learning them ""again"".

My B face folder is neatly prepared, with different poses and lighting. But the A folder is very tedious to prune each time I want to use a different target video.

But thanks for the work. It's a step in the right direction to make it easier to have good face sets.",ideally tool making face set would make folder type face keep single one original directory afterward move interesting back training folder wish use video event end nearly identical whereas training process would ultimately need waste time learning face folder neatly prepared different lighting folder tedious prune time want use different target video thanks work step right direction make easier good face,issue,positive,positive,positive,positive,positive,positive
371583629,"@acsaga thanks for the comparison.
Does IAE need a separate converter? Can we use the Masked converter to merge ?",thanks comparison need separate converter use masked converter merge,issue,negative,positive,positive,positive,positive,positive
371582109,@oatssss added new features for convert also such as histogram matching.  Maybe he changed some parts of it. I wonder if he can make a separate PR for that too. I don't think histogram matching exclusive to GAN.,added new convert also histogram matching maybe wonder make separate think histogram matching exclusive gan,issue,negative,positive,positive,positive,positive,positive
371573379,"@Clorr Feedback is welcome. 
I will try this model on the Trump/Cage dataset this weekend and post the result.",feedback welcome try model weekend post result,issue,negative,positive,positive,positive,positive,positive
371567825,"Original convert is does not work for me still, whether the alignments have format x0.png or x__0.png, it just copies the original image without the swap.",original convert work still whether format original image without swap,issue,positive,positive,positive,positive,positive,positive
371563183,"@Apollo122 FYI, here's a quick comparison:

**Original Model：**
loss：
![faceswap-original-loss](https://user-images.githubusercontent.com/1388563/37165662-257044cc-2338-11e8-98fe-7b322303b961.png)
output：
![faceswap-original-image](https://user-images.githubusercontent.com/1388563/37165719-46118768-2338-11e8-8a7a-093d4182253a.png)

**IAE Model：**
loss：
![faceswap-iae-loss](https://user-images.githubusercontent.com/1388563/37165793-6de76dca-2338-11e8-9998-f18e88834fb9.png)
output：
![faceswap-iae-image](https://user-images.githubusercontent.com/1388563/37165813-72fa4b5c-2338-11e8-97a3-2b8b991cef1d.png)

I trained the IAE model less time than the original model, and the original model has smaller loss function value. But you can see that the output of IAE model has better quality.",quick comparison original trained model le time original model original model smaller loss function value see output model better quality,issue,positive,positive,positive,positive,positive,positive
371554039,"> I'd rather go for a tools/ folder where we put utility scripts which will be run directly. Can you do this?

ok i will try",rather go folder put utility run directly try,issue,negative,positive,neutral,neutral,positive,positive
371553363,"Ah ah you're right, I messed up extract with source images...",ah ah right extract source,issue,negative,positive,positive,positive,positive,positive
371552967,"> As images are renamed, isn't this a problem if we wanted to use names to reconstruct a movie?

How you can reconstruct movie from aligned 256x256 faces?
Aligned folder only for trainer.",problem use reconstruct movie reconstruct movie folder trainer,issue,negative,neutral,neutral,neutral,neutral,neutral
371552400,@oatssss could you please make a separate PR for this? So people can use it for master,could please make separate people use master,issue,negative,neutral,neutral,neutral,neutral,neutral
371552394,"Otherwise, there is one drawback I see here, but maybe it is not a problem. As images are renamed, isn't this a problem if we wanted to use names to reconstruct a movie? It is for now the recommended way to convert a movie to extract images with ffmpeg and with a name that is the frame number",otherwise one drawback see maybe problem problem use reconstruct movie way convert movie extract name frame number,issue,negative,neutral,neutral,neutral,neutral,neutral
371551840,"Thanks for the PR, i think the tool is useful. However i would prefer to integrate it as a standalone utility rather than integrate it to faceswap.py because each script added to faceswap.py has it's import loaded and it's already a problem with the 3 main command we have now.

I'd rather go for a tools/ folder where we put utility scripts which will be run directly. Can you do this?",thanks think tool useful however would prefer integrate utility rather integrate script added import loaded already problem main command rather go folder put utility run directly,issue,negative,positive,positive,positive,positive,positive
371550666,"An example output, maybe side by side comparison would have been nice.",example output maybe side side comparison would nice,issue,negative,positive,positive,positive,positive,positive
371549067,Oh and I removed the count variable from handleImage because it wasn't doing anything.,oh removed count variable anything,issue,negative,neutral,neutral,neutral,neutral,neutral
371546613,"@iperov? How do you mean? I have nothing I can share, no, but results have been fine for me. Please feel free to test, any feedback is good.

This doesn't do anything complicated other than rotate the image. The alignments pulled from dlib are correct for the rotated image. The image is then rotated again (by the same amount) for applying the swap, so there shouldn't be any glitches here? I haven't done anything complicated like transposing dlib matrices. That would probably be a lot more efficient, but was beyond me at this stage.",mean nothing share fine please feel free test feedback good anything complicated rotate image correct rotated image image rotated amount swap done anything complicated like matrix would probably lot efficient beyond stage,issue,positive,positive,neutral,neutral,positive,positive
371545196,have you example where your fix can detect more faces without flip-glitches by aligner?,example fix detect without aligner,issue,negative,neutral,neutral,neutral,neutral,neutral
371544130,"Oh, and I found a bug during testing, hence my revert. You should only focus on the final commit",oh found bug testing hence revert focus final commit,issue,negative,neutral,neutral,neutral,neutral,neutral
371534936,"Seems perfect to me ;-) I can merge this right now or do you want to wait for some feedback? (If I merge, I suggest you add an issue so that others are aware of this new plugin)",perfect merge right want wait feedback merge suggest add issue aware new,issue,positive,positive,positive,positive,positive,positive
371529652,"Thanks for doing the changes. however I think you forgot to add the files. The `.gitignore` is buggy so you have to add the new files manually. I don't know which tool you are using, but with git cli, you have to do `git add -f *.py` from the folder where your files are ;-)",thanks however think forgot add buggy add new manually know tool git git add folder,issue,negative,positive,positive,positive,positive,positive
371509423,"Question: does the GANv2 models support re-training over a different faceset? 

I actually started to train sets of faceA and faceB. After a while, the masks started to show up.

![mask](https://user-images.githubusercontent.com/36699120/37157062-0f21e5fe-22e8-11e8-9db3-73e1851edbc8.png)

Then I switched the faceA set to another (but kept the faceB set identical), using the same model files, and then, the masks slowly disappeared and the columns became completely black. 

I thought that it needed time to remake the masks, but after hours of training (much longer than when the masks appeared in the first run) the columns stayed black.

I restarted the training with an empty directory and lo, the masks showed up after 1 hour.",question support different actually train show mask switched set another kept set identical model slowly completely black thought time remake training much longer first run stayed black training empty directory lo hour,issue,negative,positive,neutral,neutral,positive,positive
371496628,"As I said in #249 , this is not the way we will have more crisp faces because at some point the loss function is the problem.

However I was thinking higher res images would help on some small size features like eyes that sometimes are not really well rendered (I'm not talking about the sight direction but more on the fact that in some places eyes are just a horrible mix of pixels, and with higher res, you get something more meaningful). I wanted to see the results, now I see it's limits, but I thought it could help some others.

Also the goal of the experiment was to try to freeze the encoder so we can try training deeper decoders and this part seems to work.

On the next step, I'm trying to document myself on how to use the residual loss to train some side network (like the mask in GAN), because this project is for me a way to learn deep learning more than doing actual faceswaps",said way crisp point loss function problem however thinking higher would help small size like sometimes really well talking sight direction fact horrible mix higher get something meaningful see see thought could help also goal experiment try freeze try training part work next step trying document use residual loss train side network like mask gan project way learn deep learning actual,issue,positive,positive,neutral,neutral,positive,positive
371491266,"I also tried various decoders to reach more detailed face. No chance.
I think its because NN learning to reach average of all warped crap we input to it.

look at gif showing warped input and output

even bent nose outputs straight nose.:
![2018-03-08_17-55-44](https://user-images.githubusercontent.com/8076202/37154702-45f7f17e-22fa-11e8-9613-c561843cf818.gif)

on the left looking eyes outputs straight looking:
![14](https://user-images.githubusercontent.com/8076202/37154002-099366e8-22f8-11e8-9e48-4bf412be4203.jpg)

because all averaged. So why we expecting sharp details in averaged faces ?

Latest Daddario ^ I trained with this decoder:
```
    def Decoder(self):
        input_ = Input(shape=(8, 8, 512))
        x = input_
        x = self.upscale(512)(x)
        x = self.upscale(256)(x)
        x = self.upscale(128)(x)
        x = self.upscale(64)(x)
        x = self.upscale(32)(x)
        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)
        x = NearestNeighborDownsampler()(x)
        x = BicubicDownsampler()(x)        
        return KerasModel(input_, x)
```
[Link Removed]",also tried various reach detailed face chance think learning reach average warped crap input look gif showing warped input output even bent nose straight nose left looking straight looking sharp latest trained self input return link removed,issue,negative,positive,neutral,neutral,positive,positive
371485014,"Hi @acsaga 
Thank you for this awesome PR, it is always a pleasure to see a new model emerge!
I'm going to test it ASAP. Just a remark, we are moving to a new folder structure in the latest commits. You can check [my repo](https://github.com/Clorr/faceswap/blob/master/plugins/Model_Original/) to see how it is now. Recommended structure would be for you:
- Create `Model_IAE` folder in plugins
- Create __init__.py like [this one](https://github.com/Clorr/faceswap/blob/master/plugins/Model_Original/__init__.py)
- Put your files in this folder

Let me know if you need help or if you want me to do this for you",hi thank awesome always pleasure see new model emerge going test remark moving new folder structure latest check see structure would create folder create like one put folder let know need help want,issue,positive,positive,positive,positive,positive,positive
371473879,"@DLSauron This issue appeared suddenly for me too. It sometimes writes

C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:3492]

Several times for a while, then stops... then it comes back from time to time.

It happened in a training session which eventually stopped with a OOM problem after a long while (leak?).",issue suddenly sometimes several time come back time time training session eventually stopped problem long leak,issue,negative,negative,neutral,neutral,negative,negative
371473448,@oatssss sorry if the comments bothered you. Don't hesitate to ask for help at some point. I hope we can merge this soon ;-),sorry hesitate ask help point hope merge soon,issue,negative,negative,negative,negative,negative,negative
371452818,"Can you directly edit the file, it will make a pull request that we can review. Thanks",directly edit file make pull request review thanks,issue,negative,positive,positive,positive,positive,positive
371451075,"More layers is not a guarantee of anything. First you have to know what layer for what purpose. Also not only the layers are important but also the ""loss function"", the function that says to your model if it behaves right or not.

About layers, the model in DF is an autoencoder with an encoder part and a decoder part.

If you add a layer in encoder you may get more possible variations (but you don't know which ones and it is not guaranteed that you will have useful ones).

If you add layers in decoder, you will have higher resolution output (like what I did in #247 ) but not necessarly more fine grained output. 

If you want more precise output, the way to go is to enhance the loss function. It is the purpose of the GAN and of most of shaoanlu's attempts. In the original model, the loss function is just a mean of differences between generated and expected result, that's what gives this blurry look because the mean does erase details.",guarantee anything first know layer purpose also important also loss function function model right model part part add layer may get possible know useful add higher resolution output like fine grained output want precise output way go enhance loss function purpose gan original model loss function mean result blurry look mean erase,issue,positive,positive,positive,positive,positive,positive
371430184,"I have a hunch that while the compute time will be longer for each epoch, it will get to the result faster if you have more layers & nodes.  If you have a lot of resources, it may be the way to go.

But eventually, the result will be the same, not ""more detailed"".",hunch compute time longer epoch get result faster lot may way go eventually result detailed,issue,negative,positive,positive,positive,positive,positive
371371953,"I did a quick train and a convert and the convert turned even better than the training previews. It was a little blurry but I am working with a set of 250 images for B, so tentatively with bigger set or more training it would be better my loss was .02. ",quick train convert convert turned even better training little blurry working set tentatively bigger set training would better loss,issue,positive,positive,positive,positive,positive,positive
371335704,Ya I am seeing the same. Looks like it is training A twice as fast since it is the higher one.,ya seeing like training twice fast since higher one,issue,negative,positive,positive,positive,positive,positive
371334124,"@iperov Yeah, I briefly looked out what you did, looks good from reading.  A lot of what I was reading about using multi GPU stated that we needed to import tensor flow initially in the model file (and I didn't do that), and making the models in parallel data, thought then there is some problem with saving the data in parallel when you are finished...thought the actual data throughput is supposed to be really good- much better than with a single GPU. I keep experimenting and see what I can do...been on call and operating a lot so it may take some time. Any help or suggestions are appreciated- I am an apt pupil to learn from you guys.",yeah briefly good reading lot reading stated import tensor flow initially model file making parallel data thought problem saving data parallel finished thought actual data throughput supposed really much better single keep see call operating lot may take time help apt pupil learn,issue,positive,positive,positive,positive,positive,positive
371308019,"@Kirin-kun I'm not seeing the problem you are. I just re-cloned `update-GAN-v2` and Original worked.

@Clorr I'm not seeing the ^Ms, neither on GitHub nor my machine. I _have_ written code for this branch on 2 different machines, one windows, one mac so it's very possible the line endings got mucked up around somewhere.

**Edit1:** Oh, you meant `v2.1`, I'll fix it. I don't remember changing the original model between `v2` and `v2.1` though, it was an update only for the gan models.

**Edit2:** Original model in `v2.1` should be fixed now

**Edit3:** I just realized that these comments were on specific commits. I didn't know GitHub adds them to this conversation as well, it was a bit misleading.",seeing problem original worked seeing neither machine written code branch different one one mac possible line got around somewhere edit oh meant fix remember original model though update gan edit original model fixed edit specific know conversation well bit misleading,issue,negative,positive,positive,positive,positive,positive
371305144,"Note that my goal was to have more details on output, but I don't think the simple decoder architecture will let me have what I want. However, we can still test this approach with much higher resolution (but then we will have to extract higher res faces)",note goal output think simple architecture let want however still test approach much higher resolution extract higher,issue,negative,positive,positive,positive,positive,positive
371304575,"You can use an already trained model. The plugin will create a new decoder file that won't overwrite the existing one (=> the old decoder is not reloaded, at least for now, but the loss goes down much faster than for the initial training at least at the beginning).

For the converter, I did not manage yet to use the generated face at full resolution. I'll push an update when possible... (but yes, for the -t arg, you will have to use OriginalRetrain)",use already trained model create new file wo overwrite one old least loss go much faster initial training least beginning converter manage yet use face full resolution push update possible yes use,issue,positive,positive,neutral,neutral,positive,positive
371303306,"The new standard build for TF 1.6 will include the AVX instruction set so unless you've already been compiling your own, you should see improvements on some problems.  AVX2 and MKL enabled cpu's will be still faster than AVX ( ~20% ) for inferences if you still compile your own...
I found this install/compile guide helpful .
http://www.python36.com/install-tensorflow-gpu-windows/

Dlib, and some other dependencies can also be compiled with faster instruction sets.  I was experimenting with changing some of the requirements.txt for gpus somewhere along the lines of ...

pip install dlib --install-option=""--yes USE_AVX_INSTRUCTIONS"" --install-option=""--yes DLIB_USE_CUDA""

Will post something when I get it all ironed out ( the cpu requirement can drop the cuda reference and use just AVX ). PS - DLib without AVX or CUDA is much much slower
",new standard build include instruction set unless already see still faster still compile found guide helpful also faster instruction somewhere along pip install yes yes post something get requirement drop reference use without much much,issue,positive,positive,positive,positive,positive,positive
371302156,"Interesting! I think your assumptions make sense and this looks very promising. How would I go about testing this. Can I use an old model and just train again with -t OriginalRetrain? Then when converting use -t OriginalRetrain or just -t Original?

Thanks!",interesting think make sense promising would go testing use old model train converting use original thanks,issue,positive,positive,positive,positive,positive,positive
371292037,"It seems to do exactly what you would think it would do, it trains one encoder twice as fast as two and it concentrates on the higher loss problematic encoder, in my case B.
Seems to be leveling them out nicely.",exactly would think would one twice fast two higher loss problematic case leveling nicely,issue,negative,positive,positive,positive,positive,positive
371281718,"Also, not a major issue, but the parameter histogram is misspelled in convert.py : ""match-histgoram"". ",also major issue parameter histogram,issue,negative,positive,neutral,neutral,positive,positive
371277136,"> I dont demand to merge this PR right now.
Let people test difference ?

Ok for me",dont demand merge right let people test difference,issue,negative,positive,positive,positive,positive,positive
371275955,"committed code optimize

```
    def train_one_step(self, iter, viewer):       

        if not self.balance_loss or self.loss_A == 0.0 or self.loss_B == 0.0 or iter % 10 == 0 or viewer is not None:
            is_train_A = True
            is_train_B = True
        else:
            is_train_A = self.loss_A >= self.loss_B
            is_train_B = not is_train_A
            
        if is_train_A:
            epoch, warped_A, target_A = next(self.images_A)
            self.loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
            
        if is_train_B:
            epoch, warped_B, target_B = next(self.images_B)
            self.loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)       

        print(""[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}"".format(time.strftime(""%H:%M:%S""), iter, self.loss_A, self.loss_B),
            end='\r')

        if viewer is not None:
            viewer(self.show_sample(target_A[0:14], target_B[0:14]), ""training"")
```",code optimize self iter viewer iter viewer none true true else epoch next epoch next print iter viewer none viewer training,issue,negative,positive,positive,positive,positive,positive
371269111,"Tahnks @iperov for the PR

I have 2 concerns about it:
- Is that experimental, or does that bring a real advantage that we want to have this as an official feature?
- On the formal part, I'm not fond on how it is written as it brings some duplication of code and is not quite obtrusive. I'd go more for something like below:

```
train_A, train_B = True
if balance_loss:
     train_A = ...
     train_B = ...

if train_A:
    epoch, .... 
    train_on_batch...

if train_B:
    epoch, .... 
    train_on_batch...
```

this way some later options can be added to modify train_A and train_B behavior...

What's your opinion?",experimental bring real advantage want official feature formal part written duplication code quite obtrusive go something like true epoch epoch way later added modify behavior opinion,issue,positive,positive,positive,positive,positive,positive
371238539,"I tested it and while training in Windows 10 it was displaying the below message every few seconds. It did not error out and training appeared to keep going but it was annoying and filling up the screen.

018-03-07 13:25:11.713373: W C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:3492]",tested training message every error training keep going annoying filling screen,issue,negative,negative,negative,negative,negative,negative
371202611,"Sure. I’ll look into trying to embed this deeper, but right now it’s above what I can do. Really just trying to help if I can- definitely not on you guys level with this stuff but I have been reading on the keras sites and will post more if can can get a more elegant solution. 

Sent from my iPhone

> On Mar 7, 2018, at 7:04 AM, Clorr <notifications@github.com> wrote:
> 
> @kellurian no problem it is nice from you to propose this PR as it will help some people wanting this feature. I also agree with @iperov that we should find a better solution for that question of multi-gpu, and that's why I didn't merge it. But for now your PR is good enough to stay here and help some people try this feature and maybe come with a more advanced solution.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",sure look trying embed right really trying help definitely level stuff reading post get elegant solution sent mar wrote problem nice propose help people wanting feature also agree find better solution question merge good enough stay help people try feature maybe come advanced solution reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
371195478,"@Kirin-kun what might work to get rid of the flickering is use seamless clone first, then on top of that histogram match using a filter based on both the current and previous frame's histogram to try and smooth out the flickering.",might work get rid flickering use seamless clone first top histogram match filter based current previous frame histogram try smooth flickering,issue,negative,positive,positive,positive,positive,positive
371187955,"I already updated to 1.6.0 a few days ago, it works fine with the faceswap scripts on windows 10.
pip3 install --upgrade tensorflow-gpu.
Not sure what performance increase was from them activating AVX in the builds from our point of view, using mostly gpu.
It did feel slightly faster in a unscientific way.",already day ago work fine pip install upgrade sure performance increase point view mostly feel slightly faster unscientific way,issue,positive,positive,positive,positive,positive,positive
371117711,"@kellurian no problem it is nice from you to propose this PR as it will help some people wanting this feature. I also agree with @iperov that we should find a better solution for that question of multi-gpu, and that's why I didn't merge it. But for now your PR is good enough to stay here and help some people try this feature and maybe come with a more advanced solution.",problem nice propose help people wanting feature also agree find better solution question merge good enough stay help people try feature maybe come advanced solution,issue,positive,positive,positive,positive,positive,positive
371115742,"Hi @goberoi ,
Welcome and thanks for your post. If you want to contrib, feel free to make some PR if you want. You can either add a `convert-youtube` in the `scripts` folder or create a new `tools` directory with your youtube grabbing tool. Just beware of hardcoded values, but beside of that there is no problem for adding this type of script to the repo",hi welcome thanks post want feel free make want either add folder create new directory tool beware beside problem type script,issue,positive,positive,positive,positive,positive,positive
371106325,@Kirin-kun I see filcking with seamless mode only if celeb face noticeably narrower than target face.,see seamless mode face noticeably narrower target face,issue,negative,positive,neutral,neutral,positive,positive
371075165,"Well, in one case it ran the extractor inside the converter and in the other case it just read the alignments file? So, faster.

And the seamless mode takes notoriously a long time. It can multiply the time fourfold. 

Actually, I find that seamless rarely looks good on a video : it make the colors flicker a lot, since it calculates the colors for each image individually and not in context.

I think I read somewhere that it should be possible to take a predictive approach, by analyzing the images on a sliding window to calculate the color correction, but I don't know the specifics.",well one case ran extractor inside converter case read file faster seamless mode notoriously long time multiply time fourfold actually find seamless rarely good video make color flicker lot since color image individually context think read somewhere possible take predictive approach sliding window calculate color correction know,issue,negative,positive,positive,positive,positive,positive
371047740,"Also using match histogram -mh gives this error 

`Failed to convert image: E:\data\a\10\3\0066.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0067.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0068.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0069.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0070.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0071.png. Reason: local variable 'mask' referenced before assignment
Failed to convert image: E:\data\a\10\3\0072.png. Reason: local variable 'mask' referenced before assignment
  1%|██                                                                                                                                                                                                                                                | 73/8580 [00:02<05:26, 26.02it/s]Traceback (most recent call last):
  File ""faceswap.py"", line 29, in <module>
    arguments.func(arguments)
  File ""E:\faceswap\lib\cli.py"", line 73, in process_arguments
    self.process()
  File ""E:\faceswap\scripts\convert.py"", line 187, in process
    self.convert(converter, item)
  File ""E:\faceswap\scripts\convert.py"", line 214, in convert
    image = converter.patch_image(image, face, 64 if ""128"" not in self.arguments.trainer else 128)
  File ""E:\faceswap\plugins\Convert_Masked.py"", line 30, in patch_image
    new_face = self.get_new_face(image,mat,size)
  File ""E:\faceswap\plugins\Convert_Masked.py"", line 110, in get_new_face
    new_face = self.encoder(normalized_face)[0]
  File ""E:\faceswap\plugins\Model_Original\Model.py"", line 28, in <lambda>
    return lambda img: autoencoder.predict(img)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\keras\engine\training.py"", line 1790, in predict
    verbose=verbose, steps=steps)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\keras\engine\training.py"", line 1299, in _predict_loop
    batch_outs = f(ins_batch)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2357, in __call__
    **self.session_kwargs)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 905, in run
    run_metadata_ptr)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1137, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1355, in _do_run
    options, run_metadata)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1361, in _do_call
    return fn(*args)
  File ""C:\Users\AppData\Local\conda\conda\envs\faceswap\lib\site-packages\tensorflow\python\client\session.py"", line 1340, in _run_fn
    target_list, status, run_metadata)`",also match histogram error convert image reason local variable assignment convert image reason local variable assignment convert image reason local variable assignment convert image reason local variable assignment convert image reason local variable assignment convert image reason local variable assignment convert image reason local variable assignment recent call last file line module file line file line process converter item file line convert image image face else file line image mat size file line file line lambda return lambda file line predict file line file line file line run file line file line file line return file line status,issue,negative,neutral,neutral,neutral,neutral,neutral
371043551,"I'm afraid I don't follow...I also don't have great skills in this area.  This was an easy fix with what I could do currently. As I am learning to work with keras, I might be able to integrate it into one model file, but for now its what I got. Default option it still selects single GPU, but you can chose to select multiGPU, so it fixes the problem. I'll take a look and see what I can do",afraid follow also great area easy fix could currently learning work might able integrate one model file got default option still single chose select problem take look see,issue,positive,positive,positive,positive,positive,positive
371034226,"separated model not good imho
How about GPU choice option to existing model ? For example [0] or [1] or [all] or [1,2]",model good choice option model example,issue,negative,positive,positive,positive,positive,positive
371031399,"Haven't personally tested anything myself (yet) but source is
http://blog.dlib.net/2017/09/fast-multiclass-object-detection-in.html

""Unlike the 68-point landmarking model included with dlib, this model is over 10x smaller at 8.8MB compared to the 68-point model's 96MB.  It also runs faster, and even more importantly, works with the state-of-the-art CNN face detector in dlib as well as the older HOG face detector in dlib.  The central use-case of the 5-point model is to perform 2D face alignment for applications like face recognition.  In any of the dlib code that does face alignment, the new 5-point model is a drop-in replacement for the 68-point model and in fact is the new recommended model to use with dlib's face recognition tooling. ""

""The results should in general be the same, but it's faster and smaller. The alignment should actually be slightly more accurate in general, but not by a lot. The real benefit is speed, size, and ability to use it with the CNN face detector in addition to the HOG detector. 

Yes, you can just replace the old shape model with the new model in any face recognition code that used the old one and it will work. I specifically made this new model to be a replacement for the old one. It will create the same kind of alignment as the old model and work with the previously trained face recognition model.""",personally tested anything yet source unlike model included model smaller model also faster even importantly work face detector well older hog face detector central model perform face alignment like face recognition code face alignment new model replacement model fact new model use face recognition general faster smaller alignment actually slightly accurate general lot real benefit speed size ability use face detector addition hog detector yes replace old shape model new model face recognition code used old one work specifically made new model replacement old one create kind alignment old model work previously trained face recognition model,issue,positive,positive,positive,positive,positive,positive
371021654,Is perceptual loss for GAN only or can it be used in original model?,perceptual loss gan used original model,issue,negative,positive,positive,positive,positive,positive
371017145,"I tried it with both https://github.com/oatssss/faceswap/commit/b6be9db0ee8357f4f5a8af42e20bc77ec7bf0278 and https://github.com/oatssss/faceswap/commit/b4dc203e4c9f1f019666e4b447bc1be97d7df0c8 linked in this thread, with both having the same result.",tried linked thread result,issue,negative,neutral,neutral,neutral,neutral,neutral
371014686,I am ok up to batch size 64 for shaoanlu and this repo with gtx1080TI.  I still thinking if we can create a repo for all gpu user. for the range of gpu fall within  2 g to 6 g,batch size still thinking create user range fall within,issue,negative,neutral,neutral,neutral,neutral,neutral
371010038,"Nice, I was wondering where those average landmarks came from. I don't know the umeyama origin, but I'm intrigued by the 5 landmark dlib example. Thank you for this information, I will also look into this :) :)

**Edit1:** Just from a glance, there seems to be no simple way to retrieve the transform matrix applied by `dlib.get_face_chips`, which is what we need during conversion since the inverse transform is applied during patching. This might've been the reason the original dev opted for umeyama.

**Edit2:**  Under the hood, dlib's alignment [also uses umeyama](https://github.com/davisking/dlib/blob/ef25c56fbb26ef3cb7e13b6aac48d1e69f5d5368/dlib/geometry/point_transforms.h#L334-L336). But it's still worth investigating using it with 5 points instead of 51 since you said it's more accurate.",nice wondering average came know origin landmark example thank information also look edit glance simple way retrieve transform matrix applied need conversion since inverse transform applied might reason original dev edit hood alignment also still worth investigating instead since said accurate,issue,positive,positive,positive,positive,positive,positive
371001580,"Yea I can't compare to shaoanlu's because there's no 128x128 version of the 2.1 there, I just followed the same pattern to extend 64 to 128, it might not be correct though.
I don't know if the meaning of batch size in this repo is the same as over there, is anyone able to get higher batch sizes for 64x64 using shaoanlu's?

@babilio yea I was running on gpu (4gb card), I don't think I've ever run it on cpu. I have a 64gb ram machine so I thought OOM errors really only happen with the gpu.",yea ca compare version pattern extend might correct though know meaning batch size anyone able get higher batch size yea running card think ever run ram machine thought really happen,issue,negative,positive,positive,positive,positive,positive
370931154,"I was able to run training with GAN128 only on batch_size=4 on a GTX 1060 6GB, pretty resource intensive isn't it?
With the old trainer I could run it at bs=128",able run training gan pretty resource intensive old trainer could run,issue,negative,positive,positive,positive,positive,positive
370899931,"I tried running training with GAN128 and after installing `keras_vggface` from repo (which explicitly says it will check for either `tensorflow-gpu` or `tensorflow` - I have the former) I have got some error at some point, this is the last call:
```
File ""C:\env\faceswap\lib\site-packages\keras\backend\tensorflow_backend.py"", line 2, in <module>
    from tensorflow.python.training import moving_averages
ModuleNotFoundError: No module named 'tensorflow.python.training'
```
Then I tried installing `tensorflow` and training only happens on CPU, which is quite not ideal.

EDIT: Uninstalling and reinstalling `tensorflow-gpu` after uninstalling `tensorflow` did the trick",tried running training gan explicitly check either former got error point last call file line module import module tried training quite ideal edit trick,issue,negative,positive,positive,positive,positive,positive
370883962,"I've observed similar thing and mentioned it on playground repo.
Is it actually using all resources, you could try running parallel scripts on different sets of data. 
I've splitted some files into different sets and executed extract scripts in parallel. It didn't affect processing time that much, so it makes everything 3 times faster, though it is not convenient.
So if executing script in parallel makes speeds up processing then I guess something is not optimized.",similar thing playground actually could try running parallel different data different executed extract parallel affect time much everything time faster though convenient script parallel guess something,issue,negative,positive,neutral,neutral,positive,positive
370878793,My own tests gave way worst result in direct video convert compared to same video extracted into frames with ffmpeg. Any feedback welcome...,gave way worst result direct video convert video extracted feedback welcome,issue,negative,negative,neutral,neutral,negative,negative
370876118,"On a related note, the hard coded average face values in aligner.py are directly from the dlib toolchain stack -- presumably based off the pre-computed average values from his model https://github.com/davisking/dlib models/blob/master/shape_predictor_68_face_landmarks.dat.bz2

You can see the copy-paste from the lines below
https://github.com/davisking/dlib/blob/b85cb68e79471c819e29081c33d09e7371f41539/dlib/image_transforms/interpolation.h#L1927-L1944

What was the reason to drop the dlib references and alignment tools in favor of these hard coded values and umeyama? There was some follow up discussion on dlib based on how the 5 landmark alignment model was much faster, a more concise model, and a bit more accurate with cnn or hog than the previously used 68 landmark model ( which was used in faceswap prior to the plugin change ) Might start looking into the differences...

Importantly, there is a developer note from dlib that the 68 model is not compatible with cnn face detection due to different bounding boxes during the model training, i.e. only works with hog.  This caused some trouble with some people I can see in the issue history.",related note hard average face directly stack presumably based average model see reason drop alignment favor hard follow discussion based landmark alignment model much faster concise model bit accurate hog previously used landmark model used prior change might start looking importantly developer note model compatible face detection due different bounding model training work hog trouble people see issue history,issue,negative,negative,neutral,neutral,negative,negative
370846523,"Sorry for the late reply, but I’ve just managed to get back to being able to try this out. The new convert.py is able to find the aligned folder but it doesn’t check the images, instead, it claims every frame was deleted and doesn’t do any swapping. This is after running the new extract script with the better filenames and removing faces of everyone except for the target. ",sorry late reply get back able try new able find folder check instead every frame swapping running new extract script better removing everyone except target,issue,negative,positive,positive,positive,positive,positive
370841338,@oatssss have you been able to run the new GAN on GPU? Do you think that's maybe why you were able to do only -bs 2 ?,able run new gan think maybe able,issue,negative,positive,positive,positive,positive,positive
370815759,It's probably cuz I added an underscore to the naming scheme of aligned photos and also excluded deleted images in https://github.com/deepfakes/faceswap/pull/217/commits/b6be9db0ee8357f4f5a8af42e20bc77ec7bf0278 so you need to re-run extraction. Seems a few people are having this issue so I'll add in a temporary compatibility fix to make it easier for people to just switch between this branch and others.,probably added underscore naming scheme also need extraction people issue add temporary compatibility fix make easier people switch branch,issue,negative,neutral,neutral,neutral,neutral,neutral
370735982,"@GSonderling Well, god damn thanx mate. I read your post yesterday and started reminding that i allready heard of this new windows feature. I set up an ubuntu env and got everything (finaly!) working yesterday in a few hours. Super important hint you made there.",well god damn mate read post yesterday new feature set got everything working yesterday super important hint made,issue,positive,positive,positive,positive,positive,positive
370720308,I updated my faceswap folder to this PR and Original converter not works. No faces were changed.,folder original converter work,issue,negative,positive,positive,positive,positive,positive
370679986,"Also what vggface package did you use, trying to run your new code I installed but it seems to work with tensorflow cpu only for window. So I couldn't even go through an epoch. Thanks",also package use trying run new code work window could even go epoch thanks,issue,negative,positive,positive,positive,positive,positive
370661879,"@oatssss the original model train is not working for me after the last pull Loading Trainer from Model_Original plugin...
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\Users\...\AppData\Local\conda\conda\envs\fs\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\Users\...\AppData\Local\conda\conda\envs\fs\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""E:\faceswap\scripts\train.py"", line 148, in processThread
    trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
TypeError: __init__() takes from 4 to 5 positional arguments but 6 were given
",original model train working last pull loading trainer exception thread recent call last file line file line run file line trainer trainer model positional given,issue,negative,positive,neutral,neutral,positive,positive
370660864,"You can try using -c Masked now with GAN it works way better. Also if you used serializer with extract you can use that for convert and that should take care of OOM.

I am extracting again because I think there was a change to the serializers so convert is not doing anything for me know. I haven't done extract with oatsss changes",try masked gan work way better also used extract use convert take care think change convert anything know done extract,issue,positive,positive,positive,positive,positive,positive
370655180,"@babilio ,do you try GAN 128 , any error when training? it looks good from the training preview. 
only convert will be the problem  when i run -D cnn t-GAN128 c-GAN128, it will show out of memory .
and if with only -D cnn / hog , the result is not good.   ",try gan error training good training preview convert problem run show memory hog result good,issue,negative,positive,positive,positive,positive,positive
370654376,I think dfaker\df is pretty VRAM intensive too. I was getting a ton of OOM errors and couldn't get it to run for 2000 against 3000 images on gtx1080 but maybe there was something wrong with my configuration. ,think pretty intensive getting ton could get run maybe something wrong configuration,issue,negative,negative,negative,negative,negative,negative
370648802,"does any one check if the origin model can be upgrade to model 128 like what Dfake/df done before? 
since we already upgrade model GAN to GAN 128, but it will only allow those people with high Vram  to run it. if possible we can upgrade the origin model to 128 or higher to let those without high Vram to try. i have try GAN 128 before, it only can run with small batch size and more longer time.",one check origin model upgrade model like done since already upgrade model gan gan allow people high run possible upgrade origin model higher let without high try try gan run small batch size longer time,issue,positive,positive,neutral,neutral,positive,positive
370642111,"@Kirin-kun It seems I have the same problem. I can extract using CNN with no problem, but on convert, it fails with an ""out of memory error"". 

If you don't set any parameters it works because it uses the Hog detector. ",problem extract problem convert memory error set work hog detector,issue,negative,neutral,neutral,neutral,neutral,neutral
370468957,Thanks for your work! Works great on my end :),thanks work work great end,issue,positive,positive,positive,positive,positive,positive
370259842,"Unfortunately, I didn't run it for long enough to see what the mask results were. I just ran it to make sure it worked and then pushed the changes.",unfortunately run long enough see mask ran make sure worked,issue,negative,negative,neutral,neutral,negative,negative
370258872,"That's really low bs. I can use 20 with PL enabled. Hopefully it will get better.
Any news about masks? If port is the same maybe we should ask shaoanlu directly?
After the masks we can merge it finally",really low use hopefully get better news port maybe ask directly merge finally,issue,positive,positive,positive,positive,positive,positive
370257450,"I ported shaoanlu's v2.1 in the [`gan-v2.1` branch](https://github.com/deepfakes/faceswap/tree/gan-v2.1).

It uses more memory. I was only able to run gan-128-v2.1 with a batch size of 2 _without_ perceptual loss.",ported branch memory able run gan batch size perceptual loss,issue,negative,positive,positive,positive,positive,positive
370233473,"Hey, i keep getting issues when i try to convert the images, when i start the process all i get is a square box on top of the converted person face, also after 20 images i get ""no alignment found for {}"" the image file name, any ideas ?",hey keep getting try convert start process get square box top converted person face also get alignment found image file name,issue,negative,positive,positive,positive,positive,positive
370178829,"When I let everything at default instead of giving the parameters, it worked.",let everything default instead giving worked,issue,negative,neutral,neutral,neutral,neutral,neutral
370178779,"Funnily, it looks like it's working when you do NOT give the alignments parameter and keep everything at default.

It found the alignment file by itself after the extraction saved it in the default location and happily converted.

Well, case closed.",funnily like working give parameter keep everything default found alignment file extraction saved default location happily converted well case closed,issue,positive,positive,positive,positive,positive,positive
370178477,@shaoanlu thanks for all your work! You've inspired me to try and learn about model architecture so I can actually attempt to make my own instead of just porting yours :),thanks work inspired try learn model architecture actually attempt make instead,issue,positive,positive,neutral,neutral,positive,positive
370178462,Oops sorry guys I edited the helper just in github. Thanks for fixing this. I will be more careful in future commits.,sorry helper thanks fixing careful future,issue,positive,negative,neutral,neutral,negative,negative
370177271,"@Kirin-kun yes, without any OOM
![image](https://user-images.githubusercontent.com/36662385/36938938-750632ac-1f29-11e8-8eab-0afd6a7985a1.png)

Also, GPU memory usage seems pretty normal, capped at 5.3GB as intended with tensorflow
![image](https://user-images.githubusercontent.com/36662385/36938928-2d89f562-1f29-11e8-91b6-37e4bac2263c.png)

The frames look completely fine, doing the extraction and alignment again on the new video frames did the trick.",yes without image also memory usage pretty normal capped intended image look completely fine extraction alignment new video trick,issue,positive,positive,positive,positive,positive,positive
370175954,"Ok this is what I did:
1) Extracted ALL target video frames with ffmpeg (instead of 1 frame per second as I did for training)
2) Deleted the frames I didn't need as I didn't wan't to wait hours to see the result and got something around 2500 frames which is like 1 minute and half of video, pretty fair
3) Ran python faceswap.py extract with target video folder to generate the alignments.json file using CNN (it worked perfectly btw unlike a week ago)
3) Ran convert on target video folder with frames without the --aligments parameter, it found the alignments by itself

Working perfectly fine
Thanks @iperov, now it is working!
Btw I'm no python programmer but wouldn't it be better to add a parameter that specifies whether the alignment with keras has to be run before the conversion so that tensorflow can do its magic without OOM? Would be basically what I did but automated",extracted target video instead frame per second training need wa wait see result got something around like minute half video pretty fair ran python extract target video folder generate file worked perfectly unlike week ago ran convert target video folder without parameter found working perfectly fine thanks working python programmer would better add parameter whether alignment run conversion magic without would basically,issue,positive,positive,positive,positive,positive,positive
370174213,"I'm getting one-third the frame extraction rates with the latest commit compared to the original face_recognition. (not counting the loading time) Is anyone else experiencing this?

In terms of face extraction quality, I would say the current commit is probably the best general one. It is the most sensitive face extractor, although the error rate can be high at times. I'm posting the numbers I get over in the playground repo.

I do notice that the different implementations have errors on different frames at times, so it's nice having multiple implementations to backup each other for problematic frames.

I still support keep more than one implementation (hog is just plain bad, doesn't count) around if possible.

Posting my numbers/benchmarks here: https://github.com/deepfakes/faceswap-playground/issues/81",getting frame extraction latest commit original counting loading time anyone else face extraction quality would say current commit probably best general one sensitive face extractor although error rate high time posting get playground notice different different time nice multiple backup problematic still support keep one implementation hog plain bad count around possible posting,issue,positive,positive,positive,positive,positive,positive
370171696,"I think/hope the converter loads an image, then searches the landmarks in the alignment file to know where to put the face and then proceeds to do its job. If it doesn't find it, it should copy it  as-is. 

That pictures present in the alignments file would be missing from the directory should be irrelevant.

Or the error comes from that it tries to run the face extractor inside the converter if it can't find it in the alignments file? Instead of ignoring it.

The first images of the dataset don't contain any face.",converter image alignment file know put face proceeds job find copy present file would missing directory irrelevant error come run face extractor inside converter ca find file instead first contain face,issue,negative,negative,negative,negative,negative,negative
370171198,"What if the dataset is made off multiple sources AND some images were deleted?
I have multiple alignments.json files in different folders",made multiple multiple different,issue,negative,neutral,neutral,neutral,neutral,neutral
370170707,"It was a typo when I filled this issue. I changed the path here to shorten it.

It still fails, whether there's an alignment file or not. 

And anyway, if the path to the file is mistyped, the program stops with ""No such file or directory"". 

So, no, it doesn't use the face extractor inside the converter.",typo filled issue path shorten still whether alignment file anyway path file program file directory use face extractor inside converter,issue,negative,positive,positive,positive,positive,positive
370170352,"@Kirin-kun
`--alignments c;\fakes\data_A\faces\alignments.json`
;

no alignments was loaded, so used face extractor inside converter, this cause no mem for dlib+keras extractor+keras converter.

@blvck-mvgic same you didnt provide --alignments for convert

@Clorr I suggest disable converting if no alignments was loaded


",loaded used face extractor inside converter cause mem converter didnt provide convert suggest disable converting loaded,issue,negative,neutral,neutral,neutral,neutral,neutral
370170187,"I have the exact same problem with 1280x720 frames and a GTX 1060 6GB
`python faceswap.py convert -i C:\videoframes -o C:\videoframes\converted -v -m C:\model -t Original -c Masked -D hog -fr 5881-8140 -b 5 -S -M facehullandrect -e 0`
Can't process any frame, always OOM: 
`Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file C:\env\faceswap\dlib\dlib\dnn\gpu_data.cpp:195. code: 2, reason: out of memory`",exact problem python convert original masked hog ca process frame always error calling data float file code reason memory,issue,negative,positive,positive,positive,positive,positive
370168360,"@Suicidman  I recommend Ubuntu subsystem for windows. It allows you to run almost anything like you would in normal linux, using familiar command line. 
https://docs.microsoft.com/en-us/windows/wsl/install-win10
Granted, it is a developer feature. But the benefits are massive. ",recommend subsystem run almost anything like would normal familiar command line developer feature massive,issue,positive,positive,positive,positive,positive,positive
370168157,"The enter still works for windowed preview, which is what most new users use, I assume. 
",enter still work preview new use assume,issue,negative,positive,positive,positive,positive,positive
370165490,The new notebook is still messy and is very likely going to be overhauled. I'm still exploring the hyper parameters so it might take at least weeks ~ a month to settle down.,new notebook still messy likely going still exploring hyper might take least month settle,issue,negative,negative,neutral,neutral,negative,negative
370158459,I cannot speak for babilio but yes. #238 . Just a typo in his commit. ,speak yes typo commit,issue,positive,neutral,neutral,neutral,neutral,neutral
370157071,"Hi iperov,
Thanks for your advice. What confused me was that ""extract -D cnn"" worked well but ""convert -D cnn"" failed. Both of them call the same function right? BTW I am going to double check my cuda installation. Thank you!",hi thanks advice confused extract worked well convert call function right going double check installation thank,issue,positive,positive,neutral,neutral,positive,positive
370156282,"Hello, I have two questions after this PR being merged:
1. -D option seemed to be ignore, I specified faceswap convert -D hog but cnn still used.
2. I tried to disable cnn for face detection because of the following error. It happened to convert but extract was good:

Failed to convert image: /PATH/faceb/d004020.png. Reason: Error while calling cudnnCreate(&handles[new_device_id]) in file /home/xxxx/dlib/dlib/dnn/cudnn_dlibapi.cpp:104. code: 4, reason: A call to cuDNN failed
^CTraceback (most recent call last):
  File ""/home/xxxx/faceswap1/scripts/convert.py"", line 177, in convert
    for idx, face in faces:
  File ""/home/xxxx/faceswap1/lib/cli.py"", line 126, in get_faces
    for face in faces:
  File ""/home/xxxx/faceswap1/lib/faces_detect.py"", line 4, in detect_faces
    fd = FaceLandmarksExtractor.extract (frame, True if model == ""cnn"" else False )
  File ""/home/xxxx/faceswap1/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py"", line 138, in extract
    initialize(scale_to)
  File ""/home/xxxx/faceswap1/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py"", line 120, in initialize
    dlib_cnn_face_detector ( np.zeros ( (scale_to, scale_to, 3), dtype=np.uint8), 0 ) 
RuntimeError: Error while calling cudnnCreate(&handles[new_device_id]) in file /home/xxxx/dlib/dlib/dnn/cudnn_dlibapi.cpp:104. code: 4, reason: A call to cuDNN failed
",hello two option ignore convert hog still used tried disable face detection following error convert extract good convert image reason error calling file code reason call recent call last file line convert face file line face file line frame true model else false file line extract initialize file line initialize error calling file code reason call,issue,negative,positive,positive,positive,positive,positive
370155434,"Here is a link to see todays modifications: https://github.com/shaoanlu/faceswap-GAN/compare/76e14c42efa0c0adbb731d748f866e07793708d1...master

However new notebook is not diff-ed with older as it is a new file...",link see however new notebook older new file,issue,negative,positive,positive,positive,positive,positive
370154175,"A new faceswap-GAN [notebook](https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2.1_train.ipynb) was posted today!  

Diffing time... ",new notebook posted today time,issue,negative,positive,positive,positive,positive,positive
370146749,"Yea there's no point in keeping the gan converter so I'll remove it.

These 2 lines in the masked converter give us the same result as that `resize`.

``` python
mat = numpy.array(get_align_mat(face_detected)).reshape(2,3) * size
face = cv2.warpAffine( image, mat, (size,size) )
```

So as long as you pass the right size to `patch_image()`, you're gucci.",yea point keeping gan converter remove masked converter give u result resize python mat size face image mat size size long pas right size,issue,negative,positive,positive,positive,positive,positive
370145758,"@oatssss in gan128 convert I see a resize operation: cv2.resize(face_detected.image, (128, 128))
Don't we need to do same thing for Masked Convert if gan128 used?
Also what's the reason keeping gan converters as blur, histogram matching etc. are only available in masked converter?",gan convert see resize operation need thing masked convert gan used also reason keeping gan blur histogram matching available masked converter,issue,negative,positive,positive,positive,positive,positive
370142931,This one is going to be replaced by #217 which is close to the end AFAIK,one going close end,issue,negative,neutral,neutral,neutral,neutral,neutral
370142406,"@babilio, can you share some face preview after you convert?",share face preview convert,issue,negative,neutral,neutral,neutral,neutral,neutral
370142307,"Some feedback.Have try to do convert yesterday with -D cnn -t GAN128 -c GAN128 , with my gpu gtx1080ti, it show out of memory, but it not happen if I use -D hog. For the training, I can use batch size max up to 64, result looks pretty good now compare to what previously I share.  ",try convert yesterday gan gan show memory happen use hog training use batch size result pretty good compare previously share,issue,positive,positive,positive,positive,positive,positive
370138515,"Argparse is enough. Just as long as the knowledge is preserved somewhere.

On 3 Mar. 2018 21:34, ""Clorr"" <notifications@github.com> wrote:

> @babilio <https://github.com/babilio> otherwise I'm ok to merge when I
> get feedback from @gdunstone <https://github.com/gdunstone>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/238#issuecomment-370137444>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeH_459giGoP60mPYE-tjf5EvNjWfks5tanHJgaJpZM4Sawz1>
> .
>
",enough long knowledge somewhere mar wrote otherwise merge get feedback reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
370137645,"@Clorr I'd love to do a PR, but unfortunately it doesn't work with the https://github.com/deepfakes/faceswap/commit/232d9313afabc075e28c1a42047b22e0568200e6 commit. I'm not too fond of the keras stuff so if someone else could look into it that'd be great.",love unfortunately work commit stuff someone else could look great,issue,positive,positive,positive,positive,positive,positive
370137444,@babilio otherwise I'm ok to merge when I get feedback from @gdunstone ,otherwise merge get feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
370137362,"@Clorr not necessarily overfit. 
For example FakeApp result https://www.youtube.com/watch?v=Va9JLpkCUBs I trained it with every frame of video.",necessarily overfit example result trained every frame video,issue,negative,neutral,neutral,neutral,neutral,neutral
370137168,"@modelsex just a thought btw: if your faces are too similar, your training may overfit. Please keep in mind it is better to extract a frame only each 2 to 5s",thought similar training may overfit please keep mind better extract frame,issue,positive,positive,positive,positive,positive,positive
370137157,I am getting good result with -e -15 and -b 30 with original model.,getting good result original model,issue,positive,positive,positive,positive,positive,positive
370137039,"Thnaks @master131 . The problem of the global was known on Python3.6, that's why multi process was not made a default. Can you di a Pull Request so that people can test and give feedback? Thanks",master problem global known process made default di pull request people test give feedback thanks,issue,negative,positive,neutral,neutral,positive,positive
370136071,"Seems to be a problem with the ""method"" global variable in multithreading.py. It's value isn't preserved in the forked Pool processes. I made a hacky workaround which seems to do the trick. Just be warned that this doesn't work with the latest commits (last compatible commit is https://github.com/deepfakes/faceswap/commit/6f2d260591b830b4230bcdc3aa20bb3623883172) because if you try using it with them, it tries to initialize multiple instances of TensorFlow.

**multithreading.py**
```python
import multiprocessing as mp

method = None

def pool_process(method_to_run, data, processes=None):
    global method
    if processes is None:
        processes = mp.cpu_count()
    method = method_to_run
    pool = mp.Pool(processes=processes)

    for i in pool.imap_unordered(runner, map(lambda x: (method_to_run, x), data)):
        yield i if i is not None else 0
    
def runner(item):
    return item[0](item[1])
```

**extract.py**
```python
    def process(self):
        extractor_name = ""Align"" # TODO Pass as argument
        self.extractor = PluginLoader.get_extractor(extractor_name)()
        processes = self.arguments.processes
        try:
            if processes != 1:
                files = list(self.read_directory())
                self.parser = None # <--- Add this line, since multiprocessing can't pickle the parser
                for filename, faces in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):
                    self.num_faces_detected += 1
                    self.faces_detected[os.path.basename(filename)] = faces
            else:
                try:
                    for filename in tqdm(self.read_directory()):
                        image = cv2.imread(filename)
                        self.faces_detected[os.path.basename(filename)] = self.handleImage(image, filename)
                except Exception as e:
                    print('Failed to extract from image: {}. Reason: {}'.format(filename, e))
        finally:
            self.write_alignments()
```",problem method global variable value forked pool made hacky trick work latest last compatible commit try initialize multiple python import method none data global method none method pool runner map lambda data yield none else runner item return item item python process self align pas argument try list none add line since ca pickle parser total else try image image except exception print extract image reason finally,issue,negative,positive,neutral,neutral,positive,positive
370135825,"Amazing !!! Will do more test later, thanks !!!!!",amazing test later thanks,issue,positive,positive,positive,positive,positive,positive
370130357,"I understood your bug, wait fix.",understood bug wait fix,issue,negative,neutral,neutral,neutral,neutral,neutral
370122928,"I built dlib for VS2015 and ran example dnn_mmod_face_detection_ex.cpp and it found face ! even without pyramid_up() upsampling

Same dlib built for python found no faces :-\

",built ran example found face even without built python found,issue,negative,neutral,neutral,neutral,neutral,neutral
370121244,"Can you update the readme with this info as well?

On 3 Mar. 2018 2:43 pm, ""babilio"" <notifications@github.com> wrote:

> …it turns it into a dilation kernel, which allow facehullandrect to cover
> more space. Can help to cover double eyebrows. Also could be useful with
> Masked converter for GAN that oatsss is working on.
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/deepfakes/faceswap/pull/238
> Commit Summary
>
>    - Allows for negative erosion kernel for -e arg. If value is negative,
>    it turns it into a dilation kernel, which allow facehullandrect to cover
>    more space. Can help to cover double eyebrows. Also could be useful with
>    Masked converter for GAN that oatsss is working on.
>
> File Changes
>
>    - *M* plugins/Convert_Masked.py
>    <https://github.com/deepfakes/faceswap/pull/238/files#diff-0> (14)
>    - *M* scripts/convert.py
>    <https://github.com/deepfakes/faceswap/pull/238/files#diff-1> (2)
>
> Patch Links:
>
>    - https://github.com/deepfakes/faceswap/pull/238.patch
>    - https://github.com/deepfakes/faceswap/pull/238.diff
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/238>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeLvOnbe6i0JYBtzzCH12PREuHNH4ks5tahFvgaJpZM4Sawz1>
> .
>
",update well mar wrote turn dilation kernel allow cover space help cover double also could useful masked converter gan working view comment merge pull request commit summary negative erosion kernel value negative turn dilation kernel allow cover space help cover double also could useful masked converter gan working file patch link thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
370052592,"face_alignment.api.py seems to be the relevant file.

`
from __future__ import print_function
import os, glob, dlib, torch, torch.nn as nn
from torch.autograd import Variable
from enum import Enum
try:
    import urllib.request as request_file
except BaseException:
    import urllib as request_file

from .models import FAN, ResNetDepth
from .utils import *
from settings import processor

class LandmarksType(Enum):
    _2D = 1
    _2halfD = 2
    _3D = 3


class NetworkSize(Enum):
    LARGE = 4

    def __new__(cls, value):
        member = object.__new__(cls)
        member._value_ = value
        return member

    def __int__(self):
        return self.value


class FaceAlignment:
    """"""Initialize the face alignment pipeline
    
    Args:
        landmarks_type (``LandmarksType`` object): an enum defining the type of predicted points.
        network_size (``NetworkSize`` object): an enum defining the size of the network (for the 2D and 2.5D points).
        enable_cuda (bool, optional): If True, all the computations will be done on a CUDA-enabled GPU (recommended).
        enable_cudnn (bool, optional): If True, cudnn library will be used in the benchmark mode
        flip_input (bool, optional): Increase the network accuracy by doing a second forward passed with
                                    the flipped version of the image
        use_cnn_face_detector (bool, optional): If True, dlib's CNN based face detector is used even if CUDA
                                                is disabled.
    
    Example:
        >>> FaceAlignment(NetworkSize.2D, flip_input=False)
    """"""

    def __init__(self, landmarks_type, network_size=NetworkSize.LARGE, enable_cuda=True, enable_cudnn=True, flip_input=False, use_cnn_face_detector=False):
        if processor == 'CPU':
            self.enable_cuda = False
        else:
            self.enable_cuda = True
        self.use_cnn_face_detector = use_cnn_face_detector
        self.flip_input = flip_input
        self.landmarks_type = landmarks_type
        base_path = os.path.join(appdata_dir('face_alignment'), 'data')
        if not os.path.exists(base_path):
            os.makedirs(base_path)
        if enable_cudnn:
            if self.enable_cuda:
                torch.backends.cudnn.benchmark = True
        if self.enable_cuda or self.use_cnn_face_detector:
            path_to_detector = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'mmod_human_face_detector.dat')
            self.face_detector = dlib.cnn_face_detection_model_v1(path_to_detector)
        else:
            self.face_detector = dlib.get_frontal_face_detector()
        self.face_alignemnt_net = FAN(int(network_size))
        if landmarks_type == LandmarksType._2D:
            network_name = '2DFAN-' + str(int(network_size)) + '.pth.tar'
        else:
            network_name = '3DFAN-' + str(int(network_size)) + '.pth.tar'
        fan_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), network_name)
        fan_weights = (torch.load)(fan_path, map_location=(lambda storage, loc: storage))
        fan_dict = {k.replace('module.', ''):v for k, v in fan_weights['state_dict'].items()}
        self.face_alignemnt_net.load_state_dict(fan_dict)
        if self.enable_cuda:
            self.face_alignemnt_net.cuda()
        self.face_alignemnt_net.eval()
        if landmarks_type == LandmarksType._3D:
            self.depth_prediciton_net = ResNetDepth()
            depth_model_path = os.path.join(base_path, 'depth.pth.tar')
            if not os.path.isfile(depth_model_path):
                print('Downloading the Face Alignment depth Network (FAN-D). Please wait...')
                request_file.urlretrieve('https://www.adrianbulat.com/downloads/python-fan/depth.pth.tar', os.path.join(depth_model_path))
            depth_weights = (torch.load)(depth_model_path, map_location=(lambda storage, loc: storage))
            depth_dict = {k.replace('module.', ''):v for k, v in depth_weights['state_dict'].items()}
            self.depth_prediciton_net.load_state_dict(depth_dict)
            if self.enable_cuda:
                self.depth_prediciton_net.cuda()
            self.depth_prediciton_net.eval()

    def detect_faces(self, image):
        """"""Run the dlib face detector over an image
        
        Args:
            image (``ndarray`` object or string): either the path to the image or an image previosly opened
            on which face detection will be performed.
        
        Returns:
            Returns a list of detected faces
        """"""
        return self.face_detector(image, 1)

    def get_landmarks(self, input_image, all_faces=False):
        if isinstance(input_image, str):
            try:
                image = io.imread(input_image)
            except IOError:
                print('error opening file :: ', input_image)
                return

        else:
            image = input_image
        detected_faces = self.detect_faces(image)
        if len(detected_faces) > 0:
            landmarks = []
            for i, d in enumerate(detected_faces):
                if i > 1:
                    if not all_faces:
                        break
                if self.enable_cuda or self.use_cnn_face_detector:
                    d = d.rect
                center = torch.FloatTensor([
                 d.right() - (d.right() - d.left()) / 2.0,
                 d.bottom() - (d.bottom() - d.top()) / 2.0])
                center[1] = center[1] - (d.bottom() - d.top()) * 0.1
                scale = (d.right() - d.left() + d.bottom() - d.top()) / 200.0
                inp = crop(image, center, scale)
                inp = torch.from_numpy(inp.transpose((2, 0, 1))).float().div(255.0).unsqueeze_(0)
                if self.enable_cuda:
                    inp = inp.cuda()
                out = self.face_alignemnt_net(Variable(inp, volatile=True))[-1].data.cpu()
                if self.flip_input:
                    out += flip((self.face_alignemnt_net(Variable((flip(inp)), volatile=True))[-1].data.cpu()), is_label=True)
                pts, pts_img = get_preds_fromhm(out, center, scale)
                pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)
                if self.landmarks_type == LandmarksType._3D:
                    heatmaps = np.zeros((68, 256, 256))
                    for i in range(68):
                        if pts[(i, 0)] > 0:
                            heatmaps[i] = draw_gaussian(heatmaps[i], pts[i], 2)

                    heatmaps = torch.from_numpy(heatmaps).view(1, 68, 256, 256).float()
                    if self.enable_cuda:
                        heatmaps = heatmaps.cuda()
                    depth_pred = self.depth_prediciton_net(Variable((torch.cat((
                     inp, heatmaps), 1)), volatile=True)).data.cpu().view(68, 1)
                    pts_img = torch.cat((
                     pts_img, depth_pred * (1.0 / (256.0 / (200.0 * scale)))), 1)
                landmarks.append(pts_img.numpy())

        else:
            print('Warning: No faces were detected.')
            return
        return landmarks

    def process_folder(self, path, all_faces=False):
        types = ('*.jpg', '*.png')
        images_list = []
        for files in types:
            images_list.extend(glob.glob(files))

        predictions = []
        for image_name in images_list:
            predictions.append(image_name, self.get_landmarks(image_name, all_faces))

        return predictions`

",relevant file import import o torch import variable import try import except import import fan import import processor class class large value member value return member self return class initialize face alignment pipeline object type object size network bool optional true done bool optional true library used mode bool optional increase network accuracy second forward version image bool optional true based face detector used even disabled example self processor false else true true else fan else lambda storage storage print face alignment depth network please wait lambda storage storage self image run face detector image image object string either path image image face detection list return image self try image except print opening file return else image image enumerate break center center center scale crop image center scale variable flip variable flip center scale range variable scale else print return return self path return,issue,positive,positive,neutral,neutral,positive,positive
370052423,"@Kirin-kun
Hmm I think it's safe to say that face-alignment/1adrianb finds more faces at least for some scenarios. It's possible that faceapp did some modifications on it. To confirm you can try the images directly on the library I shared the link above.",think safe say least possible confirm try directly library link,issue,negative,positive,neutral,neutral,positive,positive
370049406,"@iperov I successfully decompiled the a.exe from FakeApp 1.1.

Using https://sourceforge.net/projects/pyinstallerextractor to extract the exe. It produces a bunch of pyc. 

Then ""pip install uncompyle6"" on windows to see what's in them. Obviously, FakeApp uses face-alignment from 1adrianb.

C:\FakeApp\alignment\a.exe_extracted\out00-PYZ.pyz_extracted>uncompyle6 face_alignment.pyc
```
# uncompyle6 version 3.0.0
# Python bytecode 3.6 (3379)
# Decompiled from: Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1
900 64 bit (AMD64)]
# Embedded file name: face_alignment\__init__.py
__author__ = 'Adrian Bulat'
__email__ = 'adrian.bulat@nottingham.ac.uk'
__version__ = '0.1.0'
from .api import FaceAlignment, LandmarksType, NetworkSize
# okay decompiling face_alignment.pyc
```",successfully extract bunch pip install see obviously version python python bit file name import,issue,negative,positive,positive,positive,positive,positive
370040027,"I tested various scenarios by dumping 696 pictures in a directory, with lots of different angles and faces of different people and I tried all 3 face detectors.

FakeApp (1.1 and 2.2) both detected 645 faces (including the false positives). Most of them good, very few of them a misdection.

faceswap HOG detected only 370 (including the false positive)! Obviously, HOG is only able to detect faces when they are looking at the camera and upright.

faceswap cnn (latest commit) detected 610 (including the false positive), which is better, but missed some that FakeApp didn't. It improved a lot.

faceswapp cnn seems to not be able to detect faces seen from the bottom, but is better at detecting small faces than FakeApp.  It seems to also have problems detecting the face when it's next to an angle of the image or something.

Here are two pictures (mostly SFW) that fakeapp detects correctly and that faceswap cnn does not:

[Images Removed]

When I cropped the first one to keep the face in the middle of the picture, cnn suddenly detected it!

FakeApp must have a different training base or something.",tested various dumping directory lot different different people tried face false good hog false positive obviously hog able detect looking camera upright latest commit false positive better lot able detect seen bottom better small also face next angle image something two mostly correctly removed first one keep face middle picture suddenly must different training base something,issue,positive,positive,neutral,neutral,positive,positive
370039893,"face_recognition also find nothing
```
frame = cv2.imread(sys.argv[1])
s = face_recognition.face_locations (frame, model='cnn')
```
FakeApp has DLIB version 19.8.1N, but I cannot install this version on Windows and check.",also find nothing frame frame version install version check,issue,negative,neutral,neutral,neutral,neutral,neutral
370030163,"If I specify `--skip-existing` and also an `--output-dir` that doesn't exist yet, I get:

```
File ""D:\faceswap\lib\utils.py"", line 18, in get_image_paths
    dir_scanned = list(scandir(directory))
FileNotFoundError: [WinError 3] The system cannot find the path specified: ""/the/output/dir/specified""
```

Without `--skip-existing`, it would just create it. Could you implement that as well?",specify also exist yet get file line list directory system find path without would create could implement well,issue,negative,neutral,neutral,neutral,neutral,neutral
369994640,"kar1086.png - just minimal program with `dlib.cnn_face_detection_model_v1` doesnt detect any face rectangles.
So issue not relate to last commits",minimal program doesnt detect face issue relate last,issue,negative,negative,neutral,neutral,negative,negative
369990309,"@Apollo122 `rect` will only be good if the masks are good and are completely black at the bbox edges. I think a face hull expanded with dilation would be better than a rectangle, but we'll see.",rect good good completely black think face hull expanded dilation would better rectangle see,issue,positive,positive,positive,positive,positive,positive
369981678,"@oatssss I was never able to get shaoanlu GAN working to run for me, so I don't really have much to compare. Results I get here are mixed, some frames look really promising others look weird. I havent tried to convert an actual video. Just was training pics of a and b on extracts from multiple sources.",never able get gan working run really much compare get mixed look really promising look weird havent tried convert actual video training multiple,issue,negative,negative,neutral,neutral,negative,negative
369965965,"`Cnn is almost as good, but is plagued by zoomed faces and wrong landmarks.`
your information is outdated.
Check last commits.",almost good plagued wrong information outdated check last,issue,negative,negative,neutral,neutral,negative,negative
369956490,"FakeApp is better at detecting faces than faceswap is. It detects more faces than the HOG here. Cnn is almost as good, but is plagued by zoomed faces and wrong landmarks.

Unfortunately, the alignment files are not compatible, so one can't use both applications.",better hog almost good plagued wrong unfortunately alignment compatible one ca use,issue,negative,positive,neutral,neutral,positive,positive
369951915,"There's a program ""a.exe"" in the alignment subdirectory of FakeApp 1.1


C:\FakeApp\alignment>a.exe -h
RuntimeError: module compiled against API version 0xc but this version of numpy
is 0xb
usage: a.exe [-h] [--one-face] [--all-faces] [--startFrame STARTFRAME]
             [--maxFrames MAXFRAMES] [--fileType FILETYPE]
             [--processor PROCESSOR]
             input_dir [output_dir] [output_file]

positional arguments:
  input_dir
  output_dir
  output_file

optional arguments:
  -h, --help            show this help message and exit
  --one-face
  --all-faces
  --startFrame STARTFRAME
  --maxFrames MAXFRAMES
  --fileType FILETYPE
  --processor PROCESSOR

It seems to be a compiled python exe. I guess someone could attempt to decompile it using [unpy2exe](https://github.com/matiasb/unpy2exe) to extract the .pyc and then use [pyREtic](https://github.com/MyNameIsMeerkat/pyREtic) to get the source code.",program alignment module version version usage processor processor positional optional help show help message exit processor processor python guess someone could attempt extract use pyretic get source code,issue,positive,neutral,neutral,neutral,neutral,neutral
369919035,"I suppose multiprocess work only with CPU version of dlib and tf.
in GPU version there is nothing to be ""multiprocessed"", because dlib and tf eats all vram.",suppose work version version nothing eats,issue,negative,neutral,neutral,neutral,neutral,neutral
369898372,@oatssss if `rect ` is better maybe it should be default option for GAN converter?,rect better maybe default option gan converter,issue,negative,positive,positive,positive,positive,positive
369894175,Mask bug and histogram matching prevents us to merge. But I think they will be resolved soon.,mask bug histogram matching u merge think resolved soon,issue,negative,neutral,neutral,neutral,neutral,neutral
369868232,"@oatssss have complete GAN128, i will close this issue here. will open back if we want ""high resolution"" image again in future. ",complete gan close issue open back want high resolution image future,issue,negative,positive,neutral,neutral,positive,positive
369850734,and I dont like to control tf session inside child lib. FaceSwap architecture crap already :D,dont like control session inside child architecture crap already,issue,negative,negative,negative,negative,negative,negative
369850004,"@iperov  since problem is tensorflow allocationg all the vram. i tried by limiting tensorflow memory. now i don't see the oom error but it looks like gpu is using only 2.4Gig of 4Gig.  maybe problem can be resolve this way? im not familiar with tensorflow keras etc..

the thing i tried is set the memory limit before import keras

FaceLandmarksExtractor.py

`import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.3
set_session(tf.Session(config=config))
import keras
from keras import backend as K`



",since problem tried limiting memory see error like gig maybe problem resolve way familiar thing tried set memory limit import import import import import,issue,negative,positive,positive,positive,positive,positive
369848656,@babilio are you able to get good results with the gan here?,able get good gan,issue,negative,positive,positive,positive,positive,positive
369839105,That makes sense. Thanks for the explanation. I tried rect and you are right it works so much better because it is aligned. Dilation could work really well with GAN,sense thanks explanation tried rect right work much better dilation could work really well gan,issue,positive,positive,positive,positive,positive,positive
369834565,I think in the other thread some mentioned having a plugin to choose face-alignment or face_recognition... I would recommend that route as face_recognition has some advantages in edge case scenarios.,think thread choose would recommend route edge case,issue,negative,neutral,neutral,neutral,neutral,neutral
369831457,"@babilio the erosion kernel shrinks the face hull. What if for negative values we use [dilation](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html#dilation) to expand the face hull? You can also use `rect` mode to convert similarly to the original gan converter, but since masked is aligned, the rect bboxes will be aligned to the face, but it shouldn't really matter.

@ruah1984 yea merge soon hopefully :)",erosion kernel face hull negative use dilation expand face hull also use rect mode convert similarly original gan converter since masked rect face really matter yea merge soon hopefully,issue,negative,positive,neutral,neutral,positive,positive
369822377,"sry bad english, I will try to explain.
```
@3xtr3m3d
face_alignment i was refering to is the original one from pytorch which i integrate to code as describe in the comment of LordVulkan on issue https://github.com/deepfakes/faceswap/issues/187

that able to process the folder but ported version did not.
```
because Torch frees vram after call.
But TensorFlow doesnt free, and consumes all possible vram for caching, therefore TF x2 faster than Torch.

Problem is DLIB and TF competiting for VRAM. Difference is TF can work with super low mem, but eats all freed mem again.

For example
If call TF first, it consumes all ram, and then call dlib - there is no ram for DLIB.
If we call DLIB first with 1280x1280, free mem is 2Gb, then call TF it eats all remaining ram, then call dlib with 1920x1920 - no ram for dlib and OOM error, only 1280x1280 will fine.

So I suggested fix in prev post.",bad try explain original one integrate code describe comment issue able process folder ported version torch call doesnt free possible therefore faster torch problem difference work super low mem eats freed mem example call first ram call ram call first free mem call eats ram call ram error fine fix post,issue,negative,positive,positive,positive,positive,positive
369821765,"The Masked convert vs GAN convert covers a much smaller part of the face. To me GAN convert looks better (when the images are straight, otherwise it looks terrible) because it covers more of the face and it blends well. Do you know what parameter determines how much of the face gets patched? I feel like mask crops or covers out a lot of the face. If you compare the images in GAN trainer to the output you'll see that what gets converted is much smaller.",masked convert gan convert much smaller part face gan convert better straight otherwise terrible face well know parameter much face feel like mask lot face compare gan trainer output see converted much smaller,issue,positive,negative,neutral,neutral,negative,negative
369820867,"I think that would be the way to go as well, such as a plug-in option like the low mem or gan and selectable at the command line?

Sent from my iPhone

> On Mar 1, 2018, at 9:00 PM, Ashwin <notifications@github.com> wrote:
> 
> Naah All good mate, It's pretty clear now.
> 
> By the way I have tested with the changed model_original.py file on a single gpu machine and it came up with the below:
> 
> ValueError: To call multi_gpu_model with gpus=2, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1']. However this machine only has: ['/cpu:0', '/gpu:0']. Try reducing gpus.
> 
> I think model_multigpu file option would be the way to go.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",think would way go well option like low mem gan selectable command line sent mar wrote good mate pretty clear way tested file single machine came call expect following available however machine try reducing think file option would way go reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
369820467,"I made scale image for cnns with `max_res_side` param. This scaling affects only input image to cnns. Output points scaling back to original size.

Also I do first call `dlib_cnn_face_detector  ` with `max_res_side x max_res_side x 3` then dlib consume all necessary vram for work.

```
dlib_cnn_face_detector = dlib.cnn_face_detection_model_v1(dlib_cnn_face_detector_path)            
dlib_cnn_face_detector ( np.zeros ( (max_res_side, max_res_side, 3), dtype=np.float32), 1 )
```

I have ~ 5.53Gb free before program start
and with param
`max_res_side=1850`
I got
`totalMemory: 6.00GiB freeMemory: 133.42MiB`

but even with 133Mb **keras works without problem**, but with warning

`Allocator (GPU_0_bfc) ran out of memory trying to allocate 134.44MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.`

Yes DLIB sucks, but we have no alternative.

SO

`max_res_side=1280` consumes **~2,77Gb** . This will fail at ppl who have only 3GB VRAM. Because they have ~2.2Gb free on Windows 10.

`max_res_side=1100` consumes **~2.06Gb** and will work at ppl with 3GB VRAM.

But decreasing `max_res_side` may cause unprecise landmarks detecting.

**SO what we choose ?** @Clorr ",made scale image param scaling input image output scaling back original size also first call consume necessary work free program start param got even work without problem warning allocator ran memory trying allocate caller failure may mean could performance gain memory yes alternative fail free work decreasing may cause unprecise choose,issue,positive,positive,neutral,neutral,positive,positive
369820457,"@oatssss 

> @3xtr3m3d I don't understand, isn't the face-alignment port from pytorch the ""today's update"" that you're referring to? For what extractor are you getting an OOM?

face_alignment i was refering to is the original one from pytorch which i integrate to code as describe in the comment of  LordVulkan  on issue [https://github.com/deepfakes/faceswap/issues/187](url)

that able to process the folder but ported version did not.
",understand port today update extractor getting original one integrate code describe comment issue able process folder ported version,issue,negative,positive,positive,positive,positive,positive
369819018,"@DLSauron 

> I can confirm that after I created a pure white JPG with the dimensions of 1280 x 1280 and named it 0.jpg it was able to process the entire folder

i tried this and it processed my folder with 100 images which it couldn't process before",confirm pure white able process entire folder tried folder could process,issue,negative,positive,positive,positive,positive,positive
369815592,I can confirm that after I created a pure white JPG with the dimensions of 1280 x 1280 and named it 0.jpg it was able to process the entire folder,confirm pure white able process entire folder,issue,negative,positive,positive,positive,positive,positive
369808164,"@DLSauron 
> Funny thing is I had already resized that image yesterday because the original was to big for the original cnn extractor (2678 x 4000).

1080p picture eats ~3.5GB videoram by dlib cnn BEFORE keras loading 
anyway large pictures cannot be handled by dlib cnn.
",funny thing already image yesterday original big original extractor picture eats loading anyway large handled,issue,positive,positive,positive,positive,positive,positive
369803461,"@iperov the picture I had in the folder first was 480p size.

I did what you asked and put the 1080p pics first and it went through all 1,000, and moved on to the 720p without any issue. So the problem does seem to be when it starts with low resolution and switches to higher.",picture folder first size put first went without issue problem seem low resolution higher,issue,negative,positive,positive,positive,positive,positive
369795359,"@kellurian 
Naah All good mate, It's pretty clear now.

By the way I have tested with the changed model_original.py file on a single gpu machine and it came up with the below:

> ValueError: To call `multi_gpu_model` with `gpus=2`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1']. However this machine only has: ['/cpu:0', '/gpu:0']. Try reducing `gpus`.


I think model_multigpu file option would be the way to go.

",good mate pretty clear way tested file single machine came call expect following available however machine try reducing think file option would way go,issue,positive,positive,positive,positive,positive,positive
369793730,"Another possibility is maybe using this #214 so after a full pass through the directory it would allow to rotate and go through it again, skipping the ones that were already found. Maybe is less efficient vs doing it when the img is already in memory",another possibility maybe full pas directory would allow rotate go skipping already found maybe le efficient already memory,issue,positive,positive,positive,positive,positive,positive
369792949,"@babilio 
Actually this is dlib OOM. DLIB conflicts with Keras in memory usage.

What picture size of your first image of sequence in a folder ?
For test, try set first image of sequence 1080p size (highest in all sequence) and report here.",actually memory usage picture size first image sequence folder test try set first image sequence size highest sequence report,issue,negative,positive,positive,positive,positive,positive
369791979,"@iperov  @oatssss I tried extracting extract the same set of images on the face-alignment on pytorch and the face-alignment on keras. It seems that keras implementation is much more demanding on GPU memory. I have 7,000 images of 480, 720, 1080 resolution. Pytorch went through all of them fine, keras went through 800 images of 480 resolution and threw error 

Reason: Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file C:\packages\dlib-19.9\dlib\dnn\gpu_data.cpp:195. code: 2, reason: out of memory/
 
and couldn't even handle the others",tried extract set implementation much demanding memory resolution went fine went resolution threw error reason error calling data float file code reason could even handle,issue,negative,positive,positive,positive,positive,positive
369791927,"@DLSauron 

> I did not really have any problems with the face_recognition

face_recognition has zooming problem on some footage.
[Image Removed]",really problem footage image removed,issue,negative,positive,positive,positive,positive,positive
369788207,"Oh, I can definitely do it in python using memory only, but I want to see if we can rotate the image, get the landmarks at extract and then transform the landmarks for applying at the convert stage, as this will definitely be quicker for the convert at least. If I don't get anywhere though, I will just look at rotating again at convert, but I don't want to go down that avenue until I have explored the first option.",oh definitely python memory want see rotate image get extract transform convert stage definitely convert least get anywhere though look rotating convert want go avenue first option,issue,positive,negative,neutral,neutral,negative,negative
369778475,"@torzdf If we rotate the images in-memory (or use file-like memory storage) we could avoid the IO overhead, and only write to disk when the extractor finds a face. There will definitively be a performance git anyway, but memory is much more efficient. There's the [PIL](http://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.rotate) library which can manipulate images in various ways. Although, using PIL, I believe, will add a dependency for the codebase.

Also, It's my understanding that the scripts feed the image through OpenCV which is capable of doing [geometrical transformations on read images](https://docs.opencv.org/3.3.0/da/d6e/tutorial_py_geometric_transformations.html).",rotate use memory storage could avoid io overhead write disk extractor face definitively performance git anyway memory much efficient library manipulate various way although believe add dependency also understanding feed image capable geometrical read,issue,negative,positive,positive,positive,positive,positive
369772012,"I did not really have any problems with the face_recognition, at least not that I noticed. Both face_recognition and face-alignment appear to run at the same speed for me, but that may be a limitation of my hardware (GTX 980).

I just figured if it was possible to make if it did not find an image with cnn that would try hog then it would also be possible that if cnn errored out to try with hog and not just exit, but I am not a python programmer and you all would have a better idea what is possible to do in the code.",really least appear run speed may limitation hardware figured possible make find image would try hog would also possible try hog exit python programmer would better idea possible code,issue,negative,positive,neutral,neutral,positive,positive
369770018,"@ppmdo 
>  the script could rotate the images (90°) rewrite them to disk, re-try and then store the rotation info in rotation.json or so. Bruteforce, basically.
> 
> Then, when converting, the process would have to invert the rotation and return the frame to its original orientation. However, I don't know if this would also be computationally expensive.
> 
I currently have a batch script which does exactly this, and I can say that it significantly slows down the process (mainly due to disk reads and writes and having to rescan frames with no faces multiple times). On the plus side, I see a huge improvement on the number of faces picked up. I am currently looking at a way to implement something similar within the code, to avoid the disk IO issue, but I need to try to push some usability fixes first, which will help my approach (hoping they get picked up).

Ideally we would only have to rotate the image once, to detect the face, then we could rotate the bounding rectangle, and associated landmarks by the appropriate amount when applying the convert, but I am drawing a blank on how to do this with dlib (my python is average, my dlib is non-existant). If anyone has any pointers, please let me know, otherwise I have other ideas, but there will be a performance hit, so I would make it optional.",script could rotate rewrite disk store rotation basically converting process would invert rotation return frame original orientation however know would also expensive currently batch script exactly say significantly slows process mainly due disk rescan multiple time plus side see huge improvement number picked currently looking way implement something similar within code avoid disk io issue need try push usability first help approach get picked ideally would rotate image detect face could rotate bounding rectangle associated appropriate amount convert drawing blank python average anyone please let know otherwise performance hit would make optional,issue,positive,positive,positive,positive,positive,positive
369768713,"I think scaling down first then extracting and cropping the face from original image is the ideal solution. Just be careful about cropping the face from scaled down version. Final image would be less quality.
[This](https://github.com/deepfakes/faceswap/issues/162) doesn't extract only crops but I think it scales down first.",think scaling first face original image ideal solution careful face scaled version final image would le quality extract think scale first,issue,positive,positive,positive,positive,positive,positive
369767889,"@DLSauron ah I assumed you were converting images all of the same size. Yea I think this is just a limitation of the library/resources. If you weren't having problems with face_recognition (not the new face-alignment) maybe we can have all 3 (hog, face_recognition, and face-alignment) available as options. Did face_recognition's cnn work well for you? Last I remember, it was extremely slow for me.

We can also work in a technique where images are scaled down before passing to the extractor. Then the alignment coords that are found can just be rescaled up to match the original.",ah assumed converting size yea think limitation new maybe hog available work well last remember extremely slow also work technique scaled passing extractor alignment found match original,issue,negative,positive,positive,positive,positive,positive
369767828,"Again, this is an issue I hit when running the pytorch version of face-alignment. Either upstream doesn't support multi-processing, or some code needs to change here to better support it. Either way, it seems to hit my GPU pretty hard when extracting (GTX 1080) , so if you're going down the GPU route, it probably isn't necessary to increase the cores.",issue hit running version either upstream support code need change better support either way hit pretty hard going route probably necessary increase,issue,positive,positive,positive,positive,positive,positive
369762396,"My experience with face-alignment (pytorch version) is that it has issues with any images over 720p. No rigorous testing, mind, just I have problems with bigger images, but if I resize down, all problems go away. I'd guess that this 'issue'. has pulled through. Try resizing down a bit and trying again.",experience version rigorous testing mind bigger resize go away guess try bit trying,issue,negative,neutral,neutral,neutral,neutral,neutral
369755853,"@oatssss the face-alignment from today is from the port to Keras I believe, no longer pytorch. This commit 232d931",today port believe longer commit,issue,negative,neutral,neutral,neutral,neutral,neutral
369750780,"Yeah sorry. I am a complete neophyte at this. And I am about to leave for a conference. When I get to the hotel I will look over things on my laptop and try to make it clearer. Sorry. 

Sent from my iPhone

> On Mar 1, 2018, at 5:14 PM, Ashwin <notifications@github.com> wrote:
> 
> @kellurian Cheers! I was slightly confused, as you said that you changed ""model.original file"" earlier but figured that you may have meant model_original.
> Also, I can confirm that it works.
> I can test the modified file on a single gpu device and will let you know if it works or not.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",yeah sorry complete neophyte leave conference get hotel look try make clearer sorry sent mar wrote slightly confused said file figured may meant also confirm work test file single device let know work reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
369749702,"@kellurian Cheers! I was slightly confused, as you said that you changed ""model.original file"" earlier but figured that you may have meant model_original.
Also, I can confirm that it works.  
I can test the modified file on a single gpu device and will let you know if it works or not.

",slightly confused said file figured may meant also confirm work test file single device let know work,issue,negative,negative,negative,negative,negative,negative
369748248,"Yes it appears to depend on the resolution of the image as you can see below it was able to get though 5 images but when it one that was 857 x 1280 and errored out. Funny thing is I had already resized that image yesterday because the original was to big for the original cnn extractor (2678 x 4000). 

Fun fact file size does not appear to matter to cnn only resolution. The original one was 580 KB, but the smaller one is 1.90 MB. With the original cnn extractor the 580 KB would give a OOM, but the 1.90 MB would extract just fine.

  2%|██▊                                                                                                                                                          | 5/282 [00:17<15:54,  3.44s/it]Failed to extract from image: D:\Fakes\Data\Test_A\1363877250141_resized.jpg. Reason: Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file C:\Users\DLSauron\AppData\Local\Temp\pip-build-8u_e3rm6\dlib\dlib\dnn\gpu_data.cpp:195. code: 2, reason: out of memory
Writing alignments to: D:\Fakes\Data\Test_A\alignments.json
-------------------------
Images found:        282
Faces detected:      5
-------------------------
Done!",yes depend resolution image see able get though one funny thing already image yesterday original big original extractor fun fact file size appear matter resolution original one smaller one original extractor would give would extract fine extract image reason error calling data float file code reason memory writing found done,issue,positive,positive,positive,positive,positive,positive
369744235,"@DLSauron The OOM is an all or nothing thing I believe. Have you been able to extract part-way through and then an OOM occurs?

@3xtr3m3d I don't understand, isn't the face-alignment port from pytorch the ""today's update"" that you're referring to? For what extractor are you getting an OOM?",nothing thing believe able extract understand port today update extractor getting,issue,negative,positive,positive,positive,positive,positive
369741734,Yes hog works. I wonder if it would be worth while to see if instead of just erroring out when getting a OOM error with cnn to switch over to hog for that file just like now how if it does not find a face with cnn it tries with hog.,yes hog work wonder would worth see instead getting error switch hog file like find face hog,issue,positive,positive,positive,positive,positive,positive
369739819,yes hog works also face_alignment from pytorch also work,yes hog work also also work,issue,negative,neutral,neutral,neutral,neutral,neutral
369726655,I am seeing the same on a few of my image sets. I ran an extract on 200 images last night with cnn and when I tried to run those same images today to test the new extractor it gave the OOM error. I assume this is because the new extractor is using more video memory.,seeing image ran extract last night tried run today test new extractor gave error assume new extractor video memory,issue,negative,positive,neutral,neutral,positive,positive
369694447,"@kellurian there is change in whitespace in your code and it shows like the complete file was changed. Maybe try to copy/paste only changed lines. (If you can't, I can try to do it on my side...)",change code like complete file maybe try ca try side,issue,negative,positive,neutral,neutral,positive,positive
369679743,"I have updated the base code from master and moved the drawing code to extract script, but I don't know if I did the merge correctly. Please take a look.",base code master drawing code extract script know merge correctly please take look,issue,negative,negative,negative,negative,negative,negative
369669221,"Bah on github, you can directly edit the file, it will make a PR",bah directly edit file make,issue,negative,positive,neutral,neutral,positive,positive
369664396,"Yeah I will try. I am quite new to this github thing but I’ll work on it tonight 

Sean

Sent from my iPhone

> On Mar 1, 2018, at 11:15 AM, Clorr <notifications@github.com> wrote:
> 
> @kellurian can you di a PR of that? it would be even more useful to users...
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",yeah try quite new thing work tonight sent mar wrote di would even useful reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
369656140,"Yup, maybe some other cool ideas to add to conversion will pop up later.

So the things that I'd still like to work in:
- Add cli options for perceptual loss and instance norm
- Add histogram matching
- Fix the damn masks",maybe cool add conversion pop later still like work add perceptual loss instance norm add histogram matching fix damn,issue,negative,positive,positive,positive,positive,positive
369655649,"No problem @GSonderling . `Enter` is certainly more natural for very new users, but beside of that is not of a strong interest. `Ctrl + c` adds convenience for usage in special conditions, like notebooks or remote run.",problem enter certainly natural new beside strong interest convenience usage special like remote run,issue,positive,positive,positive,positive,positive,positive
369654839,Alright thanks for the clarification. so there is only color correction missing and that can be added to Masked converter as well as Gan converter I presume.,alright thanks clarification color correction missing added masked converter well gan converter presume,issue,positive,neutral,neutral,neutral,neutral,neutral
369649211,"> you decided ? How about existing FaceSwap end-users ? Not developers, users.

If people don't like it there is no need to accept the PR. But right now the script behaves rather strangely, wouldn't you agree?

It basically just waits for any input followed by `Enter` and if there is none it just hangs. That is a little confusing. 

And for the record, I agree that my fix is not exactly the most elegant or optimal. I would prefer to get rid of those exceptions completely and just use normal key press events.

But all the solutions I tried, and that worked, involved either further imports, which would confuse the users, more threads, which is just an overkill, or worse of all bunch of code that is there just to handle one event.

Now, I don't want to cause problems by making unwanted changes to the code. So how about this, lets go to the playground and put it to vote, so that users decide what kind of behavior they want.

",decided people like need accept right script rather strangely would agree basically input enter none little record agree fix exactly elegant optimal would prefer get rid completely use normal key press tried worked involved either would confuse worse bunch code handle one event want cause making unwanted code go playground put vote decide kind behavior want,issue,positive,positive,positive,positive,positive,positive
369641107,"`use_smoothed_bbox` has to do with extracting, the new face-alignment port might have it included already as I was getting pretty smooth tracking with it

`smoothed_masked` in shaoanlu's code just applies a Guassian blur over the whole mask to smooth out the transitions between fake/real face

`use_color_correction` can be added as an option probably and shouldn't be that hard to do",new port might included already getting pretty smooth code blur whole mask smooth face added option probably hard,issue,negative,positive,positive,positive,positive,positive
369633417,"I just modified the model_original.py file as above and it works fine for me. The only issue I have had is that you can’t turn on the “allow growth” option which seems to bigger out and error when it’s enabled. Otherwise it seems to run on both cards equally and take up both vram per resource monitor

Sent from my iPhone

> On Mar 1, 2018, at 3:01 AM, Ashwin <notifications@github.com> wrote:
> 
> @kellurian or anyone who has this implemented, Could you please advise which files need to be changed to implement training with multiple gpu's
> Do I need to make changes to the training script or does this change need to be made in keras?
> Thanks!
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",file work fine issue turn allow growth option bigger error otherwise run equally take per resource monitor sent mar wrote anyone could please advise need implement training multiple need make training script change need made thanks reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
369617795,"No no I meant using the original gan convert with other trainers. Like with use_smoothed_mask, use_smoothed_bbox and use_color_correction(histogram-matching). Not smoothed_masked obviously but the other two. Or are they also tied to gan model?",meant original gan convert like obviously two also tied gan model,issue,positive,positive,positive,positive,positive,positive
369612155,"@Apollo122 I actually moved the gan convert code into masked so right now when converting using a gan model with the masked method, it uses a combination of the gan mask + face hull/rect. I'll change it so the gan mask is only used if gan converter is chosen.

All the gan converter does is take the mask output of the gan model and multiply it with the fake output. Not sure what you mean by being able to use it for other trainers as the mask is tied to the gan model. You could train the gan model for the sole purpose of generating masks, then use the mask with some other model if that's what you mean.",actually gan convert code masked right converting gan model masked method combination gan mask face change gan mask used gan converter chosen gan converter take mask output gan model multiply fake output sure mean able use mask tied gan model could train gan model sole purpose generating use mask model mean,issue,negative,positive,neutral,neutral,positive,positive
369603894,"its printing 
> Starting. Press ""Ctrl + C"" to stop training and save model

so end-users know what to do though",printing starting press stop training save model know though,issue,negative,neutral,neutral,neutral,neutral,neutral
369597093,">  I decided to drop the 'Enter' interrupt entirely.

you decided ? How about existing FaceSwap end-users ? Not developers, users.",decided drop interrupt entirely decided,issue,negative,neutral,neutral,neutral,neutral,neutral
369563647,I'll reopen there when gan stuff is finished.,reopen gan stuff finished,issue,negative,neutral,neutral,neutral,neutral,neutral
369561998,Closing this as #228 adresses this. Feel free to open new issue if there are still problems,feel free open new issue still,issue,positive,positive,positive,positive,positive,positive
369560758,"@flipflopbboi is #227 ok to solve this? Please add your review there, and continue discussion there...",solve please add review continue discussion,issue,negative,neutral,neutral,neutral,neutral,neutral
369559705,"@xthan I don't know if there is a strong theory behind the faceswap here. Here are some links about it:
- https://github.com/shaoanlu/faceswap-GAN/issues/26
- https://github.com/deepfakes/faceswap/issues/73

As @iperov said, we train a common encoder and 2 decoders (and we don't use the FaceA decoder when swapping FaceA to FaceB).

The purpose of that is to have an encoder that outputs good features when he sees a FaceA image, and that FaceB decoder unsderstands these features.

Schematically, I would summarize it like this:
- Encoder learns to recognize both FaceA and FaceB, and decoders, trained at the same time, know how to interpret encoder's output
- When we convert faces, encoder recognizes a FaceA, and generates an output that decoder of FaceB will understand

If we train the model on just one face, this would go like this:
- Encoder recognizes only FaceB and maybe overfit on FaceB
- When we try to faceswap FaceA, encoder will not recognize FaceA, and will generate an output that decoder does not understand. So it gives bad result.

On my side, I'm trying to make a generic encoder that is train with many faces so that he is not trained just on FaceB, but on thousands of different faces, so that it should output generic face features and won't be too overfitted to FaceB. Once done, I will try to train just a decoder with FaceB. @shaoanlu tried something like this already in [its One-For-All attempt](https://github.com/shaoanlu/faceswap-GAN/tree/master/notes). He was not totally satisfied of the result, but I think it is already interesting...",know strong theory behind link said train common use swapping purpose good image schematically would summarize like recognize trained time know interpret output convert output understand train model one face would go like maybe overfit try recognize generate output understand bad result side trying make generic train many trained different output generic face wo done try train tried something like already attempt totally satisfied result think already interesting,issue,positive,positive,positive,positive,positive,positive
369552000,"For me it seems ok, but I haven't tested yet. I could not work on the project lately, but I'm starting to get some more free time so I hope to give you a feedback soon...",tested yet could work project lately starting get free time hope give feedback soon,issue,positive,positive,positive,positive,positive,positive
369551454,Any suggestions? Would anyone like something added or changed? Did you find any undesirable behavior?,would anyone like something added find undesirable behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
369549770,"If something is buggy, more users will find it as it is now in the main repo. I know it is not a good practice, but many users don't check the PRs. @iperov , just have a look at issues to see if something is suspicous with your code...",something buggy find main know good practice many check look see something code,issue,negative,positive,positive,positive,positive,positive
369536426,"Ok, so should we merge this now?

@iperov you should ask to the original repo. Also I think you should submit your code to 1adrianb, maybe he can be interested to get your version as a separate branch on his repo.",merge ask original also think submit code maybe interested get version separate branch,issue,positive,positive,positive,positive,positive,positive
369501942,"In my own testing, I found that face_recognition outperforms face-alignment (pytorch version) for speed, sensitivity, and errors in everything BUT the zooming stability issue. In particular, for dynamic scenes with complex backgrounds and lots of motion, face-alignment has a much higher error rate and also misses more faces. However, in ""easy"" scenes, face-alignment is probably better because of the more stable tracking.

Given the constraints of the whole faceswap package (want nice neat, slowly moving faces anyways), face-alignment is probably better for most use cases. Face_recognition is still handy to keep around for tough scenes pushing the limits, though.",testing found version speed sensitivity everything stability issue particular dynamic complex lot motion much higher error rate also however easy probably better stable given whole package want nice neat slowly moving anyways probably better use still handy keep around tough pushing though,issue,positive,positive,positive,positive,positive,positive
369497367,Ooooh actually I extracted right before https://github.com/deepfakes/faceswap/pull/217/commits/236112afbc6bb65b0b43e25be37e3308c4f2fd35 and then did the pull. I will retry extracting tomorrow. Thanks!,actually extracted right pull retry tomorrow thanks,issue,negative,positive,positive,positive,positive,positive
369491166,are there any problems to use code from https://github.com/1adrianb/face-alignment with BSD 3-Clause License and merge with GPL 3 ?,use code license merge,issue,negative,neutral,neutral,neutral,neutral,neutral
369489016,"@oatssss great! Yeah I don't think adjust converter needs porting. Now only original gan convert remains. I wonder how the results would be with that and can we use it for other trainers.

@babilio alignment.json file's format has been changed. Have you extracted images again to get the new file? ",great yeah think adjust converter need original gan convert remains wonder would use file format extracted get new file,issue,positive,positive,positive,positive,positive,positive
369487970,"actually there is ONE Encoder training on two decoders.

```
self.encoder = self.Encoder()
self.decoder_A = self.Decoder()
self.decoder_B = self.Decoder()
...
self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
```",actually one training two,issue,negative,neutral,neutral,neutral,neutral,neutral
369481797,Your model would work well if the input had only one face. Won't the single autoencoder swap out all the faces in the input if it had more than one face?,model would work well input one face wo single swap input one face,issue,negative,negative,neutral,neutral,negative,negative
369474051,"I enabled the Masked converter for GAN models which should fix this in https://github.com/deepfakes/faceswap/pull/217/commits/236112afbc6bb65b0b43e25be37e3308c4f2fd35

@ppmdo can you see if you get better results with that commit? Remember to switch from gan to the masked converter.",masked converter gan fix see get better commit remember switch gan masked converter,issue,positive,positive,positive,positive,positive,positive
369473952,I did a rough enabling of the Masked converter for both gan models. This also fixes https://github.com/deepfakes/faceswap/issues/224 - poor results for faces that aren't upright in the original frame. I didn't bother with the Adjust converter because it gave me poor results for non-GAN anyway.,rough masked converter gan also poor upright original frame bother adjust converter gave poor anyway,issue,negative,negative,negative,negative,negative,negative
369461918,"@oatssss, Yes I've had bad results with rotated faces. I think this deserves attention.

When I read #197, I thought that if the Extract.py script didn't find a face (odd angles), the script could rotate the images (90°) rewrite them to disk, re-try and then store the rotation info in rotation.json or so. Bruteforce, basically. 

Then, when converting, the process would have to invert the rotation and return the frame to its original orientation. However, I don't know if this would also be computationally expensive. ",yes bad rotated think attention read thought script find face odd script could rotate rewrite disk store rotation basically converting process would invert rotation return frame original orientation however know would also expensive,issue,negative,negative,negative,negative,negative,negative
369459184,Thanks for this! For me it works way better than the previous extractor.,thanks work way better previous extractor,issue,positive,positive,positive,positive,positive,positive
369381192,"@Apollo122 those loss values look more like the non-GAN model. @chengjunjiecn you can convert with just a few images to see what it's like. If you're not happy, keep training!",loss look like model convert see like happy keep training,issue,positive,positive,positive,positive,positive,positive
369379244,It doesn't look like you added logic to merge the previous alignments file with the new incoming one. Does this clobber the alignments for the images that were already extracted?,look like added logic merge previous file new incoming one clobber already extracted,issue,negative,negative,neutral,neutral,negative,negative
369366283,"I wrote about bug - but no bug, all fine.",wrote bug bug fine,issue,negative,positive,positive,positive,positive,positive
369346919,"lmao, I'm not trying to steal your work! In the other PR I have I even asked @Apollo122 if he wanted to make his own commit for a couple of lines he wanted to add to my branch so he'd get credited.

Also, if I merge your commit to my branch, those commits still belong to you, so you'd still get credited. It's only if I copy/pasted your code and created my own separate commit would I be stealing it.",trying steal work even make commit couple add branch get also merge commit branch still belong still get code separate commit would stealing,issue,negative,neutral,neutral,neutral,neutral,neutral
369326411,usually below 0.08 is good enough. so if you like the preview so can stop the training.,usually good enough like preview stop training,issue,negative,positive,positive,positive,positive,positive
369281277,"I dont want speedup anything. Why rush ?
You, @Apollo122 , initiated communicate with @oatssss **that I did not ask.** 

> And next time please mind the words you use

Next time I will use words which I need. 
",dont want anything rush communicate ask next time please mind use next time use need,issue,negative,neutral,neutral,neutral,neutral,neutral
369281201,"@Apollo122 For now, this PR is standalone so I don't think @iperov needs to deal with @oatssss branch.",think need deal branch,issue,negative,neutral,neutral,neutral,neutral,neutral
369280519,"I also wondered about the warping thing. I came to the conclusion it is made so that the model does not take too much parameter from the original face like eye distance, chin shape, and so on. 

What we want in faceswap is mostly get high level features like face orientation, eyes and mouth closed or not but we don't want the output to resemble the original face too much. (I hope I'm clear ;-) )

But as @shaoanlu said, the fact the encoder is shared, lowers the probability for it to embed too much of the original face. At some point I also suggested we train an encoder with many different faces, just to get the common high level features, and then we could train only decoders. But maybe I'm still missing a point. For now I'm trying to find a dataset that would help me try this solution....",also warping thing came conclusion made model take much parameter original face like eye distance chin shape want mostly get high level like face orientation mouth closed want output resemble original face much hope clear said fact probability embed much original face point also train many different get common high level could train maybe still missing point trying find would help try solution,issue,positive,positive,positive,positive,positive,positive
369277334,"Exactly. if you want to speed up the process pull the @oatssss branch, extract images, delete some of them  then do the convert. And make sure that the images you deleted didn't get converted. Mind that you have to rename that folder to aligned. You can read the script. If everything is okay your code get merged asap.
And next time please mind the words you use. We don't need any conflict here. Everyone here has good intentions you can be sure of that.",exactly want speed process pull branch extract delete convert make sure get converted mind rename folder read script everything code get next time please mind use need conflict everyone good sure,issue,positive,positive,positive,positive,positive,positive
369275572,"@iperov, there is no intention from @oatssss to steal your work, it is normal that he merges his work to his branch so there is no conflict. 

Your work is already mergeable, so we can merge this PR before merging @oatssss PR",intention steal work normal work branch conflict work already merge,issue,negative,positive,positive,positive,positive,positive
369275065,@Clorr I think we settled the weight handling difference. I will check training code sometime. Because it's either the generator or training code gives different results,think settled weight handling difference check training code sometime either generator training code different,issue,negative,neutral,neutral,neutral,neutral,neutral
369274983,">  I'm gonna test both of your code. To make sure they don't conflict.

but if his code with my commit will be merged with main repo, and this PR rejected, then I will be not exist in contributors ?",gon na test code make sure conflict code commit main exist,issue,negative,positive,positive,positive,positive,positive
369274391,"> can I still use only hog for extract?

yes",still use hog extract yes,issue,negative,neutral,neutral,neutral,neutral,neutral
369272864,"Dude are serious? no one is stealing anything. I asked him to merge because I'm gonna test both of your code. To make sure they don't conflict. 
As for my question let me ask this way: can I still use **only hog** for extract?",dude serious one stealing anything merge gon na test code make sure conflict question let ask way still use hog extract,issue,negative,positive,neutral,neutral,positive,positive
369272328,"Note that maybe the code from the faceswap-GAN repo has changed since I took the code. If there is a difference in the weights file handling, it is not intentional from my part...",note maybe code since took code difference file handling intentional part,issue,negative,neutral,neutral,neutral,neutral,neutral
369268491,@Clorr what you think about stealing my work to @oatssss branch ?,think stealing work branch,issue,negative,neutral,neutral,neutral,neutral,neutral
369268145,"@Apollo122 what you mean ? I tested with hog, all working",mean tested hog working,issue,negative,negative,negative,negative,negative,negative
369266774,"@oatssss 

**I disagree with merging my work with your branch.**

Dont steal my work.
I want to be in contributors.
",disagree work branch dont steal work want,issue,negative,neutral,neutral,neutral,neutral,neutral
369266554,"@iperov can you clarify this: in extract if user selects hog your code doesn't work but if he selects CNN your code activates, first it tries CNN if it fails it tries hog. Or did you remove the options (cnn or hog) and combine them together? ",clarify extract user hog code work code first hog remove hog combine together,issue,negative,positive,positive,positive,positive,positive
369262215,"I believe once your changes merge into the main repo, you'll be considered a contributor https://help.github.com/enterprise/2.8/user/articles/i-don-t-see-myself-in-the-repository-contributors-graph/. So I can merge this into my fork, but it won't make you a contributor to the base repo until the branch from my fork gets merged, or this PR gets merged (both PRs can merge with no problem).

Your changes don't conflict with mine so it can be merged directly into the repo through this PR. However, you added this [large file](https://github.com/iperov/faceswap/blob/df3b707095dc5bc21d0fb4cc6a6becb19b9dcb03/lib/FaceLandmarksExtractor/2DFAN-4.h5) and I'm not sure how we want to handle large files @Clorr, if we want to store them in the repo, or pull them from another remote source.

@Apollo122 I merged this into `oatssss/update-GAN-v2`",believe merge main considered contributor merge fork wo make contributor base branch fork merge problem conflict mine directly however added large file sure want handle large want store pull another remote source,issue,negative,positive,neutral,neutral,positive,positive
369259980,"It is inherited from the original deepfakes' script. He said its inspired by [this paper](https://arxiv.org/abs/1706.02932v2). My understanding is that the warping is introduced to make the model perform batter on this specific task (face swapping). For example, in test phase, we feed face B in to generator A, generator A will treat face B as if it is a warped face A and reconstruct it to a face-A-look-alike face B. Also the warping can function as regularization to prevent overfit.

But recently I becomes suspicious about this warping because 

1. I can got good result either when I reduce the strength of warping, 
2. The encoder weights are shared among the two generators. So as long as the encoder produce good embedding (this can be achieved w/o warping, e.g., adding domain adversarial loss as in [XGAN](https://arxiv.org/abs/1711.05139)), the decoder should reconstruct good result.

I wonder if anyone would like to run some experiments w/o warping.",original script said inspired paper understanding warping make model perform batter specific task face swapping example test phase feed face generator generator treat face warped face reconstruct face also warping function regularization prevent overfit recently becomes suspicious warping got good result either reduce strength warping among two long produce good warping domain loss reconstruct good result wonder anyone would like run warping,issue,positive,positive,positive,positive,positive,positive
369256391,Thanks for the clarification! I was also wondering what is the purpose of warping the faces during training?,thanks clarification also wondering purpose warping training,issue,negative,positive,positive,positive,positive,positive
369255553,"Sorry for the late reply, my computer was broken and I have very little access to github.

I think line 184 should be the masked result and 185 for raw result (which means before masking). `tA` and `tB` are non-warped faces  and `wA` and `wB` warped ones. ",sorry late reply computer broken little access think line masked result raw result ta wa warped,issue,negative,negative,negative,negative,negative,negative
369198192,"@babilio 
Oops, I just realized I overlooked indent. 

Anyway, if you look at the code, after I fix it, you can see that the preview window still behaves as it did before. You can still stop it with `Enter`.",indent anyway look code fix see preview window still still stop enter,issue,negative,neutral,neutral,neutral,neutral,neutral
369187768,I'm not in charge of that. You should ask @Clorr . But if your code gets merged with master I don't see why not.,charge ask code master see,issue,negative,neutral,neutral,neutral,neutral,neutral
369183376,"@Apollo122 if he merge with my fork, will I exist in contributors list of faceswap repo ?",merge fork exist list,issue,negative,neutral,neutral,neutral,neutral,neutral
369166293,@oatssss can you merge this with your improvement. Im gonna test them both. Alignment file format changed let's make sure it doesn't conflict.,merge improvement gon na test alignment file format let make sure conflict,issue,negative,positive,positive,positive,positive,positive
369152013,If we are also sure that gan64 model is the same with original. We can move on and check the trainer scripts.,also sure gan model original move check trainer,issue,positive,positive,positive,positive,positive,positive
369122016,"I generated a summary for the models and compared them to shaoanlu's https://gist.github.com/oatssss/3c1bcae6d00c8ce7f4852ac9e397cee9, they appear to be the same. Whatever's going differently is I think either in the loss functions or generation of batches.",summary appear whatever going differently think either loss generation,issue,negative,neutral,neutral,neutral,neutral,neutral
369064211,"I think serializing it would help implement things like #221 more easily, right? But either option would be great right now because I don't find GAN very useful at the moment because of this problem.

Thank you for all the work you have been doing!",think would help implement like easily right either option would great right find gan useful moment problem thank work,issue,positive,positive,positive,positive,positive,positive
369063925,I agree that Ctrl + C is better than ENTER and all the difference between keys in OS.,agree better enter difference o,issue,positive,positive,positive,positive,positive,positive
369060734,"Enter works fine and reliably for me when I have the preview window and you focus on it before pressing. I am not sure removing it completely is good thing. Couldn't Ctrl+C just stop mid saving weights, potentially corrupting model files?",enter work fine reliably preview window focus pressing sure removing completely good thing could stop mid saving potentially corrupting model,issue,positive,positive,positive,positive,positive,positive
369054262,"Yes, please ask many questions! Hopefully I can answer them. For this one, yes it's intended but that can change. The difference between shaoanlu's and this port is basically how we choose to save the model. This port opts to save the generator model directly, whereas shaoanlu saves the encoder and decoders that make up the generator.

In both the port and shaoanlu's we have:
``` python
encoder = Encoder()
decoder_A = Decoder_ps()
decoder_B = Decoder_ps()   
```
You can verify that both functions `Encoder()` and `Decoder_ps()` return a Keras `Model`. We can call `save_weights` and `load_weights` on these model instances to generate weight files for each, and in fact that's what [shaoanlu's code](https://github.com/shaoanlu/faceswap-GAN/blame/76e14c42efa0c0adbb731d748f866e07793708d1/FaceSwap_GAN_v2_sz128_train.ipynb#L880-L882) does.

Further down in the code, we use the encoder and decoder models to construct the generator model:
``` python
netGA = Model(x, decoder_A(encoder(x)))
netGB = Model(x, decoder_B(encoder(x)))
```
Since these are also models, we can also call `save_weights`/`load_weights` on these instances, and in fact that's what [our port](https://github.com/oatssss/faceswap/blob/f3bb173cf1038888e10bc88e6fcc4a1127c6f043/plugins/Model_GAN/Model.py#L158-L159) does.

So that's the difference: we restore the generator as-is and shaoanlu restores the individual pieces then rebuilds the generator.

You'll notice that both generators share the same encoder, so weights for the encoder end up being stored twice. This was already raised in issue https://github.com/deepfakes/faceswap/issues/200.",yes please ask many hopefully answer one yes intended change difference port basically choose save model port save generator model directly whereas make generator port python verify return model call model generate weight fact code code use construct generator model python model model since also also call fact port difference restore generator individual generator notice share end twice already raised issue,issue,positive,positive,positive,positive,positive,positive
369044246,"@oatssss so i started to comparing the model code between [yours ](https://github.com/oatssss/faceswap/blob/update-GAN-v2-tests/plugins/Model_GAN128/Model.py)and [original](https://github.com/shaoanlu/faceswap-GAN/blob/0260702077261b77242217d04734426851f7ce42/FaceSwap_GAN_v2_sz128_train.ipynb). I may sometimes ask stupid questions so bear with me :)

First question im gonna ask is that in original code on section 6 load models i see that `netDA, netDB, encoder, decoder_A and decoder_B` get their weights loaded. There are additional weights that we don't create and use such as `encoder.h5, decoder_A.h5, decoder_B.h5` .On your code `encoder`, `decoder_A` and `decoder_B` don't get loaded with weights. Instead `netGA` and `netGB `are loaded with weights. Is this intended? ",model code original may sometimes ask stupid bear first question gon na ask original code section load see get loaded additional create use code get loaded instead loaded intended,issue,negative,positive,neutral,neutral,positive,positive
368995858,"The readme in the git page I shared says something about 4gb 980m. Only extremely high resolution pictures might be problem its written, such as 6000x6000 so I think we are clear :) haven't read the whole thing but i think our 256x256 might be used as training images for it also",git page something extremely high resolution might problem written think clear read whole thing think might used training also,issue,negative,positive,positive,positive,positive,positive
368993050,"I haven't tried to train an SR model, what if it requires the same amount of vram! :P",tried train model amount,issue,negative,neutral,neutral,neutral,neutral,neutral
368992238,Might be. Only problem with that is vram: max batch size I can do with gan128 is 20 so for gan256 it would be 10 :) I guess we can try it when current gan in our repo works same as well as the convert script. But as i said because of the vram SR might be faster.,might problem batch size gan gan would guess try current gan work well convert script said might faster,issue,negative,neutral,neutral,neutral,neutral,neutral
368983261,"The original image would be the enlarged face that's blurry (say a 128x128 swap scaled up to 200x200 to match the frame). SR will scale it up to 400x400 to improve the quality, then scale it back down to the original size (which is still larger than 128x128). To train the SR model, I believe you'd need images as large as the resolution you're trying to achieve. So if you wanna enhance 200x200 images by doubling resolution, you'd need to train it with faces at least 400x400, but I imagine SR requires inputs of fixed size, so you'd likely need to train an SR model capable of 256x256->512x512, bilinear scale the 200x200 to 256x256 to feed it through, then scale down to the target size of 200x200 again.

Also, from shaoanlu's findings, it seems that gan64/128 models are already doing a bit of super resolution on top of the autoencoder base, so maybe adding SR will only make a difference if we aim for something higher than 2x SR.

Maybe just adding a 256 model might work better?",original image would enlarged face blurry say swap scaled match frame scale improve quality scale back original size still train model believe need large resolution trying achieve wan na enhance doubling resolution need train least imagine fixed size likely need train model capable bilinear scale feed scale target size also already bit super resolution top base maybe make difference aim something higher maybe model might work better,issue,positive,positive,positive,positive,positive,positive
368981546,Yea I didn't know of a way to set the default value of an option to a value based on another option.,yea know way set default value option value based another option,issue,positive,neutral,neutral,neutral,neutral,neutral
368980252,Yes that would improve the quality but if we scale it down again wouldn't the quality of close-ups remain the same? Which is terrible :),yes would improve quality scale would quality remain terrible,issue,negative,negative,negative,negative,negative,negative
368978495,"The way I understood it is the super resolution will produce 2x bigger image, but then that image will just be rescaled down back to the original size. The end result is an image of the same size, just better image quality, so the original transforms should still work.

I thought neural enhance and super resolution are the same thing.",way understood super resolution produce bigger image image back original size end result image size better image quality original still work thought neural enhance super resolution thing,issue,positive,positive,positive,positive,positive,positive
368977618,Maybe it doesn't conflict with your work but it's better to check.,maybe conflict work better check,issue,negative,positive,positive,positive,positive,positive
368975468,"He added a feature. If user deletes a false-positive face, it's entry alignment.json gets skipped during convert. For it to work he did some changes which will be merged with master soon",added feature user face entry convert work master soon,issue,negative,neutral,neutral,neutral,neutral,neutral
368968080,@oatssss I checked the code. It seems default value is still none,checked code default value still none,issue,negative,neutral,neutral,neutral,neutral,neutral
368967093,Be sure that you merge with @oatssss changes. He changed the format of alignment file. https://github.com/deepfakes/faceswap/issues/208#issuecomment-368715218,sure merge format alignment file,issue,negative,positive,positive,positive,positive,positive
368961797,"@ruah1984 pull the latest commit https://github.com/oatssss/faceswap/commit/f3bb173cf1038888e10bc88e6fcc4a1127c6f043 from that `update-GAN-v2-tests` branch. It'll automatically restore the generator strength back to normal past 10k iterations. If you want to do it at 5k, just change [these lines](https://github.com/oatssss/faceswap/commit/f3bb173cf1038888e10bc88e6fcc4a1127c6f043#diff-d40a5cd2e84ef4154ddc11be9a7128acR133)

@Apollo122 as far as I can tell, we are using shaoanlu's code (at least for the model/trainer) just refactored to fit within the OOP class structure being used here. If you can find any differences please let me know. There may be a difference in the generation of training batches, it seemed to me like there wasn't, but I think this could have an effect on the results we get.",pull latest commit branch automatically restore generator strength back normal past want change far tell code least fit within class structure used find please let know may difference generation training like think could effect get,issue,positive,positive,neutral,neutral,positive,positive
368954967,"but fixed :)

also Keras implementation of face_alignment x1.5 - x2 times faster",fixed also implementation time faster,issue,negative,positive,neutral,neutral,positive,positive
368935133,"@oatssss i try 5 to 10k itr tonight, let's check able to get same result from shaoanlu or not. https://github.com/oatssss/faceswap/commit/44651d7a8dbd1b100c25c391ec93567c29d33259
",try tonight let check able get result,issue,negative,positive,positive,positive,positive,positive
368918727,So we can't just use Shaoanlu's code? should we also experiment on it so get the same results? Or there are parts that we are unable to Port?,ca use code also experiment get unable port,issue,negative,negative,negative,negative,negative,negative
368903577,"https://github.com/oatssss/faceswap/commit/44651d7a8dbd1b100c25c391ec93567c29d33259 I'm able to get masks somewhat close to what I was getting before with shaoanlu's if I weaken the generator. The swapped face results aren't too great tho, but I'm checking to see what happens if I restore the strength of the generator after a certain number of iterations.

Face A
![screen shot 2018-02-27 at 9 51 08 am](https://user-images.githubusercontent.com/7298535/36735285-d0d1a316-1ba3-11e8-8836-f6ac94887bd9.png)
",able get somewhat close getting weaken generator face great tho see restore strength generator certain number face screen shot,issue,positive,positive,positive,positive,positive,positive
368900122,Mask output is different from shaoanlu's maybe there are other different things too. @ruah1984 tests for both. I think it should be resolved before merging to master . Also without convert features I think it would be useless for non-programmers.,mask output different maybe different think resolved master also without convert think would useless,issue,negative,negative,negative,negative,negative,negative
368898151,"@RunetX It is always possible to have a utility to parse extracted photos and group them by similarity, but as @Apollo122 said it won't be perfect. But please open a new issue to discuss about it, as it is a different subject from the original issue",always possible utility parse extracted group similarity said wo perfect please open new issue discus different subject original issue,issue,positive,positive,positive,positive,positive,positive
368891980,"@oatssss Thank you for taking time to review/correct/enhance all of this.

My first GAN plugin was based on [the first shaoanlu's attempt to make a class from notebook](https://github.com/shaoanlu/faceswap-GAN/blob/master/temp/faceswap_GAN_keras.ipynb) and I never checked how consistent it was with the notebooks.

On the GAN128 part I tried to make a plugin directly from the notebook. However it is quite hard to modify the code so it fits in classes. Actually, I was thinking reverting all and doing this again from scratch...

If the guys here are ok with your code, I'm happy if it goes into master because on my side, it has been a bit tedious to do all of this ;-)",thank taking time first gan based first attempt make class notebook never checked consistent gan part tried make directly notebook however quite hard modify code class actually thinking scratch code happy go master side bit tedious,issue,positive,positive,positive,positive,positive,positive
368887218,Additional options are always welcomed. So your work on MTCNN would be merged most likely.,additional always work would likely,issue,negative,neutral,neutral,neutral,neutral,neutral
368886586,"@Clorr nevermind about models, they can be in lib\FaceLandmarksExtractor\ dir inside this repo

super problem !
When Keras model loaded, I cannot use dlib_cnn_face_detector
OOM error:

```
>>>dlib_cnn_face_detector(image,1)
Traceback (most recent call last):
  File ""<console>"", line 1, in <module>
RuntimeError: Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file D:\FaceSwapTorrent\FaceSwap\_internal\bin\dlib\dlib\dnn\gpu_data.cpp:195. code: 2, reason: out of memory
```
",inside super problem model loaded use error image recent call last file console line module error calling data float file code reason memory,issue,negative,positive,positive,positive,positive,positive
368885966,"@ruah1984 Go ahead without for now. Training shouldn't be affected by it, its just a consideration for better alignment. I'll probably submit the MTCNN work on a few branch into master. Its also not clear to me whether moving to pytorch would make MTCNN unneeded.

Something is off for me in masking steps for this branch recently. Masks have degraded for me and never seem to improve even after 40k iterations. I have not seen this issue in the GAN128 fork on #151 nor faceswap-GAN but it sounds like others are seeing intermittent stuff like this too. I'm wondering if there are unintended differences in the model between the GAN implementations...",go ahead without training affected consideration better alignment probably submit work branch master also clear whether moving would make unneeded something branch recently degraded never seem improve even seen issue gan fork like seeing intermittent stuff like wondering unintended model gan,issue,positive,positive,positive,positive,positive,positive
368883540,"1. We can use extractor same as usual. Then we have dataset of several faces (wrong detections). 
A1, B1, A2, A3, A4, B4, A5, B5, A6, A7, C7
2. To run similar images app with this dataset we get several sets with different faces
[A1, A2, A3, A4, A5, A6, A7], [B1, B4, B5], [C7]
3. Generate alignments.json for sets
4. Run train or extract with any set separately
5. Profit",use extractor usual several wrong run similar get several different generate run train extract set separately profit,issue,negative,negative,negative,negative,negative,negative
368881916,"Thanks for this initiative ;-)

I'll check how we can download the h5 model file automatically, maybe with something like `face-recognition-models`",thanks initiative check model file automatically maybe something like,issue,positive,positive,positive,positive,positive,positive
368875532,What I mean is face detector often gives wrong results. Maybe it can be used for initial results but you would have to go through each folder to remove false-positive and put wrongly recognized faces to appropriate folders.,mean face detector often wrong maybe used initial would go folder remove put wrongly appropriate,issue,negative,negative,neutral,neutral,negative,negative
368868607,"I thought that the mechanisms of machine learning is sometimes used to split the dataset by category.
For example https://github.com/ankonzoid/artificio/tree/master/similar_images_AE",thought machine learning sometimes used split category example,issue,negative,neutral,neutral,neutral,neutral,neutral
368852689,"almost ported face_alignment from PyTorch to Keras, output points 100% identical",almost ported output identical,issue,negative,neutral,neutral,neutral,neutral,neutral
368831136,"I making one file FaceLandmarksExtractor.py
@Clorr is normally to include 95mb model file inside py (and mmod_human_face_detector.dat) and save it to os.getcwd() if not exists, and use it?",making one file normally include model file inside save use,issue,negative,positive,positive,positive,positive,positive
368830478,@TooMuchFun  @oatssss ， if the MTCNN complete i  can try using with the result i have from shaoanlu faceswap GAN128 repo to verify the MTCNN. my new setup 1080TI at least can help for all trial run. ,complete try result gan verify new setup ti least help trial run,issue,negative,negative,neutral,neutral,negative,negative
368813926,"Sorry for bad English, I use translator.
It would be great if the program automatically divided similar faces into separate directories with its alignments.json file. In this case, it would be possible to replace individually any of the found faces ",sorry bad use translator would great program automatically divided similar separate file case would possible replace individually found,issue,negative,negative,neutral,neutral,negative,negative
368791060,@cojosao  @enniowatson can you test this? Mind that you have to run extract script again to get the alignment file. Its format has been changed.,test mind run extract script get alignment file format,issue,negative,neutral,neutral,neutral,neutral,neutral
368759765,How about neural enhance ?improve the resolution through neural network as well.,neural enhance improve resolution neural network well,issue,positive,neutral,neutral,neutral,neutral,neutral
368749209,"I realized that [`Convert_Masked.py`](https://github.com/deepfakes/faceswap/blob/819d10702a8253aec228b8083cdd0857f28e548d/plugins/Convert_Masked.py#L24) already does this, however, it just recalculates the rotation matrix with umeyama on the fly instead of serializing/deserializing in an alignments file.

Any thoughts on which strategy to prefer? Re-calculating the transform on the fly will be more computationally demanding, but it may be negligible in comparison to the rest of the conversion process. Having the rotations in the alignments file might also be useful in the future.",already however rotation matrix fly instead file strategy prefer transform fly demanding may negligible comparison rest conversion process file might also useful future,issue,negative,positive,positive,positive,positive,positive
368694182,"@oatssss ,first try 5k, FaceSwap_GAN_v2_sz128_train. (Shaoanlu)
[1/150][5100] Loss_DA: 0.182680 Loss_DB: 0.180278 Loss_GA: 0.717723 Loss_GB: 0.731879 time: 3412.171057
because is NSFW, i only can share you the mask. from what i get from Shaoanlu faceswap-gan 128, still can observe the face shape, but our faceswap here is totally white as what i comment before,  something wrong.I will continue train until 15k  and check if longer hour train, any change for Shaoanlu faceswap-gan 128

face_a
![face_a](https://user-images.githubusercontent.com/34621170/36702588-acb80bf2-1b92-11e8-98f9-ec2a29ae4178.PNG)

face_b
![face_b](https://user-images.githubusercontent.com/34621170/36702589-ae223d00-1b92-11e8-9099-421cb204303b.PNG)
",first try time share mask get still observe face shape totally white comment something continue train check longer hour train change,issue,negative,positive,positive,positive,positive,positive
368672706,Definitely worth working on it. Have you checked shaonlu's merge? Maybe there are approaches that we can benefit,definitely worth working checked merge maybe benefit,issue,positive,positive,positive,positive,positive,positive
368671722,"In original scripts there is a script called init.py . What it does is just swapping the faces using the trained model, it doesn't do the merging. You put those swapped faces into aligned folder and run merge script. Merge reads from alignment file also.
I think you are suggesting the same thing. And yes if we do this we can augment generated faces before merge them back into original frames. We should keep one thing in mind though if we double the resolution  I believe we should do some changes within merge script also coordinates of the landmarks must be recalculated but maybe a simple multiplication would work.",original script swapping trained model put folder run merge script merge alignment file also think suggesting thing yes augment merge back original keep one thing mind though double resolution believe within merge script also must maybe simple multiplication would work,issue,positive,positive,positive,positive,positive,positive
368665406,"Maybe we can add an option to separate convert into 2 stages: swap and patch.
Swap will use the alignments to grab the face from the frame and swap it with the target.
Patch just puts the face back into the frame.
This would open up the possibility to perform any intermediate actions between the 2, like for example applying super resolution before patching.",maybe add option separate convert swap patch swap use grab face frame swap target patch face back frame would open possibility perform intermediate like example super resolution,issue,positive,positive,positive,positive,positive,positive
368659716,@ruah1984 can you retry shaoanlu's using the same faceset and see what kind of masks you get?,retry see kind get,issue,positive,positive,positive,positive,positive,positive
368656762,"Same as what i have right now, running 8K of face A, 10k of face B (big sample size), and batch size=64, 5k iterations.  

face A 2nd column is white, face B 3rd column is white. 
i have try shaoanlu repo for GAN before, the result for the mask are different.  ",right running face face big sample size batch face column white face column white try gan result mask different,issue,negative,positive,neutral,neutral,positive,positive
368646823,"I have been training another model -PL enabled- with 1300(A) and 3000(B) images. Quality is really good but mask doesnt seem to be working right. Instead of handling the occlusion it seems just removing it. And on mask screen I see almost pure white columns(rgb 254,254,254).
For Face_A 2nd column is white and for Face_B 3rd column is white. I activated the optional lines. Lets see how it does effect the mask.

@oatssss 
loss value(DA) seems stuck at 0.17 ~ 0.18 but [shaoanlu says that loss value in GAN does not represent output quality](https://github.com/shaoanlu/faceswap-GAN/issues/43#issuecomment-364634620)",training another model quality really good mask doesnt seem working right instead handling occlusion removing mask screen see almost pure white column white column white optional see effect mask loss value da stuck loss value gan represent output quality,issue,negative,positive,positive,positive,positive,positive
368630459,"Yeah you can just add it yourself man.
Edit : forgot to tell, if use a Boolean make sure it deactivates the lines above the commented out(optional) ones.",yeah add man edit forgot tell use make sure optional,issue,positive,positive,positive,positive,positive,positive
368625992,"cool, do you wanna make a PR from your own fork into this branch so you can have the commit, or do you want me to just add it myself?",cool wan na make fork branch commit want add,issue,positive,positive,neutral,neutral,positive,positive
368612527,"@oatssss 
i added the optional lines and commented them out. This is for the GAN128 trainer script. i believe it would be the same for GAN64 script as well. You can merge it. Preferably you may define a boolean to activate these.

        `def define_loss(self, netD, real, fake_argb, fake_sz64, distorted, vggface_feat=None):   
        
        ...........................
            loss_G = 1 * self.loss_fn(output_fake, K.ones_like(output_fake))  
        # ==========  
        loss_G += K.mean(K.abs(fake_rgb - real))
        # loss_G += K.mean(K.abs(fake - real)) #OPTIONAL After 15k iteration**
        loss_G += K.mean(K.abs(fake_sz64 - tf.image.resize_images(real, [64, 64])))
        # ==========
        
        ...............................
            real_sz224 = Lambda(preprocess_vggface)(real_sz224)
            # ==========
            fake_sz224 = tf.image.resize_images(fake_rgb, [224, 224])
            #fake_sz224 = tf.image.resize_images(fake, [224, 224]) #OPTIONAL After 15k iteration**
            fake_sz224 = Lambda(preprocess_vggface)(fake_sz224)
            # ==========   
        .....................................
        
        return loss_D, loss_G`",added optional gan trainer script believe would gan script well merge preferably may define activate self real distorted real fake real optional iteration real lambda fake optional iteration lambda return,issue,negative,negative,negative,negative,negative,negative
368592694,"Sorry, I can't try the code right now, so I did this a bit blindly... Can you test again please?",sorry ca try code right bit blindly test please,issue,negative,negative,negative,negative,negative,negative
368584044,"now I have this:

```
(intel_face) FRSUNPWW0180:faceswap hugs$ python faceswap/faceswap.py extract -i M/frames/ -o M/faces/
Input Directory: /Users/hugs/Documents/TRYouts/faceswap/M/frames
Output Directory: /Users/hugs/Documents/TRYouts/faceswap/M/faces
Using json serializer
Starting, this may take a while...
Loading Extract from Extract_Align plugin...
  0%|                                                   | 0/918 [00:00<?, ?it/s]
Failed to extract from image: /Users/hugs/Documents/TRYouts/faceswap/M/frames/mission0.png. Reason: name 'filename' is not defined
Writing alignments to: /Users/hugs/Documents/TRYouts/faceswap/M/frames/alignments.json
-------------------------
Images found:        918
Faces detected:      0
-------------------------
Done!

```",python extract input directory output directory starting may take loading extract extract image reason name defined writing found done,issue,negative,neutral,neutral,neutral,neutral,neutral
368549447,"Thanks for the feedback, I merged a pull request today. I'm checking to correct that...",thanks feedback pull request today correct,issue,negative,positive,positive,positive,positive,positive
368543505,@ruah1984 yea maybe you can confirm that you get good results cuz I don't,yea maybe confirm get good,issue,negative,positive,positive,positive,positive,positive
368513607,see also #163 for china specific code,see also china specific code,issue,negative,neutral,neutral,neutral,neutral,neutral
368512967,"@ruah1984 convert needs work. Some essential features are missing. Check the image I posted you can see the bbox. I believe @oatssss is working on it. 
But you can start the training I don't think model would change.
",convert need work essential missing check image posted see believe working start training think model would change,issue,negative,negative,neutral,neutral,negative,negative
368505936,"Can this be use now? I just get my new setup gpu with 11GB, I can help to try it again ",use get new setup help try,issue,negative,positive,positive,positive,positive,positive
368501832,Did you use that refinement suggestion after 15k? My masks end up full black (I remember getting full white too) at around 5k iterations. I'll see what happens when I use the refinement change a bit earlier.,use refinement suggestion end full black remember getting full white around see use refinement change bit,issue,negative,positive,positive,positive,positive,positive
368407960,@p0sera I tested your app with the addition of the multiGPU addition code I added to the Model_Original.Py file and it works great. You could add a plugin option for multi-GPU on your next version if you like. I think your app works great and is far less buggy than fakeapp.,tested addition addition code added file work great could add option next version like think work great far le buggy,issue,positive,positive,positive,positive,positive,positive
368407124,In my opinion mask results are not great for my model either. For how long did you train it? I trained that set for 25k iterations with batch_size 40. That set only contains 300 photos each so it's rather a small set. You may try again with PL enabled. Also there is a tip under define_loss function to be used after 15k iterations. You can change those lines too. Later today I'll upload it to gist so you can merge it.,opinion mask great model either long train trained set set rather small set may try also tip function used change later today gist merge,issue,positive,positive,positive,positive,positive,positive
368404779,"Will try this. Can you make the default path for this to ""./folder_to_convert/aligned"" ? Like in the original scripts? People are used to copy this folder to the folder that contains the photos that they want to convert.",try make default path like original people used copy folder folder want convert,issue,positive,positive,positive,positive,positive,positive
368402097,"I have a fix here https://github.com/oatssss/faceswap/commit/b6be9db0ee8357f4f5a8af42e20bc77ec7bf0278 in branch `update-GAN-v2-tests`. Please check if it has the behaviour your looking for. I only tested to check that it still works for solo-face frames.

**Note** I changed the format for naming aligned images from

`{filename}{frame}{faceID}`
to
`{filename}{frame}_{faceID}`

So you'll have to run the extraction again, sorry! For conversion, you also now need to specify the folder of aligned images with option `-a` or `--input-aligned-dir`.

I didn't like how my aligned image names seemed like they just got multiplied by 10. The `_` gives a clear separation between frame and faceID.",fix branch please check behaviour looking tested check still work note format naming frame frame run extraction sorry conversion also need specify folder option like image like got clear separation frame,issue,positive,negative,negative,negative,negative,negative
368350532,"It's driving me nuts. I don't know what changed on my system, but I'm somehow no longer able to get good mask results from neither shaoanlu's nor this branch for both gan64 and gan128. I don't remember being able to run gan128 before tho because of low vram (but I could've been trying to use too large a batch size and didn't realize).

I even tried that same faceset you uploaded @Apollo122 and trained with gan128 and ended up no where near the results you had, at least for the masks.",driving know system somehow longer able get good mask neither branch gan gan remember able run gan tho low could trying use large batch size realize even tried trained gan ended near least,issue,negative,positive,positive,positive,positive,positive
368328468,Great! Just mind that alignment file is not necessary to be a json file. I think there are couple supported extensions. You can see them in script,great mind alignment file necessary file think couple see script,issue,positive,positive,positive,positive,positive,positive
368327925,Adding multiple assignees to get the chance wide range of objections on this from all contributors.,multiple get chance wide range,issue,negative,negative,neutral,neutral,negative,negative
368327265,"Seems simple enough to do in Python, I'll try and do this today.",simple enough python try today,issue,negative,neutral,neutral,neutral,neutral,neutral
368326670,@TooMuchFun so MTCNN is for detecting the faces right? If so it should be added in to extract script and save the values in alignment.json which will be used in convert. I think dlib's CNN will be dropped because of the zoomed in output and pytorch's CNN (face-alignment) will be added. [Discussion here](https://github.com/deepfakes/faceswap/issues/187),right added extract script save used convert think output added discussion,issue,negative,positive,positive,positive,positive,positive
368326283,Working on MTCNN right now. Hopefully will get staged in a few days...,working right hopefully get staged day,issue,negative,positive,positive,positive,positive,positive
368325478,"Yeah and adding blur is important at least it is for the original script.
What we should do is add all there's in shaoanlu's convert and experiment on it to get the best results. And yes using alignment.json is important and we should use it for the convert part. So don't waste your time getting face landmarks in convert as they should be provided in alignment.json. There's also a minor improvement you can add. Details in this [discussion](https://github.com/deepfakes/faceswap/issues/208#issuecomment-368283447)",yeah blur important least original script add convert experiment get best yes important use convert part waste time getting face convert provided also minor improvement add discussion,issue,positive,positive,positive,positive,positive,positive
368324779,"I don't know what `use_smoothed_mask` does, but I believe `use_smoothed_bbox` is better fit to go into the extraction process. If I'm not mistaken, the strategy would be to use the kalman filter to get the smoothed bbox transformations, then save them to `alignments.json`. Potentially we could also use mtcnn for the extract too.

Edit: Seems like `use_smoothed_mask` just applies a blur on the whole mask.",know believe better fit go extraction process mistaken strategy would use filter get save potentially could also use extract edit like blur whole mask,issue,positive,positive,positive,positive,positive,positive
368324486,Pull request #220 Add GNU General Public License v3.0,pull request add gnu general public license,issue,negative,positive,neutral,neutral,positive,positive
368303653,"@oatssss 
take a look at [shaoanlu' convert](https://github.com/shaoanlu/faceswap-GAN/blob/76e14c42efa0c0adbb731d748f866e07793708d1/FaceSwap_GAN_v2_sz128_train.ipynb)
Under section 13, use_smoothed_mask, use_smoothed_bbox and use_color_correction(histogram-matching) i think these can be applied to our convert script",take look convert section think applied convert script,issue,negative,neutral,neutral,neutral,neutral,neutral
368290470,"Didn't tried your last commit but I added just to be sure.
That's weird maybe you should delete existing one and train a new.
Also we can check the ports both 64 and 128 to see if they are exactly the same with original.
But I think convert should be the priority. We should add blur, kernel and seamless but also check how shaoanlu smooths the bbox and add that option as well to both convert scripts.
@oatssss are you up for it? :)",tried last commit added sure weird maybe delete one train new also check see exactly original think convert priority add blur kernel seamless also check add option well convert,issue,positive,positive,positive,positive,positive,positive
368287714,"It's weird, but now even using my local copy of shaoanlu's jupyter notebook, I don't even get the good gan64 results as I was getting before, and afaik I didn't change anything.",weird even local copy notebook even get good gan getting change anything,issue,negative,positive,neutral,neutral,positive,positive
368283625,"Did you get an error about `K` not being defined? You're right the import should be added, but it didn't error for me. Maybe because another script already imported it (I'm not too familiar with how modules work in Python)",get error defined right import added error maybe another script already familiar work python,issue,negative,positive,positive,positive,positive,positive
368283447,How difficult would it be to create a standalone script that would parse the alignments file and delete entries that don't have corresponding pictures in A/aligned? I'm no programmer but perhaps this would be a temporary fix until something can be incorporated into the main branch? I'm also in a similar spot since most of what I want to do involves two people in a scene.,difficult would create script would parse file delete corresponding programmer perhaps would temporary fix something incorporated main branch also similar spot since want two people scene,issue,negative,negative,negative,negative,negative,negative
368267152,@oatssss Normally this issue is solvable by using erosion-kernel-size and blur-size but in our convert code these are exclusive to Masked converter. Maybe you can add these options to GAN converters as well?,normally issue solvable convert code exclusive masked converter maybe add gan well,issue,negative,positive,positive,positive,positive,positive
368266592,"@Apollo122 That result looks pretty good! The masking issue at the edges of the bbox might have to do with its size. The bbox in your image extends to way more than just the crucial parts of the face. Additionally, we can probably incorporate the same strategy as with the original model with seamless blur.

And yes, absolutely try and find differences between the port I did and shaoanlu's v2!",result pretty good issue might size image way crucial face additionally probably incorporate strategy original model seamless blur yes absolutely try find port,issue,positive,positive,positive,positive,positive,positive
368266186,i have 1080 8GB and bs 20 works on GAN128 but not 32. maybe i play it little more to find max value. But yeah before PL it was 40.,work gan maybe play little find value yeah,issue,positive,negative,negative,negative,negative,negative
368265625,"Yes yes, adding `K.set_learning_phase(1)` is essential. I had figured that one out the other day but should have spoken up on this PR too. It uses way way more memory. I had to turn down to batch size 16 to run it on a 1070 w/ 8GB. Training goes great, conversion is still iffy but much more reliable than the facebook-GAN notebook.",yes yes essential figured one day spoken way way memory turn batch size run training go great conversion still iffy much reliable notebook,issue,positive,positive,positive,positive,positive,positive
368261861,"Fixed the PL error. Actually its a bug within keras_vggface.
Add ` K.set_learning_phase(1) ` [Referance](https://stackoverflow.com/questions/42969779/keras-error-you-must-feed-a-value-for-placeholder-tensor-bidirectional-1-keras)  to keras_vggface\models.py before the line 275 meaning above  ` model = Model(inputs, x, name='vggface_resnet50') `
Be careful though it requires additional memory so i had to reduce to batch_size.

edit: actually shaoanlu added this in ` FaceSwap_GAN_v2_sz128_train.ipynb `
@oatssss take a look under **4.Config** . i dont see these lines in our trainers both in GAN64 and GAN128 and ` K.set_learning_phase(1) ` should definitely be added for PL. I did it under init function before ` self.use_lsgan = True `  now i can use PL. Hopefully this is the only thing overlooked while porting. We should double check again some time. Maybe thats why you are getting different results. ",fixed error actually bug within add line meaning model model careful though additional memory reduce edit actually added take look dont see gan gan definitely added function true use hopefully thing double check time maybe thats getting different,issue,positive,positive,neutral,neutral,positive,positive
368257992,"Convert doesnt seem to be doing any correction you can see the box.

![881225890](https://user-images.githubusercontent.com/34627582/36634750-67dc759c-19ba-11e8-9fce-6c17f94794b8.jpg)
",convert doesnt seem correction see box,issue,negative,neutral,neutral,neutral,neutral,neutral
368248020,"I haven't tried to use perceptual loss. I do get the best results using shaoanlu's original repo. I tried to make the model here exactly the same, but it's still giving me different results and I have no idea why. Your gan128 results were like the good results I was getting with gan64 from shaoanlu's.",tried use perceptual loss get best original tried make model exactly still giving different idea gan like good getting gan,issue,positive,positive,positive,positive,positive,positive
368246302,"Are you following this conversation @oatssss? Maybe we should add it too. 
Btw is perception loss working for you or are you getting a error like me?
https://github.com/shaoanlu/faceswap-GAN/issues/73#issuecomment-368245627",following conversation maybe add perception loss working getting error like,issue,negative,neutral,neutral,neutral,neutral,neutral
368243946,I don't know if it has something to do with v2. But with clorr's gan64 I didn't have this issue,know something gan issue,issue,negative,neutral,neutral,neutral,neutral,neutral
368242518,"@oatssss 

That fix works for me just great, thanks for fixing what I spent all last Sunday trying to figure out. Have you tried out the results of converting out of GAN? My models are really well trained and look great in the preview trainer but quality really drops in the convert step. The bounding box around the face remains very clear and apparent. My model has over 20k iterations with a batch size 16.

Are you seeing this too?",fix work great thanks fixing spent last trying figure tried converting gan really well trained look great preview trainer quality really convert step bounding box around face remains clear apparent model batch size seeing,issue,positive,positive,positive,positive,positive,positive
368242236,Will check it. As for the issue you can see it on my previous comment. Check the image under masked. The most obvious one is at right side 3rd position from bottom,check issue see previous comment check image masked obvious one right side position bottom,issue,negative,positive,neutral,neutral,positive,positive
368241570,"@Apollo122  I haven't tested it, but try this branch https://github.com/oatssss/faceswap/tree/update-GAN-v2-tests for gan128 conversion.",tested try branch gan conversion,issue,negative,neutral,neutral,neutral,neutral,neutral
368241145,What's warped masked output? Which issue is this?,warped masked output issue,issue,negative,neutral,neutral,neutral,neutral,neutral
368240746,Also I don't remember getting warped masked output with gan64 version. Another user raised this issue as well. https://github.com/deepfakes/faceswap-playground/issues/65 ,also remember getting warped masked output gan version another user raised issue well,issue,negative,neutral,neutral,neutral,neutral,neutral
368238146,"@oatssss 
didnt pay attention. maybe you can add the change for every 100 ite also, like saying it has gone down this much. 
btw here is the link for gan128 model. i trained it for 25k iterations still not great but should be enough for you to start convert part. https://mega.nz/#!sp5E1aZD!1pP1Bi3rewmCcU2HvY-FrksXsIdQGFG5p0HaImJr4Ls",didnt pay attention maybe add change every also like saying gone much link gan model trained still great enough start convert part,issue,positive,positive,positive,positive,positive,positive
368237155,Your results seem better than what I'm getting with the gan64. Are your loss values continually decreasing?,seem better getting gan loss continually decreasing,issue,negative,positive,positive,positive,positive,positive
368218662,"@oatssss  im still training gan128 model. after 14k iterations results are like this. Especially masked output is hilarious :) guess it needs more time.

## **Raw:**
![raw](https://user-images.githubusercontent.com/34627582/36629429-b2fae40e-1966-11e8-847c-748411770577.png)

## **Mask:**
![mask](https://user-images.githubusercontent.com/34627582/36629437-c911a5a2-1966-11e8-8929-88b28a64851f.png)

## **Masked:**
![masked](https://user-images.githubusercontent.com/34627582/36629440-d59a66d8-1966-11e8-8382-9ae0ebab4ab6.png)
",still training gan model like especially masked output hilarious guess need time raw raw mask mask masked masked,issue,positive,positive,neutral,neutral,positive,positive
368217917,"People who want test this beware: keras-vggface installs cpu based tensorflow as dependency. Won't give you any error but slow your training speed by 40. You should uninstall it and install gpu based tf. Read this comment
https://github.com/shaoanlu/faceswap-GAN/issues/17#issuecomment-367791033",people want test beware based dependency wo give error slow training speed install based read comment,issue,negative,negative,negative,negative,negative,negative
368195589,"@oatssss thanks.
To get the first item I did the following:
```
mask = fake_output[0][0,:,:, :1]
new_face = fake_output[0][0,:,:, 1:]
```
It works now, but I only see the face swapped/augmented with RGB noise. Not sure what is going on.
",thanks get first item following mask work see face noise sure going,issue,positive,positive,positive,positive,positive,positive
368193450,My loss values are basically stagnant around ~0.17 for DA/B and ~0.22 for GA/B. I'll try increasing batch size and messing with the learning rate.,loss basically stagnant around try increasing batch size messing learning rate,issue,negative,neutral,neutral,neutral,neutral,neutral
368168642,Do you know from which commit your gan64 model is from? I don't think anything before my update to v2 will be compatible.,know commit gan model think anything update compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
368164295,"Yeah okay. Btw I started the training I will share it here once it's okay quality. 

I have gan64 model as well. do you think that it can be use with your PR? Or should I have to start all over?",yeah training share quality gan model well think use start,issue,positive,neutral,neutral,neutral,neutral,neutral
368162109,"I think the default save interval is 100, so I just used that. Later it can be coded to use whatever was set for the actual save interval.",think default save interval used later use whatever set actual save interval,issue,positive,neutral,neutral,neutral,neutral,neutral
368156898,Isn't 100 iterations too much? I think 10 would be ideal,much think would ideal,issue,positive,positive,positive,positive,positive,positive
368155842,"The `%` operator calculates the remainder. It's a redundant line since `iter` is always an integer and every integer is divisible by 1. i.e. `iter % 1` is always equal to 0.

I imagine shaoanlu had it as something other than 1 at some point so the output would only display every few iterations instead of with every iteration (like it is now).

**Edit:** Actually, seems like it was to only train the discriminator every few iterations, not the display. I wonder what the results were...",operator remainder redundant line since iter always integer every integer divisible iter always equal imagine something point output would display every instead every iteration like edit actually like train discriminator every display wonder,issue,positive,negative,neutral,neutral,negative,negative
368149648,"What was the importance of 
if iter % 1 == 0:   part?

It seems it got removed as well",importance iter part got removed well,issue,positive,neutral,neutral,neutral,neutral,neutral
368125493,"wait i understand. it doesnt use GPU at all

edit:
ok solved it. for whatever reason pip has installed regular tensorflow along with keras and other required  libraries. uninstalled both tensorflow packages and reinstalled tensorflow-gpu. that solved the issue.",wait understand doesnt use edit whatever reason pip regular along uninstalled issue,issue,negative,neutral,neutral,neutral,neutral,neutral
368124673,So this is after I updated gan128 to shaoanlu's latest (commit 2f38bf7)? And it was running faster before?,gan latest commit running faster,issue,negative,positive,positive,positive,positive,positive
368121915,btw for gan-128 one iteration takes 44 secs on gtx1080. not sure if it was this slow,one iteration sure slow,issue,negative,positive,neutral,neutral,positive,positive
368115400,pip list says i have Keras (2.1.2) and keras-vggface (0.5) so dont think i have the old version. and i dont see obtain_input_shape in the crash log hmm,pip list dont think old version dont see crash log,issue,negative,positive,neutral,neutral,positive,positive
368113636,I left a comment in the gan128 draft PR about trying to fix the converter. You could give it a shot too.,left comment gan draft trying fix converter could give shot,issue,negative,neutral,neutral,neutral,neutral,neutral
368112949,"lmao, I was looking at gan64, thanks.

Also, from shaoanlu's jupyter notebook, there's a comment about it:

>If you got error _obtain_input_shape(...) error, this is because your keras version is older than vggface requirement.
>Modify _obtain_input_shape(...) in keras_vggface/models.py will solve the problem. The following is 
    what worked for me:

``` python
input_shape = _obtain_input_shape(input_shape,
                                  default_size=224,
                                  min_size=197,
                                  data_format=K.image_data_format(),
                                  include_top=include_top)
```",looking gan thanks also notebook comment got error error version older requirement modify solve problem following worked python,issue,negative,positive,positive,positive,positive,positive
368111807,"That stack trace makes it seem like it's an error with the `keras_vggface` package. No clue.

The code I'm looking at looks like it already has the `self`.",stack trace seem like error package clue code looking like already self,issue,negative,neutral,neutral,neutral,neutral,neutral
368111344,"    loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=1))
    loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=2))
    loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=1))
    loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=2))

self's were missing here. this is the corrected one",self missing corrected one,issue,negative,negative,negative,negative,negative,negative
368110969,"For your first crash with the `self` missing, where was it missing?",first crash self missing missing,issue,negative,negative,neutral,neutral,negative,negative
368109985,Try that. I just disabled perceptual loss.,try disabled perceptual loss,issue,negative,negative,negative,negative,negative,negative
368105632,"crashed again. but i fixed it. you should change these lines as well. ""self"" was missing.

        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=1))
        loss_GA += w_fo * K.mean(self.first_order(mask_A, axis=2))
        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=1))
        loss_GB += w_fo * K.mean(self.first_order(mask_B, axis=2))",fixed change well self missing,issue,negative,negative,neutral,neutral,negative,negative
368100862,"@oatssss 
got this crash

Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-update-GAN-v2\scripts\train.py"", line 136, in processThread
    trainer = trainer(model, images_A, images_B, batch_size=self.arguments.batch_size)
  File ""K:\faceswap-update-GAN-v2\plugins\Model_GAN128\Trainer.py"", line 44, in __init__
    self.setup()
  File ""K:\faceswap-update-GAN-v2\plugins\Model_GAN128\Trainer.py"", line 79, in setup
    loss_GA += w_fo * K.mean(first_order(mask_A, axis=1))
NameError: name 'first_order' is not defined",got crash recent call last file line file line run file line trainer trainer model file line file line setup name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
368096459,"I had a similar problem when updating gan64 to v2 (not sure if it's the same). See commit https://github.com/deepfakes/faceswap/pull/217/commits/ca2af7128a79cb4bfcdc552c8955fc21ff466def
 for how I fixed it.

Note, using the same fix without modification definitely won't work because the gan128 model [returns a list of 2 items](https://github.com/deepfakes/faceswap/pull/151/files#diff-9a22c7ad248bbd42edb82b0285838a44R119): `[out, out64]`. So the resulting array from `self.encoder(face)` needs to be sliced differently to get just the `[out]` we're interested in. I dunno the shape of the array because I don't normally code in Python, but my first guess would be something like

``` python
fake_output = self.encoder(face)
mask = fake_output[0,:,:, :1]
new_face = fake_output[0,:,:, 1:]
```

The 0 indexes the list to retrieve the first item in the list, in this case `out`. If you're interested in `out64` you'd use a 1 instead.

So give that a try, and if it doesn't work, move the 0 around to other placements ex. [:,0,:,:,:1]. If I'm correct, one of them should work. Placement of the 0 should be the same for both `mask` and `new_face`.",similar problem gan sure see commit fixed note fix without modification definitely wo work gan model list resulting array face need sliced differently get interested shape array normally code python first guess would something like python face mask list retrieve first item list case interested use instead give try work move around ex correct one work placement mask,issue,positive,positive,positive,positive,positive,positive
368096377,"Alright. I'll start the training then. I think 5-6 hours should be enough. Will share weights here tomorrow.
If you can port 128-converter until tomorrow we can test it together.",alright start training think enough share tomorrow port tomorrow test together,issue,negative,neutral,neutral,neutral,neutral,neutral
368044552,Oh if that's the case I can test it. There are other users here as well. just do the convert and make sure everything is the  same with original then we do the training and provide weights files. I can start the training now if you are certain that clorr's port is correct and complete.,oh case test well convert make sure everything original training provide start training certain port correct complete,issue,positive,positive,positive,positive,positive,positive
368038244,"I think I know how to get the GAN128 converter working, but I don't think I'll be able to test it because I don't have enough vram to run the trainer.",think know get gan converter working think able test enough run trainer,issue,negative,positive,positive,positive,positive,positive
368031342,"Thanks, damn I realized I posted in the wrong github. Meant for the GAN one. Whoops.",thanks damn posted wrong meant gan one whoop,issue,negative,negative,negative,negative,negative,negative
368021648,Mind that if you delete a training image make sure that you delete its entry as well from the json. And yeah you have to do this manually for now,mind delete training image make sure delete entry well yeah manually,issue,positive,positive,positive,positive,positive,positive
368021350,Training images should be aligned and cropped. You can use extract script here to get alignment.json if you don't want to detect faces again on merge part.,training use extract script get want detect merge part,issue,negative,neutral,neutral,neutral,neutral,neutral
368020488,If you do it please check the existing gan64 converter here as well and make sure all is in order. There maybe some bug that prevents us to get the same results,please check gan converter well make sure order maybe bug u get,issue,positive,positive,positive,positive,positive,positive
368019128,"Awesome! Will give it a go this weekend.Let you know the results.
If you have the motivation you can work on gan128 model. Mind that its converter doesn't even exist in this repo so would be great if you can do it as well. Thanks again",awesome give go know motivation work gan model mind converter even exist would great well thanks,issue,positive,positive,positive,positive,positive,positive
368014136,I compared the Model and Trainer to shaoanlu's v2 and made sure everything's the same. I think it should work better now.,model trainer made sure everything think work better,issue,positive,positive,positive,positive,positive,positive
367933980,Because all of our programmers are on strike :) no seriously they are all missing so either we wait for them or do it ourselves. I'm c#/Java guy so don't really know python.,strike seriously missing either wait guy really know python,issue,negative,neutral,neutral,neutral,neutral,neutral
367932003,where to download the working repository? show me please. I'm here for the first time. Help,working repository show please first time help,issue,positive,positive,positive,positive,positive,positive
367931916,"Thank you for your contribution @oatssss. Is this the full port of v2 or just a partial one? GAN here still not great yeah, If you could check the existing code for wrong implementation",thank contribution full port partial one gan still great yeah could check code wrong implementation,issue,positive,positive,positive,positive,positive,positive
367927771,@kcimit do you have the above code with face_alignment-only working? Is there anything else required?,code working anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
367925855,"this seems to be a good start: https://github.com/deepfakes/faceswap/pull/151
But it is missing the converter yet, and I could not get the converter running myself.",good start missing converter yet could get converter running,issue,negative,positive,positive,positive,positive,positive
367923597,"I created ""Convert_GAN128.py"" copying the original GAN converter and changed
`        face = cv2.resize(face_detected.image, (128, 128))`
But I get the following error:

>   File ""/data/plugins/Convert_GAN128.py"", line 14, in patch_image
>     new_face = mask * new_face + (1 - mask) * face
> ValueError: operands could not be broadcast together with shapes (1,128,128,4) (1,64,64,3) 

Although I selected the GAN128 model, for some reason there seem to be still 64px faces",original gan converter face get following error file line mask mask face could broadcast together although selected gan model reason seem still,issue,negative,positive,positive,positive,positive,positive
367921747,Looks like the GAN128 converter is missing!?,like gan converter missing,issue,negative,negative,negative,negative,negative,negative
367913932,The results I get with shaoanlu's original v2 are still a lot better than what I'm getting with this. I wonder why.,get original still lot better getting wonder,issue,positive,positive,positive,positive,positive,positive
367859719,Awesome! yeah GAN here was unusable for me too. Will be trying your changes this weekend. Thanks,awesome yeah gan unusable trying weekend thanks,issue,positive,positive,positive,positive,positive,positive
367844558,"Any idea why this hasn't been addressed? Seems like an easy fix, as other versions have this functionality. It's already tedious enough deleting unwanted frames from the /aligned folder. Having to then delete parts of the .json file is a hundred times more annoying, and can cause probably even more problems if you mess up the syntax.",idea like easy fix functionality already tedious enough unwanted folder delete file hundred time annoying cause probably even mess syntax,issue,negative,negative,negative,negative,negative,negative
367840543,"@gdunstone  I strongly doubt that /u/deepfakes is going to reply or ever assert his moral right to be known as an author of parts of the original codebase for obvious reasons.

I'd be happy to assert that the masked merging is derivative of the code in /dfaker/df and as such should be under MPL-2.0 if that helps anyone line up behind a boring decision faster.",strongly doubt going reply ever assert moral right known author original obvious happy assert masked derivative code anyone line behind boring decision faster,issue,positive,positive,neutral,neutral,positive,positive
367802036,"Think as modular programming, is_debug_landmarks actually optional value and doesnt affect to `extract` major behaviour",think modular actually optional value doesnt affect extract major behaviour,issue,negative,positive,neutral,neutral,positive,positive
367787700,False as default value is redundant as it is already specified in the arguments parser.,false default value redundant already parser,issue,negative,negative,negative,negative,negative,negative
367689523,"@flipflopbboi Worked like a charm. most videos of people looking down/tilted sideways kinda make the face turn off until its in a more upright position. is that just me or are more, say, non head-on-ish frames not recognized?",worked like charm people looking sideways make face turn upright position say non,issue,positive,neutral,neutral,neutral,neutral,neutral
367613634,"@subzerofun , i watch this in youtube https://github.com/alexjc/neural-enhance, and found the pxl can be improve, i not sure if the process is we go through model training to learn , and re-train again with neural enhance another time, but for sure pxl can be improve like how the movie maker doing right now. currently i after merge the face, i will use  Da vinci resolver 14 with the face refinement to touch up,  but i found face refinement concept same as what we are doing right now, but the face detection are worst then what we have in face extraction , 

i will get a new setup soon by next week, the spec will be 
Win 10
Memory 16gb, 2933MHZ
NVDIA GTX 1080Ti with 11GB GDDR5X
Intel i7 8700k (6-core/12Thread,12MB Cache, Overclocked up to 4.6GHz across all cores)

all setup here will use for Neural network study in future. i am rookies right now , but i want to know if base on current scrip what i can change to improve the pxl and within my new hardware capabilities 

by the way, in future any changes here, i would like to try contribute and help to validate with my new setup .

 
",watch found improve sure process go model training learn neural enhance another time sure improve like movie maker right currently merge face use da resolver face refinement touch found face refinement concept right face detection worst face extraction get new setup soon next week spec win memory ti cache across setup use neural network study future right want know base current scrip change improve within new hardware way future would like try contribute help validate new setup,issue,positive,positive,neutral,neutral,positive,positive
367594773,"@flipflopbboi 

`print(""\r[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}"".format(time.strftime(""%H:%M:%S""), iter, loss_A, loss_B),end='')`

This solves the output issue. can see loss values without printing a line for every iteration",print iter output issue see loss without printing line every iteration,issue,negative,neutral,neutral,neutral,neutral,neutral
367578782,"more logical place debug argument at end of list
`def extract(self, image, face, size, is_debug_landmarks = False):`",logical place argument end list extract self image face size false,issue,negative,negative,neutral,neutral,negative,negative
367566927,"@flipflopbboi Thanks. that solved the issue. but seems it takes about 13 seconds for 1 iteration  :(

ahh now its going fast ",thanks issue iteration going fast,issue,negative,positive,positive,positive,positive,positive
367548954,"@ruah1984  That depends on how complex you want the model to be and how much your GPU can handle memory wise. More features and higher ENCODER_DIM for the Encoder as well as more layers and features for the Decoder means better output quality. But more features translate to more variables that need to be stored = bigger memory footprint. From my tests i just saw that leaving the Decoder as it is now yields blurry images. But changing it (adding a layer) increases memory usage. I'm really not sure what the ideal model would look like ...

So there is not one definitive way to change the `Model_Original.py` for 128x128px – there are quite a few. The only one that produced good output images _for me_ was one that needed tons of GPU memory. Tell me what GPU you have and i can post the model structure here. You also need to edit the `TrainingDataGenerator` class and `random_warp` function in `lib/training_data.py` so that the internal image processing can handle 128x128px images. And if you want to convert some images you also need to take a look at `Convert_Adjust.py`and `Convert_Masked.py`. Did not test converting, spent most of time with training + testing different models.",complex want model much handle memory wise higher well better output quality translate need bigger memory footprint saw leaving blurry layer memory usage really sure ideal model would look like one definitive way change quite one produced good output one memory tell post model structure also need edit class function internal image handle want convert also need take look test converting spent time training testing different,issue,positive,positive,positive,positive,positive,positive
367542868,"You should definitely adjust the convert parameters; blur size `-b 8` seems to be working well.
Also, you can turn on the seamless option via `-S` which makes a big difference. However seamless, from what I ve seen, introduces more flickering and also takes a lot longer to process.",definitely adjust convert blur size working well also turn seamless option via big difference however seamless seen flickering also lot longer process,issue,positive,positive,neutral,neutral,positive,positive
367476547,This happens sometimes when enabling histogram match (color correction) in GAN version.,sometimes histogram match color correction gan version,issue,negative,neutral,neutral,neutral,neutral,neutral
367463225,"@flipflopbboi Thanks, yes got 12GB after several attempts.  but now im not seeing loss values in the command output. also it looks like running because i see the message ""saved model weights"" appear in the output but it takes really really long time even with lowmem and batch size 32.   is there any tricks to run in colab?",thanks yes got several seeing loss command output also like running see message saved model appear output really really long time even batch size run,issue,positive,positive,neutral,neutral,positive,positive
367458986,"@3xtr3m3d This used to happen to me too, but if you restart your session (Runtime -> Restart Runtime..) and rerun your K80 memory is cleansed and you are allocated full 12 GB. ",used happen restart session restart rerun memory full,issue,negative,positive,positive,positive,positive,positive
367432419,"@k3erg  **Thanks for the code!** Just tried your script to compare the results with @facepainter's original code. But for some reason it only scans the reference image directory (tried with one image and then with 20) and when it comes to extraction the script simply stops. Without an error – it just shows `Checking 274 of 1647 frames in 137 batches of 2` and then the progress in the next line. After that it stops and i'm back to enter a new command. That's really weird ... will need to test it with another video file (and maybe with a different codec). Tried different input arguments, but the result is the same ...

To be sure to that i have the newest dependencies, i've reinstalled dlib from source with CUDA 9.0, cuddn 7 on macOS 10.12. Can confirm dlib is working with GPU acceleration: when i execute @facepainter's script i see the GPU core usage and temps increase significantly.

@facepainter  **Also thank you for the code, the extraction speed is awesome!** Sorry if this question has been asked before, just wanted to know for sure: Do your latest changes alleviate the problem with the random zooming? I've sifted through a few folders of extracted faces, but it seems there are still some images that are ""zoomed in"" / upscaled by ~10-20% compared to the rest. Also some random rotations, not present in similar images before or after the odd ones.

Hope you can also help me out with this problem:
The original video files are Quicktime movs, Apple ProRes Codec (exported from Davinci Resolve), 1920x1080p with 24 fps. I've tried running the script with a high `--batch_size` (32-96) and then also with low settings (2-16). `--skip_frames` is set to `5`, `--jitter` to `500`, all other settings are standard.

Problem with high batch sizes: The script finds significantly less faces compared to a low batch size, although extraction runs exceptionally fast.

Problem with low batch sizes: It returns much more faces, but a lot of them are duplicates (image from the same video frame, equal file size). This is just a small issue, i can sort them out with a duplicate detecting program. But i was just wondering why this happens. Tried a -bs of 2,4,6 and 8 but every setting always outputs 4 duplicates of a lot of faces. Does this have something to do with the `--skip_frames` option? If it just processes every 6th frame, and 24fps/6 = 4 – could this somehow correlate to the 4 duplicates?

–––

PS: I can highly recommend Davinci Resolve to cut movies and series, especially if you have a fast GPU. Compared to Premiere or Final Cut editing feels extremely smooth and the workflow is pretty streamlined and minimalistic in a good way. Exporting is also fast, although i have an older CPU (no h.265 acceleration). **Best feature: An option for Auto-White balance and brightness curve correction**. Works well for videos with odd color grading (e.g. Mr. Robot: especially dark and heavily edited low saturation scenes).
",thanks code tried script compare original code reason reference image directory tried one image come extraction script simply without error progress next line back enter new command really weird need test another video file maybe different tried different input result sure source confirm working acceleration execute script see core usage increase significantly also thank code extraction speed awesome sorry question know sure latest alleviate problem random sifted extracted still rest also random present similar odd hope also help problem original video apple resolve tried running script high also low set jitter standard problem high batch size script significantly le low batch size although extraction exceptionally fast problem low batch size much lot image video frame equal file size small issue sort duplicate program wondering tried every setting always lot something option every th frame could somehow correlate highly recommend resolve cut series especially fast premiere final cut extremely smooth pretty streamlined good way also fast although older acceleration best feature option balance brightness curve correction work well odd color grading robot especially dark heavily low saturation,issue,positive,positive,positive,positive,positive,positive
367417292,"@flipflopbboi  after i saw your post, i tried google colab, took me a while to get familiar with the system but once i ran training on it, it immediatly start showing oom errors.  looks like gpu memory is capped for colab sessions?

> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 503.62MiB ",saw post tried took get familiar system ran training start showing like memory capped session name major minor,issue,negative,positive,positive,positive,positive,positive
367204584,">Thanks! it works. Maybe this model should be accepted as LowMem then?

I will create PR for it today

>@qzmenko лол, так что, заработало у тебя?) А я так и забил, не получилось( Тоже 2гб памяти

да, заработало. И результаты отличные :)",thanks work maybe model accepted create today,issue,positive,positive,positive,positive,positive,positive
367195029,"I'm not sure what you mean by cloud drive but depending on the platform (windows/linux) you can transfer files dierectly. On google cloud instead of something like google drive, you have whats called a bucket. its essentially the same thing, you can upload and download files to your instance and your actual computer, its hard to describe but way handier than google drive. If I wanted to put images on my instance I'd upload them to my bucket and then download them to my cloud instance. Then set up your fakeapp on windows or faceswap on linux and you aree good to go. on Windows if you close the instance or lose internet it keeps running, on linux just install ""screen"", make a new session and you can get the same effect. I'm in love with it because I got so many renders out of it for free, and I really would reccommend it as youd get a big speed impromement with the p100 which you can add for free while your 300 dollars lasts.",sure mean cloud drive depending platform transfer cloud instead something like drive whats bucket essentially thing instance actual computer hard describe way drive put instance bucket cloud instance set good go close instance lose running install screen make new session get effect love got many free really would youd get big speed add free,issue,positive,positive,positive,positive,positive,positive
367192893,"It's my environment issue actually, finally i clean & reclone project to test, and the result became right. thanks for all!",environment issue actually finally clean project test result right thanks,issue,positive,positive,positive,positive,positive,positive
367173323,"Is anything missing here until it can be merged?
I have some GAN128 models trained with shaoanlu's notebook I would like to use :)",anything missing gan trained notebook would like use,issue,negative,negative,negative,negative,negative,negative
367171968,"@Clorr @k3erg @Apollo122 @3xtr3m3d @iperov 

Just to note I added the extract align features by slightly porting the Umeyama algorithm from scikit and the DetectedFace class from here. Now the recognition rate is much higher and as long as landmarks can be detected then it spits out transformed/aligned faces as needed.

You can test in the gist.

Again hope to actually integrate this into a pull request here this week (work is just silly atm :()",note added extract align slightly algorithm class recognition rate much higher long test gist hope actually integrate pull request week work silly,issue,negative,negative,neutral,neutral,negative,negative
367162117,"If I want to change to 128x128pxl. In model ,which line I should change the parameters ?Only change the model.py?I mean not for GAN Model",want change model line change change mean gan model,issue,negative,negative,negative,negative,negative,negative
367153803,"@kylefrost  In case you haven't solved this yourself – this is a great tutorial:  [Tensorflow 1.4 Mac OS High Sierra 10.13 GPU Support](https://gist.github.com/smitshilu/53cf9ff0fd6cdb64cca69a7e2827ed0f) 

Maybe it works for TF 1.5 too. Compiling TF on macOS since Google dropped official support can be quite time consuming ... Especially if you want to have the newest CUDA + cudnn versions. After a lot of wasted hours trying to get TF 1.4, the newest PyTorch and Torch all working with CUDA 9.1 i thought i'd share my setup plus a little hack to switch between CUDA versions.

**This is not meant to just fix problems with Tensorflow – it can come in handy if some ML frameworks work with CUDA version X, but not version Y etc.**

Download all CUDA (full DMG) installers, copy them somewhere safe if you later need to reinstall a specific version. Do the same with all CUDNN versions. Install CUDA 8.0, copy the according **cudnn** files into` /usr/local/cuda` (include and lib, like the documentation explains). **Hint**: The folder in `/usr/local/cuda/lib` is not symlinked to `/Developer/NVIDIA/CUDA-X.X/lib` – but most **files in it** are symlinked. I always copy the cudnn lib files also to the NVIDIA lib folder.

Rename the /usr/local/cuda folder to cuda80. Install CUDA 9.0, copy according cudnn files. Make sure the cudnn version is compatible with CUDA 9.0.

Rename /usr/local/cuda to cuda90. Finally install CUDA 9.1 + copy matching cudnn. The newest version will therefore point to /usr/local/cuda (don't rename to cuda91!).

Clean up your bash source file: Make sure that all environment variables point to /usr/local/cuda lib or include – correct everything with /Developer/NVIDIA/CUDA-X.X to /usr/local/cuda.

That way you can always revert back to an older CUDA + cudnn version: You just have to rename the /usr/local/cudaXX folder back to ../cuda. Only downside: When switching versions you (sometimes) need to reinstall the correct CUDA drivers/kexts (from the install dmg, only select drivers – not the whole toolkit).

Sounds a little complicated, but the advantage is that you can write a bash function that changes all env variables from /usr/local/cuda to /usr/local/cudaXX when needed. You can then reset your terminal session and try to install TF/PyTorch/etc. with another CUDA version.

I have now got CUDA 9.1 with TF 1.4 working on macOS 10.12.5. PyTorch with GPU support needed CUDA 8.0, that's where the bash function came in handy. The regular ""old"" Torch also fails to compile with CUDA 9.0 or 9.1, so the trick with the env variables also helped me successfully install it with CUDA 8.0. As long as you set the shell variables correctly, multiple different CUDA installs are possible.

--- 

Coming back to your initial question: It's always a good idea to check if the `LD_LIBRARY_PATH` and `DYLD_LIBRARY_PATH` vars don't point to older installs in /Developer/NVIDIA/... (sort out the bash source file in general). Best to set entries like `CUDA_ROOT`, `CUDA_DIR`, `CUDA_TOOLKIT_PATH`, etc. to `/usr/local/cuda/`(lib, include, etc) because then all files are symlinked to the current install.",case great tutorial mac o high sierra support maybe work since official support quite time consuming especially want lot wasted trying get torch working thought share setup plus little hack switch meant fix come handy work version version full copy somewhere safe later need reinstall specific version install copy according include like documentation hint folder always copy also folder rename folder install copy according make sure version compatible rename finally install copy matching version therefore point rename clean bash source file make sure environment point include correct everything way always revert back older version rename folder back downside switching sometimes need reinstall correct install select whole little complicated advantage write bash function reset terminal session try install another version got working support bash function came handy regular old torch also compile trick also successfully install long set shell correctly multiple different possible coming back initial question always good idea check point older sort bash source file general best set like include current install,issue,positive,positive,positive,positive,positive,positive
367136317,Thanks! it works. Maybe this model should be accepted as LowMem then?,thanks work maybe model accepted,issue,positive,positive,positive,positive,positive,positive
367110533,"Hi, thanks for the suggestion! I am actually running on a google colab notebook which provides free access to a Tesla K80. Problem is you need a good internet connection to stay connected otherwise the notebook stops :/  
I would be very interested in instruction on how to setup a vm on gcp! 
Can you mount your cloud drive or how does it work with the image db?
I tried once to build a docker image but was taking too long (mind you on google-colab I still need about 20 min to setup all dependencies etc.) plus I lack experience with such setups. 
Good thing is I've learned a ton trying to build all packages and optmise stuff to get my setup to work properly in a highly restricted ipython environment; will share once I fix a few issues.",hi thanks suggestion actually running notebook free access problem need good connection stay connected otherwise notebook would interested instruction setup mount cloud drive work image tried build docker image taking long mind still need min setup plus lack experience good thing learned ton trying build stuff get setup work properly highly restricted environment share fix,issue,positive,positive,positive,positive,positive,positive
367105051,@IcyTv Thats just writing a 4 line bash script to run the existing tools....,thats writing line bash script run,issue,negative,neutral,neutral,neutral,neutral,neutral
367104355,"Just a heads up, https://cloud.google.com/free/ gives you 300 dollars of free credit. I built a quad core linux system to run facewap on and added a 3584 cuda core Tesla P100. Trained models on it like a charm and only ran out of the free 300 after about a week, plenty of time to train models on a P100. I pay for it now because its honestly a great price for that many Cuda cores and the storage and cpu are basically free - you can get a model down to 0.02 in about 15 hours on a free instance. and it pretty much never goes down. Always been up for me.",free credit built quad core system run added core trained like charm ran free week plenty time train pay honestly great price many storage basically free get model free instance pretty much never go always,issue,positive,positive,positive,positive,positive,positive
367058127,"@babilio 
oh, I generated this image just used the pre-trained model mentiond in 'README.md' , not my own. What i mean is using pre-trained model and my own model occured the same problem.",oh image used model mean model model problem,issue,negative,negative,negative,negative,negative,negative
367054945,"@p0sera Perhaps not the best place to ask but is there a reason as to why my previews when training with the GAN model will fail to show up half the time?

https://i.imgur.com/51HcVZd.png

EDIT: Getting the same black squares when attempt to convert with this too :/

EDIT 2: Tried to continue training with same model for a bit longer, eventually squares went from black to red (some columns at least).

At that point I decided to give up and try again from scratch, only to find the same thing happened again some 4600 iterations in. Going from this: https://i.imgur.com/zvX663l.jpg to this https://i.imgur.com/ehHbxTH.jpg on save/training window refresh.",perhaps best place ask reason training gan model fail show half time edit getting black attempt convert edit tried continue training model bit longer eventually went black red least point decided give try scratch find thing going window refresh,issue,negative,negative,neutral,neutral,negative,negative
367050111,I think this could be low variety of lighting in your Nick cage pictures. It's important not only to get different angle but different lighting settings that way it is more adaptable to other skin tones,think could low variety lighting nick cage important get different angle different lighting way adaptable skin,issue,negative,positive,neutral,neutral,positive,positive
367045514,"I'm facing the same issue. Any ideas? I found out that if the image gets rotated so that the forehead is facing upwards, detection works. So maybe if no face gets detected, the script should try again after rotating the image.",facing issue found image rotated forehead facing upwards detection work maybe face script try rotating image,issue,negative,neutral,neutral,neutral,neutral,neutral
366984771,"there is bad implement of gan in faceswap :(
looks like v1 and without perceptual loss",bad implement gan like without perceptual loss,issue,negative,negative,negative,negative,negative,negative
366975906,Thanks for your comments everyone.  I think I need to train the network a little longer and make sure I have good quality pictures.,thanks everyone think need train network little longer make sure good quality,issue,positive,positive,positive,positive,positive,positive
366880962,"OK 8000 images _are_ too much. Memory (24 GB) full, swap files piling up. Terminal freezes, several Apps crash – but the Python process with tensorflow is still running, allocating space 😆.  ",much memory full swap piling terminal several crash python process still running space,issue,negative,positive,positive,positive,positive,positive
366874266,"@avilv  With how many images in folder A and B combined did you test this?
Do the images now get stored in RAM or on the GPU? I currently have a project where folder A has ~4000 face images, folder B also ~4000. I'm a little reluctant to test this without knowing if my hardware can handle pre-loading 8000 images :-)",many folder combined test get ram currently project folder face folder also little reluctant test without knowing hardware handle,issue,negative,positive,positive,positive,positive,positive
366845747,"I haven't seen the implementation of GANs in this project specifically, but designing a Generative Adversarial Network can be a pretty difficult task. 
If you reward either the Discriminator or Generator incorrectly, it can have a snowball effect where one of the agent overpowers the other and the optimization of loss stagnates. 
If I find the paper on it I will link it, but I remember it having to do with batch normalization...",seen implementation project specifically designing generative network pretty difficult task reward either discriminator generator incorrectly snowball effect one agent optimization loss find paper link remember batch normalization,issue,positive,negative,negative,negative,negative,negative
366845395,Just an aside - @carldgosselin make sure you are putting the right faces in -A and -B. I made that mistake once or twice and took me awhile to figure out why the faces looked horrible.,aside make sure right made mistake twice took awhile figure horrible,issue,negative,negative,neutral,neutral,negative,negative
366843319,"how much time has passed between Step 6 and Step 7?
The network will work better the longer you train, we're looking at losses < 0.01 for decent looking results.
Otherwise you'll just get blurry images as the network is in the process of ""learning"" the encoder/decoder relationship :+1: ",much time step step network work better longer train looking decent looking otherwise get blurry network process learning relationship,issue,negative,positive,positive,positive,positive,positive
366833287,"I'm starting to believe that he is from the future, and maybe from another planet.  This is the only way I can explain my previous results.

But seriously, I actually did extract and train two different sets of pictures/people but nothing really happened during the `convert` stage - it only partially blurred the face in the target pictures.  Clearly not as good of a result as Nicolas Cage's pics.  I'll have to try again.  

Here are the high-level steps I followed (maybe there is a glaring mistake in my flow):
**step 1.**  I took a series of pictures from Actor1 and placed it in a folder called ""input"".  Pictures were derived from a video using ffmpeg.
**step 2.** I ran `python faceswap.py extract` 
**step 3.** result:  the face pics were created in the ""output"" folder.  I copied and pasted the pics into ""input_A"" folder
**step 4.** I cleared the ""input"" folder. Also cleared the ""output"" folder.
**step 5.** I repeated the process for Actor2  and placed the face pics from ""output"" to ""input_B"" folder
**step 6.** I then ran `python faceswap.py train`
**step 7.** I cleared the ""output"" folder for the next step.  I made sure the pics I wanted altered were in the ""input"" folder with the alignments.json file included.
**step 8** Finally, I ran `python faceswap.py convert`.  Unfortunately, the faceswap didn't seem to work, it only partially blurred the original faces.

Does anyone see any major flaws in the above steps or should I just keep trying?

Thanks in advance for your help.  I already appreciate the initial response as I know that this solution should work on other people/faces.
",starting believe future maybe another planet way explain previous seriously actually extract train two different nothing really convert stage partially blurred face target clearly good result cage try maybe glaring mistake flow step took series actor folder input derived video step ran python extract step result face output folder copied pasted folder step input folder also output folder step repeated process actor face output folder step ran python train step output folder next step made sure input folder file included step finally ran python convert unfortunately seem work partially blurred original anyone see major keep trying thanks advance help already appreciate initial response know solution work,issue,positive,positive,neutral,neutral,positive,positive
366807975,"That's the magical thing about Nicolas Cage. His face is the only face computers can understand. We strongly suspect he is a perfect being from a future timeline where machines have taken over.

In all seriousness, there's more steps than just replacing the pictures. Did you do the extract and train steps from the readme?",magical thing cage face face understand strongly suspect perfect future taken seriousness extract train,issue,positive,positive,positive,positive,positive,positive
366795949,"Try this Model_LowMem.py: https://pastebin.com/aiGGxyRs
And command for run:
`python3 faceswap.py train -A data/target_faces -B data/source_faces -m model -t LowMem -p -ag -bs 16`
Succesfully run on 2GB GTX 950.",try command run python train model run,issue,negative,neutral,neutral,neutral,neutral,neutral
366774937,"Smooth is better :)
What makes you think that PL will cause more issue post @shaoanlu? I thought procedure is automatic. What could cause problems for users? And more realistic eyeball movement is pretty important because right now they look like dolls :) Also there are lots of issue posts already about gan. It's quality, time it needs and masked output. With PL we would at least stop masked posts because users will see the results prior as far as I understand.",smooth better think cause issue post thought procedure automatic could cause realistic eyeball movement pretty important right look like also lot issue already gan quality time need masked output would least stop masked see prior far understand,issue,positive,positive,positive,positive,positive,positive
366762707,"From my experiments, introducing perceptual loss can:

1. Make eyeball direction be consistent with input face.

2. Inject some prior knowledge to mask prediction, making output mask more smooth.

Otherwise there is little difference. I got similar masked faces with/without PL as shown in the issue. i.e., we can have good results w/o PL even if the training data is relatively low quality (training images are ~600 faces from a ""25 sec. video"", which means lots of duplicate).

(Update) What I want to say is that, PL is not magic, it only makes what already worked work better. And I'm worrying incorporating PL will result in unnecessary issue posts on this repo.(considering part of users are non-programmers), which distracts potential contributors from contributing.",perceptual loss make eyeball direction consistent input face inject prior knowledge mask prediction making output mask smooth otherwise little difference got similar masked shown issue good even training data relatively low quality training sec video lot duplicate update want say magic already worked work better worrying result unnecessary issue considering part potential,issue,negative,positive,positive,positive,positive,positive
366755678,"Does it include perception loss? According to @shaoanlu it's pretty important.

https://github.com/shaoanlu/faceswap-GAN/issues/50#issuecomment-366697041",include perception loss according pretty important,issue,negative,positive,positive,positive,positive,positive
366533988,"I raised this issue before but no changes yet. https://github.com/deepfakes/faceswap/pull/155#issuecomment-365079915
I proposed a utility function to check entries in json against data/A and delete the absent ones from the json. But until it is implemented manual work is only way",raised issue yet utility function check delete absent manual work way,issue,negative,neutral,neutral,neutral,neutral,neutral
366501362,"Thank you @p0sera, this looks fantastic.
Open source, updated algorithms and functionality, lightweight, putting your name behind it. Much respect.
I'll start testing this out and try to support you with publicity and documentation.

To the other users: Yes, the face alignment is still a bit of an ongoing issues, but it shouldn't be too hard to port over once the repo here resolves the issue. I, too, find that the CNN extractor from face-alignment is the current best version (with GPU support, of course). 

If you have issues building dlib under Windows, use the most recent github from davisking. You need to install boost (this is the non-obvious part) and cmake beforehand. Then, I believe you can just use setup.py and include the switches to build with CUDA (and AVX if desired).

Ignore the trolls. Is there a moderation tool...",thank fantastic open source functionality lightweight name behind much respect start testing try support publicity documentation yes face alignment still bit ongoing hard port issue find extractor current best version support course building use recent need install boost part beforehand believe use include build desired ignore moderation tool,issue,positive,positive,positive,positive,positive,positive
366500023,@p0sera You need to build dlib with Cuda support and use the cli option to use cnn. ,need build support use option use,issue,negative,neutral,neutral,neutral,neutral,neutral
366499632,"Guys can you help me, is it possible to use CNN on GPU? Is it possible with this repository? Will it be faster? What I know is that it is possible to use GPU for tensorflow package, but this package is not used for finding faces in an image.",help possible use possible repository faster know possible use package package used finding image,issue,negative,neutral,neutral,neutral,neutral,neutral
366496286,"@flosth  **Why do you so desperately want a Mac version? And why exactly would it sell? Who would buy it? Even you've said yourself you wouldn't pay for it... Can you even discern between a macOS and iOS version?** After seeing the way you talk to people here i can't help but imagine a sixteen year old passive-aggressive teenager sitting in front of a greasy MacBook from 2012 with a CPU that takes 10 seconds to open an empty tab. No dedicated GPU of course. I guess if you could set up the repo yourself you wouldn't treat the people here like they are your _**potential tools**_.  And your idea to pitch them that they could be – ahem _business partners_ is really original.

You are rude because 1) you lack the tools and knowledge to realize even the smallest step of your plan _on your own_ and 2) people won't do what you say (probably because they are all stupid). Typical puberty mindset. Would be sad if you are older than 25.

But guess what, **i can write a faceswap-App in Swift, there are many ways to do this, maybe even with some kind of iGPU / dedicated GPU hardware acceleration** ([Apple's Metal](https://developer.apple.com/documentation/metalperformanceshader)):
* https://github.com/Octadero/TensorFlow
* https://github.com/PerfectlySoft/Perfect-TensorFlow
* Core ML: https://developer.apple.com/machine-learning/
* MPSCNN: https://developer.apple.com/documentation/metalperformanceshaders
* https://github.com/xmartlabs/Bender (iOS)
* etc.

Maybe i'll start it as a slow side project and post some screenshots of my progress here.

I've probably already tried to tell you this: Macs are not ideal for machine learning. And the most important part of the faceswap project is training the network with hundreds to thousands of high quality images until the model generates usable faces. Which takes aeons and runs the fastest on a GPU with a high clock rate, a lot of VRAM and a high shader count. Which most Macs don't have.

**You want to make money with this great App, don't you?** Who would buy it when their devices are too slow to generate finished face-swapped videos fast enough? The result would have to be instant that people pay for it.

**OK, so say you had your damn Mac App – finished, perfect and ready to sell.**
You won't make any money with it because Apple would not allow an App with such negative publicity in their App Store. Neither on mobile, nor desktop.

Didn't you witness the media hysteria after the Watson video? And no, negative PR is not good PR for your potential App. Not in this case. Because it affects Apple's most important value: **Their image**.

And regarding iOS: a smartphone does not have the processing power **to train** a neural net like this, not without draining the battery and overheating the CPU. Inference is possible, but you'd still need the trained models. How to create the models / where would you get them? And where to put all the data when your device can't handle it?

- **Input A**: You need probably multiple videos of person A (at least one with a lot of angles), upload them to external servers for further processing. Big Problem: Does the App's user have consent of person A to upload the data? What if not? Data still gets processed.

- **Best case scenario: Use for celebrity-faceswap:**
 Happens server-side: you need to build a model with hundreds of photos of say, Nicolas Cage. Nearly every photo or movie still of him is in some way rights managed. So you, as the App selling company, are not allowed to use these photos for commercial purposes **unless you buy the rights**. Good luck negotiating with Hollywood. 

- **Worst case scenario: Use for _celebrity_ faceswap**:
 Serverside: a nudity checking algorithm blocks the user from editing person A's face on some p*rn clip. Problem: What happens if the nudity filter can get bypassed? What if it is too restricting? What if this would be the only feature people would pay for?


Do you maybe remember the shitstorm Apple got into due to leaked ""The Fappening"" photos/videos? People then started realizing that uploading naked photos of yourself ~maybe~ is not best way to use your iCloud space.

> [Vulnerability in Find My Phone service and weak passwords may explain alleged celebrity photo leaks](https://9to5mac.com/2014/09/01/vulnerability-in-find-my-phone-service-and-weak-passwords-may-explain-alleged-celebrity-photo-leaks/)

- https://news.ycombinator.com/item?id=8251945
""September 2, 2014 – Kirsten Dunst blames Apple for nude hacking""

---

Uhm and Apple has Guidelines too:
https://developer.apple.com/app-store/review/guidelines/


> 1. Safety
> 
> When people install an app from the App Store, they want to feel confident that it’s safe to do so—that the app doesn’t contain upsetting or offensive content, won’t damage their device, and isn’t likely to cause physical harm from its use. We’ve outlined the major pitfalls below, **but if you’re looking to shock and offend people**, the App Store isn’t the right place for your app.

> 1.1 Objectionable Content

> Apps should not include content that is offensive, insensitive, upsetting, intended to disgust, or in exceptionally poor taste. Examples of such content include:

> 1.1.1 Defamatory, discriminatory, or mean-spirited content, including references or commentary about religion, race, sexual orientation, gender, national/ethnic origin, or other targeted groups, **particularly if the app is likely to humiliate, intimidate, or place a targeted individual or group in harm’s way**. Professional political satirists and humorists are generally exempt from this requirement.
",desperately want mac version exactly would sell would buy even said would pay even discern version seeing way talk people ca help imagine sixteen year old sitting front greasy open empty tab course guess could set would treat people like potential idea pitch could ahem really original rude lack knowledge realize even step plan people wo say probably stupid typical puberty would sad older guess write swift many way maybe even kind hardware acceleration apple metal core maybe start slow side project post progress probably already tried tell ideal machine learning important part project training network high quality model usable high clock rate lot high shader count want make money great would buy slow generate finished fast enough result would instant people pay say damn mac finished perfect ready sell wo make money apple would allow negative publicity store neither mobile witness medium hysteria video negative good potential case apple important value image regarding power train neural net like without battery inference possible still need trained create would get put data device ca handle input need probably multiple person least one lot external big problem user consent person data data still best case scenario use need build model say cage nearly every photo movie still way selling company use commercial unless buy good luck worst case scenario use nudity algorithm user person face clip problem nudity filter get would feature people would pay maybe remember apple got due people realizing naked best way use space vulnerability find phone service weak may explain celebrity photo dunst apple nude hacking apple safety people install store want feel confident safe contain upsetting offensive content damage device likely cause physical harm use outlined major looking shock offend people store right place objectionable content include content offensive insensitive upsetting intended disgust exceptionally poor taste content include defamatory discriminatory content commentary religion race sexual orientation gender origin targeted particularly likely humiliate intimidate place targeted individual group harm way professional political generally exempt requirement,issue,negative,positive,positive,positive,positive,positive
366491517,In Linux there is cron. I used that and .sh to save my models every hour. I don't know much about IPython notebook though.,used save every hour know much notebook though,issue,negative,positive,positive,positive,positive,positive
366484288,"Closing because this is out of scope.

This repo is not a service. The developers are not going to donate gpu time.",scope service going donate time,issue,negative,neutral,neutral,neutral,neutral,neutral
366483206,"@flosth What are you waiting for? It already works on macOS. I'm training a model on 10.12 right now. 

![grafik](https://user-images.githubusercontent.com/17863119/36346824-2c111be4-1447-11e8-8a35-93aa3389aaae.png)


Python, Keras + Tensorflow are cross-platform. I could write an UI for it in Swift – but why 😇 ?

- Follow the install instructions of the faceswap repo
- Compile/install an OpenCL Tensorflow version:
https://github.com/hughperkins/tf-coriander
https://github.com/hughperkins/tf-coriander/blob/master/doc/installation.md
or one of those:
- https://github.com/lukeiwanski/tensorflow-opencl
- https://github.com/benoitsteiner/tensorflow-opencl

- read how to gather, extract and process training data
- 15min lookup on how to use the macOS Terminal 
- aaand 20 hours later you're ready to start training!
- start training on a macBook Air
- realize Tensorflow is just utilizing your CPU after all
- build zero-point energy nuclear research reactor for constant power
- plug in power adapter
- put yourself in cryostasis
- wake up in the year 2045, lose most of your limbs due to hypothermia
- look at training results
- Scarletts face still looks like a mole rat with 1000% jpeg compression
- look out the window
- realize the sun is now covered in a dyson sphere
- let the nanites absorb you into the singularity
- advice for the afterlife: be nice and reasonable when you ask questions and maybe people will help you (this is an ""Issues"" section and OpenSource generally doesn't follow the The Pyramid of Screaming)

Besides, most Mac hardware is not really made to train models like these for hours. Only Mac Pros fitted with newer GPUs, high-end iMacs with a new AMD GPU >2GB and the iMac Pro (which only a handful of people have considering its absurd price) would have enough processing power and VRAM to train a model in an **acceptable** timeframe. Even the newest $ 2,799 MacBook Pro only has a GPU with 4GB VRAM, which is not made to operate a few hours under 100% load. But if you want to melt a ~3000$ device just for swapping some faces – why not?",waiting already work training model right python could write swift follow install version one read gather extract process training data min use terminal later ready start training start training air realize build energy nuclear research reactor constant power plug power adapter put wake year lose due hypothermia look training face still like mole rat compression look window realize sun covered sphere let absorb singularity advice afterlife nice reasonable ask maybe people help section generally follow pyramid screaming besides mac hardware really made train like mac fitted new pro handful people considering absurd price would enough power train model acceptable even pro made operate load want melt device swapping,issue,positive,positive,neutral,neutral,positive,positive
366478157,"@flosth Try to be little considerate, we are doing it in our free time, for fun, you know.

Anyway I don't think this is a place to ask for it and I don't think it is necessary. I would propose closing this issue. ",try little considerate free time fun know anyway think place ask think necessary would propose issue,issue,positive,positive,positive,positive,positive,positive
366476987,"my work is coming up with the idea to post to mac, now it's time for others to help out",work coming idea post mac time help,issue,negative,neutral,neutral,neutral,neutral,neutral
366476917,"Do it yourself. Oh wait, you can't - you don't know anything about programming. Open-source projects are a game of give and take, no one is going to do things for you unless you put in some work yourself, actual work, not ""management"".

Regardless, you're barking up the wrong tree, OpenCL support is not a Faceswap issue, it's a Tensorflow issue.",oh wait ca know anything game give take one going unless put work actual work management regardless barking wrong tree support issue issue,issue,negative,negative,negative,negative,negative,negative
366476686,then get a mac version going,get mac version going,issue,negative,neutral,neutral,neutral,neutral,neutral
366476604,"Nothing needs to be rewritten to use OpenCL, the deepfake scripts are platform-agnostic, you just need to use an OpenCL-capable build of Tensorflow. The dev/amd_gpu branch of Luke Iwanski's Tensorflow fork works.",nothing need use need use build branch luke fork work,issue,negative,neutral,neutral,neutral,neutral,neutral
366474239,Faceapp actually uploads your content to their servers to process against their model. There is no actual calculation done on your phones hardware,actually content process model actual calculation done hardware,issue,negative,neutral,neutral,neutral,neutral,neutral
366466001,"You already answered your question
> ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install **CUDA 9.0** from this URL: https://developer.nvidia.com/cuda-toolkit

You need cuda 9.0",already question could find directory path environment variable install need,issue,negative,neutral,neutral,neutral,neutral,neutral
366463843,"I am pretty newbish with coding and will try anyway, I find this in extract.py

    def handleImage(self, filename):
        count = 0

        image = cv2.imread(filename)
        faces = self.get_faces(image)
        rvals = []
        for idx, face in faces:
            count = idx

            resized_image = self.extractor.extract(image, face, 256)
            output_file = get_folder(self.output_dir) / Path(filename).stem
            cv2.imwrite(str(output_file) + str(idx) + Path(filename).suffix, resized_image)
            f = {
                ""x"": face.x,
                ""w"": face.w,
                ""y"": face.y,
                ""h"": face.h,
                ""landmarksXY"": face.landmarksAsXY()
            }
            rvals.append(f)

also rotating from 
https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#geometric-transformations
will report back if I found a solution.",pretty try anyway find self count image image face count image face path path also rotating report back found solution,issue,positive,positive,positive,positive,positive,positive
366463558,"For me installing dlib like this was resulting in no cuda support in dlib.
Try getting repo for dlib and build it from source.
",like resulting support try getting build source,issue,positive,neutral,neutral,neutral,neutral,neutral
366455688,"I did implement only User Interface @flosth. I am not that good to implement OpenCL version. And even if I wanted to, it would take me like a year.",implement user interface good implement version even would take like year,issue,positive,positive,positive,positive,positive,positive
366455536,"@p0sera no don't wait man, think of how much money you could make if you put it out for Mac. please start working on it, I will help",wait man think much money could make put mac please start working help,issue,positive,positive,positive,positive,positive,positive
366455361,"But you can modify it yourself in Visual Studio solution and Advanced installer project if you want. The repo is here: 
https://bitbucket.org/radeksissues/myfakeapp",modify visual studio solution advanced installer project want,issue,positive,positive,positive,positive,positive,positive
366452626,@Alexander01998 you guys are very smart im sure you could find a way. you and the fakeapp creator and people like @p0sera need to come together to build a mac version and you will make tons of money. i know you can do this.,smart sure could find way creator people like need come together build mac version make money know,issue,positive,positive,positive,positive,positive,positive
366452452,"@p0sera nobody's talking about preventing you from sharing it man, look its fine but the people need a mac version right now not another windows version. i cant use it on my mac and i have to use it on my weak windows laptop, if you code that i wont have to.",nobody talking man look fine people need mac version right another version cant use mac use weak code wont,issue,negative,positive,positive,positive,positive,positive
366452138,"@p0sera no i will not pay for a mac fakeapp because i didn't even pay for the windows fakeapp, that would be unfair. however i will say that it is good.",pay mac even pay would unfair however say good,issue,negative,positive,neutral,neutral,positive,positive
366452076,Maybe next time I will not share this with other people...,maybe next time share people,issue,negative,neutral,neutral,neutral,neutral,neutral
366451977,Will you pay me @flosth ? I did this because the FakeApp v1 or v2 did not work on my PC. I have no motivation to create it for a Mac.,pay work motivation create mac,issue,negative,neutral,neutral,neutral,neutral,neutral
366451867,@p0sera well get a VM and get to work. i want to see smart people improve deepfakes but wasting time on what we already have is not the way man.,well get get work want see smart people improve wasting time already way man,issue,positive,positive,positive,positive,positive,positive
366451817,"@p0sera seems like it has basically the same options just an extra ""converter"" option.",like basically extra converter option,issue,negative,neutral,neutral,neutral,neutral,neutral
366451702,"@p0sera i can't create it because i don't know programming but if you do why don't you do it. we need a mac fakeapp, we don't need another windows fakeapp. this repo should be working on making new stuff not redoing stuff we already have.",ca create know need mac need another working making new stuff stuff already,issue,negative,positive,positive,positive,positive,positive
366451603,@gdunstone i'm not a coder i just want to make deepfakes and i was hoping to see something new like fakeapp for mac. as it is this thing is just an uglier fakeapp. make one for mac and i will praise it.,coder want make see something new like mac thing make one mac praise,issue,positive,positive,positive,positive,positive,positive
366451600,I did this app for myself. If you want an app for a Mac then create it and share it @flosth. ,want mac create share,issue,positive,neutral,neutral,neutral,neutral,neutral
366451447,"@flosth I see you have no contributions.
Contributions lend credibility to your criticism. 
If you want people to take you seriously, then I recommend you gain some credibility. ",see lend credibility criticism want people take seriously recommend gain credibility,issue,negative,negative,negative,negative,negative,negative
366451359,"@p0sera it worked for me, but either way the UI should be better and it should be crossplatform if you're trying to improve on fakeapp. 

@Apollo122 it's true though, for a second I was excited to see fakeapp going to more platforms but it's just a windows clone.",worked either way better trying improve true though second excited see going clone,issue,positive,positive,positive,positive,positive,positive
366450883,"seems like a waste of time to create a significantly worse version of fakeapp for windows. fakeapp already runs on windows, why didn't you make one for mac?",like waste time create significantly worse version already make one mac,issue,negative,negative,negative,negative,negative,negative
366427049,"For the fix suggested by @iperov  and @LordVulkan I wonder whether we need at all use face_recognition.
face_alignment when calculating landmarks already establish face location box. The question that it is impossible to get without changing get_landmarks
Provided that it returns bounding rect, the code in faces_detect could be.

`
def detect_faces(frame, model=""hog""):

    global fa
    if fa == None:
        if model==""cnn"":
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=False,enable_cudnn=False,use_cnn_face_detector=True)
        else:
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=False,enable_cudnn=False,use_cnn_face_detector=False)

    raw_rects, raw_landmarks = fa.get_landmarks(frame,all_faces=False)
    landmarksXY = []
    face_locations =[]
    if raw_landmarks is not None and raw_rects is not None:
        for raw_landmark in raw_landmarks:
            landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

        for raw_rect in raw_rects:
            face_locations.append((int(raw_rect.top()), int(raw_rect.right()), int(raw_rect.bottom()), int(raw_rect.left())))
            
        for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
            yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)`

Kind of removes calculation overhead, which makes it a bit faster especially for cnn",fix wonder whether need use calculating already establish face location box question impossible get without provided bounding rect code could frame hog global fa fa none fa else fa frame none none right bottom zip yield frame bottom right right bottom kind calculation overhead bit faster especially,issue,positive,positive,positive,positive,positive,positive
366391806,"I think CNN implementation can be improved. I use hd images for extract, if I use CNN with cuda support I get out of memory crash. If I use CNN without cuda it takes forever to complete. 

There's an implementation [here](https://github.com/deepfakes/faceswap/issues/162) I think pretty efficient. It first downsizes the image by four then use CNN with cuda to detect face then upsizes the image again and use hog to extract face. It works good but because it's not a part of the plugin system it doesn't output alignment.json file. Also It has the same zoomed in output problem.",think implementation use extract use support get memory crash use without forever complete implementation think pretty efficient first image four use detect face image use hog extract face work good part system output file also output problem,issue,positive,positive,positive,positive,positive,positive
366381987,"Is there a reason for this change? Since the encoder is the same between the two models, what is the purpose of storing it in two different places on disk?",reason change since two purpose two different disk,issue,negative,neutral,neutral,neutral,neutral,neutral
366370223,thanks @iperov and @LordVulkan but I think I miss something. Tried every method here for pytorch including building it under win10 - still same performance.,thanks think miss something tried every method building win still performance,issue,positive,positive,positive,positive,positive,positive
366361652,"Took a shot and added an option (-ps 1.25) to FacePainters Gist to add padding around detected faces: https://gist.github.com/k3erg/a042265da4649e5a2b688f393db217a6

It basically scales the detected rect AFTER doing all detection stuff and reextracts the face with padding. It takes care of keeping the rect inside the movie frame as well. So, no changes in the behaviour, just adaptable zoom.",took shot added option gist add padding around basically scale rect detection stuff face padding care keeping rect inside movie frame well behaviour adaptable zoom,issue,positive,neutral,neutral,neutral,neutral,neutral
366230455,"So the output seems not to be ideal for the purpose of masking the face regions, and more samples seem to reduce the issue.",output ideal purpose face seem reduce issue,issue,positive,positive,positive,positive,positive,positive
366224163,"@kcimit actually this is LordVulkan fix for use face_alignment in faceswap.
pytorch must be installed with cuda support, then speed is normal, ~1.3 images per sec",actually fix use must support speed normal per sec,issue,negative,positive,neutral,neutral,positive,positive
366222245,"@k3erg If you get 1.5 working with GPU on High Sierra, any chance you could type up a quick gist on how? I keep erroring after a few minutes, and can't figure out why.",get working high sierra chance could type quick gist keep ca figure,issue,negative,positive,positive,positive,positive,positive
366218464,"Even with iperov fix hog detection is terribly slow not to mention cnn detection which was always very slow for me.
Detecting a face in single 1280x720 snapshot takes from 4-10 minutes. Is it normal? Perhaps problem with tf/cuda/pyhon config.

What time does it takes normally to process single picture in your case? 
",even fix hog detection terribly slow mention detection always slow face single snapshot normal perhaps problem time normally process single picture case,issue,negative,negative,neutral,neutral,negative,negative
366195656,"I had the same problem after I trained 36h (Model A 2000 pics, Model B 400 pics), 12h ago I added more Pics to Model A.  Luckily I backup the model files often.",problem trained model model ago added model luckily backup model often,issue,negative,positive,positive,positive,positive,positive
366047402,@kellurian I'm running on two 970's with tensorflow 1.4 and CUDA 8. I'll try upgrading. Running on 1 gpu my encoderdim was 512 but on two its 128.,running two try running two,issue,negative,neutral,neutral,neutral,neutral,neutral
365929853,"Not for me. I did not have to change any of the values for it to work. Don’t know if it mattered but I had already upgraded ther version of tensorflow to 1.5 before starting this, but I have also now gone to CUDA 9 without problems as well. What two GPU’s are you running?",change work know already version starting also gone without well two running,issue,negative,neutral,neutral,neutral,neutral,neutral
365890101,"The progress of GAN training should be a competition between generator and discriminator where they're both hovering around 50% accuracy, if either pull too far ahead the system fails, what you're describing here sounds like such a failure, probably due to too low a sample size.",progress gan training competition generator discriminator hovering around accuracy either pull far ahead system like failure probably due low sample size,issue,negative,negative,neutral,neutral,negative,negative
365856442,"@kellurian For me when I tried this solution I had to dramatically drop my ENCODER_DIM number to not get an OOM error, is this expected?",tried solution dramatically drop number get error,issue,negative,neutral,neutral,neutral,neutral,neutral
365833191,"`Also @iperov example uses hog AFAIK`

> face_locations =  face_recognition.face_locations(image, 1, 'cnn')
> face_landmarks_list = face_recognition.face_landmarks(image, face_locations)

same result",also example hog image image result,issue,negative,neutral,neutral,neutral,neutral,neutral
365769372,"@subzerofun If you want to use Tensorboard it'd might make more sense to use it directly on a merged model.

    x1 = Input( shape=IMAGE_SHAPE )
    x2 = Input( shape=IMAGE_SHAPE )
    tbcallback = TensorBoard(log_path)
    mergedModel = Model( [x1,x2] decoder_A( encoder(x1) ), decoder_B( encoder(x2) ) )
    #...
    mergedModel.fit(x=[warped_A,warped_B], y=[target_A,target_B], callbacks=[tbcallback])
",want use might make sense use directly model input input model,issue,negative,positive,neutral,neutral,positive,positive
365762002,"No I did it intentionally following this issue: #96

If you want to add a CLI argument to give this var the value you want, feel free.",intentionally following issue want add argument give value want feel free,issue,positive,positive,positive,positive,positive,positive
365759437,"@Clorr - seriously, check the code!

The coverage factor determines what ""area"" of the 256x256 image is assumed to contain the real face data to train on.


First a value of 220 was used for the coverage factor. Meaning, 220/256th of the image was used to train on.

Then the coverage factor was (re)set to 160 in your changelist, which takes only 160/256th of the image (taken from the center) as ""relevant face data"".
This caused the zoom in the preview window, as the area we're training on is smaller thus will be blown up more in the preview.

The training data being a bit more zoomed in caused the""reset"" of the training that people were reporting, as suddenly the input data changed.

You don't have to believe me - just TRY it!! Set the coverage factor to 220, check the output, and then set it to 160 and compare that output!

If you didn't *intentionally* change the coverage factor from 220 back to 160, I'd strongly suggest putting it at 220 again.",seriously check code coverage factor area image assumed contain real face data train first value used coverage factor meaning image used train coverage factor set image taken center relevant face data zoom preview window area training smaller thus blown preview training data bit reset training people suddenly input data believe try set coverage factor check output set compare output intentionally change coverage factor back strongly suggest,issue,negative,positive,neutral,neutral,positive,positive
365758903,"So I played a bit with the box ;-) And it actually does not improve anything... 

I could not reproduce [@LordVulkan second example](https://github.com/deepfakes/faceswap/issues/187#issuecomment-365103341). @LordVulkan could you call `pose_predictor` without the box argument? Because I couldn't...

Also [@iperov example](https://github.com/deepfakes/faceswap/issues/187#issuecomment-365731325) uses hog AFAIK

So `face-alignment` seems the way to go.
",bit box actually improve anything could reproduce second example could call without box argument could also example hog way go,issue,positive,neutral,neutral,neutral,neutral,neutral
365737026,"@iperov it takes a whole video with multiple filter images. so its useful to extract faces lets say from a movie.

@facepainter output images are too zoomed in. could you please check [this discussion](https://github.com/deepfakes/faceswap/issues/187#issuecomment-365511279) and if possible
implement face_alignment pytorch cnn. ",whole video multiple filter useful extract say movie output could please check discussion possible implement,issue,positive,positive,positive,positive,positive,positive
365736529,"Yes, this is because the script you mention does not do a face_search before, and passes the full picture to the landmarks detector. That still adds to my conviction it is a problem of the box returned by the cnn detector",yes script mention full picture detector still conviction problem box returned detector,issue,negative,positive,positive,positive,positive,positive
365731325,"I checked problem picture directly in face_recognition/examples/find_facial_features_in_picture.py

result:

[Image Removed]


so... yes, no need face_alignment and pytorch, just need to fix existing code",checked problem picture directly result image removed yes need need fix code,issue,negative,positive,neutral,neutral,positive,positive
365725542,"Also note that there is no dependency between face detector and landmarks detector outside the box delimiting the face, so if it works with hog and not with cnn, it means it is a problem of the box",also note dependency face detector detector outside box face work hog problem box,issue,negative,neutral,neutral,neutral,neutral,neutral
365723665,"@KMMR156 In the Extract_Align plugin, the final output is done with the help of the landmarks. And indeed, if the landmarks are wrong, the aligned output will be wrong.

[However, the landmarks are computed over the box returned by the face detector](https://github.com/deepfakes/faceswap/blob/51f1993d93e0ffb581d44416f327f0cf731c34e8/lib/faces_detect.py#L7) and it seems to me that the failure of finding landmarks is due to the too narrow box returned by the face detector",final output done help indeed wrong output wrong however box returned face detector failure finding due narrow box returned face detector,issue,negative,negative,negative,negative,negative,negative
365719474,"> What bothers me here is that this zooming effect is not related to the landmarks, it is related to cnn detector that is the same in face_recognition and in face-alignment

@Clorr i think the zooming is because of the wrong landmarks if you check the gif by @iperov 

[Image Removed]


only the ones with wrong landmarks are zoomed in",effect related related detector think wrong check gif image removed wrong,issue,negative,negative,negative,negative,negative,negative
365718126,"Thanks for the PR. One question though. The extract part uses `%d`, are you sure of the `%0d` ?",thanks one question though extract part sure,issue,positive,positive,positive,positive,positive,positive
365715875,"So, as it turned out the problem is the landmarks generator(aka shape predictor), maybe switching to face-alignment completely, as it also supports hog, would be a good idea.",turned problem generator aka shape predictor maybe switching completely also hog would good idea,issue,negative,positive,positive,positive,positive,positive
365688530,"win10, I've installed Cuda 9, CuDNN 7 and TensorFlow 1.5-gpu(pip). compiled dlib with cuda 9 and used faceswap without a problem.
Then i thought i should get rid of cuda 8, uninstalled it but after it couldnt import dlib anymore. said couldnt find dll or something. installed cuda 8 again and it started to work again. i read that they can co-exist together, so far no problems.",win pip used without problem thought get rid uninstalled import said find something work read together far,issue,positive,positive,positive,positive,positive,positive
365658351,"`Convert_GAN` is made for the particular output of the GAN. If your work is based on the AutoEncoder, no need to go for this converter, you will have to stick to the over `Convert_` plugins and modify the sizes. Just modifying the line `face = cv2.resize(face, (64, 64))` to `face = cv2.resize(face, (128,128))` should make you started",made particular output gan work based need go converter stick modify size line face face face face make,issue,negative,positive,positive,positive,positive,positive
365656649,See #86 if that can help. Otherwise reopen an issue in faceswap-playground,see help otherwise reopen issue,issue,negative,neutral,neutral,neutral,neutral,neutral
365655211,Feel free to propose a PR when you have code to push,feel free propose code push,issue,positive,positive,positive,positive,positive,positive
365654868,"@IUsedToBeAPygmy the coverage is a feature from the very original repo. I introduced a var in order to be able to have 2 different values because faceswap-GAN repo does not have the same value.

AFAIK the face coverage is the part that is warped and if you did apply the warping to the whole image, you would loose part of the image and then have problem with your training

Also having it bigger wouldn't give more details to the network as the network has an input that is 64x64",coverage feature original order able different value face coverage part warped apply warping whole image would loose part image problem training also bigger would give network network input,issue,negative,positive,positive,positive,positive,positive
365651496,"And does it work now?
Please reopen in faceswap-playground if still relevant. Thanks",work please reopen still relevant thanks,issue,positive,positive,positive,positive,positive,positive
365651106,Please reopen in faceswap-playground if still relevant. Thanks,please reopen still relevant thanks,issue,positive,positive,positive,positive,positive,positive
365650617,Please reopen in faceswap-playground if still relevant,please reopen still relevant,issue,negative,positive,positive,positive,positive,positive
365650277,"That's what I think too, and it would be nice if we could include this ""normalization"" step in our code",think would nice could include normalization step code,issue,negative,positive,positive,positive,positive,positive
365649417,"The zooming effect is also present in face-alignment as you can see here (I have no clue why it is a different box though):

https://github.com/deepfakes/faceswap/issues/187#issuecomment-365238963

I think face-alignment fixes it this way:

1. Gets face location box from the image with cnn algorithm.
2. Modifies center and size of the box.
3. Crops the face from the image using the new box.
4. Calculates landmarks inside that cropped image.",effect also present see clue different box though think way face location box image algorithm center size box face image new box inside image,issue,negative,positive,neutral,neutral,positive,positive
365648867,A failure in loading data should not stop the program. Try resetting the code to the original and check your modifications if you have done some,failure loading data stop program try code original check done,issue,negative,positive,neutral,neutral,positive,positive
365648459,"@Clorr face detector same, but landmarks solver different
",face detector solver different,issue,negative,neutral,neutral,neutral,neutral,neutral
365644834,And also I would better fit in faceswap-playground...,also would better fit,issue,positive,positive,positive,positive,positive,positive
365644668,Result not only depends on the power you have but on the training images you provide. Are they well aligned? How many iterations did you? What is your actual output? You should post these details to get help,result power training provide well many actual output post get help,issue,positive,positive,positive,positive,positive,positive
365644129,"It is totally possible to add face-alignment as an option, however something still bothers me.

From what has been seen, landmarks detection seems to fail because of a too narrow crop which can be solved by adding some margin to the image before passed to the detector.

The other issue mentioned by @iperov is that we have a zooming effect that is not in `face-alignment`. What bothers me here is that this zooming effect is not related to the landmarks, it is related to cnn detector that is the same in `face_recognition` and in `face-alignment`. So I'm still wondering where this come from, and I strongly suspect the preprocessing done in `face-alignment` is the key",totally possible add option however something still seen detection fail narrow crop margin image detector issue effect effect related related detector still wondering come strongly suspect done key,issue,negative,negative,neutral,neutral,negative,negative
365581601,Maybe we could add face-alignment optional support for Linux and macOS users and leave pytorch out of the official requirements.,maybe could add optional support leave official,issue,negative,neutral,neutral,neutral,neutral,neutral
365575064,So much improvement! @iperov How do I make pytorch work for windows?,much improvement make work,issue,negative,positive,positive,positive,positive,positive
365558720,"that was my bad, flip_input must be False
now all fine !!
face_recognition dlib cnn suxx, face_alignment pytorch cnn rules.

**face_alignment pytorch cnn** VS **face_recognition dlib cnn**
in faceswap
[Image Removed]


@Clorr @gdunstone will you adapt face_alignment to faceswap?",bad must false fine image removed adapt,issue,negative,negative,negative,negative,negative,negative
365548316,"Is there a way to adapt chroma/color in the trained model, or would you have to assimilate the color of the training data before training?",way adapt trained model would assimilate color training data training,issue,negative,neutral,neutral,neutral,neutral,neutral
365547284,"Just for reference:
macOS High Sierra, custom built tensorflow 1.4 with GPU support, built against CUDA 9.1 and CuDNN works ok.
Going to take a shot at tensorfow 1.5 with GPU support later today.",reference high sierra custom built support built work going take shot support later today,issue,positive,positive,neutral,neutral,positive,positive
365544019,"You can further reduce the VRAM needed by using `- t LowMem -s 16` and editing Model_LowMem.py as follows:

`13: ENCODER_DIM = 256`
and

`51: #x = self.conv(512)(x)`

Obviously, this comes at a price, but training even on my old MacBook Pro with Nvidia 750m*  is 60x as fast as on my new maxed-out MacBook Pro with no GPU support.

*yes you can compile tensorflow 1.4 with GPU support for macOS, pm if instructions needed.",reduce obviously come price training even old pro fast new pro support yes compile support,issue,positive,positive,positive,positive,positive,positive
365511279,"@LordVulkan thx for code
I found prebuilt win64 python 3.5 torch 0.3.0 package.
and tested your code
Its works slow because you reinitialize face_alignment every frame

my temporary fix is

```
fa = None

def detect_faces(frame, model=""hog""):
    face_locations = face_recognition.face_locations(frame, model=model)
    global fa
    
    if fa == None:
        if model==""cnn"":
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=False,use_cnn_face_detector=True)
        else:
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=False,use_cnn_face_detector=False)

    raw_landmarks = fa.get_landmarks(frame,all_faces=True)
    landmarksXY = []
    if raw_landmarks is not None:
        for raw_landmark in raw_landmarks:
            landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

        for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
            yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)
        
```

I will use this face detector for my faceswap build :)",code found win python torch package tested code work slow every frame temporary fix fa none frame hog frame global fa fa none fa else fa frame none right bottom zip yield frame bottom right right bottom use face detector build,issue,positive,positive,positive,positive,positive,positive
365483016,"@LordVulkan I can confirm the suggested code finds the correct landmarks. Indeed it's slower, but a lot more precise. 

As a side note. I had to tu user an older version of PyTorch (0.3.0) because 0.3.1 requires CUDA with compute capability > 3.0.

Request a PR on that code. Also on the the bug flag for printing the dots on the images. It should be activated on demand by a --debug flag in the extract script. I can help.",confirm code correct indeed lot precise side note tu user older version compute capability request code also bug flag printing demand flag extract script help,issue,negative,positive,positive,positive,positive,positive
365481560,"So I tried using the cnn extract command first to generate the alignment.json file.
Then when I use the convert -D cnn command, it convert all the faces. with a line saying 
Reading alignments from ***/test5/alignment.json before it started converting.",tried extract command first generate file use convert command convert line saying reading converting,issue,negative,positive,positive,positive,positive,positive
365472548,What's the size of the image you're trying to convert?,size image trying convert,issue,negative,neutral,neutral,neutral,neutral,neutral
365407858,need test with 90deg rotated face,need test deg rotated face,issue,negative,neutral,neutral,neutral,neutral,neutral
365403952,"@shaoanlu has added to his repo a new algorithm for face detection better than cnn.

https://github.com/shaoanlu/faceswap-GAN

Comparison gif:
![68747470733a2f2f7777772e64726f70626f782e636f6d2f732f64697a74786e746b737334647437762f6d61736b5f646c69625f6d74636e6e2e6769663f7261773d31](https://user-images.githubusercontent.com/562386/36173639-fc9d0b74-1109-11e8-9a5b-3fb799670767.gif)

",added new algorithm face detection better comparison gif,issue,negative,positive,positive,positive,positive,positive
365384553,"I suggest open 2DFAN-4.pth.tar in torch, research network structure and tensors, and port it to keras. 
:D

is this violates https://github.com/1adrianb/face-alignment/blob/master/LICENSE ?",suggest open torch research network structure port,issue,negative,neutral,neutral,neutral,neutral,neutral
365328253,"i dont want deal with conda, trying to build from python...",dont want deal trying build python,issue,negative,neutral,neutral,neutral,neutral,neutral
365317337,"I have just replaced the landmarks for the ones from face-alignment and it works a lot better, but it is also notably slower. I leave it here if someone wants to try it, don't forget to import face_alignment

face_detect.py
```
def detect_faces(frame, model=""hog""):
    face_locations = face_recognition.face_locations(frame, model=model)

    if model==""cnn"":
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=True,use_cnn_face_detector=True)
    else:
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=True,use_cnn_face_detector=False)

    raw_landmarks = fa.get_landmarks(frame,all_faces=True)
    landmarksXY = []
    if raw_landmarks is not None:
        for raw_landmark in raw_landmarks:
            landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

        for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
            yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)
```",work lot better also notably leave someone try forget import frame hog frame fa else fa frame none right bottom zip yield frame bottom right right bottom,issue,negative,positive,positive,positive,positive,positive
365309500,"run python `faceswap.py convert -h` (works for `convert`, `train` and also `extract`) to get all possible values. 

- -t will enable you to choose the model plugin (refered as `trainer`)
- -c will help you choose the convert plugin. In you example, you have to use **-c Adjust**

Note that `GAN` model goes with `GAN` convert. Otherwise, `Original` and `LowMem` can go with `Adjust` and `Masked`",run python convert work convert train also extract get possible enable choose model trainer help choose convert example use adjust note gan model go gan convert otherwise original go adjust masked,issue,positive,positive,positive,positive,positive,positive
365247554,"Yes, from what I understand it takes the center, but i don't understand the line with the 0.12. It moves the center a bit or something?

Then the scale is computed so that the box is 195 wide, doesn't it?

Then the [crop method](https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/utils.py#L79) returns a 256 wide image, so maybe it adds some margin around, which could explain that it gets the right landmarks as the face is not cropped too narrow?

I let you have a look when possible, no hurry ;-)",yes understand center understand line center bit something scale box wide crop method wide image maybe margin around could explain right face narrow let look possible hurry,issue,negative,negative,neutral,neutral,negative,negative
365245669,"The face_location object is the box itself, it is a 4-tuple: (top,right,bottom,left)
face-alignment seems to be centering and resizing the face box before calculating landmarks, I will take a look at it.

Comparison of face-alignment and face_recognition landmarks:

face_recognition landmarks with cnn face box:
[Image Removed]


face_recognition landmarks with hog face box:
[Image Removed]


face-alignment landmarks with cnn face box:
[Image Removed]


face-alignment landmarks with hog face box:
[Image Removed]



",object box top right bottom left centering face box calculating take look comparison face box image removed hog face box image removed face box image removed hog face box image removed,issue,negative,positive,positive,positive,positive,positive
365242622,"Strange that the cnn detector returns a different box. Where did you get the values for the box? Also, there is a [preprocessing of the recognized face done in 1adrianb repo](https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/api.py#L171):
```
                center = torch.FloatTensor(
                    [d.right() - (d.right() - d.left()) / 2.0, d.bottom() -
                     (d.bottom() - d.top()) / 2.0])
                center[1] = center[1] - (d.bottom() - d.top()) * 0.12
                scale = (d.right() - d.left() + d.bottom() - d.top()) / 195.0

                inp = crop(image, center, scale)
                inp = torch.from_numpy(inp.transpose((2, 0, 1))).float().div(255.0).unsqueeze_(0)
```

However my skills are too low to understand what this does. Have you some idea?",strange detector different box get box also face done center center center scale crop image center scale however low understand idea,issue,negative,negative,neutral,neutral,negative,negative
365239578,"yeah problem in face landmarks detector.

face-alignment better, but cant build it for windows :((",yeah problem face detector better cant build,issue,negative,positive,positive,positive,positive,positive
365238963,"1adrianb also gets wrong the face box and for some reason it is a different box than the one in face_recognition. It also doesn't affect the landmarks.

Comparison of different face boxes:

Red: Extracted by face_recognition using cnn.
Green: Extracted by face-alignment using cnn.
White: Extracted with hog. Same result in both repos.

[Image Removed]

",also wrong face box reason different box one also affect comparison different face red extracted green extracted white extracted hog result image removed,issue,negative,negative,negative,negative,negative,negative
365231299,Have you an idea on the zooming effect noticed by @iperov ? Because the 1adrianb/face-alignment repo also uses [mmod detector](https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/api.py#L75),idea effect also detector,issue,negative,neutral,neutral,neutral,neutral,neutral
365228983,"I have tried with 1adrianb/face-alignment and it seems to get the right landmarks, but I don't know why it is horribly slow even with CUDA.",tried get right know horribly slow even,issue,negative,negative,neutral,neutral,negative,negative
365222426,"Thank you @LordVulkan for the awesome report!

> The shape predictor receives as an argument the face box. According to dlib examples, it tries to get the landmark points inside that box, not the full image.

- I think it is intended, because if you give an image with many faces the landmarks detector would be lost I presume.
- From what you show, there is a slight difference between the box returned by hog and cnn, which I wasn't aware of. Maybe that explains also the ""zooming"" that @iperov reports?
- My first option would be to try to enlarge the box returned by the cnn detector and see if it solves our problem. Also we can ask @ageitgey to have a look as it would be an enhancement for all `face_recognition` users.",thank awesome report shape predictor argument face box according get landmark inside box full image think intended give image many detector would lost presume show slight difference box returned hog aware maybe also first option would try enlarge box returned detector see problem also ask look would enhancement,issue,negative,positive,positive,positive,positive,positive
365197470,"GAN creator told that is not normal.

https://github.com/shaoanlu/faceswap-GAN/issues/50",gan creator told normal,issue,negative,positive,positive,positive,positive,positive
365177931,"I think problem in landmarks detector, not face detector.
FaceSwap using ageitgey/face_recognition
fakeapp using 1adrianb/face-alignment",think problem detector face detector,issue,negative,neutral,neutral,neutral,neutral,neutral
365174433,That's alpha masks preview. It's supposed to look like that. So yeah normal.,alpha preview supposed look like yeah normal,issue,positive,positive,positive,positive,positive,positive
365151960,"fakeapp align without zoom glitches:

[Image Removed]
",align without zoom image removed,issue,negative,neutral,neutral,neutral,neutral,neutral
365151039,"@Clorr  - hey :) 

Yes - totally understand - was really just to show what I mean in terms of functionality rather than actual code that would be used - a general gist :)

* a big part of read logic that reads a video 
sure, here cv2 reads video (or images as long as they are sequentially named and the same dimensions e.g. %04d.jpg - like the output of ffmpeg or whatever) - this can be broken up easily, the updated gist is much clearer in this... but I will implement as ""scripts/extract-video.py"" as suggested for any pull request.

* no real extract logic 
Yeah I just did the crop as it simplifies it massively - but the principal is the same - use the landmarks to rotate and align, just using the encoding/crop here for simplicity. 

* The face filter logic has to be check to be merged with FaceFilter existing logic.
This bit I have working it tests already so hopefully I will pull soon - just super busy!

Top work on all the other stuff the project is looking (and working) great :)

Hopefully I will pull request this week with ""this kind of thing"" implemented.


",hey yes totally understand really show mean functionality rather actual code would used general gist big part read logic video sure video long sequentially like output whatever broken easily gist much clearer implement pull request real extract logic yeah crop massively principal use rotate align simplicity face filter logic check logic bit working already hopefully pull soon super busy top work stuff project looking working great hopefully pull request week kind thing,issue,positive,positive,positive,positive,positive,positive
365140049,"@iperov 
```

(deepfakes) C:\Users\ZeroCool22\Desktop\dlib ultimo chico\dlib-master>python setup.py install --yes DLIB_USE_CUDA -G ""Visual Studio 14 2015""
usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: setup.py --help [cmd1 cmd2 ...]
   or: setup.py --help-commands
   or: setup.py cmd --help

error: option -G not recognized

(deepfakes) C:\Users\ZeroCool22\Desktop\dlib ultimo chico\dlib-master>
```",ultimo python install yes visual studio usage help help error option ultimo,issue,positive,neutral,neutral,neutral,neutral,neutral
365133791,Apologies. Its two minutes and thirty seconds between model saves (100 iterations) and I'm running on an Quadro M2200. I am not starting with an existing model.,two thirty model running starting model,issue,negative,neutral,neutral,neutral,neutral,neutral
365133507,"I'd really like to try the 128x128 output size when the code is ready, but I've got an overclocked 1070 with 8 Gb rather than the 11 Gb on the 1080i that the code was made on.  I'm hoping that the script will run on a 1070 with some tweaking.",really like try output size code ready got rather code made script run,issue,positive,positive,positive,positive,positive,positive
365103341,"This is weird:

` return [pose_predictor(face_image, face_location) for face_location in face_locations]`

The shape predictor receives as an argument the face box. According to dlib examples, it tries to get the landmark points inside that box, not the full image.

`print(""Detection {}: Left: {} Top: {} Right: {} Bottom: {}"".format(
            k, d.left(), d.top(), d.right(), d.bottom()))
        # Get the landmarks/parts for the face in box d.
        shape = predictor(img, d)`
http://dlib.net/face_landmark_detection.py.html

That would explain why the landmarks are wrong if the cnn model extracts a zoomed-in image.

Passing the face box to the predictor outputs the expected(and wrong) result:

[Image Removed]

Not passing the box gets the landmarks right as expected:

[Image Removed]

But then the unexpected happened. Pass the hog face box to the predictor, it just ignores it.

[Image Removed]






",weird return shape predictor argument face box according get landmark inside box full image print detection left top right bottom get face box shape predictor would explain wrong model image passing face box predictor wrong result image removed passing box right image removed unexpected pas hog face box predictor image removed,issue,negative,positive,neutral,neutral,positive,positive
365096410,"Hey guys, 

Thanks for coming back and posting these.",hey thanks coming back posting,issue,negative,positive,neutral,neutral,positive,positive
365079915,"@gdunstone Hmm i checked again and I'm pretty sure its not like that. Maybe I'm wrong but lets be sure. I'll try to describe it with better words:
 
1.Think a video where there is a person called Bob and a painting of Carl on the wall in it. We want to swap Bob's face with another and leave Carl there.
2. We used some tool to extract the frames and put those in photos/A
3. We used extract, it output Bob's face images and the Carl's.
4. We deleted the Carl's images and put Bob's images in data/A. Note that Carl's data are still in alignment.json. And start training using data/A
5. We are done with the training and we want to convert the whole scene. So we using this command: convert -i ./photo/A/ -o ./output/
6. At this point photo/A contains the whole frame with both Bob and Carl in it, it also has alignment.json which contains both Bob's and Carl's data which we don't want to swap. But they will both get swapped because all data are there.

This is the what i have been asking. To use convert with original deepfakes you provide a folder called aligned. This folder contains images of swapped faces and algorithm uses those images to merge with the original. To have the same functionally with our json we should maybe write an utility function to check filenames in data/A and delete the entries from alignment.json those that don't match. 
",checked pretty sure like maybe wrong sure try describe better video person bob painting carl wall want swap bob face another leave carl used tool extract put used extract output bob face carl carl put bob note carl data still start training done training want convert whole scene command convert point whole frame bob carl also bob carl data want swap get data use convert original provide folder folder algorithm merge original functionally maybe write utility function check delete match,issue,positive,positive,positive,positive,positive,positive
365065683,"Otherwise, the loss can decrease fast when you start training on a new person with an existing model, so be more precise in your request as it is hard here to understand what you did.",otherwise loss decrease fast start training new person model precise request hard understand,issue,negative,positive,positive,positive,positive,positive
365065045,"Note that the log that is printed does not make one line per iteration (as previously) but makes one new line when it saves your model.

Also please indicate number of iterations, and not a duration (the duration varies depending on how powerful your machine is)",note log printed make one line per iteration previously one new line model also please indicate number duration duration depending powerful machine,issue,positive,positive,neutral,neutral,positive,positive
365055276,"There is no specific picture zooming here, it is the extract as it is done by the code just now with the source you can find on the [original issue](https://github.com/deepfakes/faceswap-playground/issues/43)

The question is to know why the landmarks are incorrect here, and also what we can do to correct this.

But as you say, there may be another problem which is that the face is framed too narrow. However, I don't think it is the origin of the landmarks defect as the landmarks are calculated on the original image (in `lib/faces_detect.py`)",specific picture extract done code source find original issue question know incorrect also correct say may another problem face framed narrow however think origin defect calculated original image,issue,negative,positive,positive,positive,positive,positive
365047655,"why pictures zooming ?

cnn:
[Image Removed]
hog:
[Image Removed]

need mp4 file ?",image removed hog image removed need file,issue,negative,neutral,neutral,neutral,neutral,neutral
364959737,there is an option to activate the mmod_human_face_detector which is the same than FakeApp. It is not activated by default as it is slow. Add `-D cnn` to your command line,option activate default slow add command line,issue,negative,negative,negative,negative,negative,negative
364940780,"1. Installation problems are not issues.
2. They should go in https://github.com/deepfakes/faceswap-playground
3. There was 2 answers and no further activity in 3 days",installation go activity day,issue,negative,neutral,neutral,neutral,neutral,neutral
364935845,Ok I think I fixed it. Removing seamless -D cnn is giving me speeds of 5.5 it/s. Now the same 5400 images in 15 minutes,think fixed removing seamless giving,issue,negative,positive,neutral,neutral,positive,positive
364931504,"@salre9501  5402 for 50 min ????? superior result. I have only ~3000 per hour. 
I also have low GPU usage on convert, I think its normal.",min superior result per hour also low usage convert think normal,issue,negative,positive,positive,positive,positive,positive
364930734,"Ok so I did 

import dlib
dlib.DLIB_USE_CUDA

and it says true. I create an alignments.json after pulling the update and extracting again. I tried converting and I get a little faster speed, but my GPU usage still zero (except for the vram). Now I'm getting 50 minutes for 5402 images so it was an improvement. I'm just not sure if these are normal speeds.

dlib version 19.9.99, tensorflow-gpu 1.5, CUDA 9, cudnn 7",import true create update tried converting get little faster speed usage still zero except getting improvement sure normal version,issue,positive,positive,positive,positive,positive,positive
364920548,"@iperov ahh looks like I forgot to pull the latest updates!

It's complaining about a alignment.json file now, how do I generate this file?",like forgot pull latest file generate file,issue,negative,positive,positive,positive,positive,positive
364912230,"@ZeroCool22 try latest dlib with

`python setup.py install --yes DLIB_USE_CUDA -G ""Visual Studio 14 2015""`",try latest python install yes visual studio,issue,negative,positive,positive,positive,positive,positive
364908869,"Hmm I'm also having this problem.

I reinstalled dlib using the methods above, and my dlib.DLIB_USE_CUDA returns true. My tensorflow also can detect the gpu, so that isn't the problem. Using python 3.5

So when I run the convert (-D hog), it doesn't use GPU at all. Or is the (-D cnn) only one using the gpu?

I tried running the -D cnn option but then the dlib fails with 

Failed to convert image: Reason: Error while calling cudaMalloc(&data, new_size*sizeof(float)) in file: reason: out of memory

I have a gtx 1080 gpu.

Any hints on what is causing this?",also problem true also detect problem python run convert hog use one tried running option convert image reason error calling data float file reason memory causing,issue,negative,positive,positive,positive,positive,positive
364885723,@Clorr extraction certainly does work on the CPU with the (older) compiled dlib. training works as expected on the GPU.,extraction certainly work older training work,issue,negative,positive,positive,positive,positive,positive
364870013,"Yes

On 12 Feb. 2018 7:49 pm, ""Apollo122"" <notifications@github.com> wrote:

> So it reads file names from data/A right?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/155#issuecomment-364860255>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeNIU8hSGfgI5xx6STUrNNdhPNaS1ks5tT_sfgaJpZM4R-le3>
> .
>
",yes wrote file right reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
364859160,"CUDA TEST: - cmakecache ??
wrong file in google drive",test wrong file drive,issue,negative,negative,negative,negative,negative,negative
364850587,"I don't know if you needed that, that's the patch that appears in the Anaconda prompt: `C:\Users\ZeroCool22\Desktop\DLIB ULTIMO CHICO\dlib-master\build\temp.win-amd64-3.6\Release\dlib_build\cuda_test_build`",know patch anaconda prompt ultimo,issue,negative,neutral,neutral,neutral,neutral,neutral
364848560,"**DLIB INSTALLATION LOG:** https://drive.google.com/open?id=15TKqWINR8twQH7LiPSapT89JmGBGtj9-

**CUDA TEST:** https://drive.google.com/open?id=1NdzfFpC5KsOZCnI2M4nRGltq-Q-kB36z

lol, sorry fixed.",installation log test sorry fixed,issue,negative,negative,negative,negative,negative,negative
364847690,i dont know what to say without log.,dont know say without log,issue,negative,neutral,neutral,neutral,neutral,neutral
364847521,"@Apollo it can because it scans the directory and checks if the file names are in alignment.json

It will do an intersection of files and entries in alignment.json

I also highly recommend using the yaml serialiser, because you can append other yamls to alignment.yaml
",directory file intersection also highly recommend append,issue,negative,positive,positive,positive,positive,positive
364846809,"@iperov If want the cuda_test from `C:\Users\ZeroCool22\Desktop\dlib ultimo chico\dlib-master\build\temp.win-amd64-3.6\Release\dlib_build\cuda_test_build` i can give it yo you.

But the LOG with installing DLIB doesn't show up FULL on the Anaconda terminal...",want ultimo give yo log show full anaconda terminal,issue,negative,positive,positive,positive,positive,positive
364840793,I have a question; let's say during extraction we had some false positives. Before training we deleted those manually but they're still in alignment.json. So in convert won't the algorithm use those false positives because they are still in json? @gdunstone,question let say extraction false training manually still convert wo algorithm use false still,issue,negative,negative,negative,negative,negative,negative
364839604,"@iperov 

(deepfakes) C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>python cuda.py
Traceback (most recent call last):
  File ""cuda.py"", line 1, in <module>
    print(dlib.DLIB_USE_CUDA)
NameError: name 'dlib' is not defined",python recent call last file line module print name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
364839531,"I built with cuDNN 6 ok.

my trick how to build dlib with installed both 2015 and 2017:
is edit dlib\setup.py:

```
. . .
cmake_args = ['-DCMAKE_GENERATOR=Visual Studio 14 2015',
. . .
```",built trick build edit studio,issue,negative,neutral,neutral,neutral,neutral,neutral
364839066,"@iperov It´s working! Thanks dude.

In all my tries never do a `pip uninstall dlib` inside the Enviroment before install `dlib` with CUDA flag, but now with dlib uninstalled **work perfect, 500 images in a few seconds :)**.

I was a little confuse about the Enviroment, this is what I was do if it helps someone:
- Uninstall **Visual Studio 2017**
- Install **Visual Studio 2015**
- Downgrade from **cuDNN 6** to **cuDNN 5.1** (With **CUDA 8** installed)
- Inside the Enviroment:
-- `pip uninstall dlib`
-- Download last dlib version from https://github.com/davisking/dlib/archive/master.zip
-- dlib dir unzipped and `python setup.py install --yes DLIB_USE_CUDA`

**dlib check** (_Inside the Enviroment_):
```
Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import dlib
>>> dlib.DLIB_USE_CUDA
True
>>>
```

**tensorflow check** (_Inside the Enviroment_):
```
>>> import tensorflow as tf
>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
```

```
2018-02-12 03:42:56.921157: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
2018-02-12 03:42:57.291935: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:02:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2018-02-12 03:42:57.292165: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1)
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1
2018-02-12 03:42:57.624743: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\direct_session.cc:299] Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1
```",working thanks dude never pip inside install flag uninstalled work perfect little confuse someone visual studio install visual studio downgrade inside pip last version python install yes check python bit win type help copyright license information import true check import sess binary use found device name major minor device device name bus id compute capability device device name bus id compute capability device device name bus id compute capability,issue,positive,positive,positive,positive,positive,positive
364836944,"@ZeroCool22 
as interpreter:
run python.exe
import dlib
dlib.DLIB_USE_CUDA

from .py :

print(dlib.DLIB_USE_CUDA)",interpreter run import print,issue,negative,neutral,neutral,neutral,neutral,neutral
364835545,"**conda list**
 ```
packages in environment at C:\ProgramData\Anaconda3\envs\deepfakes:

 Name                    Version                   Build  Channel
absl-py                   0.1.10                    <pip>
backports                 1.0              py36h81696a8_1
backports.weakref         1.0rc1                   py36_0
bleach                    1.5.0                    py36_0    conda-forge
boost                     1.64.0              py36_vc14_4  [vc14]  conda-forge
boost-cpp                 1.64.0                   vc14_1  [vc14]  conda-forge
bzip2                     1.0.6                    vc14_1  [vc14]  conda-forge
ca-certificates           2017.08.26           h94faf87_0
certifi                   2018.1.18                py36_0
click                     6.7                       <pip>
cmake                     3.9.4                h4b83b1b_0    anaconda
cudatoolkit               8.0                           3    anaconda
cudnn                     6.0                           0    anaconda
decorator                 4.0.11                   py36_0    conda-forge
**dlib                      19.9.99                   <pip>**
face-recognition          1.2.1                     <pip>
face-recognition-models   0.3.0                     <pip>
ffmpeg                    3.4.1                         1    conda-forge
freetype                  2.8.1                    vc14_0  [vc14]  conda-forge
h5py                      2.7.1                    py36_2    conda-forge
hdf5                      1.10.1                   vc14_1  [vc14]  conda-forge
html5lib                  0.9999999                py36_0    conda-forge
icc_rt                    2017.0.4             h97af966_0
icu                       58.2                     vc14_0  [vc14]  conda-forge
imageio                   2.1.2                    py36_0    conda-forge
intel-openmp              2018.0.0             hd92c6cd_8
jpeg                      9b                       vc14_2  [vc14]  conda-forge
keras                     2.0.9                    py36_0    conda-forge
libgpuarray               0.7.5                    vc14_0  [vc14]  conda-forge
libiconv                  1.14                     vc14_4  [vc14]  conda-forge
libpng                    1.6.34                   vc14_0  [vc14]  conda-forge
libprotobuf               3.2.0                    vc14_0  [vc14]  anaconda
libtiff                   4.0.9                    vc14_0  [vc14]  conda-forge
libwebp                   0.5.2                    vc14_7  [vc14]  conda-forge
libxml2                   2.9.3                    vc14_9  [vc14]  conda-forge
mako                      1.0.7                    py36_0    conda-forge
markdown                  2.6.9                    py36_0    conda-forge
Markdown                  2.6.11                    <pip>
markupsafe                1.0                      py36_0    conda-forge
mkl                       2018.0.1             h2108138_4
moviepy                   0.2.3.2                  py36_0    conda-forge
numpy                     1.12.1           py36hf30b8aa_1    anaconda
numpy                     1.14.0                    <pip>
olefile                   0.44                     py36_0    conda-forge
opencv                    3.3.0                  py36_200    conda-forge
openssl                   1.0.2n               h74b6da3_0
pillow                    5.0.0                    py36_0    conda-forge
pip                       9.0.1                    py36_1    conda-forge
protobuf                  3.5.1               py36_vc14_3  [vc14]  conda-forge
protobuf                  3.5.1                     <pip>
pygpu                     0.7.5                    py36_0    conda-forge
python                    3.6.4                         0    conda-forge
pyyaml                    3.12                     py36_1    conda-forge
qt                        5.6.2                    vc14_1  [vc14]  conda-forge
scandir                   1.6                      py36_0    conda-forge
scipy                     1.0.0            py36h1260518_0
setuptools                38.5.1                    <pip>
setuptools                38.4.0                   py36_0    conda-forge
six                       1.11.0                   py36_1    conda-forge
six                       1.11.0                    <pip>
sqlite                    3.20.1                   vc14_2  [vc14]  conda-forge
tensorflow-gpu            1.5.0                     <pip>
tensorflow-tensorboard    1.5.1                     <pip>
theano                    1.0.1                    py36_1    conda-forge
tk                        8.6.7                    vc14_0  [vc14]  conda-forge
tqdm                      4.11.2                   py36_0    conda-forge
vc                        14                            0    conda-forge
vs2015_runtime            14.0.25420                    0    conda-forge
webencodings              0.5                      py36_0    conda-forge
Werkzeug                  0.14.1                    <pip>
werkzeug                  0.14.1                     py_0    conda-forge
wheel                     0.30.0                    <pip>
wheel                     0.30.0                   py36_2    conda-forge
wincertstore              0.2                      py36_0    conda-forge
yaml                      0.1.7                    vc14_0  [vc14]  conda-forge
zlib                      1.2.11                   vc14_0  [vc14]  conda-forge
```",list environment name version build channel pip bleach boost click pip anaconda anaconda anaconda decorator pip pip pip anaconda mako markdown markdown pip anaconda pip pillow pip pip python pip six six pip pip pip pip wheel pip wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
364834233,"@iperov Well, i used that for install DLIB, but **convert** doesn't use the **GPU**.

Can you tell how run that .py check you said before...

I did a new .py file called **cuda** y put inside the code:

```
import dlib
dlib.DLIB_USE_CUDA
```

Then i did` cd C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>python cuda.py` and excecute `python cuda.py`, 

I excecute it in my **BASE** env and said this:

```
(base) C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>python cuda.py
Traceback (most recent call last):
  File ""cuda.py"", line 2, in <module>
    dlib.DLIB_USE_CUDA
AttributeError: module 'dlib' has no attribute 'DLIB_USE_CUDA'
```

If i ejecute it on the faceswap ENVS, it doen't show me anything.

```
(deepfakes) C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>python cuda.py

(deepfakes) C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>
```

",well used install convert use tell run check said new file put inside code import python python base said base python recent call last file line module module attribute doe show anything python,issue,negative,negative,negative,negative,negative,negative
364833506,@iperov It's wrong to use `setup.py install --yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA`?,wrong use install yes yes,issue,negative,negative,negative,negative,negative,negative
364833127,"@iperov 

```
(base) C:\Users\ZeroCool22\Desktop\Nueva carpeta (2)>python cuda.py
Traceback (most recent call last):
  File ""cuda.py"", line 2, in <module>
    dlib.DLIB_USE_CUDA
AttributeError: module 'dlib' has no attribute 'DLIB_USE_CUDA'
```

",base python recent call last file line module module attribute,issue,negative,negative,negative,negative,negative,negative
364832004,"@ByFede 

extract using dlib
train using tensorflow
convert using dlib and tensorflow

in latest commit convert no more using dlib bcuz use alignments got from extract, so you have to run extract again.
also your dlib built without CUDA.

pip uninstall dlib
goto dlib dir
python setup.py install --yes DLIB_USE_CUDA
",extract train convert latest commit convert use got extract run extract also built without pip python install yes,issue,positive,positive,positive,positive,positive,positive
364830104,"@iperov Said **False**, but when I run the **Train** use my 6GB GPU Memory at 40/50% usage.

What's wrong with my instalation? I've done all exactly described twice.

```
Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import dlib
>>> dlib.DLIB_USE_CUDA
False
>>>
```",said false run train use memory usage wrong done exactly twice python bit win type help copyright license information import false,issue,positive,negative,neutral,neutral,negative,negative
364828863,"check run python
```
import dlib
dlib.DLIB_USE_CUDA
```
what output?",check run python import output,issue,negative,neutral,neutral,neutral,neutral,neutral
364825325,I have already installed faceswap for a long time. I just do not understand why the issue was closed and not repaired.,already long time understand issue closed,issue,negative,negative,neutral,neutral,negative,negative
364823882,"@iperov Yes it is, I install it manually and checked with tensorflow, but I dont have clear how to check it with CNN.
Dont know what its wrong.

**Test `dlib`**:
`cmake -G ""Visual Studio 14 2015 Win64""`

> -- Selecting Windows SDK version to target Windows 10.0.16299.
> -- The C compiler identification is MSVC 19.0.24215.1
> -- The CXX compiler identification is MSVC 19.0.24215.1
> -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe
> -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works
> -- Detecting C compiler ABI info
> -- Detecting C compiler ABI info - done
> -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe
> -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works
> -- Detecting CXX compiler ABI info
> -- Detecting CXX compiler ABI info - done
> -- Detecting CXX compile features
> -- Detecting CXX compile features - done
> -- Looking for sys/types.h
> -- Looking for sys/types.h - found
> -- Looking for stdint.h
> -- Looking for stdint.h - found
> -- Looking for stddef.h
> -- Looking for stddef.h - found
> -- Check size of void*
> -- Check size of void* - done
> -- Enabling SSE2 instructions
> -- Searching for BLAS and LAPACK
> -- Searching for BLAS and LAPACK
> -- Looking for pthread.h
> -- Looking for pthread.h - not found
> -- Found Threads: TRUE
> -- A library with BLAS API not found. Please specify library location.
> -- LAPACK requires BLAS
> -- Found CUDA: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0 (found suitable version ""8.0"", minimum required is ""7.5"")
> -- Looking for cuDNN install...
> -- Found cuDNN: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0/lib/x64/cudnn.lib
> -- Building a CUDA test project to see if your compiler is compatible with CUDA...
> -- Checking if you have the right version of cuDNN installed.
> -- Enabling CUDA support for dlib. DLIB WILL USE CUDA
> -- C++11 activated.
> -- Configuring done
> -- Generating done
> -- Build files have been written to: D:/fy/fs/faceswap_env/dlib-master



**Also I have chequed in tensorflow if GPU is enable**:
`sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`

> 2018-02-11 03:27:20.363564: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
> 2018-02-11 03:27:20.747300: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
> name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7845
> pciBusID: 0000:02:00.0
> totalMemory: 6.00GiB freeMemory: 4.97GiB
> 2018-02-11 03:27:20.747460: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1)
> Device mapping:
> /job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1
> 2018-02-11 03:27:20.933639: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\direct_session.cc:299] Device mapping:
> /job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1",yes install manually checked dont clear check dont know wrong test visual studio win version target compiler identification compiler identification check working compiler visual studio check working compiler visual studio work compiler compiler done check working compiler visual studio check working compiler visual studio work compiler compiler done compile compile done looking looking found looking looking found looking looking found check size void check size void done searching blas searching blas looking looking found found true library blas found please specify library location blas found found suitable version minimum looking install found building test project see compiler compatible right version support use done generating done build written also enable sess binary use found device name major minor device device name bus id compute capability device device name bus id compute capability device device name bus id compute capability,issue,positive,positive,positive,positive,positive,positive
364823867,"@Clorr ustc mirror is within china's firewall thus faster than the deb original mirror for CN users
@riclava but you are slowing down for other users : (",mirror within china thus faster deb original mirror,issue,negative,positive,positive,positive,positive,positive
364821858,"When I use CNN do not use my GPU, only CPU usage, I have a  gtx1060 wtih 6gb and take me 30min for 100 images.
But when I train use all my GPU memory.
There is some error related to CNN.",use use usage take min train use memory error related,issue,negative,neutral,neutral,neutral,neutral,neutral
364820908,I am expressing interest in another preview window with a graph.,interest another preview window graph,issue,negative,neutral,neutral,neutral,neutral,neutral
364820512,50 min for 3000 - faster than my gtx1060. My speed is 30 min for 1500,min faster speed min,issue,negative,neutral,neutral,neutral,neutral,neutral
364819025,"For what its worth the original trainer worked at the default batch size of 64 on my 4 GB m2200m but after increasing my faceset size (both faces) by about 1000 pictures, it required a batch size of 32 to run without OOM errors.",worth original trainer worked default batch size increasing size batch size run without,issue,negative,positive,positive,positive,positive,positive
364814873,"@IUsedToBeAPygmy Hey why not just use Tensorboard: https://keras.io/callbacks/#tensorboard ?

I'm currently trying to implement it using this as a guide: https://gist.github.com/joelthchao/ef6caa586b647c3c032a4f84d52e3a11",hey use currently trying implement guide,issue,negative,neutral,neutral,neutral,neutral,neutral
364814339,"I still think that oom error is due to the cnn detector not freeing memory for some reason, which is outside the scope of this pull request. 

Thanks for your help with this. I'm going to merge now.",still think error due detector freeing memory reason outside scope pull request thanks help going merge,issue,positive,positive,neutral,neutral,positive,positive
364814199,"I using tensorflow-gpu.

> The cnn detector does have a huge memory footprint.

i just reporting bug with initial conditions.
and this bug fixed with this commit, because no conflict tensorflow-gpu and dlib-cuda in convert, because dlib-cuda no more used :)",detector huge memory footprint bug initial bug fixed commit conflict convert used,issue,negative,positive,positive,positive,positive,positive
364814170,"Have you tried the lower batch size option, like -bs 32. It worked for me.
Also I would like to know what VRAM size is required to run the original trainer and does training data change the required VRAM size?",tried lower batch size option like worked also would like know size run original trainer training data change size,issue,positive,positive,positive,positive,positive,positive
364814035,"Tensorflow isnt by default GPU accelerated. you need to install tensorflow-gpu.

The machine I'm on now isn't GPU accelerated, but I still get using tensorflow.

The cnn detector does have a huge memory footprint.",default accelerated need install machine accelerated still get detector huge memory footprint,issue,negative,positive,positive,positive,positive,positive
364813815,"`Using Tensorflow` - convert not accelerated?

also accelerated due to call `faces = self.get_faces(image)` when dlib built with `DLIB_USE_CUDA`
this call produce memory error relate to cnn detector only.",convert accelerated also accelerated due call image built call produce memory error relate detector,issue,negative,negative,negative,negative,negative,negative
364812789,"Thats odd. I dont think convert is gpu accellerated. Perhaps the cnn detector isnt freeing memory correctly.
Either way I dont think that it is related to this pull request more than this pull request preventing the oom error... very strange.
Do you have an issue open?",thats odd dont think convert perhaps detector freeing memory correctly either way dont think related pull request pull request error strange issue open,issue,negative,negative,neutral,neutral,negative,negative
364812457,"I have memory error in convert, not extract, without alignments :)",memory error convert extract without,issue,negative,neutral,neutral,neutral,neutral,neutral
364811930,dont use the `-j` option with the cnn detector. It oom errors on my 12gb titan,dont use option detector,issue,negative,neutral,neutral,neutral,neutral,neutral
364811646,however it is correct behaviour to skip an image that isnt in the alignments.json,however correct behaviour skip image,issue,negative,neutral,neutral,neutral,neutral,neutral
364811589,"are you using the cnn face detector on that, because I always get an oom error with paralellism and that cnn detector?",face detector always get error detector,issue,negative,neutral,neutral,neutral,neutral,neutral
364810032,"slight tilt. Fakeapp would extract the face but faceswap.py would not.
![out337](https://user-images.githubusercontent.com/36125909/36081197-0e5213aa-0f61-11e8-8167-8cdad0fbfc0f.png)
",slight tilt would extract face would,issue,negative,negative,negative,negative,negative,negative
364809892,"also if alignments exist and no specific record found its cause memory error on my 6GB videocard due to  `faces = self.get_faces(image)` call

so I suggest this:

cli.py
```
 def have_alignments(self):
        fn = os.path.join(str(self.arguments.input_dir), ""alignments.{}"".format(self.serializer.ext))
        return os.path.exists(fn)
```

convert.py:
```
import os

    def prepare_images(self):
        self.read_alignments()
        is_have_alignments = self.have_alignments()
        for filename in tqdm(self.read_directory()):
            image = cv2.imread(filename)

            if is_have_alignments:
                if self.have_face(filename):
                    faces = self.get_faces_alignments(filename, image)
                else:
                    print ('no alignment found {}'.format(os.path.basename(filename)))
                    continue
            else:
                faces = self.get_faces(image)
            yield filename, image, faces
```",also exist specific record found cause memory error due image call suggest self return import o self image image else print alignment found continue else image yield image,issue,negative,negative,neutral,neutral,negative,negative
364808782,"@gdunstone also fix

```
    def have_face(self, filename):
        return os.path.basename(filename) in self.faces_detected
```

with this fix, all fine for windows",also fix self return fix fine,issue,negative,positive,positive,positive,positive,positive
364806756,"I did some braindead profiling and the issue seems to stem from the line `new_face = self.encoder( face / 255.0 )[0]` in `get_new_face()` in `Convert_Masked.py`. I don't know enough about how the software is structured to say if it's meant to use GPU acceleration or not, but it seems to often-times just hang for no reason, regardless of how many faces (if any) were detected and had landmarks extracted. Face detection and landmark extraction is fast, on the order of milliseconds. My bet is there's some infinite loop shenanigans going on in one of the yield statements.",issue stem line face know enough structured say meant use acceleration reason regardless many extracted face detection landmark extraction fast order bet infinite loop going one yield,issue,negative,positive,positive,positive,positive,positive
364804555,@iperov can you test this pull with windows (I don't have a windows development machine),test pull development machine,issue,negative,neutral,neutral,neutral,neutral,neutral
364788968,"Something to have in mind. There is a bug in current versions of CUDA 9.0 and 9.1.

[See TensorFlow 1.6.0-rc0 release](https://github.com/tensorflow/tensorflow/releases/tag/v1.6.0-rc0)

> # Known Bugs
> Using XLA:GPU with CUDA 9 and CUDA 9.1 results in garbage results and/or
> CUDA_ILLEGAL_ADDRESS failures.
> 
> Google discovered in mid-December 2017 that the PTX-to-SASS compiler in CUDA 9
> and CUDA 9.1 sometimes does not properly compute the carry bit when
> decomposing 64-bit address calculations with large offsets (e.g. load [x + large_constant]) into 32-bit arithmetic in SASS.
> 
> As a result, these versions of ptxas miscompile most XLA programs which use
> more than 4GB of temp memory. This results in garbage results and/or
> CUDA_ERROR_ILLEGAL_ADDRESS failures.
> 
> A fix in CUDA 9.1.121 is expected in late February 2018. We do not expect a
> fix for CUDA 9.0.x. Until the fix is available, the only workaround is to
> downgrade to CUDA 8.0.x
> or disable XLA:GPU.
> 
> TensorFlow will print a warning if you use XLA:GPU with a known-bad version of
> CUDA; see e00ba24.

As they say a fix for CUDA 9.0 is not expected, maybe the official requirements should stay at CUDA 8.0 until the fix for CUDA 9.1 and TensorFlow 1.6.0 releases later this month, and skip CUDA 9.0. I don't know if the bug affects this project.",something mind bug current see release known garbage discovered compiler sometimes properly compute carry bit address large load arithmetic result use temp memory garbage fix late expect fix fix available downgrade disable print warning use version see say fix maybe official stay fix later month skip know bug project,issue,negative,positive,neutral,neutral,positive,positive
364771907," @IUsedToBeAPygmy 
It certainly works for me to use the above arguments, but you have to change ""autoencoder"" to ""self.autoencoder"" which may be fairly obvious to you guys who program all the time, but it took me a while to figure that out.  Uses all 12 GB of video memory and splits the load between the two GPU's. Now the model.original file looks like this:
at the top:
`from keras.utils import multi_gpu_model`

```
self.autoencoder_A` = KerasModel(x, self.decoder_A(self.encoder(x)))
self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x))
self.autoencoder_A = multi_gpu_model( self.autoencoder_A ,2)
self.autoencoder_B = multi_gpu_model( self.autoencoder_B ,2)
```
The question is, what will this argument do if you just have one gpu? will it cause an error to include in as a general inclusion or should there be a model.multigpu file option to include? This is my first post on here, so hopefully not to lame.
",certainly work use change may fairly obvious program time took figure video memory load two file like top import question argument one cause error include general inclusion file option include first post hopefully lame,issue,negative,positive,neutral,neutral,positive,positive
364769232,Added PR #183 please review ASAP so that I can merge...,added please review merge,issue,negative,neutral,neutral,neutral,neutral,neutral
364768758,"@dr-benway Are you sure about the dlib version you specify? I don't remember why, but I found at some point that you have to use dlib > 19.7 with the project. (And there is wheel for it with Python 3.6)",sure version specify remember found point use project wheel python,issue,negative,positive,positive,positive,positive,positive
364768362,"Hi, thanks for this post. You can bring this to this repo, but as a new command more than as a plugin. Let me explain. Actual extracting is done like this:
- script/extract.py reads images (read logic)
- FaceFilter filters out unrecognised faces (filter logic)
- extract plugins apply the extraction on it (extract logic)

In the code you posted there is:
- a big part of read logic that reads a video
- a part of face filtering logic
- no real extract logic, just a crop (As far as I understand)

So your code is interesting, but the read logic has to be put in some scripts/extract-video.py . The face filter logic has to be check to be merged with FaceFilter existing logic.

In the #54 PR, I started doing a convert-video in order to be able to directly process a video, so your code is the same but for the extract step.

I don't know if you understood, as it is not that easy to explain. Feel free to discuss it here. In case it is too much of work, just create a folder `tools/`, put the file in it, and do a PR. We will see what we can do with it later on.",hi thanks post bring new command let explain actual done like read logic filter logic extract apply extraction extract logic code posted big part read logic video part face filtering logic real extract logic crop far understand code interesting read logic put face filter logic check logic order able directly process video code extract step know understood easy explain feel free discus case much work create folder put file see later,issue,positive,positive,positive,positive,positive,positive
364766182,"Hi, Original face coverage was 160. Faceswap-GAN has decided to use 220, and it seemed to be a good idea to just change that value to have a better coverage. However someone came and posted the #96 issue. So I thought it was better not to play with this on my own and that it was better to stick to the original parameters as I prefer having plugins that reflect the authors intention.

However as this is an int, it is totally possible to do an argument from this...",hi original face coverage decided use good idea change value better coverage however someone came posted issue thought better play better stick original prefer reflect intention however totally possible argument,issue,positive,positive,positive,positive,positive,positive
364765480,Feel free to discuss about this in https://github.com/deepfakes/faceswap-playground and/or make a Pull Request to improve documentation,feel free discus make pull request improve documentation,issue,positive,positive,positive,positive,positive,positive
364765145,"I think the same as @IUsedToBeAPygmy , but anyhow, thanks @GSonderling for providing a PR ",think anyhow thanks providing,issue,negative,positive,positive,positive,positive,positive
364764498,"i'm not sure about what this does, can you explain a bit more? Can someone review this?",sure explain bit someone review,issue,negative,positive,positive,positive,positive,positive
364763974,"Oh sorry, it's done already ;-)",oh sorry done already,issue,negative,negative,negative,negative,negative,negative
364763881,"Hi, and thank you for this pull request ;-)

May I suggest that you make this even more robust by using something like `self.mask_type.lower()` where relevant? This way, we don't have any more problem with that ;-)",hi thank pull request may suggest make even robust something like relevant way problem,issue,positive,positive,positive,positive,positive,positive
364763663,Are the faces you want to extract rotated or side views?,want extract rotated side,issue,negative,neutral,neutral,neutral,neutral,neutral
364763495,Can you also post the version of python you are using with `python --V`,also post version python python,issue,negative,neutral,neutral,neutral,neutral,neutral
364761579,"found one more problem

serialized path forcibly assigned to drive and folders
**""D:\\FaceSwap\\data_src\\out00183.png"": [**

so if I move whole dir, then cant convert.
it's necessary leave only filename.ext",found one problem path forcibly assigned drive move whole cant convert necessary leave,issue,negative,positive,positive,positive,positive,positive
364759211,"I understand that behavior. I just don't like it. If you don't like it either, fine, I want to change it later. But standard approach is one PR per feature. I can put more in this one, but it's going to add more complexity.",understand behavior like like either fine want change later standard approach one per feature put one going add complexity,issue,positive,positive,positive,positive,positive,positive
364748363,"They're certainly pretty but I'm not sure they're fit for the purpose of masking the replacement face, particularly how the curve of the eyebrow exactly follows Downey's eyebrow causing the mask to cut arbitrarily through Shia's. 

How does that translate to a mask meaning ""Take from the original where I'm white and take from the generator where I'm black.""?

Equally why should there be any generator output in the edges outside the face, surely with an ideal mask that should be all from the original image?",certainly pretty sure fit purpose replacement face particularly curve eyebrow exactly eyebrow causing mask cut arbitrarily translate mask meaning take original white take generator equally generator output outside face surely ideal mask original image,issue,positive,positive,positive,positive,positive,positive
364747552,@dfaker hmm but man from here https://github.com/shaoanlu/faceswap-GAN/issues/50 told that is awesome mask,man told awesome mask,issue,positive,positive,positive,positive,positive,positive
364746839,"The ""dots"" look like classic deconvolution artifacts, we might consider nudging the final two sizes and strides or sticking a tf.images.resize_images and a conv2d layer just before the final output layer.

The mask layer generally looks a little like edge detection, given that these faces have a good deal more high frequency features than any other sample set I've seen the GAN used on, I'm not sure this isn't the expected behaviour.",look like classic might consider final two size sticking layer final output layer mask layer generally little like edge detection given good deal high frequency sample set seen gan used sure behaviour,issue,positive,positive,positive,positive,positive,positive
364746790,so why you change num of epochs if you cant understand behaviour after loop end ?,change cant understand behaviour loop end,issue,negative,neutral,neutral,neutral,neutral,neutral
364746736,"I didn't alter anything after the loop. This is the original version:

https://github.com/deepfakes/faceswap/blob/20753a64b76a156aea17724348269d60dd525f87/scripts/train.py#L136-L151


As you can see that part is unchanged. The save behavior is same as in original. I want to change that too, but it should have its own PR.",alter anything loop original version see part unchanged save behavior original want change,issue,positive,positive,positive,positive,positive,positive
364736045,"Thanks, I am New for python, but I hope to know if the issue is related to ""str"", and what does it mean, any other found the same issue. The link you share is application is it?",thanks new python hope know issue related mean found issue link share application,issue,positive,positive,neutral,neutral,positive,positive
364729499,I'll have a review once I'm back at my pc. (havent forgotten about ya) ,review back havent forgotten ya,issue,negative,neutral,neutral,neutral,neutral,neutral
364728526,"Your right, in Task Manager GPU load is showing below 20% but Dedicate GPU memory usage is full.

For sure CNN work only with CPU is so slow just for a few images...",right task manager load showing dedicate memory usage full sure work slow,issue,negative,positive,positive,positive,positive,positive
364727954,"Don't understand what's wrong.

I manually install `dlib` to be sure with no error and with CUDA enable.
 Tried to downgrade to `cuDNN 5.1` (from `cuDNN 6`) and reinstall `dlib` with no luck.

All is installed with no errors but CNN not work with GPU and not sure if this affect the Train too.

**Notice so many warnings when install `dlib`:**

> d:\dlib-master\dlib\config.h(22): warning C4005: 'DLIB_JPEG_SUPPORT': macro redefinition (compiling source file D:\dlib-master\tools\python\src\numpy_returns.cpp) [D:\dli
> b-master\build\temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> d:\dlib-master\dlib\config.h(23): warning C4005: 'DLIB_PNG_SUPPORT': macro redefinition (compiling source file D:\dlib-master\tools\python\src\numpy_returns.cpp) [D:\dlib
> -master\build\temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> d:\dlib-master\dlib\config.h(28): warning C4005: 'DLIB_USE_CUDA': macro redefinition (compiling source file D:\dlib-master\tools\python\src\numpy_returns.cpp) [D:\dlib-ma
> ster\build\temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> d:\dlib-master\dlib\config.h(22): warning C4005: 'DLIB_JPEG_SUPPORT': macro redefinition (compiling source file D:\dlib-master\tools\python\src\gui.cpp) [D:\dlib-master\b
> uild\temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> d:\dlib-master\dlib\config.h(23): warning C4005: 'DLIB_PNG_SUPPORT': macro redefinition (compiling source file D:\dlib-master\tools\python\src\gui.cpp) [D:\dlib-master\bu
> ild\temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> d:\dlib-master\dlib\config.h(28): warning C4005: 'DLIB_USE_CUDA': macro redefinition (compiling source file D:\dlib-master\tools\python\src\gui.cpp) [D:\dlib-master\build
> \temp.win-amd64-3.6\Release\dlib_python.vcxproj]
> 
> 416 Warning(s)
> 0 Error(s)
> 
> Time Elapsed 00:10:07.06
> creating build\bdist.win-amd64
> creating build\bdist.win-amd64\egg
> copying build\lib.win-amd64-3.6\dlib.cp36-win_amd64.pyd -> build\bdist.win-amd64\egg
> creating stub loader for dlib.cp36-win_amd64.pyd
> byte-compiling build\bdist.win-amd64\egg\dlib.py to dlib.cpython-36.pyc
> creating build\bdist.win-amd64\egg\EGG-INFO
> copying dlib.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
> copying dlib.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
> copying dlib.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
> copying dlib.egg-info\not-zip-safe -> build\bdist.win-amd64\egg\EGG-INFO
> copying dlib.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
> writing build\bdist.win-amd64\egg\EGG-INFO\native_libs.txt
> creating dist
> creating 'dist\dlib-19.9.99-py3.6-win-amd64.egg' and adding 'build\bdist.win-amd64\egg' to it
> removing 'build\bdist.win-amd64\egg' (and everything under it)
> Processing dlib-19.9.99-py3.6-win-amd64.egg
> creating d:\lib\site-packages\dlib-19.9.99-py3.6-win-amd64.egg
> Extracting dlib-19.9.99-py3.6-win-amd64.egg to d:\lib\site-packages
> Adding dlib 19.9.99 to easy-install.pth file
> 
> Installed d:\lib\site-packages\dlib-19.9.99-py3.6-win-amd64.egg
> Processing dependencies for dlib==19.9.99
> Finished processing dependencies for dlib==19.9.99


**Chequed in tensorflow if GPU is enable:**
` sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))`

> 2018-02-11 03:27:20.363564: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
> 2018-02-11 03:27:20.747300: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
> name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7845
> pciBusID: 0000:02:00.0
> totalMemory: 6.00GiB freeMemory: 4.97GiB
> 2018-02-11 03:27:20.747460: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1)
> Device mapping:
> /job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1
> 2018-02-11 03:27:20.933639: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\direct_session.cc:299] Device mapping:
> /job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1

**Test dlib:**
`cmake -G ""Visual Studio 14 2015 Win64""`

> -- Selecting Windows SDK version  to target Windows 10.0.16299.
> -- The C compiler identification is MSVC 19.0.24215.1
> -- The CXX compiler identification is MSVC 19.0.24215.1
> -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe
> -- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works
> -- Detecting C compiler ABI info
> -- Detecting C compiler ABI info - done
> -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe
> -- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe -- works
> -- Detecting CXX compiler ABI info
> -- Detecting CXX compiler ABI info - done
> -- Detecting CXX compile features
> -- Detecting CXX compile features - done
> -- Looking for sys/types.h
> -- Looking for sys/types.h - found
> -- Looking for stdint.h
> -- Looking for stdint.h - found
> -- Looking for stddef.h
> -- Looking for stddef.h - found
> -- Check size of void*
> -- Check size of void* - done
> -- Enabling SSE2 instructions
> -- Searching for BLAS and LAPACK
> -- Searching for BLAS and LAPACK
> -- Looking for pthread.h
> -- Looking for pthread.h - not found
> -- Found Threads: TRUE
> -- A library with BLAS API not found. Please specify library location.
> -- LAPACK requires BLAS
> -- Found CUDA: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0 (found suitable version ""8.0"", minimum required is ""7.5"")
> -- Looking for cuDNN install...
> -- Found cuDNN: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0/lib/x64/cudnn.lib
> -- Building a CUDA test project to see if your compiler is compatible with CUDA...
> -- Checking if you have the right version of cuDNN installed.
> -- Enabling CUDA support for dlib.  DLIB WILL USE CUDA
> -- C++11 activated.
> -- Configuring done
> -- Generating done
> -- Build files have been written to: D:/fy/fs/faceswap_env/dlib-master

",understand wrong manually install sure error enable tried downgrade reinstall luck work sure affect train notice many install warning macro redefinition source file warning macro redefinition source file warning macro redefinition source file warning macro redefinition source file warning macro redefinition source file warning macro redefinition source file warning error time stub loader writing removing everything file finished enable sess binary use found device name major minor device device name bus id compute capability device device name bus id compute capability device device name bus id compute capability test visual studio win version target compiler identification compiler identification check working compiler visual studio check working compiler visual studio work compiler compiler done check working compiler visual studio check working compiler visual studio work compiler compiler done compile compile done looking looking found looking looking found looking looking found check size void check size void done searching blas searching blas looking looking found found true library blas found please specify library location blas found found suitable version minimum looking install found building test project see compiler compatible right version support use done generating done build written,issue,negative,positive,positive,positive,positive,positive
364726566,"@IUsedToBeAPygmy can you post comparison benchmarks 
**Cuda 8, CuDNN 6 and TensorFlow 1.4** 
vs
**Cuda 9, CuDNN 7 and TensorFlow 1.5**
?
for example epochs per minute",post comparison example per minute,issue,negative,neutral,neutral,neutral,neutral,neutral
364726565,"for me even though GPU is showing 10% on task manager, GPU compute_0 is 100%.
looks like cpu is mainly used for preview windows. once the preview windows off , cpu is using around 30% load.",even though showing task manager like mainly used preview preview around load,issue,negative,positive,positive,positive,positive,positive
364723088,"Yeah, i never installed the VS 2017, always was the 2015 and i think i have it with all the updates.",yeah never always think,issue,negative,neutral,neutral,neutral,neutral,neutral
364722905,It's real mess. There's no one answer because it's a cuda issue and so varies based on your exact cuda version. Uninstalling VS 2017 and having VS 2015 updated with all the latest patches seems to work the most frequently.,real mess one answer issue based exact version latest work frequently,issue,negative,positive,positive,positive,positive,positive
364722595,"Maybe double check dlib console output during setup.py to be certain it went successfully. Even with DLIB_USE_CUDA it can still fail to use cuda and you'll end up with a plain CPU build. There's lots of issues with cuda requiring very specific versions of visual studio to be installed, so it fails to include support frequently.",maybe double check console output certain went successfully even still fail use end plain build lot specific visual studio include support frequently,issue,positive,positive,neutral,neutral,positive,positive
364722443,"@rifterbater My DLIB installation was: 

`python setup.py install --yes USE_AVX_INSTRUCTIONS --yes DLIB_USE_CUDA`",installation python install yes yes,issue,positive,neutral,neutral,neutral,neutral,neutral
364722381,"Did you rebuild dlib with GPU support? If you use ""-D cnn"" and haven't done that it uses a CPU version of dlib, which is crazy slow during the face detection step.",rebuild support use done version crazy slow face detection step,issue,negative,negative,negative,negative,negative,negative
364722193,"This is happening to me too https://github.com/deepfakes/faceswap/issues/175

I reinstall all from zero but not success.",happening reinstall zero success,issue,positive,positive,positive,positive,positive,positive
364716759,"I change the value back to 220. In preview I can see entire face being changed. However after convert, only the middle chunk of faces were changed (eyebrow to chin)(I used lowmem trainer and masked converter). Is that also related to some size change? Can I alter the mask size?",change value back preview see entire face however convert middle chunk eyebrow chin used trainer masked converter also related size change alter mask size,issue,negative,neutral,neutral,neutral,neutral,neutral
364712667,"I've let the training run with the standard autoencoder model until a loss value of 0.02, which produced pretty good output samples – a bit blurry, but this is probably due to some bad/compressed input images from my source A folder. Then tried the same with the new GAN128 plugin, as well as the 64px GAN plugin and both output samples had some weird artifacts: mosaic-like patterns, looking like jpeg compression artifacts (applied filters/features?). Will try both plugins again with different input faces, but for this test the standard model produced better results. But i guess with the right input material the GAN plugins should produce sharper images with more details. Don't know how long you have to train the model to get rid of the articfacts though.",let training run standard model loss value produced pretty good output bit blurry probably due input source folder tried new gan well gan output weird looking like compression applied try different input test standard model produced better guess right input material gan produce sharper know long train model get rid though,issue,positive,positive,positive,positive,positive,positive
364707295,"No, I've only been training the model with the latest version. I think the problem is different from #168 and #159.",training model latest version think problem different,issue,negative,positive,positive,positive,positive,positive
364703657,"Could you maybe take image folder as an argument? We often use pictures from various sources so filenames are different. 

Another thing is that sometimes output image is too zoomed in.",could maybe take image folder argument often use various different another thing sometimes output image,issue,negative,neutral,neutral,neutral,neutral,neutral
364702886,"@gdunstone please review, I don't see any option to add/assign you as reviewer",please review see option reviewer,issue,negative,neutral,neutral,neutral,neutral,neutral
364702648,"It's a different algorithm, I'm not sure it produces better results by default, it needs more resources.

More info: https://github.com/shaoanlu/faceswap-GAN",different algorithm sure better default need,issue,positive,positive,positive,positive,positive,positive
364702614,"I think the idea is that it's running indefinitely (1000000 epochs is an absurdly high number) and only quits when the user presses return. I don't think the person who typed that really expected anyone to ever wait until the millionth epoch ;)

A ""while return not pressed"" loop would have been more clear. On the other hand, if your model hasn't produced good results after 1000000 epochs, it never will :)

",think idea running indefinitely absurdly high number quits user return think person really anyone ever wait millionth epoch return loop would clear hand model produced good never,issue,positive,positive,positive,positive,positive,positive
364701974,@Apollo122  - yeah it doesn't do much checking of paths or anything...incidentally - if you want to match all faces in the input you can just pass an empty directory as the reference.  ,yeah much anything incidentally want match input pas empty directory reference,issue,negative,positive,neutral,neutral,positive,positive
364681039,"edit: solved it. i had dlib from the pip. updated dlib from pip first then changed the dlib.cp36-win_amd64.pyd file with the one i compiled with cuda. 

gonna leave this here in case  someone has the same problem.

Didnt use ref file and got this error any ideas?

pip list gave me:
face-recognition (1.2.1)
face-recognition-models (0.3.0)

Traceback (most recent call last):
  File ""FaceGrab.py"", line 182, in <module>
    FG.process(input_path=TEST_VIDEO, output_directory=OUTPUT_DIR)
  File ""FaceGrab.py"", line 157, in process
    output_directory)
  File ""FaceGrab.py"", line 98, in __batch
    batch_size=self.batch_size)
  File ""C:\IntelPython3\lib\site-packages\face_recognition\api.py"", line 144, in batch_face_locations
    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)
  File ""C:\IntelPython3\lib\site-packages\face_recognition\api.py"", line 127, in _raw_face_locations_batched
    return cnn_face_detector(images, number_of_times_to_upsample, batch_size=batch_size)
Boost.Python.ArgumentError: Python argument types in
    cnn_face_detection_model_v1.__call__(cnn_face_detection_model_v1, list, int)
did not match C++ signature:
    __call__(class cnn_face_detection_model_v1 {lvalue}, class boost::python::list {lvalue} imgs, int upsample_num_times=0, int batch_size=128)
    __call__(class cnn_face_detection_model_v1 {lvalue}, class boost::python::api::object img, int upsample_num_times=0)",edit pip pip first file one gon na leave case someone problem didnt use ref file got error pip list gave recent call last file line module file line process file line file line file line return python argument list match signature class class boost class class boost,issue,negative,positive,neutral,neutral,positive,positive
364680086,"No fakeapps .bat file, is from the repo. I now checking if normal training or low memory training will having the same issue or not. ",file normal training low memory training issue,issue,negative,positive,neutral,neutral,positive,positive
364678887,What GAN really does? Improving quality?,gan really improving quality,issue,negative,positive,positive,positive,positive,positive
364674998,"@3xtr3m3d - Ah try it now...was just missing 

` face = cv2.resize(face, (256, 256))`

before

`cv2.imwrite(output_path, face)`

have updated it here too :)",ah try missing face face face,issue,negative,negative,negative,negative,negative,negative
364674685,yeah thats the one i'm using. it works perfectly. only problem im having is images are different size,yeah thats one work perfectly problem different size,issue,positive,positive,positive,positive,positive,positive
364673616,"Yea get the code from the gist, the bit posted here has a couple of bugs
https://gist.github.com/facepainter/adfaabe25831a7c9300bafd1b886e1c8",yea get code gist bit posted couple,issue,negative,neutral,neutral,neutral,neutral,neutral
364658320,"I don't know much about GAN, but if I'm not wrong it uses two models, a generator and a discriminator.

Loss_GX should be the value for the generator and Loss_DX for the discriminator.

I don't know what values should be considered acceptable as the discriminator values are constantly jumping, and during my tests the generator values are stuck at around 0.17 after ~15 hours.",know much gan wrong two generator discriminator value generator discriminator know considered acceptable discriminator constantly generator stuck around,issue,negative,negative,neutral,neutral,negative,negative
364658180,so with this commit I finally able to launch convert without memory error on my 6GB card.,commit finally able launch convert without memory error card,issue,positive,positive,positive,positive,positive,positive
364657998,"u launch it from .bat file ?
then add pause
and copy error message.
",launch file add pause copy error message,issue,negative,neutral,neutral,neutral,neutral,neutral
364656982,"Is there an established threshold for loss numbers with the GAN plugin yet? I'm getting two sets of numbers now instead of just one. usually people say stop around 0.09, should  I ignore the Loss_GB value or what?",established threshold loss gan yet getting two instead one usually people say stop around ignore value,issue,negative,negative,negative,negative,negative,negative
364654160,"Neverming. I had to add bs=32. Din't hit me that the loss of preview was related to the out of memory error.

so just to clarify, add -t GAN when training and then -t GAN -c GAN when applying trained model to a directory of frames of say, a video to replace the faces?",add di hit loss preview related memory error clarify add gan training gan gan trained model directory say video replace,issue,negative,neutral,neutral,neutral,neutral,neutral
364648785,How to post extract full error message ? It only show the error message as title only ?,post extract full error message show error message title,issue,negative,positive,positive,positive,positive,positive
364640156,post full error message with call stack,post full error message call stack,issue,negative,positive,positive,positive,positive,positive
364640105,"Sorry , is faceswap.py, the auto correction in iphone suck . Do you know the error message ?",sorry auto correction suck know error message,issue,negative,negative,negative,negative,negative,negative
364638914,"No new dependencies and the preview works for me.

What output log are you getting?",new preview work output log getting,issue,negative,positive,positive,positive,positive,positive
364638160,Not sure is GAN training not include the preview window ?,sure gan training include preview window,issue,negative,positive,positive,positive,positive,positive
364637642,@LordVulkan does GAN require any new dependencies? And does this eliminate the option of live preview? (-p no longer works),gan require new eliminate option live preview longer work,issue,negative,positive,positive,positive,positive,positive
364635837,"For the training process just add:
`-t GAN`

For converting add:
`-t GAN -c GAN`

",training process add gan converting add gan gan,issue,negative,neutral,neutral,neutral,neutral,neutral
364631468,"@gdunstone also I need to copy **alignments.json** from **extract output dir** to **convert input dir**

my windows batch
`for /r ""data_dst\aligned\"" %%x in (alignments.*) do move ""%%x"" ""data_dst\""`",also need copy extract output convert input batch move,issue,negative,neutral,neutral,neutral,neutral,neutral
364630578,"Thanks for the input. I'll fix that stuff when I get home.

On 10 Feb. 2018 5:33 pm, ""iperov"" <notifications@github.com> wrote:

> so I fixed with
>
>     def get_faces_alignments(self, filename, image):
>         faces_count = 0
>         faces = self.faces_detected[filename]
>         for rawface in faces:
>             face = DetectedFace(**rawface)
>             face.image = image[face.y : face.y + face.h, face.x : face.x + face.w]
>
> and
>
>     def prepare_images(self):
>         self.read_alignments()
>         for filename in tqdm(self.read_directory()):
>             image = cv2.imread(filename)
>
>             if self.have_face(filename):
>                 faces = self.get_faces_alignments(filename, image )
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/155#issuecomment-364630400>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeHhcEmIjia8_0AQhLjt8oSLQEqJxks5tTTgdgaJpZM4R-le3>
> .
>
",thanks input fix stuff get home wrote fixed self image face image self image image thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
364612551,"@petergerten I've edited the [Model_Original.py ]( faceswap/plugins/Model_Original.py )(Autoencoder, not Clorrs GAN plugin) to allow the generation of 128x128px faces here: #157. Had to change the [random_warp](https://github.com/deepfakes/faceswap/blob/20753a64b76a156aea17724348269d60dd525f87/lib/training_data.py#L64) function and the [TrainingDataGenerator](https://github.com/deepfakes/faceswap/blob/20753a64b76a156aea17724348269d60dd525f87/lib/training_data.py#L8) with some lines from Clorrs new [GAN128 plugin](https://github.com/Clorr/faceswap/commit/8a22415af7c908683d785e83117aea47a4068a7d) (he has created his [own fork](https://github.com/Clorr/faceswap/) to experiment with) and have trained the 128px model for around 100000 iterations. It seems to work 🎉! My loss values are at `loss_A: 0.0164708, loss_B: 0.0155299` now and the sample output is looking good! It wouldn't take much to edit the `Model_Original.py` to allow for 256x256px input images.

#### Some results of the 128x128px test (Info: i use a GTX 1080 Ti with 11GB):
With 64x64 input images and `ENCODER_DIM` set to 1024 (this variable is also important to keep in mind) i could use a batch size of 220 and one iteration took ~0.5s. After editing the second [Dense](https://github.com/deepfakes/faceswap/blob/20753a64b76a156aea17724348269d60dd525f87/plugins/Model_Original.py#L53) Layer the tensor size changed from 16384 to 65536 (4 * 4 * 1024 -> 8 * 8* 1024). And this 4x data increase of course needs to fit in the GPU memory. If i understand it correctly you have to multiply this layers tensor size with the batch number to get a rough understanding of how much GPU memory it consumes (to be precise you have to do it for all [changed layers](https://github.com/deepfakes/faceswap/blob/20753a64b76a156aea17724348269d60dd525f87/plugins/Model_Original.py#L45-L65) and that quickly adds up to ... _a lot_ 😁). So a `batch size` of 220 would definitely not work with the new memory requirements 😅. I had to reduce it to 20 to not get an out of memory error. First i've tried to also increase the `ENCODER_DIM` from `1024` to `2048`, but that produced an OOM error. I could have lowered the batch size but instead chose to set the encoder dim to `1536`. And now the 20 batches barely fit in the memory. One iteration now takes ~0.6 s (reminder: 220 64x64 batches took 0.5s). Disclaimer: I'm no expert on neural net architecture, so my reasoning behind doubling the values of the last Dense layer was just that it needs to be 2x that of the 64 model. _There is certainly a more efficient way to change the layers_, but i'm relying on the knowledge of others to explain how to find a better solution. Maybe someone with more experience (which is probably a lot of people here 😀) knows if this increase was even necessary. Increasing the `ENCODER_DIM` (and leaving the 2nd Dense layer as it is) probably yields better results. Hope someone can look at that and explain it (in simple terms for me, please :-) ).

**TLDR:** I've changed the original autoencoder model to allow 128x128px input images, but my edit of certain layer dimensions is probably not the best solution as it needs tons of GPU memory and is decreasing the possible batch sizes as well as increasing training time. Which is to be expected if the input images are larger, but i'm certain it's possible to reduce the required memory with a better model (by someone who knows what they are actually doing, which is not me).

### Looking at the 256x256px option: 
I will try to edit the model again and look at how much memory this needs. But i see one (small) problem with the 256 input images in general: All faces get rotated, transformed, cropped according to the `coverage` variable (which was 160 in the 64px, and now 220 in Clorrs 128px plugin) and then scaled to the defined internal size (64 or 128 e.g.). So if i take 256x256px image as input, do the transform and warping, then trim it to 220x220 and scale it **down** to 128x128 for the neural net the image would be sharp. But if you want 256x256px internal images you have to scale the 220x220 in the last step **up** again, which gets you a slightly interpolated and blurred image. Don't think this is a big problem, but if you want the best internal image quality you would need to extract images bigger than 256x256 to have to some leeway to crop it. Or maybe i'm just overthinking this.


Then there is the bigger problem of memory consumption, you could only use small batch sizes on a card with low memory and it would take significantly longer to get to acceptable loss values. I will stop the speculation now – this message is already too long. Will modify the model for 256x256 images now and test how long the training takes.",gan allow generation change function new gan fork experiment trained model around work loss sample output looking good would take much edit allow input test use ti input set variable also important keep mind could use batch size one iteration took second dense layer tensor size data increase course need fit memory understand correctly multiply tensor size batch number get rough understanding much memory precise quickly batch size would definitely work new memory reduce get memory error first tried also increase produced error could batch size instead chose set dim barely fit memory one iteration reminder took disclaimer expert neural net architecture reasoning behind doubling last dense layer need model certainly efficient way change knowledge explain find better solution maybe someone experience probably lot people increase even necessary increasing leaving dense layer probably better hope someone look explain simple please original model allow input edit certain layer probably best solution need memory decreasing possible batch size well increasing training time input certain possible reduce memory better model someone actually looking option try edit model look much memory need see one small problem input general get rotated according coverage variable scaled defined internal size take image input transform warping trim scale neural net image would sharp want internal scale last step slightly blurred image think big problem want best internal image quality would need extract bigger leeway crop maybe bigger problem memory consumption could use small batch size card low memory would take significantly longer get acceptable loss stop speculation message already long modify model test long training,issue,positive,positive,positive,positive,positive,positive
364592027,"Basically what @Tvde1  said. In addition, you could try renting some cloud services for the job or, and I think this is a better solution, obtain existing model from someone. However I'm not sure how much data would fit if it wasn't the exact same person.",basically said addition could try cloud job think better solution obtain model someone however sure much data would fit exact person,issue,positive,positive,positive,positive,positive,positive
364578559,"> facepainter commented 7 minutes ago •  edited 
> @LordVulkan - Agh sorry didn't save - will try again though and post back...if you say it can be done that is good :) - kept getting errors when building the CUDA test app. From what I'd read people were saying it was not compatible so I gave up....Just to be 100% we are talking about building dlib with CUDA support on Win64 using CUDA 9.1 and cuDNN 7 for Visual Studio 2017? i.e.
> 
> cmake -G ""Visual Studio 15 Win64"" -T host=x64 -DUSE_AVX_INSTRUCTIONS=1 -DDLIB_USE_CUDA=1

I'm sorry but I'm on Linux. I just did.

`python setup.py bdist_wheel --yes USE_AVX_INSTRUCTIONS`

If I remember correctly, it automatically detects CUDA installation and I just had to tell cmake to use gcc-6 via CC and CXX variables.",ago sorry save try though post back say done good kept getting building test read people saying compatible gave talking building support win visual studio visual studio win sorry python yes remember correctly automatically installation tell use via,issue,positive,positive,positive,positive,positive,positive
364574937,"Have you by any chance gotten the latest version of the code and tried to continue training a previous model with that?

I found out the latest code uses a different ""face coverage"" factor (160) than previous versions (220) which invalidates previous training data...

I think this happened by accident; if you have a backup of your previous training data you'll probably be able to continue once the face-coverage value is set back to the previous value of 220.",chance gotten latest version code tried continue training previous model found latest code different face coverage factor previous previous training data think accident backup previous training data probably able continue value set back previous value,issue,negative,positive,neutral,neutral,positive,positive
364574663,"@LordVulkan  - Agh sorry didn't save - will try again though and post back...if you say it can be done that is good :) - kept getting errors when building the CUDA test app. From what I'd read people were saying it was not compatible so I gave up....Just to be 100% we are talking about building dlib with CUDA support on Win64 using CUDA 9.1 and cuDNN 7 for Visual Studio 2017? i.e. 

`cmake -G ""Visual Studio 15 Win64"" -T host=x64 -DUSE_AVX_INSTRUCTIONS=1 -DDLIB_USE_CUDA=1 `",sorry save try though post back say done good kept getting building test read people saying compatible gave talking building support win visual studio visual studio win,issue,positive,positive,positive,positive,positive,positive
364548468,"@IUsedToBeAPygmy  Yep, it's in my main repo now, it just uses the MSE of the 2d face landmarks, nothing fancy but surprisingly effective, another reason to have the alignments saved rather than calculated on demand.

The warping in DF uses the same distance measure to warp an input face to have the proportions of the most similar opposing face.",yep main face nothing fancy surprisingly effective another reason saved rather calculated demand warping distance measure warp input face similar opposing face,issue,negative,positive,positive,positive,positive,positive
364547275,"No, the project just wants to get an restored version of A and an restored version of B.

I does the restoration of the input by using all the hints it can including looking for warped expressions and warped lighting cues, the face swapping is a transfer task that happens by ""accident"" when rather than feeding a distorted version of A into A's autoencoder we feed in a B, the network interprets the image of B as a distorted A and attempts to ""fix"" it to look like A again.",project get version version restoration input looking warped warped lighting face swapping transfer task accident rather feeding distorted version feed network image distorted fix look like,issue,negative,neutral,neutral,neutral,neutral,neutral
364531299,"Windows 7, python 3.5.4
```
TypeError: join() argument must be str or bytes, not 'WindowsPath'
```

fix with
```
str(self.input_dir)
str(self.output_dir)
```

also problem with convert
_--converter Adjust_
or
_--converter GAN_

it produce this error FLOOD every frame:

```
OpenCV Error: Assertion failed (ssize.width > 0 && ssize.height > 0) in cv::resi
ze, file C:\projects\opencv-python\opencv\modules\imgproc\src\imgwarp.cpp, line
3483
Failed to convert image: D:\FaceSwap\data_dst\out00057.png. Reason: C:\projects\
opencv-python\opencv\modules\imgproc\src\imgwarp.cpp:3483: error: (-215) ssize.w
idth > 0 && ssize.height > 0 in function cv::resize
```

so when I remove alignments.json it works ok
![explorer_2018-02-10_00-04-07](https://user-images.githubusercontent.com/8076202/36047650-261bc786-0df6-11e8-9cb4-e9ac533b1772.png)

alignments.json **convert** works **only** with _--converter Masked_
also you missed 
`face.image` field 
that required for ADJ and GAN

so I fixed it for myself with

```
    def get_faces_alignments(self, filename, image):
        faces_count = 0
        faces = self.faces_detected[filename]
        for rawface in faces:
            face = DetectedFace(**rawface)
            face.image = image[face.y : face.y + face.h, face.x : face.x + face.w]
```

and

```
    def prepare_images(self):
        self.read_alignments()
        for filename in tqdm(self.read_directory()):
            image = cv2.imread(filename)
            
            if self.have_face(filename):
                faces = self.get_faces_alignments(filename, image )
```",python join argument must fix also problem convert converter converter produce error flood every frame error assertion file line convert image reason error function remove work convert work converter also field gan fixed self image face image self image image,issue,negative,positive,neutral,neutral,positive,positive
364439403,"You'd probably want to try a:

    from tensorflow.python.client import device_lib
    count_gpu = len([d for d in device_lib.list_local_devices() if d.device_type=='GPU' ] )

To check that count_gpu > 1 and use that number as the second parameter for multi_gpu_model before attempting to replace the autoencoders with wrapped versions.",probably want try import check use number second parameter replace wrapped,issue,negative,neutral,neutral,neutral,neutral,neutral
364430407,"Seems like a relatively good attempt seeing as the face is melting through bars /s.

Realistically there's very strong side lighting at a glancing face angle which neither the face defector nor landmark detectors will have an easy time with, the whole set of images are very much edge cases for the modules that this project has the least control over.",like relatively good attempt seeing face melting realistically strong side lighting glancing face angle neither face defector landmark easy time whole set much edge project least control,issue,positive,positive,positive,positive,positive,positive
364429133,"> facepainter commented 18 minutes ago
> @dr-benway @shadowfolder - hmm yeah I can download/install and compile it fine...just not with CUDA support.

Can you paste the build log for dlib? I built it successfully against CUDA 9.1",ago yeah compile fine support paste build log built successfully,issue,positive,positive,positive,positive,positive,positive
364424997,@dr-benway @shadowfolder - hmm yeah I can download/install and compile it fine...just not with CUDA support.,yeah compile fine support,issue,positive,positive,positive,positive,positive,positive
364413071,"works great on > CUDA9 CuDNN7 TF 1.6.0rc0 Python 3.6.2  Win10 x64
training with GAN128 (increased kernel sizes to 4 in order for them to be divisible by the strides)",work great python win training gan kernel size order divisible,issue,positive,positive,positive,positive,positive,positive
364412660,"Not everyone runs Archlinux.

On 9 Feb. 2018 22:45, ""dr-benway"" <notifications@github.com> wrote:

> works great on > CUDA9 CuDNN7 TF 1.6.0rc0 Python 3.6.2 Win10 x64
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/161#issuecomment-364412421>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeMBumKWPOvfNOAx0_rfO-RE5cc5cks5tTC_TgaJpZM4R_Lm3>
> .
>
",everyone wrote work great python win reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
364408049,@facepainter i was unable install dlib via pip too. But i sucessfully installed dlib via github https://github.com/davisking/dlib via python setup.py install,unable install via pip via via python install,issue,negative,negative,negative,negative,negative,negative
364406700,"use python 3.5.4

I installed faceswap even on python embeddable lol, and rebuild dlib with cuda. But spent 1 day.",use python even python rebuild spent day,issue,negative,negative,neutral,neutral,negative,negative
364376279,"I've found the culprit.

In @Clorr 's changelist 
https://github.com/deepfakes/faceswap/commit/b3ae6130ed4714852211a6e8cb56de66450da83c#diff-cd6853ac48b3d61ae96f466bcc2c393eR41

The face coverage has changed from 220 to 160:

Old:
> **coverage = 220** # Coverage of the face for training. Larger value will cover more features. @shaoanlu recommends 220. Original is 160

to new:

> TrainingDataGenerator(self.random_transform_args, **160**)

This zooms in the faces much more in random_warp:

>-def random_warp(image):
> -    assert image.shape == (256, 256, 3)
> -    range_ = numpy.linspace(128 - **coverage**//2, 128 + **coverage**//2, 5)

I think this coverage value should be in the extractor anyway, not in the trainer... By putting it in the trainer we've first scaled the face from it's original size to 256x256, of which we then only use a smaller *part* in training.
By scaling it from the original size to make the ""coverage"" size fit 256x256 we possibly keep more detail.
",found culprit face coverage old coverage coverage face training value cover original new much image assert coverage coverage think coverage value extractor anyway trainer trainer first scaled face original size use smaller part training scaling original size make coverage size fit possibly keep detail,issue,positive,positive,positive,positive,positive,positive
364368084,"Just pip install tensorflow , working fine on my windows env with latest version.",pip install working fine latest version,issue,negative,positive,positive,positive,positive,positive
364359468,"I have been using CUDA 9.1, cuDNN 7 and a custom build from TensorFlow master branch without trouble.",custom build master branch without trouble,issue,negative,negative,negative,negative,negative,negative
364352473,"> I've just synced and looking at the preview window it looks like the faces are much more zoomed in now - to the point where some faces where the mouth is open actually have the mouth go almost go out of frame. Could it be that an extra zoom factor was accidentally added somehow?

I confirm that. Images in preview window looks more zoomed after pulling from master branch.
",looking preview window like much point mouth open actually mouth go almost go frame could extra zoom factor accidentally added somehow confirm preview window master branch,issue,negative,positive,neutral,neutral,positive,positive
364334812,"@IUsedToBeAPygmy 

I too have a set up with CUDA 9, CuDNN 7 and TF 1.5 using Python 3.6 on Win10 64bit and it works great...execpt I can't build dlib with CUDA support against version 9 :( 

Have you had joy with this? This is all that is keeping me on v8/6 and TF 1.4...",set python win bit work great ca build support version joy keeping,issue,positive,positive,positive,positive,positive,positive
364314648,maybe i found the reason.i copy the command and pasted .and the command include lots of enter key/,maybe found copy command pasted command include lot enter,issue,negative,neutral,neutral,neutral,neutral,neutral
364295463,"@Clorr @shaoanlu Thanks, did take a look at your modified `random_warp` function from #151. Copied it over, added the `scale` and `zoom` options to the `TrainingDataGenerator` and now it works perfectly. But i guess my model is not a very efficient nor elegant solution, at one point the last `Dense` layer of the `Encoder` produces a tensor of size `65536`, where in the 64x64 model it would be `16384`. Simply doubling everything of course slows down the training. And would probably cause problems for cards with little VRAM.

I've copied the structure of your Encoder and Decoder models over and 100 iterations take half the time. But since the GAN models function differently i guess i'm just poking around in the dark 😀. Will let the training run for a few hundred additional iterations and look if the output gets sharper.
If not, i will wait until your new plugin is finished and try to the understand the GAN structure better.

I would push a PR only if i'd feel confident enough that the code works optimal for others too. Since i  lack the experience to write efficient code (i'm just experimenting and playing around) i shouldn't let my frankenstein-code out in the wild 😅.

@Clorr Do you get better results in a shorter timeframe with the GAN approach? And is it a lot of work to modify the Convert script(s) for the GAN 128 plugin – do you only need to edit the `Convert_GAN.py`? I guess the masking is a little more time consuming ...",thanks take look function copied added scale zoom work perfectly guess model efficient elegant solution one point last dense layer tensor size model would simply doubling everything course slows training would probably cause little copied structure take half time since gan function differently guess poking around dark let training run hundred additional look output sharper wait new finished try understand gan structure better would push feel confident enough code work optimal since lack experience write efficient code around let wild get better shorter gan approach lot work modify convert script gan need edit guess little time consuming,issue,positive,positive,positive,positive,positive,positive
364284112,"I'd love to have the option to switch between 64, 128 and 256.
Even if my current gpu can't hack it, it's only a matter of time before the average you can.",love option switch even current ca hack matter time average,issue,positive,positive,positive,positive,positive,positive
364283611,I think we should use something like `tensorflow-gpu>=1.4.0`,think use something like,issue,negative,neutral,neutral,neutral,neutral,neutral
364279083,"I went with outputting SVG using Pygal as that has the least amount of dependencies and SVG is a universal format (can be opened with any webbrowser).

Ill create a pull for it soon.",went pygal least amount universal format ill create pull soon,issue,negative,negative,negative,negative,negative,negative
364257225,"Hmm, not willingly for sure... I should check where this can come from, however I won't be available until Monday ",willingly sure check come however wo available,issue,negative,positive,positive,positive,positive,positive
364255205,"I've just synced and looking at the preview window it looks like the faces are much more zoomed in now - to the point where some faces where the mouth is open actually have the mouth go almost go out of frame.

Could it be that an extra zoom factor was accidentally added somehow? That would explain why it still loads the old model weights but suddenly the losses are up again.",looking preview window like much point mouth open actually mouth go almost go frame could extra zoom factor accidentally added somehow would explain still old model suddenly,issue,negative,positive,neutral,neutral,positive,positive
364252986,"@gdunstone I've created the pull request, but I don't know how to add you as reviewer.
Be gentle, it's my first go at using Python *and* Github ;)",pull request know add reviewer gentle first go python,issue,negative,positive,positive,positive,positive,positive
364251686,"Random_transform_args where in lib/training_data.py line 10.

Can you tell me which was the previous version you were using? Because one thing that changed lately is the face coverage that changed from 160 to 220. So maybe that is a possibility. Can you try setting it to 160 again and see if it changes loss?",line tell previous version one thing lately face coverage maybe possibility try setting see loss,issue,negative,negative,negative,negative,negative,negative
364239396,"With regards to the earlier question: I stopped training, git pulled, and restarted training and the loss increased dramatically (from 0.016 to 0.042). No error was printed, and no paths were changed.

```
loaded model weights
Loading Trainer from Model_Original plugin...
Starting. Press ""Enter"" to stop training and save model
saved model weights loss_A: 0.04229, loss_B: 0.04221
```",question stopped training git training loss dramatically error printed loaded model loading trainer starting press enter stop training save model saved model,issue,negative,neutral,neutral,neutral,neutral,neutral
364238926,I don't see this randomness in the previous version https://github.com/deepfakes/faceswap/blob/b34d7d1a4956ae4f3eaf863f071e3f70e301a097/lib/ModelAE.py#L46,see randomness previous version,issue,negative,negative,negative,negative,negative,negative
364234386,"Random transform args were previously in training_data. They were not added. Also it wouldn't change much on output loss. AFAIK this part is to avoid having always the same image as source, it increases diversity.

Also note the values are very small, and aligned faces , even very similar ones, will have bigger differences ",random transform previously added also would change much output loss part avoid always image source diversity also note small even similar bigger,issue,negative,negative,negative,negative,negative,negative
364233897,"Especially since deepfakes relies on python 3.6. Older versions of popular distros, such as Ubuntu, don't have it in their default package repositories. And let's face it, most people still have old 2.7 on their machines as default python. 

Basically, it would be safer to assume that we start from scratch and that user doesn't have anything.",especially since python older popular default package let face people still old default python basically would assume start scratch user anything,issue,negative,positive,positive,positive,positive,positive
364230056,"I understand the purpose of random mirrors and flips, but what is the purpose of randomly transforming (rotating, shifting, zooming) the faces after I spent hours aligning them the exact same way with extract?",understand purpose random purpose randomly transforming rotating shifting spent exact way extract,issue,negative,negative,negative,negative,negative,negative
364229666,"I believe this could be the cause:
https://github.com/deepfakes/faceswap/commit/b3ae6130ed4714852211a6e8cb56de66450da83c#diff-298a939aa6a53af15be411af8f08ac8fR43

The training data has changed. Now it has random transforms",believe could cause training data random,issue,negative,negative,negative,negative,negative,negative
364225682,"To answer your questions:
- ENCODER_DIM is located inside plugins/Model_LowMem.py
- yes you can resume

But as @andykdy said, with less than 2GB it may be hard/impossible to make it run. In some attempt, you can try the patch in #140 ",answer inside yes resume said le may make run attempt try patch,issue,negative,neutral,neutral,neutral,neutral,neutral
364225401,"I personally agree with Pygmy
In a forum format, important information can be kept and seen by a lot of people.
In a chat useful bits of info are swept away by a slew of useless banter. 
I thought /r/deepfakes would have been an excellent place for technical discussion... But it was taken over by the internet",personally agree pygmy forum format important information kept seen lot people chat useful swept away slew useless banter thought would excellent place technical discussion taken,issue,positive,positive,positive,positive,positive,positive
364224883,"While my preference is usually going with the Python package that comes with my distro + virtualenv + pip, like you said, you can't always count on the right Python version being installed. I think Anaconda was suggested at some point, and that could solve a lot of those issues. Anaconda/Conda manages both the environment and packages, meaning that it can also manage different Python versions available on the same machine. I have little experience with this myself, but one would assume that Conda would allow for a bunch more automation in setting up the environment, by means of a bash or powershell script.",preference usually going python package come pip like said ca always count right python version think anaconda point could solve lot environment meaning also manage different python available machine little experience one would assume would allow bunch setting environment bash script,issue,positive,positive,neutral,neutral,positive,positive
364223913,"@subzerofun no problem for this issue. As long as you try contributing, it is always welcome. Even better you could have pushed a pull request so that people can directly checkout your code and try to debug.

As Shaoanlu stated, you can have a look at the GAN 128 plugin, or directly at faceswap-GAN repo",problem issue long try always welcome even better could pull request people directly code try stated look gan directly,issue,negative,positive,positive,positive,positive,positive
364222624,"Hmm, it shouldn't and also the loss cannot go back, unless the loss function is modified which is not the case. Assuming you have the same config / arguments, I only see 3 possible behaviors:
- Paths have changed / Filenames have changed: A message will indicate files have not been found
- Model has changed / Files are corrupted / An updated lib makes files unreadable: A message will indicate files can't be reloaded (In this case, be careful, the existing files will be overwritten by a new model save)
- Otherwise the model will be reloaded as is with it's current progress

Note that the message may not be much distinguishible from other outputs",also loss go back unless loss function case assuming see possible message indicate found model corrupted unreadable message indicate ca case careful new model save otherwise model current progress note message may much,issue,negative,positive,neutral,neutral,positive,positive
364218988,"Well if it comes down to making things simple for the end user, and if we assume almost complete ignorance on their end, there is nothing that beats the old school, downloadable binary installer. 

Everyone is familiar with it, and everyone is comfortable with it. Too much if you ask me but that would work in our favor.

Sadly such arrangement is not exactly great for more advanced users, and right now those are more likely to use this project.

Anyway, I think that creating a script in bash and powershell would be a fitting for most potential users.
Letting it handle dependencies, environment setup etc. while still providing user with easy way to review it. 

Additional checks could be implemented in python, but that already assumes python runs properly. ",well come making simple end user assume almost complete ignorance end nothing old school binary installer everyone familiar everyone comfortable much ask would work favor sadly arrangement exactly great advanced right likely use project anyway think script bash would fitting potential handle environment setup still providing user easy way review additional could python already python properly,issue,positive,positive,positive,positive,positive,positive
364216174,"I was just thinking of writing the graph to a jpg at the same time the preview is shown/saved.
Nice and easy.",thinking writing graph time preview nice easy,issue,positive,positive,positive,positive,positive,positive
364200638,"OK. I think I understand :)
What is the general way to handle obstructions? Should these samples be removed from the training sets? If so, can it generate frames where the face is obstructed in the final target?",think understand general way handle removed training generate face final target,issue,negative,positive,neutral,neutral,positive,positive
364199679,"So i checked the convert code and it seems that it doesn't use whats in the Data A only. We cant rely on json file because they may be false-positive entries in it.

I think if user passes alignment file, code should only care whats in Data A folder and read its features from json and skip the rest. Basically this part should never call detect face because they have been detected before.

` def prepare_images(self):
        self.read_alignments()
        for filename in tqdm(self.read_directory()):
            image = cv2.imread(filename)
            if self.have_face(filename):
                faces = self.get_faces_alignments(filename)
            else:
                faces = self.get_faces(image)
            yield filename, image, faces`",checked convert code use whats data cant rely file may think user alignment file code care whats data folder read skip rest basically part never call detect face self image else image yield image,issue,negative,neutral,neutral,neutral,neutral,neutral
364193972,"> Don't get me wrong, I'm all for user-friendliness but I can't see how someone could misinterpret that message.

Your assumption is that someone has prior experience with python and python dependency management. While you and I know what it means, I'm pretty sure that's not representative of the users we would like to reach. I would like to get to a point where the end-user doesn't have to worry about installing Python, or managing dependencies at all.

Perhaps we want to manage the dependencies for the end-user, perhaps we want to ship the tool as a precompiled package, perhaps we want to only nudge/guide the user in the right direction; tell them how to manage the dependencies. While this was just one initial idea back in December, there are many other ways of approaching this. None of these issues are set in stone, feel free to contribute your opinion on it.",get wrong ca see someone could misinterpret message assumption someone prior experience python python dependency management know pretty sure representative would like reach would like get point worry python perhaps want manage perhaps want ship tool package perhaps want user right direction tell manage one initial idea back many way approaching none set stone feel free contribute opinion,issue,positive,positive,positive,positive,positive,positive
364193144,"It's normal. Masks will be learnt  once the L1 reconstruction loss is low enough. i.e., generated faces before masking should be good enough so that masking make sense.",normal learnt reconstruction loss low enough good enough make sense,issue,negative,positive,positive,positive,positive,positive
364193119,"Both seem simple enough. The epochs are already limited in the script. It would only be necessary to change constant to a variable. 

As for the graph, that would require a graphics output, possibly in separate window. Again, not exactly hard by itself. But since there is still no proper GUI we should be careful not to reinvent the wheel and make features that will be quickly obsolete.

Of course there are ways around that issue. For example text output to a csv file. That can be later used for creation of graph. Another option might be bare bones graphics in form of a bitmap.

But the real question is if the graph should be real time or made after the run of program. ",seem simple enough already limited script would necessary change constant variable graph would require graphic output possibly separate window exactly hard since still proper careful reinvent wheel make quickly obsolete course way around issue example text output file later used creation graph another option might bare graphic form real question graph real time made run program,issue,negative,positive,neutral,neutral,positive,positive
364188717,"Actually, the LowMem model is just the Original Model with the ENCODER_DIM set to 512 instead of 1024.
I think you can try going down all the way to 256... But at that point I would rather invest time on cloud computing instead.


",actually model original model set instead think try going way point would rather invest time cloud instead,issue,negative,positive,positive,positive,positive,positive
364181796,"I think that this needs some explanation. The python already tells you if you try to import nonexistent module, and in a pretty clear way.
`ModuleNotFoundError: No module named
` 

Don't get me wrong, I'm all for user-friendliness but I can't see how someone could misinterpret that message. 

Of course it is trivial to check all the dependencies before, in the  `faceswap.py` or even in specialized bash/powershell script, but it feels kind of superfluous.

Could you explain how do you imagine the it should behave? ",think need explanation python already try import nonexistent module pretty clear way module get wrong ca see someone could misinterpret message course trivial check even specialized script kind superfluous could explain imagine behave,issue,positive,positive,positive,positive,positive,positive
364175074,"How about taking existing code from somewhere that extracts all frames from a video, running the face swap over those and then taking the output and combine it to a video?",taking code somewhere video running face swap taking output combine video,issue,negative,neutral,neutral,neutral,neutral,neutral
364159958,"Doesn't really matter where its written but original code writes it to input folder.

I'm willing to test this, so I'll get the file from extract.py and how should I use it for swap and merge? Should I write any parameters, will it only convert the files in A dataset?",really matter written original code input folder willing test get file use swap merge write convert,issue,negative,positive,positive,positive,positive,positive
364155523,I think having a Discord guild would be beneficial for people looking for support.,think discord guild would beneficial people looking support,issue,negative,neutral,neutral,neutral,neutral,neutral
364155206,Lots of training data and lots of hours of training (weeks),lot training data lot training,issue,negative,neutral,neutral,neutral,neutral,neutral
364149948,That's great. It would be cool to have it configurable. So 256px would be possible as well. I guess that is largely a constraint on GPU memory and training time?,great would cool would possible well guess largely constraint memory training time,issue,positive,positive,positive,positive,positive,positive
364147537,I'm going to hook you up with the code soon so you can make your own graphs :),going hook code soon make,issue,negative,neutral,neutral,neutral,neutral,neutral
364144486,IMO github should be/stay the common way to do techtalk. /r/deepfake%%% is mostly frequented by end users not interested in tech but rather hard facts. If you know what I mean. Also not a big loss. Just my 5 cents.,common way mostly end interested tech rather hard know mean also big loss,issue,negative,negative,neutral,neutral,negative,negative
364139057,"Thanks.

For those interested, in Linux install ImageMagick and then:

`for file in *.png *.jpg *.jpeg; do convert $file -resize 1000\>x1000\> $file; done`

That will downscale all images if either their height or width is bigger than 1000 while keeping their aspect ratio.",thanks interested install file convert file file done either height width bigger keeping aspect ratio,issue,positive,positive,positive,positive,positive,positive
364134601,"I'd prefer not to use a chat environment, I'd rather use a forum environment where the discussion is permanent allowing people to join the discussion on their own time.",prefer use chat environment rather use forum environment discussion permanent people join discussion time,issue,negative,neutral,neutral,neutral,neutral,neutral
364132526,"You can do this but keep in mind you will have the same problem on the convert command (unless we do save alignments, see #135 )",keep mind problem convert command unless save see,issue,negative,neutral,neutral,neutral,neutral,neutral
364131633,"Use ImageResizer. Select all images, right click -> Resize pictures.
Then select Custom : Scale to 900x900 pixels.

It'll make sure the max(width, height) is 900 pixels (keeping the aspect ratio)

http://www.bricelam.net/ImageResizer/",use select right click resize select custom scale make sure width height keeping aspect ratio,issue,negative,positive,positive,positive,positive,positive
364129332,I'm trying to find the max size I can safely use and resize all images bigger than that automatically.,trying find size safely use resize bigger automatically,issue,negative,positive,positive,positive,positive,positive
364129096,just crop the face and resize to 512-ish. The final face gets scaled to 256x256 anyway.,crop face resize final face scaled anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
364127531,"Basically, you could just change image_shape, but there will be quite a lot of caveats and it is not guaranteed that your model performs well on another size.",basically could change quite lot model well another size,issue,negative,neutral,neutral,neutral,neutral,neutral
364125634,I put a patch that seemed to help some others in #140 try and let us know if it works,put patch help try let u know work,issue,negative,neutral,neutral,neutral,neutral,neutral
364112375,"The problem does not come from `face_recognition`, which uses dlib methods. The [dlib's author also has no other advice than reducing image size](https://github.com/davisking/dlib/issues/790)",problem come author also advice reducing image size,issue,negative,neutral,neutral,neutral,neutral,neutral
364106994,"1080x1262

I have tried to remove it and the same happens with other images of similar size.

Dammit, I suppose it is a problem of face_recognition, but 4GB should be enough for those images.",tried remove similar size suppose problem enough,issue,negative,neutral,neutral,neutral,neutral,neutral
364100268,"> ZeroCool22 commented 11 hours ago •  edited 
> @modelsex Can you help me to install this REPO via TEAMVIEWER?
> I'm not being lazy, really tried (#134) and it end in a totally disaster, after that nothing related with Python was working, i must uninstall/reinstall everything to get the original code working again, (with original code i mean the first one posted on the DeepFakes READDIT) even the FAKEAPP wasn't working.
> 
> So if could give me a hand would be nice.
> 
> PC SPECS: Windows 10, 7700k, 32gb RAM, SMi 1080TI, SSD.

Try with Linux, Windows gave me a lot of problems.",ago help install via lazy really tried end totally disaster nothing related python working must everything get original code working original code mean first one posted even working could give hand would nice spec ram ti try gave lot,issue,positive,positive,positive,positive,positive,positive
364093199,"Im surprised at some of those numbers (like bson wtf), I suppose json is almost a straight repr for most common python types.",like suppose almost straight common python,issue,negative,negative,neutral,neutral,negative,negative
364086018,"It is because convert loads cnn **+** model, and for some reason they take both much memory. I have added a patch in #140 that tells tensorflow to allocate memory on-demand and not all at once. I don't guarantee it works, but if you can try and give feedback it would be nice....",convert model reason take much memory added patch allocate memory guarantee work try give feedback would nice,issue,positive,positive,positive,positive,positive,positive
364085064,"cnn mode work perfect on Extract, but I get follow problem when use cnn to convert:

Command example: python faceswap.py convert -i D:/project4/data_A/ -o D:/face/final/ -m D:/face/project4/models/ -D cnn 

My Env. CUDA-8.0 | cudnn-8.0 | dlib-19.9

**Log output**
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.62GiB
2018-02-08 19:24:41.501735: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
loaded model weights
Loading Convert from Convert_Masked plugin...
  0%|                                                                                          | 0/800 [00:00<?, ?it/s]Failed to convert image: D:\project4\data_A\kar0001.png. **Reason: Error while calling cudaMalloc(&data, n) in file D:\dlib-master\dlib\dnn\cuda_data_ptr.cpp:28. code: 2, reason: out of memory**
  0%|▏                                                                                 | 2/800 [00:00<04:24,  3.02it/s]Failed to convert image: D:\project4\data_A\kar0002.png. **Reason: Error while calling cudaGetLastError() in file D:\dlib-master\dlib\dnn\gpu_data.cpp:91. code: 2, reason: out of memory**
Failed to convert image: D:\project4\data_A\kar0003.png. Reason: Error while calling cudaMalloc(&data, n) in file D:\dlib-master\dlib\dnn\cuda_data_ptr.cpp:28. code: 2, reason: out of memory
  0%|▍                                                                                 | 4/800 [00:00<02:34,  5.16it/s]Failed to convert image: D:\project4\data_A\kar0004.png. Reason: Error while calling cudaGetLastError() in file D:\dlib-master\dlib\dnn\gpu_data.cpp:91. code: 2, reason: out of memory
......",mode work perfect extract get follow problem use convert command example python convert log output name major minor device device name bus id compute capability loaded model loading convert convert image reason error calling data file code reason memory convert image reason error calling file code reason memory convert image reason error calling data file code reason memory convert image reason error calling file code reason memory,issue,negative,positive,positive,positive,positive,positive
364067784,I just mean transforming [this version of @shaoanlu script](https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2_sz128_train.ipynb) to a plugin. It has 128px large applied face,mean transforming version script large applied face,issue,negative,negative,neutral,neutral,negative,negative
364065892,"What you can do is add it to a source file, and make a PR. So people with multi GPU will be able to try and give you feedback. I did that for #140 . Maybe the feedback will be slow as not everyone is checking pull requests, but at least it will be more practical to test and iterate over it",add source file make people able try give feedback maybe feedback slow everyone pull least practical test iterate,issue,negative,negative,neutral,neutral,negative,negative
364048903,"I think yaml might be better due to being able to easily concat files.

On 8 Feb. 2018 6:52 am, ""dfaker"" <notifications@github.com> wrote:

> You'd read the json once at initialisation the processing time for which
> is dwarfed by even the most trivial image operations you'd do with it's
> contents.
>
> The ability to immediately slice and dice human-readable text (for manual
> insertion of new batches or externally augmented training samples) isn't
> worth the time saved.
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/135#issuecomment-363890006>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeNNM9bh45rzhPKhmnnsU3T-dQTPyks5tSf8agaJpZM4R8ptp>
> .
>
",think might better due able easily wrote read time even trivial image content ability immediately slice dice text manual insertion new externally augmented training worth time saved assigned reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
364038705,"@IUsedToBeAPygmy regarding the topic of this issue - what about opening a [Gitter](https://gitter.im/) room or a [Slack](https://slack.com/get-started#create) workspace? Even IRC/Discord could work, honestly :)",regarding topic issue opening room slack even could work honestly,issue,negative,positive,positive,positive,positive,positive
364028395,"I'd already forked and implemented my changes, but I figured I'd sync / merge to the latest master version first before creating a pull request?
Once I've figured this out I'll create the pull request and add you as a reviewer.",already forked figured sync merge latest master version first pull request figured create pull request add reviewer,issue,negative,positive,positive,positive,positive,positive
364013982,"You won't be able to copy it verbatim, but the general principle (installing all the various dependencies, compiling, etc) should remain the same on MacOS. You could try using Brew instead of Aptitude to install packages.",wo able copy verbatim general principle various remain could try brew instead aptitude install,issue,negative,positive,positive,positive,positive,positive
363983255,"Oh, wow. No wonder haha. I kept seeing a few modules get deleted and I noticed every time they did, face swap would no longer work. Thanks so much, the tutorial is awesome! I'm guessing I can't do it on MacOS though?",oh wow wonder kept seeing get every time face swap would longer work thanks much tutorial awesome guessing ca though,issue,positive,positive,positive,positive,positive,positive
363983104,"Thanks your answer. If we input A and B. Did the project want to get the combination of A's identity and B's expression and the combination of B's identity and A's expression? If yes, the undistorted  face may be not A. ",thanks answer input project want get combination identity expression combination identity expression yes undistorted face may,issue,positive,positive,positive,positive,positive,positive
363975182,"@modelsex Can you help me to install this REPO via **[TEAMVIEWER](https://www.teamviewer.com)**?
I'm not being lazy, really tried (https://github.com/deepfakes/faceswap/issues/134) and it end in a totally disaster, after that nothing related with Python was working, i must uninstall/reinstall everything to get the original code working again, _(with original code i mean the first one posted on the DeepFakes READDIT)_ even the FAKEAPP wasn't working.

So if could give me a hand would be nice.

**PC SPECS:** Windows 10, 7700k, 32gb RAM, SMi 1080TI, SSD.",help install via lazy really tried end totally disaster nothing related python working must everything get original code working original code mean first one posted even working could give hand would nice spec ram ti,issue,positive,positive,positive,positive,positive,positive
363973549,"@IUsedToBeAPygmy 
/r/deepfaketechtalk is dead though. If you want to discuss tech do it at /r/fakeapp or /r/sfwdeepfakes, which are still up.",dead though want discus tech still,issue,negative,negative,negative,negative,negative,negative
363971068,"Tf-Coriander does not work for deepfakes because it's based on an outdated version of Tensorflow, use the dev/amd_gpu branch of https://github.com/lukeiwanski/tensorflow.

I have a full guide for getting the deepfake scripts running on AMD cards on Ubuntu 16.04 here: https://hastebin.com/yodusucilo which you may be able to modify to get it running on MacOS, it mostly depends on AMD having drivers that support your OS that expose your card to OpenCL, which they probably do considering it's in your machine.",work based outdated version use branch full guide getting running may able modify get running mostly support o expose card probably considering machine,issue,negative,positive,positive,positive,positive,positive
363968266,"You should fork the project and develop your changes, then create a pull
request for your fork.

When you create the pull request, add me as a reviewer.

On 8 Feb. 2018 11:27, ""subzerofun"" <notifications@github.com> wrote:

> @IUsedToBeAPygmy <https://github.com/iusedtobeapygmy> Hey if you find out
> what to change for the 128x128 resolution – could you please upload a gist
> of the edited files? I've been trying around far too long and can't solve
> it myself.
>
> —
> You are receiving this because you were assigned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/142#issuecomment-363959896>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeANEpkNVFB9zvInhj1AFxGyJe8uEks5tSj9mgaJpZM4R84X4>
> .
>
",fork project develop create pull request fork create pull request add reviewer wrote hey find change resolution could please gist trying around far long ca solve assigned reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
363959896,@IUsedToBeAPygmy  Hey if you find out what to change for the 128x128 resolution – could you please upload a gist of the edited files? I've been trying around far too long and can't solve it myself.,hey find change resolution could please gist trying around far long ca solve,issue,negative,positive,neutral,neutral,positive,positive
363934649,"Both autoencoders are being trained to transform a warped and distorted version of an individual's face into an undistorted version, the ground truth is the undistorted face.

Being able to convert from one face to another is a side effect of the network interpreting A's face as a distorted image of B and ""correcting"" it.",trained transform warped distorted version individual face undistorted version ground truth undistorted face able convert one face another side effect network face distorted image correcting,issue,negative,positive,positive,positive,positive,positive
363931637,"discussing the code and technology without any NSFW connotation can still be done in the /r/deepfaketechtalk subreddit.

https://www.reddit.com/r/deepfaketechtalk/",code technology without connotation still done,issue,negative,neutral,neutral,neutral,neutral,neutral
363922633,"Alright I've got it working locally with selectable loss functions (including SSIM, and blend-weights to blend SSIM with L1 or L2), and the filenames now include the name of the used model.
I'll add selectable activation functions including PELU, and probably make the optimizer selectable as well.

I just need to figure out how git works (I only have svn/p4 experience) to sync to master, merge my changes and commit.
Going to RTFM now.





",alright got working locally selectable loss blend include name used model add selectable activation pelu probably make selectable well need figure git work experience sync master merge commit going,issue,negative,neutral,neutral,neutral,neutral,neutral
363890006,"You'd read the json once at initialisation the processing time for which is dwarfed by even the most trivial image operations you'd do with it's contents.

The ability to immediately slice and dice human-readable text (for manual insertion of new batches or externally augmented training samples) isn't worth the time saved.",read time even trivial image content ability immediately slice dice text manual insertion new externally augmented training worth time saved,issue,positive,positive,positive,positive,positive,positive
363883859,"By the way, what do I have to change to up the face resolution from 64x64 to 128x128?",way change face resolution,issue,negative,neutral,neutral,neutral,neutral,neutral
363867623,"So the original solution was a Masked solution, then Adjust came along, but then Masked was improved to the point where it's the solution people have the most luck with?",original solution masked solution adjust came along masked point solution people luck,issue,positive,positive,positive,positive,positive,positive
363860474,Thank you! I'll add anything i find back to the repo,thank add anything find back,issue,negative,neutral,neutral,neutral,neutral,neutral
363843308,"This should be fixed in this commit https://github.com/deepfakes/faceswap/commit/f3bb0bba072f0bfc4c11480cd6f0728aaf1e3db6

Thanks for the bug report",fixed commit thanks bug report,issue,positive,positive,positive,positive,positive,positive
363835390,Can you get us some of those sweet sweet numbers? Or hook us up with a hit of graphs? :stuck_out_tongue: ,get u sweet sweet hook u hit,issue,positive,positive,positive,positive,positive,positive
363834943,"Thanks, use dlib git fixed. 1 suggestion for all Windows user: better not switch Command window while extracting. ",thanks use git fixed suggestion user better switch command window,issue,positive,positive,positive,positive,positive,positive
363834446,"I'm going to close this.

When you want to add a pull request to merge your changes please reference this issue.",going close want add pull request merge please reference issue,issue,negative,neutral,neutral,neutral,neutral,neutral
363828166,"I can look over it. Its better than the code I look over for work.

On 8 February 2018 at 03:33, Clorr <notifications@github.com> wrote:

> Oh, feel free to do as you want and propose to others. My opinion is that
> it seems fine, but I'm not the only one here ;-)
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/142#issuecomment-363827568>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeGNLTcyv09xjONetLpCYYkacKOkuks5tSdBogaJpZM4R84X4>
> .
>



-- 

yubikey <https://pgp.mit.edu/pks/lookup?op=get&search=0xEF32AD3C725E89DD>
 - *0xef32ad3c725e89dd*
personal <https://pgp.mit.edu/pks/lookup?op=get&search=0xB380946AFE4AE982>
- *0xb380946afe4ae982*
work <https://pgp.mit.edu/pks/lookup?op=get&search=0x246CF7D3840A8081>
- *0x246cf7d3840a8081 *
",look better code look work wrote oh feel free want propose opinion fine one thread reply directly view mute thread personal work,issue,positive,positive,positive,positive,positive,positive
363827568,"Oh, feel free to do as you want and propose to others. My opinion is that it seems fine, but I'm not the only one here ;-)",oh feel free want propose opinion fine one,issue,positive,positive,positive,positive,positive,positive
363825506,"You have to compile it manually AFAIK. CPU version is really slow, yes...",compile manually version really slow yes,issue,negative,negative,negative,negative,negative,negative
363824862,"Which  dlib version is compiled with CUDA? Now I using dlib-19.9 in cnn mode  Only extract 38 pictures in 24 minutes. (But much better than before, can recognize almost all scenes)
My GTX1080 GPU log:
GPU Core Clock [MHz] : 164.5
Memory Used [MB]      :  438
GPU Load [%]               :  13

GPU in low use, is there any solution can fix this? Thanks. 

",version mode extract much better recognize almost log core clock memory used load low use solution fix thanks,issue,positive,positive,positive,positive,positive,positive
363819092,"Ah ok, I understand. Thats possible, file names are just string we can construct on the fly...",ah understand thats possible file string construct fly,issue,negative,positive,positive,positive,positive,positive
363818395,"It was really a bug in the code, but that i did not have on Linux... Thanks for reporting!",really bug code thanks,issue,negative,positive,positive,positive,positive,positive
363817782,"Hi Clorr
Issue fixed, I updated all, not sure which one effect, updated python/cmake/dlib to latest one, then all work.
Now I have smoke test on extract, thanks a lot !!! 
This issue can be closed.

BR
ModelSex",hi issue fixed sure one effect latest one work smoke test extract thanks lot issue closed,issue,positive,positive,positive,positive,positive,positive
363810913,We should do it for all parameters that break the serialization / ability to continue really.,break serialization ability continue really,issue,negative,positive,positive,positive,positive,positive
363809678,"I totally agree, I did that for GAN, I should have done it for LowMem",totally agree gan done,issue,negative,neutral,neutral,neutral,neutral,neutral
363809197,"Okay.

I'm thinking about using plugins for the activation as well, so we can add / test different activation types instead of the current LeakyReLu (like SELU, PELU etc.)..
The same for the used optimizer (Adam / SGD / Nadam etc.)

But using custom activation types (like the ones in keras.contrib) change the serialization of the models - models trained with one activation type can't be loaded / continued with another.

So I'd like to propose to store used settings (model, optimizer, activation) in the actual filenames as to not overwrite previous data when switching to another type for testing.

I could imagine storing
decoder_A_dssim_adam_pelu.h5
or
decoder_B_original_nadam_leakyrelu.h5

Any thoughts?",thinking activation well add test different activation instead current like pelu used custom activation like change serialization trained one activation type ca loaded continued another like propose store used model activation actual overwrite previous data switching another type testing could imagine,issue,positive,negative,neutral,neutral,negative,negative
363804669,"Ah thanks for the link, I was tired of looking /r/deepfakes ...

for the face filter, it is the one from https://github.com/ageitgey/face_recognition . It is quite good for most common poses, but has limits with very weird poses",ah thanks link tired looking face filter one quite good common weird,issue,negative,negative,neutral,neutral,negative,negative
363803226,"There are side repos for usage and theory in https://github.com/deepfakes/faceswap-playground and https://github.com/deepfakes/faceswap-model but they are not much used.

If it is to dicuss about theory, faceswap-model is better, if it is to add new features and then add code, it is ok to do it here. If you have code, it is even better to do a PR so that other can try it on their side",side usage theory much used theory better add new add code code even better try side,issue,positive,positive,positive,positive,positive,positive
363802871,"How well does the face filter perform?
I mean, I'd expect the facefilter to not be able to recognize the same face all the time because it's only using one reference picture..?

oh and for those who follow reddit, please visit /r/deepfaketechtalk :)
",well face filter perform mean expect able recognize face time one reference picture oh follow please visit,issue,positive,positive,neutral,neutral,positive,positive
363798788,"The only Python's i have are the **Intel One** from this guide (https://www.reddit.com/r/deepfakes/comments/7nq173/v2_tutorial_intelbased_python_easy_to_follow/) and P**ython 3.6.3 (Anaconda3 5.0.1 64bit)**.

I just finished to reinstall everything to get working again the Original Code and the APP 1.1.

I still wanna try your REPO guys, but i don't want to fuck everything again, so if someone of you want to help me to install it trough **TEAMVIEWER** tell me.

**PC SPECS:** 7700k, 32gb ram, MSI 1080TI, 2 SSD's, HDD, Windows 10 creators.",python one guide anaconda bit finished reinstall everything get working original code still wan na try want everything someone want help install trough tell spec ram ti,issue,positive,positive,neutral,neutral,positive,positive
363792802,"Json is readable and hence can be edited easily. Last time, I merged additional files into my original json file. This is the only reason json is ideal. But if you can provide same functionality for another format I think it's not an issue",readable hence easily last time additional original file reason ideal provide functionality another format think issue,issue,positive,positive,positive,positive,positive,positive
363790207,I know how the process works. My only real gripes are that json isn't exactly an ideal format for this kind of data. It doesn't really matter all that much. I will add options for more serializers.,know process work real exactly ideal format kind data really matter much add,issue,positive,positive,positive,positive,positive,positive
363789699,"I can do both.

I can structure the json serializer around the one in the fakeapp repo, and the other serializers, Ill just do whatever works.

It most likely already uses a similar structure to what I'm thinking of, maybe with different names.",structure around one ill whatever work likely already similar structure thinking maybe different,issue,negative,negative,negative,negative,negative,negative
363789662,"You can check the original code posted on Reddit as starting point (I can provide the scripts if you can't find them).
Basically when extracting algorithm outputs a json file containing info about the images. Then we swap the face only within training set. Now we have a folder of converted faces. Then using this file and converted images we do the merges.",check original code posted starting point provide ca find basically algorithm file swap face within training set folder converted file converted,issue,negative,positive,positive,positive,positive,positive
363788360,"\ o /

Glad you want to take that part ;-) On the json part I strongly encourage you to stick to what is done already in the official repo, otherwise we will encounter endless issues ;-)

You could do a new format, but then don't use the same name. But I'm less keen on that because we would create yet another format...

Do you know where to find the original format?

",glad want take part part strongly encourage stick done already official otherwise encounter endless could new format use name le keen would create yet another format know find original format,issue,positive,positive,positive,positive,positive,positive
363787376,"This is within my capabilities, and I'm willing to do it.

Might take me a couple of days (need to do some paid work).

Are we particularly attached to json? something more performant would be great, like pickle or shelve (both python stdlib)?

I will serialise it as such:

```python3
{
    ""filename-aligned-0001.tif"": {
        ""position"": [...],
        ""landmarks"": [...]
    }
...
}
```

and then when we retrieve the data, for each image that we have, try and get some data, otherwise skip it.

Does that sound good?

 I will make it with multiple serializers for meatbag functionality. so that people can share their aligned datasets without worrying about evaluating someone elses pickle, or edit the files directly.",within willing might take couple day need work particularly attached something performant would great like pickle shelve python python position retrieve data image try get data otherwise skip sound good make multiple functionality people share without worrying someone pickle edit directly,issue,positive,positive,positive,positive,positive,positive
363786739,Can you update to the latest version and let me know if it ok?,update latest version let know,issue,negative,positive,positive,positive,positive,positive
363782654,"It is always better but, I don't think your issue relates to that. It seems something really Windows related. I'll try to check ASAP on a windows machine...

Thanks for your report, it is top quality ;-)",always better think issue something really related try check machine thanks report top quality,issue,positive,positive,positive,positive,positive,positive
363781489,"Thanks a lot for reply, really appreciate your work.  Should I update to latest python 3.6.4 ?

After removed Exception, log as follow:
2018-02-07 22:02:40.101480: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
Exception in thread Thread-1:.14971, loss_B: 0.19145
Traceback (most recent call last):
  File ""C:\Users\xxx\Anaconda3\lib\threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""C:\Users\xxx\Anaconda3\lib\threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""D:\face\faceswap\scripts\train.py"", line 143, in processThread
    model.save_weights()
  File ""D:\face\faceswap\lib\ModelAE.py"", line 36, in save_weights
    self.encoder.save_weights(self.model_dir / encoderH5)
  File ""C:\Users\xxx\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 2603, in save_weights
    f = h5py.File(filepath, 'w')
  File ""C:\Users\xxx\Anaconda3\lib\site-packages\h5py\_hl\files.py"", line 267, in __init__
    name = name.encode(sys.getfilesystemencoding())
AttributeError: 'WindowsPath' object has no attribute 'encode'

---------------------------------------------------------------------
pathlib output:
Name: pathlib
Version: 1.0.1
Summary: Object-oriented filesystem paths
Home-page: https://pathlib.readthedocs.org/
Author: Antoine Pitrou
Author-email: solipsis@pitrou.net
License: MIT License
Location: c:\users\xxx\anaconda3\lib\site-packages
Requires:",thanks lot reply really appreciate work update latest python removed exception log follow device device name bus id compute capability exception thread recent call last file line file line run file line file line file line file line name object attribute output name version summary author license license location,issue,positive,positive,positive,positive,positive,positive
363777343,"I'm also merging this, because thankfully to trainer arguments, GAN is no more the default value, and the plugin can now live without having impact on the rest of the codebase",also thankfully trainer gan default value live without impact rest,issue,positive,positive,positive,positive,positive,positive
363775502,Who said anything about fake porn? It's a general issue if you want to convert a scene or algorithm gives you a false-positive output. Of course I'm not saying what you should do or when you should do. I'm just pointing an issue for everyone here.,said anything fake general issue want convert scene algorithm output course saying pointing issue everyone,issue,negative,negative,negative,negative,negative,negative
363774673,"Also, can you go in `scripts/train.py` and remove this:
```
        except Exception as e:
            print(e)
            exit(1)
```
And rerun so that I can have more explicit error",also go remove except exception print exit rerun explicit error,issue,negative,neutral,neutral,neutral,neutral,neutral
363773590,"Can you give me also the pathlib version? (`pip show pathlib` or `pip3 show pathlib`)

Also is python 3.5.2 latest version on windows?",give also version pip show pip show also python latest version,issue,negative,positive,positive,positive,positive,positive
363770610,"Bah the problem here is more that we have many users and only few coders. My priorities depend on what i want to do which is not fake porn, so I understand your point, but on my side I don't have this problem for now at least...",bah problem many depend want fake understand point side problem least,issue,negative,negative,neutral,neutral,negative,negative
363769419,"Face detection algorithm sometimes confuse objects with faces. Last time I converted something algorithm also converted the painting on the wall. Right now only way to solve this issue is feeding the algorithm with single filter-face file. But then algorithm fails to detect all the faces because of the angle of something. Isn't this a big issue or am I missing something? 

Using the json file is not mandatory but then we should tell the algorithm only to use what's in the dataset. But that means comparing every time it detects a new ""face"" during convert",face detection algorithm sometimes confuse last time converted something algorithm also converted painting wall right way solve issue feeding algorithm single file algorithm detect angle something big issue missing something file mandatory tell algorithm use every time new face convert,issue,negative,positive,neutral,neutral,positive,positive
363765868,"My feelings where a bit mitigated on `alignment.json`. With the `HOG` it was not a big deal because it is fast, but i agree that with `MMOD/CNN` maybe the game changed.

The most annoying part for me was the fact that with `alignments.json` we depend on a file that almost no one can edit and it makes the convert rely on something that may be lost / corrupted.

However, we still can add an option to generate the `alignments.json`, it is just a matter of serializing a data we already have. On the convert side, I don't think it is a big deal either, but for now I want to focus on the GAN, so I let this for now, but if someone wants to take it, I'm fine",bit hog big deal fast agree maybe game annoying part fact depend file almost one edit convert rely something may lost corrupted however still add option generate matter data already convert side think big deal either want focus gan let someone take fine,issue,negative,negative,neutral,neutral,negative,negative
363763546,"I did not follow your code, but I did a `lib.multithread.py` to have the code separated and easily rewritable. We still have problems on windows, but I hope someone can sort this out ;-)

But anyway thanks for the contrib, I would have been pleased to see your name in the commits ;-)",follow code code easily still hope someone sort anyway thanks would see name,issue,positive,positive,positive,positive,positive,positive
363761636,So you would prefer converting 12000 frames you didn't train on? I don't understand. If you want to convert a video you should use all the frames. Maybe you are confusing with Data B?,would prefer converting train understand want convert video use maybe data,issue,negative,neutral,neutral,neutral,neutral,neutral
363759811,@Clorr - it looks like his execution stopped directly after the first update/save.,like execution stopped directly first,issue,negative,positive,positive,positive,positive,positive
363759348,"What if you want to convert 20000 frames, but only train on a subset of 8000 of those?",want convert train subset,issue,negative,neutral,neutral,neutral,neutral,neutral
363758383,"FWIW, I'm running Python 3.6, Tensorflow 1.5, Cuda 9 and cuDNN 7 without any problems.

Are you using Python 3.6?",running python without python,issue,negative,neutral,neutral,neutral,neutral,neutral
363757250,"I'm merging this now because we should move on, don't hesitate to open issues if you find bugs...",move hesitate open find,issue,negative,neutral,neutral,neutral,neutral,neutral
363756890,"faceswap original script is an autoencoder, faceswap-GAN is a fork that uses a GAN, but all-in-all it does the same thing",original script fork gan thing,issue,negative,positive,positive,positive,positive,positive
363756887,"I classified that as misc update also :)
But sure can be opened as different issue",classified update also sure different issue,issue,negative,positive,positive,positive,positive,positive
363756395,"@ZeroCool22 sorry you have trouble installing, but anyway the install process is still very rough, especially on windows.

What i can tell you from my windows experience is:
- dlib is hard to setup with pip on python 3.5 because it lacks a precompiled version. With python 3.6, there is a precompiled version of dlib that is the 19.7.0
- The problem if you go for the 3.6 version is that tensorflow 1.4.0 does not work with it
- BUT tensorflow 1.5.0 has been released and should work with python 3.6

Otherwise, instead of pip, there is conda that can help you setup things because it has more precompiled libs, but I never tried conda",sorry trouble anyway install process still rough especially tell experience hard setup pip python version python version problem go version work work python otherwise instead pip help setup never tried,issue,negative,negative,negative,negative,negative,negative
363754533,"@Apollo122 supporting an `alignment.json` file is totally feasible because it is just a matter of saving the landmarks that are generated on extract. Just this is not related to this PR so maybe discuss it in a specific issue.

@facepainter if you have some code to propose, we are totally open to it ;-) Feel free to make a PR. Just be careful to make it after this one has been merged, so we don't get too much conflicts",supporting file totally feasible matter saving extract related maybe discus specific issue code propose totally open feel free make careful make one get much,issue,positive,positive,neutral,neutral,positive,positive
363753889,"@IUsedToBeAPygmy After i ejecuted the command you told me **""pip install dlib""**, now **nothing related with Python works**, not even the FAKEAPP, neither virtualenv, what could happened?

Damn how i regret to try to use this repo, now nothing works...",command told pip install nothing related python work even neither could damn regret try use nothing work,issue,positive,neutral,neutral,neutral,neutral,neutral
363751097,"I was having similar issues too. I can't recally if it was the same issue, but try installing http://landinghub.visualstudio.com/visual-cpp-build-tools 2015 version. This fixed everything for me.",similar ca issue try version fixed everything,issue,negative,positive,neutral,neutral,positive,positive
363750579,"@Clorr  thanks, I wanted to make a contribution, but, currently, I just don't have time. Feel free to use my code ",thanks make contribution currently time feel free use code,issue,positive,positive,positive,positive,positive,positive
363745440,"I already have CMAKE installed since 2017, i do the PIP you told me anyways?

![screenshot_3](https://user-images.githubusercontent.com/13344308/35914862-acbb028a-0be3-11e8-8790-d6a4321288ef.png)
**CMake (cmake-gui)**",already since pip told anyways,issue,negative,neutral,neutral,neutral,neutral,neutral
363743226,"The error is  No CMAKE_C_COMPILER could be found.

try pip install cmake

",error could found try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
363738532,"Hello and thanks for this PR!

It is ok but I will reject it because it will create a conflict with my pending PR #109 . The merge will be done this afternoon, so if you want, I let you add it to the new code",hello thanks reject create conflict pending merge done afternoon want let add new code,issue,negative,positive,positive,positive,positive,positive
363736297,Thanks for this PR. I saw something similar in https://www.reddit.com/r/deepfakes/comments/7mbzu2/patched_face_alignment_and_merge_scripts_with/ (I paste the link for keeping track),thanks saw something similar paste link keeping track,issue,negative,positive,neutral,neutral,positive,positive
363734613,"The steps I posted aren't in the install manual, they're to correct your previously wrong configured virtualenv... Anyway, if you've really done done ""setprojectdir ."" in c:\faceswap-master it should be fine now.

Which exact version of Python are you using?  
Can you try
> pip install dlib


to see what happens?",posted install manual correct previously wrong anyway really done done fine exact version python try pip install see,issue,negative,positive,neutral,neutral,positive,positive
363732854,"Yes, ofc. i did that steps, i'm in the part of **pip install -r requirements-gpu.txt** but get a lot of errors (red text).

I make a video to show you that i'm doing the things like you told me, (and the guide installation): https://www.youtube.com/watch?v=kEaS2eXDhLc

I think i will give up, it will be impossible to install without the help of some of you guys...

What you ask me for:

![screenshot_2](https://user-images.githubusercontent.com/13344308/35912547-a6ecc2b0-0bdb-11e8-9484-6b87f8a6da3a.png)
",yes part pip install get lot red text make video show like told guide installation think give impossible install without help ask,issue,negative,negative,negative,negative,negative,negative
363727552,"Can you type lsvirtualenv and paste the output?
I'm still not convinced your virtualenv is setup correctly.

Have you actually done 

> rmvirtualenv faceswap
> cd \faceswap-master
> mkvirtualenv faceswap
> setprojectdir .

? 

",type paste output still convinced setup correctly actually done,issue,negative,neutral,neutral,neutral,neutral,neutral
363725810,"Thx for your help, i got the others errors solved, but now i get:

**Failed building wheel for dlib and more errors....**

After ejecute **pip install -r requirements-gpu.txt**

https://pastebin.com/3wvEZQXP",help got get building wheel pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
363725407,"All the plugins have a description at the beginning to tell where it does come from. The Masked and Align come from early modifications of the original script which I took as they came out. (I should retrieve exact links, the links in the files are just general indications)

FYI, the original script was quite awful with squared faces and strange skin tones. There were some attempt to get it better but with quite a big overhead. Some guy came with a really simple simple solution, which is the ""Adjust"" version. Finally, the most successful version was one with face detection and landmarks. But it was adding `pytorch` as dependency, and I just removed that to use `face_recognition` lib which has all what's need and is quite fast and lightweight

For all your questions, I encourage you to go on reddit. If you get your answers, feel free to add a heading in the plugin files with a documentation and a how-to, this would be extra nice ;-)",description beginning tell come masked align come early original script took came retrieve exact link link general original script quite awful squared strange skin attempt get better quite big overhead guy came really simple simple solution adjust version finally successful version one face detection dependency removed use need quite fast lightweight encourage go get feel free add heading documentation would extra nice,issue,positive,positive,positive,positive,positive,positive
363715628,"I think there is some misunderstanding here...

I'm not the one who did the original code and I don't know the reason why it is made so. My ""opinion"" is that there is no strong reason, and that the original code is more the result of an experiment than a strongly theoritized approach.

From here what I say, is: if you think you have a better approach, or even just an alternative, feel free to try and see if you can do better. If so, you can propose alternatives here, thanks to the plugin architecture (which, I agree, is more complex than just a flat script).

The GAN version I'm refering to is [here](https://github.com/shaoanlu/faceswap-GAN), and I'm on the way to make this a plugin because it is an interesting approach",think misunderstanding one original code know reason made opinion strong reason original code result experiment strongly approach say think better approach even alternative feel free try see better propose thanks architecture agree complex flat script gan version way make interesting approach,issue,positive,positive,positive,positive,positive,positive
363708683,"I'm using the SSIM from keras.contrib and mix its result with the result of a normal loss function like mean_absolute_error (using a very small factor for the SSIM).

https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py

Keras.contrib also supplies alternative advanced activation functions like PELU.
",mix result result normal loss function like small factor also alternative advanced activation like pelu,issue,positive,positive,positive,positive,positive,positive
363707605,"It literally says ""ERROR: virtualenv ""faceswap"" already exists.

You haven't properly removed your old virtualenv before trying to create it again in the proper location.

I don't want to be rude but both your problems so far have been caused by not taking the time to properly read instructions / error messages.",literally error already properly removed old trying create proper location want rude far taking time properly read error,issue,negative,negative,neutral,neutral,negative,negative
363706170,"> 
> (faceswap) C:\Windows\System32>setprojectdir .
>  
>     ""C:\Windows\System32"" is now the project directory for
>     virtualenv ""C:\Users\ZeroCool22\Envs\faceswap""
>  
>     ""C:\Windows\System32"" added to
>     C:\Users\ZeroCool22\Envs\faceswap\Lib\site-packages\virtualenv_path_extensions.pth

You are setting up your project directory to be C:\Windows\System32 instead of C:\faceswap-master

I think you have missed this part:

>For now, extract the code to a directory where you're comfortable working with it. **Navigate to it with the command line.**

Try to remove your current virtualenv and try to create it again from your faceswap-master folder?
",project directory added setting project directory instead think part extract code directory comfortable working navigate command line try remove current try create folder,issue,positive,positive,positive,positive,positive,positive
363695433,"You see the code i paste in pastebin?

> (faceswap) C:\Windows\System32>cd C:\faceswap-master
  
> (faceswap) C:\faceswap-master>pip install -r requirements-gpu.txt

I was in the folder C:\faceswap-master **before ejecute** pip install -r requirements-gpu.txt

I'm following step by step the **guide** of the repo: https://github.com/deepfakes/faceswap/blob/master/INSTALL.md


",see code paste pip install folder pip install following step step guide,issue,negative,neutral,neutral,neutral,neutral,neutral
363688595,"First of all why are you doing all this in your Windows\System32 folder?

Try it from your C:\faceswap-master folder!",first folder try folder,issue,negative,positive,positive,positive,positive,positive
363639880,"@Clorr have been playing with this myself - the face_detection lib actually allows you to batch process upto 128 frames at a time using a CNN model. You just have to make sure that you compile dlib with CUDA extensions and then you get to use the GPU too :) totally removes the ffmpeg splitting to frames step :)  -oh - all the frames do have to be the exact same dimensions but it using video that is no problem :)

I have just been testing it - the idea is you give it a video, a small sample of images of a person you want (say a directory with 5-10 good shots). an output folder and a batch size i.e.

`faceswap.py extract -i videoOfX.mp4 -r ./ImagesOfX -o ./grabedFramesX -b 32`

It is actually working pretty well - it is faster - and as it negates first extracting and loading the frames as a step outside the application in ffmpeg or whatever. 

I even put together a version with youtube-dl included so you can do...

`faceswap.py extract -i 2z3JUS1aXdY  -r ./ImagesOfX -o ./grabedFramesX -b 32`

Where **2z3JUS1aXdY**  is the id of a youtube video (it just gets the best version, then does as above).

Really all just based off these two examples: https://github.com/ageitgey/face_recognition/blob/master/examples/find_faces_in_batches.py
https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_video_file.py

Anyhow thought you might be interested - apologies if this is something that has already been looked at :)",actually batch process time model make sure compile get use totally splitting step exact video problem testing idea give video small sample person want say directory good output folder batch size extract actually working pretty well faster first loading step outside application whatever even put together version included extract id video best version really based two anyhow thought might interested something already,issue,positive,positive,positive,positive,positive,positive
363581044,"So i tested the convert as well seems fine.
Although I have a suggestion about it:

Right now convert takes a full frame. First it detects the face then crops it, runs model and finally merges it back.
But we've already done half the job during extraction. We detected the face and cropped it to train on it. So it doesn't make sense to do it all over again(especially if we want to use cnn). Also algorithm may miss some faces or output some garbage images that we got rid out before training. With this approach we have absolutely no control what images it uses. We should use the extracted images to process and merge only those. For example 1adrianb's face-detector outputs alignment.json after extraction. With using something like that we would know where the face is on the frame and where to merge it without processing again.",tested convert well fine although suggestion right convert full frame first face model finally back already done half job extraction face train make sense especially want use also algorithm may miss output garbage got rid training approach absolutely control use extracted process merge example extraction something like would know face frame merge without,issue,positive,positive,positive,positive,positive,positive
363535959,"Hey thanks for getting back to me! I was actually not referring to the Plugin structure itself (which I find kind of hard to read but that's your design choice and like you said certainly makes things much easier when swapping components). What I was referring to is that the increase in spatial dimension in the decoder is done by reshaping the output to have less color channels but larger spatial extend. Some color channels thereby encode similar information but slightly shifted spatially. This is unlike anything I have seen so far. I am not questioning that at all (especially since it seems to work); I would just like to know why this approach was chosen over simply using a transposed convolution which would be the much more obvious choice in this context. Was there a specific reasoning behind it?

What exactly do you mean by 'the GAN one'? Do you have a specific experiment in mind that you would like to try? I guess working with GANs might improve results but will also complicate things. If you ditch the l1 loss the network is currently using to reconstruct images with an adversarial loss you will need to condition the generated image on something to ensure that the same person/expression you presented to the encoder was reconstructed by the decoder. Or am I missing something here?",hey thanks getting back actually structure find kind hard read design choice like said certainly much easier swapping increase spatial dimension done output le color spatial extend color thereby encode similar information slightly spatially unlike anything seen far especially since work would like know approach chosen simply convolution would much obvious choice context specific reasoning behind exactly mean gan one specific experiment mind would like try guess working might improve also complicate ditch loss network currently reconstruct loss need condition image something ensure reconstructed missing something,issue,positive,negative,neutral,neutral,negative,negative
363520173,"My opinion is that Deepfakes original code is far from optimized and is the result of some experimentations. For me the model is quite strange, but I may not be experienced enough to estimate that. I think that it is really possible to optimize it, and you should try to apply your knowledge there and see if your approach brings better results ;-)

That' really the reason behind the fact I did a plugin architecture, because we should try other solutions, like the GAN one.",opinion original code far result model quite strange may experienced enough estimate think really possible optimize try apply knowledge see approach better really reason behind fact architecture try like gan one,issue,positive,positive,positive,positive,positive,positive
363517714,"Also note that loss_A: 0.18594, loss_B: 0.20080 is not a good value, usable value is closer to 0.03 or less. Also look at the preview to estimate wether your training is ok or not",also note good value usable value closer le also look preview estimate wether training,issue,positive,positive,positive,positive,positive,positive
363450821,"Didn't you just press enter too much? pressing enter is the only way to stop it, otherwise it will just continue training indefinitely.

If it stops without pressing enter there's nothing left to do for you but start debugging to see why it exits the program.

",press enter much pressing enter way stop otherwise continue training indefinitely without pressing enter nothing left start see program,issue,negative,positive,neutral,neutral,positive,positive
363405071,"if i want to use seamless clone, what i should type in cmd.",want use seamless clone type,issue,negative,positive,neutral,neutral,positive,positive
363389274,"@IUsedToBeAPygmy Thanks! Can you work it as a plugin similar to how GAN is being used?

I literally did a drop in replacement of Adam with Nadam, and the preview output while I was gathering the above data looked totally fine.",thanks work similar gan used literally drop replacement preview output gathering data totally fine,issue,negative,positive,positive,positive,positive,positive
363388701,"It takes a lot of time to converge, I dont know much about the docker image.",lot time converge dont know much docker image,issue,negative,positive,positive,positive,positive,positive
363371500,"thanks for the replies, working on it; indeed removing the `\r` does print loss functions.
Now working on embedding preview window within notebook and compiling a fully working notebook.",thanks working indeed removing print loss working preview window within notebook fully working notebook,issue,negative,positive,positive,positive,positive,positive
363344589,"Also, I've created a model that implements the loss function as a mix of SSIM and L2  and uses PELU instead of LeakyReLu which seems to work rather well (have only been training shortly so I'll might eat those words later). If I find it does and people want I can put in a pull request later.

http://research.nvidia.com/sites/default/files/pubs/2017-03_Loss-Functions-for/NN_ImgProc.pdf",also model loss function mix pelu instead work rather well training shortly might eat later find people want put pull request later,issue,negative,neutral,neutral,neutral,neutral,neutral
363342991,"@gdunstone - I've just tried to replace the used Adam with Keras' standard Nadam, but all I get is completely red images so apparently it's not just a drop-in replacement.
Did you get it to work and if so, how?",tried replace used standard get completely red apparently replacement get work,issue,negative,positive,neutral,neutral,positive,positive
363342623,"Can someone tell me what the exact changes are for the 128x128 resolution? It's not entirely clear to me.
I'd like to try them locally in this codebase..",someone tell exact resolution entirely clear like try locally,issue,positive,positive,positive,positive,positive,positive
363341397,"Dfaker has written some code to compare Faceset A to Faceset B to see the (dis)similarity between images so you can get an idea of which faces of A do not have a representative face in B...

https://github.com/dfaker/df/blob/master/imageGapsScanner.py",written code compare see dis similarity get idea representative face,issue,negative,neutral,neutral,neutral,neutral,neutral
363319744,"thank you! i mean saving model weights fast but the loss is still high ,i have no idea how it stops.just sometimes it works well.most time it saved model weights just once.i use docker pull it.no return code as i show above.python3 ",thank mean saving model fast loss still high idea sometimes work time saved model use docker pull return code show,issue,negative,positive,neutral,neutral,positive,positive
363312681,"Can you please reword the problem?

Saving model weights fast is a good thing, saving them at a high frequency will have a performance impact but shouldn't impact the result.

There is a key press (s) that will save the model weights that might have something to do with it.

Can you describe how it stops? Does it freeze the system? Does it hang? Does it give a return code?

Also what version of python3, Cuda, and tensorflow are you using? ",please reword problem saving model fast good thing saving high frequency performance impact impact result key press save model might something describe freeze system give return code also version python,issue,positive,positive,positive,positive,positive,positive
363308468,"i have try it a week ago,it works good ,but recently it always stop early with no error
",try week ago work good recently always stop early error,issue,negative,positive,positive,positive,positive,positive
363306190,"It says in the stack trace: no such file or directory.

Create the models directory and it will be good I think",stack trace file directory create directory good think,issue,positive,positive,positive,positive,positive,positive
363224633,"Ah thanks for this bug. maybe I should add a check for the output folder
",ah thanks bug maybe add check output folder,issue,negative,positive,positive,positive,positive,positive
363224237,"i have 4 cores yes. on task manager its written 4 cores and 8 logical processor.
btw i tried train got this error and it stuck.
Unable to create file (unable to open file: name = 'models/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)

created the folder manually and it worked.
i lost my trump-cage model so gonna let it train. tomorrow will test the convert part ",yes task manager written logical processor tried train got error stuck unable create file unable open file name error message file directory folder manually worked lost model gon na let train tomorrow test convert part,issue,negative,negative,negative,negative,negative,negative
363223197,"13% ? If you have 4 cores + hyperthreading, it is likely that it uses only one core (100% / 8 = 12.5%)

640 images is largely enough for the test.

I'll have more in-depth look about it tomorrow...",likely one core largely enough test look tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
363222368,"yeah i see the spikes. 
on task manager, it shows under CPU python.exe uses 13.
Im extracting 640 images",yeah see task manager,issue,negative,neutral,neutral,neutral,neutral,neutral
363220701,"hmm strange. Have you tried opening the resource monitor to see if all cores are used? also, how big is your data set ? If it is too small, the startup overhead may compensate the parallelization",strange tried opening resource monitor see used also big data set small overhead may compensate parallelization,issue,negative,negative,neutral,neutral,negative,negative
363219928,"Ok i changed both ""j"" and ""threads"" with ""processes"" and its working. 
i tried with --processes 8 but it still takes the same time. I didn't see any improvement with remaining time.
Btw images I'm extracting are hq's and uhq's",working tried still time see improvement time,issue,negative,neutral,neutral,neutral,neutral,neutral
363215126,"Yes, because with 1 process, it does not call the 'bad' part with the `processes` argument. But if other parts are ok, let me know",yes process call part argument let know,issue,negative,neutral,neutral,neutral,neutral,neutral
363214637,"So this one didnt work
python faceswap.py extract -i photos/A -o data/A --processes 2

but this worked: python faceswap.py extract -i photos/A -o data/A --processes 1

but its not utilizing multi-threading anymore ",one didnt work python extract worked python extract,issue,negative,neutral,neutral,neutral,neutral,neutral
363214225,"Oh, it is because of the signature of the copy/paste'd code does not have the argument `processes`. It is named `j` in the copy/paste'd code I showed you, it should be renamed. Test if it is still ok for you, and maybe push a correction, if not I will finalize on my side tomorrow",oh signature code argument code test still maybe push correction finalize side tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
363213252,"@fakePr0f1le i've already did it like you, I even changed display resolution to 800x600 to reduce and get more video memory in real time, but still having problems with ran out of memory. Are your faceswap is up to date? Can you try with current version of faceswap(just git clone and try it).


Im also sure that  **ENCODER_DIM** is not only one parameter that can be reduced. What about this numbers?
  ```
  def Encoder(self):
        input_ = Input(shape=IMAGE_SHAPE)
        x = input_
        x = self.conv(128)(x)
        x = self.conv(256)(x)
        x = self.conv(512)(x)
        #x = self.conv(1024)(x)
        x = Dense(ENCODER_DIM)(Flatten()(x))
        x = Dense(4 * 4 * 1024)(x)
        x = Reshape((4, 4, 1024))(x)
        x = self.upscale(512)(x)
        return KerasModel(input_, x)
```",already like even display resolution reduce get video memory real time still ran memory date try current version git clone try also sure one parameter reduced self input dense flatten dense reshape return,issue,positive,positive,positive,positive,positive,positive
363212510,"Now its complaining about something else but I got the same error for both codes above.
command i used : python faceswap.py extract -i photos/A -o data/A -j  2

Loading Extract from Extract_Align plugin...
Traceback (most recent call last):
  File ""faceswap.py"", line 29, in <module>
    arguments.func(arguments)
  File ""K:\faceswap-master\lib\cli.py"", line 50, in process_arguments
    self.process()
  File ""K:\faceswap-master\scripts\extract.py"", line 46, in process
    for _ in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):
TypeError: pool_process() got an unexpected keyword argument 'processes'",something else got error command used python extract loading extract recent call last file line module file line file line process total got unexpected argument,issue,negative,positive,neutral,neutral,positive,positive
363211221,"Ah yes, this has been discussed above. You can replace the code given by @gdunstone in it's comment https://github.com/deepfakes/faceswap/pull/109#issuecomment-362954373 The code goes in `lib/multithreading.py`. If it doesn't work let us know, or try another of the versions above",ah yes replace code given comment code go work let u know try another,issue,negative,neutral,neutral,neutral,neutral,neutral
363209948,"Extract doesnt work. 
`multiprocessing.pool.RemoteTraceback:
""""""
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""K:\faceswap-master\lib\multithreading.py"", line 16, in runner
    return method(item)
TypeError: 'NoneType' object is not callable
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""faceswap.py"", line 29, in <module>
    arguments.func(arguments)
  File ""K:\faceswap-master\lib\cli.py"", line 50, in process_arguments
    self.process()
  File ""K:\faceswap-master\scripts\extract.py"", line 46, in process
    for _ in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):
  File ""C:\IntelPython3\lib\site-packages\tqdm\_tqdm.py"", line 955, in __iter__
    for obj in iterable:
  File ""K:\faceswap-master\lib\multithreading.py"", line 12, in pool_process
    for i in pool.imap_unordered(runner, data):
  File ""C:\IntelPython3\lib\multiprocessing\pool.py"", line 735, in next
    raise value
TypeError: 'NoneType' object is not callable`",extract doesnt work recent call last file line worker result true file line runner return method item object callable exception direct cause following exception recent call last file line module file line file line process total file line iterable file line runner data file line next raise value object callable,issue,positive,positive,neutral,neutral,positive,positive
363209183,"Good catch, you can modify the directly, it will be made as pull request, and we will accept it",good catch modify directly made pull request accept,issue,positive,positive,positive,positive,positive,positive
363207477,"Just regular commands. You can also try different plugins, but that's not mandatory; more specific cases may be raised as issues",regular also try different mandatory specific may raised,issue,negative,neutral,neutral,neutral,neutral,neutral
363206838,"Alright then.
Is there any specific config should I use? Or just regular extract, train and convert? ",alright specific use regular extract train convert,issue,negative,neutral,neutral,neutral,neutral,neutral
363202645,"@shadowfolder yes I changed only that one. Also i'm not using `-bs 8` because otherwise I get some strange errors.
Btw, I read also this error in your output:
```
Unable to open file (unable to open file: name = '/home/tuw/Desktop/faceswap_/data/model/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
```
Try to fix it :)

You can find here the output of `nvidia-smi` before faceswap and while it's running.
How much Memory is already used in your videocard before running faceswap?

Before:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 387.34                 Driver Version: 387.34                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 760     Off  | 00000000:01:00.0 N/A |                  N/A |
| 71%   60C    P0    N/A /  N/A |     70MiB /  1991MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0                    Not Supported                                       |
+-----------------------------------------------------------------------------+
```

While it's running:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 387.34                 Driver Version: 387.34                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 760     Off  | 00000000:01:00.0 N/A |                  N/A |
| 78%   73C    P0    N/A /  N/A |   1888MiB /  1991MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0                    Not Supported                                       |
+-----------------------------------------------------------------------------+
```

p.s. i'm not using the standard cage/trump faceset",yes one also otherwise get strange read also error output unable open file unable open file name error message file directory try fix find output running much memory already used running driver version name volatile fan temp compute mib mib default memory type process name usage running driver version name volatile fan temp compute mib mib default memory type process name usage standard,issue,negative,negative,negative,negative,negative,negative
363195702,"It would be nice, because even if someone has, maybe he hasn't the same config as you",would nice even someone maybe,issue,negative,positive,positive,positive,positive,positive
363195117,"Hey guys,
Has anyone tested this PR on Windows? I can take a look if not.",hey anyone tested take look,issue,negative,neutral,neutral,neutral,neutral,neutral
363157947,"I'll reopen https://github.com/deepfakes/faceswap/issues/65

I think Clorr meant to add a license file describing the he current status of the licensing (that the original author hasn't provided a licence) ",reopen think meant add license file current status original author provided,issue,negative,positive,positive,positive,positive,positive
363151916,"@fakePr0f1le  so you changed only ENCODER_DIM frin 512 to 128? Because i'm not friendly for diff commands. Can you please attach here your Model_LowMem.py? Thanks. Because i've tried and get error:

```
KERAS_BACKEND=tensorflow python3 faceswap.py train -A '/home/tuw/Desktop/faceswap_/data/trump1' -B '/home/tuw/Desktop/faceswap_/data/cage' -m '/home/tuw/Desktop/faceswap_/data/model' -p -v -t LowMem -bs 8
Model A Directory: /home/tuw/Desktop/faceswap_/data/trump1
Model B Directory: /home/tuw/Desktop/faceswap_/data/cage
Training data directory: /home/tuw/Desktop/faceswap_/data/model
Loading data, this may take a while...
Loading Model from Model_LowMem plugin...
Using live preview
/home/tuw/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Failed loading existing training data.
Unable to open file (unable to open file: name = '/home/tuw/Desktop/faceswap_/data/model/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
Loading Trainer from Model_LowMem plugin...
Starting. Press ""Enter"" to stop training and save model
2018-02-05 20:06:08.689901: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-05 20:06:08.690465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-02-05 20:06:08.690862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce 840M major: 5 minor: 0 memoryClockRate(GHz): 1.124
pciBusID: 0000:07:00.0
totalMemory: 1.96GiB freeMemory: 1.55GiB
2018-02-05 20:06:08.690880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce 840M, pci bus id: 0000:07:00.0, compute capability: 5.0)
2018-02-05 20:06:10.656403: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:10.749381: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:10.822686: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.06GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.138106: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.199321: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.10GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.345082: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.412747: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.10GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.412778: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 569.52MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.523119: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:11.657352: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 20:06:23.960241: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 72.00MiB.  Current allocation summary follows.
2018-02-05 20:06:23.960294: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 113, Chunks in use: 113. 28.2KiB allocated for chunks. 28.2KiB in use in bin. 564B client-requested in use in bin.
2018-02-05 20:06:23.960302: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 16, Chunks in use: 16. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 8.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960310: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 18, Chunks in use: 18. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 18.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960316: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 17, Chunks in use: 17. 34.0KiB allocated for chunks. 34.0KiB in use in bin. 34.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960323: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 11, Chunks in use: 11. 46.2KiB allocated for chunks. 46.2KiB in use in bin. 44.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960329: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 9, Chunks in use: 9. 72.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960337: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 9, Chunks in use: 9. 168.8KiB allocated for chunks. 168.8KiB in use in bin. 168.8KiB client-requested in use in bin.
2018-02-05 20:06:23.960343: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 10, Chunks in use: 10. 371.2KiB allocated for chunks. 371.2KiB in use in bin. 356.2KiB client-requested in use in bin.
2018-02-05 20:06:23.960350: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 9, Chunks in use: 9. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960357: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 1, Chunks in use: 0. 134.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 20:06:23.960364: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 2, Chunks in use: 2. 780.2KiB allocated for chunks. 780.2KiB in use in bin. 640.0KiB client-requested in use in bin.
2018-02-05 20:06:23.960371: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 4, Chunks in use: 4. 2.38MiB allocated for chunks. 2.38MiB in use in bin. 1.88MiB client-requested in use in bin.
2018-02-05 20:06:23.960378: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 12, Chunks in use: 12. 13.62MiB allocated for chunks. 13.62MiB in use in bin. 13.12MiB client-requested in use in bin.
2018-02-05 20:06:23.960385: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 10, Chunks in use: 9. 28.88MiB allocated for chunks. 25.88MiB in use in bin. 25.00MiB client-requested in use in bin.
2018-02-05 20:06:23.960392: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 12, Chunks in use: 12. 53.25MiB allocated for chunks. 53.25MiB in use in bin. 50.75MiB client-requested in use in bin.
2018-02-05 20:06:23.960399: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 18, Chunks in use: 17. 184.50MiB allocated for chunks. 172.00MiB in use in bin. 164.00MiB client-requested in use in bin.
2018-02-05 20:06:23.960406: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 21, Chunks in use: 21. 362.38MiB allocated for chunks. 362.38MiB in use in bin. 349.00MiB client-requested in use in bin.
2018-02-05 20:06:23.960413: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 1, Chunks in use: 0. 63.62MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 20:06:23.960420: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 9, Chunks in use: 9. 648.00MiB allocated for chunks. 648.00MiB in use in bin. 648.00MiB client-requested in use in bin.
2018-02-05 20:06:23.960426: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 20:06:23.960432: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 20:06:23.960438: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 72.00MiB was 64.00MiB, Chunk State: 
2018-02-05 20:06:23.960445: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0000 of size 1280
2018-02-05 20:06:23.960451: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0500 of size 256
2018-02-05 20:06:23.960455: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0600 of size 256
2018-02-05 20:06:23.960459: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0700 of size 512
2018-02-05 20:06:23.960463: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0900 of size 256
2018-02-05 20:06:23.960468: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0a00 of size 256
2018-02-05 20:06:23.960472: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0b00 of size 1024
2018-02-05 20:06:23.960477: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0f00 of size 256
2018-02-05 20:06:23.960482: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1000 of size 256
2018-02-05 20:06:23.960486: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1100 of size 2048
2018-02-05 20:06:23.960491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1900 of size 256
2018-02-05 20:06:23.960495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1a00 of size 256
2018-02-05 20:06:23.960500: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1b00 of size 256
2018-02-05 20:06:23.960504: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1c00 of size 256
2018-02-05 20:06:23.960509: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1d00 of size 65536
2018-02-05 20:06:23.960513: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1d00 of size 256
2018-02-05 20:06:23.960518: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1e00 of size 256
2018-02-05 20:06:23.960522: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1f00 of size 8192
2018-02-05 20:06:23.960526: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b3f00 of size 256
2018-02-05 20:06:23.960531: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4000 of size 256
2018-02-05 20:06:23.960536: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4100 of size 4096
2018-02-05 20:06:23.960540: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5100 of size 256
2018-02-05 20:06:23.960544: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5200 of size 256
2018-02-05 20:06:23.960549: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5300 of size 256
2018-02-05 20:06:23.960553: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5400 of size 256
2018-02-05 20:06:23.960558: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5500 of size 256
2018-02-05 20:06:23.960562: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5600 of size 256
2018-02-05 20:06:23.960567: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5700 of size 256
2018-02-05 20:06:23.960572: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5800 of size 256
2018-02-05 20:06:23.960576: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5900 of size 256
2018-02-05 20:06:23.960581: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5a00 of size 256
2018-02-05 20:06:23.960585: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5b00 of size 256
2018-02-05 20:06:23.960590: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5c00 of size 256
2018-02-05 20:06:23.960595: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5d00 of size 38400
2018-02-05 20:06:23.960599: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042bf300 of size 3276800
2018-02-05 20:06:23.960604: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7045df300 of size 13107200
2018-02-05 20:06:23.960609: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70525f300 of size 16777216
2018-02-05 20:06:23.960614: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70625f300 of size 8388608
2018-02-05 20:06:23.960618: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x706a5f300 of size 75497472
2018-02-05 20:06:23.960623: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70b25f300 of size 18874368
2018-02-05 20:06:23.960628: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70c45f300 of size 4718592
2018-02-05 20:06:23.960633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70c8df300 of size 1179648
2018-02-05 20:06:23.960638: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70c9ff300 of size 19200
2018-02-05 20:06:23.960642: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70ca03e00 of size 19200
2018-02-05 20:06:23.960646: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70ca08900 of size 19200
2018-02-05 20:06:23.960650: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70ca0d400 of size 512
2018-02-05 20:06:23.960654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70ca0d600 of size 1179648
2018-02-05 20:06:23.960659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70cb2d600 of size 2097152
2018-02-05 20:06:23.960664: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70cd2d600 of size 1024
2018-02-05 20:06:23.960669: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70cd2da00 of size 13107200
2018-02-05 20:06:23.960673: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70d9ada00 of size 2048
2018-02-05 20:06:23.960678: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70d9ae200 of size 16777216
2018-02-05 20:06:23.960682: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70e9ae200 of size 512
2018-02-05 20:06:23.960687: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70e9ae400 of size 8388608
2018-02-05 20:06:23.960692: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70f1ae400 of size 65536
2018-02-05 20:06:23.960696: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70f1be400 of size 18874368
2018-02-05 20:06:23.960701: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7103be400 of size 8388608
2018-02-05 20:06:23.960706: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x710bbe400 of size 18874368
2018-02-05 20:06:23.960710: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711dbe400 of size 4718592
2018-02-05 20:06:23.960715: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71223e400 of size 3276800
2018-02-05 20:06:23.960720: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71255e400 of size 21364736
2018-02-05 20:06:23.960724: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7139be400 of size 8192
2018-02-05 20:06:23.960729: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7139c0400 of size 18874368
2018-02-05 20:06:23.960734: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x714bc0400 of size 18874368
2018-02-05 20:06:23.960738: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x715dc0400 of size 4096
2018-02-05 20:06:23.960743: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x715dc1400 of size 4718592
2018-02-05 20:06:23.960748: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716241400 of size 4718592
2018-02-05 20:06:23.960752: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7166c1400 of size 2048
2018-02-05 20:06:23.960757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7166c1c00 of size 1179648
2018-02-05 20:06:23.960762: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7167e1c00 of size 38400
2018-02-05 20:06:23.960766: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7167eb200 of size 65536
2018-02-05 20:06:23.960771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7167fb200 of size 256
2018-02-05 20:06:23.960776: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7167fb300 of size 256
2018-02-05 20:06:23.960780: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7167fb400 of size 38400
2018-02-05 20:06:23.960785: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716804a00 of size 512
2018-02-05 20:06:23.960790: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716804c00 of size 1024
2018-02-05 20:06:23.960794: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716805000 of size 2048
2018-02-05 20:06:23.960799: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716805800 of size 512
2018-02-05 20:06:23.960803: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716805a00 of size 65536
2018-02-05 20:06:23.960808: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716815a00 of size 8192
2018-02-05 20:06:23.960813: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716817a00 of size 4096
2018-02-05 20:06:23.960817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716818a00 of size 2048
2018-02-05 20:06:23.960822: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716819200 of size 1024
2018-02-05 20:06:23.960826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716819600 of size 19200
2018-02-05 20:06:23.960831: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71681e100 of size 256
2018-02-05 20:06:23.960836: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71681e200 of size 38400
2018-02-05 20:06:23.960840: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716827800 of size 512
2018-02-05 20:06:23.960845: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716827a00 of size 1024
2018-02-05 20:06:23.960850: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716827e00 of size 2048
2018-02-05 20:06:23.960854: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716828600 of size 512
2018-02-05 20:06:23.960859: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716828800 of size 65536
2018-02-05 20:06:23.960863: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716838800 of size 8192
2018-02-05 20:06:23.960868: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71683a800 of size 4096
2018-02-05 20:06:23.960873: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71683b800 of size 2048
2018-02-05 20:06:23.960877: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71683c000 of size 1024
2018-02-05 20:06:23.960882: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71683c400 of size 19200
2018-02-05 20:06:23.960886: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716840f00 of size 256
2018-02-05 20:06:23.960891: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841000 of size 256
2018-02-05 20:06:23.960896: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841100 of size 256
2018-02-05 20:06:23.960900: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841200 of size 256
2018-02-05 20:06:23.960905: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841300 of size 256
2018-02-05 20:06:23.960909: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841400 of size 256
2018-02-05 20:06:23.960914: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841500 of size 256
2018-02-05 20:06:23.960919: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841600 of size 256
2018-02-05 20:06:23.960923: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841700 of size 256
2018-02-05 20:06:23.960928: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841800 of size 256
2018-02-05 20:06:23.960932: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841900 of size 256
2018-02-05 20:06:23.960937: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841a00 of size 256
2018-02-05 20:06:23.960941: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841b00 of size 256
2018-02-05 20:06:23.960946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841c00 of size 256
2018-02-05 20:06:23.960951: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841d00 of size 256
2018-02-05 20:06:23.960955: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841e00 of size 256
2018-02-05 20:06:23.960960: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716841f00 of size 256
2018-02-05 20:06:23.960964: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842000 of size 256
2018-02-05 20:06:23.960969: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842100 of size 256
2018-02-05 20:06:23.960974: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842200 of size 256
2018-02-05 20:06:23.960978: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842300 of size 256
2018-02-05 20:06:23.960983: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842400 of size 256
2018-02-05 20:06:23.960987: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842500 of size 256
2018-02-05 20:06:23.960992: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842600 of size 256
2018-02-05 20:06:23.960997: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842700 of size 256
2018-02-05 20:06:23.961001: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842800 of size 256
2018-02-05 20:06:23.961006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842900 of size 256
2018-02-05 20:06:23.961010: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842a00 of size 256
2018-02-05 20:06:23.961015: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842b00 of size 256
2018-02-05 20:06:23.961020: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842c00 of size 256
2018-02-05 20:06:23.961024: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842d00 of size 256
2018-02-05 20:06:23.961029: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842e00 of size 256
2018-02-05 20:06:23.961033: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716842f00 of size 256
2018-02-05 20:06:23.961038: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716843000 of size 256
2018-02-05 20:06:23.961043: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716843100 of size 781056
2018-02-05 20:06:23.961054: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716901c00 of size 1024
2018-02-05 20:06:23.961060: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902000 of size 256
2018-02-05 20:06:23.961064: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902100 of size 256
2018-02-05 20:06:23.961069: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902200 of size 256
2018-02-05 20:06:23.961074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902300 of size 256
2018-02-05 20:06:23.961078: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902400 of size 256
2018-02-05 20:06:23.961083: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902500 of size 256
2018-02-05 20:06:23.961087: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902600 of size 256
2018-02-05 20:06:23.961092: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902700 of size 256
2018-02-05 20:06:23.961096: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902800 of size 256
2018-02-05 20:06:23.961101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902900 of size 256
2018-02-05 20:06:23.961106: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902a00 of size 256
2018-02-05 20:06:23.961110: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902b00 of size 256
2018-02-05 20:06:23.961115: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902c00 of size 256
2018-02-05 20:06:23.961119: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902d00 of size 512
2018-02-05 20:06:23.961124: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716902f00 of size 1024
2018-02-05 20:06:23.961129: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716903300 of size 2048
2018-02-05 20:06:23.961133: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716903b00 of size 8192
2018-02-05 20:06:23.961138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716905b00 of size 4096
2018-02-05 20:06:23.961143: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716906b00 of size 19200
2018-02-05 20:06:23.961147: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690b600 of size 256
2018-02-05 20:06:23.961152: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690b700 of size 256
2018-02-05 20:06:23.961157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690b800 of size 4096
2018-02-05 20:06:23.961161: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690c800 of size 256
2018-02-05 20:06:23.961166: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690c900 of size 256
2018-02-05 20:06:23.961171: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690ca00 of size 2048
2018-02-05 20:06:23.961175: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690d200 of size 256
2018-02-05 20:06:23.961180: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690d300 of size 256
2018-02-05 20:06:23.961184: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690d400 of size 256
2018-02-05 20:06:23.961189: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690d500 of size 1024
2018-02-05 20:06:23.961194: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690d900 of size 256
2018-02-05 20:06:23.961198: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690da00 of size 256
2018-02-05 20:06:23.961203: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690db00 of size 256
2018-02-05 20:06:23.961207: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690dc00 of size 256
2018-02-05 20:06:23.961212: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690dd00 of size 256
2018-02-05 20:06:23.961216: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690de00 of size 256
2018-02-05 20:06:23.961221: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71690df00 of size 38400
2018-02-05 20:06:23.961226: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716917500 of size 512
2018-02-05 20:06:23.961230: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716917700 of size 256
2018-02-05 20:06:23.961235: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716917800 of size 3276800
2018-02-05 20:06:23.961240: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716c37800 of size 1024
2018-02-05 20:06:23.961244: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716c37c00 of size 256
2018-02-05 20:06:23.961249: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x716c37d00 of size 13107200
2018-02-05 20:06:23.961254: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7178b7d00 of size 2048
2018-02-05 20:06:23.961258: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7178b8500 of size 16777216
2018-02-05 20:06:23.961263: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7188b8500 of size 512
2018-02-05 20:06:23.961267: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7188b8700 of size 256
2018-02-05 20:06:23.961272: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7188b8800 of size 8388608
2018-02-05 20:06:23.961277: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7190b8800 of size 65536
2018-02-05 20:06:23.961282: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7190c8800 of size 75497472
2018-02-05 20:06:23.961286: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71d8c8800 of size 8192
2018-02-05 20:06:23.961291: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71d8ca800 of size 18874368
2018-02-05 20:06:23.961296: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71eaca800 of size 4096
2018-02-05 20:06:23.961300: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71eacb800 of size 256
2018-02-05 20:06:23.961305: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71eacb900 of size 4718592
2018-02-05 20:06:23.961310: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71ef4b900 of size 2048
2018-02-05 20:06:23.961314: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71ef4c100 of size 1179648
2018-02-05 20:06:23.961319: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f06c100 of size 1024
2018-02-05 20:06:23.961323: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f06c500 of size 19200
2018-02-05 20:06:23.961328: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f071000 of size 19200
2018-02-05 20:06:23.961333: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f075b00 of size 256
2018-02-05 20:06:23.961337: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f075c00 of size 256
2018-02-05 20:06:23.961342: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f075d00 of size 38400
2018-02-05 20:06:23.961347: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f07f300 of size 256
2018-02-05 20:06:23.961351: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f07f400 of size 512
2018-02-05 20:06:23.961356: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f07f600 of size 3276800
2018-02-05 20:06:23.961360: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f39f600 of size 256
2018-02-05 20:06:23.961365: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f39f700 of size 1024
2018-02-05 20:06:23.961370: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f39fb00 of size 256
2018-02-05 20:06:23.961374: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f39fc00 of size 13107200
2018-02-05 20:06:23.961379: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72001fc00 of size 2048
2018-02-05 20:06:23.961384: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x720020400 of size 256
2018-02-05 20:06:23.961388: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x720020500 of size 16777216
2018-02-05 20:06:23.961393: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721020500 of size 512
2018-02-05 20:06:23.961397: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721020700 of size 8388608
2018-02-05 20:06:23.961402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721820700 of size 256
2018-02-05 20:06:23.961407: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721820800 of size 65536
2018-02-05 20:06:23.961411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721830800 of size 256
2018-02-05 20:06:23.961416: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x721830900 of size 75497472
2018-02-05 20:06:23.961421: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x726030900 of size 8192
2018-02-05 20:06:23.961425: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x726032900 of size 256
2018-02-05 20:06:23.961430: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x726032a00 of size 18874368
2018-02-05 20:06:23.961435: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x727232a00 of size 4096
2018-02-05 20:06:23.961439: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x727233a00 of size 4718592
2018-02-05 20:06:23.961444: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7276b3a00 of size 256
2018-02-05 20:06:23.961449: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7276b3b00 of size 2048
2018-02-05 20:06:23.961453: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7276b4300 of size 1179648
2018-02-05 20:06:23.961458: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7277d4300 of size 1024
2018-02-05 20:06:23.961463: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7277d4700 of size 256
2018-02-05 20:06:23.961467: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7277d4800 of size 38400
2018-02-05 20:06:23.961472: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7277dde00 of size 3276800
2018-02-05 20:06:23.961477: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x727afde00 of size 13107200
2018-02-05 20:06:23.961481: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72877de00 of size 16777216
2018-02-05 20:06:23.961486: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72977de00 of size 75497472
2018-02-05 20:06:23.961491: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72df7de00 of size 75497472
2018-02-05 20:06:23.961495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73277de00 of size 16777216
2018-02-05 20:06:23.961500: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73377de00 of size 8388608
2018-02-05 20:06:23.961505: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733f7de00 of size 75497472
2018-02-05 20:06:23.961509: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73877de00 of size 18874368
2018-02-05 20:06:23.961514: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73997de00 of size 4718592
2018-02-05 20:06:23.961519: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739dfde00 of size 1179648
2018-02-05 20:06:23.961523: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739f1de00 of size 3276800
2018-02-05 20:06:23.961528: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73a23de00 of size 13107200
2018-02-05 20:06:23.961533: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73aebde00 of size 16777216
2018-02-05 20:06:23.961537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73bebde00 of size 8388608
2018-02-05 20:06:23.961542: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73c6bde00 of size 75497472
2018-02-05 20:06:23.961547: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x740ebde00 of size 18874368
2018-02-05 20:06:23.961551: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7420bde00 of size 4718592
2018-02-05 20:06:23.961556: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74253de00 of size 1179648
2018-02-05 20:06:23.961561: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74265de00 of size 393216
2018-02-05 20:06:23.961565: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426bde00 of size 256
2018-02-05 20:06:23.961570: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426bdf00 of size 256
2018-02-05 20:06:23.961575: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426be000 of size 256
2018-02-05 20:06:23.961579: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426be100 of size 38400
2018-02-05 20:06:23.961584: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426c7700 of size 256
2018-02-05 20:06:23.961588: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426c7800 of size 256
2018-02-05 20:06:23.961593: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426c7900 of size 512
2018-02-05 20:06:23.961598: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7426c7b00 of size 1048576
2018-02-05 20:06:23.961603: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac7b00 of size 2048
2018-02-05 20:06:23.961607: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac8300 of size 1024
2018-02-05 20:06:23.961612: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac8700 of size 256
2018-02-05 20:06:23.961617: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac8800 of size 256
2018-02-05 20:06:23.961621: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac8900 of size 256
2018-02-05 20:06:23.961626: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ac8a00 of size 34560
2018-02-05 20:06:23.961631: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ad1100 of size 2048
2018-02-05 20:06:23.961635: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ad1900 of size 512
2018-02-05 20:06:23.961640: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ad1b00 of size 6400
2018-02-05 20:06:23.961645: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ad3400 of size 65536
2018-02-05 20:06:23.961649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ae3400 of size 8192
2018-02-05 20:06:23.961654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ae5400 of size 256
2018-02-05 20:06:23.961659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ae5500 of size 512
2018-02-05 20:06:23.961663: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ae5700 of size 1280
2018-02-05 20:06:23.961668: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742ae5c00 of size 38400
2018-02-05 20:06:23.961672: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742aef200 of size 512
2018-02-05 20:06:23.961677: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742aef400 of size 1024
2018-02-05 20:06:23.961682: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742aef800 of size 2048
2018-02-05 20:06:23.961686: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742af0000 of size 65536
2018-02-05 20:06:23.961691: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b00000 of size 8192
2018-02-05 20:06:23.961696: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b02000 of size 4096
2018-02-05 20:06:23.961700: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b03000 of size 2048
2018-02-05 20:06:23.961705: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b03800 of size 19200
2018-02-05 20:06:23.961709: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b08300 of size 4096
2018-02-05 20:06:23.961714: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742b2ac00 of size 3276800
2018-02-05 20:06:23.961719: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742e4ac00 of size 1024
2018-02-05 20:06:23.961724: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742e4b000 of size 405760
2018-02-05 20:06:23.961728: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742eae100 of size 13107200
2018-02-05 20:06:23.961733: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x743b2e100 of size 2097152
2018-02-05 20:06:23.961738: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x743d2e100 of size 524288
2018-02-05 20:06:23.961743: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x743dae100 of size 1572864
2018-02-05 20:06:23.961748: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x743f2e100 of size 16777216
2018-02-05 20:06:23.961752: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x744f2e100 of size 8388608
2018-02-05 20:06:23.961757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74572e100 of size 75497472
2018-02-05 20:06:23.961761: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x749f2e100 of size 18874368
2018-02-05 20:06:23.961766: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74b12e100 of size 4718592
2018-02-05 20:06:23.961771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74b5ae100 of size 4194304
2018-02-05 20:06:23.961776: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74b9ae100 of size 1179648
2018-02-05 20:06:23.961780: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74bace100 of size 1048576
2018-02-05 20:06:23.961785: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74bbce100 of size 4460544
2018-02-05 20:06:23.961790: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74c00f100 of size 13107200
2018-02-05 20:06:23.961794: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74cc8f100 of size 16777216
2018-02-05 20:06:23.961799: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74dc8f100 of size 8388608
2018-02-05 20:06:23.961804: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74e48f100 of size 1179648
2018-02-05 20:06:23.961808: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74e5af100 of size 524288
2018-02-05 20:06:23.961813: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74e62f100 of size 663552
2018-02-05 20:06:23.961818: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74e6d1100 of size 75497472
2018-02-05 20:06:23.961822: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x753b51100 of size 18874368
2018-02-05 20:06:23.961827: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x754d51100 of size 4718592
2018-02-05 20:06:23.961833: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x7427c7b00 of size 3145728
2018-02-05 20:06:23.961838: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x742b09300 of size 137472
2018-02-05 20:06:23.961843: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x752ed1100 of size 13107200
2018-02-05 20:06:23.961848: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x7551d1100 of size 66711296
2018-02-05 20:06:23.961852: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-02-05 20:06:23.961859: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 113 Chunks of size 256 totalling 28.2KiB
2018-02-05 20:06:23.961865: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 512 totalling 8.0KiB
2018-02-05 20:06:23.961870: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 1024 totalling 16.0KiB
2018-02-05 20:06:23.961875: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1280 totalling 2.5KiB
2018-02-05 20:06:23.961880: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 17 Chunks of size 2048 totalling 34.0KiB
2018-02-05 20:06:23.961886: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 10 Chunks of size 4096 totalling 40.0KiB
2018-02-05 20:06:23.961891: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 6400 totalling 6.2KiB
2018-02-05 20:06:23.961896: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 8192 totalling 72.0KiB
2018-02-05 20:06:23.961901: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 19200 totalling 168.8KiB
2018-02-05 20:06:23.961907: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 34560 totalling 33.8KiB
2018-02-05 20:06:23.961912: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 38400 totalling 337.5KiB
2018-02-05 20:06:23.961917: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 65536 totalling 576.0KiB
2018-02-05 20:06:23.961923: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 393216 totalling 384.0KiB
2018-02-05 20:06:23.961928: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 405760 totalling 396.2KiB
2018-02-05 20:06:23.961933: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 524288 totalling 1.00MiB
2018-02-05 20:06:23.961938: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 663552 totalling 648.0KiB
2018-02-05 20:06:23.961943: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 781056 totalling 762.8KiB
2018-02-05 20:06:23.961949: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 1048576 totalling 2.00MiB
2018-02-05 20:06:23.961954: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 1179648 totalling 10.12MiB
2018-02-05 20:06:23.961959: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1572864 totalling 1.50MiB
2018-02-05 20:06:23.961964: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 2 Chunks of size 2097152 totalling 4.00MiB
2018-02-05 20:06:23.961969: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 3276800 totalling 21.88MiB
2018-02-05 20:06:23.961975: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 4194304 totalling 4.00MiB
2018-02-05 20:06:23.961979: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 4460544 totalling 4.25MiB
2018-02-05 20:06:23.961985: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 10 Chunks of size 4718592 totalling 45.00MiB
2018-02-05 20:06:23.961990: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 8388608 totalling 72.00MiB
2018-02-05 20:06:23.961995: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 13107200 totalling 100.00MiB
2018-02-05 20:06:23.962001: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 16777216 totalling 144.00MiB
2018-02-05 20:06:23.962006: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 11 Chunks of size 18874368 totalling 198.00MiB
2018-02-05 20:06:23.962011: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 21364736 totalling 20.38MiB
2018-02-05 20:06:23.962017: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 9 Chunks of size 75497472 totalling 648.00MiB
2018-02-05 20:06:23.962022: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 1.25GiB
2018-02-05 20:06:23.962029: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                  1424818176
InUse:                  1341716480
MaxInUse:               1423373312
NumAllocs:                     729
MaxAllocSize:            437068288

2018-02-05 20:06:23.962050: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ************************************************************************************************____
2018-02-05 20:06:23.962064: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[2048,1024,3,3]
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2048,1024,3,3]
	 [[Node: model_1/conv2d_4/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_1/reshape_1/Reshape, conv2d_4/kernel/read)]]
	 [[Node: loss_1/mul/_411 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss_1/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/tuw/Desktop/fake/faceswap/scripts/train.py"", line 139, in processThread
    trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
  File ""/home/tuw/Desktop/fake/faceswap/lib/ModelAE.py"", line 54, in train_one_step
    loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 1849, in train_on_batch
    outputs = self.train_function(ins)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2475, in __call__
    **self.session_kwargs)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[2048,1024,3,3]
	 [[Node: model_1/conv2d_4/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_1/reshape_1/Reshape, conv2d_4/kernel/read)]]
	 [[Node: loss_1/mul/_411 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss_1/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'model_1/conv2d_4/convolution', defined at:
  File ""/usr/lib/python3.5/threading.py"", line 882, in _bootstrap
    self._bootstrap_inner()
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/tuw/Desktop/fake/faceswap/scripts/train.py"", line 122, in processThread
    model = PluginLoader.get_model(trainer)(self.arguments.model_dir)
  File ""/home/tuw/Desktop/fake/faceswap/lib/ModelAE.py"", line 20, in __init__
    self.initModel()
  File ""/home/tuw/Desktop/fake/faceswap/plugins/Model_LowMem.py"", line 20, in initModel
    self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 617, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2078, in call
    output_tensors, _, _ = self.run_internal_graph(inputs, masks)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/topology.py"", line 2229, in run_internal_graph
    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/layers/convolutional.py"", line 168, in call
    dilation_rate=self.dilation_rate)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 3332, in conv2d
    data_format=tf_data_format)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 751, in convolution
    return op(input, filter)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 835, in __call__
    return self.conv_op(inp, filter)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 499, in __call__
    return self.call(inp, filter)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py"", line 187, in __call__
    name=self.name)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 631, in conv2d
    data_format=data_format, name=name)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,1024,3,3]
	 [[Node: model_1/conv2d_4/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](model_1/reshape_1/Reshape, conv2d_4/kernel/read)]]
	 [[Node: loss_1/mul/_411 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss_1/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]


```",friendly please attach thanks tried get error python train model directory model directory training data directory loading data may take loading model live preview conversion second argument float future float import loading training data unable open file unable open file name error message file directory loading trainer starting press enter stop training save model binary use successful node read negative value must least one node node zero found device name major minor device device name bus id compute capability allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate current allocation summary bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin chunk state chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size free size free size free size free size summary size size size size size size size size size size size size size size size size size size size size size size size size size size size size size size size size sum total limit resource exhausted tensor shape exception thread recent call last file line return file line status file line tensor shape node node handling exception another exception recent call last file line file line run file line epoch else none file line file line file line file line run file line file line file line raise type message tensor shape node node defined file line file line file line run file line model trainer file line file line file line output file line call file line file line call file line file line convolution return input filter file line return filter file line return filter file line file line file line file line file line see tensor shape node node,issue,positive,negative,neutral,neutral,negative,negative
363146045,"Hi, I'm using an nvidia gtx 760 with slightly less than 2GB (1.99x).
It's working for me if
1) Everything else is closed (web browser, ...)
2) With the following patch applied:
```
diff --git a/plugins/Model_LowMem.py b/plugins/Model_LowMem.py
index eda931e..ac7a40d 100644
--- a/plugins/Model_LowMem.py
+++ b/plugins/Model_LowMem.py
@@ -10,7 +10,7 @@ from lib.ModelAE import ModelAE, TrainerAE
 from lib.PixelShuffler import PixelShuffler
 
 IMAGE_SHAPE = (64, 64, 3)
-ENCODER_DIM = 512
+ENCODER_DIM = 128
 
 class Model(ModelAE):
     def initModel(self):
```
3) using this command line:
```
KERAS_BACKEND=tensorflow python faceswap.py train -A ... -B ... -m ... -p -v -t LowMem -bs 16
```
using batchsize=32 works for a couple of minutes and then crashes.",hi slightly le working everything else closed web browser following patch applied git index import import class model self command line python train work couple,issue,negative,negative,neutral,neutral,negative,negative
363144601,"I have little to no experience in computer vision and python, so I don't know whether my search results would be useful. And sorry but I currently have no hard determination to contribute a lot to the project. I am just a user with programming background and a bit of knowledge about machine learning and opencv.

Face direction: 
https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/

Eye open/close detection: (the technique seems to be applicable for mouth too)
https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/",little experience computer vision python know whether search would useful sorry currently hard determination contribute lot project user background bit knowledge machine learning face direction eye detection technique applicable mouth,issue,positive,negative,negative,negative,negative,negative
363143014,"How can I add a license for someone else's code?  The license needs to come from the original author.  If they didn't choose one already, they can use [this](https://choosealicense.com/) to pick one.

I see this is covered by #65",add license someone else code license need come original author choose one already use pick one see covered,issue,negative,positive,positive,positive,positive,positive
363141248,"I've added
```
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list=""0""
set_session(tf.Session(config=config))
``` in Model_LowMem.py but i still have errors. :cry: 

```
python3 faceswap.py train -A '/home/tuw/Desktop/faceswap_/data/trump1' -B '/home/tuw/Desktop/faceswap_/data/cage' -m '/home/tuw/Desktop/faceswap_/data/model' -t LowMem
Model A Directory: /home/tuw/Desktop/faceswap_/data/trump1
Model B Directory: /home/tuw/Desktop/faceswap_/data/cage
Training data directory: /home/tuw/Desktop/faceswap_/data/model
Loading data, this may take a while...
Loading Model from Model_LowMem plugin...
/home/tuw/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Failed loading existing training data.
Unable to open file (unable to open file: name = '/home/tuw/Desktop/faceswap_/data/model/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
Loading Trainer from Model_LowMem plugin...
Starting. Press ""Enter"" to stop training and save model
2018-02-05 19:28:58.599409: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-05 19:28:58.600185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-02-05 19:28:58.600750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce 840M major: 5 minor: 0 memoryClockRate(GHz): 1.124
pciBusID: 0000:07:00.0
totalMemory: 1.96GiB freeMemory: 1.47GiB
2018-02-05 19:28:58.600789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce 840M, pci bus id: 0000:07:00.0, compute capability: 5.0)
2018-02-05 19:29:00.675353: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.75MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-02-05 19:29:10.098385: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 72.00MiB.  Current allocation summary follows.
2018-02-05 19:29:10.098437: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 76, Chunks in use: 75. 19.0KiB allocated for chunks. 18.8KiB in use in bin. 604B client-requested in use in bin.
2018-02-05 19:29:10.098450: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098459: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 12, Chunks in use: 12. 12.2KiB allocated for chunks. 12.2KiB in use in bin. 12.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098467: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 16, Chunks in use: 16. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098474: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 7, Chunks in use: 6. 31.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098482: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 5, Chunks in use: 5. 40.0KiB allocated for chunks. 40.0KiB in use in bin. 40.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098490: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 6, Chunks in use: 6. 112.5KiB allocated for chunks. 112.5KiB in use in bin. 112.5KiB client-requested in use in bin.
2018-02-05 19:29:10.098497: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 4, Chunks in use: 4. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098505: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 384.0KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.
2018-02-05 19:29:10.098512: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.098518: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.098525: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 1, Chunks in use: 0. 1005.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.098533: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 5, Chunks in use: 5. 5.62MiB allocated for chunks. 5.62MiB in use in bin. 5.62MiB client-requested in use in bin.
2018-02-05 19:29:10.098541: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 7, Chunks in use: 7. 20.62MiB allocated for chunks. 20.62MiB in use in bin. 19.75MiB client-requested in use in bin.
2018-02-05 19:29:10.098549: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 8, Chunks in use: 8. 36.50MiB allocated for chunks. 36.50MiB in use in bin. 33.12MiB client-requested in use in bin.
2018-02-05 19:29:10.098557: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 5, Chunks in use: 5. 62.50MiB allocated for chunks. 62.50MiB in use in bin. 62.50MiB client-requested in use in bin.
2018-02-05 19:29:10.098564: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 108.00MiB allocated for chunks. 108.00MiB in use in bin. 102.50MiB client-requested in use in bin.
2018-02-05 19:29:10.098572: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 9, Chunks in use: 9. 294.19MiB allocated for chunks. 294.19MiB in use in bin. 274.00MiB client-requested in use in bin.
2018-02-05 19:29:10.098580: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 11, Chunks in use: 11. 752.00MiB allocated for chunks. 752.00MiB in use in bin. 744.00MiB client-requested in use in bin.
2018-02-05 19:29:10.098586: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.098593: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.098600: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 72.00MiB was 64.00MiB, Chunk State: 
2018-02-05 19:29:10.098607: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0000 of size 1280
2018-02-05 19:29:10.098612: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0500 of size 256
2018-02-05 19:29:10.098617: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0600 of size 256
2018-02-05 19:29:10.098622: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0700 of size 512
2018-02-05 19:29:10.098627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0900 of size 256
2018-02-05 19:29:10.098632: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0a00 of size 256
2018-02-05 19:29:10.098637: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0b00 of size 1024
2018-02-05 19:29:10.098642: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0f00 of size 256
2018-02-05 19:29:10.098647: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1000 of size 256
2018-02-05 19:29:10.098653: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1100 of size 2048
2018-02-05 19:29:10.098657: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1900 of size 256
2018-02-05 19:29:10.098662: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1a00 of size 256
2018-02-05 19:29:10.098668: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1b00 of size 256
2018-02-05 19:29:10.098673: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1c00 of size 256
2018-02-05 19:29:10.098679: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1d00 of size 65536
2018-02-05 19:29:10.098683: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1d00 of size 256
2018-02-05 19:29:10.098688: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1e00 of size 256
2018-02-05 19:29:10.098693: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1f00 of size 8192
2018-02-05 19:29:10.098698: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b3f00 of size 256
2018-02-05 19:29:10.098703: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4000 of size 256
2018-02-05 19:29:10.098708: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4100 of size 4096
2018-02-05 19:29:10.098712: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5100 of size 256
2018-02-05 19:29:10.098717: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5200 of size 256
2018-02-05 19:29:10.098722: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5300 of size 256
2018-02-05 19:29:10.098727: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5400 of size 256
2018-02-05 19:29:10.098732: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5500 of size 256
2018-02-05 19:29:10.098737: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5600 of size 256
2018-02-05 19:29:10.098742: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5700 of size 256
2018-02-05 19:29:10.098747: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5800 of size 256
2018-02-05 19:29:10.098752: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5900 of size 256
2018-02-05 19:29:10.098757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5a00 of size 256
2018-02-05 19:29:10.098762: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5b00 of size 256
2018-02-05 19:29:10.098767: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5c00 of size 256
2018-02-05 19:29:10.098772: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5d00 of size 38400
2018-02-05 19:29:10.098776: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042bf300 of size 3276800
2018-02-05 19:29:10.098781: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7045df300 of size 13107200
2018-02-05 19:29:10.098786: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70525f300 of size 67108864
2018-02-05 19:29:10.098792: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70925f300 of size 33554432
2018-02-05 19:29:10.098797: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70b25f300 of size 75497472
2018-02-05 19:29:10.098802: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70fa5f300 of size 18874368
2018-02-05 19:29:10.098807: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x710c5f300 of size 4718592
2018-02-05 19:29:10.098812: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7110df300 of size 1179648
2018-02-05 19:29:10.098817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7111ff300 of size 19200
2018-02-05 19:29:10.098822: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711203e00 of size 19200
2018-02-05 19:29:10.098827: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711208900 of size 19200
2018-02-05 19:29:10.098832: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d400 of size 512
2018-02-05 19:29:10.098837: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d600 of size 1179648
2018-02-05 19:29:10.098842: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71132d600 of size 2097152
2018-02-05 19:29:10.098847: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152d600 of size 1024
2018-02-05 19:29:10.098852: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152da00 of size 4718592
2018-02-05 19:29:10.098857: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7119ada00 of size 3145728
2018-02-05 19:29:10.098862: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711cada00 of size 5242880
2018-02-05 19:29:10.098867: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ada00 of size 2048
2018-02-05 19:29:10.098871: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ae200 of size 33554432
2018-02-05 19:29:10.098876: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7141ae200 of size 33554432
2018-02-05 19:29:10.098881: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161ae200 of size 2048
2018-02-05 19:29:10.098886: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161aea00 of size 33554432
2018-02-05 19:29:10.098891: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181aea00 of size 65536
2018-02-05 19:29:10.098896: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181bea00 of size 75497472
2018-02-05 19:29:10.098901: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9bea00 of size 8192
2018-02-05 19:29:10.098906: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9c0a00 of size 18874368
2018-02-05 19:29:10.098911: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71dbc0a00 of size 18874368
2018-02-05 19:29:10.098916: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc0a00 of size 4096
2018-02-05 19:29:10.098921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc1a00 of size 4718592
2018-02-05 19:29:10.098926: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f241a00 of size 4718592
2018-02-05 19:29:10.098931: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c1a00 of size 2048
2018-02-05 19:29:10.098936: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c2200 of size 1179648
2018-02-05 19:29:10.098941: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7e2200 of size 65536
2018-02-05 19:29:10.098946: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f2200 of size 19200
2018-02-05 19:29:10.098951: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f6d00 of size 65536
2018-02-05 19:29:10.098956: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902200 of size 1024
2018-02-05 19:29:10.098961: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902600 of size 256
2018-02-05 19:29:10.098966: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902700 of size 256
2018-02-05 19:29:10.098971: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902800 of size 256
2018-02-05 19:29:10.098976: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902900 of size 256
2018-02-05 19:29:10.098981: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902a00 of size 256
2018-02-05 19:29:10.098986: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902b00 of size 256
2018-02-05 19:29:10.098991: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902c00 of size 256
2018-02-05 19:29:10.098996: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902d00 of size 256
2018-02-05 19:29:10.099002: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902e00 of size 256
2018-02-05 19:29:10.099006: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902f00 of size 256
2018-02-05 19:29:10.099011: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903000 of size 256
2018-02-05 19:29:10.099016: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903100 of size 256
2018-02-05 19:29:10.099021: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903200 of size 256
2018-02-05 19:29:10.099027: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903300 of size 256
2018-02-05 19:29:10.099032: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903500 of size 256
2018-02-05 19:29:10.099037: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903600 of size 256
2018-02-05 19:29:10.099042: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903700 of size 256
2018-02-05 19:29:10.099047: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903800 of size 1024
2018-02-05 19:29:10.099052: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903c00 of size 2048
2018-02-05 19:29:10.099057: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904400 of size 2048
2018-02-05 19:29:10.099062: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904c00 of size 8192
2018-02-05 19:29:10.099067: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f906c00 of size 4096
2018-02-05 19:29:10.099072: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f907c00 of size 2048
2018-02-05 19:29:10.099077: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908400 of size 1024
2018-02-05 19:29:10.099082: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908800 of size 256
2018-02-05 19:29:10.099086: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908900 of size 256
2018-02-05 19:29:10.099091: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908a00 of size 1024
2018-02-05 19:29:10.099096: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908e00 of size 2048
2018-02-05 19:29:10.099101: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909600 of size 2048
2018-02-05 19:29:10.099106: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909e00 of size 256
2018-02-05 19:29:10.099111: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909f00 of size 256
2018-02-05 19:29:10.099117: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bc00 of size 256
2018-02-05 19:29:10.099122: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bd00 of size 256
2018-02-05 19:29:10.099127: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90be00 of size 4096
2018-02-05 19:29:10.099132: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90ce00 of size 256
2018-02-05 19:29:10.099137: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90cf00 of size 256
2018-02-05 19:29:10.099142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d000 of size 2048
2018-02-05 19:29:10.099147: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d800 of size 256
2018-02-05 19:29:10.099152: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d900 of size 256
2018-02-05 19:29:10.099157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90da00 of size 256
2018-02-05 19:29:10.099162: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90db00 of size 1024
2018-02-05 19:29:10.099168: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90df00 of size 256
2018-02-05 19:29:10.099173: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e000 of size 256
2018-02-05 19:29:10.099178: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e100 of size 256
2018-02-05 19:29:10.099183: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e200 of size 256
2018-02-05 19:29:10.099188: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e300 of size 256
2018-02-05 19:29:10.099193: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e400 of size 256
2018-02-05 19:29:10.099198: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e500 of size 38400
2018-02-05 19:29:10.099203: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917b00 of size 512
2018-02-05 19:29:10.099208: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917d00 of size 256
2018-02-05 19:29:10.099213: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917e00 of size 3276800
2018-02-05 19:29:10.099217: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc37e00 of size 1024
2018-02-05 19:29:10.099222: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38200 of size 256
2018-02-05 19:29:10.099228: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38300 of size 13107200
2018-02-05 19:29:10.099233: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8300 of size 2048
2018-02-05 19:29:10.099238: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8b00 of size 67108864
2018-02-05 19:29:10.099243: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b8b00 of size 2048
2018-02-05 19:29:10.099248: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9300 of size 256
2018-02-05 19:29:10.099252: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9400 of size 33554432
2018-02-05 19:29:10.099257: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268b9400 of size 65536
2018-02-05 19:29:10.099262: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268c9400 of size 75497472
2018-02-05 19:29:10.099267: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0c9400 of size 8192
2018-02-05 19:29:10.099272: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0cb400 of size 18874368
2018-02-05 19:29:10.099277: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cb400 of size 4096
2018-02-05 19:29:10.099282: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc400 of size 256
2018-02-05 19:29:10.099287: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc500 of size 4718592
2018-02-05 19:29:10.099291: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74c500 of size 2048
2018-02-05 19:29:10.099296: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74cd00 of size 1179648
2018-02-05 19:29:10.099301: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86cd00 of size 1024
2018-02-05 19:29:10.099306: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86d100 of size 19200
2018-02-05 19:29:10.099311: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c871c00 of size 19200
2018-02-05 19:29:10.099316: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876700 of size 256
2018-02-05 19:29:10.099321: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876800 of size 256
2018-02-05 19:29:10.099326: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876900 of size 38400
2018-02-05 19:29:10.099331: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c87ff00 of size 256
2018-02-05 19:29:10.099336: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880000 of size 512
2018-02-05 19:29:10.099342: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880200 of size 3276800
2018-02-05 19:29:10.099347: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0200 of size 256
2018-02-05 19:29:10.099352: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0300 of size 1024
2018-02-05 19:29:10.099357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0700 of size 256
2018-02-05 19:29:10.099362: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0800 of size 13107200
2018-02-05 19:29:10.099367: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d820800 of size 2048
2018-02-05 19:29:10.099372: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821000 of size 256
2018-02-05 19:29:10.099377: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821100 of size 67108864
2018-02-05 19:29:10.099382: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821100 of size 2048
2018-02-05 19:29:10.099387: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821900 of size 33554432
2018-02-05 19:29:10.099392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821900 of size 256
2018-02-05 19:29:10.099397: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821a00 of size 65536
2018-02-05 19:29:10.099402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831a00 of size 256
2018-02-05 19:29:10.099406: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831b00 of size 75497472
2018-02-05 19:29:10.099412: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738031b00 of size 8192
2018-02-05 19:29:10.099417: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033b00 of size 256
2018-02-05 19:29:10.099422: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033c00 of size 18874368
2018-02-05 19:29:10.099427: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739233c00 of size 4096
2018-02-05 19:29:10.099432: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739234c00 of size 4718592
2018-02-05 19:29:10.099437: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4c00 of size 256
2018-02-05 19:29:10.099442: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4d00 of size 2048
2018-02-05 19:29:10.099447: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b5500 of size 1179648
2018-02-05 19:29:10.099452: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5500 of size 1024
2018-02-05 19:29:10.099457: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5900 of size 256
2018-02-05 19:29:10.099462: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5a00 of size 38400
2018-02-05 19:29:10.099467: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397df000 of size 3276800
2018-02-05 19:29:10.099472: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739aff000 of size 13107200
2018-02-05 19:29:10.099477: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73a77f000 of size 67108864
2018-02-05 19:29:10.099482: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73e77f000 of size 75497472
2018-02-05 19:29:10.099487: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742f7f000 of size 75497472
2018-02-05 19:29:10.099492: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74777f000 of size 18874368
2018-02-05 19:29:10.099497: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74897f000 of size 4718592
2018-02-05 19:29:10.099502: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x748dff000 of size 3276800
2018-02-05 19:29:10.099507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74911f000 of size 13107200
2018-02-05 19:29:10.099512: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x749d9f000 of size 67108864
2018-02-05 19:29:10.099517: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74dd9f000 of size 33554432
2018-02-05 19:29:10.099522: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74fd9f000 of size 33554432
2018-02-05 19:29:10.099527: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x751d9f000 of size 40046592
2018-02-05 19:29:10.099532: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f806d00 of size 1029376
2018-02-05 19:29:10.099538: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f903400 of size 256
2018-02-05 19:29:10.099543: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f90a000 of size 7168
2018-02-05 19:29:10.099549: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-02-05 19:29:10.099555: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 75 Chunks of size 256 totalling 18.8KiB
2018-02-05 19:29:10.099561: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 512 totalling 2.0KiB
2018-02-05 19:29:10.099567: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 11 Chunks of size 1024 totalling 11.0KiB
2018-02-05 19:29:10.099572: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2018-02-05 19:29:10.099578: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 2048 totalling 32.0KiB
2018-02-05 19:29:10.099584: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 4096 totalling 24.0KiB
2018-02-05 19:29:10.099590: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 8192 totalling 40.0KiB
2018-02-05 19:29:10.099595: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 19200 totalling 112.5KiB
2018-02-05 19:29:10.099601: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 38400 totalling 150.0KiB
2018-02-05 19:29:10.099607: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 65536 totalling 384.0KiB
2018-02-05 19:29:10.099612: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 1179648 totalling 5.62MiB
2018-02-05 19:29:10.099618: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2097152 totalling 2.00MiB
2018-02-05 19:29:10.099623: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3145728 totalling 3.00MiB
2018-02-05 19:29:10.099629: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 3276800 totalling 15.62MiB
2018-02-05 19:29:10.099635: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 4718592 totalling 31.50MiB
2018-02-05 19:29:10.099641: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5242880 totalling 5.00MiB
2018-02-05 19:29:10.099646: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 13107200 totalling 62.50MiB
2018-02-05 19:29:10.099652: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 18874368 totalling 108.00MiB
2018-02-05 19:29:10.099658: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 33554432 totalling 256.00MiB
2018-02-05 19:29:10.099664: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 40046592 totalling 38.19MiB
2018-02-05 19:29:10.099670: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 67108864 totalling 320.00MiB
2018-02-05 19:29:10.099675: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 75497472 totalling 432.00MiB
2018-02-05 19:29:10.099681: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 1.25GiB
2018-02-05 19:29:10.099688: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                  1343422464
InUse:                  1342385664
MaxInUse:               1342385664
NumAllocs:                     209
MaxAllocSize:             75497472

2018-02-05 19:29:10.099706: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ****************************************************************************************************
2018-02-05 19:29:10.099720: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,1024,2048]
2018-02-05 19:29:10.675625: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.00MiB.  Current allocation summary follows.
2018-02-05 19:29:10.675677: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 76, Chunks in use: 75. 19.0KiB allocated for chunks. 18.8KiB in use in bin. 604B client-requested in use in bin.
2018-02-05 19:29:10.675688: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675697: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 12, Chunks in use: 12. 12.2KiB allocated for chunks. 12.2KiB in use in bin. 12.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675705: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 16, Chunks in use: 16. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675713: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 7, Chunks in use: 6. 31.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675720: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675728: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 6, Chunks in use: 6. 112.5KiB allocated for chunks. 112.5KiB in use in bin. 112.5KiB client-requested in use in bin.
2018-02-05 19:29:10.675736: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 4, Chunks in use: 4. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675743: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 384.0KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.
2018-02-05 19:29:10.675750: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.675757: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.675763: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 1, Chunks in use: 0. 997.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.675770: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 5, Chunks in use: 5. 5.62MiB allocated for chunks. 5.62MiB in use in bin. 5.62MiB client-requested in use in bin.
2018-02-05 19:29:10.675778: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 7, Chunks in use: 7. 20.62MiB allocated for chunks. 20.62MiB in use in bin. 19.75MiB client-requested in use in bin.
2018-02-05 19:29:10.675786: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 8, Chunks in use: 8. 36.50MiB allocated for chunks. 36.50MiB in use in bin. 33.12MiB client-requested in use in bin.
2018-02-05 19:29:10.675793: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 5, Chunks in use: 5. 62.50MiB allocated for chunks. 62.50MiB in use in bin. 62.50MiB client-requested in use in bin.
2018-02-05 19:29:10.675800: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 108.00MiB allocated for chunks. 108.00MiB in use in bin. 102.50MiB client-requested in use in bin.
2018-02-05 19:29:10.675808: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 9, Chunks in use: 9. 294.19MiB allocated for chunks. 294.19MiB in use in bin. 274.00MiB client-requested in use in bin.
2018-02-05 19:29:10.675816: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 11, Chunks in use: 11. 752.00MiB allocated for chunks. 752.00MiB in use in bin. 744.00MiB client-requested in use in bin.
2018-02-05 19:29:10.675822: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.675828: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:10.675835: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 32.00MiB was 32.00MiB, Chunk State: 
2018-02-05 19:29:10.675842: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0000 of size 1280
2018-02-05 19:29:10.675847: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0500 of size 256
2018-02-05 19:29:10.675852: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0600 of size 256
2018-02-05 19:29:10.675857: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0700 of size 512
2018-02-05 19:29:10.675862: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0900 of size 256
2018-02-05 19:29:10.675867: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0a00 of size 256
2018-02-05 19:29:10.675871: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0b00 of size 1024
2018-02-05 19:29:10.675875: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0f00 of size 256
2018-02-05 19:29:10.675879: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1000 of size 256
2018-02-05 19:29:10.675884: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1100 of size 2048
2018-02-05 19:29:10.675887: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1900 of size 256
2018-02-05 19:29:10.675892: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1a00 of size 256
2018-02-05 19:29:10.675896: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1b00 of size 256
2018-02-05 19:29:10.675900: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1c00 of size 256
2018-02-05 19:29:10.675905: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1d00 of size 65536
2018-02-05 19:29:10.675909: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1d00 of size 256
2018-02-05 19:29:10.675912: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1e00 of size 256
2018-02-05 19:29:10.675917: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1f00 of size 8192
2018-02-05 19:29:10.675921: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b3f00 of size 256
2018-02-05 19:29:10.675925: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4000 of size 256
2018-02-05 19:29:10.675930: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4100 of size 4096
2018-02-05 19:29:10.675935: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5100 of size 256
2018-02-05 19:29:10.675939: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5200 of size 256
2018-02-05 19:29:10.675944: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5300 of size 256
2018-02-05 19:29:10.675949: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5400 of size 256
2018-02-05 19:29:10.675953: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5500 of size 256
2018-02-05 19:29:10.675958: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5600 of size 256
2018-02-05 19:29:10.675963: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5700 of size 256
2018-02-05 19:29:10.675968: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5800 of size 256
2018-02-05 19:29:10.675973: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5900 of size 256
2018-02-05 19:29:10.675977: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5a00 of size 256
2018-02-05 19:29:10.675982: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5b00 of size 256
2018-02-05 19:29:10.675987: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5c00 of size 256
2018-02-05 19:29:10.675992: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5d00 of size 38400
2018-02-05 19:29:10.675997: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042bf300 of size 3276800
2018-02-05 19:29:10.676002: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7045df300 of size 13107200
2018-02-05 19:29:10.676007: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70525f300 of size 67108864
2018-02-05 19:29:10.676012: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70925f300 of size 33554432
2018-02-05 19:29:10.676017: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70b25f300 of size 75497472
2018-02-05 19:29:10.676022: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70fa5f300 of size 18874368
2018-02-05 19:29:10.676027: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x710c5f300 of size 4718592
2018-02-05 19:29:10.676032: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7110df300 of size 1179648
2018-02-05 19:29:10.676037: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7111ff300 of size 19200
2018-02-05 19:29:10.676042: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711203e00 of size 19200
2018-02-05 19:29:10.676047: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711208900 of size 19200
2018-02-05 19:29:10.676051: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d400 of size 512
2018-02-05 19:29:10.676056: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d600 of size 1179648
2018-02-05 19:29:10.676061: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71132d600 of size 2097152
2018-02-05 19:29:10.676066: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152d600 of size 1024
2018-02-05 19:29:10.676071: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152da00 of size 4718592
2018-02-05 19:29:10.676076: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7119ada00 of size 3145728
2018-02-05 19:29:10.676081: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711cada00 of size 5242880
2018-02-05 19:29:10.676085: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ada00 of size 2048
2018-02-05 19:29:10.676090: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ae200 of size 33554432
2018-02-05 19:29:10.676095: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7141ae200 of size 33554432
2018-02-05 19:29:10.676100: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161ae200 of size 2048
2018-02-05 19:29:10.676104: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161aea00 of size 33554432
2018-02-05 19:29:10.676109: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181aea00 of size 65536
2018-02-05 19:29:10.676114: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181bea00 of size 75497472
2018-02-05 19:29:10.676119: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9bea00 of size 8192
2018-02-05 19:29:10.676123: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9c0a00 of size 18874368
2018-02-05 19:29:10.676128: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71dbc0a00 of size 18874368
2018-02-05 19:29:10.676133: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc0a00 of size 4096
2018-02-05 19:29:10.676138: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc1a00 of size 4718592
2018-02-05 19:29:10.676142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f241a00 of size 4718592
2018-02-05 19:29:10.676147: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c1a00 of size 2048
2018-02-05 19:29:10.676152: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c2200 of size 1179648
2018-02-05 19:29:10.676157: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7e2200 of size 65536
2018-02-05 19:29:10.676161: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f2200 of size 19200
2018-02-05 19:29:10.676166: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f6d00 of size 65536
2018-02-05 19:29:10.676171: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f806d00 of size 8192
2018-02-05 19:29:10.676176: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902200 of size 1024
2018-02-05 19:29:10.676180: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902600 of size 256
2018-02-05 19:29:10.676185: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902700 of size 256
2018-02-05 19:29:10.676190: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902800 of size 256
2018-02-05 19:29:10.676195: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902900 of size 256
2018-02-05 19:29:10.676200: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902a00 of size 256
2018-02-05 19:29:10.676204: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902b00 of size 256
2018-02-05 19:29:10.676209: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902c00 of size 256
2018-02-05 19:29:10.676214: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902d00 of size 256
2018-02-05 19:29:10.676218: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902e00 of size 256
2018-02-05 19:29:10.676223: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902f00 of size 256
2018-02-05 19:29:10.676228: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903000 of size 256
2018-02-05 19:29:10.676233: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903100 of size 256
2018-02-05 19:29:10.676237: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903200 of size 256
2018-02-05 19:29:10.676242: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903300 of size 256
2018-02-05 19:29:10.676247: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903500 of size 256
2018-02-05 19:29:10.676252: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903600 of size 256
2018-02-05 19:29:10.676256: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903700 of size 256
2018-02-05 19:29:10.676261: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903800 of size 1024
2018-02-05 19:29:10.676266: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903c00 of size 2048
2018-02-05 19:29:10.676271: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904400 of size 2048
2018-02-05 19:29:10.676275: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904c00 of size 8192
2018-02-05 19:29:10.676280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f906c00 of size 4096
2018-02-05 19:29:10.676285: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f907c00 of size 2048
2018-02-05 19:29:10.676290: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908400 of size 1024
2018-02-05 19:29:10.676294: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908800 of size 256
2018-02-05 19:29:10.676299: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908900 of size 256
2018-02-05 19:29:10.676304: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908a00 of size 1024
2018-02-05 19:29:10.676309: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908e00 of size 2048
2018-02-05 19:29:10.676313: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909600 of size 2048
2018-02-05 19:29:10.676318: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909e00 of size 256
2018-02-05 19:29:10.676323: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909f00 of size 256
2018-02-05 19:29:10.676328: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bc00 of size 256
2018-02-05 19:29:10.676333: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bd00 of size 256
2018-02-05 19:29:10.676338: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90be00 of size 4096
2018-02-05 19:29:10.676342: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90ce00 of size 256
2018-02-05 19:29:10.676347: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90cf00 of size 256
2018-02-05 19:29:10.676352: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d000 of size 2048
2018-02-05 19:29:10.676357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d800 of size 256
2018-02-05 19:29:10.676361: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d900 of size 256
2018-02-05 19:29:10.676366: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90da00 of size 256
2018-02-05 19:29:10.676371: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90db00 of size 1024
2018-02-05 19:29:10.676376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90df00 of size 256
2018-02-05 19:29:10.676384: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e000 of size 256
2018-02-05 19:29:10.676392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e100 of size 256
2018-02-05 19:29:10.676397: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e200 of size 256
2018-02-05 19:29:10.676402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e300 of size 256
2018-02-05 19:29:10.676406: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e400 of size 256
2018-02-05 19:29:10.676411: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e500 of size 38400
2018-02-05 19:29:10.676416: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917b00 of size 512
2018-02-05 19:29:10.676421: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917d00 of size 256
2018-02-05 19:29:10.676426: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917e00 of size 3276800
2018-02-05 19:29:10.676430: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc37e00 of size 1024
2018-02-05 19:29:10.676435: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38200 of size 256
2018-02-05 19:29:10.676440: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38300 of size 13107200
2018-02-05 19:29:10.676445: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8300 of size 2048
2018-02-05 19:29:10.676450: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8b00 of size 67108864
2018-02-05 19:29:10.676454: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b8b00 of size 2048
2018-02-05 19:29:10.676459: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9300 of size 256
2018-02-05 19:29:10.676464: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9400 of size 33554432
2018-02-05 19:29:10.676469: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268b9400 of size 65536
2018-02-05 19:29:10.676473: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268c9400 of size 75497472
2018-02-05 19:29:10.676478: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0c9400 of size 8192
2018-02-05 19:29:10.676483: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0cb400 of size 18874368
2018-02-05 19:29:10.676488: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cb400 of size 4096
2018-02-05 19:29:10.676492: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc400 of size 256
2018-02-05 19:29:10.676497: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc500 of size 4718592
2018-02-05 19:29:10.676502: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74c500 of size 2048
2018-02-05 19:29:10.676507: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74cd00 of size 1179648
2018-02-05 19:29:10.676512: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86cd00 of size 1024
2018-02-05 19:29:10.676516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86d100 of size 19200
2018-02-05 19:29:10.676521: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c871c00 of size 19200
2018-02-05 19:29:10.676526: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876700 of size 256
2018-02-05 19:29:10.676530: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876800 of size 256
2018-02-05 19:29:10.676535: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876900 of size 38400
2018-02-05 19:29:10.676540: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c87ff00 of size 256
2018-02-05 19:29:10.676545: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880000 of size 512
2018-02-05 19:29:10.676550: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880200 of size 3276800
2018-02-05 19:29:10.676554: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0200 of size 256
2018-02-05 19:29:10.676559: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0300 of size 1024
2018-02-05 19:29:10.676564: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0700 of size 256
2018-02-05 19:29:10.676568: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0800 of size 13107200
2018-02-05 19:29:10.676573: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d820800 of size 2048
2018-02-05 19:29:10.676578: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821000 of size 256
2018-02-05 19:29:10.676583: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821100 of size 67108864
2018-02-05 19:29:10.676587: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821100 of size 2048
2018-02-05 19:29:10.676592: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821900 of size 33554432
2018-02-05 19:29:10.676597: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821900 of size 256
2018-02-05 19:29:10.676602: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821a00 of size 65536
2018-02-05 19:29:10.676606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831a00 of size 256
2018-02-05 19:29:10.676611: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831b00 of size 75497472
2018-02-05 19:29:10.676616: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738031b00 of size 8192
2018-02-05 19:29:10.676620: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033b00 of size 256
2018-02-05 19:29:10.676625: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033c00 of size 18874368
2018-02-05 19:29:10.676630: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739233c00 of size 4096
2018-02-05 19:29:10.676635: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739234c00 of size 4718592
2018-02-05 19:29:10.676639: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4c00 of size 256
2018-02-05 19:29:10.676644: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4d00 of size 2048
2018-02-05 19:29:10.676649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b5500 of size 1179648
2018-02-05 19:29:10.676654: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5500 of size 1024
2018-02-05 19:29:10.676658: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5900 of size 256
2018-02-05 19:29:10.676663: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5a00 of size 38400
2018-02-05 19:29:10.676668: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397df000 of size 3276800
2018-02-05 19:29:10.676673: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739aff000 of size 13107200
2018-02-05 19:29:10.676678: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73a77f000 of size 67108864
2018-02-05 19:29:10.676682: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73e77f000 of size 75497472
2018-02-05 19:29:10.676687: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742f7f000 of size 75497472
2018-02-05 19:29:10.676692: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74777f000 of size 18874368
2018-02-05 19:29:10.676696: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74897f000 of size 4718592
2018-02-05 19:29:10.676701: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x748dff000 of size 3276800
2018-02-05 19:29:10.676706: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74911f000 of size 13107200
2018-02-05 19:29:10.676711: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x749d9f000 of size 67108864
2018-02-05 19:29:10.676715: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74dd9f000 of size 33554432
2018-02-05 19:29:10.676720: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74fd9f000 of size 33554432
2018-02-05 19:29:10.676725: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x751d9f000 of size 40046592
2018-02-05 19:29:10.676730: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f808d00 of size 1021184
2018-02-05 19:29:10.676735: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f903400 of size 256
2018-02-05 19:29:10.676740: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f90a000 of size 7168
2018-02-05 19:29:10.676745: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-02-05 19:29:10.676752: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 75 Chunks of size 256 totalling 18.8KiB
2018-02-05 19:29:10.676758: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 512 totalling 2.0KiB
2018-02-05 19:29:10.676764: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 11 Chunks of size 1024 totalling 11.0KiB
2018-02-05 19:29:10.676769: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2018-02-05 19:29:10.676775: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 2048 totalling 32.0KiB
2018-02-05 19:29:10.676780: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 4096 totalling 24.0KiB
2018-02-05 19:29:10.676785: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 8192 totalling 48.0KiB
2018-02-05 19:29:10.676791: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 19200 totalling 112.5KiB
2018-02-05 19:29:10.676796: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 38400 totalling 150.0KiB
2018-02-05 19:29:10.676802: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 65536 totalling 384.0KiB
2018-02-05 19:29:10.676807: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 1179648 totalling 5.62MiB
2018-02-05 19:29:10.676812: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2097152 totalling 2.00MiB
2018-02-05 19:29:10.676818: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3145728 totalling 3.00MiB
2018-02-05 19:29:10.676823: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 3276800 totalling 15.62MiB
2018-02-05 19:29:10.676829: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 4718592 totalling 31.50MiB
2018-02-05 19:29:10.676834: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5242880 totalling 5.00MiB
2018-02-05 19:29:10.676840: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 13107200 totalling 62.50MiB
2018-02-05 19:29:10.676845: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 18874368 totalling 108.00MiB
2018-02-05 19:29:10.676851: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 33554432 totalling 256.00MiB
2018-02-05 19:29:10.676856: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 40046592 totalling 38.19MiB
2018-02-05 19:29:10.676862: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 67108864 totalling 320.00MiB
2018-02-05 19:29:10.676867: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 75497472 totalling 432.00MiB
2018-02-05 19:29:10.676873: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 1.25GiB
2018-02-05 19:29:10.676880: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                  1343422464
InUse:                  1342393856
MaxInUse:               1342393856
NumAllocs:                     210
MaxAllocSize:             75497472

2018-02-05 19:29:10.676896: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ****************************************************************************************************
2018-02-05 19:29:10.676910: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,32,32,128]
2018-02-05 19:29:20.099933: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.00MiB.  Current allocation summary follows.
2018-02-05 19:29:20.099981: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 76, Chunks in use: 75. 19.0KiB allocated for chunks. 18.8KiB in use in bin. 604B client-requested in use in bin.
2018-02-05 19:29:20.099995: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100010: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 12, Chunks in use: 12. 12.2KiB allocated for chunks. 12.2KiB in use in bin. 12.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100023: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 16, Chunks in use: 16. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100036: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 7, Chunks in use: 6. 31.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100049: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100062: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 6, Chunks in use: 6. 112.5KiB allocated for chunks. 112.5KiB in use in bin. 112.5KiB client-requested in use in bin.
2018-02-05 19:29:20.100076: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 4, Chunks in use: 4. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100090: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 384.0KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.
2018-02-05 19:29:20.100102: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.100113: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.100125: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 1, Chunks in use: 0. 997.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.100137: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 5, Chunks in use: 5. 5.62MiB allocated for chunks. 5.62MiB in use in bin. 5.62MiB client-requested in use in bin.
2018-02-05 19:29:20.100151: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 7, Chunks in use: 7. 20.62MiB allocated for chunks. 20.62MiB in use in bin. 19.75MiB client-requested in use in bin.
2018-02-05 19:29:20.100164: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 8, Chunks in use: 8. 36.50MiB allocated for chunks. 36.50MiB in use in bin. 33.12MiB client-requested in use in bin.
2018-02-05 19:29:20.100177: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 5, Chunks in use: 5. 62.50MiB allocated for chunks. 62.50MiB in use in bin. 62.50MiB client-requested in use in bin.
2018-02-05 19:29:20.100191: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 108.00MiB allocated for chunks. 108.00MiB in use in bin. 102.50MiB client-requested in use in bin.
2018-02-05 19:29:20.100204: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 9, Chunks in use: 9. 294.19MiB allocated for chunks. 294.19MiB in use in bin. 274.00MiB client-requested in use in bin.
2018-02-05 19:29:20.100217: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 11, Chunks in use: 11. 752.00MiB allocated for chunks. 752.00MiB in use in bin. 744.00MiB client-requested in use in bin.
2018-02-05 19:29:20.100229: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.100240: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.100252: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 18.00MiB was 16.00MiB, Chunk State: 
2018-02-05 19:29:20.100263: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0000 of size 1280
2018-02-05 19:29:20.100272: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0500 of size 256
2018-02-05 19:29:20.100280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0600 of size 256
2018-02-05 19:29:20.100290: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0700 of size 512
2018-02-05 19:29:20.100298: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0900 of size 256
2018-02-05 19:29:20.100307: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0a00 of size 256
2018-02-05 19:29:20.100316: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0b00 of size 1024
2018-02-05 19:29:20.100325: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0f00 of size 256
2018-02-05 19:29:20.100333: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1000 of size 256
2018-02-05 19:29:20.100342: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1100 of size 2048
2018-02-05 19:29:20.100349: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1900 of size 256
2018-02-05 19:29:20.100357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1a00 of size 256
2018-02-05 19:29:20.100366: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1b00 of size 256
2018-02-05 19:29:20.100374: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1c00 of size 256
2018-02-05 19:29:20.100383: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1d00 of size 65536
2018-02-05 19:29:20.100392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1d00 of size 256
2018-02-05 19:29:20.100400: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1e00 of size 256
2018-02-05 19:29:20.100409: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1f00 of size 8192
2018-02-05 19:29:20.100418: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b3f00 of size 256
2018-02-05 19:29:20.100426: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4000 of size 256
2018-02-05 19:29:20.100435: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4100 of size 4096
2018-02-05 19:29:20.100443: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5100 of size 256
2018-02-05 19:29:20.100452: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5200 of size 256
2018-02-05 19:29:20.100460: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5300 of size 256
2018-02-05 19:29:20.100468: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5400 of size 256
2018-02-05 19:29:20.100477: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5500 of size 256
2018-02-05 19:29:20.100485: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5600 of size 256
2018-02-05 19:29:20.100494: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5700 of size 256
2018-02-05 19:29:20.100502: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5800 of size 256
2018-02-05 19:29:20.100511: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5900 of size 256
2018-02-05 19:29:20.100519: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5a00 of size 256
2018-02-05 19:29:20.100527: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5b00 of size 256
2018-02-05 19:29:20.100536: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5c00 of size 256
2018-02-05 19:29:20.100545: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5d00 of size 38400
2018-02-05 19:29:20.100553: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042bf300 of size 3276800
2018-02-05 19:29:20.100563: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7045df300 of size 13107200
2018-02-05 19:29:20.100571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70525f300 of size 67108864
2018-02-05 19:29:20.100580: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70925f300 of size 33554432
2018-02-05 19:29:20.100589: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70b25f300 of size 75497472
2018-02-05 19:29:20.100598: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70fa5f300 of size 18874368
2018-02-05 19:29:20.100607: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x710c5f300 of size 4718592
2018-02-05 19:29:20.100615: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7110df300 of size 1179648
2018-02-05 19:29:20.100624: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7111ff300 of size 19200
2018-02-05 19:29:20.100633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711203e00 of size 19200
2018-02-05 19:29:20.100641: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711208900 of size 19200
2018-02-05 19:29:20.100650: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d400 of size 512
2018-02-05 19:29:20.100658: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d600 of size 1179648
2018-02-05 19:29:20.100667: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71132d600 of size 2097152
2018-02-05 19:29:20.100675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152d600 of size 1024
2018-02-05 19:29:20.100684: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152da00 of size 4718592
2018-02-05 19:29:20.100693: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7119ada00 of size 3145728
2018-02-05 19:29:20.100702: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711cada00 of size 5242880
2018-02-05 19:29:20.100710: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ada00 of size 2048
2018-02-05 19:29:20.100719: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ae200 of size 33554432
2018-02-05 19:29:20.100728: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7141ae200 of size 33554432
2018-02-05 19:29:20.100737: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161ae200 of size 2048
2018-02-05 19:29:20.100745: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161aea00 of size 33554432
2018-02-05 19:29:20.100754: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181aea00 of size 65536
2018-02-05 19:29:20.100763: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181bea00 of size 75497472
2018-02-05 19:29:20.100771: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9bea00 of size 8192
2018-02-05 19:29:20.100779: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9c0a00 of size 18874368
2018-02-05 19:29:20.100786: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71dbc0a00 of size 18874368
2018-02-05 19:29:20.100794: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc0a00 of size 4096
2018-02-05 19:29:20.100801: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc1a00 of size 4718592
2018-02-05 19:29:20.100809: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f241a00 of size 4718592
2018-02-05 19:29:20.100817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c1a00 of size 2048
2018-02-05 19:29:20.100826: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c2200 of size 1179648
2018-02-05 19:29:20.100835: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7e2200 of size 65536
2018-02-05 19:29:20.100843: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f2200 of size 19200
2018-02-05 19:29:20.100852: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f6d00 of size 65536
2018-02-05 19:29:20.100860: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f806d00 of size 8192
2018-02-05 19:29:20.100870: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902200 of size 1024
2018-02-05 19:29:20.100878: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902600 of size 256
2018-02-05 19:29:20.100884: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902700 of size 256
2018-02-05 19:29:20.100891: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902800 of size 256
2018-02-05 19:29:20.100899: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902900 of size 256
2018-02-05 19:29:20.100908: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902a00 of size 256
2018-02-05 19:29:20.100916: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902b00 of size 256
2018-02-05 19:29:20.100925: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902c00 of size 256
2018-02-05 19:29:20.100933: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902d00 of size 256
2018-02-05 19:29:20.100942: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902e00 of size 256
2018-02-05 19:29:20.100951: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902f00 of size 256
2018-02-05 19:29:20.100959: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903000 of size 256
2018-02-05 19:29:20.100968: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903100 of size 256
2018-02-05 19:29:20.100976: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903200 of size 256
2018-02-05 19:29:20.100985: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903300 of size 256
2018-02-05 19:29:20.100994: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903500 of size 256
2018-02-05 19:29:20.101002: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903600 of size 256
2018-02-05 19:29:20.101011: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903700 of size 256
2018-02-05 19:29:20.101019: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903800 of size 1024
2018-02-05 19:29:20.101028: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903c00 of size 2048
2018-02-05 19:29:20.101037: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904400 of size 2048
2018-02-05 19:29:20.101045: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904c00 of size 8192
2018-02-05 19:29:20.101064: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f906c00 of size 4096
2018-02-05 19:29:20.101073: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f907c00 of size 2048
2018-02-05 19:29:20.101082: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908400 of size 1024
2018-02-05 19:29:20.101090: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908800 of size 256
2018-02-05 19:29:20.101099: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908900 of size 256
2018-02-05 19:29:20.101108: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908a00 of size 1024
2018-02-05 19:29:20.101116: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908e00 of size 2048
2018-02-05 19:29:20.101125: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909600 of size 2048
2018-02-05 19:29:20.101134: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909e00 of size 256
2018-02-05 19:29:20.101142: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909f00 of size 256
2018-02-05 19:29:20.101151: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bc00 of size 256
2018-02-05 19:29:20.101160: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bd00 of size 256
2018-02-05 19:29:20.101169: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90be00 of size 4096
2018-02-05 19:29:20.101177: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90ce00 of size 256
2018-02-05 19:29:20.101186: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90cf00 of size 256
2018-02-05 19:29:20.101194: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d000 of size 2048
2018-02-05 19:29:20.101203: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d800 of size 256
2018-02-05 19:29:20.101211: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d900 of size 256
2018-02-05 19:29:20.101219: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90da00 of size 256
2018-02-05 19:29:20.101228: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90db00 of size 1024
2018-02-05 19:29:20.101237: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90df00 of size 256
2018-02-05 19:29:20.101245: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e000 of size 256
2018-02-05 19:29:20.101254: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e100 of size 256
2018-02-05 19:29:20.101262: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e200 of size 256
2018-02-05 19:29:20.101271: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e300 of size 256
2018-02-05 19:29:20.101280: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e400 of size 256
2018-02-05 19:29:20.101288: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e500 of size 38400
2018-02-05 19:29:20.101297: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917b00 of size 512
2018-02-05 19:29:20.101305: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917d00 of size 256
2018-02-05 19:29:20.101314: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917e00 of size 3276800
2018-02-05 19:29:20.101323: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc37e00 of size 1024
2018-02-05 19:29:20.101331: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38200 of size 256
2018-02-05 19:29:20.101340: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38300 of size 13107200
2018-02-05 19:29:20.101348: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8300 of size 2048
2018-02-05 19:29:20.101357: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8b00 of size 67108864
2018-02-05 19:29:20.101366: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b8b00 of size 2048
2018-02-05 19:29:20.101374: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9300 of size 256
2018-02-05 19:29:20.101383: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9400 of size 33554432
2018-02-05 19:29:20.101392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268b9400 of size 65536
2018-02-05 19:29:20.101400: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268c9400 of size 75497472
2018-02-05 19:29:20.101409: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0c9400 of size 8192
2018-02-05 19:29:20.101417: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0cb400 of size 18874368
2018-02-05 19:29:20.101426: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cb400 of size 4096
2018-02-05 19:29:20.101435: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc400 of size 256
2018-02-05 19:29:20.101443: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc500 of size 4718592
2018-02-05 19:29:20.101452: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74c500 of size 2048
2018-02-05 19:29:20.101460: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74cd00 of size 1179648
2018-02-05 19:29:20.101469: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86cd00 of size 1024
2018-02-05 19:29:20.101478: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86d100 of size 19200
2018-02-05 19:29:20.101486: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c871c00 of size 19200
2018-02-05 19:29:20.101495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876700 of size 256
2018-02-05 19:29:20.101503: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876800 of size 256
2018-02-05 19:29:20.101512: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876900 of size 38400
2018-02-05 19:29:20.101520: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c87ff00 of size 256
2018-02-05 19:29:20.101529: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880000 of size 512
2018-02-05 19:29:20.101537: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880200 of size 3276800
2018-02-05 19:29:20.101546: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0200 of size 256
2018-02-05 19:29:20.101555: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0300 of size 1024
2018-02-05 19:29:20.101563: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0700 of size 256
2018-02-05 19:29:20.101572: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0800 of size 13107200
2018-02-05 19:29:20.101581: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d820800 of size 2048
2018-02-05 19:29:20.101589: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821000 of size 256
2018-02-05 19:29:20.101598: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821100 of size 67108864
2018-02-05 19:29:20.101606: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821100 of size 2048
2018-02-05 19:29:20.101615: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821900 of size 33554432
2018-02-05 19:29:20.101623: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821900 of size 256
2018-02-05 19:29:20.101632: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821a00 of size 65536
2018-02-05 19:29:20.101640: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831a00 of size 256
2018-02-05 19:29:20.101649: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831b00 of size 75497472
2018-02-05 19:29:20.101658: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738031b00 of size 8192
2018-02-05 19:29:20.101666: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033b00 of size 256
2018-02-05 19:29:20.101675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033c00 of size 18874368
2018-02-05 19:29:20.101684: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739233c00 of size 4096
2018-02-05 19:29:20.101692: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739234c00 of size 4718592
2018-02-05 19:29:20.101701: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4c00 of size 256
2018-02-05 19:29:20.101709: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4d00 of size 2048
2018-02-05 19:29:20.101718: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b5500 of size 1179648
2018-02-05 19:29:20.101727: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5500 of size 1024
2018-02-05 19:29:20.101735: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5900 of size 256
2018-02-05 19:29:20.101744: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5a00 of size 38400
2018-02-05 19:29:20.101753: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397df000 of size 3276800
2018-02-05 19:29:20.101762: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739aff000 of size 13107200
2018-02-05 19:29:20.101770: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73a77f000 of size 67108864
2018-02-05 19:29:20.101778: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73e77f000 of size 75497472
2018-02-05 19:29:20.101787: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742f7f000 of size 75497472
2018-02-05 19:29:20.101796: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74777f000 of size 18874368
2018-02-05 19:29:20.101804: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74897f000 of size 4718592
2018-02-05 19:29:20.101813: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x748dff000 of size 3276800
2018-02-05 19:29:20.101822: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74911f000 of size 13107200
2018-02-05 19:29:20.101830: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x749d9f000 of size 67108864
2018-02-05 19:29:20.101839: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74dd9f000 of size 33554432
2018-02-05 19:29:20.101847: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74fd9f000 of size 33554432
2018-02-05 19:29:20.101856: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x751d9f000 of size 40046592
2018-02-05 19:29:20.101866: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f808d00 of size 1021184
2018-02-05 19:29:20.101874: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f903400 of size 256
2018-02-05 19:29:20.101883: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f90a000 of size 7168
2018-02-05 19:29:20.101892: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-02-05 19:29:20.101905: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 75 Chunks of size 256 totalling 18.8KiB
2018-02-05 19:29:20.101916: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 512 totalling 2.0KiB
2018-02-05 19:29:20.101927: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 11 Chunks of size 1024 totalling 11.0KiB
2018-02-05 19:29:20.101937: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2018-02-05 19:29:20.101946: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 2048 totalling 32.0KiB
2018-02-05 19:29:20.101956: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 4096 totalling 24.0KiB
2018-02-05 19:29:20.101966: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 8192 totalling 48.0KiB
2018-02-05 19:29:20.101977: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 19200 totalling 112.5KiB
2018-02-05 19:29:20.101987: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 38400 totalling 150.0KiB
2018-02-05 19:29:20.101995: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 65536 totalling 384.0KiB
2018-02-05 19:29:20.101999: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 1179648 totalling 5.62MiB
2018-02-05 19:29:20.102008: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2097152 totalling 2.00MiB
2018-02-05 19:29:20.102018: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3145728 totalling 3.00MiB
2018-02-05 19:29:20.102028: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 3276800 totalling 15.62MiB
2018-02-05 19:29:20.102038: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 4718592 totalling 31.50MiB
2018-02-05 19:29:20.102048: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5242880 totalling 5.00MiB
2018-02-05 19:29:20.102058: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 13107200 totalling 62.50MiB
2018-02-05 19:29:20.102068: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 18874368 totalling 108.00MiB
2018-02-05 19:29:20.102078: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 33554432 totalling 256.00MiB
2018-02-05 19:29:20.102089: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 40046592 totalling 38.19MiB
2018-02-05 19:29:20.102099: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 67108864 totalling 320.00MiB
2018-02-05 19:29:20.102109: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 75497472 totalling 432.00MiB
2018-02-05 19:29:20.102119: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 1.25GiB
2018-02-05 19:29:20.102131: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                  1343422464
InUse:                  1342393856
MaxInUse:               1342393856
NumAllocs:                     210
MaxAllocSize:             75497472

2018-02-05 19:29:20.102157: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ****************************************************************************************************
2018-02-05 19:29:20.102177: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,512,1024]
2018-02-05 19:29:20.677046: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.00MiB.  Current allocation summary follows.
2018-02-05 19:29:20.677113: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (256): 	Total Chunks: 76, Chunks in use: 75. 19.0KiB allocated for chunks. 18.8KiB in use in bin. 604B client-requested in use in bin.
2018-02-05 19:29:20.677126: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (512): 	Total Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677138: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1024): 	Total Chunks: 12, Chunks in use: 12. 12.2KiB allocated for chunks. 12.2KiB in use in bin. 12.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677150: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2048): 	Total Chunks: 16, Chunks in use: 16. 32.0KiB allocated for chunks. 32.0KiB in use in bin. 32.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677161: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4096): 	Total Chunks: 7, Chunks in use: 7. 31.0KiB allocated for chunks. 31.0KiB in use in bin. 28.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677175: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8192): 	Total Chunks: 6, Chunks in use: 6. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677188: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16384): 	Total Chunks: 6, Chunks in use: 6. 112.5KiB allocated for chunks. 112.5KiB in use in bin. 112.5KiB client-requested in use in bin.
2018-02-05 19:29:20.677199: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (32768): 	Total Chunks: 4, Chunks in use: 4. 150.0KiB allocated for chunks. 150.0KiB in use in bin. 150.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677211: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (65536): 	Total Chunks: 6, Chunks in use: 6. 384.0KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.
2018-02-05 19:29:20.677221: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (131072): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.677232: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.677243: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (524288): 	Total Chunks: 1, Chunks in use: 0. 997.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.677254: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (1048576): 	Total Chunks: 5, Chunks in use: 5. 5.62MiB allocated for chunks. 5.62MiB in use in bin. 5.62MiB client-requested in use in bin.
2018-02-05 19:29:20.677267: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (2097152): 	Total Chunks: 7, Chunks in use: 7. 20.62MiB allocated for chunks. 20.62MiB in use in bin. 19.75MiB client-requested in use in bin.
2018-02-05 19:29:20.677279: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (4194304): 	Total Chunks: 8, Chunks in use: 8. 36.50MiB allocated for chunks. 36.50MiB in use in bin. 33.12MiB client-requested in use in bin.
2018-02-05 19:29:20.677291: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (8388608): 	Total Chunks: 5, Chunks in use: 5. 62.50MiB allocated for chunks. 62.50MiB in use in bin. 62.50MiB client-requested in use in bin.
2018-02-05 19:29:20.677303: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (16777216): 	Total Chunks: 6, Chunks in use: 6. 108.00MiB allocated for chunks. 108.00MiB in use in bin. 102.50MiB client-requested in use in bin.
2018-02-05 19:29:20.677315: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (33554432): 	Total Chunks: 9, Chunks in use: 9. 294.19MiB allocated for chunks. 294.19MiB in use in bin. 274.00MiB client-requested in use in bin.
2018-02-05 19:29:20.677328: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (67108864): 	Total Chunks: 11, Chunks in use: 11. 752.00MiB allocated for chunks. 752.00MiB in use in bin. 744.00MiB client-requested in use in bin.
2018-02-05 19:29:20.677338: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.677348: I tensorflow/core/common_runtime/bfc_allocator.cc:627] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-02-05 19:29:20.677359: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin for 8.00MiB was 8.00MiB, Chunk State: 
2018-02-05 19:29:20.677369: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0000 of size 1280
2018-02-05 19:29:20.677377: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0500 of size 256
2018-02-05 19:29:20.677385: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0600 of size 256
2018-02-05 19:29:20.677394: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0700 of size 512
2018-02-05 19:29:20.677402: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0900 of size 256
2018-02-05 19:29:20.677409: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0a00 of size 256
2018-02-05 19:29:20.677417: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0b00 of size 1024
2018-02-05 19:29:20.677425: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a0f00 of size 256
2018-02-05 19:29:20.677433: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1000 of size 256
2018-02-05 19:29:20.677441: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1100 of size 2048
2018-02-05 19:29:20.677448: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1900 of size 256
2018-02-05 19:29:20.677456: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1a00 of size 256
2018-02-05 19:29:20.677464: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1b00 of size 256
2018-02-05 19:29:20.677471: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1c00 of size 256
2018-02-05 19:29:20.677480: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042a1d00 of size 65536
2018-02-05 19:29:20.677487: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1d00 of size 256
2018-02-05 19:29:20.677495: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1e00 of size 256
2018-02-05 19:29:20.677503: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b1f00 of size 8192
2018-02-05 19:29:20.677511: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b3f00 of size 256
2018-02-05 19:29:20.677519: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4000 of size 256
2018-02-05 19:29:20.677527: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b4100 of size 4096
2018-02-05 19:29:20.677534: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5100 of size 256
2018-02-05 19:29:20.677542: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5200 of size 256
2018-02-05 19:29:20.677550: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5300 of size 256
2018-02-05 19:29:20.677558: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5400 of size 256
2018-02-05 19:29:20.677565: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5500 of size 256
2018-02-05 19:29:20.677573: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5600 of size 256
2018-02-05 19:29:20.677581: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5700 of size 256
2018-02-05 19:29:20.677588: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5800 of size 256
2018-02-05 19:29:20.677596: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5900 of size 256
2018-02-05 19:29:20.677604: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5a00 of size 256
2018-02-05 19:29:20.677611: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5b00 of size 256
2018-02-05 19:29:20.677619: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5c00 of size 256
2018-02-05 19:29:20.677627: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042b5d00 of size 38400
2018-02-05 19:29:20.677635: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7042bf300 of size 3276800
2018-02-05 19:29:20.677643: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7045df300 of size 13107200
2018-02-05 19:29:20.677651: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70525f300 of size 67108864
2018-02-05 19:29:20.677659: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70925f300 of size 33554432
2018-02-05 19:29:20.677667: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70b25f300 of size 75497472
2018-02-05 19:29:20.677675: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x70fa5f300 of size 18874368
2018-02-05 19:29:20.677683: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x710c5f300 of size 4718592
2018-02-05 19:29:20.677691: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7110df300 of size 1179648
2018-02-05 19:29:20.677699: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7111ff300 of size 19200
2018-02-05 19:29:20.677707: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711203e00 of size 19200
2018-02-05 19:29:20.677714: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711208900 of size 19200
2018-02-05 19:29:20.677722: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d400 of size 512
2018-02-05 19:29:20.677730: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71120d600 of size 1179648
2018-02-05 19:29:20.677738: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71132d600 of size 2097152
2018-02-05 19:29:20.677746: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152d600 of size 1024
2018-02-05 19:29:20.677753: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71152da00 of size 4718592
2018-02-05 19:29:20.677762: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7119ada00 of size 3145728
2018-02-05 19:29:20.677770: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x711cada00 of size 5242880
2018-02-05 19:29:20.677778: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ada00 of size 2048
2018-02-05 19:29:20.677786: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7121ae200 of size 33554432
2018-02-05 19:29:20.677793: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7141ae200 of size 33554432
2018-02-05 19:29:20.677801: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161ae200 of size 2048
2018-02-05 19:29:20.677809: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7161aea00 of size 33554432
2018-02-05 19:29:20.677817: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181aea00 of size 65536
2018-02-05 19:29:20.677825: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7181bea00 of size 75497472
2018-02-05 19:29:20.677832: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9bea00 of size 8192
2018-02-05 19:29:20.677840: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71c9c0a00 of size 18874368
2018-02-05 19:29:20.677848: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71dbc0a00 of size 18874368
2018-02-05 19:29:20.677856: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc0a00 of size 4096
2018-02-05 19:29:20.677864: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71edc1a00 of size 4718592
2018-02-05 19:29:20.677872: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f241a00 of size 4718592
2018-02-05 19:29:20.677880: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c1a00 of size 2048
2018-02-05 19:29:20.677887: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f6c2200 of size 1179648
2018-02-05 19:29:20.677895: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7e2200 of size 65536
2018-02-05 19:29:20.677903: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f2200 of size 19200
2018-02-05 19:29:20.677911: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f7f6d00 of size 65536
2018-02-05 19:29:20.677919: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f806d00 of size 8192
2018-02-05 19:29:20.677926: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902200 of size 1024
2018-02-05 19:29:20.677934: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902600 of size 256
2018-02-05 19:29:20.677942: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902700 of size 256
2018-02-05 19:29:20.677950: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902800 of size 256
2018-02-05 19:29:20.677958: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902900 of size 256
2018-02-05 19:29:20.677965: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902a00 of size 256
2018-02-05 19:29:20.677973: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902b00 of size 256
2018-02-05 19:29:20.677981: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902c00 of size 256
2018-02-05 19:29:20.677989: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902d00 of size 256
2018-02-05 19:29:20.677996: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902e00 of size 256
2018-02-05 19:29:20.678004: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f902f00 of size 256
2018-02-05 19:29:20.678012: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903000 of size 256
2018-02-05 19:29:20.678019: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903100 of size 256
2018-02-05 19:29:20.678027: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903200 of size 256
2018-02-05 19:29:20.678035: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903300 of size 256
2018-02-05 19:29:20.678043: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903500 of size 256
2018-02-05 19:29:20.678050: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903600 of size 256
2018-02-05 19:29:20.678058: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903700 of size 256
2018-02-05 19:29:20.678066: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903800 of size 1024
2018-02-05 19:29:20.678074: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f903c00 of size 2048
2018-02-05 19:29:20.678082: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904400 of size 2048
2018-02-05 19:29:20.678089: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f904c00 of size 8192
2018-02-05 19:29:20.678097: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f906c00 of size 4096
2018-02-05 19:29:20.678105: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f907c00 of size 2048
2018-02-05 19:29:20.678112: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908400 of size 1024
2018-02-05 19:29:20.678120: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908800 of size 256
2018-02-05 19:29:20.678128: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908900 of size 256
2018-02-05 19:29:20.678136: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908a00 of size 1024
2018-02-05 19:29:20.678143: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f908e00 of size 2048
2018-02-05 19:29:20.678151: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909600 of size 2048
2018-02-05 19:29:20.678159: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909e00 of size 256
2018-02-05 19:29:20.678167: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f909f00 of size 256
2018-02-05 19:29:20.678175: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90a000 of size 7168
2018-02-05 19:29:20.678182: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bc00 of size 256
2018-02-05 19:29:20.678190: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90bd00 of size 256
2018-02-05 19:29:20.678198: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90be00 of size 4096
2018-02-05 19:29:20.678206: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90ce00 of size 256
2018-02-05 19:29:20.678213: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90cf00 of size 256
2018-02-05 19:29:20.678221: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d000 of size 2048
2018-02-05 19:29:20.678229: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d800 of size 256
2018-02-05 19:29:20.678237: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90d900 of size 256
2018-02-05 19:29:20.678244: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90da00 of size 256
2018-02-05 19:29:20.678252: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90db00 of size 1024
2018-02-05 19:29:20.678260: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90df00 of size 256
2018-02-05 19:29:20.678267: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e000 of size 256
2018-02-05 19:29:20.678275: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e100 of size 256
2018-02-05 19:29:20.678283: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e200 of size 256
2018-02-05 19:29:20.678291: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e300 of size 256
2018-02-05 19:29:20.678298: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e400 of size 256
2018-02-05 19:29:20.678306: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f90e500 of size 38400
2018-02-05 19:29:20.678314: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917b00 of size 512
2018-02-05 19:29:20.678322: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917d00 of size 256
2018-02-05 19:29:20.678330: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71f917e00 of size 3276800
2018-02-05 19:29:20.678337: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc37e00 of size 1024
2018-02-05 19:29:20.678345: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38200 of size 256
2018-02-05 19:29:20.678353: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x71fc38300 of size 13107200
2018-02-05 19:29:20.678361: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8300 of size 2048
2018-02-05 19:29:20.678368: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7208b8b00 of size 67108864
2018-02-05 19:29:20.678376: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b8b00 of size 2048
2018-02-05 19:29:20.678384: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9300 of size 256
2018-02-05 19:29:20.678392: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7248b9400 of size 33554432
2018-02-05 19:29:20.678400: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268b9400 of size 65536
2018-02-05 19:29:20.678407: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7268c9400 of size 75497472
2018-02-05 19:29:20.678415: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0c9400 of size 8192
2018-02-05 19:29:20.678423: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72b0cb400 of size 18874368
2018-02-05 19:29:20.678431: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cb400 of size 4096
2018-02-05 19:29:20.678438: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc400 of size 256
2018-02-05 19:29:20.678446: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c2cc500 of size 4718592
2018-02-05 19:29:20.678454: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74c500 of size 2048
2018-02-05 19:29:20.678462: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c74cd00 of size 1179648
2018-02-05 19:29:20.678470: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86cd00 of size 1024
2018-02-05 19:29:20.678477: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c86d100 of size 19200
2018-02-05 19:29:20.678485: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c871c00 of size 19200
2018-02-05 19:29:20.678493: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876700 of size 256
2018-02-05 19:29:20.678501: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876800 of size 256
2018-02-05 19:29:20.678509: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c876900 of size 38400
2018-02-05 19:29:20.678516: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c87ff00 of size 256
2018-02-05 19:29:20.678524: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880000 of size 512
2018-02-05 19:29:20.678532: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72c880200 of size 3276800
2018-02-05 19:29:20.678540: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0200 of size 256
2018-02-05 19:29:20.678547: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0300 of size 1024
2018-02-05 19:29:20.678555: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0700 of size 256
2018-02-05 19:29:20.678563: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72cba0800 of size 13107200
2018-02-05 19:29:20.678571: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d820800 of size 2048
2018-02-05 19:29:20.678578: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821000 of size 256
2018-02-05 19:29:20.678586: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x72d821100 of size 67108864
2018-02-05 19:29:20.678594: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821100 of size 2048
2018-02-05 19:29:20.678602: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x731821900 of size 33554432
2018-02-05 19:29:20.678610: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821900 of size 256
2018-02-05 19:29:20.678617: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733821a00 of size 65536
2018-02-05 19:29:20.678625: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831a00 of size 256
2018-02-05 19:29:20.678633: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x733831b00 of size 75497472
2018-02-05 19:29:20.678640: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738031b00 of size 8192
2018-02-05 19:29:20.678648: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033b00 of size 256
2018-02-05 19:29:20.678656: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x738033c00 of size 18874368
2018-02-05 19:29:20.678664: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739233c00 of size 4096
2018-02-05 19:29:20.678671: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739234c00 of size 4718592
2018-02-05 19:29:20.678679: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4c00 of size 256
2018-02-05 19:29:20.678687: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b4d00 of size 2048
2018-02-05 19:29:20.678695: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7396b5500 of size 1179648
2018-02-05 19:29:20.678703: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5500 of size 1024
2018-02-05 19:29:20.678710: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5900 of size 256
2018-02-05 19:29:20.678718: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397d5a00 of size 38400
2018-02-05 19:29:20.678726: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x7397df000 of size 3276800
2018-02-05 19:29:20.678734: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x739aff000 of size 13107200
2018-02-05 19:29:20.678741: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73a77f000 of size 67108864
2018-02-05 19:29:20.678749: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x73e77f000 of size 75497472
2018-02-05 19:29:20.678757: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x742f7f000 of size 75497472
2018-02-05 19:29:20.678765: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74777f000 of size 18874368
2018-02-05 19:29:20.678773: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74897f000 of size 4718592
2018-02-05 19:29:20.678781: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x748dff000 of size 3276800
2018-02-05 19:29:20.678789: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74911f000 of size 13107200
2018-02-05 19:29:20.678796: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x749d9f000 of size 67108864
2018-02-05 19:29:20.678804: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74dd9f000 of size 33554432
2018-02-05 19:29:20.678812: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x74fd9f000 of size 33554432
2018-02-05 19:29:20.678820: I tensorflow/core/common_runtime/bfc_allocator.cc:661] Chunk at 0x751d9f000 of size 40046592
2018-02-05 19:29:20.678829: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f808d00 of size 1021184
2018-02-05 19:29:20.678837: I tensorflow/core/common_runtime/bfc_allocator.cc:670] Free at 0x71f903400 of size 256
2018-02-05 19:29:20.678845: I tensorflow/core/common_runtime/bfc_allocator.cc:676]      Summary of in-use Chunks by size: 
2018-02-05 19:29:20.678855: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 75 Chunks of size 256 totalling 18.8KiB
2018-02-05 19:29:20.678864: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 512 totalling 2.0KiB
2018-02-05 19:29:20.678873: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 11 Chunks of size 1024 totalling 11.0KiB
2018-02-05 19:29:20.678882: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 1280 totalling 1.2KiB
2018-02-05 19:29:20.678891: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 16 Chunks of size 2048 totalling 32.0KiB
2018-02-05 19:29:20.678900: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 4096 totalling 24.0KiB
2018-02-05 19:29:20.678909: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 7168 totalling 7.0KiB
2018-02-05 19:29:20.678918: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 8192 totalling 48.0KiB
2018-02-05 19:29:20.678927: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 19200 totalling 112.5KiB
2018-02-05 19:29:20.678936: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 4 Chunks of size 38400 totalling 150.0KiB
2018-02-05 19:29:20.678945: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 65536 totalling 384.0KiB
2018-02-05 19:29:20.678954: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 1179648 totalling 5.62MiB
2018-02-05 19:29:20.678962: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 2097152 totalling 2.00MiB
2018-02-05 19:29:20.678971: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 3145728 totalling 3.00MiB
2018-02-05 19:29:20.678980: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 3276800 totalling 15.62MiB
2018-02-05 19:29:20.678990: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 7 Chunks of size 4718592 totalling 31.50MiB
2018-02-05 19:29:20.678998: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 5242880 totalling 5.00MiB
2018-02-05 19:29:20.679007: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 13107200 totalling 62.50MiB
2018-02-05 19:29:20.679017: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 18874368 totalling 108.00MiB
2018-02-05 19:29:20.679026: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 8 Chunks of size 33554432 totalling 256.00MiB
2018-02-05 19:29:20.679035: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 1 Chunks of size 40046592 totalling 38.19MiB
2018-02-05 19:29:20.679044: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 5 Chunks of size 67108864 totalling 320.00MiB
2018-02-05 19:29:20.679053: I tensorflow/core/common_runtime/bfc_allocator.cc:679] 6 Chunks of size 75497472 totalling 432.00MiB
2018-02-05 19:29:20.679062: I tensorflow/core/common_runtime/bfc_allocator.cc:683] Sum Total of in-use chunks: 1.25GiB
2018-02-05 19:29:20.679073: I tensorflow/core/common_runtime/bfc_allocator.cc:685] Stats: 
Limit:                  1343422464
InUse:                  1342401024
MaxInUse:               1342401024
NumAllocs:                     211
MaxAllocSize:             75497472

2018-02-05 19:29:20.679098: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ****************************************************************************************************
2018-02-05 19:29:20.679116: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,32,32,128]
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,3,1024,2048]
	 [[Node: training/Adam/mul_53 = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/beta_2/read, training/Adam/Variable_30/read)]]
	 [[Node: loss/mul/_239 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/tuw/Desktop/faceswap/scripts/train.py"", line 139, in processThread
    trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
  File ""/home/tuw/Desktop/faceswap/lib/ModelAE.py"", line 53, in train_one_step
    loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 1849, in train_on_batch
    outputs = self.train_function(ins)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2475, in __call__
    **self.session_kwargs)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,3,1024,2048]
	 [[Node: training/Adam/mul_53 = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/beta_2/read, training/Adam/Variable_30/read)]]
	 [[Node: loss/mul/_239 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'training/Adam/mul_53', defined at:
  File ""/usr/lib/python3.5/threading.py"", line 882, in _bootstrap
    self._bootstrap_inner()
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/tuw/Desktop/faceswap/scripts/train.py"", line 139, in processThread
    trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
  File ""/home/tuw/Desktop/faceswap/lib/ModelAE.py"", line 53, in train_one_step
    loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 1848, in train_on_batch
    self._make_train_function()
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/engine/training.py"", line 970, in _make_train_function
    loss=self.total_loss)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/optimizers.py"", line 456, in get_updates
    v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py"", line 754, in _run_op
    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 894, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 1117, in _mul_dispatch
    return gen_math_ops._mul(x, y, name=name)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2726, in _mul
    ""Mul"", x=x, y=y, name=name)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,1024,2048]
	 [[Node: training/Adam/mul_53 = Mul[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/beta_2/read, training/Adam/Variable_30/read)]]
	 [[Node: loss/mul/_239 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1490_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]


```

VIdeo: https://streamable.com/0au1v",added import import true still cry python train model directory model directory training data directory loading data may take loading model conversion second argument float future float import loading training data unable open file unable open file name error message file directory loading trainer starting press enter stop training save model binary use successful node read negative value must least one node node zero found device name major minor device device name bus id compute capability allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate current allocation summary bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin chunk state chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size free size free size free size summary size size size size size size size size size size size size size size size size size size size size size size size sum total limit resource exhausted tensor shape allocator ran memory trying allocate current allocation summary bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin chunk state chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size free size free size free size summary size size size size size size size size size size size size size size size size size size size size size size size sum total limit resource exhausted tensor shape allocator ran memory trying allocate current allocation summary bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin chunk state chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size free size free size free size summary size size size size size size size size size size size size size size size size size size size size size size size sum total limit resource exhausted tensor shape allocator ran memory trying allocate current allocation summary bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin total use use bin use bin bin chunk state chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size chunk size free size free size summary size size size size size size size size size size size size size size size size size size size size size size size size sum total limit resource exhausted tensor shape exception thread recent call last file line return file line status file line tensor shape node node handling exception another exception recent call last file line file line run file line epoch else none file line file line file line file line run file line file line file line raise type message tensor shape node node defined file line file line file line run file line epoch else none file line file line file line file line wrapper return file line file line return operator file line return file line return file line file line file line file line see tensor shape node node video,issue,positive,positive,neutral,neutral,positive,positive
363122228,"Ah. I thought the above poster was referring to something from this repo, but the GAN and 128x128 repos are on the agenda to implement eventually. Realistic eyes I'm not aware of, what's the repo?",ah thought poster something gan agenda implement eventually realistic aware,issue,negative,positive,positive,positive,positive,positive
363121028,"@fakeapp GAN masking, it doesn't blur the objects blocking the face. I'm sure you saw the gifs.
And 128x128 resolution for generated faces.
Also more realistic eyes.

Basically all the stuff that @shaoanlu did.",gan blur blocking face sure saw resolution also realistic basically stuff,issue,negative,positive,positive,positive,positive,positive
363119707,"No problem, it is just a way to say ""feedback"" ;-)",problem way say feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
363111352,"I was able to start training on the GPU without errors using the file _Model_LowMem.py_ in comment [#362956396](https://github.com/deepfakes/faceswap/issues/119#issuecomment-362956396), BUT it's impossible to use old models because of error ""You are trying to load a weight file containing 6 layers into a model with 7 layers."" and training starts from scratch.

Also results of training is very poor after 8 hours, even on CPU results is better. Not sure, but maybe it's due to the fact that training starts from scratch.

I also tried to use the solution proposed by @fat-tire in comment [#362975335](https://github.com/deepfakes/faceswap/issues/119#issuecomment-362975335) by adding this lines of code:

```
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list=""0""
set_session(tf.Session(config=config))
```

in beginning of the file _Model_Original.py_.

Also I added this line:
`config.gpu_options.per_process_gpu_memory_fraction=0.5`

During training I noticed that the GPU usage is limited to using only 1 GB instead of 2 GB. But it did not help and I still get the error:
""OOM when allocating tensor with shape[16,128,32,32] and type float on...""

So, looks like that at the moment the only working solution for me is using the CPU :)
",able start training without file comment impossible use old error trying load weight file model training scratch also training poor even better sure maybe due fact training scratch also tried use solution comment code import import true beginning file also added line training usage limited instead help still get error tensor shape type float like moment working solution,issue,positive,positive,neutral,neutral,positive,positive
363110313,"Yes, I was using small number of images. Thanks for figuring it out.",yes small number thanks,issue,positive,negative,neutral,neutral,negative,negative
363104987,@Clorr  hey totally wasn't a complaint at all - just an observation that using globals across processes won't work on windows :) didn't mean for it to get long winded or to offend :) ,hey totally complaint observation across wo work mean get long winded offend,issue,negative,negative,negative,negative,negative,negative
363097668,I don't think the original scripts -- which FakeApp runs on -- are dated. Is there a faceswap feature that isn't available in the app that you'd like to see there?,think original feature available like see,issue,positive,positive,positive,positive,positive,positive
363089064,"Unless other complaints, I will merge this tomorrow so we can move on",unless merge tomorrow move,issue,negative,neutral,neutral,neutral,neutral,neutral
363087826,"@gdunstone - Ah interesting link - thanks :) I really just meant the cost difference of the alternate approaches really - again not claiming to be an expert or anything.

My take away is whilst multiprocessing is not affected by GIL, you cant use non picklable objects...and that there are pretty huge differences between Linux and Windows when it comes to processes, shared memory, and concurrency mechanisms in python (and in general really).",ah interesting link thanks really meant cost difference alternate really expert anything take away whilst affected cant use non pretty huge come memory concurrency python general really,issue,positive,positive,positive,positive,positive,positive
363071418,"@fat-tire if you are using this code and are confident about it's behavior, please do a Pull Request so that we can integrate it and share with others ;-)",code confident behavior please pull request integrate share,issue,positive,positive,positive,positive,positive,positive
363071051,"Feel free to add a license file, stating the current situation if you have some idea about it",feel free add license file current situation idea,issue,positive,positive,positive,positive,positive,positive
363070701,"I was also thinking about that, just to have a report of face poses after extract. It would help people knowing if their training data contains same poses from src face and target face.

If you have some link to share with code, I would appreciate",also thinking report face extract would help people knowing training data face target face link share code would appreciate,issue,positive,neutral,neutral,neutral,neutral,neutral
363059690,"we still need to get /u/deepfakes to approve this licensing. If you can get into contact with him, then we can put a license on it.

We cant license it without /u/deepfakes because then the license is void due to the unknown license of the original source.",still need get approve get contact put license cant license without license void due unknown license original source,issue,negative,positive,neutral,neutral,positive,positive
363057426,"Any license that makes it free for life, anyone/company can contribute but understood that they cannot claim whole/part ownership of it ever(companies should sign like a waiver that even if they had contributed work/resources on it, they could never take a tiny bit whole/part ownership/partnership neither permanently nor temporarily, cause you know companies can pay lawyers and find loopholes.), not to use whole/part of any where of the app/code to make their own free NOR especially for commercial, neither for private nor non-private use.

You can also patent it or something.

",license free life contribute understood claim ownership ever sign like waiver even could never take tiny bit neither permanently temporarily cause know pay find use make free especially commercial neither private use also patent something,issue,positive,positive,positive,positive,positive,positive
363055969,"@jondubin, that's correct. My project is to compliment yours, more specifically it's for people that don't have the local resources available ie. AMD GPU, can't dedicate GPU for long periods, wanting to spin up more than one run at once, etc. etc.",correct project compliment specifically people local available ie ca dedicate long wanting spin one run,issue,negative,positive,positive,positive,positive,positive
363033609,It seems the GUI version didn't manage to get it into here and the current version of fakeapp still runs on dated scripts. Sadly.,version manage get current version still sadly,issue,negative,negative,negative,negative,negative,negative
363031401,"I have very limited knowdge about autoencoders, but I’ve seen both L1 and L2 loss benn used in papers (as the loss func. to ground truth image). I think its somehow hurustic and empirical. In fact, I’ve tried both losses in this project but didn’t find much difference in terms of output quality.",limited seen loss benn used loss ground truth image think somehow empirical fact tried project find much difference output quality,issue,negative,positive,neutral,neutral,positive,positive
363001656,"tested on python3.6.4 as well.
this is unrelated to the python version though.",tested python well unrelated python version though,issue,negative,neutral,neutral,neutral,neutral,neutral
362999655,"@flipflopbboi 

I think its not printing the loss outputs due to a commit I have made which sets end keyword of the print statement to `'\r'`. If you remove that it will print every iteration.

It should be saving the progress if it raises KeyboardInterrupt. You should exit using that method.",think printing loss due commit made end print statement remove print every iteration saving progress exit method,issue,negative,negative,negative,negative,negative,negative
362975335,"The question is-- are you able to generate an image with `convert` that is meaningful?  One thing I'm noticing is that by commenting out that one line, there's an error about trying to load a weight file containing 6 layers into a model with 7 layers.  And there's also an apparent mismatch with ""Dimension 0""... but I guess I'm curious if you're able to generate a swapped face using the graphs.

Here's the code I put at the top btw to do that thing you asked about. It's an amalgam of different discussions I found.

```
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list=""0""
set_session(tf.Session(config=config))
```
The allow_growth part is what you asked about and the visible_device_list=""0"" thing was also suggested to try..  These lines should go at the top of the file before Keras actually starts doing stuff.

You can see how memory is being used on the card in real time by opening up a window and typing `nvidia-smi -l`

Also per someone's request I wrote up a long HOWTO on building/running with linux as I've been doing it thusfar, but I want to let it marinate a little.  These CNNs are kind of eating up memory so I'm setting it up on another newer card than the GeForce GTX 690.  I am able to get smaller things to work fine tho...
",question able generate image convert meaningful one thing one line error trying load weight file model also apparent mismatch dimension guess curious able generate face code put top thing amalgam different found import import true part thing also try go top file actually stuff see memory used card real time opening window also per someone request wrote long want let marinate little kind eating memory setting another card able get smaller work fine tho,issue,positive,positive,positive,positive,positive,positive
362972663,"Its not that there is an overhead, but that Thread is not **full parallelism**, just concurrent.

https://code.tutsplus.com/articles/introduction-to-parallel-and-concurrent-programming-in-python--cms-28612",overhead thread full parallelism concurrent,issue,negative,positive,positive,positive,positive,positive
362956942,"Thanks for the info. I've monitored the memory usage, with the `cnn` option it quickly goes up from 2% to 99% (11149 MB) and then the error appears.

Looking forward to the additional options! Have you compared the output quality from the GAN method with the standard one? Is there a significant difference? I can't tell yet, will have to start training my current dataset with the ""old"" method.  ",thanks memory usage option quickly go error looking forward additional output quality gan method standard one significant difference ca tell yet start training current old method,issue,negative,positive,positive,positive,positive,positive
362956396,"@fat-tire I even tried to set -bs 16 with **-t LowMem** but doesnt helped me.
Now i found the solution, don't know if it really working, i've randomly changed numbers  (not only ENCODER_DIM)
Here is Model_LowMem.py:

[Model_LowMem.py.zip](https://github.com/deepfakes/faceswap/files/1693507/Model_LowMem.py.zip)
With option **python3 faceswap.py train -A '/home/tuw/Desktop/faceswap_/data/trump1'  -B '/home/tuw/Desktop/faceswap_/data/cage'  -m '/home/tuw/Desktop/faceswap_/data/model' _-t LowMem -bs 64 -t LowMem_** is seems to be working... Or not? Can you please check code of my attached  Model_LowMem.py . And here is poc video https://streamable.com/k6sc7",even tried set doesnt found solution know really working randomly option python train working please check code attached video,issue,negative,negative,negative,negative,negative,negative
362955378,"@gdunstone  - Ah I didn't figure on that overhead - was just thinking imap_unordered vs map :( ...There isn't much info on  ThreadPool at all :(

",ah figure overhead thinking map much,issue,negative,positive,positive,positive,positive,positive
362954373,"I profiled these two as ive never seen ThreadPool before. Its hella slow in comparison to a normal Pool
I think its because pythons threading isnt real threading (thanks GIL), and multiprocessing actually has the ability to do real multiprocessing.

```python3

import multiprocessing as mp
from multiprocessing.pool import ThreadPool

method = None

def pool_process(method_to_run, data, j=None):
    global method
    if j is None:
        j = mp.cpu_count() * 2 # I though *2 for HT if you have intel, made no difference
    method = method_to_run
    pool = ThreadPool(threads)
    for i in pool.imap_unordered(runner, data):
        yield(i)

def runner(item):
    return method(item)
```",two never seen slow comparison normal pool think real thanks actually ability real python import import method none data global method none though made difference method pool runner data yield runner item return method item,issue,positive,positive,neutral,neutral,positive,positive
362953536,"Okay, so for cards with low memory I've played with a few tweaks.

1.  set the batch size lower by doing something like `-bs 32` when training.

2.  use `-t LowMem`

3.  As mentioned above, changing `ENCODER_DIM` to 64 or even lower in LowMem or whatever might do something?

I can look at that allow_growth thing and see if it makes a difference.",low memory set batch size lower something like training use even lower whatever might something look thing see difference,issue,negative,neutral,neutral,neutral,neutral,neutral
362951220,"@vladjerca as i say i tried edit it, doesnt helped.",say tried edit doesnt,issue,negative,neutral,neutral,neutral,neutral,neutral
362945044,Can somebody try to include tensorflow option from https://stackoverflow.com/a/44102727 maybe it will help,somebody try include option maybe help,issue,negative,neutral,neutral,neutral,neutral,neutral
362945015,"@shadowfolder @ruah1984 

Just edit ```./plugins/Model_LowMem.py:13```

Update ENCODER_DIM to something lower, 256 or 128.

I'm testing things on my 970M, and the predefined profile isn't sufficient, I get the OOM error if I use the 512 encoder (even though the card has 3GBs of VRam).

On my rig I use batches of 16 images, with the ENCODER_DIM set to 256.",edit update something lower testing profile sufficient get error use even though card rig use set,issue,negative,neutral,neutral,neutral,neutral,neutral
362944625,"hi, can we update all the plugin function to USAGE.MD? i have no idea for the plugin, if some one else can update it how it can type in the terminal. ",hi update function idea one else update type terminal,issue,negative,neutral,neutral,neutral,neutral,neutral
362943874,"You need to add:
> --trainer=""LowMem""

for using Model_LowMem.py

But I have the same problem with ""Resource exhausted: OOM"" and using ""LowMem"" doesn't solve my problem.

p.s. GeForce GTX 950 2GB vram",need add problem resource exhausted solve problem,issue,negative,negative,negative,negative,negative,negative
362934345,Glad it's working... yes I am running 1.5 (master branch) w/CUDA 9.1.  I posted the pip packages [here](https://github.com/deepfakes/faceswap/issues/113#issuecomment-362897301) and I'm going to post an more extensive LINUX-README.md that I'll write later today.,glad working yes running master branch posted pip going post extensive write later today,issue,positive,positive,positive,positive,positive,positive
362934199,"Thanks mate! I fix it by installed and add libcudnn6-dev version:

https://yangcha.github.io/Install-CUDA8/
p.s. Are you now running tensorflow 1.5 with CUDA 9.1? Would be great if you paste here your pip packages (**pip3 list**)




",thanks mate fix add version running would great paste pip pip list,issue,positive,positive,positive,positive,positive,positive
362933595,I'm not sure-- could it be baked into the tensorflow you installed with pip?  You really might consider [building tensorflow yourself](https://www.tensorflow.org/install/install_sources).  I'm running CUDA 9.1 and CudNN 7.... and it works with a self-built tensorflow.  that way duringthe installation I could tell it exactly what the version of everything is.  I'm writing up some tips right now on self-building for Linu FWIW so I'll post those in acouple hours in a PR.,sure could baked pip really might consider building running work way installation could tell exactly version everything writing right post,issue,negative,positive,positive,positive,positive,positive
362933125,"@fat-tire yes, i have cudnn for cuda8.
I thought it was because tensorflow 1.5, i've reinstalled tensorflow 1.4 (pip3 install --upgrade tensorflow-gpu==1.4)

Added export path like you
**#cuda 8
export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64**

But... Now i have ImportError: libcudnn.so.6: cannot open shared object file: No such file or directory
Hm... Why is showing  libcudnn.so.6?
",yes thought pip install upgrade added export path like export path path export open object file file directory showing,issue,positive,neutral,neutral,neutral,neutral,neutral
362932413,"lol just RTFM now - https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy

there is actually a ThreadPool in multiprocessing.  Just not well doc'd at all.

- not this but something very like...(this will actually work btw, try it)

```
from multiprocessing.pool import ThreadPool

method = None

def pool_process(method_to_run, data):
    global method
    method = method_to_run
    pool = ThreadPool()
    for i in pool.imap_unordered(runner, data):
        yield(i)
    
def runner(item):
    return method(item)
```

This is actually good in some ways as using imap_unordered (like you had with the processes) is going to be hella faster than ThreadPoolExecutor.map - plus this way there  is no dependence of futures as with ThreadPoolExecutor  :) Still, it could be a lot prettier sans globals here....also could update shared mem for counts with lock....hmmm.

Really don't want to tread on toes or offend here :) I'm happy to play with this for a couple of hours to get it solid?
",actually well doc something like actually work try import method none data global method method pool runner data yield runner item return method item actually good way like going faster plus way dependence still could lot sans also could update mem lock really want tread offend happy play couple get solid,issue,positive,positive,positive,positive,positive,positive
362931650,"do you have [cudnn](https://developer.nvidia.com/cudnn) installed?

Also your export looks strange in in `~/.bashrc`.  Here's what I added:

`export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64`

Finally, see [here](https://github.com/tensorflow/tensorflow/issues/15604).",also export strange added export finally see,issue,negative,negative,neutral,neutral,negative,negative
362931360,"Installed tensorflow-gpu, but i'm getting:
python3 faceswap.py train -A '/home/tuw/Desktop/faceswap/data/trump1'  -B '/home/tuw/Desktop/faceswap/data/cage'  -m '/home/tuw/Desktop/faceswap/data/model' -p
Model A Directory: /home/tuw/Desktop/faceswap/data/trump1
Model B Directory: /home/tuw/Desktop/faceswap/data/cage
Training data directory: /home/tuw/Desktop/faceswap/data/model
Loading data, this may take a while...
Using live preview
Loading Model from Model_Original plugin...
/home/tuw/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/tuw/Desktop/faceswap/scripts/train.py"", line 122, in processThread
    model = PluginLoader.get_model(trainer)(self.arguments.model_dir)
  File ""/home/tuw/Desktop/faceswap/plugins/PluginLoader.py"", line 13, in get_model
    return PluginLoader._import(""Model"", ""Model_{0}"".format(name))
  File ""/home/tuw/Desktop/faceswap/plugins/PluginLoader.py"", line 22, in _import
    module = __import__(name, globals(), locals(), [], 1)
  File ""/home/tuw/Desktop/faceswap/plugins/Model_Original.py"", line 3, in <module>
    from keras.models import Model as KerasModel
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/utils/conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/backend/__init__.py"", line 83, in <module>
    from .tensorflow_backend import *
  File ""/home/tuw/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/tuw/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.



Why is that happening? I already have nvidia driver and cuda8 installed
**_nvcc --version_
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Tue_Jan_10_13:22:03_CST_2017
Cuda compilation tools, release 8.0, V8.0.61**


And in ~/.bashrc i have path's:
**export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}**







P.S. Monitoring app is conky, here is my ~/.conyrc file https://pastebin.com/5fnPAx6m",getting python train model directory model directory training data directory loading data may take live preview loading model conversion second argument float future float import exception thread recent call last file line module import file line module file line description file line return name file file line return spec open object file file directory handling exception another exception recent call last file line file line run file line model trainer file line return model name file line module name file line module import model file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module raise recent call last file line module import file line module file line description file line return name file file line return spec open object file file directory load native see common include entire stack trace error message help happening already driver compiler driver copyright corporation built compilation release path export path path export conky file,issue,negative,negative,neutral,neutral,negative,negative
362928778,"Thanks for your feedback. I see you are using cuda with dlib. With loaded model for convert, maybe it starts being too much for the gpu. You should try to profile to see how much memory is used, maybe try nvidia-smi. The cnn option is not better for all, just for rotated and side faces.

The convert with GAN is limited for now, but with small changes, I can make all convert work with GAN. I'll try to add it this week ",thanks feedback see loaded model convert maybe much try profile see much memory used maybe try option better rotated side convert gan limited small make convert work gan try add week,issue,positive,positive,positive,positive,positive,positive
362928031,"Ok, let's go for that.

I'm just benchmarking by running an extract with 400 images ",let go running extract,issue,negative,neutral,neutral,neutral,neutral,neutral
362926530,"@Clorr 

Thanks for adding this Plugin! Have two questions about it, hope you can help me out:

1) After training, when i start the conversion script and select the `--detector` option `cnn` i get this error:
```Failed to convert image: (...) Reason: Error while calling cudaMalloc(&data, n) in file /private/var/folders/1j/r_nj68nn3tl7sqfc93_18t_80000gp/T/pip-build-o7algsyj/dlib/dlib/dnn/cuda_data_ptr.cpp:28. code: 2, reason: out of memory```

The output images are 1280 x 720px and i use a GTX 1080 Ti with 11 GB VRAM. I have two cards installed, one for handling the display and OS stuff and the 1080 solely for Machine Learning. So i always have the full 11 GB available for CUDA processing. Was just wondering – **aren't 11 GB enough for this output size**? Can i tweak some parameters – where should i look? I know the alternative option is selecting `hog` and that works, but i guess the `cnn` option yields better results.

2) Is there an option when using the GAN converter to get seamless faces on the output images? I've trained quite a while and still have hard edges around the faces.",thanks two hope help training start conversion script select detector option get error convert image reason error calling data file code reason memory output use ti two one handling display o stuff solely machine learning always full available wondering enough output size tweak look know alternative option hog work guess option better option gan converter get seamless output trained quite still hard around,issue,positive,positive,positive,positive,positive,positive
362926323,"@gdunstone Of course there's no reason for the batch size to be bigger, but say somethings doing something where only 40 images exist of one person (reasonable thing for someone to attempt) and didn't know how to change the batch size. Hence it being an error.

@facepainter when you add the column descriptors, consider adding what they should look like for a good model.",course reason batch size bigger say something exist one person reasonable thing someone attempt know change batch size hence error add column consider look like good model,issue,negative,positive,positive,positive,positive,positive
362924073,"@Clorr  yeah that works, threading is the way to do it, much simpler and avoids the memory isolation / pickling issues :) - that is really good in the profiler too, much faster :)

OOI what are you using to profile/benchmark - i've been using the Python Profiling in Visual Studio 2017  and I'm really impressed. ",yeah work way much simpler memory isolation really good profiler much faster python visual studio really,issue,negative,positive,positive,positive,positive,positive
362923216,"> If it worked for you and you are linux? Then it must be linux/windows os.fork BS. Wouldn't be surprised if global behaves differently here somehow across platform :(
Yes it is annoying

For the multi processing, the sharing of data is a problem, but here, we don't really have to share data, because each task handles one image and saves it, so it simplifies things.",worked must would global differently somehow across platform yes annoying data problem really share data task one image,issue,negative,negative,negative,negative,negative,negative
362922226,"@Clorr

>   I took reference here for the global.

Ah yeah - that wont work across process at all. 
If you imagine, you can't spawn a process - then have that process do a bunch of stuff in memory on another process (i.e. the one that spawned it), you have to use IPC rather than shared memory when doing such things. 

multi threading/processing has a bunch of caveats to it - mainly that anything you pass across processes has to be picklable (serialisable). 

(As an aside this is actually where electron/nodejs excels - it is totally built on the asynchronous IPC model - almost enforces it throughout...more my background too).

Will test now with the thread pool but at a glance that looks good :)

>I see from your stack that you are using python 3.6, while I'm using 3.5, maybe the behavior have change in between. 

I get same in 3.5/3.6....

If it 100% worked for you and you are linux? Then it must be linux/windows os.fork BS. Wouldn't be surprised if global behaves differently here somehow across platform  :(",took reference global ah yeah wont work across process imagine ca spawn process process bunch stuff memory another process one use rather memory bunch mainly anything pas across aside actually totally built asynchronous model almost throughout background test thread pool glance good see stack python maybe behavior change get worked must would global differently somehow across platform,issue,positive,positive,positive,positive,positive,positive
362921406,"My intention is to use this code here instead of the FakeApp GUI. And now I want to figure out where I can find the parameters ""Layers"" and ""Nodes"" in the faceswap code.",intention use code instead want figure find code,issue,negative,neutral,neutral,neutral,neutral,neutral
362918960,"The question is: what is your global understanding of the code, and what is your intention here?

If your problem is that you have not enough memory to run the model, you should use the LowMem plugin instead of modifying things.

If you want to play with the model and adjust yourself the params, I would assume you have enough background to do so...",question global understanding code intention problem enough memory run model use instead want play model adjust would assume enough background,issue,negative,neutral,neutral,neutral,neutral,neutral
362918144,"I tried with this code in `lib/multithreading.py`:

```
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor()

def pool_process(method_to_run, data):
    for i in executor.map(method_to_run, data):
        yield i if i is not None else 0
```

And it seems to perform as well as the previous solution. Can you tell me if it is ok for you @facepainter ?

**edit:** I ran 2 tests to test previous version and this one, they seemed to show similar performance, but maybe I did a mistake because, when I run them now, I have better result for previous version. So  maybe this patch is not as fast as the previous one. Let me know if you see differences",tried code import executor data data yield none else perform well previous solution tell edit ran test previous version one show similar performance maybe mistake run better result previous version maybe patch fast previous one let know see,issue,negative,positive,neutral,neutral,positive,positive
362917230,"@facepainter if you find a patch for your platform, let me know. I'm checking on my side, but I don't want to upgrade python for now...",find patch platform let know side want upgrade python,issue,negative,neutral,neutral,neutral,neutral,neutral
362917041,"@facepainter I see from your stack that you are using python 3.6, while I'm using 3.5, maybe the behavior have change in between. I took reference [here](https://stackoverflow.com/questions/423379/using-global-variables-in-a-function-other-than-the-one-that-created-them) for the `global`.

Also on the thread/process questions, I took what I found in Python, as I'm still beginner in Python, so maybe it is not the right way to go. If you have better samples to show me, feel free.",see stack python maybe behavior change took reference global also took found python still beginner python maybe right way go better show feel free,issue,positive,positive,positive,positive,positive,positive
362916791,"Hey,
Ive studied a bit the ""Model_Original.py"", but I cant figure out what parameter is for adjusting nodes and layers. Do I have do change the ENCODER_DIM to adjust the node? And how do I adjust layers?
Can you help me please?",hey studied bit cant figure parameter change adjust node adjust help please,issue,positive,neutral,neutral,neutral,neutral,neutral
362916716,"Hi @gdunstone,
honestly, but it's just my opinion, I prefer my solution since it fixes the problem and it lets someone with a small group of images (say for example 63, since the default batch size is 64) to use the script without having to manually adjust the -bs argument.",hi honestly opinion prefer solution since problem someone small group say example since default batch size use script without manually adjust argument,issue,positive,positive,positive,positive,positive,positive
362912584,"@dfaker Thanks, I haven't checked your code in depth for now, but maybe I can do a plugin from it. I'll try to check end of coming week",thanks checked code depth maybe try check end coming week,issue,negative,positive,positive,positive,positive,positive
362910918,"@Clorr Hey there, feel free to ask any questions of bits you'd like to have offered for pull, I keep meaning to send over a patch for the multi-threaded version of https://github.com/dfaker/df/blob/master/training_data.py#L56 which can be a major bottleneck if you've got a fast enough GPU.",hey feel free ask like pull keep meaning send patch version major bottleneck got fast enough,issue,positive,positive,positive,positive,positive,positive
362910673,"@Clorr - Hmm yes I still get the error on exact against your master (that is correct yes?) , I get 0 results and the following in the console.

```
multiprocessing.pool.RemoteTraceback:
Traceback (most recent call last):
  File ""U:\Python\Python36\Lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""U:\faceswap\lib\multithreading.py"", line 13, in runner
    return method(item)
TypeError: 'NoneType' object is not callable

The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File ""faceswap.py"", line 24, in <module>
    arguments.func(arguments)
  File ""U:\faceswap\lib\cli.py"", line 53, in process_arguments
    self.process()
  File ""U:\faceswap\scripts\extract.py"", line 30, in process
    self.faces_detected = sum(pool_process(self.processFiles, list(self.read_directory())))
  File ""U:\faceswap\lib\multithreading.py"", line 9, in pool_process
    for i in pool.imap_unordered(runner, data):
  File ""U:\Python36\Lib\multiprocessing\pool.py"", line 735, in next
    raise value
TypeError: 'NoneType' object is not callable
```

> The global method shouldn't be a big deal because it is written once, and read multiple times, which should be thread-safe.

Not pretending to know loads about this or anything, like I said my python is well rusty ( that sounds wrong) ...anyway, basically multi-threading!=multi-processing. Threads share the same memory, processes don't - they have....different process ID, etc. It is confusing because 

```
def runner(item):
    return method(item) 
```

is right there....but ""method"" here is not ""global method"" above - this is because when runner is called ```pool.imap_unordered(runner, data)``` it starts a whole new process that has its own memory. At least as I understand it. Or else am I totally missing the point!?! Was pretty sure that is why it was failing for me.... 

Tell me to shut up if I am talking shit here :) Just really want it to be fassssst nooooow :)",yes still get error exact master correct yes get following console recent call last file line worker result true file line runner return method item object callable exception direct cause following exception recent call last file line module file line file line process sum list file line runner data file line next raise value object callable global method big deal written read multiple time know anything like said python well rusty wrong anyway basically share memory different process id runner item return method item right method global method runner runner data whole new process memory least understand else totally missing point pretty sure failing tell shut talking really want,issue,positive,positive,neutral,neutral,positive,positive
362910062,"whoops my bad, I was going off the old version proposed here:

https://github.com/deepfakes/faceswap/pull/62/commits/c4a65ebc147d39105b1acee5345ec756a403b9b7",whoop bad going old version,issue,negative,negative,negative,negative,negative,negative
362908493,"Hmm, can you point out which line it is? In `lib/multithreading.py`, I'm using `Pool` because it was almost a one liner, but I had to use an intermediate var because the `map/imap` functions where not ok with a class method",point line pool almost one liner use intermediate class method,issue,negative,neutral,neutral,neutral,neutral,neutral
362908247,What's the benefit of using Process over Pool in this instance? It seems like it adds some unnecessary complexity. ,benefit process pool instance like unnecessary complexity,issue,positive,negative,negative,negative,negative,negative
362906922,"There is no parameter to modify the model, because the model files can only be reloaded if the parameters stay constant. If you want to do so, you have to modify directly the `Model` file in the `plugins` folder. ",parameter modify model model stay constant want modify directly model file folder,issue,negative,positive,neutral,neutral,positive,positive
362906574,"If you use -w param, you will have a file written to the disk, but I don't know if you can retrieve it from your notebook.

Otherwise, you can go in `scripts/train.py`, copy the code, and use this as your notebook, instead of running python from shell. Then you can modify the `show` function at the bottom of the file, and replace it with : `display(Image.fromarray(image))`. Don't forget to import the libs:
```
from PIL import Image
from IPython.display import display
```

You will have also to set the arguments manually because the arguments parsing won't work

If you have a clean way to use python notebooks, please submit a pull request, and share your notebooks with others. (put them in a `/notebook/` folder at the root)",use param file written disk know retrieve notebook otherwise go copy code use notebook instead running python shell modify show function bottom file replace display image forget import import image import display also set manually wo work clean way use python please submit pull request share put folder root,issue,positive,positive,positive,positive,positive,positive
362905893,"Please report how you fixed this in this thread, if you think it may help other users",please report fixed thread think may help,issue,positive,positive,neutral,neutral,positive,positive
362905569,"@fat-tire HUGE thanks mate! Now i finally installed it and run it without any errors. Damnit, this takes me over 40 hours to figure it out and with your help i did it. Now i know where was error. Also thanks @Clorr ",huge thanks mate finally run without figure help know error also thanks,issue,negative,positive,positive,positive,positive,positive
362904939,"@gdunstone the mmod face detector is in extract & convert, it wouldn't make sense otherwise ;-)

@seattleg yes, the mmod detector is ultra slow on large images, but it remains an alterntive, it is not used by default

@facepainter I'm not really satisfied of how I handled `lib/multithreading.py` but I got it working like that.. The `global method` shouldn't be a big deal because it is written once, and read multiple times, which should be thread-safe. If anyone has a better solution, I'm fine, it also why I did a separate file so that it is simple to modify it. But please confirm you have the error with the latest versions, because I had it before, but it should be solved",face detector extract convert would make sense otherwise yes detector ultra slow large remains used default really satisfied handled got working like global method big deal written read multiple time anyone better solution fine also separate file simple modify please confirm error latest,issue,positive,positive,positive,positive,positive,positive
362904112,"@shadowfolder please open only one issue when you have trouble with your install, you will get feedback from others anyway",please open one issue trouble install get feedback anyway,issue,negative,negative,neutral,neutral,negative,negative
362903986,"@fat-tire thanks for all these info, feel free to add them in the INSTALL.md, or even create a new file like INSTALL-UBUNTU.md",thanks feel free add even create new file like,issue,positive,positive,positive,positive,positive,positive
362903893,"@shadowfolder the docker file helps for the general setup, but the most important thing is to install the requirements located in `./requirements.txt`

If you want to use the GPU, install ./requirements-gpu.txt as well as CUDA and CuDNN (see https://yangcha.github.io/Install-CUDA8/)

Note that GPU is not supported in Docker unless you adventure yourself with nvidia-docker.

If you have errors, report them explicitly or we won't be able to help you",docker file general setup important thing install want use install well see note docker unless adventure report explicitly wo able help,issue,positive,positive,positive,positive,positive,positive
362900815,"@gdunstone  sure, happy to help wherever :) will have time this w/e. Also agree about the check ""seems like almost no reason"" -, it is an edge case - but it already came up lol.",sure happy help wherever time also agree check like almost reason edge case already came,issue,positive,positive,positive,positive,positive,positive
362897301,"**A NOTE ON USING THIS W/LINUX--**

I built tensorflow myself in Ubuntu 17.10 (x86_64), so I'm not going to get into the details of building from source, but a few things that the README doesn't note:

0.  If you are building from source, make sure you use `/usr/bin/python3` not `/usr/bin/python` when running `./configure`.  I won't go into how to do the rest as the [official instructions](https://www.tensorflow.org/install/install_sources) are pretty good. (If you're not building from source you won't get all the benefits of an optimized build for your specific machine.)

1.  You'll also need to `apt-install cmake` before installing the python modules.

2.  You need to use `pip3` and not `pip`, since deepfakes uses python3 not python 2.7

```
sudo apt-install cmake
pip3 install scandir
pip3 install pathlib
pip3 install h5py
pip3 install Keras
pip3 install opencv-python
pip3 install tqdm
pip3 install face_recognition
```
3.  If you are going to use the gpu and you have an nvidia driver (and are installing the cuda 9.1 and cudann packages from nvidia) you probably want to use the latest 387 version driver.  For me that was 387.34.   I got a black screen on boot using the standard 387 -- the fix was to `sudo add-apt-repository ppa:graphics-drivers` first and then I got the driver that worked.

4.  So if you're NOT building you'd do `pip3 install tensorflow` and maybe `pip3 install tensorflow-tensorboard` if you want the nifty web visualizer thing.  I had thought there was a tensorflow-gpu too but what do I know..

5.  There seems to be a bug with `faceswap.py` and python3 in 17.10 that required a small change.  There's actually a better way to fix this, but this works if you run into a crash on the last line about missing 'func'  (yes, I am bringing you the 'func').  Just add:

    parser.set_defaults(func=exit(0))

above the 2nd-to-last line in the file:

    arguments= parser.parse_args()

Basically this is what the program does if you don't give it any arguments.  So you're just saying to exit.  You can also make a function like:

def need_more_args(args):
    print('Use an argument:  [ extract | train | convert ]')
    exit(0)

Then you could change that 3rd-to-last-line to:

    parser.set_defaults(func=need_more_args)

6.  There are minor other issues, such as the input file containing the raw images should be called `/input` not `/src` and the faces are placed in `/output` not `/extract`.  But whatever.  You can override that with `-i` and `-o` for the input and output directories.  (or -A and -B for the two faces directories when training.  Both `-A` and `-B` default to `/input` I think, so be careful)

All that said, I'm still playing with this myself, but I hope this helps.",note built going get building source note building source make sure use running wo go rest official pretty good building source wo get build specific machine also need python need use pip pip since python python pip install pip install pip install pip install pip install pip install pip install going use driver probably want use latest version driver got black screen boot standard fix first got driver worked building pip install maybe pip install want nifty web visualizer thing thought know bug python small change actually better way fix work run crash last line missing yes add line file basically program give saying exit also make function like print argument extract train convert exit could change minor input file raw whatever override input output two training default think careful said still hope,issue,positive,positive,positive,positive,positive,positive
362895201,"tl;dr - I get a  ""NoneType is not callable"" when extracting

My python is not the strongest, need to RTFM myself but to me the global use in #109 lib/multithreading.py seems odd.

Can runner call (bound method ExtractTrainingData.processFiles) via a global like that? I thought it was not possible to use a global between two separate processes... If I do a quick test of this it throws ""NoneType is not callable"".

Again - don't quote me - but pretty sure you need Queue or Pipe, to share picklable stuff between processes... and as this is a bound method I'm not sure that would work.

Maybe I'm too tired or not high enough...totally disregard if this makes no sense - I could well be doing something odd :) 


 








",get callable python need global use odd runner call bound method via global like thought possible use global two separate quick test callable quote pretty sure need queue pipe share stuff bound method sure would work maybe tired high enough totally disregard sense could well something odd,issue,positive,positive,neutral,neutral,positive,positive
362892067,@facepainter Could you add that information about the preview window to our USAGE.md?,could add information preview window,issue,negative,neutral,neutral,neutral,neutral,neutral
362891895,"@Gastel71 it is better to throw an error in this case.

I would put a test just before processing begins:

https://github.com/deepfakes/faceswap/blob/1f1cbdf0e7c69a1cdf162e182470c51d3e6623d2/lib/training_data.py#L33

```python
assert length >= batchsize, ""Number of images less than batch size. # images: {}"".format(length)
```

Correct me if Im wrong but there seems like almost no reason why the batch size should be larger than the number of images.",better throw error case would put test python assert length number le batch size length correct wrong like almost reason batch size number,issue,negative,neutral,neutral,neutral,neutral,neutral
362886098,"Just change line 43 on training_data.py to
`rtn = numpy.float32([read_image(data[j]) for j in range(i,min(length,i+size))])`
if you want to fix the index out of range error",change line data range min length want fix index range error,issue,negative,neutral,neutral,neutral,neutral,neutral
362878295,"I remember trying the dlib cnn face detector out myself and it kept giving out of memory errors because the input images were 1280x720, I had to dial back the image size using cv2.resize to less than a half of the dimensions to get it working on my 8GB gpu. ",remember trying face detector kept giving memory input dial back image size le half get working,issue,negative,negative,neutral,neutral,negative,negative
362876324,Is the accuracy higher for this one? And can we specify this for the convert as well? I have had some issues with inaccurate scaling with the current detector for convert but I have processing power up the wazoo. ,accuracy higher one specify convert well inaccurate scaling current detector convert power,issue,negative,positive,positive,positive,positive,positive
362874074,"OpenCV was installed by anaconda, i've removed anaconda and getting another error:
python3 faceswap.py train -A /home/tuw/Desktop/trump -B /home/tuw/Desktop/cage -m /home/tuw/Desktop/models -p
Traceback (most recent call last):
  File ""faceswap.py"", line 10, in <module>
    from scripts.extract import ExtractTrainingData
  File ""/home/tuw/Desktop/faceswap/scripts/extract.py"", line 4, in <module>
    from lib.cli import DirectoryProcessor
  File ""/home/tuw/Desktop/faceswap/lib/cli.py"", line 7, in <module>
    from lib.FaceFilter import FaceFilter
  File ""/home/tuw/Desktop/faceswap/lib/FaceFilter.py"", line 3, in <module>
    import face_recognition
  File ""/usr/local/lib/python3.5/dist-packages/face_recognition/__init__.py"", line 7, in <module>
    from .api import load_image_file, face_locations, batch_face_locations, face_landmarks, face_encodings, compare_faces, face_distance
  File ""/usr/local/lib/python3.5/dist-packages/face_recognition/api.py"", line 4, in <module>
    import dlib
ImportError: libmkl_rt.so: cannot open shared object file: No such file or directory

I've reinstall face_recognition package but this doesn't helped me :cry: ",anaconda removed anaconda getting another error python train recent call last file line module import file line module import file line module import file line module import file line module import file line module import open object file file directory reinstall package cry,issue,negative,neutral,neutral,neutral,neutral,neutral
362871783,"It looks like your version of opencv was built without any gui support and is lacking the waitKey function.

How did you install it? Where from?  Do you have previous/other version of OpenCV installed?

To be sure what is the output of...

```
import cv2
print cv2.__version__
```

Whatever the case - you can DL the latest releases and source from here - https://opencv.org/releases.html",like version built without support function install version sure output import print whatever case latest source,issue,negative,positive,positive,positive,positive,positive
362870703,"Not really the place for an extended discussion about that here....but 

col 1 shows A 
col 2 shows A redrawn using model
col 3 shows predicted transform A->B
cols 4-6 do the same as 1-3.
cols 7-9 do the same as 1-3 but swap A for B
cols 10-12 do the same 7-9.

Edit - actually there is a good explanation with pictures here - https://www.deepfakes.club/tutorial/",really place extended discussion col col model col transform swap edit actually good explanation,issue,negative,positive,positive,positive,positive,positive
362869211,"Fair enough, just mentioning people would be worth including in the usage.md if you want to go that way. 

Also, if you don't mind, could you please walk me through what the window shown by -p is displaying? That flag and the usage don't specify, and (at least without a trained model) it's not clear what exactly it's representing (I'm familiar with CNNS, GANs etc, but all that pops up is a grid of images and blurry colors, which isn't enough on it's own without labeled columns etc).",fair enough people would worth want go way also mind could please walk window shown flag usage specify least without trained model clear exactly familiar grid blurry color enough without,issue,negative,positive,positive,positive,positive,positive
362868992," You can get the full list of arguments for each script by running it with the help flag. e.g.

> python faceswap.py -h
> python faceswap.py train -h
> python faceswap.py extract -h
> python faceswap.py convert -h
",get full list script running help flag python python train python extract python convert,issue,negative,positive,positive,positive,positive,positive
362868363,"Could you add the -bs flag to the usage md file as well?
",could add flag usage file well,issue,negative,neutral,neutral,neutral,neutral,neutral
362868153,"> My paths are fine, they're just weird. the <> is to anonymize it if that's what you're asking about.

Ah ok, makes sense.

> Is there a flag to change the batch size to get around this?

Sure - just set the batch size via the -bs flag (Batch size, as a power of 2 (64, 128, 256, etc))

`train -A ~/faceswap/A -B ~/faceswap/B -m ~/faceswap/models -bs 32
`
Looking at 

https://github.com/deepfakes/faceswap/blob/2198ec677961aad77dfab25988b62b0ea654e8a0/lib/training_data.py#L43

There is actually a check on line 39 - but 43 is not in that scope....

https://github.com/deepfakes/faceswap/blob/2198ec677961aad77dfab25988b62b0ea654e8a0/lib/training_data.py#L39

Anyhow I am sure it can be fixed easily. 
I guess it hasn't come up because most people are training with 100s/1000s of images.

> Also, because I can't find this anywhere else, how many images are recommended

Well quality has more to do that quantity - there isn't a  recommended amount - the more good data you throw at it the better it gets.",fine weird ah sense flag change batch size get around sure set batch size via flag batch size power train looking actually check line scope anyhow sure fixed easily guess come people training also ca find anywhere else many well quality quantity amount good data throw better,issue,positive,positive,positive,positive,positive,positive
362867934,"My paths are fine, they're just weird. the <> is to anonymize it if that's what you're asking about.

The 64 items explains it; a more specific error and documentation would be very helpful. I'm doing something specific where there's only 40 images available for the face being transferred. Is there a flag to change the batch size to get around this?

Also, because I can't find this anywhere else, how many images are recommended? (I'm aware it's more than 40, but ball park).",fine weird specific error documentation would helpful something specific available face transferred flag change batch size get around also ca find anywhere else many aware ball park,issue,negative,positive,positive,positive,positive,positive
362867554,"Are you sure the number of input images is greater than your batch size?

That is - make sure there more than 64 images in the source directories you are training with...

Also - your paths look funky....

Model A Directory: /<>/data
Model B Directory: /home/<>data

are you sure they are correct?",sure number input greater batch size make sure source training also look funky model directory model directory data sure correct,issue,positive,positive,positive,positive,positive,positive
362850453,@Clorr @facepainter Thanks for your interest and the new class :) I will try to understand your functions and classes better and then work on adapting a data generator class for our usage in my free times.,thanks interest new class try understand class better work data generator class usage free time,issue,positive,positive,positive,positive,positive,positive
362845999,"@fcakyon @Clorr  ah - my bad, misunderstood - that is actually *super* useful!",ah bad misunderstood actually super useful,issue,negative,negative,neutral,neutral,negative,negative
362844665,"Added in #109

Note that it is really slow, and may conflict with multithreading, but I need your feedback on that...",added note really slow may conflict need feedback,issue,negative,negative,negative,negative,negative,negative
362844536,"Now with mmod_human_face_detector! Add the -D cnn argument to activate it. But be careful, it is really slow and time consuming, but it detects faces from many more angles",add argument activate careful really slow time consuming many,issue,negative,positive,neutral,neutral,positive,positive
362842151,"It is also possible that you have installed Cuda 9 instead of Cuda 8. 
You need to upgrade tensorflow to 1.5.0 or downgrade Cuda to 8 version.",also possible instead need upgrade downgrade version,issue,negative,neutral,neutral,neutral,neutral,neutral
362837913,"Your cuda/cudnn install is not complete. You can see it here: ` ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory`

The best resource I found for that is: https://yangcha.github.io/Install-CUDA8/
",install complete see open object file file directory best resource found,issue,positive,positive,positive,positive,positive,positive
362827172,"@fcakyon If you look at [this commit](https://github.com/Clorr/faceswap/commit/ae671067cae835cf71a928043dc19a891f0515c3) , you will find a new class named `TrainingDataGenerator` which could be a base for your modifications if you want",look commit find new class could base want,issue,negative,negative,negative,negative,negative,negative
362818379,"Multi-threading and GPU processing are 2 separate thing. The code here does not use GPU at all, it is only the library used that are made to use it or not. If you want to have GPU for extract you can look for a `dlib` compiled with CUDA support.

In #62, there is a proposal for multi threading, which will increase throughput by using all CPU cores, but not use GPU",separate thing code use library used made use want extract look support proposal increase throughput use,issue,positive,neutral,neutral,neutral,neutral,neutral
362817862,"@fcakyon I find your link very interesting, and if you can provide a working version, feel free ;-)

The only thing I'm wondering here is that, as of now, we don't use `.fit(...)`, but `.train_on_batch(...)` which, AFAIK, loads only one batch at a time. Also it is done like this because the model is composed of one encoder and 2 decoders trained with separate data. I don't know if it is possible to use `.fit(...)` with such a configuration. But, again, feel free to propose. If it works, it will be accepted.

Note that the training data preparation is done in `lib/training_data.py` which I intend to heavily rework (after reading your link ;-) ), so please warn me if you intend to work on that soon.",find link interesting provide working version feel free thing wondering use one batch time also done like model composed one trained separate data know possible use configuration feel free propose work accepted note training data preparation done intend heavily rework reading link please warn intend work soon,issue,positive,positive,positive,positive,positive,positive
362804197,"I changed some code that fixes your issue @AngryLoki :
```
diff --git a/scripts/train.py b/scripts/train.py
index aa536d8..e097e31 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -6,11 +6,14 @@ from lib.utils import get_image_paths
 from lib.cli import FullPaths
 from plugins.PluginLoader import PluginLoader
 
+from threading import Lock
+
 class TrainingProcessor(object):
     arguments = None
 
     def __init__(self, subparser, command, description='default'):
         self.parse_arguments(description, subparser, command)
+        self.lock = Lock()
 
     def process_arguments(self, arguments):
         self.arguments = arguments
@@ -96,8 +99,9 @@ class TrainingProcessor(object):
             print('Using live preview')
             while True:
                 try:
-                    for name, image in self.preview_buffer.items():
-                        cv2.imshow(name, image)
+                    with self.lock:
+                        for name, image in self.preview_buffer.items():
+                            cv2.imshow(name, image)
 
                     key = cv2.waitKey(1000)
                     if key == ord('\n') or key == ord('\r'):
@@ -156,15 +160,16 @@ class TrainingProcessor(object):
         except Exception as e:
             print(e)
             exit(1)
-    
+
     preview_buffer = {}
 
     def show(self, image, name=''):
         try:
-            if self.arguments.preview:
-                self.preview_buffer[name] = image
-            elif self.arguments.write_image:
-                cv2.imwrite('_sample_{}.jpg'.format(name), image)
+            with self.lock:
+                if self.arguments.preview:
+                    self.preview_buffer[name] = image
+                elif self.arguments.write_image:
+                    cv2.imwrite('_sample_{}.jpg'.format(name), image)
         except Exception as e:
             print(""could not preview sample"")
             print(e)

```
",code issue git index import import import import lock class object none self command description command lock self class object print live preview true try name image name image name image name image key key key class object except exception print exit show self image try name image name image name image name image except exception print could preview sample print,issue,negative,positive,neutral,neutral,positive,positive
362795779,"When launching with `-p`:
```[12:55:41] [0/num_epochs][0] Loss_DA: 0.246727 Loss_DB: 0.248788 Loss_GA: 0.523137 Loss_GB: 0.475922
Traceback (most recent call last):
  File ""faceswap.py"", line 24, in <module>
    arguments.func(arguments)
  File ""/projects/face-work/faceswap/scripts/train.py"", line 21, in process_arguments
    self.process()
  File ""/projects/face-work/faceswap/scripts/train.py"", line 99, in process
    for name, image in self.preview_buffer.items():
RuntimeError: dictionary changed size during iteration
```",recent call last file line module file line file line process name image dictionary size iteration,issue,negative,neutral,neutral,neutral,neutral,neutral
362784069,"If you train a model without a Data Generator implementation, script puts the whole data in vram/ram, then updates the weights in batches. However, with DataGenerator, it only puts the batch to vram/ram, and only after finishing current batch, it puts new input data to vram/ram, resulting in a significantly reduced vram usage.
After implementing a custom generator function, you perform the training with fit_generator function.
I can help on this topic if needed.
Keep the good work up! :)",train model without data generator implementation script whole data however batch finishing current batch new input data resulting significantly reduced usage custom generator function perform training function help topic keep good work,issue,positive,positive,positive,positive,positive,positive
362783754,"No I dont mean that. Bu using Keras Data Generator, you can make model read images in batches instead of allocating vram for all of the training images at the same time. This way it always uses batch size of vram which would be sms'ler than 1gb.",dont mean bu data generator make model read instead training time way always batch size would,issue,negative,negative,negative,negative,negative,negative
362780877,@fcakyon ... the code is already using the Keras functional API to create a dense connected network rather than just using the standard Sequential model...also it already supports configurable batch processing.,code already functional create dense connected network rather standard sequential model also already batch,issue,negative,neutral,neutral,neutral,neutral,neutral
362742713,"I think its better to use explicit keyword arguments with defaults because its self documenting and it provides for the case of the converter being used as a lib, but what you wrote seems fine.

Ill give this version a go at some point soon.",think better use explicit self case converter used wrote fine ill give version go point soon,issue,negative,positive,positive,positive,positive,positive
362657876,"Having better defined images as output means the model has to learn smaller features, and need then a bigger model.

I was aware of the faceswap-GAN version, and I intend to add it. Thanks for the @dfaker link, I was not aware of it!",better defined output model learn smaller need bigger model aware version intend add thanks link aware,issue,positive,positive,positive,positive,positive,positive
362654657,"I don't know much about this issue, but I think it comes from a bad training set of images. Please note that if you have too few images or too few diversity in images, the model cannot invent angles he does not know about. If you think it is not the case, feel free to reopen",know much issue think come bad training set please note diversity model invent know think case feel free reopen,issue,negative,negative,neutral,neutral,negative,negative
362653508,"You may have a silent failure. When you see `usage: faceswap.py...` it is because it has failed. With the latest versions, there should be less silent errors, but I closed this because there is not enough info",may silent failure see usage latest le silent closed enough,issue,negative,positive,neutral,neutral,positive,positive
362651639,"`lib/utils.py` has now the `mkdir` activated, so it won't fail anymore if the directory does not exist. If we have to add a prompt, the issue can be reopened.",wo fail directory exist add prompt issue,issue,negative,negative,negative,negative,negative,negative
362649375,"@gdunstone I modified the way we pass arguments to convert plugin. I now pass the full arguments object instead of separate fields; I think it is easier in the long term because the parameters list will grow the more we add plugins...

Feel free to make a feedback if you prefer your version",way pas convert pas full object instead separate think easier long term list grow add feel free make feedback prefer version,issue,positive,positive,positive,positive,positive,positive
362645870,@permosegaard looks awesome! i didn't see any of the faceswapping code itself in the repo. is it meant to be used in conjunction with this project? ,awesome see code meant used conjunction project,issue,positive,positive,positive,positive,positive,positive
362638408,"If you train with LowMem you will also need to use the LowMem model when converting. If not you will get a layer count mismatch. 

I could see a todo in the code so have put a pull request in to fix this. Hope that is OK. Please just disregard if not :) ",train also need use model converting get layer count mismatch could see code put pull request fix hope please disregard,issue,negative,neutral,neutral,neutral,neutral,neutral
362637224,"Im going to close this as wontfix because this low number of training images shouldn't happen.

Warn about low number of images?",going close low number training happen warn low number,issue,negative,neutral,neutral,neutral,neutral,neutral
362635320,"Question was also asked in #73 about which paper this is based on. You will also find some info on reddit, but there is not much about this around. All I can tell you is that it is an [autoencoder](https://en.wikipedia.org/wiki/Autoencoder)",question also paper based also find much around tell,issue,negative,positive,positive,positive,positive,positive
362587738,"The code is based on an autoencoder, but not a variational nor an adversarial one. It is made with convolution layers, but does not use pooling which is strange because pooling is very common after conv layers. I don't know if it was based on a specific paper, you should try asking on reddit to /u/deepfakes directly",code based variational one made convolution use strange common know based specific paper try directly,issue,negative,negative,neutral,neutral,negative,negative
362576632,"Thanks so much for all your help, I'll have a play around with it and see how it goes.",thanks much help play around see go,issue,positive,positive,positive,positive,positive,positive
362573534,"I don't think a configuration where you can only configure the amount of conv-layers would be helpful.

Just adding conv-layers probably won't improve the model. Considering the current `IMAGE_SHAPE` and as of how the conv-layers are constructed, the input for the layer `x = self.conv(1024)(x)` has the shape `(8, 8, 512)` and the output the shape `(4, 4, 1024)`. Learning features of the size `2x2` pixel in following conv-layers probably won't do anything if not worsen the NN.

Tweaking the NN with pooling-layers or changing the `strides` and `kernel_size`s of the conv-layers would be the better approach here (Besides other common tweaks for NNs, like dropout, ...). But that is always trial and error.

But as @Clorr already mentioned this is something only advanced users would do and a config parameter for that would be more complex, than just changing the code.",think configuration configure amount would helpful probably wo improve model considering current input layer shape output shape learning size following probably wo anything worsen would better approach besides common like dropout always trial error already something advanced would parameter would complex code,issue,positive,positive,neutral,neutral,positive,positive
362563507,"Actually, there is no ""correct"" shape for the NN. The shape of each layer, and the global shape of the network can be almost whatever you want. The shape is to be tweaked until you get a result corresponding to what you expect.

After that I'm not experienced enough to tell you if there is a flaw in what you suggest. You should try and see what you get from it ;-) ",actually correct shape shape layer global shape network almost whatever want shape get result corresponding expect experienced enough tell flaw suggest try see get,issue,negative,positive,positive,positive,positive,positive
362561715,"I'm not much in favor of adding CLI params for that, because if you later provide incorrect params, you may well end up with unusable model files. They are not parameters in the sense you can change them freely from time to time, they are intrinsic to the model that is trained.",much favor later provide incorrect may well end unusable model sense change freely time time intrinsic model trained,issue,positive,positive,positive,positive,positive,positive
362559844,"Yes it seems to come from there. Possibly it can be solved with a slice notation like `rtn = numpy.float32([read_image(item) for item in data[i,size])`

But having so few images that it is below batch-size is a problem because the training won't have much varied data and won't train well IMHO",yes come possibly slice notation like item item data size problem training wo much varied data wo train well,issue,positive,positive,neutral,neutral,positive,positive
362554618,"That sounds perfectly fine reasoning to me.
If I did want to do it, is what I did above the correct way to do it?",perfectly fine reasoning want correct way,issue,positive,positive,positive,positive,positive,positive
362551949,"I am not in favor of letting end user changing this. Because generated model files won't be reloadable if the parameters change. If someone more advanced wants to play with these, it is possible but he will change parameters directly.",favor end user model wo change someone advanced play possible change directly,issue,positive,positive,positive,positive,positive,positive
362551608,"Ahh python 3, damnit. I was runned it from python 2.x. Thanks mate, problem is solved! :)",python python thanks mate problem,issue,negative,positive,positive,positive,positive,positive
362551235,"Hello, the error is on the last line: ""No module named scandir"". Did you install the requirements? They are located in `requirements.txt` or `requirements-gpu.txt` and you can install them with `pip3 install -r requirements.txt`. Also don't forget to install CUDA and CuDNN",hello error last line module install install pip install also forget install,issue,negative,neutral,neutral,neutral,neutral,neutral
362491328,"I think I worked this out. Are you using a small number of images?
I got the same error trying to train on less than 64 images.
if you really want to train on such a small number of images you can set the `--batch-size` argument to something less than number of images.",think worked small number got error trying train le really want train small number set argument something le number,issue,negative,negative,neutral,neutral,negative,negative
362488470,"missing models dir is not an issue. Rather (just tried with python3.5):

```
Exception in thread Thread-2:
Traceback (most recent call last):
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/root/faceswap/lib/utils.py"", line 42, in run
    for item in self.generator:
  File ""/root/faceswap/lib/training_data.py"", line 44, in minibatch
    rtn = numpy.float32([read_image(data[j]) for j in range(i,i+size)])
  File ""/root/faceswap/lib/training_data.py"", line 44, in <listcomp>
    rtn = numpy.float32([read_image(data[j]) for j in range(i,i+size)])
IndexError: list index out of range
```
It looks like it is a problem with some of the images I was using. Because on face-swap.zip training works just fine",missing issue rather tried python exception thread recent call last file line file line run item file line data range file line data range list index range like problem training work fine,issue,negative,positive,neutral,neutral,positive,positive
362484151,"> Unable to open file (unable to open file: name = '/root/faceswap/models/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)

models directory doesn't exist, I'll look into writing a fix now. for the time being just mkdir the models directory and it should work.",unable open file unable open file name error message file directory directory exist look writing fix time directory work,issue,negative,negative,negative,negative,negative,negative
362470165,"Are you using python 3?
The exist_ok keyword argument was only added in python 3",python argument added python,issue,negative,neutral,neutral,neutral,neutral,neutral
362435555,"No it was my coding error.

On 2 Feb. 2018 10:22, ""ruah1984"" <notifications@github.com> wrote:

> The screen shoot only show convert can be done without error with loading
> bar. After this try , no more error for ""Failed to convert image:XXX.
> Reason: 'NoneType' object is not iterable"".
>
> i think the issue maybe due to i forget to copy the
> ""shape_predictor_68_face_landmarks.dat"" to this repo. and it not able to
> apply the face shape landmark.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/93#issuecomment-362435235>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AEDEeNbkOroualogUSSVJUwgfs4i2V28ks5tQkckgaJpZM4R2APk>
> .
>
",error wrote screen shoot show convert done without error loading bar try error convert image reason object iterable think issue maybe due forget copy able apply face shape landmark reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
362435235,"The screen shoot only show convert can be done without error with loading bar. After this try , no more error for ""Failed to convert image:XXX. Reason: 'NoneType' object is not iterable"". 

i think the issue maybe due to i forget to copy the ""shape_predictor_68_face_landmarks.dat"" to this repo. and it not able to apply the face shape landmark.  ",screen shoot show convert done without error loading bar try error convert image reason object iterable think issue maybe due forget copy able apply face shape landmark,issue,negative,positive,positive,positive,positive,positive
362431892,is this fixed? I cant see anything wrong with your screenshot,fixed cant see anything wrong,issue,negative,negative,negative,negative,negative,negative
362425798,"@gdunstone , fix.
show loading bar when convert.

https://imgur.com/a/3WtFb
",fix show loading bar convert,issue,negative,neutral,neutral,neutral,neutral,neutral
362418335,"This was my bad, I wasn't checking a value in the converter.

If this is still an issue please reopen.",bad value converter still issue please reopen,issue,negative,negative,negative,negative,negative,negative
362385958,I had this NoneType issue when my machine crashed and corrupted my source images...try opening that one or the entire folder to see.,issue machine corrupted source try opening one entire folder see,issue,negative,neutral,neutral,neutral,neutral,neutral
362372285,"I've a NVIDIA GeForce 940MX with 2GB dedicated VRAM.

I edited `ENCODER_DIM` in `Model_LowMem.py` to `128` (it represents nodes of NN?) and commented line 

`#x = self.conv(512)(x)` (layers of NN?)

It works for me.

Could be useful to add CLI parameters for ENCODER_DIM and convolutions.",line work could useful add,issue,negative,positive,positive,positive,positive,positive
362359359,"Models did not change AFAIK

If you use gan, it is not yet finished, so please add this to the pull request so that we know that the error belongs there",change use gan yet finished please add pull request know error,issue,negative,neutral,neutral,neutral,neutral,neutral
362337940,"thanks @gdunstone , and where  i can adjust if i would like to use it.",thanks adjust would like use,issue,positive,positive,positive,positive,positive,positive
362319323,"Yes, it's ok like that ;-)

Adding an intermediate var has no impact on the speed, if you do `if not func()`, there will always be an internal var created. Also calling a function has a cost, but it is very small (typically around 0.1 microsecond).

The only cases where you would prefer inlining the code (ie. not creating a function) is in places where the code is called millions of times or more.

For a loop like this, that is called once per image, the performance impact is totally unnoticeable and it is much better to keep code clean",yes like intermediate impact speed always internal also calling function cost small typically around microsecond would prefer code ie function code million time loop like per image performance impact totally unnoticeable much better keep code clean,issue,positive,positive,neutral,neutral,positive,positive
362317396,"lol yep. Also I'm super keen for GAN.
Haven't looked much at it yet but I'm excited. XD",yep also super keen gan much yet excited,issue,positive,positive,positive,positive,positive,positive
362316582,"No problem, I'm not that used to public repos either. And I prefer a living repo than a too strict one where nothing moves on ;-)",problem used public either prefer living strict one nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
362316050,@Clorr sorry if I rely on you too much. I normally work on private repos.,sorry rely much normally work private,issue,negative,negative,negative,negative,negative,negative
362314767,"I think this is ok?

I feel like checking a variable is less taxing than calling a func here.

",think feel like variable le taxing calling,issue,negative,neutral,neutral,neutral,neutral,neutral
362311371,You are totally right about checkSkip needing to be a separate func.,totally right needing separate,issue,negative,positive,positive,positive,positive,positive
362309166,"Hi, I just read your code as I'm continuing on the GAN plugin. I just noticed something that would be a better practice in order to keep the code clean.

In the code below:
```

    def convert(self, converter, item):
        try:
            (filename, image, faces) = item
            skip = False
            try:
                if self.frame_ranges is not None:
                    # grab the index with last number regex
                    idx = int(self.imageidxre.findall(filename)[0])
                    # only skip if the current index is not between any of the frame ranges.
                    skip = not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
            except:
                # if we error, dont skip
                skip = False

            if not skip: # process as normal
                for idx, face in faces:
                    image = converter.patch_image(image, face)

            output_file = self.output_dir / Path(filename).name
            if self.arguments.discard_frames and skip:
                return
            cv2.imwrite(str(output_file), image)
        except Exception as e:
            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
```

it would be better to avoid having the logic inside the main function, because if add more and more logic here, it will end up with a big messy function. It would be better to have something like:

```
    def convert(self, converter, item):
        try:
            (filename, image, faces) = item
            if not checkSkip(filename): # process as normal
                for idx, face in faces:
                    image = converter.patch_image(image, face)

            output_file = self.output_dir / Path(filename).name
            if self.arguments.discard_frames and skip:
                return
            cv2.imwrite(str(output_file), image)
        except Exception as e:
            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
```
and define `checkSkip` in an outside function ;-)",hi read code gan something would better practice order keep code clean code convert self converter item try image item skip false try none grab index last number skip current index frame skip map lambda except error dont skip skip false skip process normal face image image face path skip return image except exception print convert image reason would better avoid logic inside main function add logic end big messy function would better something like convert self converter item try image item process normal face image image face path skip return image except exception print convert image reason define outside function,issue,positive,positive,neutral,neutral,positive,positive
362287565,"for dependencies a useful command is:
`pip3 install -r requirements{-gpu}.txt`

we can also create 2x pypi packages.",useful command pip install also create,issue,positive,positive,positive,positive,positive,positive
362270551,I think this has gone beyond resolved now.,think gone beyond resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
362253069,"I'm trying to add a feature right now that will allow you to specify frame ranges like `./faceswap.py convert -fr 10-20 50-60` to apply conversion to those frames, while still writing the other frames out",trying add feature right allow specify frame like convert apply conversion still writing,issue,positive,positive,positive,positive,positive,positive
362251286,"Ok, I checked in FakeApp, and it uses `dlib.cnn_face_detection_model_v1(""mmod_human_face_detector.dat"")`. It seems to support more angles but is also much more resource intensive and seems to fails on large images (I had a `bad_alloc` on a 2K wide image). 

Maybe we should add it, but as fallback.",checked support also much resource intensive large wide image maybe add fallback,issue,negative,positive,positive,positive,positive,positive
362247338,"I changed the default mask type to facehullandrect.
I also made Convert_Adjust.py and Convert_Masked.py able to take extra parameters (and ignore ones that do not apply).",default mask type also made able take extra ignore apply,issue,negative,positive,positive,positive,positive,positive
362237802,"I tried the 3 yet known methods (face_recognition from @ageitgey, haarcascade from opencv, get_frontal_face_detector from dlib) and all 3 fail on detecting the face on your image. 

I rotated it and then it was working, so the problem seem to come from the angle. Maybe there is some parameter to improve that. We could also rotate images if no face is found. Also we can have a look at the fakeapp method if possible",tried yet known fail face image rotated working problem seem come angle maybe parameter improve could also rotate face found also look method possible,issue,negative,negative,negative,negative,negative,negative
362236569,"If you feel more comfortable with it, try to do it in a config file",feel comfortable try file,issue,positive,positive,positive,positive,positive,positive
362235360,"Nice ;-)

If you want to take other things, feel free. Just assign yourself where relevant. ",nice want take feel free assign relevant,issue,positive,positive,positive,positive,positive,positive
362231578,"I added some more fixes and cli args.
I completed the todo in train.py and added a save_now (s key) for the --preview option.",added added key preview option,issue,negative,neutral,neutral,neutral,neutral,neutral
362231513,"Thanks for the pull request! I invited you as collaborator, feel free to merge this by yourself if youfeel confident enough on your code ;-)",thanks pull request collaborator feel free merge confident enough code,issue,positive,positive,positive,positive,positive,positive
362058880,Would appreciate it. i would discribe me as an user somewhere around a noob when it goes on things like that. building under windows is just too annoying. gotta setup a virtual machine for doing shit.,would appreciate would user somewhere around go like building annoying got ta setup virtual machine,issue,negative,negative,negative,negative,negative,negative
362046865,"Welp, I actually have no idea how, my Python knowledge is very lacking. I can't figure out how to pass the args from the `ConvertImage` class in `convert.py` to the `Convert` class in `Convert_Masked.py`.",actually idea python knowledge ca figure pas class convert class,issue,negative,neutral,neutral,neutral,neutral,neutral
362025987,"@Irastris @Clorr ,i think seamlessclone and masktype can be abjust but not sure the erosion kernel can be adjust or not.
default will be ""none"" , if want to change, what will be the command?

i suggest we can put at USAGE.md , the command to change. refer to this 

https://www.reddit.com/r/deepfakes/comments/7mbzu2/patched_face_alignment_and_merge_scripts_with/

[–]depfakacc[S] 2 points 1 month ago 
These need to be used together as the new align_images_masked.py also saves the face points detected to the json file along with the filenames and transforms.

A few interresting options to pass merge_faces_masked.py:

--seamlessClone=yes will attempt to use opencv seamless clone on the faces, otherwise alpha blending is used.

--blurSize=2 will blur the borders of the mask to give a smooth transition between faces and head.

--erosionKernelSize=2 will nibble at the borders of the face mask, making the face area used smaller before the merge is performed.

--maskType=FaceHullAndRect takes three possible options:

Rect - The standard transformed square edges. FaceHull - Create an outline from the detected face points and mask with these. FaceHullAndRect - a AND of the two keeping portions of the face that are both within the detected face points and the face rect.

align_images_masked.py also has new options for --startFrame and --maxFrames which control the image number to start conversion at, and the maximum number of images to convert.",think sure erosion kernel adjust default none want change command suggest put command change refer month ago need used together new also face file along pas attempt use seamless clone otherwise alpha blending used blur mask give smooth transition head nibble face mask making face area used smaller merge three possible rect standard square create outline face mask two keeping face within face face rect also new control image number start conversion maximum number convert,issue,positive,positive,positive,positive,positive,positive
362023462,"Also there is a LowMem model plugin now. You can edit `scripts/convert.py` and replace ""Original in ""`variant = ""Original""` with ""LowMem"". But be careful, as it has one layer less, your current model will not be reloaded if you started training it!",also model edit replace original variant original careful one layer le current model training,issue,positive,positive,positive,positive,positive,positive
362022118,"I can't tell you about fakeapp. If it does not use paralellization for image processing, maybe the cpu uses only one core, and then only few data is fed to the gpu which does not work full power. It is just a guess.",ca tell use image maybe one core data fed work full power guess,issue,negative,positive,positive,positive,positive,positive
362021198,Also closing this as it is pending in the pull request,also pending pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
362021000,"Yeah I think Im going to have to rent out an AWS machine to train =/ 

Thanks",yeah think going rent machine train thanks,issue,positive,positive,positive,positive,positive,positive
362020917,Thanks for the info. Feel free to close the issue if it is solved ;-),thanks feel free close issue,issue,positive,positive,positive,positive,positive,positive
362020699,"faceswap is based on the Tensorflow framework. And Tensorflow itself only supports CPU and NVIDIA GPU (CUDA). There are forks available that provide AMD GPU support for Tensorflow but these forks are very slow compared to NVIDIA (CUDA).

See my [github page](https://github.com/AlphasCodes/DeepLearning) for more information. Also see the [Tensorflow github issue 22](https://github.com/tensorflow/tensorflow/issues/22) for detailed information.",based framework available provide support slow see page information also see issue detailed information,issue,negative,positive,positive,positive,positive,positive
362020552,Sadly we don't have proper parsing of command line parameters for this part yet. I just let the original code so you can uncomment it if you want.,sadly proper command line part yet let original code want,issue,negative,positive,positive,positive,positive,positive
362020129,"Thanks for this info. If you have some code/doc modification to add here, feel free to do a pull request.",thanks modification add feel free pull request,issue,positive,positive,positive,positive,positive,positive
362020033,"@Clorr I posted to early, found the https://github.com/deepfakes/faceswap/blob/027b833e6971f28f57ba92cf12c9037e0ea222e6/INSTALL.md file that mentions the issue is with tensorflow. 

After some searching I found this, which might work, but is 4 times slower then CUDA.

https://github.com/hughperkins/tf-coriander/blob/master/doc/execution_speed.md",posted early found file issue searching found might work time,issue,negative,positive,neutral,neutral,positive,positive
362019499,"Thanks for your feedback! I'd be happy if we had some command line params for that but, unfortunately, no one seems to be available for that now. If you have skills you can do a pull request, it will certainly be accepted",thanks feedback happy command line unfortunately one available pull request certainly accepted,issue,positive,positive,positive,positive,positive,positive
362019065,"Hi !

This project does not use CUDA directly. CUDA is used in tensorflow, which maybe also have AMD support. Did you try installing the project on your machine?",hi project use directly used maybe also support try project machine,issue,negative,positive,neutral,neutral,positive,positive
362018357,"Hi @iSevenDays !

Sorry I could not work on the project these last weeks, but I'm now back with a bit of time. I'll probably take your changes now that I finished my own modifications. If you want to review your changes, feel free, otherwise, I can do it on my side.",hi sorry could work project last back bit time probably take finished want review feel free otherwise side,issue,positive,negative,neutral,neutral,negative,negative
362017032,"Hello,

I've merged my modifications and it creates a conflict. Can you solve this ? I can do it on my side, but not today.

Thanks",hello conflict solve side today thanks,issue,negative,positive,positive,positive,positive,positive
362016352,I'm merging this since I tested it on my side. Feel free to report any problem if any.,since tested side feel free report problem,issue,negative,positive,positive,positive,positive,positive
362007855,Or atleast add optional command line parameters to tweak these,add optional command line tweak,issue,negative,neutral,neutral,neutral,neutral,neutral
361794744,"Also, glad my suggestion is being considered!",also glad suggestion considered,issue,negative,positive,positive,positive,positive,positive
361794083,"Along with `requirements.txt`, the new `tqdm` module should be added to `requirements-gpu.txt` as well.",along new module added well,issue,negative,positive,positive,positive,positive,positive
361616345,"Had the same with 4GB GPU

I edited `ENCODER_DIM` to `512` in `model.py` and it works for me. Iterations are 20x faster on GPU now.

see also https://github.com/deepfakes/faceswap/issues/40#issuecomment-354393545",work faster see also,issue,negative,neutral,neutral,neutral,neutral,neutral
361588251,This will probably impact https://github.com/deepfakes/faceswap/pull/62  with the multicore directory processor.,probably impact multicore directory processor,issue,negative,neutral,neutral,neutral,neutral,neutral
361583849,"with tqdm this is super easy, not sure about including it as a dependency, I'll fork tomorrow.

*faceswap/lib/cli.py:51*
```
def process_directory(self):
        for filename in tqdm(self.input_dir):
            if self.arguments.verbose:
                print('Processing: {}'.format(os.path.basename(filename)))

            self.process_image(filename)
            self.images_processed = self.images_processed + 1

        self.finalize()
```",super easy sure dependency fork tomorrow self print,issue,positive,positive,positive,positive,positive,positive
361482881,Did you figured it out? Because i have 2GB card too and im facing  ran out of memory error too.,figured card facing ran memory error,issue,negative,neutral,neutral,neutral,neutral,neutral
361355894,"Awesome, glad to have you back @Clorr. Excited to see this and GAN merged in",awesome glad back excited see gan,issue,positive,positive,positive,positive,positive,positive
361314447,Increase Nodes to 1024 and it should work. There's a discrepancy between your model complexity and the default model complexity of FakeApp.,increase work discrepancy model complexity default model complexity,issue,negative,neutral,neutral,neutral,neutral,neutral
361236039,I'd go with MIT or Apache because that way companies can contribute without worrying how they might be able to use it in the future. Just my 2 cent.,go apache way contribute without worrying might able use future cent,issue,negative,positive,positive,positive,positive,positive
361088547,"I did not enable the preview window.
It's just 2 GB memory. 
Just wanted to have a look at this!",enable preview window memory look,issue,negative,neutral,neutral,neutral,neutral,neutral
361087656,"Setting batch size <14 can screw up the preview window which is hard-coded to display a bunch of preview images. It's possible to edit that too and run 1 sized batches but it's kind of a pain.

How much memory does your GPU have? 64 is really low for ENCODER_DIM, probably going to have a hard time getting good results.",setting batch size screw preview window display bunch preview possible edit run sized kind pain much memory really low probably going hard time getting good,issue,negative,positive,positive,positive,positive,positive
361087146,"tried tuning ENCODER_DIM and BATCH_SIZE. did not find a working combination. 
For ENCODER_DIM=64 and BATCH_SIZE=1 i get one valid output `0.15305635 0.11783895` but then it just says `save model weights` and quits.

```
2018-01-28 20:05:43.939681: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this T
ensorFlow binary was not compiled to use: AVX
2018-01-28 20:05:44.539616: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: Quadro K2000M major: 3 minor: 0 memoryClockRate(GHz): 0.745
pciBusID: 0000:01:00.0
totalMemory: 2.00GiB freeMemory: 1.92GiB
2018-01-28 20:05:44.540210: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GP
U:0) -> (device: 0, name: Quadro K2000M, pci bus id: 0000:01:00.0, compute capability: 3.0)
2018-01-28 20:05:47.504003: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:47.566201: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.07GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:47.603648: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.04GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:47.730635: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.04GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:47.838415: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.03GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:47.860781: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.07GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:48.012480: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.06GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:48.050733: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:48.051200: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 2.13GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-28 20:05:48.108983: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory
trying to allocate 1.13GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
0.15305635 0.11783895
save model weights
usage: faceswap.py [-h] {extract,train,convert} ...

positional arguments:
  {extract,train,convert}
    extract             Extract the faces from a pictures.
    train               This command trains the model for the two faces A and
                        B.
    convert             Convert a source image to a new one with the face
                        swapped.

optional arguments:
  -h, --help            show this help message and exit
```",tried tuning find working combination get one valid output save model quits binary use found device name major minor device device name bus id compute capability allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available allocator ran memory trying allocate caller failure may mean could performance gain memory available save model usage extract train convert positional extract train convert extract extract train command model two convert convert source image new one face optional help show help message exit,issue,positive,negative,neutral,neutral,negative,negative
361077889,"I can confirm the issue on my system (Lubuntu 17.10, Python 3.6, Nvidia driver 390.12, Cuda 9.1, cuDNN 7.0.5, Tensorflow 1.5). My workaround is to use the fork of @Clorr (https://github.com/Clorr/faceswap).",confirm issue system python driver use fork,issue,negative,neutral,neutral,neutral,neutral,neutral
361073339,Your GPU does not have enough memory. Try decreasing ENCODER_DIM  to 512.,enough memory try decreasing,issue,negative,neutral,neutral,neutral,neutral,neutral
360929873,"Once this is merged, I'll be able to work full time on GAN, so it should move on faster now.

I will also have a look at the overall performance, because I'm surprised the cpu gets so much load...",able work full time gan move faster also look overall performance much load,issue,negative,positive,positive,positive,positive,positive
360928871,"not sure is the input and output problem or not. i have this problem previously,but after i put all input and output folder to C:\Users\xxx , it not happen any more.  

here is how i run python faceswap
python faceswap.py train -A ~/faceswap/data/faceB -B ~/faceswap/data/faceA -m ~/faceswap/models/ -p.
",sure input output problem problem previously put input output folder happen run python python train,issue,negative,positive,positive,positive,positive,positive
360925920,"@ruah1984  Nope. I am not using floydhub. I am running it locally. Following is my output

(venv) kumaran@kumaran:~/Projects/faceswap$ python faceswap.py train -A data/trump -B data/obama -m models/obama_trump/ -p
/home/kumaran/Projects/faceswap/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/home/kumaran/Projects/faceswap/venv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
Model A Directory: /home/kumaran/Projects/faceswap/data/trump
Model B Directory: /home/kumaran/Projects/faceswap/data/obama
Training data directory: /home/kumaran/Projects/faceswap/models/obama_trump
Not loading existing training data.
Unable to open file (unable to open file: name = '/home/kumaran/Projects/faceswap/models/obama_trump/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
Starting, this may take a while...
usage: faceswap.py [-h] {extract,train,convert} ...

positional arguments:
  {extract,train,convert}
    extract             Extract the faces from a pictures.
    train               This command trains the model for the two faces A and
                        B.
    convert             Convert a source image to a new one with the face
                        swapped.

optional arguments:
  -h, --help            show this help message and exit
(venv) kumaran@kumaran:~/Projects/faceswap$",nope running locally following output python train conversion second argument float future float import version module match version return model directory model directory training data directory loading training data unable open file unable open file name error message file directory starting may take usage extract train convert positional extract train convert extract extract train command model two convert convert source image new one face optional help show help message exit,issue,negative,negative,neutral,neutral,negative,negative
360911879,"Welcome back @Clorr 
Waiting for GAN progress :)
Nice setup you have there btw",welcome back waiting gan progress nice setup,issue,positive,positive,positive,positive,positive,positive
360905822,"I'm getting closer! Now I have a preview window to test ;-)
![screenshot-nomachine](https://user-images.githubusercontent.com/873943/35460950-0ab5699a-02e6-11e8-8635-d362750e91d8.jpg)
",getting closer preview window test,issue,negative,neutral,neutral,neutral,neutral,neutral
360870759,"Yes. i am using windows 10 x64. Ok thanks i understand, will keep waiting tensorflow-gpu stable for windows",yes thanks understand keep waiting stable,issue,positive,positive,positive,positive,positive,positive
360857733,"I would suggest that you try to install the cpu version of tensorflow because installing the gpu version on windows is a hell of a mess. I just assume that you try that on windows, if that is not the case tell me. but otherwise do try the cpu version it is easier to install. the only downside is that it will run slower. if you are serious about tensorflow gpu switch to linux. ",would suggest try install version version hell mess assume try case tell otherwise try version easier install downside run serious switch,issue,negative,negative,negative,negative,negative,negative
360848786,"can't install tensorflow-gpu
binascii.Error: Incorrect padding",ca install incorrect padding,issue,negative,neutral,neutral,neutral,neutral,neutral
360845423,"I think it is that paper: https://arxiv.org/abs/1511.05644

but I am not sure. It looks like he is using some kind of autoencoder. let me know when you find more.",think paper sure like kind let know find,issue,positive,positive,positive,positive,positive,positive
360513440,"Hi guys,

I'm not fully settled yet, but I start having a bit more time for coding ;-) Also I should be finished in a couple of days with my new PC on which I will have a linux and a windows, but mostly a 8gb 1070 Geforce ^^

Btw I pushed a modification for the ""darker"" images, which was coming from the gan repo merge. I think it is ok, but you should confirm.

Also I tried a new preview approach, but it is not tested as I'm still running on my imac+docker setup

Let me know if you see something I should change...",hi fully settled yet start bit time also finished couple day new mostly modification coming gan merge think confirm also tried new preview approach tested still running setup let know see something change,issue,negative,positive,positive,positive,positive,positive
360195673,"This can be closed off, I think its duplication of functionality already covered in #53 ",closed think duplication functionality already covered,issue,negative,negative,neutral,neutral,negative,negative
359946507,"Important note!

Now that I have a windows machine to run this, I also encountered the problem. The reason why this happens is due to the install of the 32 bit version of Python! Please ensure you have installed the 64 bit version!",important note machine run also problem reason due install bit version python please ensure bit version,issue,negative,positive,positive,positive,positive,positive
359250768,@Clorr was working on GAN but he's not available nowadays it seems. Dfaker's results are blurry and don't look good at all in my view.,working gan available nowadays blurry look good view,issue,negative,positive,positive,positive,positive,positive
358785253,"The video script works well.  CNN acceleration is hit and miss, but I get basically the same results with hog instead, so no loss there. ",video script work well acceleration hit miss get basically hog instead loss,issue,negative,neutral,neutral,neutral,neutral,neutral
358563735,"I checked the code again and I think the input is already -1 ~ +1.

There is a piece of code for video making of GAN class in this [notebook](https://github.com/shaoanlu/faceswap-GAN/blob/master/temp/faceswap_WGAN-GP_keras_github.ipynb). Modify the following line in video making cell to make it compatible with the plugins:
```python
result = gan.netGA.predict(np.array([ae_input])) # Change path_A/path_B here
```
Change the above line to something like (not sure about the exact variable name used in the plugin):
```python
result = trainer.gan.netGA.predict(np.array([ae_input])) 
```
The output of netGA is a list of `[alpha_mask, bgr_image]` where `alpha_mask` has shape `(64, 64, 1)` and `bgr_image` `(64, 64, 3)`

As nkfs had mentioned, it seems like there are some people encountering problems that dlib not using GPU for CNN acceleration. I don't know the cause of this issue. Perhaps it has something to do with installing dlib, e.g., not compiling dlib with CUDA support.",checked code think input already piece code video making gan class notebook modify following line video making cell make compatible python result change change line something like sure exact variable name used python result output list shape like people acceleration know cause issue perhaps something support,issue,positive,positive,positive,positive,positive,positive
358507343,"I couldn't wrap my head around doing it as a plug in. The clustering requires evaluating all the faces in the set rather than individual processing. In the end I've done it as a separate script, but could use some feedback before considering a pull request.

Having put some time in to writing it I'm not sure if it's going to add a huge amount of value compared to the additional layer of complexity, possibly a lot more issues non technical user. Looking at it now I think I would rather re-do it a switch for the existing extract.py but wanted to find out if it could be useful before spending time re-writing.

https://github.com/badluckwiththinking/faceswap/commit/7ada68d0a92d57e6b19b100f48e647d8291517ff",could wrap head around plug clustering set rather individual end done separate script could use feedback considering pull request put time writing sure going add huge amount value additional layer complexity possibly lot non technical user looking think would rather switch find could useful spending time,issue,positive,positive,positive,positive,positive,positive
358092210,"I think the extract is ok, I think the +1 -1 thing is more in the image load before training, but maybe @shaoanlu can point this in his own code.

----

Plugins are just basic classes. The potentially tedious part is that a part of the code can be in a base class like ""Model_Original inherits from ModelAE"" so you have to open both classes to see the whole code. Also you should open the corresponding script to see where the code begins to run. 

The only strange looking part of the plugin system is the PluginLoader, but you shouldn't have to look at it. Just know that the plugin loader selects the good class for you depending on the string you give as load function argument.

-----

For the convert part, I'm not sure of what is up to date or not. In the https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2_test_img.ipynb file, the model does not seem to correspond to what we have in the GAN model class. Also, this script shows an image and a mask separately. I think the https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2_test_video.ipynb file is much more complete but has to be reworked to be applied to one image only. However, one good improvment of the video part is that it has a bounding box smoothed over multiple frames, and then it makes more sense to do a direct video convert. That's the meaning of my PR #54 ",think extract think thing image load training maybe point code basic class potentially tedious part part code base class like open class see whole code also open corresponding script see code run strange looking part system look know loader good class depending string give load function argument convert part sure date file model seem correspond gan model class also script image mask separately think file much complete reworked applied one image however one good video part bounding box multiple sense direct video convert meaning,issue,positive,positive,neutral,neutral,positive,positive
358071266,"Yes you can integrate it as an extract plugin. The extract plugin has not been much prepared for a new behavior, but it is still possible. Don't be scared of modifying the extract.py and propose something that suit you better.",yes integrate extract extract much prepared new behavior still possible propose something suit better,issue,positive,positive,positive,positive,positive,positive
358043924,"@Clorr good luck with your move, this is a side project for all of us anyways. 

I'll try to figure out how to modify the file in your repo, I'm new to this whole dev thing.  Been researching the +1 / -1 thing, I don't think it's affecting us? I feel like the current extract is already doing it, or maybe it's how the files get loaded in... I'm not sure. 

If you have a moment, could you explain how the 'plugin' system works? I'm summarizing that you're trying to make all the different components (align, merge, convert, etc.) into different files and then calling them in as plugins? 

The preview issue is of minimal value imo, the file output works.  What needs to be done on the convert side to get the mask + img combined? Can we utilize shaoanlu's code for the inline cnn video convert? One issue I do see about it though is that it is very limited by a single CPU thread, it consumes all my vram, but the GPU isn't doing any heavy lifting at all.",good luck move side project u anyways try figure modify file new whole dev thing thing think affecting u feel like current extract already maybe get loaded sure moment could explain system work trying make different align merge convert different calling preview issue minimal value file output work need done convert side get mask combined utilize code video convert one issue see though limited single thread heavy lifting,issue,positive,positive,neutral,neutral,positive,positive
357940147,"As a contributor, I feel happier knowing that the software will be free in perpetuity; usable for everyone, rather than leaving it open to companies that wouldn't contribute anything back to the project.

Should other contributors want to opt for something more permissive, the LGPL would be an adequate compromise.",contributor feel happier knowing free perpetuity usable everyone rather leaving open would contribute anything back project want opt something permissive would adequate compromise,issue,positive,positive,positive,positive,positive,positive
357923389,"Hi guys, sorry but I'm in the middle of a process to move to another city, so that does not let me as much time as wanted. Also I only have an old imac at hand and it's a bit tedious to work on it... I'll try to see what I can do, but I can't guarantee anything. If you have patches, feel free to put them on my repo, and I'll add them to this PR

@nkfs maybe you can modify the file directly in my repo, it will do a pull request I think

For the +1 / -1 thing, if you can pinpoint the problem, that would be of great help.

For the preview thing, I'll try to make something as it is more in the area of my habitual programming skills (but if you have propositions, feel free)",hi sorry middle process move another city let much time also old hand bit tedious work try see ca guarantee anything feel free put add maybe modify file directly pull request think thing pinpoint problem would great help preview thing try make something area habitual feel free,issue,positive,positive,positive,positive,positive,positive
357855769,"Ok.  Here is an update.  I took the advice from @shaoanlu and added in the cv2.cvtcolor() function and now my preview output has proper colors.  However, even after 18k iterations the images are still pretty ""messed"" (too many drugs or something).  Not sure if this has to do with image scaling from -1 to +1 instead of 0 to 1.  I couldn't figure out where to change / add that in.  I don't know any python at all, and googling this didn't help.  Where do we go next?",update took advice added function preview output proper color however even still pretty many something sure image scaling instead could figure change add know python help go next,issue,positive,positive,positive,positive,positive,positive
357549985,Should be GNU. Then other projects which use this will always be open source,gnu use always open source,issue,negative,neutral,neutral,neutral,neutral,neutral
357530235,"@apollo122 those are file output jpegs, not preview screenshots. 
@Clorr I didn't get blue output in the notebook version either. But I think the solution is already posted. ",file output preview get blue output notebook version either think solution already posted,issue,negative,neutral,neutral,neutral,neutral,neutral
357513358,"@Clorr 
yeah. last print before save:
[468/num_epochs][13000] Loss_DA: 0.141957 Loss_DB: 0.211055 Loss_GA: 0.259931 Loss_GB: 0.237249

https://mega.nz/#!0h4FXKwT!SIf-YAhkgnBcJmVUxkWjf8vl5-0HVOTY95_estUdQ2M
includes photos as well.",yeah last print save well,issue,positive,neutral,neutral,neutral,neutral,neutral
357502630,"@nkfs you wrote you also got unresponsive preview windows before. What did you do differently to have preview windows working?

@Clorr I'll send you trump-cage model later today",wrote also got unresponsive preview differently preview working send model later today,issue,negative,neutral,neutral,neutral,neutral,neutral
357500181,"We got these guest from Na'vi because of missing `cv2.cvtColor(...)` in display function. The GAN model expect input as 64x64 BGR channel image, and it should be scaled to -1 to +1, not 0 to +1. The output of netGA and netGB are also 64x64 BGR image in range of -1 to +1. ",got guest missing display function gan model expect input channel image scaled output also image range,issue,negative,negative,negative,negative,negative,negative
357499233,Thanks for the feedback. I don't remember of the blueish look when I played with the jupyter notebook version. Maybe @shaoanlu can confirm this is correct or not?,thanks feedback remember look notebook version maybe confirm correct,issue,negative,positive,positive,positive,positive,positive
357487405,"File preview writes 3 images, they are attached.  I'm not sure if this is what you're looking for.  They look fairly similar to the GAN scripts you forked from - however I never got those working correctly either. Models are at 15k epochs : Loss_DA: 0.264415 Loss_DB: 0.235073 Loss_GA: 0.228625 Loss_GB: 0.353471

[images removed]

",file preview attached sure looking look fairly similar gan forked however never got working correctly either removed,issue,negative,positive,positive,positive,positive,positive
357472713,"Maybe it comes from the read_image in training_data.py I took from the Gan version. It makes ""/ 255 * 2 -1"" this makes images darker. I have to see why it's done like that...",maybe come took gan version see done like,issue,negative,neutral,neutral,neutral,neutral,neutral
357471065,"I'll have a look at the preview thing hopefully tomorrow. meanwhile, you can use the file preview and see if it gives correct results. 

For the convert, can anyone send me trained models? I won't be able to train on my actual machine...",look preview thing hopefully tomorrow meanwhile use file preview see correct convert anyone send trained wo able train actual machine,issue,negative,positive,positive,positive,positive,positive
357471063,"Writing sample still works, but somehow it seems to save it much darker than it should.
[Image removed]
",writing sample still work somehow save much image removed,issue,negative,positive,positive,positive,positive,positive
357455941,Hmm that's a bit annoying since I can't have preview window as I'm working with docker. I'll try with that link when I can  : https://stackoverflow.com/questions/44577228/multithreaded-cv2-imshow-in-python-does-not-work,bit annoying since ca preview window working docker try link,issue,negative,negative,negative,negative,negative,negative
357451809,"Tested on linux, similar results to Apollo, I only have 2 preview windows instead of 3, RAW and Mask.  Both are reported by the DE as unresponsive windows.  ",tested similar preview instead raw mask de unresponsive,issue,negative,negative,negative,negative,negative,negative
357450717,"I trained it for 14000 iterations.
When i started to convert it I got this for all faces it merges:

[Image Removed]
",trained convert got image removed,issue,negative,neutral,neutral,neutral,neutral,neutral
357444283,"So i started training. Now i see 3 preview windows but they are not working (Not responding).
Is it a Win10 problem or a general one?

![a](https://user-images.githubusercontent.com/34627582/34907532-1dba5ac8-f891-11e7-9095-cf60b4be898d.PNG)

",training see preview working win problem general one,issue,negative,positive,positive,positive,positive,positive
357443925,The training preview is broken. My guess would be that the image window can only be updated from the main thread.,training preview broken guess would image window main thread,issue,negative,negative,negative,negative,negative,negative
357441982,"I sent you a collab invite on my repo, if you have fixes to push to my master now you can fix it directly if you want...",sent invite push master fix directly want,issue,negative,positive,neutral,neutral,positive,positive
357441294,"Hi @Ganonmaster !

Happy to see you have some time for review! For me it is a bit hard because I only have an old iMac to program for these days and it's a hell to run this monster ;-)

I hope you can merge this soon, so we can quickly move on to the GAN version ;-)

I am a bit busy now, but if you have small changes to do, tell them here, and I'll see if I can do a quick fix before I leave...

I pushed the corrections you asked for, but had no time to test :-/",hi happy see time review bit hard old program day hell run monster hope merge soon quickly move gan version bit busy small tell see quick fix leave time test,issue,negative,positive,positive,positive,positive,positive
357440123,"Hmm, no it is still a bit of work before using the mask.

What has to be done, is to take the convert code from the @shaoanlu repo and put it into plugins/convert_GAN.py

And also I have to see how I can have the converter return the mask without breaking other plugins. For now the Model_GAN/GANModel class returns only the image (the [1] in the converter lambda). It is not a big problem but I have to take care of it.

However note that the model you train contains already the mask, so you won't have to retrain",still bit work mask done take convert code put also see converter return mask without breaking class image converter lambda big problem take care however note model train already mask wo retrain,issue,negative,neutral,neutral,neutral,neutral,neutral
357439114,"Thanks for your efforts @Clorr. I'll be testing it today.
As for the mask, for me its the only reason why  this method matters.
We can use a a command line parameter to tell convert class which image should it output and would be great if we do the same thing for preview screen.
But for now if its not that hard you can tell me where to change within code so i can try masked output as well later.
",thanks testing today mask reason method use command line parameter tell convert class image output would great thing preview screen hard tell change within code try masked output well later,issue,positive,positive,positive,positive,positive,positive
357438429,@iSevenDays I added in my master branch the same preload for the convert as the one I had on train. Feel free to review it,added master branch convert one train feel free review,issue,positive,positive,positive,positive,positive,positive
357438050,"Ok, I pushed a new version I was able to ""test"". I put quotes on it as I don't have a proper model to test, but at least it outputs something...

Beside the converter method I did not update, there was a problem I missed. The GAN predictor outputs 2 images: a mask and an image. For now, I just use the image in the convert. I'll try to see later the GAN code to include the masking and all the nice features, but for now, I'm done, I won't have more time to work on it today...

I hope it works for you!",new version able test put proper model test least something beside converter method update problem gan predictor mask image use image convert try see later gan code include nice done wo time work today hope work,issue,negative,positive,positive,positive,positive,positive
357434062,"Indeed I really hate myself ;-)

I took the convert method from the old version of the gan plugin, but I changed it on the master btw... I pushed a new non tested version, I'll check it on my side (just I have not enough ram to have firefox and docker at the same time running, so it is a pain each time to switch...)",indeed really hate took convert method old version gan master new non tested version check side enough ram docker time running pain time switch,issue,negative,negative,negative,negative,negative,negative
357433810,":( another
Loading Convert from Convert_GAN plugin...
Traceback (most recent call last):
  File ""faceswap.py"", line 18, in <module>
    arguments.func(arguments)
  File ""K:\faceswap-dev-gan-plugin\lib\cli.py"", line 52, in process_arguments
    self.process()
  File ""K:\faceswap-dev-gan-plugin\scripts\convert.py"", line 50, in process
    converter = PluginLoader.get_converter(conv_name)(model.converter(False))
TypeError: converter() takes 1 positional argument but 2 were given",another loading convert recent call last file line module file line file line process converter false converter positional argument given,issue,negative,negative,negative,negative,negative,negative
357433757,"sometimes, I hate myself ;-)

Look at Model_GEN/Model.py and rename the `def convert(self):` into `def converter(self):`",sometimes hate look rename convert self converter self,issue,negative,negative,negative,negative,negative,negative
357433524,"now it gives another error

Loading Convert from Convert_GAN plugin...
Traceback (most recent call last):
  File ""faceswap.py"", line 18, in <module>
    arguments.func(arguments)
  File ""K:\faceswap-dev-gan-plugin\lib\cli.py"", line 52, in process_arguments
    self.process()
  File ""K:\faceswap-dev-gan-plugin\scripts\convert.py"", line 50, in process
    converter = PluginLoader.get_converter(conv_name)(model.converter(False))
AttributeError: 'GANModel' object has no attribute 'converter'",another error loading convert recent call last file line module file line file line process converter false object attribute,issue,negative,negative,negative,negative,negative,negative
357433138,"@Apollo122 the Model not found error is a mistake from me. It should be fixed now. Please check you see that code in `Model_GAN/Model.py` 
```
    def load(self, swapped):
        if swapped:
            print(""swapping not supported on GAN"")
            # TODO load is done in __init__ => look how to swap if possible
        return True
```

The `return True` was missing previously",model found error mistake fixed please check see code load self print swapping gan load done look swap possible return true return true missing previously,issue,negative,positive,neutral,neutral,positive,positive
357432934,"@Apollo122 
the original script is made to output 3 different images, but I just adapted one function to show preview. Thanks for pointing that out, I pushed a new version which will show you the 3 outputs",original script made output different one function show preview thanks pointing new version show,issue,positive,positive,positive,positive,positive,positive
357432925,"In GAN, loss value is basically meaningless since its a min-max game between two networks: discriminator and generator. The two networks compete each other so that the output become more and more realistic as training goes on. For example, when loss D (discriminator) goes down, loss G (generator) is likely to go up. How to evaluate results of GAN is still an open question. We usually subjectively evaluate it according to output visual quality.

Also, how long to train the model depends on your training data. I got good results after 15k ~ 20k iters. But it did not apply to everyone as far as I know.",gan loss value basically meaningless since game two discriminator generator two compete output become realistic training go example loss discriminator go loss generator likely go evaluate gan still open question usually subjectively evaluate according output visual quality also long train model training data got good apply everyone far know,issue,negative,negative,neutral,neutral,negative,negative
357432454,"Another problem:
So i train it for 1700 epochs but when i tried to convert it, it says Model Not Found. I checked the folder. There are 4 files ending with GAN. Maybe you should print model directory as well as input and output. So we can see where its searching for models.

K:\faceswap-dev-gan-plugin>python faceswap.py convert -i ./photos/trump/ -o ./output/ -m ./models/
Input Directory: K:\faceswap-dev-gan-plugin\photos\trump
Output Directory: K:\faceswap-dev-gan-plugin\output
Starting, this may take a while...
Loading Model from Model_GAN plugin...
Using TensorFlow backend.
2018-01-13 15:32:06.136239: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-01-13 15:32:06.369845: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.759
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.60GiB
2018-01-13 15:32:06.369962: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
Discriminator models loaded.
Generator models loaded.
Model Not Found! A valid model must be provided to continue!",another problem train tried convert model found checked folder ending gan maybe print model directory well input output see searching python convert input directory output directory starting may take loading model binary use found device name major minor device device name bus id compute capability discriminator loaded generator loaded model found valid model must provided continue,issue,negative,positive,neutral,neutral,positive,positive
357431787,"@Apollo122 
the original script is made to output 3 different images, but I just adapted one function to show preview. Thanks for pointing that out. I'll see if I can display the 3 different images",original script made output different one function show preview thanks pointing see display different,issue,positive,positive,positive,positive,positive,positive
357431492,"@shaoanlu 
Question: What do
Loss_DA, Loss_DB, Loss_GA, Loss_GB, mean?
And what should their values be for a nice swap?",question mean nice swap,issue,negative,positive,positive,positive,positive,positive
357431166,"It doesnt crash now but i dont see anything on preview screen.
Another thing is when it comes to ""Masked results: Raw Results: Alpha Results:"" part it waits couple of minutes then continues.

![a](https://user-images.githubusercontent.com/34627582/34906046-e07c67fc-f875-11e7-8c3d-69f83687e3b6.PNG)

",doesnt crash dont see anything preview screen another thing come masked raw alpha part couple,issue,negative,negative,negative,negative,negative,negative
357430701,"@iSevenDays I'm not sure I understand the question. According to the stackoverflow thread, the problem is that self.process_images is a bound function and can't be pickled. I don't think that adding output_dir as a parameter fixes anything",sure understand question according thread problem bound function ca think parameter anything,issue,negative,positive,positive,positive,positive,positive
357430612,"Ah yes, I remember now. Thanks, I'll add it as a var",ah yes remember thanks add,issue,positive,positive,positive,positive,positive,positive
357430331,"@Dagur 

I think the reason why does it work is that args now contain self.output_dir, could you please check it?",think reason work contain could please check,issue,negative,neutral,neutral,neutral,neutral,neutral
357429945,"It increases the coverage of face in input images.For example, with 80 in linspace, the outputs of `random_warp()` are the center 160x160 area of the input 256x256 images. By increasing it to 110, warped images cover larger area (220x220 pixels) of input faces, thus being likely to cover more face features such as eyebrows and chins.",coverage face input example center area input increasing warped cover area input thus likely cover face,issue,negative,negative,neutral,neutral,negative,negative
357428030,"@Apollo122 @nkfs @shaoanlu 

I pushed a new version. Now preview will show `batch_size` * 2 elements instead of 14 (this is due to the fact the batch reader has fixed size because of the preload). It is still on 4 columns

![_sample](https://user-images.githubusercontent.com/873943/34905639-7dd51fa8-f85d-11e7-91be-6b7b6aa90d73.jpg)
",new version preview show instead due fact batch reader fixed size still,issue,negative,positive,neutral,neutral,positive,positive
357427353,"I can confirm that this fixes the problem. I added this top the bottom of cli.py (basically copy+paste from extract.py)

```
from plugins.PluginLoader import PluginLoader
import cv2
from lib.faces_detect import detect_faces
from pathlib import Path

def process_image(filename, output_dir):
    extractor = PluginLoader.get_extractor(""Align"")()
    faces_detected = 0
    try:
        image = cv2.imread(filename)
        for (idx, face) in enumerate(detect_faces(image)):
            # if idx > 0 and self.arguments.verbose:
            #     print('- Found more than one face!')
            #     self.verify_output = True

            resized_image = extractor.extract(image, face, 256)
            output_file = output_dir / Path(filename).stem
            cv2.imwrite(str(output_file) + str(idx) +
                        Path(filename).suffix, resized_image)
            faces_detected = faces_detected + 1
    except Exception as e:
        print('Failed to extract from image: {}. Reason: {}'.format(filename, e))
    finally:
        return faces_detected
```

and called it like this
`p = multiprocessing.Process(target=process_image, args=(filename, self.output_dir))`

I'll let you refactor this. I'm not used to object oriented python :)",confirm problem added top bottom basically import import import import path extractor align try image face enumerate image print found one face true image face path path except exception print extract image reason finally return like let used object python,issue,positive,positive,positive,positive,positive,positive
357426541,"I found this about windows and multiprocess
https://stackoverflow.com/questions/9670926/multiprocessing-on-windows-breaks#9671030

Sounds like all that needs to be done is to move process_image so that it's a top level function. I'll give it a go",found like need done move top level function give go,issue,positive,positive,positive,positive,positive,positive
357426154,"Got it!

It is because of the batch_size . In my code, I have a ""preloader"" that prepares images for the trainer. This preloader has a fixed batch_size. In the show_sample method the .send(14) tells the generator to give him 14 images, but the generator returns him ""batch_size"" elements and things fail here...

I'm looking to correct that...",got code trainer fixed method generator give generator fail looking correct,issue,negative,negative,negative,negative,negative,negative
357424640,"@iSevenDays I pushed an update. The `def process(self, reader)` was a miss from an older version of my code. I was passing `process_directory` as argument to the function, but now I call it directly from the `process` functions.

I will have a look to integrate your changes on my branch.

Do you have an idea of the windows related problem?",update process self reader miss older version code passing argument function call directly process look integrate branch idea related problem,issue,negative,positive,neutral,neutral,positive,positive
357424334,I'm not sure about merging a PR which is not available for Windows. Maybe we can branch it as macOS version but that would create maintenance issues for future.,sure available maybe branch version would create maintenance future,issue,positive,positive,positive,positive,positive,positive
357422092,"@Dagur, unfortunately, I don't have a Windows set up to test, I use macOS. It seems that multiprocessing module works incorrectly in Windows.
As an option, you can always use -j 1, and this will fall back to default implementation that will work.",unfortunately set test use module work incorrectly option always use fall back default implementation work,issue,negative,negative,negative,negative,negative,negative
357418933,"This PR doesn't work for me. I get this error

E:\opt\faceswap>python faceswap.py extract -i E:\vids\equi\orig -o
E:\proj\first\data\equi -j 2
Using TensorFlow backend.
Parallel jobs: 2
Input Directory: E:\vids\equi\orig
Output Directory: E:\proj\first\data\equi
Starting, this may take a while...
Traceback (most recent call last):
  File ""faceswap.py"", line 18, in <module>
    arguments.func(arguments)
  File ""E:\opt\faceswap\lib\cli.py"", line 124, in process_arguments
    super().process_arguments(arguments)
  File ""E:\opt\faceswap\lib\cli.py"", line 52, in process_arguments
    self.process_directory()
  File ""E:\opt\faceswap\lib\cli.py"", line 144, in process_directory
    p.start()
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"",
line 105, in start
    self._popen = self._Popen(self)
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\context.py"",
line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\context.py"",
line 322, in _Popen
    return Popen(process_obj)
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\popen_spawn_win32.py"",
line 65, in __init__
    reduction.dump(process_obj, to_child)
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\reduction.py"",
line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
AttributeError: Can't pickle local object
'ArgumentParser.__init__.<locals>.identity'

E:\opt\faceswap>Using TensorFlow backend.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"",
line 105, in spawn_main
    exitcode = _main(fd)
  File
""C:\Users\dagur\AppData\Local\Programs\Python\Python36\lib\multiprocessing\spawn.py"",
line 115, in _main
    self = reduction.pickle.load(from_parent)
EOFError: Ran out of input

E:\opt\faceswap>

On Fri, 12 Jan 2018 at 23:51 Anton Sokolchenko <notifications@github.com>
wrote:

> @Clorr <https://github.com/clorr> I have just tried to merge conflicts
> and it seems that your PR doesn't work for me.
>
> Class DirectoryProcessor has a method
> def process(self, reader):
> ..
>
> But above, in process_arguments, you call self.process() without arguments.
>
> Given the above, class ExtractTrainingData(DirectoryProcessor) has a
> method without arguments at all
> def process(self):
>
> And this is not a correct override as I think. I didn't get what does
> 'reader' stands for.
>
> I couldn't make a fast merge, so it seems that you know more details than
> me on how to merge it.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/pull/62#issuecomment-357386380>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AADUTvSeGCNVEelN5g8gBXX5ABATHfnjks5tJ_ANgaJpZM4Ra3cN>
> .
>
",work get error python extract parallel input directory output directory starting may take recent call last file line module file line super file line file line file line start self file line return file line return file line file line dump file protocol ca pickle local object recent call last file string line module file line file line self ran input wrote tried merge work class method process self reader call without given class method without process self correct override think get could make fast merge know merge thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
357415751,"Wonder if the shape error has something to do with  `display_fn()`, the `viewer`? `Image.fromarray()` does not return a numpy array.",wonder shape error something viewer return array,issue,negative,neutral,neutral,neutral,neutral,neutral
357392158,"changed the code. same stuff. im running on win 10. my images are 256x256 too

[03:25:12] [0/num_epochs][100] Loss_DA: 0.250239 Loss_DB: 0.249831 Loss_GA: 0.294532 Loss_GB: 0.311934
Masked results:
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 109, in processThread
    trainer.train_one_step(epoch, self.show if save_iteration else None)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 82, in train_one_step
    self.show_sample(viewer)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 87, in show_sample
    self.showG(tA, tB, display_fn)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 115, in showG
    display_fig(figure_A, figure_B)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 92, in display_fig
    figure = figure.reshape((4,7) + figure.shape[1:])
ValueError: cannot reshape array of size 589824 into shape (4,7,3,64,64,3)",code stuff running win masked exception thread recent call last file line file line run file line epoch else none file line viewer file line ta file line file line figure reshape array size shape,issue,positive,positive,positive,positive,positive,positive
357391938,"Same issue with the 128-80 change.  I changed both the - and the +.  Also running without preview. Same error.
ValueError: cannot reshape array of size 589824 into shape (4,7,3,64,64,3)

If it makes any difference to you, I'm running on Linux.  My images are created from faceswap.py extract.  So they are the standard 256x256 output.",issue change also running without preview error reshape array size shape difference running extract standard output,issue,negative,neutral,neutral,neutral,neutral,neutral
357386380,"@Clorr  I have just tried to merge conflicts and it seems that your PR doesn't work for me.

Class DirectoryProcessor has a method 
def process(self, reader):
..

But above, in process_arguments, you call self.process() without arguments.

Given the above, class ExtractTrainingData(DirectoryProcessor) has a method without arguments at all
def process(self):

And this is not a correct override as I think. I didn't get what does 'reader' stands for.

I couldn't make a fast merge, so it seems that you know more details than me on how to merge it.",tried merge work class method process self reader call without given class method without process self correct override think get could make fast merge know merge,issue,negative,positive,positive,positive,positive,positive
357382792,"Ah I see that shaoanlu uses a modified random_warp function with a linspace 128 - 110 instead of 128 - 80.

Gan you guys tell me if changing the value in the lib/training _data.py solves your problem?",ah see function instead gan tell value problem,issue,negative,neutral,neutral,neutral,neutral,neutral
357379960,"@Apollo122 had the error ""ValueError: cannot reshape array of size 2359296 into shape (4,7,3,64,64,3)"" and @nkfs now have an error ""ValueError: cannot reshape array of size 589824 into shape (4,7,3,64,64,3)"".

 Does anyone see any relationship ? What is the size of the images you are using for training ?",error reshape array size shape error reshape array size shape anyone see relationship size training,issue,negative,neutral,neutral,neutral,neutral,neutral
357378938,"Thanks for the update @Clorr. 
I'll be testing it after preview bug is fixed.",thanks update testing preview bug fixed,issue,negative,positive,positive,positive,positive,positive
357376666,"Ok, thanks. The warning is the one I mentioned. The error is certainly a preview error we had previously. I'll try to see that tomorrow. If you want to try without the preview, maybe it will run for more cycles...",thanks warning one error certainly preview error previously try see tomorrow want try without preview maybe run,issue,negative,positive,neutral,neutral,positive,positive
357369883,"I tested your latest version.  I ran it for a training cycle and generated 2 errors:
Before it begins:
/lib/python3.5/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?

After the first iteration:
ValueError: cannot reshape array of size 589824 into shape (4,7,3,64,64,3)

It stops training after this. 
Your previous commit to the branch worked fine for me, (no errors), however the results were atrocious looking.. ",tested latest version ran training cycle discrepancy trainable collected trainable set without calling first iteration reshape array size shape training previous commit branch worked fine however atrocious looking,issue,negative,positive,neutral,neutral,positive,positive
357347144,"Here is an updated version, with the latest code from shaoanlu repo.

I did not manage to have it run for an entire training cycle on my old iMac as it stops with an OutOfMemory error. If you want to have a look feel free

It outputs a warning ""Discrepancy between trainable weights and collected trainable"", this shouldn't be a problem, but I had no feedback on this yet

CC @Apollo122 @ruah1984",version latest code manage run entire training cycle old error want look feel free warning discrepancy trainable collected trainable problem feedback yet,issue,negative,positive,positive,positive,positive,positive
357321354,"Hi @iSevenDays !

Indeed understanding each other when beginning to work with each other is always a problem ;-)

Your new commit is nice, there is just a problem because it will conflict with my own PR #61 :-/

So I suggest you just limit yourself to extract on this PR so we can merge everything without problem.

If you want, you can still push the convert, but do it in a manner we don't have a conflict:
 - or you can do it on my personal repo, I will integrate it in master, and it will be pushed with all other changes
 - or you can do it here, but do it from the code in my pending PR so that it does not conflict after my PR is merged

Sorry bothering you with that but it will be easier in the merge process afterward",hi indeed understanding beginning work always problem new commit nice problem conflict suggest limit extract merge everything without problem want still push convert manner conflict personal integrate master code pending conflict sorry easier merge process afterward,issue,negative,positive,neutral,neutral,positive,positive
357307762,"@Clorr okay, there was a misunderstanding, - done. 

Now you can use ""convert -j number_of_cores"" and you will see a very big performance gain. Please see the latest commit.",misunderstanding done use convert see big performance gain please see latest commit,issue,positive,positive,positive,positive,positive,positive
357239463,"sure.  i use these commands.

frames to video
ffmpeg -f image2 -framerate <fps_of_source_video> -i ""img (%d).jpg"" -vcodec libx264 -profile:v high444 -refs 16 -crf 0 -preset ultrafast input_0.mp4

adding sound
ffmpeg -i input_0.mp4 -i source.mp4 -c copy -map 0:0 -map 1:1 -shortest out.mp4

before using these commands, you should copy source frames to merged folder and say NO when it asks if it should overwrite existing files. You should do thing step because there might be some frames without faces in them or algorithm may have failed to detect faces for specific frames. If you fail to do this step correctly final video and audio won't sync. ",sure use video image high sound copy copy source folder say overwrite thing step might without algorithm may detect specific fail step correctly final video audio wo sync,issue,negative,positive,neutral,neutral,positive,positive
357227841,"sorry for the typo.
no hurry i think i can wait until GAN plugin ready in deepfakes/faceswap. 
thanks.",sorry typo hurry think wait gan ready thanks,issue,positive,negative,neutral,neutral,negative,negative
357227248,"For the gan plugin, the classes are somewhat ready in https://github.com/shaoanlu/faceswap-GAN/blob/master/temp/faceswap_GAN_keras.ipynb I have to merge them, hopefully later today ",gan class somewhat ready merge hopefully later today,issue,positive,positive,neutral,neutral,positive,positive
357220807,In my view this can be archived with FFMPEG easily. So it's not a priority. I'm waiting for GAN with masking it will be a game changer if its like in those gifs,view easily priority waiting gan game changer like,issue,positive,positive,neutral,neutral,positive,positive
357213361,":-D Frame, not flame!

I currently have in mind the @shaoanlu method with moviepy, but I have not much time to work on it. There is a draft pull request if you want to have a look ",frame flame currently mind method much time work draft pull request want look,issue,negative,positive,neutral,neutral,positive,positive
357212080,He asks a plugin which converts frames into the video and adds original audio from source video into fake video.,video original audio source video fake video,issue,negative,negative,neutral,neutral,negative,negative
357212023,"(However be careful the link points to an old version of dlib, try with latest one...)",however careful link old version try latest one,issue,negative,positive,positive,positive,positive,positive
357211470,"Also if you google ""dlib windows python install"", you may find useful links like this one: https://github.com/charlielito/install-dlib-python-windows/blob/master/README.md",also python install may find useful link like one,issue,positive,positive,positive,positive,positive,positive
357210322,"Hi,

Sorry that you have so much trouble setting things up.

There is an issue on face_recognition lib concerning windows, maybe it can help:

https://github.com/ageitgey/face_recognition/issues/158",hi sorry much trouble setting issue concerning maybe help,issue,negative,negative,negative,negative,negative,negative
357208318,"Hi,

Thanks for the update. If convert may have problem with the multiprocessing, I think it is better not to propose the option.

On my side, I was not proposing to make the convert multithreaded, I was proposing to do the photo preprocessing(face recognition + landmarks detection) in a separate thread, like I did for training. It shouldn't have impact on tensorflow itself ",hi thanks update convert may problem think better propose option side make convert multithreaded photo face recognition detection separate thread like training impact,issue,positive,positive,positive,positive,positive,positive
357207157,"Hello,

I don't understand the request. Can you provide more info please ?",hello understand request provide please,issue,negative,neutral,neutral,neutral,neutral,neutral
357066861,"SOLVED

Clean install of Python 3.5
Then Installed individually:
pip install pathlib==1.0.1
pip install scandir==1.6
pip install h5py==2.7.1
pip install Keras==2.1.2
pip install opencv-python==3.3.0.10
pip install tensorflow-gpu==1.4.0

(Windows 10)",clean install python individually pip install pip install pip install pip install pip install pip install,issue,negative,positive,positive,positive,positive,positive
357045317,"@Clorr convert will not work properly in multi-threaded mode. https://github.com/tensorflow/tensorflow/issues/8220
Firstly, I got an error that a second process doesn't have enough memory.
Then, when I set to ""allow growth"" of video memory in TensorFlow - I got errors CUDA NOT INITIALIZED.

I added command line argument --jobs -j , you can specify jobs number.",convert work properly mode firstly got error second process enough memory set allow growth video memory got added command line argument specify number,issue,negative,positive,neutral,neutral,positive,positive
356966704,"Yes, maybe parallelizing the work of convert is not a good idea. Or maybe I could handle it as for the training, where the photo are read separately from the main training loop (see #49)",yes maybe work convert good idea maybe could handle training photo read separately main training loop see,issue,positive,positive,positive,positive,positive,positive
356963887,"The joshua-wu repo is the first repo and it has the original code and it misses many improvments. This repo was created because the joshua-wu one is not really active. If you make it run, you should be able to make this one runningas the requirements are almost the same.

For instructions, the Readme on the homepage shoudl give you an overview of how things go. also the reddit page may help you. Anyhow the goal is to convert images/video, anf it goes like this:

> Get a video => transform into images => convert images with a model => transform back to a video

For the video <=> images transformation, you'll need ffmpeg
For the model, you will have to do as for Trump and Cage:

> Gather photos of your source (the person in the video) and of your target (the person you want to see in video) => extract faces from photos => train the model

Note that for your source photos, you can take the images you have from the video you want to convert",first original code many one really active make run able make one almost give overview go also page may help anyhow goal convert go like get video transform convert model transform back video video transformation need model trump cage gather source person video target person want see video extract train model note source take video want convert,issue,positive,positive,positive,positive,positive,positive
356962046,"@Clorr Thanks.  I will try this also on convert, but I think it will not be an option - convert usually requires a lot of video memory, I saw it used around ~3-4 GB from my 6 GB.",thanks try also convert think option convert usually lot video memory saw used around,issue,negative,negative,neutral,neutral,negative,negative
356959922,"Nice PR, I think it will be accepted.

Would it be possible to have it also on convert (If that brings any improvment)?",nice think accepted would possible also convert,issue,positive,positive,positive,positive,positive,positive
356876594,"Finally got some progress. Started from the beginning using this Github: https://github.com/joshua-wu/deepfakes_faceswap

GPU working. Training working. I am currently waiting for the trump/cage training to finish. Although I do not know what the process is after that since there is no further instructions after that was provided in joshua-wu's github. I am not even sure how I would tackle this with other data besides the provided trump/cage photos. Can your code be implemented into this also?",finally got progress beginning working training working currently waiting training finish although know process since provided even sure would tackle data besides provided code also,issue,positive,positive,positive,positive,positive,positive
356392727,"That's the way it goes for everyone, even developers ;-)

Good luck!

Note that you shouldn't have to reinstall everything, just pip install the requirements, it should skip what is already installed, and just do what it misses",way go everyone even good luck note reinstall everything pip install skip already,issue,positive,positive,positive,positive,positive,positive
356391737,"Yes I was just saying that I am more accustomed to Mac but I am mostly trying to do this in Windows since most people use it. If I can get some Windows help that would be great. I don't remember what happened when I tried to install the tensorflow-gpu after I got the CPU version running. I'm pretty sure I got some error. I'll have to go back and go through the process and recreate again.
  I really rather do this with GPU. I don't have patience waiting a week to train something. As being a professional video editor and cameraman I already wait for rendering. lol",yes saying accustomed mac mostly trying since people use get help would great remember tried install got version running pretty sure got error go back go process recreate really rather patience waiting week train something professional video editor cameraman already wait rendering,issue,positive,positive,positive,positive,positive,positive
356386018,"Now that thing works, did you try installing the `tensorflow-gpu` ? AFAIK there is no particular thing to do to run the with the GPU, so I assume it all depends on having the good lib...",thing work try particular thing run assume good,issue,negative,positive,positive,positive,positive,positive
356385019,"Ok, happy to know you managed to run something ;-)

On my side I don't do training since my mac is quite old, so I'm afraid I won't be of much help on how to setup the gpu thing
  ",happy know run something side training since mac quite old afraid wo much help setup thing,issue,positive,positive,positive,positive,positive,positive
356357275,"Hi @1adrianb , and welcome around!

Thanks for the info. Meanwhile we switched to `face_detection` lib since we are just using 2D landmarks and that `face_detection` was already used for face extraction.

If you think we can take advantage of any part of your work, feel free to suggest or even make a PR, we will take care of it with great pleasure!",hi welcome around thanks meanwhile switched since already used face extraction think take advantage part work feel free suggest even make take care great pleasure,issue,positive,positive,positive,positive,positive,positive
356343854,"Hey guys @Clorr @Ganonmaster  just accidentally found this :) I have recently addressed some accuracy issues and now the code should be on par (or very close) with the results reported in the paper.

Regarding support on windows, while official support will be added soon, there is already a conda package available that works fine on windows: https://anaconda.org/peterjc123/pytorch

With respect to the speed, the slowest bit is dlib face detector, however, one can replace it with almost any other face detection method. 



",hey accidentally found recently accuracy code par close paper regarding support official support added soon already package available work fine respect speed bit face detector however one replace almost face detection method,issue,positive,positive,positive,positive,positive,positive
356230048,"This PR should be ready to merge, contrary to other [DRAFT] PRs",ready merge contrary draft,issue,negative,positive,positive,positive,positive,positive
356133792,"What chat service do you use? Maybe we can chat in real time. Probably be easier.
  tried doing this install:
https://www.reddit.com/r/deepfakes/comments/7n00f2/really_high_level_tutorial/?st=jc7c0ezj&sh=72a48965

 but ran into errors.

I tried this tutorial and successfully ran the training but CPU only was working and not the GPU.
https://www.reddit.com/r/deepfakes/comments/7nq173/v2_tutorial_intelbased_python_easy_to_follow/?st=jc7c72gv&sh=5632e386

 just fyi im not an avid windows/pc user. (mac user) I just have a custom built PC with mac os installed as dual boot. im new to this cmd prompt stuff.
  ",chat service use maybe chat real time probably easier tried install ran tried tutorial successfully ran training working avid user mac user custom built mac o dual boot new prompt stuff,issue,positive,positive,positive,positive,positive,positive
356093659,"If you can have a look at the #59 , it is much more about new features and bug corrections...
  ",look much new bug,issue,negative,positive,positive,positive,positive,positive
356093413,"Thanks! Anyhow I did not focus on that today. Today I did split the bugs + the models plugins from the GAN itself. Yesterday it was all done in one big commit.

I'll work on the GAN version tomorrow if I can",thanks anyhow focus today today split gan yesterday done one big commit work gan version tomorrow,issue,positive,positive,neutral,neutral,positive,positive
356090935,Using this code to train a model from scratch on GPU now. Will report back.,code train model scratch report back,issue,negative,neutral,neutral,neutral,neutral,neutral
356084712,"Without preview I would be flying blind so the speak.
I can take a look again when it's ready",without preview would flying blind speak take look ready,issue,negative,negative,negative,negative,negative,negative
356080387,"Ah, I just had a closer look at the trace. The bug is in the preview, so the training certainly can go on without this. If you disable the preview, it may still be training...

(In the trace, it says `File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 126, in show
cv2.imshow('', image_gen())` which means the bug relies in the preview display...)",ah closer look trace bug preview training certainly go without disable preview may still training trace file line show bug preview display,issue,negative,positive,positive,positive,positive,positive
356078056,"im afraid its beyond me right now.
no problem. thanks for putting your time into this
  ",afraid beyond right problem thanks time,issue,negative,negative,neutral,neutral,negative,negative
356076539,"About the preview, there are options to add at command line look inside `scripts/train.py` if the config is correct

Otherwise it starts being specific to the GAN code. If you are really motivated, you can look at the GAN repo. Otherwise, I will have a look tomorrow hopefully, and maybe, as I said to @shaoanlu , I'll rework the latest code from there

Anyhow thanks for the feedback!",preview add command line look inside correct otherwise specific gan code really look gan otherwise look tomorrow hopefully maybe said rework latest code anyhow thanks feedback,issue,positive,positive,positive,positive,positive,positive
356075405,"removed the comments from load still the same error.
last print:

[22:41:47] [51/150][50] Loss_DA: 0.193126 Loss_DB: 0.189106 Loss_GA: 0.245307 Loss_GB: 0.259314
[22:41:50] Working...
[22:41:53] Working...
[22:41:55] Working...
[22:41:58] Working...
[22:42:01] Working...
[22:42:03] Working...
[22:42:06] Working...
[22:42:09] Working...
[22:42:11] Working...
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
..........",removed load still error last print working working working working working working working working working exception thread recent call last file line,issue,negative,neutral,neutral,neutral,neutral,neutral
356072685,"worked a little then gave this error

File K:\faceswap-dev-gan-plugin\models\decoder_A_GAN.h5 does not exist, creating...
File K:\faceswap-dev-gan-plugin\models\decoder_B_GAN.h5 does not exist, creating...
File K:\faceswap-dev-gan-plugin\models\netDA_GAN.h5 does not exist, creating...
File K:\faceswap-dev-gan-plugin\models\netDB_GAN.h5 does not exist, creating...
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 111, in processThread
    self.show(sample_gen)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 126, in show
    cv2.imshow('', image_gen())
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 58, in <lambda>
    return lambda: self.show_sample()
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 64, in show_sample
    self.showG(tA, tB, self.trainer_A.path, self.trainer_B.path)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 80, in showG
    figure = figure.reshape((4,7) + figure.shape[1:])
ValueError: cannot reshape array of size 2359296 into shape (4,7,3,64,64,3)
  ",worked little gave error file exist file exist file exist file exist exception thread recent call last file line file line run file line file line show file line lambda return lambda file line ta file line figure reshape array size shape,issue,negative,negative,neutral,neutral,negative,negative
356072445,"now its says ""Working"" but i dont see the preview screen
i used -p",working dont see preview screen used,issue,negative,neutral,neutral,neutral,neutral,neutral
356071466,"Ah... (Should really have tested my rebase before pushing, sorry for that...)
replace minibatch by
```
def minibatch(data, batchsize, args):
    length = len(data)
    epoch = i = 0
    shuffle(data)
    while True:
        size = batchsize
        if i+size > length:
            shuffle(data)
            i = 0
            epoch+=1        
        rtn = numpy.float32([read_image(data[j], args) for j in range(i,i+size)])
        i+=size
        yield epoch, rtn[:,0,:,:,:], rtn[:,1,:,:,:]       
```

You'll notice the new args param, passed to read_image",ah really tested rebase pushing sorry replace data length data epoch shuffle data true size length shuffle data data range yield epoch notice new param,issue,negative,positive,neutral,neutral,positive,positive
356070441,"@Clorr 
i commented  like this in Model.py under Model_GAN
def load(self, swapped):
        #self.encoder.load_weights(ensure_file_exists(self.model_dir, encoderH5))
        #self.decoder_A.load_weights(ensure_file_exists(self.model_dir, decoder_AH5))
        #self.decoder_B.load_weights(ensure_file_exists(self.model_dir, decoder_BH5))
        #self.netDA.load_weights(ensure_file_exists(self.model_dir, netDAH5))
        #self.netDB.load_weights(ensure_file_exists(self.model_dir, netDBH5))
        print (""model loaded."")

now this.

Starting. Press ""Enter"" to stop training and save model
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 107, in processThread
    sample_gen = trainer.train_one_step(epoch)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 33, in train_one_step
    epoch, warped_A, target_A = next(self.images_A)
  File ""K:\faceswap-dev-gan-plugin\lib\training_data.py"", line 31, in minibatchAB
    batch = BackgroundGenerator(minibatch(images, batchsize, args))
TypeError: minibatch() takes 2 positional arguments but 3 were given
  ",like load self print model loaded starting press enter stop training save model exception thread recent call last file line file line run file line epoch file line epoch next file line batch positional given,issue,positive,neutral,neutral,neutral,neutral,neutral
356068489,"Ah, this is because the `ensure_file_exists` creates empty files that cannot be read. Someone pointed this out, but I forgot to correct.

Comment out the `load_weights` lines, and train until files are saved once
 
And delete empty files",ah empty read someone pointed forgot correct comment train saved delete empty,issue,negative,negative,neutral,neutral,negative,negative
356067386,"@Clorr 
now another error. 

`File K:\faceswap-dev-gan-plugin\models\encoder_GAN.h5 does not exist, creating...
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 96, in processThread
    model.load(swapped=False)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Model.py"", line 159, in load
    self.encoder.load_weights(ensure_file_exists(self.model_dir, encoderH5))
  File ""C:\IntelPython3\lib\site-packages\keras\engine\topology.py"", line 2616, in load_weights
    f = h5py.File(filepath, mode='r')
  File ""C:\IntelPython3\lib\site-packages\h5py\_hl\files.py"", line 269, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)
  File ""C:\IntelPython3\lib\site-packages\h5py\_hl\files.py"", line 99, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py\h5f.pyx"", line 78, in h5py.h5f.open
OSError: Unable to open file (file signature not found)`
  ",another error file exist exception thread recent call last file line file line run file line file line load file line file line fid name mode file line fid name file line file line file line unable open file file signature found,issue,negative,negative,negative,negative,negative,negative
356066806,"Aw, it is from my last rebase. Remove the `=random_transform_args` and that will work. I'll push a correction ASAP",aw last rebase remove work push correction,issue,negative,neutral,neutral,neutral,neutral,neutral
356066268,"@Clorr 
when i tried to train i got this exception

`Traceback (most recent call last):
  File ""C:\IntelPython3\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""C:\IntelPython3\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""K:\faceswap-dev-gan-plugin\scripts\train.py"", line 95, in processThread
    model = PluginLoader.get_model(variant)(self.arguments.model_dir)
  File ""K:\faceswap-dev-gan-plugin\plugins\PluginLoader.py"", line 13, in get_model
    return PluginLoader._import(""Model"", ""Model_{0}"".format(name))
  File ""K:\faceswap-dev-gan-plugin\plugins\PluginLoader.py"", line 22, in _import
    module = __import__(name, globals(), locals(), [], 1)
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\__init__.py"", line 7, in <module>
    from .Trainer import Trainer
  File ""K:\faceswap-dev-gan-plugin\plugins\Model_GAN\Trainer.py"", line 5, in <module>
    from lib.training_data import minibatchAB
  File ""K:\faceswap-dev-gan-plugin\lib\training_data.py"", line 7, in <module>
    def read_image(fn, random_transform_args=random_transform_args):
NameError: name 'random_transform_args' is not defined`
  ",tried train got exception recent call last file line file line run file line model variant file line return model name file line module name file line module import trainer file line module import file line module name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
356065374,"Hi @shaoanlu and thanks for coming,

I'm just taking your code, you still remain the one who owns it ;-) 

The approach I took for that, is a plugin architecture. The advantage of it is that many concurrent script can live together. What would be awesome is if you stick to the formalism of the plugins. 

If you have a look, you will see that for GAN plugin there are three classes: Model, Trainer and ""Trainable"" (maybe the name is not great). If you want, I can fork your repo and reshape your class so that it gets compatible. That way we could update this repo and you could make your code evolve without any burden.

What do you think?

  ",hi thanks coming taking code still remain one approach took architecture advantage many concurrent script live together would awesome stick formalism look see gan three class model trainer trainable maybe name great want fork reshape class compatible way could update could make code evolve without burden think,issue,positive,positive,positive,positive,positive,positive
356049991,"I wrote a [FaceSwapGAN class](https://github.com/shaoanlu/faceswap-GAN/blob/master/temp/faceswap_GAN_keras.ipynb).  `model.train_on_batch()` and `model.predict()` are used so it looks like keras code now. But I haven't fully checked if it performs the same with original one (Running it for 30 mins, everything seems fine). I will report the results later.
 
Edit: Oops, I didn't notice that Clorr is already working on adding GAN as a plugin. Not intended to disrupt your flow (really appreciate your work). If this class didn't seem to be of help, just ignore it.
  ",wrote class used like code fully checked original one running everything fine report later edit notice already working gan intended disrupt flow really appreciate work class seem help ignore,issue,positive,positive,positive,positive,positive,positive
355953204,"I hope we can get high resolution generated images. So we can have better close-ups. With GAN, objects blocking faces are no longer being an issue doing more close-up scenes is very tempting. ",hope get high resolution better gan blocking longer issue tempting,issue,negative,positive,positive,positive,positive,positive
355948228,Looking forward to see the code.,looking forward see code,issue,negative,neutral,neutral,neutral,neutral,neutral
355946861,"Note: Usage is the same as for other versions

@apollo122 this is the new version. It is the same as the previous but it is seprated from other more generic modifications",note usage new version previous generic,issue,negative,negative,neutral,neutral,negative,negative
355946615,"Yes, it is indeed very interesting. the code though is a bit hard to split and structure so I'll move on slowly on this. I did a new PR that is more dedicated to GAN

The usage is exactly the same as the previous one.

On the face resolution, it doesn't help, but somehow I think we can train the encoder with low res images and the decoder with higher res one. I should give it a try but I won't have much time soon
  ",yes indeed interesting code though bit hard split structure move slowly new gan usage exactly previous one face resolution help somehow think train low higher one give try wo much time soon,issue,positive,positive,neutral,neutral,positive,positive
355934450,"You are missing the Boost dependency. You can have a look at the Dockerfile to see how to install it, but I think you won't have apt-get on windows. 

Otherwise look on reddit /r/deepfakes someone posted a tutorial on how to set up things. The repo here uses the same things except you don't need pytorch.

I can't give you the link, I'm at work and the reddit is somewhat NSFW...",missing boost dependency look see install think wo otherwise look someone posted tutorial set except need ca give link work somewhat,issue,negative,negative,negative,negative,negative,negative
355929553,"I uninstalled Python 3.5 and reinstalled. Got past the runpy error and the tensorflow gpu error but now ran into other errors:

Failed building wheel for dlib
Failed building wheel for scikit-image

 -- The BOOST_ROOT and/or BOOST_LIBRARYDIR environment variables are not set.  You need to set these
  -- variables so we know where boost is installed.  So set these variables to something like this:
  --     BOOST_ROOT=C:\local\boost_1_57_0
  --     BOOST_LIBRARYDIR=C:\local\boost_1_57_0\stage\lib
  -- The best way to set enviornment variables in Windows is to go to the start menu's search box,
  -- type environment, and open the Environment Variables dialog.  That lets you add more variables.
  -- Add these variables to either user or system variables, it doesn't matter.
  -- You might have to log out and log back in before the environment changes take effect.

 CMake Error at C:/Users/Mi/AppData/Local/Temp/pip-build-fw5bfa97/dlib/dlib/cmake_utils/add_python_module:149 (message):
     Boost python library not found.
  Call Stack (most recent call first):
    CMakeLists.txt:9 (include)
  -- Configuring incomplete, errors occurred!
  See also ""C:/Users/Mi/AppData/Local/Temp/pip-build-fw5bfa97/dlib/tools/python/build/CMakeFiles/CMakeOutput.log"".
  See also ""C:/Users/Mi/AppData/Local/Temp/pip-build-fw5bfa97/dlib/tools/python/build/CMakeFiles/CMakeError.log"".
  error: cmake configuration failed!

 -- Found CUDA: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0 (found suitable version ""8.0"", minimum required is ""7.5"")
    CMake Warning at C:/Users/Mi/AppData/Local/Temp/pip-build-fw5bfa97/dlib/dlib/CMakeLists.txt:535 (message):
      You have CUDA installed, but we can't use it unless you put visual studio
      in 64bit mode.
    -- Disabling CUDA support for dlib.  DLIB WILL NOT USE CUDA
    -- C++11 activated.

I am pretty much giving up at this point... I cant get past install. sigh*
",uninstalled python got past error error ran building wheel building wheel environment set need set know boost set something like best way set go start menu search box type environment open environment add add either user system matter might log log back environment take effect error message boost python library found call stack recent call first include incomplete see also see also error configuration found found suitable version minimum warning message ca use unless put visual studio bit mode support use pretty much giving point cant get past install sigh,issue,positive,positive,positive,positive,positive,positive
355895820,"Man so excited about GAN. I saw the gifs and I was blown away with masking it uses which doesn't blur foreign objects in front of faces such as hands.
I have one question though, does it help with resolution of generated face? 64x64 is really low and because of that close up scenes suck with original code.
I can test it if anyone give me a walk-through about how to use it.",man excited gan saw blown away blur foreign front one question though help resolution face really low close suck original code test anyone give use,issue,negative,positive,positive,positive,positive,positive
355895727,"As I see runpy is a part of python itself, so there seems to be a problem with your installation. The most useful resource I found is that one: https://stackoverflow.com/questions/44463879/could-not-import-runpy-module

Alternatively you can check reddit and get the install procedure from there. Maybe you will have more luck with it ",see part python problem installation useful resource found one alternatively check get install procedure maybe luck,issue,negative,positive,positive,positive,positive,positive
355893346,"Very strange, there is no runpy module imported in the project. Maybe a sub dependency. I'll check that today if I can reproduce...",strange module project maybe sub dependency check today reproduce,issue,negative,negative,neutral,neutral,negative,negative
355860474,"I uninstalled 3.6 and installed 3.5. 

This is the result after running the requirements-gpu.txt command:
(faceswap) C:\faceswap>pip install -r requirements-gpu.txt
Could not import runpy module
ModuleNotFoundError: No module named 'runpy'",uninstalled result running command pip install could import module module,issue,negative,neutral,neutral,neutral,neutral,neutral
355845960,"Yes, it is a heavy file so it was not put in the code. You can download it from the url provided.

Note that the repo has just been updated and that the new version downloads everything by itself. It also now uses the latest masked script",yes heavy file put code provided note new version everything also latest masked script,issue,negative,positive,positive,positive,positive,positive
355845711,"Ok, many thanks! I merge this because we need to move on.

The 2 points are from the original code, so we can say it's legacy ;-) We can change them at some point anyway...",many thanks merge need move original code say legacy change point anyway,issue,positive,positive,positive,positive,positive,positive
355834472,well.it's actually just missing a file in the contrib folder and it already told you where to download it.,actually missing file folder already told,issue,negative,negative,negative,negative,negative,negative
355829757,"Other than that, seems legit. I was unable to test this on GPU at this time, but I doubt it would yield different results. Just faster.",legit unable test time doubt would yield different faster,issue,negative,negative,negative,negative,negative,negative
355808727,Did you try install python version 3.5?,try install python version,issue,negative,neutral,neutral,neutral,neutral,neutral
355799377,"I tried your method to remove the ==1.4.0. No success.

I then tried the other method in the official doc link you provided with this result: 
c:\>pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-win_amd64.whl
tensorflow_gpu-0.12.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.

I am really scratching my head over this issue. I run a Intel i7 7700K  CPU and NVIDIA GTX 1080 ",tried method remove success tried method official doc link provided result pip install upgrade wheel platform really scratching head issue run,issue,positive,positive,positive,positive,positive,positive
355785969,"In a [comment](https://github.com/tensorflow/tensorflow/issues/8251#issuecomment-285503939) on the link you provide, it says that `tensorflow-gpu` works only with `python 3.5.x` . Maybe it is for the `1.4.0` and if you try a newer lib it will work with `python 3.6.x`. It is likely something like that. If you manage to solve this with a newer version, please paste here the version number you finally used.
  ",comment link provide work python maybe try work python likely something like manage solve version please paste version number finally used,issue,positive,neutral,neutral,neutral,neutral,neutral
355744199,"Thanks for the link, and feel free to join!

If you have code for the GUI to put here, just make a `gui` folder at the root and do a PR, we will help you on that.

CC @Ganonmaster @Yutsa @lukaville @yangchen8710 @shaoanlu @junglewreck",thanks link feel free join code put make folder root help,issue,positive,positive,positive,positive,positive,positive
355656586,"I do like this idea of a library and several UI using it

Le ven. 5 janv. 2018 à 20:03, Hidde Jansen <notifications@github.com> a
écrit :

> The command line is just another UI and again, you just use the command
> line arguments to fill out a config. I would rather vote for turning this
> project into a library and having separate projects for UI. That way you
> have a separate web UI, GUI and command line, but they all reference this
> same library.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/deepfakes/faceswap/issues/55#issuecomment-355637610>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ALAVd6herynz6BuSaiJH_ryut2iw3tvsks5tHnIDgaJpZM4RUwNZ>
> .
>
-- 

Cordialement,
Édouard WILLISSECK
",like idea library several command line another use command line fill would rather vote turning project library separate way separate web command line reference library thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
355637610,"The command line is just another UI and again, you just use the command line arguments to fill out a config. I would rather vote for turning this project into a library and having separate projects for UI. That way you have a separate web UI, GUI and command line, but they all reference this same library.",command line another use command line fill would rather vote turning project library separate way separate web command line reference library,issue,negative,neutral,neutral,neutral,neutral,neutral
355518572,"Hi @lukaville ,

I'm closing the PR as I did reintegrate the modifications in my plugin branch.

You will see the modifications here : https://github.com/Clorr/faceswap/commit/0eb85275f15511fdb9ca9e9cffb823ba2431c621

Feel free to review, test and provide feedback.

Note that it is still a work in progress branch so maybe you may encounter problems

Also Note that the default model there is the GAN network, if you want to change this, I can help you",hi reintegrate branch see feel free review test provide feedback note still work progress branch maybe may encounter also note default model gan network want change help,issue,positive,positive,positive,positive,positive,positive
355294819,"just for your information, the issue only happen if we are using floyd cloud. what i am thinking, it possible the dataset cannot mount to the project for training. It never occur when i using my personal laptop.

this issue can consider close, i not sure other members also facing the same issue or not. ",information issue happen cloud thinking possible mount project training never occur personal issue consider close sure also facing issue,issue,negative,positive,positive,positive,positive,positive
355070827,"Thanks for the feedback. I also think there is way for arg parsing, but I'm not much into it yet... We'll see how it goes.

Good luck for your exams!",thanks feedback also think way much yet see go good luck,issue,positive,positive,positive,positive,positive,positive
355043927,"I tested it and it works great ! For me the only missing thing will be the ability to choose which plugin to use and pass arguments to that plugin as you said.

I could look into it, unfortunately I have exams during the whole next week so I won't be available to code before somewhere around the 15th of January.
  
I guess we'd need to make plugins be subcommands, that way we'll be able to change plugins and pass them arguments",tested work great missing thing ability choose use pas said could look unfortunately whole next week wo available code somewhere around th guess need make way able change pas,issue,negative,positive,positive,positive,positive,positive
355019634,"Usage did not change. The command line plugin selection is still to be done. The people who will add arg parsing will certainly do the doc updates, but its not done yet...",usage change command line selection still done people add certainly doc done yet,issue,negative,positive,positive,positive,positive,positive
355012284,Great! When it's merged a usage guide would be nice so we can try out,great usage guide would nice try,issue,positive,positive,positive,positive,positive,positive
354890727,Messy issue. Reopen for a specific question if needed,messy issue reopen specific question,issue,negative,negative,neutral,neutral,negative,negative
354890387,Also did someone try a Jupyter / Notebook launch ?,also someone try notebook launch,issue,negative,neutral,neutral,neutral,neutral,neutral
354890120,"This is nice indeed!

The main drawback I see here for a newbie wanting to launch this on his computer is the docker/nvidia-docker dependency. But for a cloud install, this would be very nice...",nice indeed main drawback see wanting launch computer dependency cloud install would nice,issue,positive,positive,positive,positive,positive,positive
354889631,"A thing I noticed on the new face merge, is that there is no face landmarks detection on the generated face. I think there is room for improvments here. After the plugin part, I'll try to make a hull detection on the generated face and try to better fit it in the old hull, maybe it can bring some gain...",thing new face merge face detection face think room part try make hull detection face try better fit old hull maybe bring gain,issue,positive,positive,positive,positive,positive,positive
354884104,"Yeah I'll try, I think it's from the `load_images(image_paths, convert=None)` function, I'll look into it",yeah try think function look,issue,negative,neutral,neutral,neutral,neutral,neutral
354883964,"I pushed a working version of the enhanced face merge (in https://github.com/Clorr/faceswap/tree/dev/masked_plugin). It should be working now, but I did not test it thoroughly. I'll do that tomorrow, and update the master. Also I will add the PluginSelector",working version enhanced face merge working test thoroughly tomorrow update master also add,issue,negative,neutral,neutral,neutral,neutral,neutral
354875161,"Also a good catch is the silent failure. If you can add some warning there, that would be handy to some people...",also good catch silent failure add warning would handy people,issue,negative,positive,positive,positive,positive,positive
354874787,"Nice catch, original script was using 160 instead of `size`. I replaced without really understanding how things work....",nice catch original script instead size without really understanding work,issue,positive,positive,positive,positive,positive,positive
354872925,"I resized and indeed it was the issue. You wrote :

```Python
new_size = int( size + padding * 2 )
```
 I don't really get why but the extra 96 pixels in width and height are because of that since you pass a padding of 48 here 

```Python
return self.transform( image, alignment, size, 48 ) # original size was 160. Crop was on 256, is that ok?
```",indeed issue wrote python size padding really get extra width height since pas padding python return image alignment size original size crop,issue,negative,positive,positive,positive,positive,positive
354868953,"Weirdly enough, I tried to train the model with these new pictures added to my dataset and the training script exits before even starting the training.

I tried with the old pictures, without the alignement, and it works. I don't know what causes this for my pictures, I'm looking into it.

It may have to do with the size being 352x352 instead of 256x256",weirdly enough tried train model new added training script even starting training tried old without work know looking may size instead,issue,negative,positive,neutral,neutral,positive,positive
354843756,"Oh sorry, english is not my native language and I misunderstood. I've got that one from the side but I don't have the original one anymore.

![00290](https://user-images.githubusercontent.com/11539831/34495367-28dfe746-eff5-11e7-9fe4-45cb6d4621cf.png)
",oh sorry native language misunderstood got one side original one,issue,negative,negative,neutral,neutral,negative,negative
354842049,"Ah, I was thinking about some face you see from the side, profile view ;-)",ah thinking face see side profile view,issue,negative,neutral,neutral,neutral,neutral,neutral
354838195,"I tried on a face that was leaning on the side and it correctly put it straight.

For instance : 

![0010](https://user-images.githubusercontent.com/11539831/34494716-07d5a598-eff2-11e7-81e9-3233b5780193.png)

![00100](https://user-images.githubusercontent.com/11539831/34494717-0c006586-eff2-11e7-8818-deffc8c567c9.png)
",tried face leaning side correctly put straight instance,issue,negative,positive,positive,positive,positive,positive
354836358,"Thanks for the kind feedback! Did you also try on side faces? I tried on a group photo, but not much more...

I'm working currently on a factory to return a plugin according to a string. I'll let you add the argparser part.

I have a working branch (https://github.com/Clorr/faceswap/tree/dev/masked_plugin) where I'm adding the masked convert. As you may see, the convert plugin will have to handle specific params depending on which plugin is active. This should be passed as command line args, but I don't know how to tackle that. But that's for later I think...",thanks kind feedback also try side tried group photo much working currently factory return according string let add part working branch masked convert may see convert handle specific depending active command line know tackle later think,issue,positive,positive,positive,positive,positive,positive
354833826,"I ran the extract with align and it worked flawlessly ! Great job !

Should we add a way for the user to choose which extractor plugin to use ?",ran extract align worked flawlessly great job add way user choose extractor use,issue,positive,positive,positive,positive,positive,positive
354802160,I'll have some time tonight to review and provide feedback.,time tonight review provide feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
354801879,"I would encourage this, but would prefer keeping it in a separate repository, perhaps importing this project as a library of some kind.",would encourage would prefer keeping separate repository perhaps project library kind,issue,positive,positive,positive,positive,positive,positive
354790891,"But I don't like to spend too much time on debugging, so if you can try and give me feedback, feel free",like spend much time try give feedback feel free,issue,positive,positive,positive,positive,positive,positive
354790661,"Yes, my goal is to gather/integrate the different improvments, and that's why a plugin approach comes handy.

I was trying since a while to understand/integrate the face alignment. Now that it is done on `extract`, I'll move on the face merge.",yes goal different approach come handy trying since face alignment done extract move face merge,issue,negative,positive,positive,positive,positive,positive
354787513,"On reddit a user also patched the falce_align and merge_face scripts to use masks and it worked great apparently, should we be able to include those two scripts now that you deleted the pytorch dependency ?

It's a bit sad that all those people on reddit use a collection of scripts scattered everywhere and are not using and contributing directly to this project",user also use worked great apparently able include two dependency bit sad people use collection scattered everywhere directly project,issue,negative,positive,positive,positive,positive,positive
354783879,That'd be awesome and maybe not too hard to implement using Flask for instance. That would be really interesting to do,awesome maybe hard implement flask instance would really interesting,issue,positive,positive,positive,positive,positive,positive
354783674,"I love the plugin idea since there are lots of versions of the scripts on the deepfake subreddit, it'd be a good way to use several versions.

As for the face alignement, if it works as well as the one using pytorch that's awesome because that script was really great !",love idea since lot good way use several face work well one awesome script really great,issue,positive,positive,positive,positive,positive,positive
354782272,"Hi guys!

Little awesome news: I added a face align plugin that does not rely on pytorch!

I still need to do the switch between plugins, but otherwise, I think I'm on a good way!

Don't hesitate to give me feedback!

Thx",hi little awesome news added face align rely still need switch otherwise think good way hesitate give feedback,issue,positive,positive,positive,positive,positive,positive
354763769,"I updated my code so it can run 😃 

Please make me some feedback when you can so I can move on...",code run please make feedback move,issue,negative,neutral,neutral,neutral,neutral,neutral
354662672,"The class is in my PR as the `Convert_Adjust.py` plugin. However, I did not address the fact that the model is reloaded for each image.

@Ganonmaster , let me know if you want to tackle this separately, or if you are ok with my `plugins` folder. If so I'll make it run so it can be integrated quickly",class however address fact model image let know want tackle separately folder make run quickly,issue,negative,positive,positive,positive,positive,positive
354647883,"I'm adding a Convert class which will load models on `__init__`

It will be in my branch until I do a PR, but feel free to have a look",convert class load branch feel free look,issue,positive,positive,positive,positive,positive,positive
354642649,"In the end, all these libraries boil down to is basic interaction with ffmpeg. I'm pretty sure python-OpenCV has this, but only if configured to use it. I would opt for the library with the most straightforward/pythonic interface. I would guess that is most likely moviepy, but I will look further into this after I've recovered from the new years hangover.",end boil basic interaction pretty sure use would opt library interface would guess likely look new,issue,positive,positive,positive,positive,positive,positive
354634974,"  @Ganonmaster @duoyu5555 i just use the trained model provided by the author to generate the output, and didn't train the model.
",use trained model provided author generate output train model,issue,negative,neutral,neutral,neutral,neutral,neutral
354629399,"Hmm, I just realized that probably ""Unable to open file"" error may be irrelevant to the real issue because even when everything is OK and script creates models for the first time this message still printed.

@ruah1984 check that there are images in /faces_a and /faces_b directories. I've just had the same issue with the same output and it happens when there are no image files in input directories root. Probably we have to print more clear message in this case :)",probably unable open file error may irrelevant real issue even everything script first time message still printed check issue output image input root probably print clear message case,issue,negative,negative,neutral,neutral,negative,negative
354627017,"What I understand from your issue, is that it tries to load an encoder.h5 from the `/output/models ` folder and does not find it. But what is not clear for me is if you have to upload this file before launching the training or not. In desperate case, try uploading the 3 .h5 files in `/output/models` folder",understand issue load folder find clear file training desperate case try folder,issue,negative,negative,negative,negative,negative,negative
354626687,"oh ok, the quote is closing the one before `python...` , so it seems fine. As @lukaville suggested, you should check with the `--mode jupyter` flag to have more visibility on what is going on...",oh quote one python fine check mode flag visibility going,issue,negative,positive,positive,positive,positive,positive
354626284,"@Clorr here is the command line i use in cmd
floyd run --gpu --env tensorflow-1.4:py2 --data faces_a:/faces_a --data faces_b:/faces_b ""python faceswap.py train -A /faces_a -B /faces_b -v -m /output/models

in floydhub, the command will show
floyd run --gpu --env tensorflow-1.4:py2 --data ruah1984/datasets/faces_a:/faces_a --data ruah1984/datasets/faces_b:/faces_b 'python faceswap.py train -A /faces_a -B /faces_b -v -m /output/models'",command line use run data data python train command show run data data train,issue,negative,neutral,neutral,neutral,neutral,neutral
354626058,"Ok @ruah1984 . That will help someone who may know more than me on that... 

One question though, there is a quote at the end of your command line, is that a copy/paste bug, or do you use it in your run?",help someone may know one question though quote end command line bug use run,issue,negative,neutral,neutral,neutral,neutral,neutral
354626041,"@ruah1984 you can start job using `--mode jupyter` flag and open terminal in jupyter web interface. So you can inspect directories using command line utils (`ls`, `cd`, etc.), or you can use built-in jupyter file manager and check that this directory exists.",start job mode flag open terminal web interface inspect command line use file manager check directory,issue,negative,neutral,neutral,neutral,neutral,neutral
354625967,"all process have been follow,
the latest one is create an output folder inside the faceswap directory 
--faceswap1\output\models

You can refer below link
https://www.floydhub.com/ruah1984/projects/quick-start-trial-and-error/10

Data set is here
https://www.floydhub.com/ruah1984/datasets/faces_b
https://www.floydhub.com/ruah1984/datasets/faces_a

all above is public, you can view it from the link ",process follow latest one create output folder inside directory refer link data set public view link,issue,negative,positive,positive,positive,positive,positive
354625772,"I'm not into floyd for now, so that was a guess from your error message. I checked [this page](https://www.reddit.com/r/deepfakes/comments/7mgpki/floydhub_cloud_training/) that gives pretty handy instructions. Did you follow everything? (there is a mention of a ""models"" folder also...)

- [ ] Install floyd-cli: `pip install -U floyd-cli`
- [ ] Login: `floyd login`
- [ ] Then inside faceswap project directory run: `floyd init faceswap`
- [ ] Outside project directory create directories with training data for face A and B and run inside each directory: 
```
floyd data init faces_a # in the first directory
floyd data upload
floyd data init faces_b # in the second directory
floyd data upload
```

- [ ] Inside faceswap directory create empty `models` folder. If the folder contains models it may not work because there is a size limit for code directory.
- [ ] Copy `requirements-gpu.txt` to `floyd_requirements.txt`
- [ ] Remove ""lib"" from `.floydignore` file
- [ ] Finally, run the training :) `floyd run --gpu --env tensorflow-1.4:py2 --data faces_a:/faces_a --data faces_b:/faces_b ""python faceswap.py train -A /faces_a -B /faces_b -v -m /output/models""`
",guess error message checked page pretty handy follow everything mention folder also install pip install login login inside project directory run outside project directory create training data face run inside directory data first directory data data second directory data inside directory create empty folder folder may work size limit code directory copy remove file finally run training run data data python train,issue,negative,positive,positive,positive,positive,positive
354625531,"hi @Clorr  this is the command line i use,

`floyd run --gpu --env tensorflow-1.4:py2 --data ruah1984/datasets/faces_a:/faces_a --data ruah1984/datasets/faces_b:/faces_b 'python faceswap.py train -A /faces_a -B /faces_b -v -m /output/models'`

the input dateset store inside floydhub
ruah1984/datasets/faces_a
ruah1984/datasets/faces_b

as other mention in the reddit, i have create an output folder but same issue as well



",hi command line use run data data train input store inside mention create output folder issue well,issue,negative,neutral,neutral,neutral,neutral,neutral
354625127,"Ah ok. I think the printing of the help message after termination is a reported issue (#43)

Beside that, I can't help for now. What's the command line that is used here?",ah think printing help message termination issue beside ca help command line used,issue,positive,neutral,neutral,neutral,neutral,neutral
354624998,"@Clorr, looks like @ruah1984 uses Floydhub, where output folder should be pre-created automatically and writable https://docs.floydhub.com/guides/data/storing_output/",like output folder automatically writable,issue,negative,neutral,neutral,neutral,neutral,neutral
354623346,Remark: ‘python-opencv‘ seems not to have video support built-in as default. Is ‘moviepy‘ a better alternative?,remark video support default better alternative,issue,positive,positive,positive,positive,positive,positive
354623222,Closing this since we have a decent face merge with #30 and that the seamless clone is part of the face align script (#16),since decent face merge seamless clone part face align script,issue,negative,positive,positive,positive,positive,positive
354623179,"Closing this issue because the referenced scripted has evolved and should not be integrated as is in the project.

I'll reopen an issue to handle the new script when I'll be more available on the project",issue project reopen issue handle new script available project,issue,negative,positive,positive,positive,positive,positive
354602004,"HI @lukaville , same error message found when using cloud base GPU
as below 

2017-12-31 04:42:30,364 INFO - Unable to open file (unable to open file: name = '/output/encoder.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
2017-12-31 04:42:30,603 INFO - usage: faceswap.py [-h] {extract,train,convert} ...
2017-12-31 04:42:30,603 INFO - 
2017-12-31 04:42:30,604 INFO - positional arguments:
2017-12-31 04:42:30,604 INFO - {extract,train,convert}
2017-12-31 04:42:30,604 INFO - extract             Extract the faces from a pictures.
2017-12-31 04:42:30,604 INFO - train               This command trains the model for the two faces A and
2017-12-31 04:42:30,604 INFO - B.

can't figure what's go wrong",hi error message found cloud base unable open file unable open file name error message file directory usage extract train convert positional extract train convert extract extract train command model two ca figure go wrong,issue,negative,negative,negative,negative,negative,negative
354599430,I had a similar problem. Is it caused by a too-short-training time or some problems of resolution or something else?,similar problem time resolution something else,issue,negative,neutral,neutral,neutral,neutral,neutral
354597628,What does the training preview output look like?,training preview output look like,issue,negative,neutral,neutral,neutral,neutral,neutral
354518241,This issue should probably be closed and split up into more specific issues since we have some basic command line usage now.,issue probably closed split specific since basic command line usage,issue,negative,negative,neutral,neutral,negative,negative
354462507,"Yeah I was actually looking at `nvidia-docker`, it looks complicated to have a Docker container with GPU.

I guess we'll have to wait for this to be better supported.",yeah actually looking complicated docker container guess wait better,issue,positive,neutral,neutral,neutral,neutral,neutral
354462315,"In order to use Docker with a GPU, you'd need to split it up further between OpenCL and CUDA. To use Nvidia CUDA with docker, the only possible way is [nvidia-docker](https://github.com/NVIDIA/nvidia-docker), which is only supported on Linux. In addition, the same is true for Docker with OpenCL. As far as I know, OpenCL support in Docker involves manually giving your docker container access to your host's GPU driver.

So, assuming that Linux users are per definition more tech-savvy than Windows or macOS users and considering that Dockerized GPU support is limited to Linux for the time being, I strongly believe that the usage of Docker does not help non-technical users at all. Yes, it's nice if you're savvy with Docker and containers, but is that really even a desirable method of distribution for people who have very limited command line knowledge?

I do not think Docker GPU support is going to help in getting this project usable for non-technical users. A Docker Hub image would be nice, but it would be limited to a CPU version, because getting it working on a GPU (CUDA or OpenCL) would still be a pain.

Still, I would encourage you to research and play around with this, and provide pull requests if you manage to get it working.",order use docker need split use docker possible way addition true docker far know support docker manually giving docker container access host driver assuming per definition considering support limited time strongly believe usage docker help yes nice savvy docker really even desirable method distribution people limited command line knowledge think docker support going help getting project usable docker hub image would nice would limited version getting working would still pain still would encourage research play around provide pull manage get working,issue,positive,positive,positive,positive,positive,positive
354459881,"Shouldn't we provide to `Dockerfile`s ? One for GPU and the other for CPU ?

Ideally we should upload both images on Docker Hub, that way a user would only have to install docker and run the `docker run -it --rm -v [sourceFolder]:/srv -it user/faceswap:tag bash`

I also thought maybe we could add a function to create the video from the swapped pictures after `convert` maybe ?

Ideally if we could from the same tool cut the video into frames, cut faces, train, replace faces and assemble the video back it would be the best for a user.",provide one ideally docker hub way user would install docker run docker run tag bash also thought maybe could add function create video convert maybe ideally could tool cut video cut train replace assemble video back would best user,issue,positive,positive,positive,positive,positive,positive
354434898,Also this guy had the problem as his card is having only 2Gb: https://www.reddit.com/r/deepfakes/comments/7mqob8/first_try_with_smaller_network/,also guy problem card,issue,negative,neutral,neutral,neutral,neutral,neutral
354393545,"Open model.py in lib, try reduce the filter number 
```
def Encoder():
    input_ = Input(shape=IMAGE_SHAPE)
    x = input_
    x = conv(128)(x)
    x = conv(256)(x)
    x = conv(512)(x)
    x = conv(1024)(x)
    x = Dense(ENCODER_DIM)(Flatten()(x))
    x = Dense(4 * 4 * 1024)(x)
    x = Reshape((4, 4, 1024))(x)
    x = upscale(512)(x)
    return Model(input_, x)
```
It works.
This is the [link](https://www.reddit.com/r/deepfakes/comments/7jqvny/release_face_swap_model_tool/dr8qivr/). Thanks [deepfakes](https://www.reddit.com/user/deepfakes).
",open try reduce filter number input dense flatten dense reshape upscale return model work link thanks,issue,negative,positive,neutral,neutral,positive,positive
354380103,"It's not necessarily about Tensorflow. It's not necessarily about the pictures you are using. It's about the training model as well. There are a lot of factors to consider. Essentially, for this specific processing task, you need around 3-4GB of graphics memory. I'm unsure about specifying the size of the loaded training data; I would have to dive into Tensorflow and Keras in more detail. Perhaps this is something that can be improved in the future, but it looks like you might be stuck with CPU training.",necessarily necessarily training model well lot consider essentially specific task need around graphic memory unsure size loaded training data would dive detail perhaps something future like might stuck training,issue,negative,neutral,neutral,neutral,neutral,neutral
354376383,"Thanks for explaining it.
Is there a method to specify the size of the loaded train data? 
Even I load one pictures for training, it show me the OOM. 
The Tensorflow-gpu has a minimum requirement for memory of video card (at least 4GB )?
Thanks. 
",thanks explaining method specify size loaded train data even load one training show minimum requirement memory video card least thanks,issue,positive,positive,neutral,neutral,positive,positive
354371187,"```Resource exhausted: OOM when allocating tensor with shape[3, 3, 128, 256]```

OOM = Out of Memory. This means there is not enough graphics memory available to load the training data. It is possible that this is related to [this issue,](https://github.com/deepfakes/faceswap/issues/39), which I will most probably be fixing tomorrow or the day after. (or, if you are capable, you could attempt to fix it on your own and send a pull request for us to merge)

But while that may be the case here, remember that a GTX660 has only 2GB of usable graphics memory in its default configuration. Most people who have had this running on GPU were using at least 4GB of graphics memory. It could therefore be possible that it is not related to that bug and that you do lack the memory required.",resource exhausted tensor shape memory enough graphic memory available load training data possible related issue probably fixing tomorrow day capable could attempt fix send pull request u merge may case remember usable graphic memory default configuration people running least graphic memory could therefore possible related bug lack memory,issue,negative,negative,neutral,neutral,negative,negative
354351955,"Checking on dependencies would be neat, but if we intend to distribute this tool as a self contained executable, it's not necessary. Other than that, catching some obvious `ImportError`s for the main libs (keras, tensorflow, dlib, face_recognition) here and there might be sufficient.",would neat intend distribute tool self executable necessary catching obvious main might sufficient,issue,negative,positive,positive,positive,positive,positive
354350256,"Closing this, and making a new issue as user @Nelthirion seems to have issues in editing the title.",making new issue user title,issue,negative,positive,positive,positive,positive,positive
354348326,"Ideally we'd want a function that does `convert_video` instead of `convert_one_image`. Feel free to create a pull request, otherwise I'll get to it later this week.",ideally want function instead feel free create pull request otherwise get later week,issue,positive,positive,positive,positive,positive,positive
354327280,"Now that you put it like that agreed.
As for the questions, 
yes seamlessclone should be added; 
In my view most significant problem with pytorch is that it's not working for Windows. But there are people working on it. https://github.com/pytorch/pytorch/issues/494
So in time we may get an update",put like agreed yes added view significant problem working people working time may get update,issue,positive,positive,positive,positive,positive,positive
354323544,"Just thinking here. Can we also check for installed dependencies ? 

(Note: I did not look at the latest commits so maybe it's on its way...)",thinking also check note look latest maybe way,issue,negative,positive,positive,positive,positive,positive
354323055,"Hmm, we can't let issues opened just for improvement. We already have the faceswap-model for that.

The question is then:
- should we add seamlessclone?
- how is this code on the alignment? Is it worth continuing on #16 ? (Considering pytorch is a heavy dependency)",ca let improvement already question add code alignment worth considering heavy dependency,issue,positive,positive,neutral,neutral,positive,positive
354321492,I think they should remain being open. So that other people may come and improve those. #8 may use an edit though as it's not the current case anymore,think remain open people may come improve may use edit though current case,issue,negative,neutral,neutral,neutral,neutral,neutral
354318048,"@yangchen8710 many thanks for this amesome contrib!

It's amazing how you did it with such simple approach! I added you as collab on the 2 side projects (playground and models) so you can freely make things move on if you want. On the main project, I let @Ganonmaster handle things as he does this like a boss ;-) But feel free to push other things...

One question though. Does this cover the issues #8 and #16 about masking and alignment ? What should we do with them, close them or continue ? ",many thanks amazing simple approach added side playground freely make move want main project let handle like bos feel free push one question though cover alignment close continue,issue,positive,positive,positive,positive,positive,positive
354281231,"Also, it will be nice to print an error if we can't write to the directory. Currently, the script fails without error description and for some reason prints help information if models directory is read-only. This is very confusing and took me some time to figure out where is the problem :)",also nice print error ca write directory currently script without error description reason help information directory took time figure problem,issue,negative,positive,positive,positive,positive,positive
354251677,"There is no such warning at this time. I have made a issue for creating it, but if you wish to implement it yourself, you are free to submit a pull request.",warning time made issue wish implement free submit pull request,issue,positive,positive,positive,positive,positive,positive
354248455,"@Ganonmaster 
as how to use Theano , i follow this link [https://github.com/keras-team/keras/issues/3794](url) and do as ch3ll0v3k said:
$ nano ~/.keras/keras.json
{
""image_dim_ordering"": ""th"",
""epsilon"": 1e-07,
""floatx"": ""float32"",
""backend"": ""theano""
}

btw, i have set the input_A, input_B and models' dir, otherwise there should be warning that: input dir not found. but i didn't receive this warning.",use follow link said th epsilon float set otherwise warning input found receive warning,issue,negative,neutral,neutral,neutral,neutral,neutral
354247272,"Hi, you seem to have not specified input, output and/or model directories. Could you try specifying any of those options and see what the command does then? Also note that these directories must exist for the script to work.

Also note that I'm assuming you have made changes to the script to use the Theano backend. The default is the Tensorflow backend. If you could share your experiences with this backend, we'd be very grateful.",hi seem input output model could try see command also note must exist script work also note assuming made script use default could share grateful,issue,positive,neutral,neutral,neutral,neutral,neutral
354246470,"yeah.
@Ganonmaster 
the command : **sudo CUDA_VISIBLE_DEVICES=1 python3 faceswap.py train**
**running log message:**

Using Theano backend.
usage : faceswap.py [-h]{extract,train,convert}....
positional arguments:
{extract,train,convert}
extract 
train
convert
optional arguments:
-h, --help

Then it return to the dir that i run the command,  and there is no other error message.
i have installed the tf1.3, python3.5, keras2.2 and my os is ubuntu14.04",yeah command python train running log message usage extract train convert positional extract train convert extract train convert optional help return run command error message o,issue,negative,neutral,neutral,neutral,neutral,neutral
354239114,"Hi, visonpon. Could you please fill out the issue template or otherwise expand on your problem description? You have given us very little information to go on.

If you could, would you be so kind as to provide us with information about the command that you are running that results in this error and perhaps some information on the operating system you are using?",hi could please fill issue template otherwise expand problem description given u little information go could would kind provide u information command running error perhaps information operating system,issue,negative,positive,positive,positive,positive,positive
354158847,The doc changes have been merged. I'll look at your other issue shortly. 👍 ,doc look issue shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
354154759,"Cool @lukaville , great job.
Will give it a try ;)
In the mean time can you have a look on this link and help me out?
https://github.com/deepfakes/faceswap-playground/issues/10
Thanks once again.
",cool great job give try mean time look link help thanks,issue,positive,positive,positive,positive,positive,positive
354153982,"@nerdprogrammergm I successfully used floydhub, I made a post about it https://www.reddit.com/r/deepfakes/comments/7mgpki/floydhub_cloud_training/",successfully used made post,issue,negative,positive,positive,positive,positive,positive
354153586,"There is also a typo in the doc for converting:
 Using TensorFlow backend.
usage: faceswap.py [-h] {extract,train,convert} ...
faceswap.py: error: invalid choice: 'data/trump' (choose from 'extract', 'train', 'convert')


Proper command to convert is: python3.6 faceswap.py convert -i data/trump -o output/trump -m models

@Ganonmaster  @yangchen8710 

Sorry for tagging ya all, m noob at using github too!",also typo doc converting usage extract train convert error invalid choice choose proper command convert python convert sorry ya,issue,negative,negative,negative,negative,negative,negative
354153008,"Yes, thanks man. Have you tried to setup this on aws ec2 p2 instance?
Overthere, I am dealing with the issue for cuda9, got to wait until tensorflow support cuda9.
For cuda8, I tried but somewhere dlib through error about lib related to 9.so . Try to troubleshoot it but found that its tensorflow which is not compatible with cuda9 yet :/
You got any solution for this?",yes thanks man tried setup instance dealing issue got wait support tried somewhere error related try found compatible yet got solution,issue,positive,positive,neutral,neutral,positive,positive
354152660,"Got the issue, its the ""train"" missed out from the command!
This command should be used to train the model: python3.6 faceswap.py train -A extract/trump -B extract/cage -m models -p 
@lukaville @yangchen8710  @Ganonmaster ",got issue train command command used train model python train,issue,negative,neutral,neutral,neutral,neutral,neutral
354152624,Looks like it's a typo in the doc. Use `python faceswap.py train -A ~/faceswap/data/trump -B ~/faceswap/data/cage -m ~/faceswap/models/` instead.,like typo doc use python train instead,issue,negative,neutral,neutral,neutral,neutral,neutral
354152384,"I am following the instructions mentioned on this lnk:https://github.com/deepfakes/faceswap/blob/master/USAGE.md

which says to execute the following command to train the model!
python3.6 faceswap.py -A ~/faceswap/data/trump -B ~/faceswap/data/cage -m ~/faceswap/models/",following execute following command train model python,issue,negative,neutral,neutral,neutral,neutral,neutral
354152189,"Most likely you are trying to start the script with invalid arguments. You have to specify 'extract', 'train' or 'convert' right after `faceswap.py`",likely trying start script invalid specify right,issue,negative,positive,positive,positive,positive,positive
354151966,"Thanks for quick reply.
I figured out the issue and now working on further part.
Presently I am getting this error:
Using TensorFlow backend.
usage: faceswap.py [-h] {extract,train,convert} ...
faceswap.py: error: invalid choice: 'extract/trump' (choose from 'extract', 'train', 'convert')


I have extracted the faces in extract/trump and extract/cage,
using this command to train the model: python3.6 faceswap.py -A extract/trump -B extract/cage -m models -p 


What wrong am I doing?",thanks quick reply figured issue working part presently getting error usage extract train convert error invalid choice choose extracted command train model python wrong,issue,negative,positive,neutral,neutral,positive,positive
354150592,"Otherwise, try running the script in a virtualenv as described in the guide.",otherwise try running script guide,issue,negative,neutral,neutral,neutral,neutral,neutral
354149279,"I'm currently looking into creating an initial self-contained build of the command-line tool in its current state. PyInstaller seems like a good option, although I fear it might result in very large binaries.

Would be nice to release it on January 1st if possible!",currently looking initial build tool current state like good option although fear might result large would nice release st possible,issue,positive,positive,positive,positive,positive,positive
354137274,"Make sure you are running python 3.6 or otherwise try adding `pathlib` through pip:

```bash
pip install --upgrade pathlib
```",make sure running python otherwise try pip bash pip install upgrade,issue,negative,positive,positive,positive,positive,positive
354115289,use python3.6 instead of python3?,use python instead python,issue,negative,neutral,neutral,neutral,neutral,neutral
354102286,"I just tested this latest pull request, and it seems to be functioning accordingly.",tested latest pull request accordingly,issue,negative,positive,positive,positive,positive,positive
354102227,"IF you look at the script in its current form, it simply crops a straight rectangle and applies the transformation to that + pastes it back. However, sometimes a head is tilted sideways and we could get a better crop if we rotated the cropped image for example. That's what the aligner is for. It's kind of rough in its current state, that's why it was commeted out.",look script current form simply straight rectangle transformation back however sometimes head sideways could get better crop rotated image example aligner kind rough current state,issue,positive,positive,positive,positive,positive,positive
354101414,What does it align exactly ? How does it improve the results ? Sorry for my ignorance,align exactly improve sorry ignorance,issue,negative,negative,negative,negative,negative,negative
354101237,"The aligner was not ready, that's why the default setting is off. Having it as an option should make testing improvements for it easier though.",aligner ready default setting option make testing easier though,issue,positive,positive,positive,positive,positive,positive
354058892,"@yangchen8710
Great. You can make a pull request if it's ready",great make pull request ready,issue,positive,positive,positive,positive,positive,positive
354057118," @Apollo122  
This is a result of automatic.
Already done the code.",result automatic already done code,issue,negative,neutral,neutral,neutral,neutral,neutral
354055970,Looks good. Can this be done automatically in the pipeline?,good done automatically pipeline,issue,negative,positive,positive,positive,positive,positive
354017016,"Closing this for now as it does not seem to be a code bug. If there is a structural issue, it can be re-opened. Meanwhile, ask your question on the faceswap-playground. https://github.com/deepfakes/faceswap-playground",seem code bug structural issue meanwhile ask question,issue,negative,neutral,neutral,neutral,neutral,neutral
353995729,The documentation looks great ! The little walkthrough is really helpful.,documentation great little really helpful,issue,positive,positive,positive,positive,positive,positive
353880633,"Hi @nerdprogrammergm ,

As @Ganonmaster stated, and as you know it as programmer, it is not always easy to do user friendly things. This project uses advanced libraries and those are not really easy to package for now.

So for now, all we can do is improving usage (and the project is already easier to use than before), but we can't promise about a ""super easy"" solution.

Also note that the project is collaborative and everyone coming here should consider that it is not done by super Python programmers who just don't care about end user. I'm also a Java programmer, and tackled C# or NodeJs from time to time, but never did Python. I spent hours to find out things and that's the way it is for now. Also @Ganonmaster  spent many hours to improve things so he deserves much gratitude for that.

Now if you are trying hard to get the project running, just come here, or on the 'faceswap-playground' repo and request for help in a detailed manner with a description of your error so that we can give you a constructive answer that will also help later newcomers.

Thanks for your understanding",hi stated know programmer always easy user friendly project advanced really easy package improving usage project already easier use ca promise super easy solution also note project collaborative everyone coming consider done super python care end user also programmer tackled time time never python spent find way also spent many improve much gratitude trying hard get project running come request help detailed manner description error give constructive answer also help later thanks understanding,issue,positive,positive,positive,positive,positive,positive
353876200,"Well, you can say whateva you want to sounds like cry for help or blah blah blah, idc, what I care about is I am keen to lean this and I am trying my best to figure out the things.
If you can show me path to get it in working state, I will be glad and thankful else, still thanks for replying!
I just run the new files with the command mentioned in the readme.md. And it gave me th above mentioned error!",well say want like cry help blah blah blah care keen lean trying best figure show path get working state glad thankful else still thanks run new command gave th error,issue,positive,positive,positive,positive,positive,positive
353867507,"I just tested this, and am unable to reproduce your error. Please verify that you are running `faceswap.py` from the project directory, are specifying the correct arguments and that all the dependencies are installed in your environment.",tested unable reproduce error please verify running project directory correct environment,issue,negative,negative,negative,negative,negative,negative
353867471,"This sounds like a cry for help, rather than a coherent question. Would you like to rephrase your question? Perphaps specify the steps you've taken, and where you're experiencing issues?

We're working to improve our documentation, but it's really too early to have this work out of the box for new users. Batteries are NOT included.",like cry help rather coherent question would like rephrase question specify taken working improve documentation really early work box new included,issue,positive,positive,positive,positive,positive,positive
353860516,"It's mac book pro early 2015 model.
No I am not using any gpu yet. Once I get success using it on my mac, I will move it to powerful system.
I am just playing around with damn warning and error.",mac book pro early model yet get success mac move powerful system around damn warning error,issue,negative,positive,positive,positive,positive,positive
353860155,"> It takes around 50 minutes for 100 iteration on my system

By the way, what configuration do you use? Is it just MacBook Pro? Do you use GPU?",around iteration system way configuration use pro use,issue,negative,neutral,neutral,neutral,neutral,neutral
353858320,"Well, I already figured it out after posting it here. It takes around 50 minutes for 100 iteration on my system, thinking to move stuff to cloud.
Thanks for quick reply.",well already figured posting around iteration system thinking move stuff cloud thanks quick reply,issue,positive,positive,positive,positive,positive,positive
353847422,"Hello,

It is a problem I encountered also, and indeed, it should be fixed. Luckily, the model is saved every 100 epoch/iterations so you should find a model in your models folder.

Go there, copy your model somewhere safe, and then you will be able to kill the program without loosing anything ",hello problem also indeed fixed luckily model saved every find model folder go copy model somewhere safe able kill program without loosing anything,issue,negative,positive,positive,positive,positive,positive
353801488,"Please also update the README.md, there are instructions in old style (like `python train.py`)",please also update old style like python,issue,positive,positive,neutral,neutral,positive,positive
353788462,"Looks excellent so far. However, you seem to have forgotten the `scripts` package. 😅 ",excellent far however seem forgotten package,issue,negative,positive,positive,positive,positive,positive
353746967,"Yes and it is also heavy as hell....

I'm still investigating because if it used just for faces landmarks, `face_recognition` does it pretty well also...",yes also heavy hell still investigating used pretty well also,issue,negative,positive,neutral,neutral,positive,positive
353743446,"The face alignment script seems to rely on PyTorch, which is not fully supported on GPU for Windows users at this time. This could be blocking if we want it to be accessible and fast for non-tech users.",face alignment script rely fully time could blocking want accessible fast,issue,negative,positive,positive,positive,positive,positive
353735748,"Yes, you can achieve this easily using the subparser feature that comes as part of `argparse`. I was going to do this myself, but I may not have time today.",yes achieve easily feature come part going may time today,issue,positive,positive,positive,positive,positive,positive
353731991,"I am working on using one main script that calls the other.

The idea is to get commands like this `./faceswap.py train`, `./faceswap.py extract`, `./faceswap.py convert`.

I don't know if this is what you want though.",working one main script idea get like train extract convert know want though,issue,negative,positive,positive,positive,positive,positive
353731712,"@Yutsa I merged your PR with the error message. We can most likely also improve the behavior for handling non-existent input/output directories with some ""folder does not exist, create it? y/n"" dialogues.",error message likely also improve behavior handling folder exist create,issue,negative,neutral,neutral,neutral,neutral,neutral
353727022,"When I tried running the `convert.py` script I had the following error : 

`Failed to extract from image: /home/edouard/Téléchargements/faceswap-data/source-images/lawrence/107.jpg. Reason: Unable to open contrib/shape_predictor_68_face_landmarks.dat`

I had to look into the code to know what to do.

I guess we'll need a way to get this file without having to download it separatly if we want to make it user friendly. Or say explictily how and where to download it if it is missing when executing the script.",tried running script following error extract image reason unable open look code know guess need way get file without want make user friendly say missing script,issue,negative,negative,neutral,neutral,negative,negative
353715906,"If we could manage to create a program with different commands it would be way easier to use indeed.

Something like `faceswap extract`, `faceswap train` and `faceswap convert`",could manage create program different would way easier use indeed something like extract train convert,issue,positive,neutral,neutral,neutral,neutral,neutral
353715784,I read you commits and it looks great to me. Removing duplicate scripts was a great idea too.,read great removing duplicate great idea,issue,positive,positive,positive,positive,positive,positive
353692599,"I pushed also accidentally yesterday and I was not even drunk...

No problem, have a look tomorrow. Me I'll be on the way back to my family...",also accidentally yesterday even drunk problem look tomorrow way back family,issue,negative,negative,negative,negative,negative,negative
353692053,"Basic command line usage is almost ready. Can probably look into cooking up pre-built packages once that's done. I might look into some CI stuff to make semi-automated builds, but that might be goals to shoot for after christmas or start of 2018.",basic command line usage almost ready probably look cooking done might look stuff make might shoot start,issue,negative,positive,neutral,neutral,positive,positive
353691742,"Updated `train.py` and accidentally pushed results to upstream. I'm very drunk, so if someone could verify if the scripts are still working, please do so.

Now that all these scripts are using the same basic classes, we can probably consolidate them to a single file so they can be called from a single entrypoint. (like how `git` has several subcommands, faceswap.py could have `extract`, `train` and `convert` commands) That's my next objective, which I will be looking to tackle tomorrow. (after the hangover passes)",accidentally upstream drunk someone could verify still working please basic class probably consolidate single file single like git several could extract train convert next objective looking tackle tomorrow,issue,negative,negative,neutral,neutral,negative,negative
353691436,"I've pushed changes that allow for these arguments to be passed to the script. Please verify their correctness, I was very drunk while refactoring, so I'll probably hate it tomorrow morning.",allow script please verify correctness drunk probably hate tomorrow morning,issue,negative,negative,negative,negative,negative,negative
353675242,"A better merge function is also provided

https://gist.github.com/anonymous/8f468972d6286f403318c94bc6dbe382",better merge function also provided,issue,negative,positive,positive,positive,positive,positive
353669180,"I'm currently working on face alignment, the lib is to be built manually. 

Please ensure Python3 does not block the install of the lib

Also note it requires `dlib==19.5.0`, maybe we should also stick to that one if we integrate face-alignment in the project.

Don't hesitate to discuss this before starting...",currently working face alignment built manually please ensure python block install also note maybe also stick one integrate project hesitate discus starting,issue,negative,neutral,neutral,neutral,neutral,neutral
353647812,"If you want to take care of this, please try also to remove useless dependencies as much as possible ;-)",want take care please try also remove useless much possible,issue,negative,negative,negative,negative,negative,negative
353620699,"Several changes were because I modified a older/modified version of the script.

Since you want to use `argparse`, I could either implement it using the right version of the script or you could reject the PR and do it like you did for the other ones.

Thanks for the review",several version script since want use could either implement right version script could reject like thanks review,issue,negative,positive,positive,positive,positive,positive
353619094,"Other than that, this is indeed useful functionality. Once we get the command line functionality working, we have a really good basis that is already more friendly to use and might actually start distributing as a package.",indeed useful functionality get command line functionality working really good basis already friendly use might actually start package,issue,positive,positive,positive,positive,positive,positive
353613248,"Hi, thanks for your pull request. I will be reviewing it shortly.",hi thanks pull request shortly,issue,negative,positive,neutral,neutral,positive,positive
353610441,@clor would love to but I can't nowadays. coming months I will be helping other issues and features though,would love ca nowadays coming helping though,issue,positive,positive,positive,positive,positive,positive
353604954,"I removed the keras image dependency, so it means a clearer view for newcomers on how to setup a machine from scratch.

Migrating it to a full Python3 setup would be even better. I'll try this later on....",removed image dependency clearer view setup machine scratch full python setup would even better try later,issue,negative,positive,positive,positive,positive,positive
353604549,"I pushed a first draft on my repo, inside the `align` folder, it is the GIST code reworked to separate program logic from processing logic.

It is not intended to work, but if you want to work on it, please start from there.

CC @Ganonmaster ",first draft inside align folder gist code reworked separate program logic logic intended work want work please start,issue,negative,positive,positive,positive,positive,positive
353590881,"Btw, note that face recognition seems to be better with the `face_recognition` module integrated here. So the `dlib.get_frontal_face_detector()` should be replaced where relevant",note face recognition better module relevant,issue,negative,positive,positive,positive,positive,positive
353590453,"Yes, I have seen that and it looks promising. Do you want to take a look at it ?

There is also a Gist with a sample:
https://gist.github.com/anonymous/5832a6fffb8309ac851a29874c3dbb7b",yes seen promising want take look also gist sample,issue,positive,positive,positive,positive,positive,positive
353566585,"I'm giving up for now, opencv-python seems not to have video support, and the full opencv lib is a pain to build....

I'll try to handle sequences of photos instead (video will just be a sequence of frames so it will adapt easily to videos)",giving video support full pain build try handle instead video sequence adapt easily,issue,negative,positive,positive,positive,positive,positive
353552978,"Hi,

**Short answer**
(I assume you have all dependencies [installed](https://github.com/deepfakes/faceswap-playground/issues/6))
Put the sample data (`data ` + `models`) in the same folder as the code. 
Create a `output` folder
Run `convert_trump_cage.py`, and _voila!_
The converted photos will be in the output folder

I put a more complete HowTo [here](https://github.com/deepfakes/faceswap-playground/issues/5)",hi short answer assume put sample data data folder code create output folder run converted output folder put complete,issue,negative,positive,neutral,neutral,positive,positive
353543504,Could you please describe the problem you are encountering in more detail? What training data? What are you trying to accomplish? What have you tried?,could please describe problem detail training data trying accomplish tried,issue,negative,neutral,neutral,neutral,neutral,neutral
353282645,"As I see on your video, there are also little glitches due to the face generator that may generate different faces for 2 consecutive frames. I don't see a clear solution here for now. ",see video also little due face generator may generate different consecutive see clear solution,issue,positive,negative,neutral,neutral,negative,negative
353281183,"For now, I have an issue with input video reading. It seems python-opencv has no video decoder so I had to compile the full version...",issue input video reading video compile full version,issue,negative,positive,positive,positive,positive,positive
353280933,"Indeed this a common issue. Face detection is often blocked by compression artifacts. It is the case in still pics and is even more present in videos.

I don't think there is a built in interpolation, but you can try doing it manually. While parsing frames, just keep a track of 1 or 2 previous frames and if current frame has nothing detected, do a 'mean' with previous data.

Other possibility is to keep the result of the last detection, and keep frames without faces until you detect another face. If the new face is close to the last, apply the new detection (or the old, or an interpolation) to the buffered frames. (Don't forget to give a max size to your buffer and flush it if no new face has been detected for x frames)

I'll try to tackle that later on...",indeed common issue face detection often blocked compression case still even present think built interpolation try manually keep track previous current frame nothing previous data possibility keep result last detection keep without detect another face new face close last apply new detection old interpolation forget give size buffer flush new face try tackle later,issue,negative,negative,neutral,neutral,negative,negative
353197758,`extract.py` now has basic command line options for specifying paths and verbose output. I'm going to be looking at `convert.py` next.,basic command line verbose output going looking next,issue,negative,neutral,neutral,neutral,neutral,neutral
353171866,I'll make a new merge request with my changes. This is kind of a mess.,make new merge request kind mess,issue,negative,positive,positive,positive,positive,positive
353112008,"Does OpenCV make it possible to interpolate face positions between frames? I've had several instances where I've tried to convert a series of frames, but it fails to detect faces in a few frames in between; causing[ a glitching effect where the target face turns on and off](https://gfycat.com/GrandVengefulGalapagossealion). (link semi-nsfw)",make possible interpolate face several tried convert series detect causing effect target face turn link,issue,negative,neutral,neutral,neutral,neutral,neutral
353084213,Also if it possible to make the Dockerfile not depend on the keras image it would be better. Perhaps it should be based on some debian (or any other distribution)...,also possible make depend image would better perhaps based distribution,issue,negative,positive,positive,positive,positive,positive
353078925,"I was wondering how to update my repo before being able to continue working on it...
These pages have helped:
- https://help.github.com/articles/configuring-a-remote-for-a-fork/
- https://help.github.com/articles/syncing-a-fork/",wondering update able continue working,issue,negative,positive,positive,positive,positive,positive
353053379,"""ages"" means that it takes a very long time.
It is an old iMac 2009, so I don't really try to train a model on it. It is just to assess it works...

On the minimal requirements, feel free to share your experience in the faceswap-playground repo. There is no easy way to tell you that this or this platform is eligible or not for training or converting. The only way we have to know that is through the users feedback. 

After, if you want to crawl docs of the tools to gather minimal requirements of each tool, feel free, it is up to you.",long time old really try train model ass work minimal feel free share experience easy way tell platform eligible training converting way know feedback want crawl gather minimal tool feel free,issue,positive,positive,positive,positive,positive,positive
353045713,"@deepfakes it was in the first minute. After closing other programs, now it runs, and updates the h5 files.
The process has some 5.2GB peaks, using Python 3.6 x64 on a Windows 7 machine.

What do you mean by ages ?
If I install the GPU version of tensorflow, I'll need at least 5.2GB of VRAM ? Or it uses mainly RAM ?

It would be nice to define the ""minimal requirements"" ... but I guess it depeds on the number of pictures.",first minute process python machine mean install version need least mainly ram would nice define minimal guess number,issue,negative,positive,neutral,neutral,positive,positive
353038478,"I would propose to keep the different ""actions"" or steps in their current files (`train.py`, `convert.py`, `extract.py`) and then allow for model data directory names to be used as input/output arguments. Example:

`train.py --data-dirs=""./data/trump;/data/cage"" --model-dir=""./models/trump-cage/""`",would propose keep different current allow model data directory used example,issue,negative,neutral,neutral,neutral,neutral,neutral
353026873,Looks like I don't have collab rights on that repo. I can't attach labels there. I will look into uploading the data files and possibly some (poorly) trained models as well.,like ca attach look data possibly poorly trained well,issue,positive,negative,negative,negative,negative,negative
353024267,"I can start running the train.py on my old iMac with 4Gb, from within a Docker-machine. I never trained fully the model as it takes ages, but at least it starts.

When is your training failing ? At start ? After a while ?",start running old within never trained fully model least training failing start,issue,negative,negative,neutral,neutral,negative,negative
353024197,"@Ganonmaster Ok, perfect, so no need for huge ammounts of memory :)",perfect need huge memory,issue,positive,positive,positive,positive,positive,positive
353023868,@cercata I tested it on a laptop with 16GB of RAM inside a docker container; it used up roughly 4-6GB. Your mileage may vary.,tested ram inside docker container used roughly mileage may vary,issue,negative,negative,neutral,neutral,negative,negative
353021417,"Also if you have ideas for a better folder structure, feel free to suggest!",also better folder structure feel free suggest,issue,positive,positive,positive,positive,positive,positive
353021078,"I'm closing this. If you still have problem, please submit them on the ""faceswap-playground"" repo",still problem please submit,issue,negative,neutral,neutral,neutral,neutral,neutral
353020896,"I added a first draft in order to apply the generated faces warped with Dlib landmarks. It sometimes gives better results, but it can be improved...

Note: In order to use it, you will have to DL the landmarks file from Dlib
http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2

![505546486](https://user-images.githubusercontent.com/34667098/34201737-c18a30e4-e575-11e7-9fa9-3fd89bf35951.jpg)

![831982426](https://user-images.githubusercontent.com/34667098/34201739-c19cd064-e575-11e7-9e66-c2b013c54e97.jpg)
",added first draft order apply warped sometimes better note order use file,issue,negative,positive,positive,positive,positive,positive
353019792,"@Ganonmaster I'll close this issue as it has become a bit messy. Also I created a 'faceswap-playground' repo so that end users can submit issues without cluttering this repo. Can you open an issue there with the 'data' label and put your link in it?

Also, are you ok to gather large files like the models, the dat files like shape_predictor_68_face_landmarks.dat and host them on your server ?",close issue become bit messy also end submit without open issue label put link also gather large like like host server,issue,negative,positive,neutral,neutral,positive,positive
353008733,"Hi @Ganonmaster ,

I had to rebase the whole repo because my pro credentials where appearing in some commits. You will have to rebase on the whole history on your side. 

Hopefully, it shouldn't be a big deal, but I had conflicts on Dockerfile, so maybe you will have it too...

Sorry for that",hi rebase whole pro rebase whole history side hopefully big deal maybe sorry,issue,negative,negative,neutral,neutral,negative,negative
352908999,"Oh sorry, I see that you can have an archive of one folder. My bad! Your server is perfect!",oh sorry see archive one folder bad server perfect,issue,negative,negative,neutral,neutral,negative,negative
352908644,"Yes, I saw that and its important to keep faces folder separated. I was just proposing to have a trump.zip, a cage.zip, and so on. So anyone interested for one specific person will be able to grab the person he wants conveniently. But nevermind, it's not a big deal...",yes saw important keep folder anyone interested one specific person able grab person conveniently big deal,issue,positive,positive,positive,positive,positive,positive
352901772,"The link I provided contains several folders, you should be able to download them individually like so: [link removed]",link provided several able individually like link removed,issue,negative,positive,positive,positive,positive,positive
352895385,"Thanks for that, just a little remark: please split your packages as it can grow up fast, and it will make it easier to pick what we want most.

I did not check the data yet, but AFAIK, alignment shouldn't be a problem as photos are warped before being injected into the autoencoder. 

On the size part, faces are reduced to 64x64 before injected into the trainer (but this is one reason why generated faces are so blurry, and this should be improved)",thanks little remark please split grow fast make easier pick want check data yet alignment problem warped size part reduced trainer one reason blurry,issue,positive,positive,neutral,neutral,positive,positive
352894284,"You most likely ran out of memory. Your computer has 8GB of RAM and at its peak used 9.8GB. Which means it was most likely writing to the swap space on your hard disk. When your PC runs out of RAM space to write to, it will write to and read to a designated ""swap"" space on your hard drive as if it were part of your memory. This is to prevent your PC from crashing.

You need more than 8GB, because your OS and other apps will also use part of your memory. But 16GB will probably be fine. Just be aware that running it on CPU will most likely be 10 times slower than running it on a GPU. So even if you have the RAM, but not a top of the line CPU or a compatible Nvidia GPU, training will take a long time.",likely ran memory computer ram peak used likely writing swap space hard disk ram space write write read swap space hard drive part memory prevent need o also use part memory probably fine aware running likely time running even ram top line compatible training take long time,issue,negative,positive,neutral,neutral,positive,positive
352893774,"This may be specific to your setup. Please tell us what env are you running on. Do you use Docker ? Docker-machine ?

Also, for standard errors, a little Google search can help. [This page](https://github.com/tensorflow/tensorflow/issues/136) for example has a couple of reasons/solutions. ",may specific setup please tell u running use docker also standard little search help page example couple,issue,positive,negative,neutral,neutral,negative,negative
352867484,"[Here is a folder containing the cage and trump faces, as well as a few faces I've gathered.] [link removed]

My pics are much lower quality than the ones provided by deepfakes and are not aligned properly, but they might be useful if cleaned, aligned and trained.",folder cage trump well link removed much lower quality provided properly might useful trained,issue,negative,positive,positive,positive,positive,positive
352818967,"Here we go!

You should have received an invite.

You'll be able to push, and hopefully to merge Pull Requests.",go received invite able push hopefully merge pull,issue,positive,positive,positive,positive,positive,positive
352815908,"Yes, I would like to add more usability improvements this week.",yes would like add usability week,issue,positive,neutral,neutral,neutral,neutral,neutral
352814254,"Works fine, thanks!

Do you want to be added as collaborator ?",work fine thanks want added collaborator,issue,positive,positive,positive,positive,positive,positive
352806944,I would recommend using separate `requirement.txt` files for Python dependencies. This keeps the dependencies in sync for people who prefer not to use Docker and those who do.,would recommend separate python sync people prefer use docker,issue,negative,neutral,neutral,neutral,neutral,neutral
352806790,"Hi, thanks for the PR!

It seems the last line of the Dockerfile is a result of a conflict. 

Can you clean it and test on you side ?

I'll happily merge after that!",hi thanks last line result conflict clean test side happily merge,issue,positive,positive,positive,positive,positive,positive
352789935,"In theory an installation like that works, but for development, you ideally you want it in some kind of separate environment. Virtualenv or something, so it does not conflict with any local packages you may already have installed.

Packaging is not necessary immediatelly, but I can imagine having prebuilt executables of a command line version is already a great improvement. It allows other devs to setup simple frontends that interface with the command-line tool. Having a pre-built command-line tool is a great step towards coupling it with both web and native frontends.",theory installation like work development ideally want kind separate environment something conflict local may already necessary imagine command line version already great improvement setup simple interface tool tool great step towards coupling web native,issue,positive,positive,positive,positive,positive,positive
352780421,"It's quite easy making the installation on windows x64, for CPU based processing:

- Install python 3.6 x64 from: https://www.python.org/ftp/python/3.6.4/python-3.6.4-amd64.exe
- And then, from a command line with supervisor permisions, the following commands:

- [ ]  pip3 install --upgrade tensorflow
- [ ]  pip3 install h5py
- [ ]  pip3 install keras
- [ ]  pip3 install opencv-python

Until some GUI is added, I don't think it's worth packaging it ...


",quite easy making installation based install python command line supervisor following pip install upgrade pip install pip install pip install added think worth,issue,positive,positive,positive,positive,positive,positive
352753142,"I would see separate GPU and CPU versions for each target OS.

What I wonder, is how the process would look for the end user. Seeing as the training portion takes the most time, you could initially start by providing the basic ""image processor"" to the user, and have more advanced users share their models in ready made archives. I'm unfamiliar with the format, so I'm not sure if that opens it up to some kind of security issue. However, I feel like that could be an easy way of simplifying the process for non-technical people. Your video/picture + a pre-made swappable model = easy result.",would see separate target o wonder process would look end user seeing training portion time could initially start providing basic image processor user advanced share ready made unfamiliar format sure kind security issue however feel like could easy way process people model easy result,issue,positive,positive,positive,positive,positive,positive
