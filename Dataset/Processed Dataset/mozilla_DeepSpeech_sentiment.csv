id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1969050126,"> Hello, I would like to use pre-trained Mandarin Chinese deepspeech models to extract audio features. However I did not find a way to load .pbmm file. When I tried to load checkpoint, I also encountered with a cudnn_lstm bug. So may I get the pretrained .pb file(only academic purpose)? My email is [20120346@bjtu.edu.cn](mailto:20120346@bjtu.edu.cn), thank you very much!

请问老铁是否找到了中文的.pb模型",hello would like use mandarin extract audio however find way load file tried load also bug may get file academic purpose thank much,issue,positive,positive,neutral,neutral,positive,positive
1918642062,"Please avoid posting screenshot for CLI, it's impossible to work with.

Sadly, `curl` in PowerShell is not `curl` so please adapt parameters.

Your `pip` failing is just because this is either a version we did not publish wheel for, or the ABI is incompatible (we only supported official Python builds).

Plus, project is unmaintained for years.",please avoid posting impossible work sadly curl curl please adapt pip failing either version publish wheel incompatible official python plus project unmaintained,issue,negative,negative,negative,negative,negative,negative
1918636527,"You can but project is unmaintained, CI is most probably broken, and I dont have time for reviews.",project unmaintained probably broken dont time,issue,negative,negative,negative,negative,negative,negative
1872232637,Project is unmaintained best advice was given and is to rebuild,project unmaintained best advice given rebuild,issue,positive,positive,positive,positive,positive,positive
1872232476,Msys2 python likely is incompatible we only built and guaranteed against official python builds. Please rebuild and don't directly install the wheel it might fail in weird ways,python likely incompatible built official python please rebuild directly install wheel might fail weird way,issue,negative,negative,negative,negative,negative,negative
1872087024,"> I have python 3.9. I still got this [image: image.png]
> […](#)
> On Fri, Dec 29, 2023 at 2:19 AM Butui Hu ***@***.***> wrote: oh, it's a typo, I mean you need python 3.9. The latest python release this pkg support is python 3.9. For newer python release, you need to build deepspeech from the source, see also here <https://deepspeech.readthedocs.io/en/r0.9/BUILDING.html>. — Reply to this email directly, view it on GitHub <[#3784 (comment)](https://github.com/mozilla/DeepSpeech/issues/3784#issuecomment-1871659644)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AMSQ2BFVBUH55SF76IEWQ33YLYLDXAVCNFSM6AAAAABBDGF5B2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQNZRGY2TSNRUGQ> . You are receiving this because you authored the thread.Message ID: ***@***.***>

![image](https://github.com/mozilla/DeepSpeech/assets/52759812/22687528-b46c-4c03-87b7-949bfd58f1cb)
",python still got image wrote oh typo mean need python latest python release support python python release need build source see also reply directly view comment id image,issue,negative,positive,neutral,neutral,positive,positive
1871983397,"I have python 3.9. I still got this
[image: image.png]

On Fri, Dec 29, 2023 at 2:19 AM Butui Hu ***@***.***> wrote:

> oh, it's a typo, I mean you need python 3.9. The latest python release
> this pkg support is python 3.9. For newer python release, you need to build
> deepspeech from the source, see also here
> <https://deepspeech.readthedocs.io/en/r0.9/BUILDING.html>.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3784#issuecomment-1871659644>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMSQ2BFVBUH55SF76IEWQ33YLYLDXAVCNFSM6AAAAABBDGF5B2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQNZRGY2TSNRUGQ>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",python still got image wrote oh typo mean need python latest python release support python python release need build source see also reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1871659644,"oh, it's a typo, I mean you need python 3.9. The latest python release this pkg support is python 3.9. For newer python release, you need to build deepspeech from the source, see also [here](https://deepspeech.readthedocs.io/en/r0.9/BUILDING.html).",oh typo mean need python latest python release support python python release need build source see also,issue,negative,positive,neutral,neutral,positive,positive
1870923329,"Do you mean pip install deep speech will work if I have python V10?

On Thu, Dec 28, 2023, 08:15 Butui Hu ***@***.***> wrote:

> According to deepspeech <https://pypi.org/project/deepspeech/#files> and
> deepspeech-gpu <https://pypi.org/project/deepspeech-gpu/#files>, you need
> python 3.10. for GPU support, cuda 10.1 is needed. You could get cuda 10.1
> docker from nvidia ngc
> <https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda/tags>.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3784#issuecomment-1870890295>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMSQ2BAE2OGXXHVRYSRADFDYLUMCVAVCNFSM6AAAAABBDGF5B2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTQNZQHA4TAMRZGU>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",mean pip install deep speech work python wrote according need python support could get docker reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1870890295,"According to [deepspeech](https://pypi.org/project/deepspeech/#files) and [deepspeech-gpu](https://pypi.org/project/deepspeech-gpu/#files), you need python 3.9. for GPU support, cuda 10.1 is needed. You could get cuda 10.1 docker from [nvidia ngc](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda/tags).",according need python support could get docker,issue,negative,neutral,neutral,neutral,neutral,neutral
1869546214,"@ListenQ 

python <= 3.8


or better yet, try openai/whisper",python better yet try,issue,negative,positive,positive,positive,positive,positive
1869317575,"> what is happening with the Repo? can't even install deepspeech library.

no wheel at python 3.10......sad",happening ca even install library wheel python sad,issue,negative,negative,negative,negative,negative,negative
1868770944,"> Unsupported version of python, there's no fix unless you want to take on maintenance.

Which python version is supported?",unsupported version python fix unless want take maintenance python version,issue,negative,neutral,neutral,neutral,neutral,neutral
1866322991,"Unsupported version of python, there's no fix unless you want to take on maintenance.",unsupported version python fix unless want take maintenance,issue,negative,neutral,neutral,neutral,neutral,neutral
1849064425,"Has anyone got anywhere with this, or got any resources to share? I’m considering looking in to it but if work has already been done then I can start from there.

obviously training on apple silicon hardware is out of the question. Considering that deepspeech is still a viable solution to many small domain specific projects with limited  budget, adding support for inference on apple silicon is something that would be worth working on. 

",anyone got anywhere got share considering looking work already done start obviously training apple silicon hardware question considering still viable solution many small domain specific limited budget support inference apple silicon something would worth working,issue,positive,positive,neutral,neutral,positive,positive
1842059135,"To analyze syllables or phonemes alongside DeepSpeech, consider integrating with libraries like NLTK or PyDictionary in Python. These libraries provide syllable information and phonetic details, complementing DeepSpeech's text-to-speech conversion. By combining these tools, you can create a comprehensive solution for a more in-depth linguistic analysis of spoken words.",analyze alongside consider like python provide syllable information phonetic conversion combining create comprehensive solution linguistic analysis spoken,issue,positive,positive,neutral,neutral,positive,positive
1842058409,"DeepSpeech, developed by Mozilla, excels in converting spoken words to text but doesn't provide syllable or phoneme-level details. For such linguistic features, consider using specialized libraries like NLTK in Python or PyDictionary, which offer syllable information. These can be integrated to analyze syllables or phonemes alongside DeepSpeech for a comprehensive solution.",converting spoken text provide syllable linguistic consider specialized like python offer syllable information analyze alongside comprehensive solution,issue,positive,positive,neutral,neutral,positive,positive
1807212906,"> You'd need to get back CI working again because it is likely broken since this time. Then adding support for new versions of python like e.g.,
> 
> https://github.com/mozilla/DeepSpeech/blob/aa1d28530d531d0d92289bf5f11a49fe516fdc86/.github/workflows/build-and-test.yml#L313
> 
> (but there are many other places to update)

Does this mean that I shoud be able to pip install deepspeech if my python version is between  versions 3,6 and 3,9? Becouse I tried to install it with version 3,7 and it still was not possible",need get back working likely broken since time support new python like many update mean able pip install python version tried install version still possible,issue,negative,positive,neutral,neutral,positive,positive
1798363326,"what is happening with the Repo? can't even install deepspeech library.
",happening ca even install library,issue,negative,neutral,neutral,neutral,neutral,neutral
1738250660,"KenLM doesn't seem to have a bin2arpa tool



---- Replied Message ----
| From | Aadarsh ***@***.***> |
| Date | 09/28/2023 02:49 |
| To | ***@***.***> |
| Cc | ***@***.***>***@***.***> |
| Subject | Re: [mozilla/DeepSpeech] how to convert LM's binary model to arpa file (Issue #3777) |

Well it may involves several steps, and the exact process may vary depending on the specific LM format and tools you have available.
Although I can try give u a general guideline for converting a binary LM to an ARPA file:

Identify the Binary LM Format. Different tools and frameworks may use different binary formats, and the conversion process may vary accordingly. Install Required Software. Common tools for language modeling include SRILM and KenLM.

If your binary LM is in the SRILM format, you can use SRILM's utilities to convert it to ARPA. Here's an example command:

ngram -lm binary_lm_file -order N -ppl test_corpus.txt

Replace binary_lm_file with the path to your binary LM file and N with the LM order test_corpus.txt should be replaced with the path to a text corpus that will be used to generate the ARPA file. The -ppl flag is used to specify that you want to compute perplexity, which will also create the ARPA file.

Note that - If your binary LM is in the KenLM format, you can use KenLM's bin2arpa tool to convert it to ARPA:

bin2arpa binary_lm_file > arpa_lm_file.arpa
Replace binary_lm_file with the path to your binary LM file, and arpa_lm_file.arpa with the desired name for the resulting ARPA file.

Depending on your specific use case, you may need to perform additional preprocessing on the ARPA file, such as removing certain entries or adjusting probabilities.

Keep in mind that the exact steps and tools may vary depending on the binary LM format and the toolkit used. Make sure to refer to the documentation of the specific toolkit you are working with for detailed instructions.

Hope it helps!

—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***>",seem tool message date subject convert binary model file issue well may several exact process may vary depending specific format available although try give general guideline converting binary file identify binary format different may use different binary conversion process may vary accordingly install common language modeling include binary format use convert example command replace path binary file order path text corpus used generate file flag used specify want compute perplexity also create file note binary format use tool convert replace path binary file desired name resulting file depending specific use case may need perform additional file removing certain keep mind exact may vary depending binary format used make sure refer documentation specific working detailed hope reply directly view id,issue,positive,positive,positive,positive,positive,positive
1737912924,"Well it may involves several steps, and the exact process may vary depending on the specific LM format and tools you have available. 
Although I can try give u a general guideline for converting a binary LM to an ARPA file:

Identify the Binary LM Format. Different tools and frameworks may use different binary formats, and the conversion process may vary accordingly. Install Required Software. Common tools for language modeling include SRILM and KenLM.

If your binary LM is in the SRILM format, you can use SRILM's utilities to convert it to ARPA. Here's an example command:

`ngram -lm binary_lm_file -order N -ppl test_corpus.txt`

Replace binary_lm_file with the path to your binary LM file and N with the LM order test_corpus.txt should be replaced with the path to a text corpus that will be used to generate the ARPA file. The -ppl flag is used to specify that you want to compute perplexity, which will also create the ARPA file.

Note that - If your binary LM is in the KenLM format, you can use KenLM's bin2arpa tool to convert it to ARPA:

`bin2arpa binary_lm_file > arpa_lm_file.arpa`
Replace binary_lm_file with the path to your binary LM file, and arpa_lm_file.arpa with the desired name for the resulting ARPA file.

Depending on your specific use case, you may need to perform additional preprocessing on the ARPA file, such as removing certain entries or adjusting probabilities.

Keep in mind that the exact steps and tools may vary depending on the binary LM format and the toolkit used. Make sure to refer to the documentation of the specific toolkit you are working with for detailed instructions.

Hope it helps!",well may several exact process may vary depending specific format available although try give general guideline converting binary file identify binary format different may use different binary conversion process may vary accordingly install common language modeling include binary format use convert example command replace path binary file order path text corpus used generate file flag used specify want compute perplexity also create file note binary format use tool convert replace path binary file desired name resulting file depending specific use case may need perform additional file removing certain keep mind exact may vary depending binary format used make sure refer documentation specific working detailed hope,issue,positive,positive,positive,positive,positive,positive
1690429895,"Unfortunately, you need to know how to hack GitHub Actions to dive into this yaml file, and the build process involves building tensorflow,combined with the limitations from GitHub Actions, it ends up being non trivial. If you'd like to hack around, I'd suggest to learn GitHub Actions first.",unfortunately need know hack dive file build process building combined non trivial like hack around suggest learn first,issue,negative,negative,negative,negative,negative,negative
1690319171,"> You'd need to get back CI working again because it is likely broken since this time. Then adding support for new versions of python like e.g.,
> 
> https://github.com/mozilla/DeepSpeech/blob/aa1d28530d531d0d92289bf5f11a49fe516fdc86/.github/workflows/build-and-test.yml#L313
> 
> (but there are many other places to update)

this the yaml file for the CI? what commands do you run to test this? 

Sorry to ask just assume that I am new and a idiot right now ",need get back working likely broken since time support new python like many update file run test sorry ask assume new idiot right,issue,negative,negative,neutral,neutral,negative,negative
1690310846,"You'd need to get back CI working again because it is likely broken since this time. Then adding support for new versions of python like e.g., https://github.com/mozilla/DeepSpeech/blob/aa1d28530d531d0d92289bf5f11a49fe516fdc86/.github/workflows/build-and-test.yml#L313 (but there are many other places to update)",need get back working likely broken since time support new python like many update,issue,negative,positive,neutral,neutral,positive,positive
1690307501,"> > > Project is unmaintained and thus no wheel built and updated for newer versions of Python.
> > 
> > 
> > @lissyx can we contribute? or update to newer versions of python or branch off for update? the projects claims open-source?
> 
> Of course, we moved away from TaskCluster to GitHub Actions for that purpose back in 2021, but nobody showed interest in getting more into the project while we were available to help and mentor. Given the long time, it's possible a lot of broken, but if you come up with fixes I will obviously review.

Awesome so for this issue would I need to upgrade to a version of python that deepspeech doesn't run on and update the code that is breaking? to fix this issue? then Merge a PR?",project unmaintained thus wheel built python contribute update python branch update course away purpose back nobody interest getting project available help mentor given long time possible lot broken come obviously review awesome issue would need upgrade version python run update code breaking fix issue merge,issue,positive,positive,positive,positive,positive,positive
1690288969,"> > Project is unmaintained and thus no wheel built and updated for newer versions of Python.
> 
> @lissyx can we contribute? or update to newer versions of python or branch off for update? the projects claims open-source?

Of course, we moved away from TaskCluster to GitHub Actions for that purpose back in 2021, but nobody showed interest in getting more into the project while we were available to help and mentor. Given the long time, it's possible a lot of broken, but if you come up with fixes I will obviously review.",project unmaintained thus wheel built python contribute update python branch update course away purpose back nobody interest getting project available help mentor given long time possible lot broken come obviously review,issue,negative,negative,neutral,neutral,negative,negative
1690266064,"> Project is unmaintained and thus no wheel built and updated for newer versions of Python.

@lissyx can we contribute? or update to newer versions of python or branch off for update? the projects claims open-source? ",project unmaintained thus wheel built python contribute update python branch update,issue,negative,neutral,neutral,neutral,neutral,neutral
1690192541,"@lissyx Fair enough. I'm trying to share my perspective as an outsider. GitHub marks you as a collaborator, who apparently has the ability to close GitHub issues. Do you also have the ability to edit the README.md file? Could you help me understand why this issue was closed as ""completed"", but there are still 114 issues that are still open? Why not close those as ""completed"" too?",fair enough trying share perspective outsider collaborator apparently ability close also ability edit file could help understand issue closed still still open close,issue,positive,positive,positive,positive,positive,positive
1690111014,"@lissyx  Do you have access to this repository? Could you mark this repos as unmaintained in the `README.md` , or archive the GitHub repo? There is no indication anywhere that this project is officially unmaintained. It doesn't feel right to close valid issues as ""completed"" when they are not fixed.",access repository could mark unmaintained archive indication anywhere project officially unmaintained feel right close valid fixed,issue,negative,positive,positive,positive,positive,positive
1689936750,Project is unmaintained and thus no wheel built and updated for newer versions of Python.,project unmaintained thus wheel built python,issue,negative,neutral,neutral,neutral,neutral,neutral
1689924174,"I also get this error on Ubuntu 23.04:

```console
$ pip install deepspeech
ERROR: Could not find a version that satisfies the requirement deepspeech (from versions: none)
ERROR: No matching distribution found for deepspeech
```

The Python version is 3.11.4",also get error console pip install error could find version requirement none error matching distribution found python version,issue,negative,neutral,neutral,neutral,neutral,neutral
1679887379,@rajib-raiyat The [DeepSpeech Playbook](https://mozilla.github.io/deepspeech-playbook/) has been produced to assist you with training a model on other languages. ,playbook produced assist training model,issue,negative,neutral,neutral,neutral,neutral,neutral
1634859145,"Same here I tried install deepspeech in docker deployment on google cloud but I am sure if the python version matters etc

Status: Downloaded newer image for python:3.11-slim
 ---> be2470db10f7
Step 2/10 : ENV PYTHONUNBUFFERED True
 ---> Running in a280f0c6f72c
Removing intermediate container a280f0c6f72c
 ---> 67f6a22d9077
Step 3/10 : ENV APP_HOME /back-end
 ---> Running in dac66b099f39
Removing intermediate container dac66b099f39
 ---> 40ce01092bbb
Step 4/10 : WORKDIR $APP_HOME
 ---> Running in 280bd9da0927
Removing intermediate container 280bd9da0927
 ---> 36a519dc5411
Step 5/10 : COPY . ./
Step 6/10 : RUN pip3 install --verbose deepspeech
Using pip 23.1.2 from /usr/local/lib/python3.11/site-packages/pip (python 3.11)
ERROR: Could not find a version that satisfies the requirement deepspeech (from versions: none)
ERROR: No matching distribution found for deepspeech
The command '/bin/sh -c pip3 install --verbose deepspeech' returned a non-zero code: 1
ERROR
ERROR: build step 0 ""gcr.io/cloud-builders/docker"" failed: step exited with non-zero status: 1
",tried install docker deployment cloud sure python version status image python step true running removing intermediate container fad step running removing intermediate container step running removing intermediate container step copy step run pip install verbose pip python error could find version requirement none error matching distribution found command pip install verbose returned code error error build step step status,issue,negative,positive,positive,positive,positive,positive
1617571153,"Hey Komol Kunty Rajib, you can do this by making the training model consume  the Bangla dataset with audio and tex mapping to the model. Now create a superset model where it takes audio to text API to convert and take the audio and make clear text input to model and since model has trained on your data set it will provide the value mapping of the provided text key and easily retrieve the translation text. ",hey making training model consume audio model create model audio text convert take audio make clear text input model since model trained data set provide value provided text key easily retrieve translation text,issue,positive,positive,positive,positive,positive,positive
1558728010,"> > > Please direct your anger against the right people.
> > 
> > 
> > It's not anger, it's sorrow if anything. Also, since the DeepSpeech isn't mantained anymore, some of it is also related to this project.
> 
> Taking over someone else's code is hard. Taking over lots of other people's code is second to impossible (at least very hard). For this reason, I guess this is the main reason why nothing happened.

Yes, we know that, this is why we constantly welcomed contributors and did everything we could to make it easier. The discourse thead on GitHub Actions has had 1 reply for 1300 reads.

I'm sorry but at some point, if there's so much interest, it should be possible to get a few people interested enough to **start** contributing. Nobody talks about owning the whole codebase from day 1.

> The number of comments in both forums (DeepSpeech and Coqui STT) show that there is a market. I would gladly pay a reasonable price for a working product - however a pay-per-usage, which is then a direct competitor to Google/Bing/Amazon, but with higher prices and more bugs, it won't happen for both economical and quality reasons.

A business model is complicated, but the fact that Coqui pivoted away from STT shows that maybe there is not such an interesting market. I can't speak for them, but it's my reading of the events.

> 
> In my own little project, it just can't make any budget hold if I had to pay per transcription - so local hosting is the only solution. My guess is that a lot of other people's projects share the same challenge.

Which is one of the motivation for DeepSpeech at first.

Now, the sad truth is here: nobody cares enough to have spent a little time to try and continue the project. That's sad, but that's it.",please direct anger right people anger sorrow anything also since also related project taking someone else code hard taking lot people code second impossible least hard reason guess main reason nothing yes know constantly everything could make easier discourse reply sorry point much interest possible get people interested enough start nobody whole day number show market would gladly pay reasonable price working product however direct competitor higher wo happen economical quality business model complicated fact away maybe interesting market ca speak reading little project ca make budget hold pay per transcription local hosting solution guess lot people share challenge one motivation first sad truth nobody enough spent little time try continue project sad,issue,negative,negative,neutral,neutral,negative,negative
1558721434,"> > Please direct your anger against the right people.
> 
> It's not anger, it's sorrow if anything. Also, since the DeepSpeech isn't mantained anymore, some of it is also related to this project.

Taking over someone else's code is hard. Taking over lots of other people's code is second to impossible (at least very hard). For this reason, I guess this is the main reason why nothing happened. The number of comments in both forums (DeepSpeech and Coqui STT) show that there is a market. I would gladly pay a reasonable price for a working product - however a pay-per-usage (cloud / hosted solution), which is then a direct competitor to Google/Bing/Amazon, but with higher prices and more bugs, it won't happen for both economical and quality reasons.

In my own little project, it just can't make any budget hold if I had to pay per transcription - so local hosting is the only solution. My guess is that a lot of other people's projects share the same challenge.",please direct anger right people anger sorrow anything also since also related project taking someone else code hard taking lot people code second impossible least hard reason guess main reason nothing number show market would gladly pay reasonable price working product however cloud solution direct competitor higher wo happen economical quality little project ca make budget hold pay per transcription local hosting solution guess lot people share challenge,issue,negative,negative,neutral,neutral,negative,negative
1558711694,"> Please direct your anger against the right people.

It's not anger, it's sorrow if anything. Also, since the DeepSpeech isn't mantained anymore, some of it is also related to this project.",please direct anger right people anger sorrow anything also since also related project,issue,negative,negative,negative,negative,negative,negative
1558707717,"Also, for the record, we completed work to make the project uncoupled from TaskCluster and only dependant on GitHub Actions so that people could fork and continue on it. Unfortunately, nobody invested time in this.",also record work make project uncoupled people could fork continue unfortunately nobody time,issue,negative,negative,negative,negative,negative,negative
1558706118,"> > Project is not maintained anymore.
> 
> It's a damned shame that the developers have vanished, like with the Coqui project STT part at https://github.com/coqui-ai/STT - where the source is left in a broken non-compilable state. Laws concerning accessibility have been introduced in many countries, so the market and demand for STT is starting to mature.

Please direct your anger against the right people.",project damned shame like project part source left broken state concerning accessibility many market demand starting mature please direct anger right people,issue,negative,negative,neutral,neutral,negative,negative
1558688240,"> Project is not maintained anymore.

It's a damned shame that the developers have vanished, like with the Coqui project STT part at https://github.com/coqui-ai/STT - where the source is left in a broken non-compilable state. Laws concerning accessibility have been introduced in many countries, so the market and demand for STT is starting to mature.",project damned shame like project part source left broken state concerning accessibility many market demand starting mature,issue,negative,positive,neutral,neutral,positive,positive
1558672514,Project is not maintained anymore. The reason there was no M1 support was lack of hardware available for GitHub Actions to support CI on it.,project reason support lack hardware available support,issue,negative,positive,positive,positive,positive,positive
1518740243,"+1. I just tried importing the package on a .NET 7 WPF app and the same issue mentioned above happens.

I will try the suggested workaround and edit this comment.",tried package issue try edit comment,issue,negative,neutral,neutral,neutral,neutral,neutral
1508802146,Please understand that the project is unmaintained. Likely there is no wheel published for this pair of platform and python version,please understand project unmaintained likely wheel pair platform python version,issue,negative,neutral,neutral,neutral,neutral,neutral
1416777801,"This Issue gonna work you need to add your browser driver in google clob because in google cloab is a better platform for doing this type of issue. because in some time we found that our computer path problem.
basically trackback error occur when something flow out of range where the python file could not understand
(you can add this driver to clob after that pip3 install --upgrade --force-reinstall -e .?)just below the driver code 
please do this in google drive your error gonna fix.
(%%shell
# Ubuntu no longer distributes chromium-browser outside of snap
#
# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap

# Add debian buster
cat > /etc/apt/sources.list.d/debian.list <<'EOF'
deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main
deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main
deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main
EOF

# Add keys
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A

apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg
apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg
apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg

# Prefer debian repo for chromium* packages only
# Note the double-blank lines between entries
cat > /etc/apt/preferences.d/chromium.pref << 'EOF'
Package: *
Pin: release a=eoan
Pin-Priority: 500


Package: *
Pin: origin ""deb.debian.org""
Pin-Priority: 300


Package: chromium*
Pin: origin ""deb.debian.org""
Pin-Priority: 700
EOF

# Install chromium and chromium-driver
apt-get update
apt-get install chromium chromium-driver
)
",issue gon na work need add browser driver better platform type issue time found computer path problem basically error occur something flow range python file could understand add driver pip install upgrade driver code please drive error gon na fix shell longer outside snap solution add buster cat deb buster main deb main deb main add export export export prefer chromium note cat package pin release package pin origin package chromium pin origin install chromium update install chromium,issue,negative,positive,positive,positive,positive,positive
1379932063,"What version of python are you using, because tensorflow 1.15.4 seems to support up to 3.7, as per the pypi page https://pypi.org/project/tensorflow/1.15.4/",version python support per page,issue,negative,neutral,neutral,neutral,neutral,neutral
1364437273,"Per this comment last week, the project is unmaintained: https://github.com/mozilla/DeepSpeech/issues/3756#issuecomment-1354743283",per comment last week project unmaintained,issue,negative,neutral,neutral,neutral,neutral,neutral
1310903824,"@GeorgeS2019 Can you please provide pointers to the solution? 
Do you have a link documenting it? Thanks! ",please provide solution link thanks,issue,positive,positive,positive,positive,positive,positive
1308085327,@LangR7 I also meet too. Have you resolved?Thanks.,also meet resolved thanks,issue,positive,positive,positive,positive,positive,positive
1295670482,May you consider to transfer maintenance to @abandonware community best effort ,may consider transfer maintenance community best effort,issue,positive,positive,positive,positive,positive,positive
1250859884,"It does work. Project is unmaintained, and you dont even care to share STR, nobody can help you.",work project unmaintained dont even care share nobody help,issue,negative,neutral,neutral,neutral,neutral,neutral
1237442389,"Had a similar issue when training a small model for romansh (<15h). Turns out lowering the batch size wasn't enough. (`TF_CUDNN_RESET_RND_GEN_STATE=1` was already set as I'm using a [docker image](https://github.com/wasertech/commonvoice-rm))
My fix was to lower top_k for the lm to be smaller than the max amount of unique words. (from 500 000 to 10 500 in my case :smiling_face_with_tear: )

Hope this can help someone stuck with this error.",similar issue training small model turn lowering batch size enough already set docker image fix lower smaller amount unique case hope help someone stuck error,issue,negative,positive,neutral,neutral,positive,positive
1230433530,"Hi dears,, 
can anyone help me ""how to train this code?"", I tried many times but it seems have something that I couldn't understand.",hi anyone help train code tried many time something could understand,issue,negative,positive,positive,positive,positive,positive
1224198815,"There was already documentation covering that. DeepSpeech is not maintained anymore, there is no point in supporting newer versions of Python. Please look at Coqui https://github.com/coqui-ai/STT/",already documentation covering point supporting python please look,issue,positive,positive,positive,positive,positive,positive
1224183954,"[Official Documentation](https://github.com/mozilla/DeepSpeech/blob/master/doc/BUILDING.rst).

# UPDATE
Due to the change in dependencies, especially SWIG being shifted from https://community-tc.services.mozilla.com/ to ds-swig pre-built package from Mozilla-DS, a new patch is documented below (a major chunk of the fix is the same as above):

# Instructions
## Bazel
You first have to install Bazel 3.1.0. do not install the latest version of Bazel (5.1 as of time of this writing) it is not compatible with tensorflow build.
```bash
$ sudo wget https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-linux-arm64
$ chmod 755 bazel-3.7.2-linux-arm64
$ mv bazel-3.7.2-linux-arm64 /usr/local/bin/bazel
$ mkdir /usr/local/lib/bazel && mkdir /usr/local/lib/bazel/bin
$ cd ""/usr/local/lib/bazel/bin""
$ curl -fLO https://releases.bazel.build/3.1.0/release/bazel-3.1.0-linux-x86_64 && chmod +x bazel-3.1.0-linux-x86_64
```

## Python
Upgrade python to python3.8 or 3.9. Set the path variables.
```bash
$ sudo apt-get install python3.9
$ export PATH=$PATH:/usr/local/bin
```

## Compile DeepSpeech
```bash
$ git clone https://github.com/mozilla/DeepSpeech.git
$ git checkout v0.9.3
$ git submodule sync tensorflow/
$ git submodule update --init tensorflow/
$ cd tensorflow
```

### Configure
When configuring TensorFlow use ""-march=armv8-a+crc -Wno-sign-compare"" when you are asked:
```bash
$ ./configure
```

### Compile
```bash
$ sudo apt update
$ sudo apt install python-is-python3
# Use tmux to keep the process running, when logged in over ssh, if doing # this locally, you can skip it
$ tmux
$ bazel clean
# For non TFLite version:
# bazel --host_jvm_args=-Xmx6000m build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --local_cpu_resources=1 -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=monolithic --config=nogcp --config=nohdfs --config=nonccl --copt=-fvisibility=hidden --config=noaws --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer //native_client:libdeepspeech.so 
# For TFLite version
$ bazel --host_jvm_args=-Xmx6000m build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --local_cpu_resources=1 -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --define=runtime=tflite --config=monolithic --config=nogcp --config=nohdfs --config=nonccl --copt=-fvisibility=hidden --config=noaws --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer //native_client:libdeepspeech.so //native_client:tflite
$ cd ../native_client
$ sudo apt-get install -y libsox-dev libpng-dev libgsm1-dev libmagic-dev libltdl-dev liblzma-dev libbz2-dev
$ sudo make deepspeech
# Do not install swig as given in GitHub Documentation.
# Do not execute `PREFIX=/usr/local sudo make install` like instructed in the manual, otherwise the libdeepspeech.so will not be included in the Python wheel
```

## Miscellaneous
```bash
$ sudo apt update
$ sudo apt install python3-testresources
$ sudo pip3 install numpy –upgrade
$ sudo apt-get install byacc
```

## SWIG
```bash
$ sudo apt-get remove swig
$ sudo git clone https://github.com/swig/swig
$ cd swig/
$ sudo sh autogen.sh
$ sudo ./configure --prefix=<path/to/deepspeech>/native_client/ds-swig/ --program-prefix=ds-
$ sudo make -j
$ sudo make -j install
$ cd ../ds-swig/bin && ln -s ds-swig swig
$ cd /usr/bin
$ sudo ln -s <path/to/deepspeech>/native_client/ds-swig/bin/ds-swig swig
$ swig --version
# Check SWIG install. Should return: SWIG Version 4.1.0
```

## Python DeepSpeech Bindings
### Patch
Apply the following patches:
* [Python bindings patch for aarch64 systems](https://github.com/mozilla/DeepSpeech/pull/3663/commits/8e4c6f27e61acbc39fe9a733aba648669977e854): Edit native_client/definitions.mk.
* [SWIG URL patch](https://github.com/mozilla/DeepSpeech/blob/73e1e4fa01a40bfd34d78669838b0147ccc4eb57/native_client/definitions.mk#L212): Edit native_client/definitions.mk. Changes from line 212-245.
* [Python/Makefile patch](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/Makefile): Change python to python3 and pip to pip3.

### Create Python Bindings
```bash
$ cd python
# For non TFLite version
# make bindings
# For TFLite version
$ make SETUP_FLAGS=""--project_name deepspeech_tflite"" bindings
$ pip install dist/deepspeech*.whl
```",official documentation update due change especially swig package new patch major chunk fix first install install latest version time writing compatible build bash curl python upgrade python python set path bash install python export path compile bash git clone git git sync git update configure use bash compile bash apt update apt install use keep process running logged locally skip clean non version build bash opt version build bash opt install make install swig given documentation execute make install like instructed manual otherwise included python wheel miscellaneous bash apt update apt install pip install install swig bash remove swig git clone sh make make install swig swig swig version check swig install return swig version python patch apply following python patch edit swig patch edit line patch change python python pip pip create python bash python non version make version make pip install,issue,positive,positive,positive,positive,positive,positive
1198396454,"> The big-picture action I am trying to achieve is making DeepSpeech compatible with Unity WebGL. I believe the next step in that process is creating a new DLL file compatible with WebGL. I do not know where to begin with that process and was hoping for advice. However, since DeepSpeech is not maintained and the new iteration ""Coqui STT"" is, I imagine the better course of action is to attempt WebGL support for Coqui.

Nevermind, I misread ""WebGL"" as ""OpenGL"". Using WebGL from TensorFlow, I dont know, WebGL is still quite new. Maybe the WASM work done on Coqui can help.",action trying achieve making compatible unity believe next step process new file compatible know begin process advice however since new iteration imagine better course action attempt support misread dont know still quite new maybe work done help,issue,positive,positive,positive,positive,positive,positive
1198386769,"The big-picture action I am trying to achieve is making DeepSpeech compatible with Unity WebGL. I believe the next step in that process is creating a new DLL file compatible with WebGL. I do not know where to begin with that process and was hoping for advice. However, since DeepSpeech is not maintained and the new iteration ""Coqui STT"" is, I imagine the better course of action is to attempt WebGL support for Coqui.",action trying achieve making compatible unity believe next step process new file compatible know begin process advice however since new iteration imagine better course action attempt support,issue,positive,positive,positive,positive,positive,positive
1197690206,"While @ftyers is right, please note @St3ph3nBr00ks that stating ""and hit a wall with the DLL files"" is absolutely unactionable, even if I wanted to help, you provide 0 information on the actual issue.",right please note hit wall absolutely even help provide information actual issue,issue,positive,positive,positive,positive,positive,positive
1195448246,"Maybe we should consider moving the effort to coqui instead of deepspeech ?
https://github.com/coqui-ai/STT/discussions/2027",maybe consider moving effort instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1188981848,"> Hey @lissyx , may i know why the issue is closed?

Search other issues, discourse, etc. DeepSpeech is not maintained anymore, there is no more CI.",hey may know issue closed search discourse,issue,negative,negative,neutral,neutral,negative,negative
1188843513,"Hey @lissyx , may i know why the issue is closed?",hey may know issue closed,issue,negative,negative,neutral,neutral,negative,negative
1179686841,"@lissyx hello, a long time has passed since this pr was created :)  is there a chance we can finish PR? I see it uses GitHub Actions - I can try to adjust the pipeline, but I didn't find where particularly dotnet builds",hello long time since chance finish see try adjust pipeline find particularly,issue,negative,positive,neutral,neutral,positive,positive
1133821797,"I record .m4a file from windows 'Voice Recorder' in Chinese, and then convert it to .wav:
audio_format=6
num_channels=2
sample_rate=16000 (desired=16000)
bits_per_sample=8
res.buffer_size=291939
it seems that the  codes run correctly:

fseek(wave, 40, SEEK_SET); rv = fread(&res.buffer_size, 4, 1, wave);
fprintf(stderr, ""res.buffer_size=%ld\n"", res.buffer_size);

fseek(wave, 44, SEEK_SET);
res.buffer = (char*)malloc(sizeof(char) * res.buffer_size);
rv = fread(res.buffer, sizeof(char), res.buffer_size, wave);

res.buffer_size is 291939, means that voice file has been read.

BUT when I convert the .m4a flie to .wav, using mono channel:
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=62
2022-05-22 13:15:58.042539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
the result is: ?

the res.buffer_size=62, it looks like the voice file was not read correctly.

why????
",record file recorder convert run correctly wave wave wave char char char wave voice file read convert mono channel successfully dynamic library result like voice file read correctly,issue,positive,neutral,neutral,neutral,neutral,neutral
1107539961,@Camel-RD thanks for your interest! Please see #3693.,thanks interest please see,issue,positive,positive,positive,positive,positive,positive
1107472746,"Well, are there any plans on supporting M1 officialy? Or has anyone from the community tried to recompile it for M1?",well supporting anyone community tried recompile,issue,positive,positive,positive,positive,positive,positive
1093833384,Is this fixed or still needs fixing?,fixed still need fixing,issue,negative,positive,neutral,neutral,positive,positive
1075035286,"> See #3693. 

I am very sad to see this, but i will find a way,

Thank you Sir for improving my knowledge.",see sad see find way thank sir improving knowledge,issue,negative,negative,negative,negative,negative,negative
1066588774,"What is weird you just confirmed my statement ? v16 was pushed only on master, never released.",weird confirmed statement master never,issue,negative,negative,neutral,neutral,negative,negative
1064374728,"Dear @zefaridator , please take a look at #3693. ",dear please take look,issue,positive,neutral,neutral,neutral,neutral,neutral
1054539270,"This still seems to be an issue on the latest stable release ([v0.9.3](https://github.com/mozilla/DeepSpeech/releases/tag/v0.9.3))? I just set up the environment as described in [Train Your Own Model](https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html)

```
ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==0.9.3 (from deepspeech-training==0.9.3) (from versions: none)
ERROR: No matching distribution found for ds_ctcdecoder==0.9.3 (from deepspeech-training==0.9.3)
WARNING: You are using pip version 20.2.2; however, version 22.0.3 is available.
You should consider upgrading via the '/home/jovyan/dpsc-train-venv/bin/python3 -m pip install --upgrade pip' command.
```",still issue latest stable release set environment train model error could find version requirement none error matching distribution found warning pip version however version available consider via pip install upgrade pip command,issue,negative,positive,positive,positive,positive,positive
1040895952,You might take a look into Issue https://github.com/mozilla/DeepSpeech/issues/3693 before you get started,might take look issue get,issue,negative,neutral,neutral,neutral,neutral,neutral
1035859307,"Thanks @kdavis-mozilla you saved my day, I kept getting 'DLL load failed' from cmd or Illegal instruction ('core' dumped) from Ubuntu after installing deepspeech and trying to run it. 
At the end of the day, after checking is AVX enable by hwinfo software, I realize my computer cannot develop deepspeech, and after installing to another computer, worked like a charm.",thanks saved day kept getting load illegal instruction trying run end day enable realize computer develop another computer worked like charm,issue,positive,negative,negative,negative,negative,negative
1019044343,"> I needed to do this, too:
> 
> ```diff
> diff --git a/native_client/BUILD b/native_client/BUILD
> index d25454a..be6040a 100644
> --- a/native_client/BUILD
> +++ b/native_client/BUILD
> @@ -2,7 +2,6 @@
>  
>  load(""@org_tensorflow//tensorflow:tensorflow.bzl"", ""tf_cc_shared_object"", ""tf_copts"", ""lrt_if_needed"")
>  load(""@local_config_cuda//cuda:build_defs.bzl"", ""if_cuda"")
> -load(""@com_github_nelhage_rules_boost//:boost/boost.bzl"", ""boost_deps"")
>  load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_static_framework"")
>  
>  load(
> @@ -175,7 +174,6 @@ cc_library(
>              ""//tensorflow/core/kernels:gather_nd_op"",  # GatherNd
>              ""//tensorflow/core/kernels:identity_op"",  # Identity
>              ""//tensorflow/core/kernels:immutable_constant_op"",  # ImmutableConst (used in memmapped models)
> -            ""//tensorflow/core/kernels:deepspeech_cwise_ops"",  # Less, Minimum, Mul
>              ""//tensorflow/core/kernels:matmul_op"",  # MatMul
>              ""//tensorflow/core/kernels:reduction_ops"",  # Max
>              ""//tensorflow/core/kernels:mfcc_op"",  # Mfcc
> ```

",git index da load load load load identity used le minimum,issue,negative,neutral,neutral,neutral,neutral,neutral
1016227123,"Unless someone is willing to actively maintain the project, it's not a good idea.",unless someone willing actively maintain project good idea,issue,positive,positive,positive,positive,positive,positive
1012301712,"No and I don't think there is any support for Java, because it was made only for Android.",think support made android,issue,negative,neutral,neutral,neutral,neutral,neutral
1011805718,"I've solved it

```python
from deepspeech import Model
import numpy as np
import wave

audio_path = 'models/yasi2.wav'
# 已下载的模型地址（正确的模型文件中有以.pb结尾的文件）
model_path = ""models/deepspeech-0.9.3-models.pbmm""
ars = Model(model_path)

fin = wave.open(audio_path, 'rb')
audio = np.frombuffer(fin.readframes(fin.getnframes()), np.int16)

translate_txt = ars.stt(audio)
print(translate_txt)
```
run result:
```python
C:\Users\Administrator\AppData\Local\Programs\Python\Python38\python.exe E:/iston_algorithm/util/speech/Test.py
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.9.3-0-gf2e9c858
2022-01-13 12:53:25.896530: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
a nine year old girl in new mexico has raised morethan five hundred dollars for her little brother who needs hart surgery in whosten texas this july ad assun were tolsy's grand mother came alread said addison probably overheared a conversation between family members talking about the fun's needed to get her little brather to treatment i guess she overheard her grandfather and me talking about how we are worried about how we are going to get to hoston for my grandson's hearp surgery said alrd she decided to go outside and have a lemonade stand and make some drawings and pictures and seldom that's when addestan and her friends herrecer and emily bordon decided to sell lemonade for fifty cents accup and sel pictures for twenty five cents each before all red new it new mexico state police officers were among the many stopping by helping the reach a total of five hundred ad sixty eight dollars the family turned to social media expressing their gratitude saying from the bottom of our hearts we would like to deeply thank each an every person that stopped by questions one and two a bestd on the mews report you ave just heard question one god id addison raised money for eston to how did abison raised money

Process finished with exit code 0
```",python import model import import wave model fin audio audio print run result python binary deep neural network library use following enable rebuild appropriate compiler nine year old girl new raised five hundred little brother need hart surgery ad grand mother came said probably conversation family talking fun get little treatment guess grandfather talking worried going get grandson surgery said decided go outside lemonade stand make seldom decided sell lemonade fifty twenty five red new new state police among many stopping helping reach total five hundred ad sixty eight family turned social medium gratitude saying bottom heart would like deeply thank every person stopped one two report ave question one god id raised money raised money process finished exit code,issue,positive,positive,positive,positive,positive,positive
1011805186,@Jochen-sys hi jochen Have you found a solution to integrate Java,hi found solution integrate,issue,negative,neutral,neutral,neutral,neutral,neutral
1008058343,"Firstly - yay for Turkmen! Glad to see the language getting some new technology:)

Take a look at issue #3693
",firstly glad see language getting new technology take look issue,issue,negative,positive,positive,positive,positive,positive
1007243654,Any reason why you would need another version ? Because removing those rules will break for other's. ,reason would need another version removing break,issue,negative,neutral,neutral,neutral,neutral,neutral
1007000401,"I needed to do this, too:
```patch
diff --git a/native_client/BUILD b/native_client/BUILD
index d25454a..be6040a 100644
--- a/native_client/BUILD
+++ b/native_client/BUILD
@@ -2,7 +2,6 @@
 
 load(""@org_tensorflow//tensorflow:tensorflow.bzl"", ""tf_cc_shared_object"", ""tf_copts"", ""lrt_if_needed"")
 load(""@local_config_cuda//cuda:build_defs.bzl"", ""if_cuda"")
-load(""@com_github_nelhage_rules_boost//:boost/boost.bzl"", ""boost_deps"")
 load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_static_framework"")
 
 load(
@@ -175,7 +174,6 @@ cc_library(
             ""//tensorflow/core/kernels:gather_nd_op"",  # GatherNd
             ""//tensorflow/core/kernels:identity_op"",  # Identity
             ""//tensorflow/core/kernels:immutable_constant_op"",  # ImmutableConst (used in memmapped models)
-            ""//tensorflow/core/kernels:deepspeech_cwise_ops"",  # Less, Minimum, Mul
             ""//tensorflow/core/kernels:matmul_op"",  # MatMul
             ""//tensorflow/core/kernels:reduction_ops"",  # Max
             ""//tensorflow/core/kernels:mfcc_op"",  # Mfcc
```",patch git index da load load load load identity used le minimum,issue,negative,neutral,neutral,neutral,neutral,neutral
1005104187,"> @lissyx This looks like [nelhage/rules_boost issue #186](https://github.com/nelhage/rules_boost/issues/186). I get this
> 
> ```
> ERROR: Skipping '//native_client:libdeepspeech.so': error loading package 'native_client': Unable to find package for @com_github_nelhage_rules_boost//:boost/boost.bzl: The repository '@com_github_nelhage_rules_boost' could not be resolved.
> ```
> 
> issue with Bazel release 3.7.2, too.

I'm not sure bazel 3.7.2 is a supported release for the version of tensorflow targetted ",like issue get error skipping error loading package unable find package repository could resolved issue release sure release version,issue,negative,neutral,neutral,neutral,neutral,neutral
1004524247,"@lissyx This looks like [nelhage/rules_boost issue #186](https://github.com/nelhage/rules_boost/issues/186). I get this
```
ERROR: Skipping '//native_client:libdeepspeech.so': error loading package 'native_client': Unable to find package for @com_github_nelhage_rules_boost//:boost/boost.bzl: The repository '@com_github_nelhage_rules_boost' could not be resolved.
```
issue with Bazel release 3.7.2, too.",like issue get error skipping error loading package unable find package repository could resolved issue release,issue,negative,negative,negative,negative,negative,negative
1002766735,"> Hello, I have summarized the whole thing a bit. you can find all the information in my prepared GitHub: https://github.com/AndreP2211/deepspeech-help

Please avoid forwarding people like that, it makes it much more complicated to understand your issue ...

Illegal instruction, you're running a VM it seems? And there's no AVX extensions reported on the CPU, so it's unsupported and expected to fail like that.",hello whole thing bit find information prepared please avoid forwarding people like much complicated understand issue illegal instruction running unsupported fail like,issue,negative,negative,negative,negative,negative,negative
1002460058,"Thanks, this is a hard requirements inherited from tensorflow, and moving training pipeline to 2.x is already an open issue that wont be fixed given we are not working on that anymore. Using docker would make you immune to this. You might hit the same limite with coqui but they are actively working on it so training should move to 2.x at some point. @reuben can tell you more on @coqui_ai ",thanks hard moving training pipeline already open issue wont fixed given working docker would make immune might hit actively working training move point tell,issue,positive,negative,neutral,neutral,negative,negative
998521170,"> 
so how to fix it? I can't find any questions identical to this one. I come to this problem when performing the inference.",fix ca find identical one come problem inference,issue,negative,neutral,neutral,neutral,neutral,neutral
993738953,"@MauryaRitesh this repo is not longer maintained, but lives on as [Coqui STT](https://github.com/coqui-ai/STT), which does have working macOS CI. Depending on your interest and expertise I can suggest something to work on there. Easiest way would be for you to join our [Gitter room](https://gitter.im/coqui-ai/STT) and ping me there so we can chat :)",longer working depending interest suggest something work easiest way would join room ping chat,issue,positive,neutral,neutral,neutral,neutral,neutral
986751386,"I was trying to use Meyda, as suggested before, for MFCC extraction and it did not work out well. I submit an issue to them: https://github.com/meyda/meyda/issues/1099.

Also, I found that during inference, if I directly call `model.predict`, it would throw an error:

> Uncaught Error: This execution contains the node 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cond_3/Merge_2', which has the dynamic op 'Merge'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [new_state_h]

I would require me to call model.executeAsync(). I could indeed infer through executeAsync, but it gave me a lot of troubles in maintaining the hidden state of previous_state_c, previous_state_h asynchronously. Are there any ideas about how to get around with it? [new_state_h] seemed to be the output to me. Tensorflowjs indicate that it is an input. This is quite confusing.

Thank you @reuben for your advice on webassembly! Now I think webassembly should be the right solution as MFCC extraction through web seemed too complex to debug. I will look into webassembly next. ",trying use extraction work well submit issue also found inference directly call would throw error uncaught error execution node dynamic please use instead alternatively avoid dynamic specify would require call could indeed infer gave lot hidden state get around output indicate input quite thank advice think right solution extraction web complex look next,issue,positive,negative,neutral,neutral,negative,negative
986199478,"You might be able to extract just the MFCC computation code and then compile it to WebAssembly. Take a look at https://github.com/coqui-ai/inference-engine/blob/main/CMakeLists.txt for example, and https://github.com/coqui-ai/inference-engine/tree/main/third_party/tensorflow
",might able extract computation code compile take look example,issue,negative,positive,positive,positive,positive,positive
985367253,"> Very nice! I would be more than happy to help you get this merged onto [Coqui STT](https://github.com/coqui-ai/STT) (not sure if you're aware but this repo is no longer maintained). Then we can have the JS client tested in CI and kept working well with changes.

I am happy to do so but I am now struggling with the MFCC generation from Web Audio Context. Will try to compute the same set of MFCC between web and tensorflow lib first and see how it goes.",nice would happy help get onto sure aware longer client tested kept working well happy struggling generation web audio context try compute set web first see go,issue,positive,positive,positive,positive,positive,positive
983676555,Very nice! I would be more than happy to help you get this merged onto [Coqui STT](https://github.com/coqui-ai/STT) (not sure if you're aware but this repo is no longer maintained). Then we can have the JS client tested in CI and kept working well with changes.,nice would happy help get onto sure aware longer client tested kept working well,issue,positive,positive,positive,positive,positive,positive
983451472,"I could finally do inference with a deepspeech trained model with TensorflowJS. 
My previous two comments were in the wrong direction because tensorflowjs_converter outputs BlockLSTM and Mfcc related ops that was not supported in tensorflowjs. If you want to proceed, please follow @reuben 's previous post https://github.com/mozilla/DeepSpeech/issues/2233#issuecomment-616815988 to change the model to use static_rnn and remove mfcc related parts. 

I tried feeding all zeros tensors to the network and it gave ""blank"" high probabilities for n_steps. This result seems correct to me. ",could finally inference trained model previous two wrong direction related want proceed please follow previous post change model use remove related tried feeding network gave blank high result correct,issue,negative,negative,neutral,neutral,negative,negative
983425431,"Hey there, I'm interested in this project and would like to contribute further. Since I'm new to this organization, I would like to know if there are particular ideas I should be working on.
Thanks",hey interested project would like contribute since new organization would like know particular working thanks,issue,positive,positive,positive,positive,positive,positive
983314327,"Oh, during implementation, I found the answer to my question 1. `input_samples` does not have impact on `logits/new_state_c/new_state_h`. MFCC computation is done in the graph network as well, instead of computing using other lib.
Dimension of 512 comes from Sample_rate * window_length => 16000 * 32ms = 512 samples. This actually makes implementation much easier.",oh implementation found answer question impact computation done graph network well instead dimension come actually implementation much easier,issue,positive,positive,neutral,neutral,positive,positive
981635563,"Hi thank you @reuben for the great comments. It did help me a lot in understanding what I would need to do to make tensorflowjs work. 
I was trying to write the preprocessing including MFCC buffering, etc and to construct the input from streaming audio wave. However, I checkout the latest code I found that the model converted now takes 5 parameters. 

```
[
    { ""name"": ""input_samples"", ""shape"": [ 512 ], ""dtype"": ""float32"" },
    { ""name"": ""input_node"",  ""shape"": [1, 4, 19, 26],""dtype"": ""float32"" },
    { ""name"": ""input_lengths"", ""shape"": [ 1 ], ""dtype"": ""int32"" },
    { ""name"": ""previous_state_c"", ""shape"": [ 1, 512 ], ""dtype"": ""float32"" },
    { ""name"": ""previous_state_h"", ""shape"": [ 1, 512 ], ""dtype"": ""float32"" }
]
```
Which is different from the above result that only needs 4 parameters. ""input_samples"" is the extra parameter. I tried to find out what this is and I found some hint here: https://github.com/mozilla/DeepSpeech/blob/aa1d28530d531d0d92289bf5f11a49fe516fdc86/training/deepspeech_training/train.py#L736

Here are my quetsions:

1. I went through the code but this ""input_samples"" was not passed in the tensorflow main graph to do any processing for `logits / new_state_c / new_state_h` . It was merely used to create a seperate mfcc output. In such case, is it safe to just ignore this input? Why do we have this in the first place? I try to find the commit / PR for adding this change but I failed to do that. Also, the dimension of 512, which comes from `Config.audio_window_samples`, did not match anything ( I was using default settings for` feature_win_len, feature_win_step, sample_rate`. Those numbers also cannot multiply into 512 in terms of actual audio samples ). I did not find any clues of feeding it into the actual pipeline. Could you advice if there is anything I missed? 
2. I read the code carefully and I found that in the input_node second dimension is actually the same as input_lengths, which comes from the config.n_step. Why do we have an extra input called ""input_lengths"" instead of using input_node's second dimension as the input_lengths? I think I might miss some ideas here as well.

Many thanks!
",hi thank great help lot understanding would need make work trying write construct input streaming audio wave however latest code found model converted name shape float name shape float name shape name shape float name shape float different result need extra parameter tried find found hint went code main graph merely used create output case safe ignore input first place try find commit change also dimension come match anything default also multiply actual audio find feeding actual pipeline could advice anything read code carefully found second dimension actually come extra input instead second dimension think might miss well many thanks,issue,positive,positive,positive,positive,positive,positive
977603359,"While looking to get [high-quality STT working at home, on an NVidia Jetson board](https://github.com/domcross/DeepSpeech-for-Jetson-Nano), I saw mention of the possible deprecation of [Deepspeech](https://github.com/mozilla/DeepSpeech). The following 'fork' of Deepspeech (as of v0.93) was introduced, supposedly developed by former members of Mozilla's Deepspeech team:

[Coqui (about)](https://coqui.ai/about)

> In 2016 while at Mozilla the founders of Coqui noticed that speech technology was siloed in large corporations....

Code is at https://github.com/coqui-ai/STT",looking get working home board saw mention possible deprecation following supposedly former team speech technology large code,issue,negative,positive,neutral,neutral,positive,positive
972426885,"I'm trying to get the nodejs binaries built against node versions but getting nowhere. Am I supposed to install electron manually or against a specific version? am I using the wrong node versions? 

- v10.4.0
- v12.22.7
- v14.18.1
- v16.10.0

Output:
![image](https://user-images.githubusercontent.com/7339311/142336359-bba908d5-2e97-4d1c-85e9-e207d342ee62.png)

",trying get built node getting nowhere supposed install electron manually specific version wrong node output image,issue,negative,negative,negative,negative,negative,negative
971819118,"> @lissyx, sorry but the errors in the test failures might be a bit over my head. I'm not sure they're related directly to the electron version bump.
> 
> The windows failure seems to be the main TensorFlow lib for Windows being unable to compile properly.
> 
> ```
> ERROR: D:/a/deepspeech/deepspeech/tensorflow/tensorflow/core/platform/default/BUILD:177:1: C++ compilation of rule '//tensorflow/core/platform/default:logging' failed (Exit 1): vc_installation_error.bat failed: error executing command 
>   cd D:/a/deepspeech/deepspeech/.bazel_cache/output/execroot/org_tensorflow
> ```
> 
> The linux failure seems to be at the `check_artifact_exists` step. I don't even see an error on that one, just seems to fail after downloading artifacts.

If windows is failing to build, `check_artifact_exists` might fail as a side effect

> 
> @lissyx, have you run the current master branch through GitHub Actions recently to make sure it's all still passing without these changes?

I am not working on this project anymore, so I advise to have a look at older PRs merged on https://github.com/mozilla/DeepSpeech/commits/master and see their status.

It's possible there has been GitHub Actions specific regressions, I'd suspect the Windows ones for example. But I really have no time to investigate and fix those.",sorry test might bit head sure related directly electron version bump failure main unable compile properly error compilation rule logging exit error command failure step even see error one fail failing build might fail side effect run current master branch recently make sure still passing without working project advise look older see status possible specific suspect example really time investigate fix,issue,negative,negative,neutral,neutral,negative,negative
970573969,"@lissyx, sorry but the errors in the test failures might be a bit over my head. I'm not sure they're related directly to the electron version bump. 

The windows failure seems to be the main TensorFlow lib for Windows being unable to compile properly. 
```
ERROR: D:/a/deepspeech/deepspeech/tensorflow/tensorflow/core/platform/default/BUILD:177:1: C++ compilation of rule '//tensorflow/core/platform/default:logging' failed (Exit 1): vc_installation_error.bat failed: error executing command 
  cd D:/a/deepspeech/deepspeech/.bazel_cache/output/execroot/org_tensorflow
```

The linux failure seems to be at the `check_artifact_exists` step. I don't even see an error on that one, just seems to fail after downloading artifacts. 

@lissyx, have you run the current master branch through GitHub Actions recently to make sure it's all still passing without these changes?",sorry test might bit head sure related directly electron version bump failure main unable compile properly error compilation rule logging exit error command failure step even see error one fail run current master branch recently make sure still passing without,issue,negative,negative,neutral,neutral,negative,negative
967625795,"FWIW I've just updated the Coqui STT builds to cover newer NodeJS and ElectronJS versions over in https://github.com/coqui-ai/STT/pull/2018

Should be available in npm soon, I'll trigger a new alpha version.",cover available soon trigger new alpha version,issue,negative,positive,positive,positive,positive,positive
966348213,"@lissyx I'm not that familiar with the GitHub Actions workflow of this project. But, I think I was able to get a (mostly) successful run on my fork here:
https://github.com/dudewheresmycode/DeepSpeech/actions/runs/1451548491

I was able to get a clean build for MacOS of the electron binaries. But hit some errors on Windows and Linux builds. Hoping you can advise there.

Note: I had to update the URL for `PCRE` (it was timing out during builds), not sure if I should keep that change or not. I saw a couple other failures, but I think the relevant bits passed.",familiar project think able get mostly successful run fork able get clean build electron hit advise note update timing sure keep change saw couple think relevant,issue,positive,positive,positive,positive,positive,positive
956397345,Use discourse for support. read the documentation.,use discourse support read documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
955674133,Nobody is working on that but if you send patches we can review. ,nobody working send review,issue,negative,neutral,neutral,neutral,neutral,neutral
953741302,"> Does it possible for Mozilla to facilitate the recruitment of new maintainer volunteers? (could be from inside and outside Mozilla). I guess I see some potentials in above comments.

This is work we tried to push and complete last year until the early days of 2021, however nobody ever stepped up on the call top volunteer and actions we put in place. Moving CI from TaskCluster to GitHub Actions move was also a big milestone we achieved to help people take ownership.

It looks like that ship has sailed, and now Mozilla has nobody working anymore on the project full time, and while it's not impossible for people to review PRs, it makes it much much more complicated.",possible facilitate recruitment new maintainer could inside outside guess see work tried push complete last year early day however nobody ever stepped call top volunteer put place moving move also big milestone help people take ownership like ship sailed nobody working project full time impossible people review much much complicated,issue,positive,positive,neutral,neutral,positive,positive
953719601,Does it possible for Mozilla to facilitate the recruitment of new maintainer volunteers? (could be from inside and outside Mozilla). I guess I see some potentials in above comments.,possible facilitate recruitment new maintainer could inside outside guess see,issue,negative,positive,neutral,neutral,positive,positive
953221615,"> > Because nobody is around to review and merge your contributions to this repo.
> 
> Mozilla is looking for a new team to support DeepSpeech, so things could change soon.

Could you please elaborate from where you have that information ?",nobody around review merge looking new team support could change soon could please elaborate information,issue,positive,positive,positive,positive,positive,positive
953218538,"> Because nobody is around to review and merge your contributions to this repo.

Mozilla is looking for a new team to support DeepSpeech, so things could change soon.
",nobody around review merge looking new team support could change soon,issue,negative,positive,positive,positive,positive,positive
950938862,"This is not an issue, and it's already covered in the forum. Furthermore, I'm not working on that anymore.",issue already covered forum furthermore working,issue,negative,neutral,neutral,neutral,neutral,neutral
950803830,"@reuben 
Yup, the hard fact is the core team of DeepSpeech has been laid off. 
Hence, no one is going to support it anymore.",hard fact core team laid hence one going support,issue,negative,negative,negative,negative,negative,negative
950795894,Because nobody is around to review and merge your contributions to this repo.,nobody around review merge,issue,negative,neutral,neutral,neutral,neutral,neutral
950394666,"Why do we need another repo? We are ready to contribute to this.
",need another ready contribute,issue,negative,positive,positive,positive,positive,positive
950387095,"@bobkleiner -- archiving this repo ([in the Github sense](https://docs.github.com/en/repositories/archiving-a-github-repository/archiving-repositories)) shouldn't affect your ability to release your own codebase... where do you see the issue?

Archiving allows this repo to persist, but it also lets contributors know that PRs and open issues aren't being reviewed.",sense affect ability release see issue persist also know open,issue,negative,neutral,neutral,neutral,neutral,neutral
950377616,"Sorry, it is not a great idea. Our company created a huge codebase based on this repo and we are actively looking to contribute it back to the Mozilla community. We still see DeepSpeech as a great project!
",sorry great idea company huge based actively looking contribute back community still see great project,issue,positive,positive,positive,positive,positive,positive
950135706,"@JRMeyer 
Agreed very much with you that it gave a completely wrong expectation to those who were looking for code update !!!!",agreed much gave completely wrong expectation looking code update,issue,negative,negative,negative,negative,negative,negative
947279008,"I also witnessed this. And, I found it's related with Computer Memory usage of python.
I have 12 GB graphic card, and if python uses more than 12GB, the error occurs. 
You can see Memory usage of python in ""Task Manager "" of windows.
So, I reduced my batch size, to reduce Memory usage. And used TF_CUDNN_RESET_RND_GEN_STATE=1 to solve the problem.
Hope this can help to figure out the problem.",also found related computer memory usage python graphic card python error see memory usage python task manager reduced batch size reduce memory usage used solve problem hope help figure problem,issue,negative,neutral,neutral,neutral,neutral,neutral
944844969,"Calculating WER and related statistics seems like a task like that would best be left to a separate tool.

Offhand, this looks like a reasonable candidate tool if you like Python: [jiwer · PyPI](https://pypi.org/project/jiwer/)

You also might want to edit your question to remove the extraneous unanswered and/or irrelevant questions.
Best wishes.",calculating wer related statistic like task like would best left separate tool offhand like reasonable candidate tool like python also might want edit question remove extraneous unanswered irrelevant best,issue,positive,positive,positive,positive,positive,positive
937822327,"huggingface has a normative python model interface where each model has an architecture wrapped with code in their codebase.  Often this means copying work from other codebases or languages into their python transformers code.

The huggingface inference endpoints do not appear to be free, but they provide free demos of the models for web visitors to try them out.

The open source huggingface transformers codebase is very convenient and easy to use, as a developer.  It gives the developer the personal control of advanced technology shortly after it reaches research, that can otherwise seem inaccessible, and transformers is actively being used to form new research and products across the globe.  It ties together models and work that would otherwise be an obscure mess spread across the web.  The transformers codebase usually accesses copies of models that are uploaded to huggingface's cached public git repositories, but can also access models locally.

I believe at present the only speech to text models available on huggingface's model hub are from facebook.

It's possible to set up models in huggingface transformers such that they can be used with multiple different machine learning architectures: for example a user could theoretically choose between pytorch, jax, or straight tensorflow.

The huggingface codebase does not read like it was written by a computer scientist and it can be more laborious than needed to implement things due to some of the factoring choices.

Combining these two projects would likely mean adding to the transformers codebase a python interface to the deepspeech model that uses a normative python library to load and use it, such as pytorch or jax.  Then either a compatible model would be uploaded to huggingface, or the transformers codebase would be extended to retrieve the model directly from mozilla.

Alternatively mozilla's deepspeech python bindings could be referenced straight from the transformers codebase.  This could make implementation comparably quite easy.

To huggingface: among community software we like to make sure that the user always has full control, so as to foremost act to protect people above all other things.  So, there can be bumps when things like hardcoded centralised hosting or for-pay features are found.

[EDITED with a couple more paragraphs throughout]",normative python model interface model architecture wrapped code often work python code inference appear free provide free demo web try open source convenient easy use developer developer personal control advanced technology shortly research otherwise seem inaccessible actively used form new research across globe together work would otherwise obscure mess spread across web usually public git also access locally believe present speech text available model hub possible set used multiple different machine learning example user could theoretically choose straight read like written computer scientist laborious implement due combining two would likely mean python interface model normative python library load use either compatible model would would extended retrieve model directly alternatively python could straight could make implementation comparably quite easy among community like make sure user always full control foremost act protect people like hosting found couple throughout,issue,positive,positive,positive,positive,positive,positive
934722946,"> @lissyx So, is it not considered even if it is paid under a proper commercial deal ?

You'd need some entity to sign that, there is no such thing available for deepspeech. If you work on it and send PR, I'd review it.",considered even proper commercial deal need entity sign thing available work send review,issue,negative,positive,positive,positive,positive,positive
934630647,"> And magic, if you use master, it is already defaulting to v0.9.3 github hosted artifacts.

okay, thankyou",magic use master already,issue,negative,positive,positive,positive,positive,positive
934595570,@tim5go there are people offering commercial support for DeepSpeech. You could contact them.,people offering commercial support could contact,issue,negative,neutral,neutral,neutral,neutral,neutral
934592794,"@lissyx 
So, is it not considered even if it is paid under a proper commercial deal ?",considered even proper commercial deal,issue,negative,neutral,neutral,neutral,neutral,neutral
934577452,"> > > > https://github.com/mozilla/DeepSpeech/releases/tag/v0.9.3
> > > 
> > > 
> > > Can you give a little specifics, please?
> > 
> > 
> > download `ds-swig` from there?
> 
> and what next? Untar it and thats it?

Read the doc and set the appropriate env variable to pick it ?",give little please next untar thats read doc set appropriate variable pick,issue,negative,positive,positive,positive,positive,positive
934576763,"> > > https://github.com/mozilla/DeepSpeech/releases/tag/v0.9.3
> > 
> > 
> > Can you give a little specifics, please?
> 
> download `ds-swig` from there?

and what next? Untar it and thats it?",give little please next untar thats,issue,negative,negative,neutral,neutral,negative,negative
934538896,"@lissyx 
Understood.
Um... from your rough estimation, do you know the development effort of upgrading TF 1.15 to the latest version of TF?",understood um rough estimation know development effort latest version,issue,negative,positive,positive,positive,positive,positive
934537248,"

> https://github.com/mozilla/DeepSpeech/releases/tag/v0.9.3

Can you give a little specifics, please? Couldn't resolve same issue but while building from [https://github.com/mozilla/DeepSpeech/blob/bfccca320563f2c374d27eb34f7240b5899e421f/Dockerfile.build.tmpl#L168](url)

(same error if i skip this to build ctcdecode)

Version i used:
`DEEPSPEECH_REPO=https://github.com/mozilla/DeepSpeech.git \
    DEEPSPEECH_SHA=f2e9c85880dff94115ab510cde9ca4af7ee51c19`

And my output is 
```
root@351fe16cf9e1:/DeepSpeech/native_client/python# make bindings
mkdir -p /DeepSpeech/native_client/ds-swig
wget -O - """"https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.linux.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.0/artifacts/public/ds-swig.tar.gz"""" | tar -C /DeepSpeech/native_client/ds-swig -zxf -
--2021-10-05 15:48:14--  https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.linux.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.0/artifacts/public/ds-swig.tar.gz
Resolving community-tc.services.mozilla.com (community-tc.services.mozilla.com)... 34.102.144.36
Connecting to community-tc.services.mozilla.com (community-tc.services.mozilla.com)|34.102.144.36|:443... connected.
HTTP request sent, awaiting response... 404 Not Found
2021-10-05 15:48:15 ERROR 404: Not Found.


gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error is not recoverable: exiting now
../definitions.mk:234: recipe for target '/DeepSpeech/native_client/ds-swig/bin/swig' failed
make: *** [/DeepSpeech/native_client/ds-swig/bin/swig] Error 2
```",give little please could resolve issue building error skip build version used output root make tar connected request sent response found error found unexpected end file tar child returned status tar error recoverable recipe target make error,issue,negative,negative,neutral,neutral,negative,negative
934327990,Inference on client side is already based on TensorFlow r2.4. Only training is stuck at r1.15. Please understand nobody is actively working on the codebase anymore. Feel free to send patches for supporting training on r2.x branches.,inference client side already based training stuck please understand nobody actively working feel free send supporting training,issue,positive,positive,positive,positive,positive,positive
929978075,"> > First, follow the github template and seek support on Discourse. Second, aarch64 is not allowed on pypi. Please use github release linux aarch64 python wheel.
> 
> Now, AArch64 is supported by PyPI. It would be helpful is you could upload AArch64 wheels on PyPI.

Feel free to add support in a PR, i'm not working on this anymore. ",first follow template seek support discourse second please use release python wheel would helpful could feel free add support working,issue,positive,positive,positive,positive,positive,positive
929975559,"> First, follow the github template and seek support on Discourse. Second, aarch64 is not allowed on pypi. Please use github release linux aarch64 python wheel.

Now, AArch64 is supported by PyPI. It would be helpful is you could upload AArch64 wheels on PyPI.",first follow template seek support discourse second please use release python wheel would helpful could,issue,positive,positive,positive,positive,positive,positive
929125613,"hi, where could I got this wheel?",hi could got wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
924779112,"We only provided support for latest Raspbian, if it is running elsewhere it's nice but not enforced. Please send PR for adding new python versions.",provided support latest running elsewhere nice enforced please send new python,issue,positive,positive,positive,positive,positive,positive
924777933,Please use Discourse for support and read the doc.,please use discourse support read doc,issue,positive,neutral,neutral,neutral,neutral,neutral
922681106,How does hotword get stored? I mean when we add hotword what process happens? Where does it get stored? Does it get updated in model? @vchagari  @JRMeyer . Can you guys help me on this,get mean add process get get model help,issue,negative,negative,negative,negative,negative,negative
915117037,"> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).

",support please use discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
913204665,"> @reuben @lissyx I gave up on fixing this and just took the accuracy hit from splitting the audio file into 5-minute segments. I've published the app using this, [ReLearn](https://relearn.fyi), to the Android/iOS App Stores. It uses DeepSpeech to transcribe long video recordings of lectures for free on-device in the background (it also transcribes audio in-person recordings on Android, but uses Apple's solution for that on iOS for now).

@zaptrem I've been wanting to build something very similar to this but just ran up against Apple's one minute live transcription limit with SFSpeechRecognizer. How are you getting around this in ReLearn? Any chance you'd like to collaborate on some live speech / mind mapping type applications?",gave fixing took accuracy hit splitting audio file relearn transcribe long video free background also audio android apple solution wanting build something similar ran apple one minute live transcription limit getting around relearn chance like collaborate live speech mind type,issue,positive,positive,positive,positive,positive,positive
907106854,"how to add the domain specific words to vocabulary for deepspeech2 so as to correctly transcript it for ASR??
",add domain specific vocabulary correctly transcript,issue,negative,neutral,neutral,neutral,neutral,neutral
903125308,"@Chaitanya1597 and @yunzqq - what you are looking for is the metric called - ""Levenshtein Distance"". You have to calculate this between the Ground-Truth-Text (alias Referenztext (the origin voice input that you made as text)) and the Deepspeech - Transcription (output text)
more useful informations: [Articel from Rafael C. Carrasco](https://sites.google.com/site/textdigitisation/qualitymeasures/computingerrorrates) - i hope this is helpful for you?",looking metric distance calculate alias origin voice input made text transcription output text useful hope helpful,issue,positive,positive,positive,positive,positive,positive
898988806,"Few weeks ago I was planning to do that (opening a PR against coqui). But failed to build the iOS static framework -- bazel prompts:

`""ERROR: file 'native_client/libkenlm.so' is generated by these conflicting actions:"". `

Will give it another try later.",ago opening build static framework error file conflicting give another try later,issue,negative,positive,positive,positive,positive,positive
898928608,I no longer have push access to this repository. If you can open the PR against our coqui-ai/STT fork I'm happy to merge it.,longer push access repository open fork happy merge,issue,positive,positive,positive,positive,positive,positive
898902939,"@Boya-Na 
Could you please check, if your crashes go away after merging #3527?",could please check go away,issue,negative,neutral,neutral,neutral,neutral,neutral
898902414,"Could you please consider merging this, @reuben? Thanks!",could please consider thanks,issue,positive,positive,positive,positive,positive,positive
893143435,calculate the word error rate,calculate word error rate,issue,negative,neutral,neutral,neutral,neutral,neutral
893141484,I also want to know how could I calculate the WER?,also want know could calculate wer,issue,negative,neutral,neutral,neutral,neutral,neutral
888322957,"> what is discourse support, will you please ellaborate this or share link

You have the link in the template you have not taken the time to read nor to file.",discourse support please share link link template taken time read file,issue,positive,neutral,neutral,neutral,neutral,neutral
888322240,"> Mozilla, it sounds like communicating around this has been difficult. It would be great if it were supported to build on arm machines. Many people run systems that are aarch64 or armv7l.

It is supported: cross-compilation

> 
> I see the importance of adding tests. Could any familiar with the testing system give a quick outline of what is needed to add tests for building on arm? Has anybody started this work?

Please look at the GitHub Actions folder and #3317",like communicating around difficult would great build arm many people run see importance could familiar testing system give quick outline add building arm anybody work please look folder,issue,positive,positive,positive,positive,positive,positive
888316242,"what is discourse support, will you please ellaborate this or share link 
",discourse support please share link,issue,positive,neutral,neutral,neutral,neutral,neutral
888310212,Please use Discourse for support.,please use discourse support,issue,positive,neutral,neutral,neutral,neutral,neutral
888279435,"Get error-
raise RuntimeError(""CreateModel failed with '{}' (0x{:X})"".format(deepspeech.impl.ErrorCodeToErrorMessage(status),status))
RuntimeError: CreateModel failed with 'Failed to initialize memory mapped model.' (0x3000)
",get raise status status initialize memory model,issue,negative,neutral,neutral,neutral,neutral,neutral
886176561,"Mozilla, it sounds like communicating around this has been difficult.  It would be great if it were supported to build on arm machines.  Many people run systems that are aarch64 or armv7l.

I see the importance of adding tests.  Could any familiar with the testing system give a quick outline of what is needed to add tests for building on arm?  Has anybody started this work?",like communicating around difficult would great build arm many people run see importance could familiar testing system give quick outline add building arm anybody work,issue,positive,positive,positive,positive,positive,positive
882810300,"Please use Discourse for support, this is not a bug.",please use discourse support bug,issue,positive,neutral,neutral,neutral,neutral,neutral
882440743,It looks as though incorporating transformers as a language model into DeepSpeech has been on people's Wishlist for a while. Does anyone know if any progress has been made or if anyone has managed this? I've looked but can't find anything - not sure if I'm missing something.,though language model people anyone know progress made anyone ca find anything sure missing something,issue,negative,positive,positive,positive,positive,positive
877947340,I don't think iPhone 8 has enough memory to hold the entire model files. You may want to give the modern ones a try (iPhone 10+).,think enough memory hold entire model may want give modern try,issue,negative,positive,neutral,neutral,positive,positive
877169894,This issue relates to the version pulled in from deepspeech v0.9.3. So there are already more up to date branches. For 0.9.3 the solution would be then to compile with gcc10.,issue version already date solution would compile,issue,negative,neutral,neutral,neutral,neutral,neutral
876560983,"thanks for the advices, maybe someone else can help me solve this?",thanks maybe someone else help solve,issue,positive,positive,positive,positive,positive,positive
876559419,"I'm sorry, but I am not working on that project anymore, and I don't have time to investigate that.",sorry working project time investigate,issue,negative,negative,negative,negative,negative,negative
876535952,tf_http_archive() only accepts one patch. should then the existing merged with the new one?,one patch new one,issue,negative,positive,positive,positive,positive,positive
876277036,"> yeah, but the workaround is not in a file in mozilla/tensorflow, but in a file from a package automatically downloaded from bazel. (abseil)

That's not a problem: https://github.com/mozilla/tensorflow/blob/r2.4/tensorflow/workspace.bzl#L188",yeah file file package automatically problem,issue,negative,neutral,neutral,neutral,neutral,neutral
876274107,"yeah, but the workaround is not in a file in mozilla/tensorflow, but in a file from a package automatically downloaded from bazel. (abseil)",yeah file file package automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
876139875,"Use older gcc version, or send PR for tensorflow.",use older version send,issue,negative,positive,positive,positive,positive,positive
873045394,"I would love to see this PR finished off so I can use DeepSpeech in my applications. I'd be happy to help out with getting GitHub Actions CI finished. Is that the only thing left?

If so, I could create a new PR based on the latest `master`, and re-use the project/code changes from this branch, and not worry about the taskcluster changes, right? Or if @stepkillah plans to come back to this, I can hold off.",would love see finished use happy help getting finished thing left could create new based latest master branch worry right come back hold,issue,positive,positive,positive,positive,positive,positive
869621911,"# Summary 

Because the DeepSpeech project is not supporting Python bindings for Python 3.8 and later for 64 bit arm systems (aarch64), e.g. used on the Raspberry Pi 4 running Ubuntu server 20.04, DeepSpeech and DeepSpeech-TFLite must be compiled manually.

# Instructions

## Bazel

You have to install [Bazel](https://github.com/bazelbuild/bazel/releases) 3.1.0 first:

~~~shell
wget https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-linux-arm64
chmod 755 bazel-3.7.2-linux-arm64
mv bazel-3.7.2-linux-arm64 /usr/local/bin/bazel
cd ""/usr/local/lib/bazel/bin"" && curl -fLO https://releases.bazel.build/3.1.0/release/bazel-3.1.0-linux-x86_64 && chmod +x bazel-3.1.0-linux-x86_64
~~~

## Install Python 3.8

Install Python 3.8 locally and set it as default (this should be default on Ubuntu 20.04 and can be skipped):

~~~shell
git clone https://github.com/pyenv/pyenv.git ~/.pyenv
# Follow instructions on https://github.com/pyenv/pyenv
sudo apt-get install libbz2-dev libssl-dev libreadline-dev libsqlite3-dev
pyenv install 3.8.10
pyenv local 3.8.10
~~~

## Compile DeepSpeech

~~~shell
git clone https://github.com/mozilla/DeepSpeech.git
git checkout v0.9.3
git submodule sync tensorflow/
git submodule update --init tensorflow/
cd tensorflow
~~~

Configure:

When configuring TensorFlow use ""-march=armv8-a+crc -Wno-sign-compare"" when you are asked:

~~~shell
./configure
~~~

Compile: 

__NOTE:__ This is targeting TFLite, but in the comments also the compilation for standard DeepSpeech is given.

~~~shell
# Use tmux to keep the process running, when logged in over ssh, if doing this locally, you can skip it
tmux
bazel clean
# For non TFLite version:
#bazel --host_jvm_args=-Xmx6000m build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --local_cpu_resources=1 -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --config=monolithic --config=nogcp --config=nohdfs --config=nonccl --copt=-fvisibility=hidden --config=noaws --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer //native_client:libdeepspeech.so 
# For TFLite version
bazel --host_jvm_args=-Xmx6000m build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --local_cpu_resources=1 -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --define=runtime=tflite --config=monolithic --config=nogcp --config=nohdfs --config=nonccl --copt=-fvisibility=hidden --config=noaws --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer //native_client:libdeepspeech.so //native_client:tflite
cd ../native_client
sudo apt-get install -y libsox-dev libpng-dev libgsm1-dev libmagic-dev libltdl-dev liblzma-dev libbz2-dev swig
make deepspeech
# Do not execute `PREFIX=/usr/local sudo make install` like instructed in the manual, otherwise the libdeepspeech.so will not be included in the Python wheel  
~~~

## Python DeepSpeech Bindings

### Patch

Apply this patch to use the correct naming for the Python wheel:

~~~
diff --cc native_client/definitions.mk
index a3af0970,72c12e3a..00000000
--- a/native_client/definitions.mk
+++ b/native_client/definitions.mk
@@@ -51,7 -52,11 +52,11 @@@ SOX_LDFLAGS     := `pkg-config --libs s
  endif # OS others
  PYTHON_PACKAGES := numpy${NUMPY_BUILD_VERSION}
  ifeq ($(OS),Linux)
+ ifeq ($(PROCESSOR),x86_64)
 -PYTHON_PLATFORM_NAME := --plat-name manylinux1_x86_64
 +PYTHON_PLATFORM_NAME ?= --plat-name manylinux1_x86_64
+ else
 -PYTHON_PLATFORM_NAME := --plat-name linux_${PROCESSOR}
++PYTHON_PLATFORM_NAME ?= --plat-name linux_${PROCESSOR}
+ endif
  endif
  endif
~~~

### Create Python Bindings 

__NOTE:__ This is targeting TFLite, but in the comments also the compilation for standard DeepSpeech is given.

~~~shell
cd python
# For non TFLite version
# make bindings
# For TFLite version
make SETUP_FLAGS=""--project_name deepspeech_tflite"" bindings
pip install dist/deepspeech*.whl 
~~~",summary project supporting python python later bit arm used raspberry pi running server must manually install first curl install python install python locally set default default git clone follow install install local compile git clone git git sync git update configure use compile also compilation standard given use keep process running logged locally skip clean non version build bash opt version build bash opt install swig make execute make install like instructed manual otherwise included python wheel python patch apply patch use correct naming python wheel index o o processor else processor processor create python also compilation standard given python non version make version make pip install,issue,positive,positive,neutral,neutral,positive,positive
869177331,"Would there be interest in integrating pyctcdecode? https://github.com/kensho-technologies/pyctcdecode
It supports multiple language models as well as a few other things out of the box.",would interest multiple language well box,issue,positive,neutral,neutral,neutral,neutral,neutral
868861384,"> Well, then I will document the patch at least here or somewhere else if embedded arm devices on recent Python versions are not in the current scope of the Deepspeech project so that other programmers can still use it. If it will not be merged, this can be closed.

If you are willing to support other versions, you should try and add testing for it with cross-compilation being supported ; we did the move to GitHub Actions explicitely to ease contributions.",well document patch least somewhere else arm recent python current scope project still use closed willing support try add testing move ease,issue,positive,negative,neutral,neutral,negative,negative
868854706,"Well, then I will document the patch at least here or somewhere else if embedded arm devices on recent Python versions are not  in the current scope of the Deepspeech project so that other programmers can still use it. If it will not be merged, this can be closed.",well document patch least somewhere else arm recent python current scope project still use closed,issue,negative,negative,neutral,neutral,negative,negative
868834011,"> Ok, with my fix then the full built chain would be supported for Python 3.8+ for Ubuntu based devices. I do not think that only supporting Raspbian / ARMBian with Python 3.7 is matching the majority of users for the Raspberry Pi 4.

And yet that's their distro. The problem is that your fix will make it work but we have no test coverage for building on this hardware, since we only support cross-compilation.",fix full built chain would python based think supporting python matching majority raspberry pi yet problem fix make work test coverage building hardware since support,issue,negative,positive,positive,positive,positive,positive
868820656,"Ok, with my fix then the full built chain would be supported for Python 3.8+ for Ubuntu based devices. I do not think that only supporting Raspbian / ARMBian with Python 3.7 is matching the majority of users for the Raspberry Pi 4.",fix full built chain would python based think supporting python matching majority raspberry pi,issue,negative,positive,positive,positive,positive,positive
868808570,"> Looking at the release page I cannot find supported wheels for Python 3.8 and Python 3.9. Can you please provide the link?

We only support Python as the one provided by Raspbian / ARMBian, so 3.7.",looking release page find python python please provide link support python one provided,issue,positive,neutral,neutral,neutral,neutral,neutral
868801485,Looking at the release page I cannot find supported wheels for Python 3.8 and Python 3.9. Can you please provide the link?,looking release page find python python please provide link,issue,negative,neutral,neutral,neutral,neutral,neutral
868269230,"> no Python wheels are supported for aarch64.

We provide them on the github release page, I don't get your point.",python provide release page get point,issue,negative,neutral,neutral,neutral,neutral,neutral
867953149,"The fix is for the binding only, yes. But I could successfully compile deepspeech on a Rasp Pi 4 running Ubuntu 20.04 in about 3 hours without problems. It seems to be supported. Do you need the command line how to built it? I also built the tflite version. I also see no other way of doing it because no Python wheels are supported for aarch64.",fix binding yes could successfully compile rasp pi running without need command line built also built version also see way python,issue,positive,positive,positive,positive,positive,positive
865134969,"@ftyers Dear Mr. Tyers, thank you very much for the script, your attention and your time!",dear thank much script attention time,issue,positive,positive,positive,positive,positive,positive
865054051,"[Here](https://github.com/ftyers/commonvoice-docker/blob/main/test.sh) is the command I use. But for further assistance, please get in touch on [Matrix](https://app.element.io/#/room/#machinelearning:mozilla.org) or [Discourse](https://discourse.mozilla.org/c/deepspeech/247).",command use assistance please get touch matrix discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
864866460,"@ftyers Dear Mr. Tyers, thank you for a swift reply! 
Could you be so kind as to clarify the steps for stopping the test and rerunning it independently?
Currently, the testing begins after training ends with ""FINISHED OPTIMIZATION"" automatically. 
Thank you for a moment of your time.
",dear thank swift reply could kind clarify stopping test independently currently testing training finished optimization automatically thank moment time,issue,positive,positive,positive,positive,positive,positive
864810128,"> Hey @lissyx I checked the successful pull requests, looks like they were using an artifact, which is missing in my [run](https://pipelines.actions.githubusercontent.com/1JGGHXEsvQE9F2oxg64uTGkAHCoJy4UEnMxmIhj3HZPnBaUavA/_apis/pipelines/1/runs/90/signedlogcontent/3?urlExpires=2021-06-20T12%3A51%3A06.4877581Z&urlSigningMethod=HMACV1&urlSignature=RMj7DTgNYKn3oJdNp10Kn9hJEmccGbD4uIhZpGgu0Bk%3D), so this [Win|Build Tensorflow (opt)](https://github.com/hmen97/DeepSpeech/blob/9e67724d39ff89f191f7052e653aaddac7c90b19/.github/workflows/build-and-test.yml#L1211-L1255) is passed without actually running any of the build instructions in the test. Can you check if that artifact still exists in the CI_ARTIFACTS_DIR? or maybe there is some config I'm missing... here are some logs for ref...
> 
> _2021-06-20T12:34:40.8675106Z HEAD is now at 6f9dee7 Merge [5f1a600](https://github.com/mozilla/DeepSpeech/commit/5f1a60014031c405bfc1aff2c5fb959b1e7192e2) into [9e67724](https://github.com/mozilla/DeepSpeech/commit/9e67724d39ff89f191f7052e653aaddac7c90b19) 2021-06-20T12:34:40.8676006Z ##[endgroup] 2021-06-20T12:34:40.8676682Z [command]/usr/bin/git log -1 --format='%H' 2021-06-20T12:34:40.8677557Z '6f9dee7bfee62e87a15adab7271055a9a2c8da58' 2021-06-20T12:34:40.8864765Z ##[group]Run ./.github/actions/get_cache_key 2021-06-20T12:34:40.8865287Z with: 2021-06-20T12:34:40.8865690Z extras: 7 2021-06-20T12:34:40.8866092Z env: 2021-06-20T12:34:40.8866651Z CI_TASK_DIR: /home/runner/work/DeepSpeech/DeepSpeech 2021-06-20T12:34:40.8867442Z CI_ARTIFACTS_DIR: /home/runner/work/DeepSpeech/DeepSpeech/artifacts 2021-06-20T12:34:40.8868137Z MACOSX_DEPLOYMENT_TARGET: 10.10 2021-06-20T12:34:40.8868642Z CI_NODE_MODULES_NTH: 1 2021-06-20T12:34:40.8869150Z CI_MSYS_VERSION: MSYS_NT-10.0-17763 2021-06-20T12:34:40.8869719Z MSYS2_SHELL_PATH: D:\a_temp\msys\msys64\usr\bin 2021-06-20T12:34:40.8870247Z ##[endgroup] 2021-06-20T12:34:40.9374241Z ##[group]Run ./.github/actions/check_artifact_exists 2021-06-20T12:34:40.9374854Z with: 2021-06-20T12:34:40.9375587Z name: tensorflow-opt_Windows_23ad988fcde60fb01f9533e95004bbc4877a9143_7 2021-06-20T12:34:40.9377197Z github_token: *** 2021-06-20T12:34:40.9377766Z download: false 2021-06-20T12:34:40.9378302Z path: ./ 2021-06-20T12:34:40.9378784Z repo: hmen97/DeepSpeech 2021-06-20T12:34:40.9379322Z env: 2021-06-20T12:34:40.9379898Z CI_TASK_DIR: /home/runner/work/DeepSpeech/DeepSpeech 2021-06-20T12:34:40.9380732Z CI_ARTIFACTS_DIR: /home/runner/work/DeepSpeech/DeepSpeech/artifacts 2021-06-20T12:34:40.9381493Z MACOSX_DEPLOYMENT_TARGET: 10.10 2021-06-20T12:34:40.9382019Z CI_NODE_MODULES_NTH: 1 2021-06-20T12:34:40.9382602Z CI_MSYS_VERSION: MSYS_NT-10.0-17763 2021-06-20T12:34:40.9383198Z MSYS2_SHELL_PATH: D:\a_temp\msys\msys64\usr\bin 2021-06-20T12:34:40.9383772Z ##[endgroup] 2021-06-20T12:34:41.0056481Z ==> Repo: hmen97/DeepSpeech 2021-06-20T12:34:41.9702165Z ==> maybe goodRepoArtifacts: [] 2021-06-20T12:34:41.9703889Z ==> goodArtifacts: [] 2021-06-20T12:34:41.9705943Z ==> Artifact tensorflow-opt_Windows_23ad988fcde60fb01f9533e95004bbc4877a9143_7 missing 2021-06-20T12:34:41.9739080Z ==> download false 2021-06-20T12:34:41.9869993Z Post job cleanup._

The artifact is missing because previous builds expired after the 90 days, and your logs shows something is broken on Windows builds.

You need to investigate this, I can't do more.",hey checked successful pull like artifact missing run opt without actually running build test check artifact still maybe missing ref head merge fa command log group run group run name false path maybe artifact missing false post job artifact missing previous day something broken need investigate ca,issue,negative,negative,negative,negative,negative,negative
864808143,"> I tried to compile deepspeech on a Raspberry Pi running Ubuntu 20.04. The created wheel after building the Python bindings used an incorrect naming: `manylinux1_x86_64.whl` although it should be `linux_aarch64.whl`

We only support building those arch via cross-compilation. Your fix is for the binding only?",tried compile raspberry pi running wheel building python used incorrect naming although support building arch via fix binding,issue,negative,neutral,neutral,neutral,neutral,neutral
864632580,"Thanks for the report, this is a known issue when testing using transfer learning directly after training. You can stop the test and rerun it independently from the checkpoint and it should work.",thanks report known issue testing transfer learning directly training stop test rerun independently work,issue,negative,positive,positive,positive,positive,positive
864570153,"Hey @lissyx I checked the successful pull requests, looks like they were using an artifact, which is missing in my [run](https://pipelines.actions.githubusercontent.com/1JGGHXEsvQE9F2oxg64uTGkAHCoJy4UEnMxmIhj3HZPnBaUavA/_apis/pipelines/1/runs/90/signedlogcontent/3?urlExpires=2021-06-20T12%3A51%3A06.4877581Z&urlSigningMethod=HMACV1&urlSignature=RMj7DTgNYKn3oJdNp10Kn9hJEmccGbD4uIhZpGgu0Bk%3D), so this [Win|Build Tensorflow (opt)](https://github.com/hmen97/DeepSpeech/blob/9e67724d39ff89f191f7052e653aaddac7c90b19/.github/workflows/build-and-test.yml#L1211-L1255) is passed without actually running any of the build instructions in the test. Can you check if that artifact still exists in the CI_ARTIFACTS_DIR? or maybe there is some config I'm missing... here are some logs for ref...


*2021-06-20T12:34:40.8675106Z HEAD is now at 6f9dee7 Merge 5f1a60014031c405bfc1aff2c5fb959b1e7192e2 into 9e67724d39ff89f191f7052e653aaddac7c90b19
2021-06-20T12:34:40.8676006Z ##[endgroup]
2021-06-20T12:34:40.8676682Z [command]/usr/bin/git log -1 --format='%H'
2021-06-20T12:34:40.8677557Z '6f9dee7bfee62e87a15adab7271055a9a2c8da58'
2021-06-20T12:34:40.8864765Z ##[group]Run ./.github/actions/get_cache_key
2021-06-20T12:34:40.8865287Z with:
2021-06-20T12:34:40.8865690Z   extras: 7
2021-06-20T12:34:40.8866092Z env:
2021-06-20T12:34:40.8866651Z   CI_TASK_DIR: /home/runner/work/DeepSpeech/DeepSpeech
2021-06-20T12:34:40.8867442Z   CI_ARTIFACTS_DIR: /home/runner/work/DeepSpeech/DeepSpeech/artifacts
2021-06-20T12:34:40.8868137Z   MACOSX_DEPLOYMENT_TARGET: 10.10
2021-06-20T12:34:40.8868642Z   CI_NODE_MODULES_NTH: 1
2021-06-20T12:34:40.8869150Z   CI_MSYS_VERSION: MSYS_NT-10.0-17763
2021-06-20T12:34:40.8869719Z   MSYS2_SHELL_PATH: D:\a\_temp\msys\msys64\usr\bin
2021-06-20T12:34:40.8870247Z ##[endgroup]
2021-06-20T12:34:40.9374241Z ##[group]Run ./.github/actions/check_artifact_exists
2021-06-20T12:34:40.9374854Z with:
2021-06-20T12:34:40.9375587Z   name: tensorflow-opt_Windows_23ad988fcde60fb01f9533e95004bbc4877a9143_7
2021-06-20T12:34:40.9377197Z   github_token: ***
2021-06-20T12:34:40.9377766Z   download: false
2021-06-20T12:34:40.9378302Z   path: ./
2021-06-20T12:34:40.9378784Z   repo: hmen97/DeepSpeech
2021-06-20T12:34:40.9379322Z env:
2021-06-20T12:34:40.9379898Z   CI_TASK_DIR: /home/runner/work/DeepSpeech/DeepSpeech
2021-06-20T12:34:40.9380732Z   CI_ARTIFACTS_DIR: /home/runner/work/DeepSpeech/DeepSpeech/artifacts
2021-06-20T12:34:40.9381493Z   MACOSX_DEPLOYMENT_TARGET: 10.10
2021-06-20T12:34:40.9382019Z   CI_NODE_MODULES_NTH: 1
2021-06-20T12:34:40.9382602Z   CI_MSYS_VERSION: MSYS_NT-10.0-17763
2021-06-20T12:34:40.9383198Z   MSYS2_SHELL_PATH: D:\a\_temp\msys\msys64\usr\bin
2021-06-20T12:34:40.9383772Z ##[endgroup]
2021-06-20T12:34:41.0056481Z ==> Repo: hmen97/DeepSpeech
2021-06-20T12:34:41.9702165Z ==> maybe goodRepoArtifacts: []
2021-06-20T12:34:41.9703889Z ==> goodArtifacts: []
2021-06-20T12:34:41.9705943Z ==> Artifact tensorflow-opt_Windows_23ad988fcde60fb01f9533e95004bbc4877a9143_7 missing
2021-06-20T12:34:41.9739080Z ==> download false
2021-06-20T12:34:41.9869993Z Post job cleanup.*",hey checked successful pull like artifact missing run opt without actually running build test check artifact still maybe missing ref head merge command log group run group run name false path maybe artifact missing false post job cleanup,issue,negative,negative,neutral,neutral,negative,negative
863440934,"> @reuben , If silence is all zero deepspeech do not work ,
> eg for utterance ""Go back "" - > Deepspeech gives ""back""
> but if all zero silence of 100ms is added it agains gives back result as ""back""
> if we add random values from 0 to 255 for 100ms silence results comes perfecttly ""go back"".
> 
> Similarly thing audacity does it adds some short of dithering and with that suprisingly deepspeech
> works better.

How are you adding silence to the mic stream?",silence zero work utterance go back back zero silence added back result back add random silence come go back similarly thing audacity short work better silence stream,issue,negative,neutral,neutral,neutral,neutral,neutral
863212476,"Looks like you missed:
> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).

And you don't provide any info.",like support please use discourse provide,issue,positive,neutral,neutral,neutral,neutral,neutral
862842854,@erksch Can you share your deepspeech_ios.framework? Task Cluster seems to be gone and I'm not sure how to set up my own.,share task cluster gone sure set,issue,positive,positive,positive,positive,positive,positive
861817931,Please reach for support on Discourse or Matrix.,please reach support discourse matrix,issue,positive,neutral,neutral,neutral,neutral,neutral
861816776,"I'm really on a very tight schedule, Anyone who can help. I can provide me Telegram for them!",really tight schedule anyone help provide telegram,issue,negative,negative,negative,negative,negative,negative
861548765,"`AudioSpectrogram` and `MFCC` are manually exposed  to the TFLite runtime on our tensorflow fork, as much as I remember.",manually exposed fork much remember,issue,negative,positive,positive,positive,positive,positive
861548265,Please reach for support on Discourse.,please reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
861126666,"Depends on your audio file. If it's US English, it should have decent performance. I'm planning to use Wav2Vec2 later on for AutoSub. It has much better accuracy. ",audio file u decent performance use later much better accuracy,issue,negative,positive,positive,positive,positive,positive
861013789,@abhirooptalasila ty for reply. how good it is? i tested mozilla DeepSpeech  and its correctness were terrible for my speech :(,reply good tested correctness terrible speech,issue,negative,negative,negative,negative,negative,negative
859539217,"> May you please give me a link for that?

It is the first item you have when you file a new issue. ",may please give link first item file new issue,issue,negative,positive,positive,positive,positive,positive
859527544,May you please give me a link for that?,may please give link,issue,negative,neutral,neutral,neutral,neutral,neutral
859524257,Please use Discourse for reaching support.,please use discourse reaching support,issue,positive,neutral,neutral,neutral,neutral,neutral
859397715,"> > BTW, the original issue was about the CTC decoder python binding, not the DeepSpeech python binding
> 
> Yeah sorry for deviating, I got through a few levels of understanding because of that. Anyway please check this [pull request](https://github.com/hmen97/DeepSpeech/actions/runs/927502606). The [Win|Build Tensorflow (opt)](https://github.com/hmen97/DeepSpeech/blob/9e67724d39ff89f191f7052e653aaddac7c90b19/.github/workflows/build-and-test.yml#L1211-L1255) test is failing in master too, here are the [logs](https://github.com/hmen97/DeepSpeech/runs/2800099499?check_suite_focus=true), looks like Bazel isn't able to find some Visual C++ build tools.

I'm sorry but:
 - I dont have time to check PR on your repo, there might be too many changes i'm unaware of
 - I don't have time to investigate Bazel, Windows and GitHub Actions
 - Try and repro with an empty PR, if it fails the same way then something changed on GitHub Actions and I'm afraid you will have to debug that",original issue python binding python binding yeah sorry got understanding anyway please check pull request opt test failing master like able find visual build sorry dont time check might many unaware time investigate try empty way something afraid,issue,negative,negative,neutral,neutral,negative,negative
859390717,"> Thanks for clearing that up. Using `gcc-8`, i.e. adding
> 
> ```diff
> --- a/PKGBUILD
> +++ b/PKGBUILD
> @@ -35,2 +37,3 @@ export BAZEL_SH=/bin/bash
> +  export CC=""gcc-8""
>    ./configure
> ```
> 
> seems to work fine for now.

I'm assuming this means it is enough for you, closing the issue then.

If someone wants to send patches to support GCC-11 on the tensorflow side, it is welcome to file a new issue.",thanks clearing export export work fine assuming enough issue someone send support side welcome file new issue,issue,positive,positive,positive,positive,positive,positive
859390641,"> BTW, the original issue was about the CTC decoder python binding, not the DeepSpeech python binding 

Yeah sorry for deviating, I got through a few levels of understanding because of that. Anyway please check this [pull request](https://github.com/hmen97/DeepSpeech/actions/runs/927502606). The [Win|Build Tensorflow (opt)](https://github.com/hmen97/DeepSpeech/blob/9e67724d39ff89f191f7052e653aaddac7c90b19/.github/workflows/build-and-test.yml#L1211-L1255) test is failing in master too, here are the [logs](https://github.com/hmen97/DeepSpeech/runs/2800099499?check_suite_focus=true), looks like Bazel isn't able to find some Visual C++ build tools. ",original issue python binding python binding yeah sorry got understanding anyway please check pull request opt test failing master like able find visual build,issue,positive,positive,neutral,neutral,positive,positive
859319163,"> @lissyx
> When will the problem be fixed？

When someone can take a look at it? I'm not working anymore on DeepSpeech for a few weeks now. ",problem someone take look working,issue,negative,neutral,neutral,neutral,neutral,neutral
858558528,"BTW, the original issue was about the CTC decoder python binding, not the DeepSpeech python binding",original issue python binding python binding,issue,negative,positive,positive,positive,positive,positive
858521903,"> they are being set in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk and for example you can see the ones for linux/armv7 in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk#L72-L92

I followed the calls all the way to the native_client/python/Makefile , didn't notice the definitions.mk. Ok so I think I get it now, correct me if I'm wrong, you set the architecture to `linux_aarch64` [here](https://github.com/mozilla/DeepSpeech/blob/9e67724d39ff89f191f7052e653aaddac7c90b19/native_client/definitions.mk#L110) but since PyPi didn't have any `numpy` wheel for `aarch64`, it gets the wheel from [here](https://github.com/lissyx/deepspeech-python-wheels/tree/master/numpy) only supporting 1.14.2 or 1.17.0 for linux `aarch64` which also explains [this](https://github.com/hmen97/DeepSpeech/pull/2/checks?check_run_id=2781014642)

So based on the os and architecture, if I create another case for `Linux:aarch64` [here](https://github.com/mozilla/DeepSpeech/tree/master/.github/actions/numpy_vers), and change `linux_aarch64` to `manylinux2014_aarch64`, we will be using the PyPi supported wheels for numpy",set example see way notice think get correct wrong set architecture since wheel wheel supporting also based o architecture create another case change,issue,negative,negative,negative,negative,negative,negative
858488450,"> The build is done here https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/Makefile#L13 and you can see we depend on a lot of env variables
> 
> they are being set in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk and for example you can see the ones for linux/armv7 in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk#L72-L92

And as you can see, this is where we set some `PYTHON_` variables to properly cross-compile:
 - PYTHON_PATH
 - NUMPY_INCLUDE
 - PYTHON_SYSCONFIGDATA
 - PYTHON_PLATFORM_NAME",build done see depend lot set example see see set properly,issue,negative,neutral,neutral,neutral,neutral,neutral
858487588,"The build is done here https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/Makefile#L13 and you can see we depend on a lot of env variables

they are being set in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk and  for example you can see the ones for linux/armv7 in https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk#L72-L92",build done see depend lot set example see,issue,negative,neutral,neutral,neutral,neutral,neutral
858484498,"> Yeah I can do that, but I just need one clarification, the host system is a `ubuntu 20.04 x86_64` , the `arm7` and `aarch64` are mounts. When building python bindings I can only see is the `numpy` build and dep version being passed as params, how does the right wheel get selected in case of varying architectures?

I'm not sure I get your question. Python wheel are cross-compiled, as `libdeepspeech` is",yeah need one clarification host system arm building python see build version right wheel get selected case sure get question python wheel,issue,positive,positive,positive,positive,positive,positive
858475512,"> This is exactly what I was telling, you bumped linux minimal deps with no justifications, so the packages on https://github.com/lissyx/deepspeech-python-wheels built only for CI are not met

Oh yeah, I just bumped that up to the min numpy version from the versions in specific platform & instruction set combination. Will revert that to what it was before.

> Looks like now PyPi accepts aarch64 for wheels on linux. If you feel up to it, please
    file an issue to fix that
    add proper manylinux support to ensure we meet the requirements

Yeah I can do that, but I just need one clarification, the host system is a `ubuntu 20.04 x86_64` , the `arm7` and `aarch64` are mounts. When building python bindings I can only see is the `numpy` build and dep version being passed as params, how does the right wheel get selected in case of varying architectures?  ",exactly telling minimal built met oh yeah min version specific platform instruction set combination revert like feel please file issue fix add proper support ensure meet yeah need one clarification host system arm building python see build version right wheel get selected case,issue,positive,positive,neutral,neutral,positive,positive
857627474,"> > [](https://github.com/lissyx/deepspeech-python-wheels/blob/master/numpy/numpy-1.17.0-cp37-cp37m-linux_aarch64.whl)
> 
> `aarch64` wheels is complicated, the packages built are there for automation purpose only ; it is up to the users to handle the situation, because pypi does not accept `aarch64` wheels for linux

Looks like now PyPi accepts `aarch64` for wheels on linux. If you feel up to it, please:
 - file an issue to fix that
 - add proper `manylinux` support to ensure we meet the requirements",complicated built purpose handle situation accept like feel please file issue fix add proper support ensure meet,issue,positive,negative,negative,negative,negative,negative
857626441,"> I can run more tests to find the minimum stable version for each platform&py-version combination.

At some point, I think what should be done is using this to replace the hard-coded list as much as possible, instead. And have ways to reproduce what you did ; because so far, I only see versions being changed with nothing to justify, and breaking backward compat.",run find minimum stable version platform combination point think done replace list much possible instead way reproduce far see nothing justify breaking backward,issue,negative,positive,neutral,neutral,positive,positive
857625434,"So: https://github.com/hmen97/DeepSpeech/runs/2781014601?check_suite_focus=true#step:10:152

This is exactly what I was telling, you bumped linux minimal deps with no justifications, so the packages on https://github.com/lissyx/deepspeech-python-wheels built only for CI are not met.",exactly telling minimal built met,issue,negative,positive,neutral,neutral,positive,positive
857622749,"> > This change does not look super good at a first glance, you bump the minimal versions on many linux versions for example, this is going to break backward compatibility
> 
> Used this [repo](https://github.com/scipy/oldest-supported-numpy/blob/master/setup.cfg) for minimum recommended version of numpy. I can run more tests to find the minimum stable version for each platform&py-version combination.

nice repo, is this official? it seems to only focus on arm/aarch64 though

it still does not explain why you push everything with a bare minimum of `1.19.x` on linux for example

> 
> > I can't give any definitive answer only from that line, I need to know how you repro that ...
> 
> I just changed the numpy versions in .github/actions/numpy_vers/action.yml and in github/workflows/build-and-test.yml I added [python versions in the build ctc decoder matrix strategy](https://github.com/hmen97/DeepSpeech/commit/f011f96977f66985794666acc0b9424ffdb713b3#diff-bc668a2c9f2299cef15b222055b4b4d5311646caec2e7610e540cee18ae9b948). On creating a pull request to my forked master branch, the checks are triggered. Basically was checking how everything works, or rather where and why it breaks for different versions.

Please give me a link to the errors ?

> 
> > Those prebuilt wheels were for Aarch64 only. Without context, I have no idea what you are doing
> 
> My bad the wheels are already present [here](https://pypi.org/simple), when I checked it was down yesterday probably because of the outage. But let's say we need a lower version of aarch64 numpy wheel, do we stick to what numpy has wheels for(1.19.2 onwards) or build our own like you [did](https://github.com/lissyx/deepspeech-python-wheels/blob/master/numpy/numpy-1.17.0-cp37-cp37m-linux_aarch64.whl)

`aarch64` wheels is complicated, the packages built are there for automation purpose only ; it is up to the users to handle the situation, because pypi does not accept `aarch64` wheels for linux",change look super good first glance bump minimal many example going break backward compatibility used minimum version run find minimum stable version platform combination nice official focus though still explain push everything bare minimum example ca give definitive answer line need know added python build matrix strategy pull request forked master branch triggered basically everything work rather different please give link without context idea bad already present checked yesterday probably outage let say need lower version wheel stick onwards build like complicated built purpose handle situation accept,issue,positive,positive,positive,positive,positive,positive
857613896,"> This change does not look super good at a first glance, you bump the minimal versions on many linux versions for example, this is going to break backward compatibility

Used this [repo](https://github.com/scipy/oldest-supported-numpy/blob/master/setup.cfg) for minimum recommended version of numpy. I can run more tests to find the minimum stable version for each platform&py-version combination. 

> I can't give any definitive answer only from that line, I need to know how you repro that ...

I just changed the numpy versions in .github/actions/numpy_vers/action.yml and in github/workflows/build-and-test.yml I added [python versions in the build ctc decoder matrix strategy](https://github.com/hmen97/DeepSpeech/commit/f011f96977f66985794666acc0b9424ffdb713b3#diff-bc668a2c9f2299cef15b222055b4b4d5311646caec2e7610e540cee18ae9b948). On creating a pull request to my forked master branch, the checks are triggered. Basically was checking how everything works, or rather where and why it breaks for different versions.

> Those prebuilt wheels were for Aarch64 only. Without context, I have no idea what you are doing

My bad the wheels are already present [here](https://pypi.org/simple), when I checked it was down yesterday probably because of the outage. But let's say we need a lower version of aarch64 numpy wheel, do we stick to what numpy has wheels for(1.19.2 onwards) or build our own like you [did](https://github.com/lissyx/deepspeech-python-wheels/blob/master/numpy/numpy-1.17.0-cp37-cp37m-linux_aarch64.whl)",change look super good first glance bump minimal many example going break backward compatibility used minimum version run find minimum stable version platform combination ca give definitive answer line need know added python build matrix strategy pull request forked master branch triggered basically everything work rather different without context idea bad already present checked yesterday probably outage let say need lower version wheel stick onwards build like,issue,positive,positive,positive,positive,positive,positive
857490252,"> @lissyx I went through this thread, spent some time looking at github actions, came up with this pull request [hmen97#2](https://github.com/hmen97/DeepSpeech/pull/2).

This change does not look super good at a first glance, you bump the minimal versions on many linux versions for example, this is going to break backward compatibility

> 
> CTC decoder has been built for
> 
>     * [3.6, 3.7, 3.8, 3.9] build-ctc-decoder-Linux
> 
>     * [3.6.8, 3.7.9, 3.8.8, 3.9.2] build-ctc-decoder-Windows
> 
>     * [3.6.8, 3.7.9, 3.8.8, 3.9.2] build-ctc-decoder-macos
> 
> 
> The test python bindings step for each platform is running into an error or being skipped, logs below:
> 
> `Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple, https://lissyx.github.io/deepspeech-python-wheels/ Processing /home/runner/work/DeepSpeech/DeepSpeech/tmp/deepspeech_tflite-0.10.0a3-cp37-cp37m-linux_aarch64.whl Collecting numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3) Could not find a version that satisfies the requirement numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3) (from versions: 1.17.0) No matching distribution found for numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3)`

I can't give any definitive answer only from that line, I need to know how you repro that ...

> 
> Will it be solved if I add the required prebuilt numpy wheel from pypi(for each python version) in this [project](https://github.com/lissyx/deepspeech-python-wheels) or does some other change have to be made while saving artifacts?

Those prebuilt wheels were for Aarch64 only. Without context, I have no idea what you are doing.",went thread spent time looking came pull request change look super good first glance bump minimal many example going break backward compatibility built test python step platform running error looking could find version requirement matching distribution found ca give definitive answer line need know add wheel python version project change made saving without context idea,issue,positive,positive,positive,positive,positive,positive
857466143,"@lissyx  I went through this thread, spent some time looking at github actions, came up with this pull request [hmen97#2](https://github.com/hmen97/DeepSpeech/pull/2).

CTC decoder has been built for 
- [3.6, 3.7, 3.8, 3.9] build-ctc-decoder-Linux
- [3.6.8, 3.7.9, 3.8.8, 3.9.2] build-ctc-decoder-Windows
- [3.6.8, 3.7.9, 3.8.8, 3.9.2] build-ctc-decoder-macos

The test python bindings step for each platform is running into an error or being skipped, logs below:

`Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple, https://lissyx.github.io/deepspeech-python-wheels/
Processing /home/runner/work/DeepSpeech/DeepSpeech/tmp/deepspeech_tflite-0.10.0a3-cp37-cp37m-linux_aarch64.whl
Collecting numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3)
  Could not find a version that satisfies the requirement numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3) (from versions: 1.17.0)
No matching distribution found for numpy>=1.19.3 (from deepspeech-tflite==0.10.0a3)`

Will it be solved if I add the required prebuilt numpy wheel from pypi(for each python version) in this [project](https://github.com/lissyx/deepspeech-python-wheels) or does some other change have to be made while saving artifacts?",went thread spent time looking came pull request built test python step platform running error looking could find version requirement matching distribution found add wheel python version project change made saving,issue,negative,negative,neutral,neutral,negative,negative
853640797,i try `sudo apt-get install libsox-fmt-mp3` in terminal . it work,try install terminal work,issue,negative,neutral,neutral,neutral,neutral,neutral
851530164,"Thanks for clearing that up. Using `gcc-8`, i.e. adding

```diff
--- a/PKGBUILD
+++ b/PKGBUILD
@@ -35,2 +37,3 @@ export BAZEL_SH=/bin/bash
+  export CC=""gcc-8""
   ./configure
```

seems to work fine for now.",thanks clearing export export work fine,issue,positive,positive,positive,positive,positive,positive
851521619,"> gcc 11



I dont think this is supported by TensorFlow r2.3: https://github.com/mozilla/tensorflow/tree/r2.3

> Since it isn't immediately clear to me what the purpose of https://github.com/mozilla/tensorflow is, I have _not_ yet tried compiling with a different version of tensorflow.

As documented, this fork contains specific changes required to either fix build issues similar to yours, or fix upstream issues that have not yet been upstreamed, or specific hacking/tuning we require. Do not try to attempt to build with another version.",dont think since immediately clear purpose yet tried different version fork specific either fix build similar fix upstream yet specific require try attempt build another version,issue,negative,positive,neutral,neutral,positive,positive
850368771,"> How does Deep Speech run on a Raspberry Pi 4 which uses an Arm CPU (100% doesn't support AVX).

Your question does not even make any sense ; it's not the same code that is being ran by `libdeepspeech.so` on ARM CPUs than on Intel/AMD x86-64 CPUs.

As documented, AVX is required for the prebuilt binaries, for performance reasons. Chances are if you CPU does not support AVX it's anyway too slow to perform decently on this task, but you can always rebuild.

Next time:
 - read the doc
 - read the code
 - ask for support on discourse",deep speech run raspberry pi arm support question even make sense code ran arm performance support anyway slow perform decently task always rebuild next time read doc read code ask support discourse,issue,positive,negative,neutral,neutral,negative,negative
850366921,"> in case my PC don’t support AVX

You will have to rebuild `libdeepspeech.so`, it is documented our binaries requires it. Performances cannot be the same without AVX.",case support rebuild without,issue,negative,neutral,neutral,neutral,neutral,neutral
850365875,Second time you are purposedly not opening a support request on Discourse but on Github.,second time purposedly opening support request discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
849680688,"This is a support request, please use Discourse.",support request please use discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
848705248,"I resolved the error by installing C++ build tools 2015. I also installed python on the console which showed me what i was missing such as the build tools and python.

Still the sample is crashing and causing all kinds of issues.
I will try to use the nuget package and follow the API document to replicate it myself. 
",resolved error build also python console missing build python still sample causing try use package follow document replicate,issue,negative,negative,negative,negative,negative,negative
847274158,"I am getting the error:
`System.DllNotFoundException: 'Unable to load DLL 'libdeepspeech.so' or one of its dependencies: The specified module could not be found. (Exception from HRESULT: 0x8007007E)'
`
Can someone please guide me to how can i get 'libdeepspeech.so'? The documentation says that the binaries are already provided but i couldn't find this DLL anywhere.",getting error load one module could found exception someone please guide get documentation already provided could find anywhere,issue,negative,neutral,neutral,neutral,neutral,neutral
846590972,"I'm not knowledgeable around iOS work, and i'm not working anymore on this project, so i cant really give a definitive  answer, i dont even know what is cocoapods. But i think having everything in the main repo is best.

However, as you can see and as ive replied elsewhere, we moved ci out of taskcluster to github actions, and the iOS part is still to be done. 

Part of the move is to make it easier for contributors, so we hope it would make you able to send pr for this 😉",knowledgeable around work working project cant really give definitive answer dont even know think everything main best however see elsewhere part still done part move make easier hope would make able send,issue,positive,positive,positive,positive,positive,positive
846589555,"Taskcluster has been decommissioned, you would need to add github actions support for iOS bindings. ",would need add support,issue,negative,neutral,neutral,neutral,neutral,neutral
846565714,"Just came back to this and saw that there are no artifacts from the task cluster that have run the `BUILD_LIBRARY_FOR_DISTRIBUTION=YES` configuration, I think. Is there a build available that was run with that configuration? Otherwise, a new alpha on master would be very helpful.",came back saw task cluster run configuration think build available run configuration otherwise new alpha master would helpful,issue,negative,positive,positive,positive,positive,positive
846470348,Hi @lissyx I'd like to pick this up. Can you let me know how to get started?,hi like pick let know get,issue,negative,neutral,neutral,neutral,neutral,neutral
844879550,"> @lissyx how I can handle this issue??

Stop responding on github issues, you have already started a thread on Discourse.",handle issue stop already thread discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
844714149,"Thanks for your attention @ftyers actually I faced the problem while I was training DeepSpeech for Persian language. Reduce on Plateau may drive the model to higher points of the parameters space, because it takes time to detect the plateau. While scheduling learning rate according to epoch makes more sense, because as training goes forward, we need less oscillation in parameters and thus reducing learning rate can help a lot in this approach. 
On the other hand, this feature is provided in famous frameworks, e.g. Tensorflow and PyTorch, so I was thinking why not in DeepSpeech?! 
At last, it is easy to work with the parameter because of its pythonic format. It is a compact form of nested if else blocks while because it will get evaluated during the running, you are able to use any python function inside the learning rate scheduler parameter.",thanks attention actually faced problem training language reduce plateau may drive model higher space time detect plateau learning rate according epoch sense training go forward need le oscillation thus reducing learning rate help lot approach hand feature provided famous thinking last easy work parameter pythonic format compact form else get running able use python function inside learning rate parameter,issue,positive,positive,positive,positive,positive,positive
843839866,"@zackees Please take that to Discourse, there were already multiple reports that were unactionable on that issue, looks like you might be able to investigate it more.",please take discourse already multiple issue like might able investigate,issue,positive,positive,positive,positive,positive,positive
843810337,"I investigated this more.

I installed the DUMPBIN tool from the VS toolset and ran `DUMPBIN /imports libdeepspeech.so`

And found the following dependencies:


```
    ""USERENV.dll"",
    ""VERSION.dll"",
    ""ADVAPI32.dll"",
    ""WS2_32.dll"",
    ""CRYPT32.dll"",
    ""Normaliz.dll"",
    ""dbghelp.dll"",
    ""MSVCP140.dll"",
    ""SHLWAPI.dll"",
    ""KERNEL32.dll"",
    ""VCRUNTIME140.dll"",
    ""VCRUNTIME140_1.dll"",
    ""api-ms-win-crt-runtime-l1-1-0.dll"",
    ""api-ms-win-crt-heap-l1-1-0.dll"",
    ""api-ms-win-crt-utility-l1-1-0.dll"",
    ""api-ms-win-crt-math-l1-1-0.dll"",
    ""api-ms-win-crt-stdio-l1-1-0.dll"",
    ""api-ms-win-crt-filesystem-l1-1-0.dll"",
    ""api-ms-win-crt-convert-l1-1-0.dll"",
    ""api-ms-win-crt-string-l1-1-0.dll"",
    ""api-ms-win-crt-environment-l1-1-0.dll"",
    ""api-ms-win-crt-time-l1-1-0.dll"",
```

I then tested each library to see if it can be loaded before the libdeepspeech.so file is found:

```
import signal
import ctypes
import os

HERE = os.path.abspath(os.path.dirname(__file__))

assert os.path.exists(HERE)

dlls = [
    ""USERENV.dll"",
    ""VERSION.dll"",
    ""ADVAPI32.dll"",
    ""WS2_32.dll"",
    ""CRYPT32.dll"",
    ""Normaliz.dll"",
    ""dbghelp.dll"",
    ""MSVCP140.dll"",
    ""SHLWAPI.dll"",
    ""KERNEL32.dll"",
    ""VCRUNTIME140.dll"",
    ""VCRUNTIME140_1.dll"",
    ""api-ms-win-crt-runtime-l1-1-0.dll"",
    ""api-ms-win-crt-heap-l1-1-0.dll"",
    ""api-ms-win-crt-utility-l1-1-0.dll"",
    ""api-ms-win-crt-math-l1-1-0.dll"",
    ""api-ms-win-crt-stdio-l1-1-0.dll"",
    ""api-ms-win-crt-filesystem-l1-1-0.dll"",
    ""api-ms-win-crt-convert-l1-1-0.dll"",
    ""api-ms-win-crt-string-l1-1-0.dll"",
    ""api-ms-win-crt-environment-l1-1-0.dll"",
    ""api-ms-win-crt-time-l1-1-0.dll"",
]

for dll in dlls:
    try:
        print('Loading: ', ctypes.windll.LoadLibrary(dll))
    except OSError as err:
        print(f'Error while processing {dll} because of {err}')

print(""\nFinished loading windows dlls"")


so_path=os.path.join(HERE,'venv', 'Lib', 'site-packages', 'deepspeech', 'lib', 'libdeepspeech.so')
assert os.path.exists(so_path), f'could not find {so_path}'
ctypes.CDLL(os.path.abspath(so_path))
```

Surprisingly, every dll file was successfully loaded just fine.


",tool ran found following tested library see loaded file found import signal import import o assert try print except err print err print loading assert find surprisingly every file successfully loaded fine,issue,positive,positive,positive,positive,positive,positive
843774360,"Indeed, the libdeepspeech.so file is being loaded on windows. It is actually failing inside the code.

Example:

```
import ctypes
import os

HERE = os.path.abspath(os.path.dirname(__file__))
assert os.path.exists(HERE)
so_path=os.path.join(HERE,'venv', 'Lib', 'site-packages', 'deepspeech', 'lib', 'libdeepspeech.so')
assert os.path.exists(so_path), f'could not find {so_path}'
ctypes.CDLL(os.path.abspath(so_path))
```

Output (On broken machine):

```
Traceback (most recent call last):
  File ""loadlib.py"", line 9, in <module>
    ctypes.CDLL(os.path.abspath(so_path))
  File ""c:\users\niteris\appdata\local\programs\python\python38\lib\ctypes\__init__.py"", line 369, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 1114] A dynamic link library (DLL) initialization routine failed
```


Output (On working machine):
```
<CDLL 'C:\Users\zachv\Programming\transcribe-anything\venv\Lib\site-packages\deepspeech\lib\libdeepspeech.so', handle 7ff8c2400000 at 0x24f8ec7d6d0>
```

",indeed file loaded actually failing inside code example import import o assert assert find output broken machine recent call last file line module file line mode dynamic link library routine output working machine handle,issue,negative,negative,neutral,neutral,negative,negative
842473862,"Thanks @soroushhashemifar could you give some details about how you imagine this should be used and how the ""reduce on plateau"" functionality doesn't solve this already?",thanks could give imagine used reduce plateau functionality solve already,issue,positive,positive,positive,positive,positive,positive
842113289,"@Oo121oO The Mandarin model is released as experimental, and the android code you are running is really only meant for running CI, it has not been tested with Mandarin input.",mandarin model experimental android code running really meant running tested mandarin input,issue,negative,positive,positive,positive,positive,positive
839740344,"> Hello @lissyx Sir are you free to guide me now for this ? Please

I have already explained to you, I can't explain more if you don't tell precisely what you don't understand.
You need to find the existing wheels for that platform that are ABI compatible and available for the matching python version",hello sir free guide please already ca explain tell precisely understand need find platform compatible available matching python version,issue,positive,positive,positive,positive,positive,positive
835151014,Please ask support on Discourse. There's a thread with links to models. ,please ask support discourse thread link,issue,positive,neutral,neutral,neutral,neutral,neutral
832173606,"@lissyx , Yes Sir that we have to avoid having to rebuild numpy so we stick to versions where there is an existing upstream wheel file.",yes sir avoid rebuild stick upstream wheel file,issue,negative,neutral,neutral,neutral,neutral,neutral
831909951,"> > > > > > > > > > Sir @lissyx ?
> > > > > > > > > 
> > > > > > > > > 
> > > > > > > > > It looks good but I don't see any CI run ?
> > > > > > > > 
> > > > > > > > 
> > > > > > > > Sir, Can you approve the PR which was made against the Original Repo.
> > > > > > > > then I think it will run
> > > > > > > 
> > > > > > > 
> > > > > > > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> > > > > > 
> > > > > > 
> > > > > > Sir, Everything is looking fine my side.
> > > > > > I have added python version with matrix and changed versions of python that's it.
> > > > > 
> > > > > 
> > > > > No, it is not:
> > > > > ```
> > > > > * [Ayushsunny#2](https://github.com/Ayushsunny/DeepSpeech/pull/2) does not show any build and tests running
> > > > > 
> > > > > * https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: ` The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`
> > > > > ```
> > > > 
> > > > 
> > > > Sir, even after updating as you've said, it's again throwing error something like that `installer: Error - the package path specified was invalid: 'python.pkg'.` [here](https://github.com/Ayushsunny/DeepSpeech/runs/2491999522?check_suite_focus=true)
> > > 
> > > 
> > > This is specific to macOS that does not use the same action. You need three-digits versions number for it.
> > 
> > 
> > Hello Sir, I'm bothering you too much today see again it throws some new error which was not added by me https://github.com/Ayushsunny/DeepSpeech/runs/2492609550?check_suite_focus=true
> 
> it is failing because trying to rebuild `numpy`
> 
> Please investigate what versions of numpy provides a wheel on pypi that works for python 3.8 and then update the env variables `NUMPY_BUILD_VERSION` / `NUMPY_DEP_VERSION` in https://github.com/mozilla/DeepSpeech/blob/master/.github/actions/numpy_vers/action.yml

Sir, I have tried to find out every solution for this but I am not able to.

are we going to add this version ??
![Screenshot from 2021-05-04 18-08-20](https://user-images.githubusercontent.com/73520373/117004580-d67dae00-ad03-11eb-9676-d4d044b89e7f.png)
",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence sir even said throwing error something like installer error package path invalid specific use action need number hello sir much today see new error added failing trying rebuild please investigate wheel work python update sir tried find every solution able going add version,issue,negative,positive,positive,positive,positive,positive
831318495,"> > > > > > > > > Sir @lissyx ?
> > > > > > > > 
> > > > > > > > 
> > > > > > > > It looks good but I don't see any CI run ?
> > > > > > > 
> > > > > > > 
> > > > > > > Sir, Can you approve the PR which was made against the Original Repo.
> > > > > > > then I think it will run
> > > > > > 
> > > > > > 
> > > > > > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> > > > > 
> > > > > 
> > > > > Sir, Everything is looking fine my side.
> > > > > I have added python version with matrix and changed versions of python that's it.
> > > > 
> > > > 
> > > > No, it is not:
> > > > ```
> > > > * [Ayushsunny#2](https://github.com/Ayushsunny/DeepSpeech/pull/2) does not show any build and tests running
> > > > 
> > > > * https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: ` The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`
> > > > ```
> > > 
> > > 
> > > Sir, even after updating as you've said, it's again throwing error something like that `installer: Error - the package path specified was invalid: 'python.pkg'.` [here](https://github.com/Ayushsunny/DeepSpeech/runs/2491999522?check_suite_focus=true)
> > 
> > 
> > This is specific to macOS that does not use the same action. You need three-digits versions number for it.
> 
> Hello Sir, I'm bothering you too much today see again it throws some new error which was not added by me https://github.com/Ayushsunny/DeepSpeech/runs/2492609550?check_suite_focus=true

it is failing because trying to rebuild `numpy`

Please investigate what versions of numpy provides a wheel on pypi that works for python 3.8 and then update the env variables `NUMPY_BUILD_VERSION` / `NUMPY_DEP_VERSION` in https://github.com/mozilla/DeepSpeech/blob/master/.github/actions/numpy_vers/action.yml",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence sir even said throwing error something like installer error package path invalid specific use action need number hello sir much today see new error added failing trying rebuild please investigate wheel work python update,issue,negative,positive,positive,positive,positive,positive
831302018,"> > > > > > > > Sir @lissyx ?
> > > > > > > 
> > > > > > > 
> > > > > > > It looks good but I don't see any CI run ?
> > > > > > 
> > > > > > 
> > > > > > Sir, Can you approve the PR which was made against the Original Repo.
> > > > > > then I think it will run
> > > > > 
> > > > > 
> > > > > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> > > > 
> > > > 
> > > > Sir, Everything is looking fine my side.
> > > > I have added python version with matrix and changed versions of python that's it.
> > > 
> > > 
> > > No, it is not:
> > > ```
> > > * [Ayushsunny#2](https://github.com/Ayushsunny/DeepSpeech/pull/2) does not show any build and tests running
> > > 
> > > * https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: ` The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`
> > > ```
> > 
> > 
> > Sir, even after updating as you've said, it's again throwing error something like that `installer: Error - the package path specified was invalid: 'python.pkg'.` [here](https://github.com/Ayushsunny/DeepSpeech/runs/2491999522?check_suite_focus=true)
> 
> This is specific to macOS that does not use the same action. You need three-digits versions number for it.

Hello Sir, I'm bothering you too much today see again it throws some new error which was not added by me https://github.com/Ayushsunny/DeepSpeech/runs/2492609550?check_suite_focus=true",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence sir even said throwing error something like installer error package path invalid specific use action need number hello sir much today see new error added,issue,negative,positive,positive,positive,positive,positive
831283244,"Hi @lissyx
I see your points / thanks for details.
I left the issue open. At least I propose to update this doc  https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/README.md with a reference to the current issue. Or I'd update the current public npm package version 0.9.3 ",hi see thanks left issue open least propose update doc reference current issue update current public package version,issue,negative,negative,neutral,neutral,negative,negative
831261928,"> > > > > > > Sir @lissyx ?
> > > > > > 
> > > > > > 
> > > > > > It looks good but I don't see any CI run ?
> > > > > 
> > > > > 
> > > > > Sir, Can you approve the PR which was made against the Original Repo.
> > > > > then I think it will run
> > > > 
> > > > 
> > > > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> > > 
> > > 
> > > Sir, Everything is looking fine my side.
> > > I have added python version with matrix and changed versions of python that's it.
> > 
> > 
> > No, it is not:
> > ```
> > * [Ayushsunny#2](https://github.com/Ayushsunny/DeepSpeech/pull/2) does not show any build and tests running
> > 
> > * https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: ` The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`
> > ```
> 
> Sir, even after updating as you've said, it's again throwing error something like that `installer: Error - the package path specified was invalid: 'python.pkg'.` [here](https://github.com/Ayushsunny/DeepSpeech/runs/2491999522?check_suite_focus=true)

This is specific to macOS that does not use the same action. You need three-digits versions number for it.",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence sir even said throwing error something like installer error package path invalid specific use action need number,issue,negative,positive,positive,positive,positive,positive
831261180,"> > > > > > Sir @lissyx ?
> > > > > 
> > > > > 
> > > > > It looks good but I don't see any CI run ?
> > > > 
> > > > 
> > > > Sir, Can you approve the PR which was made against the Original Repo.
> > > > then I think it will run
> > > 
> > > 
> > > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> > 
> > 
> > Sir, Everything is looking fine my side.
> > I have added python version with matrix and changed versions of python that's it.
> 
> No, it is not:
> 
>     * [Ayushsunny#2](https://github.com/Ayushsunny/DeepSpeech/pull/2) does not show any build and tests running
> 
>     * https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: ` The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`


Sir, even after updating as you've said, it's again throwing error something like that `installer: Error - the package path specified was invalid: 'python.pkg'.`  [here](https://github.com/Ayushsunny/DeepSpeech/runs/2491999522?check_suite_focus=true)",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence sir even said throwing error something like installer error package path invalid,issue,negative,positive,positive,positive,positive,positive
831221228,"> > > > > Sir @lissyx ?
> > > > 
> > > > 
> > > > It looks good but I don't see any CI run ?
> > > 
> > > 
> > > Sir, Can you approve the PR which was made against the Original Repo.
> > > then I think it will run
> > 
> > 
> > No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.
> 
> Sir, Everything is looking fine my side.
> I have added python version with matrix and changed versions of python that's it.

No, it is not:
 - https://github.com/Ayushsunny/DeepSpeech/pull/2 does not show any build and tests running
 - https://github.com/Ayushsunny/DeepSpeech/actions/runs/793109099 shows failure: `
The workflow is not valid. .github/workflows/build-and-test.yml (Line: 169, Col: 27): A sequence was not expected .github/workflows/build-and-test.yml (Line: 710, Col: 27): A sequence was not expected`",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python show build running failure valid line col sequence line col sequence,issue,positive,positive,positive,positive,positive,positive
831220457,"> > > > Sir @lissyx ?
> > > 
> > > 
> > > It looks good but I don't see any CI run ?
> > 
> > 
> > Sir, Can you approve the PR which was made against the Original Repo.
> > then I think it will run
> 
> No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.

Sir, Everything is looking fine my side.
I have added python version with matrix and changed versions of python that's it.",sir good see run sir approve made original think run already working please look page fix sir everything looking fine side added python version matrix python,issue,positive,positive,positive,positive,positive,positive
831199888,"> > > Sir @lissyx ?
> > 
> > 
> > It looks good but I don't see any CI run ?
> 
> Sir, Can you approve the PR which was made against the Original Repo.
> then I think it will run

No, it is already NOT working on your own repo, please have a look at your `Actions` page, you have errors to fix.",sir good see run sir approve made original think run already working please look page fix,issue,positive,positive,positive,positive,positive,positive
831182354,"> > Sir @lissyx ?
> 
> It looks good but I don't see any CI run ?

Sir, Can you approve the PR which was made against the Original Repo.
then I think it will run",sir good see run sir approve made original think run,issue,positive,positive,positive,positive,positive,positive
831175172,"> Sir @lissyx ?

It looks good but I don't see any CI run ?",sir good see run,issue,negative,positive,positive,positive,positive,positive
831173832,"@solyarisoftware The move to GitHub Actions was to make it easier for contributor to actually contribute, please read https://mozilla.github.io/deepspeech-playbook/CONTINUOUS_INTEGRATION.html",move make easier contributor actually contribute please read,issue,positive,neutral,neutral,neutral,neutral,neutral
831173428,"@solyarisoftware There is no support for NodeJS v16 on the uploaded packages. Current packages on master have it but:
 - GitHub Actions support only covers linux (amd64, armv7, aarch64), windows (amd64), macOS (amd64)
 - Unfortunaly, unlike TaskCluster, we don't have the ability to access unauthenticated to the build artifacts
 - There is no support for publishing new releases (#3606)
 - TaskCluster infra has been completely decomissionned, so producing a 0.9.4 is impossible.

If you are willing to try and help, you are more than welcome. A good first item would be #3606 in your case.

Try and see if you can get `deepspeech-tf.tgz` or `deepspeech-tflite.tgz` from the last run: https://github.com/mozilla/DeepSpeech/actions/runs/793741932",support current master support unlike ability access unauthenticated build support new infra completely impossible willing try help welcome good first item would case try see get last run,issue,positive,positive,positive,positive,positive,positive
829065893,"Hello @reuben, @lissyx and @carlfm01 
I see this issue is closed for a few months now, but I'm experiencing the very same problem here: I create a new .NET Core 3.1 console project in Visual Studio (details further on), copy Program.cs from the examples and get a [compiler error CS0246](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-messages/cs0246?f1url=%3FappId%3Droslyn%26k%3Dk(CS0246)) (missing reference).

I am far from being an expert using VS, maybe I am doing something wrong.

- Here the details of my VS instance:
Microsoft Visual Studio Enterprise 2019
Version 16.9.2
VisualStudio.16.Release/16.9.2+31112.23
Microsoft .NET Framework
Version 4.8.03752

Installed Version: Enterprise

Architecture Diagrams and Analysis Tools   00433-90050-55344-AA737
Microsoft Architecture Diagrams and Analysis Tools

Visual C++ 2019   00433-90050-55344-AA737
Microsoft Visual C++ 2019

.NET Core Debugging with WSL 2   1.0
.NET Core Debugging with WSL 2

ADL Tools Service Provider   1.0
This package contains services used by Data Lake tools

ASA Service Provider   1.0

ASP.NET and Web Tools 2019   16.9.688.6828
ASP.NET and Web Tools 2019

ASP.NET Core Razor Language Services   16.1.0.2112521+5741df381174d72f08e3632bb99f52e8635b6a1a
Provides languages services for ASP.NET Core Razor.

ASP.NET Web Frameworks and Tools 2019   16.9.688.6828
For additional information, visit https://www.asp.net/

Azure App Service Tools v3.0.0   16.9.688.6828
Azure App Service Tools v3.0.0

Azure Data Lake Node   1.0
This package contains the Data Lake integration nodes for Server Explorer.

Azure Data Lake Tools for Visual Studio   2.6.1000.0
Microsoft Azure Data Lake Tools for Visual Studio

Azure Functions and Web Jobs Tools   16.9.688.6828
Azure Functions and Web Jobs Tools

Azure Stream Analytics Tools for Visual Studio   2.6.1000.0
Microsoft Azure Stream Analytics Tools for Visual Studio

C# Tools   3.9.0-6.21160.10+59eedc33d35754759994155ea2f4e1012a9951e3
C# components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Common Azure Tools   1.10
Provides common services for use by Azure Mobile Services and Microsoft Azure Tools.

Cookiecutter   16.9.21026.1
Provides tools for finding, instantiating and customizing templates in cookiecutter format.

Extensibility Message Bus   1.2.6 (master@34d6af2)
Provides common messaging-based MEF services for loosely coupled Visual Studio extension components communication and integration.

Fabric.DiagnosticEvents   1.0
Fabric Diagnostic Events

GitHub.VisualStudio   2.11.102.28613
A Visual Studio Extension that brings the GitHub Flow into Visual Studio.

IntelliCode Extension   1.0
IntelliCode Visual Studio Extension Detailed Info

Linux Core Dump Debugging   1.0.9.31112
Enables debugging of Linux core dumps.

Microsoft Azure HDInsight Azure Node   2.6.1000.0
HDInsight Node under Azure Node

Microsoft Azure Hive Query Language Service   2.6.1000.0
Language service for Hive query

Microsoft Azure Service Fabric Tools for Visual Studio   16.0
Microsoft Azure Service Fabric Tools for Visual Studio

Microsoft Azure Stream Analytics Language Service   2.6.1000.0
Language service for Azure Stream Analytics

Microsoft Azure Stream Analytics Node   1.0
Azure Stream Analytics Node under Azure Node

Microsoft Azure Tools   2.9
Microsoft Azure Tools for Microsoft Visual Studio 2019 - v2.9.40218.1

Microsoft Continuous Delivery Tools for Visual Studio   0.4
Simplifying the configuration of Azure DevOps pipelines from within the Visual Studio IDE.

Microsoft JVM Debugger   1.0
Provides support for connecting the Visual Studio debugger to JDWP compatible Java Virtual Machines

Microsoft Library Manager   2.1.113+g422d40002e.RR
Install client-side libraries easily to any web project

Microsoft MI-Based Debugger   1.0
Provides support for connecting Visual Studio to MI compatible debuggers

Microsoft Visual C++ Wizards   1.0
Microsoft Visual C++ Wizards

Microsoft Visual Studio Tools for Containers   1.1
Develop, run, validate your ASP.NET Core applications in the target environment. F5 your application directly into a container with debugging, or CTRL + F5 to edit & refresh your app without having to rebuild the container.

Microsoft Visual Studio VC Package   1.0
Microsoft Visual Studio VC Package

Mono Debugging for Visual Studio   16.9.7 (df23ba6)
Support for debugging Mono processes with Visual Studio.

NuGet Package Manager   5.9.0
NuGet Package Manager in Visual Studio. For more information about NuGet, visit https://docs.nuget.org/

ProjectServicesPackage Extension   1.0
ProjectServicesPackage Visual Studio Extension Detailed Info

Python   16.9.21026.1
Provides IntelliSense, projects, templates, debugging, interactive windows, and other support for Python developers.

Python - Conda support   16.9.21026.1
Conda support for Python projects.

Python - Django support   16.9.21026.1
Provides templates and integration for the Django web framework.

Python - IronPython support   16.9.21026.1
Provides templates and integration for IronPython-based projects.

Python - Profiling support   16.9.21026.1
Profiling support for Python projects.

Snapshot Debugging Extension   1.0
Snapshot Debugging Visual Studio Extension Detailed Info

SQL Server Data Tools   16.0.62103.10080
Microsoft SQL Server Data Tools

Syntax Visualizer   1.0
An extension for visualizing Roslyn SyntaxTrees.

Test Adapter for Boost.Test   1.0
Enables Visual Studio's testing tools with unit tests written for Boost.Test.  The use terms and Third Party Notices are available in the extension installation directory.

Test Adapter for Google Test   1.0
Enables Visual Studio's testing tools with unit tests written for Google Test.  The use terms and Third Party Notices are available in the extension installation directory.

ToolWindowHostedEditor   1.0
Hosting json editor into a tool window

TypeScript Tools   16.0.30201.2001
TypeScript Tools for Microsoft Visual Studio

Visual Basic Tools   3.9.0-6.21160.10+59eedc33d35754759994155ea2f4e1012a9951e3
Visual Basic components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Visual C++ for Cross Platform Mobile Development (Android)   16.0.31025.194
Visual C++ for Cross Platform Mobile Development (Android)

Visual C++ for Cross Platform Mobile Development (iOS)   16.0.31004.209
Visual C++ for Cross Platform Mobile Development (iOS)

Visual C++ for Linux Development   1.0.9.31112
Visual C++ for Linux Development

Visual F# Tools   16.9.0-beta.21102.9+7ce7132f1459095e635194d09d6f73265352029a
Microsoft Visual F# Tools

Visual Studio Code Debug Adapter Host Package   1.0
Interop layer for hosting Visual Studio Code debug adapters in Visual Studio

Visual Studio Container Tools Extensions   1.0
View, manage, and diagnose containers within Visual Studio.

Visual Studio Tools for CMake   1.0
Visual Studio Tools for CMake

Visual Studio Tools for Containers   1.0
Visual Studio Tools for Containers

Visual Studio Tools for Kubernetes   1.0
Visual Studio Tools for Kubernetes

VisualStudio.DeviceLog   1.0
Information about my package

VisualStudio.Foo   1.0
Information about my package

VisualStudio.Mac   1.0
Mac Extension for Visual Studio

Xamarin   16.9.000.273 (d16-9@1bba9e0)
Visual Studio extension to enable development for Xamarin.iOS and Xamarin.Android.

Xamarin Designer   16.9.0.316 (remotes/origin/d16-9@fdbf64026)
Visual Studio extension to enable Xamarin Designer tools in Visual Studio.

Xamarin Templates   16.9.68 (8e9b569)
Templates for building iOS, Android, and Windows apps with Xamarin and Xamarin.Forms.

Xamarin.Android SDK   11.2.2.1 (d16-9/877f572)
Xamarin.Android Reference Assemblies and MSBuild support.
    Mono: 5e9cb6d
    Java.Interop: xamarin/java.interop/d16-9@54f8c24
    ProGuard: Guardsquare/proguard/v7.0.1@912d149
    SQLite: xamarin/sqlite/3.34.1@daff8f4
    Xamarin.Android Tools: xamarin/xamarin-android-tools/d16-9@d210f11


Xamarin.iOS and Xamarin.Mac SDK   14.14.2.5 (3836759d4)
Xamarin.iOS and Xamarin.Mac Reference Assemblies and MSBuild support.",hello see issue closed problem create new core console project visual studio copy get compiler error missing reference far expert maybe something wrong instance visual studio enterprise version framework version version enterprise architecture analysis architecture analysis visual visual core core service provider package used data lake service provider web web core razor language core razor web additional information visit azure service azure service azure data lake node package data lake integration server explorer azure data lake visual studio azure data lake visual studio azure web azure web azure stream analytics visual studio azure stream analytics visual studio used ide depending project type different version compiler may used common azure common use azure mobile azure finding format extensibility message bus master common loosely coupled visual studio extension communication integration fabric diagnostic visual studio extension flow visual studio extension visual studio extension detailed core dump core azure azure node node azure node azure hive query language service language service hive query azure service fabric visual studio azure service fabric visual studio azure stream analytics language service language service azure stream analytics azure stream analytics node azure stream analytics node azure node azure azure visual studio continuous delivery visual studio configuration azure within visual studio ide support visual studio compatible virtual library manager install easily web project support visual studio mi compatible visual visual visual studio develop run validate core target environment application directly container edit refresh without rebuild container visual studio package visual studio package mono visual studio support mono visual studio package manager package manager visual studio information visit extension visual studio extension detailed python interactive support python python support support python python support integration web framework python support integration python support support python snapshot extension snapshot visual studio extension detailed server data server data syntax visualizer extension test adapter visual studio testing unit written use third party available extension installation directory test adapter test visual studio testing unit written test use third party available extension installation directory hosting editor tool window typescript typescript visual studio visual basic visual basic used ide depending project type different version compiler may used visual cross platform mobile development android visual cross platform mobile development android visual cross platform mobile development visual cross platform mobile development visual development visual development visual visual visual studio code adapter host package layer hosting visual studio code visual studio visual studio container view manage diagnose within visual studio visual studio visual studio visual studio visual studio visual studio visual studio information package information package mac extension visual studio visual studio extension enable development designer visual studio extension enable designer visual studio building android reference support mono reference support,issue,positive,positive,neutral,neutral,positive,positive
828543427,Sir I have also made a PR against my repo and I think I have updated all what we need https://github.com/Ayushsunny/DeepSpeech/pull/2,sir also made think need,issue,negative,neutral,neutral,neutral,neutral,neutral
828507617,"> @Ayushsunny That's a good start, you might want to add / experiment more test coverage on all those versions now

Yes Sir, Thank you so much for your review",good start might want add experiment test coverage yes sir thank much review,issue,positive,positive,positive,positive,positive,positive
828497954,"@Ayushsunny That's a good start, you might want to add / experiment more test coverage on all those versions now",good start might want add experiment test coverage,issue,negative,positive,positive,positive,positive,positive
828496683,"> Hello @lissyx Sir I have made a PR as a Demo Which I am going to add matrix version in every CTC decoders.
> could you please review and guide me that I am going right or not please?
> #3640

I see you opened the PR against our repo ; if you open it against **your** repo, then you can run GitHub Actions without our approval and debug on your own side ;)",hello sir made going add matrix version every could please review guide going right please see open run without approval side,issue,negative,positive,positive,positive,positive,positive
828488805,"Hello @lissyx Sir I have made a PR as a Demo Which I am going to add matrix version in every CTC decoders.
could you please review and guide me that I am going right or not please?
https://github.com/mozilla/DeepSpeech/pull/3640",hello sir made going add matrix version every could please review guide going right please,issue,positive,positive,positive,positive,positive,positive
827163932,"> Yes @dijksterhuis, Thank you so much.
> @lissyx Can I make a PR with matrix for all versions [here](https://github.com/mozilla/DeepSpeech/blob/0b007c9fb6df56fa277e4f9278e9340af59db2b4/.github/workflows/build-and-test.yml#L98-L138)

Yes. The whole idea of our switching to Github Actions is to allow people to run CI easily on their account as well:
 - fork deepspeech to your github account
 - make a new branch on your local copy of your fork
 - push your branch to your fork and open a PR against **your fork**

Tada, things runs :). Experiment, ask us help and we can move forward.",yes thank much make matrix yes whole idea switching allow people run easily account well fork account make new branch local copy fork push branch fork open fork experiment ask u help move forward,issue,positive,positive,positive,positive,positive,positive
827155217,"Yes @dijksterhuis, Thank you so much.
@lissyx Can I make a PR with matrix for all versions [here](https://github.com/mozilla/DeepSpeech/blob/0b007c9fb6df56fa277e4f9278e9340af59db2b4/.github/workflows/build-and-test.yml#L98-L138)",yes thank much make matrix,issue,positive,positive,positive,positive,positive,positive
827095656,"@Ayushsunny looks like the original file has been renamed to [build-and-test.yml](https://github.com/mozilla/DeepSpeech/blob/master/.github/workflows/build-and-test.yml). 

I think [this is the section](https://github.com/mozilla/DeepSpeech/blob/master/.github/workflows/build-and-test.yml#L98) you want to be looking at (it looks like what was originally posted by @lissyx after a very brief inspection).
",like original file think section want looking like originally posted brief inspection,issue,positive,positive,positive,positive,positive,positive
826807510,"Hey @FurkanGozukara 
I wanted to do the same thing and ended up building my own app to generate subtitles.
Check out [AutoSub](https://github.com/abhirooptalasila/AutoSub)!",hey thing ended building generate check,issue,negative,neutral,neutral,neutral,neutral,neutral
825426742,"But sir How I am supposed to fix this if I am not able to find this /macOS-amd64.yml file in master branch for more knowledge I am sticking the screenshots here : 

**Not available in the master branch -**

![Screenshot from 2021-04-23 12-01-37](https://user-images.githubusercontent.com/73520373/115829214-56666700-a42c-11eb-875b-38e6a410c85c.png)

**see this is available in your branch -**

![Screenshot from 2021-04-23 12-01-58](https://user-images.githubusercontent.com/73520373/115829229-5c5c4800-a42c-11eb-9c32-14f82f6b61ef.png)
",sir supposed fix able find file master branch knowledge sticking available master branch see available branch,issue,negative,positive,positive,positive,positive,positive
825425169,"> > Which reply Sir? @lissyx
> 
> One I thought I had sent
> 
> > and, may make a PR for this? or I need to improve the last code which I've sent .
> 
> What you shared is not what we need, but it's on the right path.
> 
> We need a job like the one I shared earlier, but on more versions of python.

Okay @lissyx Sir I got it do we need like this right ?
```yml
  build-ctc-decoder: 
     name: ""Build CTC decoder Python package for testing"" 
     needs: [ swig_macOS ] 
     runs-on: macos-10.15 
     strategy:
      matrix:
        python-version: [3.6.8, 3.7.9, 3.8.8, 3.9.2]
     if: ${{ github.event_name == 'pull_request' }} 
     steps: 
       - uses: actions/checkout@v2 
         with: 
           fetch-depth: 0 
       - uses: ./.github/actions/install-python-upstream 
         with: 
           version:  ${{ matrix.python-version }}
       - run: | 
           python --version 
           pip --version 
       - uses: actions/download-artifact@v2 
         with: 
           name: ""swig_macOS"" 
           path: ${{ github.workspace }}/native_client/ds-swig/ 
       - run: | 
           ls -hal ${{ github.workspace }}/native_client/ds-swig/bin 
           ln -s ds-swig ${{ github.workspace }}/native_client/ds-swig/bin/swig 
           chmod +x ${{ github.workspace }}/native_client/ds-swig/bin/ds-swig ${{ github.workspace }}/native_client/ds-swig/bin/swig 
       - run: | 
           make -C native_client/ctcdecode/ \ 
             NUM_PROCESSES=$(sysctl hw.ncpu |cut -d' ' -f2) \ 
             bindings 
       - uses: actions/upload-artifact@v2 
         with: 
           name: ""ds_ctcdecoder-test.whl"" 
           path: ${{ github.workspace }}/native_client/ctcdecode/dist/*.whl 
       - run: | 
           make -C native_client/ctcdecode clean-keep-third-party 
```
",reply sir one thought sent may make need improve last code sent need right path need job like one python sir got need like right name build python package testing need strategy matrix version run python version pip version name path run run make name path run make,issue,positive,positive,positive,positive,positive,positive
824013648,">  Optimize process with chroot caching

This is too much trouble:
 - each arch variant cache is ~250MB
 - we need to perform unmount of workspace directory before making a cache, otherwise we embed test binaries and data into the cache
 - however, composite github actions do not allow for post run

All in all it will consume quite a lot of the cache storage allowance and add complexity to the workflow to save ~3m of runtime on each tests",optimize process much trouble arch variant cache need perform unmount directory making cache otherwise embed test data cache however composite allow post run consume quite lot cache storage allowance add complexity save,issue,positive,negative,negative,negative,negative,negative
823887370,"> Hmm, apparently this fix for the linux version breaks the automated build of the MacOS version?

@Patronics So I do reproduce the issue, it's just that current master is still relying to a older `ds-swig` prebuilt binary we share for v0.9.3 building. But on master we've moved to news upstream (previous version of swig we used was a fork to get support of newer versions of NodeJS).

If you build your own version of swig from their current master branch, it should work:
```
$ git clone https://github.com/swig/swig
$ cd swig/
$ sh autogen.sh
$ ./configure --prefix=<path/to/deepspeech>/native_client/ds-swig/ --program-prefix=ds-
$ make -j
$ make -j install
$ cd <path/to/deepspeech>/native_client/ds-swig/bin && ln -s ds-swig swig
```",apparently fix version build version reproduce issue current master still older binary share building master news upstream previous version swig used fork get support build version swig current master branch work git clone sh make make install swig,issue,positive,positive,neutral,neutral,positive,positive
823815876,"Hmm, apparently this fix for the linux version breaks the automated build of the MacOS version? ",apparently fix version build version,issue,negative,positive,neutral,neutral,positive,positive
821394162,"> Which reply Sir? @lissyx

One I thought I had sent



>  and, may make a PR for this? or I need to improve the last code which I've sent .

What you shared is not what we need, but it's on the right path. 

We need a job like the one I shared earlier, but on more versions of python.",reply sir one thought sent may make need improve last code sent need right path need job like one python,issue,positive,positive,positive,positive,positive,positive
821320443,"> @Ayushsunny Sorry looks like my reply got lost ; that's the good basis, you'll have to build on top of that.

Which reply Sir? @lissyx 
and, may make a PR for this? or I need to improve the last code which I've sent .",sorry like reply got lost good basis build top reply sir may make need improve last code sent,issue,positive,positive,positive,positive,positive,positive
821206730,"@Ayushsunny Sorry looks like my reply got lost ; that's the good basis, you'll have to build on top of that.",sorry like reply got lost good basis build top,issue,positive,positive,positive,positive,positive,positive
820138357,"So Sir, as per my understanding I think this should be the code which I have to add. @lissyx ?

``` YML
jobs:
  build:
    runs-on: macos-10.15
    strategy:
      matrix:
        python-version: [ '2.x', '3.x', 'pypy-2.7', 'pypy-3.6', 'pypy-3.7' ]
    name: Python ${{ matrix.python-version }} sample
    steps:
      - uses: actions/checkout@v2
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64
      - run: python my_script.py `",sir per understanding think code add build strategy matrix name python sample name setup python architecture run python,issue,negative,neutral,neutral,neutral,neutral,neutral
819556033,"> I'm really sorry Sir @lissyx
> I was studying for my University Exam.
> Now I'm free and from tomorrow I'll start working on it.

Thanks, I don't want to pressure you, it's fine if you can't take it, but we just need to know :)",really sorry sir university exam free tomorrow start working thanks want pressure fine ca take need know,issue,positive,positive,positive,positive,positive,positive
819410846,"> The Windows ElectronJS tests are broken on the multi-platform package in a very weird way. Sometimes the inference result returns a single letter, and sometimes it just hangs until the test times out. The Windows only intermediate package works fine. Calling the client directly from a worker machine never hangs, always returns the single letter output. I'm a bit stumped.

I'm wondering if it's not indicative of a broken binary somehow. Maybe the repackaging is breaking with macOS + Windows.",broken package weird way sometimes inference result single letter sometimes test time intermediate package work fine calling client directly worker machine never always single letter output bit wondering indicative broken binary somehow maybe breaking,issue,negative,negative,negative,negative,negative,negative
819398472,"The Windows ElectronJS tests are broken on the multi-platform package in a very weird way. Sometimes the inference result returns a single letter, and sometimes it just hangs until the test times out. The Windows only intermediate package works fine. Calling the client directly from a worker machine never hangs, always returns the single letter output. I'm a bit stumped.",broken package weird way sometimes inference result single letter sometimes test time intermediate package work fine calling client directly worker machine never always single letter output bit,issue,negative,negative,neutral,neutral,negative,negative
818976309,"I'm really sorry Sir @lissyx 
I was studying for my University Exam.
Now I'm free and from tomorrow I'll start working on it.",really sorry sir university exam free tomorrow start working,issue,negative,negative,neutral,neutral,negative,negative
816732638,"@wuchaowei2012 Mandarin model is using Byte output mode, so you don't need an alphabet.",mandarin model output mode need alphabet,issue,negative,neutral,neutral,neutral,neutral,neutral
816675824,"This looks like a supoort request so you should check out Discourse or [STT Discussions](https://github.com/coqui-ai/STT/discussions), but afaik Mandarin is based on the bytes-only mode so you don't need an alphabet file.",like request check discourse mandarin based mode need alphabet file,issue,negative,neutral,neutral,neutral,neutral,neutral
815968229,"Rationale:
 - We want to quickly find some failures, so reduce amount of tests
 - limit testing to major versions
 - only test 16k alternative
 - only test on `test` model

We will cover 8k/16k and prod model with proper multiplatform packages from #3597 ",rationale want quickly find reduce amount limit testing major test alternative test test model cover prod model proper,issue,negative,positive,positive,positive,positive,positive
815056270,"> @lissyx OK. Are there any other docs to update or is this one file change the only one?

No it's the same one",update one file change one one,issue,negative,neutral,neutral,neutral,neutral,neutral
815046854,@lissyx OK. Are there any other docs to update or is this one file change the only one?,update one file change one,issue,negative,neutral,neutral,neutral,neutral,neutral
814834128,@Ayushsunny Have you been able to get a grasp of what needs to be done ?,able get grasp need done,issue,negative,positive,positive,positive,positive,positive
814254078,"It was not against you, it's just that it's not the best time to have to do one. It just proves that what is not tested is broken ;)",best time one tested broken,issue,negative,positive,positive,positive,positive,positive
814201318,"> Sorry, I haven't had a great deal of time so this isn't likely to proceed much for a bit. I'll try a bit more next weekend

@nmstoker Gentle ping? It's okay if you don't have time ;)",sorry great deal time likely proceed much bit try bit next weekend gentle ping time,issue,positive,positive,positive,positive,positive,positive
814162575,"> If you prefer, we can also just revert the remote I/O changes for this file, which would mean that you just can’t do this for remote files.
> […](#)
> On Tue, Apr 6, 2021 at 05:26 lissyx ***@***.***> wrote: We update the import to from io import open_remote which assumes that you're calling the script from within the util directory. it's even going to break because io is a python provided module, so usually it should take precedence. — You are receiving this because you were assigned. Reply to this email directly, view it on GitHub <[#3599 (comment)](https://github.com/mozilla/DeepSpeech/issues/3599#issuecomment-814078859)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AACRFKYFY647VTVZXPWLOTTTHL4YBANCNFSM42JBTP7A> .

Either way, current 0.9.3 images and docs are broken, and whatever fix we pick we need to make a new dot release (which makes me unhappy), so I prefer to wwait for reuben's opinion :)",prefer also revert remote file would mean remote tue wrote update import io import calling script within directory even going break io python provided module usually take precedence assigned reply directly view comment either way current broken whatever fix pick need make new dot release unhappy prefer opinion,issue,negative,negative,negative,negative,negative,negative
814156511,"If you prefer, we can also just revert the remote I/O changes for this
file, which would mean that you just can’t do this for remote files.

On Tue, Apr 6, 2021 at 05:26 lissyx ***@***.***> wrote:

> We update the import to from io import open_remote which assumes that
> you're calling the script from within the util directory.
>
> it's even going to break because io is a python provided module, so
> usually it should take precedence.
>
> —
> You are receiving this because you were assigned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3599#issuecomment-814078859>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AACRFKYFY647VTVZXPWLOTTTHL4YBANCNFSM42JBTP7A>
> .
>
",prefer also revert remote file would mean remote tue wrote update import io import calling script within directory even going break io python provided module usually take precedence assigned reply directly view,issue,negative,negative,negative,negative,negative,negative
814078859,"> We update the import to ` from io import open_remote` which assumes that you're calling the script from within the `util` directory.

it's even going to break because `io` is a python provided module, so usually it should take precedence.",update import io import calling script within directory even going break io python provided module usually take precedence,issue,negative,negative,negative,negative,negative,negative
814078209,@reuben Do you have an opinion on whether it is sound we break backward compat here?,opinion whether sound break backward,issue,negative,positive,positive,positive,positive,positive
814077830,">     1. `python -m deepspeech_training.util.check_characters`

So after thinking again, it also means we are breaking backward compatility.",python thinking also breaking backward,issue,negative,neutral,neutral,neutral,neutral,neutral
812994313,"> where you'd want to add an invocation of this script in the various workflows.

I'd suggest adding a new job for that, next to e.g. the C++ binary tests",want add invocation script various suggest new job next binary,issue,negative,positive,neutral,neutral,positive,positive
812949273,"I updated the docs. It's awesome that you moved to Github Actions -- I love them. However, I couldn't figure out at a quick glance where you'd want to add an invocation of this script in the various workflows. I'm probably not the right person to write a test for this as I've also never used this script…",awesome love however could figure quick glance want add invocation script various probably right person write test also never used,issue,positive,positive,positive,positive,positive,positive
812662964,"> Ah sorry about that! I think two options
> 
>     1. We update the instructions to call this script as a module like
>        ```
>        python -m deepspeech_training.util.check_characters
>        ```
>        
>        
>        That allows you to call the script from the base directory as long as you specify the right relative module path and there are `__init__.py`s along the way.
> 
>     2. We update the import to ` from io import open_remote` which assumes that you're calling the script from within the `util` directory.
> 
> 
> Do you have a preference between these two?

I'd prefer 1

It could be awesome if you can add GitHub Actions coverage :)",ah sorry think two update call script module like python call script base directory long specify right relative module path along way update import io import calling script within directory preference two prefer could awesome add coverage,issue,positive,negative,neutral,neutral,negative,negative
812659962,"Ah sorry about that! I think two options

1. We update the instructions to call this script as a module like
    ```
    python -m deepspeech_training.util.check_characters
    ```
    That allows you to call the script from the base directory as long as you specify the right relative module path and there are `__init__.py`s along the way.
2. We update the import to ` from io import open_remote` which assumes that you're calling the script from within the `util` directory.

Do you have a preference between these two?",ah sorry think two update call script module like python call script base directory long specify right relative module path along way update import io import calling script within directory preference two,issue,negative,negative,negative,negative,negative,negative
812582780,"Unfortunately, I am witnessing by myself that the fix does not cover all the cases: `TF_CUDNN_RESET_RND_GEN_STATE=1` required to train a DeepSpeech v0.9.3 model (batch size 8, K40m GPU with 12GB VRAM) on Breton release of Common Voice v6.1 cc @ftyers ",unfortunately fix cover train model batch size release common voice,issue,negative,negative,negative,negative,negative,negative
812513881,"@Ayushsunny If it can help you get a better understanding, here is my PR: https://github.com/mozilla/DeepSpeech/pull/3598",help get better understanding,issue,positive,positive,positive,positive,positive,positive
812250250,"I can, this just seemed neater for the situation in which I was using it at least, and I thought I might as well push that back as it's only a small feature. The help message doesn't make it fully clear either what is happening with the results of the inference; something like ''--output file   File to write text result (default is stdout)"" would clarify this.",situation least thought might well push back small feature help message make fully clear either happening inference something like output file file write text result default would clarify,issue,positive,negative,negative,negative,negative,negative
812045996,"> So what I have to do first to understand this specific topic to fix this issue

Read this code, get yourself into https://docs.github.com/en/actions/guides :)",first understand specific topic fix issue read code get,issue,negative,positive,positive,positive,positive,positive
812045540,"> Yes, I can pickup #3373 and help with gihub actions

Please note the goal of moving to Github Actions is making the repository easier to maintain for others than us, so feedback on anything related is highly welcome. We don't yet have the CI part in place @reuben is still working on it, but I guess you can already poke in the existing macOS bits?",yes pickup help please note goal moving making repository easier maintain u feedback anything related highly welcome yet part place still working guess already poke,issue,positive,positive,positive,positive,positive,positive
812042020,"> @Ayushsunny This might be easier, if you are still willing to learn GitHub Actions at the same time

Thank you so much as you want me to learn. It's so nice of you Sir @lissyx .
and yes I want to learn, So what I have to do first is to understand this specific topic to fix this issue",might easier still willing learn time thank much want learn nice sir yes want learn first understand specific topic fix issue,issue,positive,positive,positive,positive,positive,positive
811985803,"@Ayushsunny This might be easier, if you are still willing to learn GitHub Actions at the same time",might easier still willing learn time,issue,negative,positive,positive,positive,positive,positive
811982611,"> > @Ayushsunny Is it clear to you? Do you think you have all the infos? It's fine if you feel you need more infos, just dig into the code, hack and ask! :)
> 
> Sorry @lissyx Sir I'm not able to understand this as these things are new to me, but I really want to solve this issue to learn, So Please help me sir I want to contribute.

Well it's fine if you can't work on this one, you can find many others: https://github.com/mozilla/DeepSpeech/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+bug%22",clear think fine feel need dig code hack ask sorry sir able understand new really want solve issue learn please help sir want contribute well fine ca work one find many,issue,positive,positive,positive,positive,positive,positive
811977004,"> @Ayushsunny Is it clear to you? Do you think you have all the infos? It's fine if you feel you need more infos, just dig into the code, hack and ask! :)

Sorry @lissyx Sir I'm not able to understand this as these things are new to me, but I really want to solve this issue to learn, So Please help me sir I want to contribute.",clear think fine feel need dig code hack ask sorry sir able understand new really want solve issue learn please help sir want contribute,issue,positive,positive,positive,positive,positive,positive
811836509,"@Ayushsunny Is it clear to you? Do you think you have all the infos? It's fine if you feel you need more infos, just dig into the code, hack and ask! :)",clear think fine feel need dig code hack ask,issue,positive,positive,positive,positive,positive,positive
811836169,@Ayushsunny One example of a composite action setting an output value can be seen at https://github.com/mozilla/DeepSpeech/blob/5f566f442541d76f320ee081294cdef980c361d1/.github/actions/get_cache_key/action.yml and it is used https://github.com/mozilla/DeepSpeech/blob/5f566f442541d76f320ee081294cdef980c361d1/.github/workflows/macOS-amd64.yml#L154-L171,one example composite action setting output value seen used,issue,negative,positive,neutral,neutral,positive,positive
811835430,"@Ayushsunny We would need this shell code to be ported as an action being used in this job: https://github.com/mozilla/DeepSpeech/blob/5f566f442541d76f320ee081294cdef980c361d1/.github/workflows/macOS-amd64.yml#L243-L285

You could make it in JS https://docs.github.com/en/actions/creating-actions/creating-a-javascript-action or I think a simple Composite action can be enough https://docs.github.com/en/actions/creating-actions/creating-a-composite-run-steps-action

We already have a few composite actions, look under `.github/actions`.

As you can see, existing bash code sets some env variables. For using as GitHub Actions, we would rely on the Inputs/Outputs mechanism to pass the correct values as `NUMPY_BUILD_VERSION` and `NUMPY_DEP_VERSION`.",would need shell code ported action used job could make think simple composite action enough already composite look see bash code would rely mechanism pas correct,issue,negative,positive,neutral,neutral,positive,positive
811751508,"> Hello @lissyx , So I have to change the NUMPY version here?

no, we have the code I linked, which was used on taskcluster, the goal of the issue is to replicate the behavior for GitHub Actions",hello change version code linked used goal issue replicate behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
811252396,"> @Ayushsunny Are you hacking on it? Do you have questions?

Yes, I'm trying to understand Sir",hacking yes trying understand sir,issue,negative,neutral,neutral,neutral,neutral,neutral
811147683,"Hi, don't think I made a mistake, I had downloaded this file to run deepspeech on my machine and wanted to output the results without the extra information on stdout cluttering this, so thought it might be useful to add a switch and just used the browser-based editor to submit the changes.",hi think made mistake file run machine output without extra information thought might useful add switch used editor submit,issue,negative,positive,positive,positive,positive,positive
811144431,"> No, I did not noticed a merge request was already in progress.
> We can forget about this one.

@jetelain Do you want to pickup #3373 and help us land that with GitHub Actions coverage ?",merge request already progress forget one want pickup help u land coverage,issue,positive,neutral,neutral,neutral,neutral,neutral
811143713,"@hunterwebapps As you can see in #3317 and on https://github.com/mozilla/DeepSpeech/projects/13 we are in the process of moving to GitHub Actions current status is that we have mostly end-to-end pipeline on macOS but it's not covering the mandarin work ; if you are interested it would be welcome to add test coverage there.

Getting feedback from people on the new GitHub Actions flow is also super important to us, so it would be a perfect case.",see process moving current status mostly pipeline covering mandarin work interested would welcome add test coverage getting feedback people new flow also super important u would perfect case,issue,positive,positive,positive,positive,positive,positive
810907566,"@stellarpower Thanks, but I think you did a mistake opening a PR against this repo instead of your fork.",thanks think mistake opening instead fork,issue,negative,positive,positive,positive,positive,positive
810550040,"> Hello @lissyx I would like to work on this issue

Feel free to have a look at the code and propose a PR, or ask questions!",hello would like work issue feel free look code propose ask,issue,positive,positive,positive,positive,positive,positive
810549570,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",wo notify release get touch new version available rather skip next major minor version let know ignore major version ignore minor version change mind resolve,issue,negative,positive,neutral,neutral,positive,positive
810536161,Hello @lissyx I would like to work on this issue,hello would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
810092603,Please read the documentation and reach for support on Discourse. ,please read documentation reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
809518980,"> zip usecare looks to be breaking our symlinks.

That might be it. Thank you. And apologies for not finding anything about this on Google or my lack of skills in searching. This issue's title just happened to exact same as what I looked up on Google.",zip breaking might thank finding anything lack searching issue title exact,issue,negative,positive,positive,positive,positive,positive
809518108,"> Not sure if this is ""hijacking"" the issue, but on my mac with DeepSpeech tagged 0.9.3, I'm getting:
> 
> ```
> >> pip install --upgrade -e .
> ... other packages downloaded...
> ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training)
> ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION
> ```
> 
> where `DeepSpeech/training/deepspeech_training/VERSION` has the version, `DeepSpeech/VERSION` has `training/deepspeech_training/VERSION` and `setup.py` in main function says:
> 
> ```python
> def main():
>     version_file = Path(__file__).parent / 'VERSION'
>     with open(str(version_file)) as fin:
>         version = fin.read().strip()
> ```
> 
> where I'm just following the tutorial: https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html with the only exception being that I downloaded the zip file rather than using `git clone`.

Re-reading, it seems you are explicitely hitting the issue because `zip` usecare looks to be breaking our symlinks.",sure issue mac tagged getting pip install upgrade error could find version requirement error matching distribution found version main function python main path open fin version following tutorial exception zip file rather git clone issue zip breaking,issue,negative,positive,positive,positive,positive,positive
809517104,"> Not sure if this is ""hijacking"" the issue, but on my mac with DeepSpeech tagged 0.9.3, I'm getting:
> 
> ```
> >> pip install --upgrade -e .
> ... other packages downloaded...
> ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training)
> ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION
> ```
> 
> where `DeepSpeech/training/deepspeech_training/VERSION` has the version, `DeepSpeech/VERSION` has `training/deepspeech_training/VERSION` and `setup.py` in main function says:
> 
> ```python
> def main():
>     version_file = Path(__file__).parent / 'VERSION'
>     with open(str(version_file)) as fin:
>         version = fin.read().strip()
> ```
> 
> where I'm just following the tutorial: https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html with the only exception being that I downloaded the zip file rather than using `git clone`.

Too bad you're not giving any useful information, we have some macOS things on https://pypi.org/project/ds-ctcdecoder/#files but I can't check if you're trying with an unsupported version of python or what.



> with the only exception being that I downloaded the zip file rather than using `git clone`.

Which is something that is known for breaking.

Please do not use GitHub for support but rather look at Discourse.",sure issue mac tagged getting pip install upgrade error could find version requirement error matching distribution found version main function python main path open fin version following tutorial exception zip file rather git clone bad giving useful information ca check trying unsupported version python exception zip file rather git clone something known breaking please use support rather look discourse,issue,negative,positive,neutral,neutral,positive,positive
809494852,"Not sure if this is ""hijacking"" the issue, but on my mac with DeepSpeech tagged 0.9.3, I'm getting:

```
>> pip install --upgrade -e .
... other packages downloaded...
ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training)
ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION
```

where `DeepSpeech/training/deepspeech_training/VERSION` has the version, `DeepSpeech/VERSION` has `training/deepspeech_training/VERSION` and `setup.py` in main function says:

```python
def main():
    version_file = Path(__file__).parent / 'VERSION'
    with open(str(version_file)) as fin:
        version = fin.read().strip()
```

where I'm just following the tutorial: https://deepspeech.readthedocs.io/en/v0.9.3/TRAINING.html with the only exception being that I downloaded the zip file rather than using `git clone`.",sure issue mac tagged getting pip install upgrade error could find version requirement error matching distribution found version main function python main path open fin version following tutorial exception zip file rather git clone,issue,negative,positive,positive,positive,positive,positive
807958022,Reducing the number of batch size from 64 to 32 for training and 32 to 16 for test and dev data solved this issue.,reducing number batch size training test dev data issue,issue,negative,neutral,neutral,neutral,neutral,neutral
807571767,"> For now only x86-64 (linux I believe) works, though you could easily modify the Makefile for your platform. This is a WIP.
> 
> Keep in mind the code for the standalone jdk is probably going to change a bit, I dont like the way library loading is done at the moment.
> 
> I should have some time to look at it again tomorrow afternoon and Saturday.

Thanks for your work!",believe work though could easily modify platform keep mind code probably going change bit dont like way library loading done moment time look tomorrow afternoon thanks work,issue,negative,positive,positive,positive,positive,positive
807567635,"For now only x86-64 (linux I believe) works, though you could easily modify the Makefile for your platform. This is a WIP.

Keep in mind the code for the standalone jdk is probably going to change a bit, I dont like the way library loading is done at the moment.

I should have some time to look at it again tomorrow afternoon and Saturday.",believe work though could easily modify platform keep mind code probably going change bit dont like way library loading done moment time look tomorrow afternoon,issue,negative,positive,positive,positive,positive,positive
807506814,"> > Hi TheDutchMC,
> > I face an issue after `make standalone`. The file `tensorflow/bazel-out/x86_64-*/bin/native_client/libdeepspeech.so` is not found.
> 
> Hey there, have you built DeepSpeech before trying to create the java bindings? See [the documentation here](https://deepspeech.readthedocs.io/en/v0.9.3/BUILDING.html)

Except for compiling DeepSpeech, which platform should be built? If you could upload libdeepspeech.jar and `*.so` files, it would be convenient to test the Java bindings.",hi face issue make file found hey built trying create see documentation except platform built could would convenient test,issue,negative,neutral,neutral,neutral,neutral,neutral
806974008,"> 
>     * [ ]  interface `bazel build` with `make` ?

@reuben Maybe GitHub Action move is a good time to address this?
",interface build make maybe action move good time address,issue,negative,positive,positive,positive,positive,positive
806971755,"Just a word to mention that there's a PR in flight and we just started using GitHub Actions, so now might be a good fit for people who would like to work on the new CI to address and land this.",word mention flight might good fit people would like work new address land,issue,positive,positive,positive,positive,positive,positive
806970302,"@djmitche I need to thank you again for the continued support regarding TaskCluster, but we are sadly not going to address that :/",need thank continued support regarding sadly going address,issue,negative,negative,negative,negative,negative,negative
806764480,"> Neither worked (both saying audio files are 0 sec long).

Those NPM packages were green on CI, so I'd suspect something weird on your side, but I can't tell for sure.",neither worked saying audio sec long green suspect something weird side ca tell sure,issue,negative,negative,neutral,neutral,negative,negative
806733691,"@stepkillah Gentle ping, I've merged the first GitHub Actions bit :)",gentle ping first bit,issue,negative,positive,positive,positive,positive,positive
806453023,"> Hi TheDutchMC,
> I face an issue after `make standalone`. The file `tensorflow/bazel-out/x86_64-*/bin/native_client/libdeepspeech.so` is not found.

Hey there, have you built DeepSpeech before trying to create the java bindings? See [the documentation here](https://deepspeech.readthedocs.io/en/v0.9.3/BUILDING.html)",hi face issue make file found hey built trying create see documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
806264096,"Hi TheDutchMC,
I face an issue after `make standalone`. The file `tensorflow/bazel-out/x86_64-*/bin/native_client/libdeepspeech.so` is not found.",hi face issue make file found,issue,negative,neutral,neutral,neutral,neutral,neutral
806219143,"Ah! I misunderstood. I just ran the updated version and am actually getting no output. It's telling me that my audio files are 0 seconds in length. I am still using the 0.9.3 models, and I tried both english (which was working with the corresponding release version) and chinese. Neither worked (both saying audio files are 0 sec long). I tried to look for updated models with the new alpha versions, but there don't appear to be any available. I just tried to modify the below url. No surprise there, but I figured I'd try.

https://github.com/mozilla/DeepSpeech/releases/download/v0.10.0-alpha.3/deepspeech-0.10.0-alpha.3-models-zh-CN.pbmm",ah misunderstood ran version actually getting output telling audio length still tried working corresponding release version neither worked saying audio sec long tried look new alpha appear available tried modify surprise figured try,issue,negative,positive,neutral,neutral,positive,positive
806211428,"> Here's the discourse thread.
> https://discourse.mozilla.org/t/pretrained-chinese-model-invalid-inference-output/77439/5
> 
> It seems to be specific to the npm package. It just puts out bad encoding, rather than the expected output of valid encoding. Like ����� instead of 我会说中文。But when I used the python command line tool it outputs as expected.
> 
> I can work without the javascript bindings, but I just wanted to report here so the team is aware, and anybody else who is looking (like I was) can at least find some info. Thanks!

Right, so if you can give a try to the link above it might help us: this are current master bindings, and they are built with newer SWIG version, where they have (properly) fixed the NodeJS incompatibilities we had patches for on our SWIG fork.

So hopefully, the issue might have been on our patches. If that's the case, this newer npm package would fix.",discourse thread specific package bad rather output valid like instead used python command line tool work without report team aware anybody else looking like least find thanks right give try link might help u current master built swig version properly fixed swig fork hopefully issue might case package would fix,issue,positive,negative,neutral,neutral,negative,negative
806207908,"Here's the discourse thread.
https://discourse.mozilla.org/t/pretrained-chinese-model-invalid-inference-output/77439/5

It seems to be specific to the npm package. It just puts out bad encoding, rather than the expected output of valid encoding. Like ����� instead of 我会说中文。But when I used the python command line tool it outputs as expected.

I can work without the javascript bindings, but I just wanted to report here so the team is aware, and anybody else who is looking (like I was) can at least find some info. Thanks!",discourse thread specific package bad rather output valid like instead used python command line tool work without report team aware anybody else looking like least find thanks,issue,positive,negative,negative,negative,negative,negative
806066216,"> > NodeJS v12-v15 has been merged upstream and should be part of SWIG 4.1 ; we should direct people to use that release instead of relying on our fork (which will continue only for TC integration purposes).
> 
> can I work on this issue?

Unfortunately, there is nothing to do here until SWIG does a 4.1 release.

However, if you are looking into hacking, you could have a look at #3317 ",upstream part swig direct people use release instead fork continue integration work issue unfortunately nothing swig release however looking hacking could look,issue,negative,negative,negative,negative,negative,negative
805849132,"Manual testing of the TF / TFLite Python (Python 3.9 Homebrew):
```
ds-tc-worker:test-github-actions ds-worker-admin$ deepspeech --model deepspeech-0.9.3-models.pbmm --scorer deepspeech-0.9.3-models.scorer --audio audio/4507-16021-0012.wav --extended
Loading model from file deepspeech-0.9.3-models.pbmm
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.10.0-alpha.3-57-g0b30a4d8
2021-03-24 15:03:12.295583: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loaded model in 0.014s.
Loading scorer from files deepspeech-0.9.3-models.scorer
Loaded scorer in 0.000314s.
Running inference.
why should one halt on the way
Inference took 1.329s for 2.735s audio file.
ds-tc-worker:test-github-actions ds-worker-admin$ deepspeech --model deepspeech-0.9.3-models.tflite --scorer deepspeech-0.9.3-models.scorer --audio audio/4507-16021-0012.wav --extended
Loading model from file deepspeech-0.9.3-models.tflite
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.10.0-alpha.3-57-g0b30a4d8
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2021-03-24 15:03:26.890383: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Data loss: Can't parse deepspeech-0.9.3-models.tflite as binary proto
Traceback (most recent call last):
  File ""/usr/local/bin/deepspeech"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.9/site-packages/deepspeech/client.py"", line 119, in main
    ds = Model(args.model)
  File ""/usr/local/lib/python3.9/site-packages/deepspeech/__init__.py"", line 38, in __init__
    raise RuntimeError(""CreateModel failed with '{}' (0x{:X})"".format(deepspeech.impl.ErrorCodeToErrorMessage(status),status))
RuntimeError: CreateModel failed with 'Error reading the proto buffer model file.' (0x3005)
ds-tc-worker:test-github-actions ds-worker-admin$ pip3 install --upgrade deepspeech_tflite-0.10.0a3-cp39-cp39-macosx_10_9_x86_64.whl
Processing ./deepspeech_tflite-0.10.0a3-cp39-cp39-macosx_10_9_x86_64.whl
Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from deepspeech-tflite==0.10.0a3) (1.20.1)
Installing collected packages: deepspeech-tflite
Successfully installed deepspeech-tflite-0.10.0a3
ds-tc-worker:test-github-actions ds-worker-admin$ deepspeech --model deepspeech-0.9.3-models.tflite --scorer deepspeech-0.9.3-models.scorer --audio audio/4507-16021-0012.wav --extended
Loading model from file deepspeech-0.9.3-models.tflite
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.10.0-alpha.3-57-g0b30a4d8
Loaded model in 0.0011s.
Loading scorer from files deepspeech-0.9.3-models.scorer
Loaded scorer in 0.0004s.
Running inference.
why should one halt on the way
Inference took 0.585s for 2.735s audio file.
ds-tc-worker:test-github-actions ds-worker-admin$
```",manual testing python python model scorer audio extended loading model file binary deep neural network library use following enable rebuild appropriate compiler loaded model loading scorer loaded scorer running inference one halt way inference took audio file model scorer audio extended loading model file warning reading entire model file memory transform model file graph reduce heap usage binary deep neural network library use following enable rebuild appropriate compiler data loss ca parse binary proto recent call last file line module main file line main model file line raise status status reading proto buffer model file pip install upgrade requirement already satisfied collected successfully model scorer audio extended loading model file loaded model loading scorer loaded scorer running inference one halt way inference took audio file,issue,negative,positive,positive,positive,positive,positive
805846896,"Manual testing of the TF / TFLite NodeJS (NodeVS v15):
```
ds-tc-worker:test-github-actions ds-worker-admin$ PATH=$(pwd)/node-v15.12.0-darwin-x64/bin/:$PATH ./tflite/node_modules/.bin/deepspeech --model deepspeech-0.9.3-models.tflite --scorer deepspeech-0.9.3-models.scorer --audio audio/4507-16021-0012.wav --extended --stream
Loading model from file deepspeech-0.9.3-models.tflite
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.10.0-alpha.3-57-g0b30a4d8
Loaded model in 0.005774s.
Loading scorer from file deepspeech-0.9.3-models.scorer
Loaded scorer in 0.0004919s.
intermediate:
intermediate:
intermediate:
intermediate:
intermediate: why
intermediate: why should i
intermediate: why should one
intermediate: why should one
intermediate: why should one halt to
intermediate: why should one halt on the
intermediate: why should one halt on the
why should one halt on the way
ds-tc-worker:test-github-actions ds-worker-admin$ PATH=$(pwd)/node-v15.12.0-darwin-x64/bin/:$PATH ./tf/node_modules/.bin/deepspeech --model deepspeech-0.9.3-models.pbmm --scorer deepspeech-0.9.3-models.scorer --audio audio/4507-16021-0012.wav --extended --stream
Loading model from file deepspeech-0.9.3-models.pbmm
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.10.0-alpha.3-57-g0b30a4d8
2021-03-24 15:00:28.072326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loaded model in 0.01582s.
Loading scorer from file deepspeech-0.9.3-models.scorer
Loaded scorer in 0.0004769s.
intermediate:
intermediate:
intermediate:
intermediate:
intermediate: why s
intermediate: why should i
intermediate: why should one
intermediate: why should one
intermediate: why should one halt
intermediate: why should one halt on the
intermediate: why should one halt on the
why should one halt on the way
ds-tc-worker:test-github-actions ds-worker-admin$
```",manual testing path model scorer audio extended stream loading model file loaded model loading scorer file loaded scorer intermediate intermediate intermediate intermediate intermediate intermediate intermediate one intermediate one intermediate one halt intermediate one halt intermediate one halt one halt way path model scorer audio extended stream loading model file binary deep neural network library use following enable rebuild appropriate compiler loaded model loading scorer file loaded scorer intermediate intermediate intermediate intermediate intermediate intermediate intermediate one intermediate one intermediate one halt intermediate one halt intermediate one halt one halt way,issue,negative,positive,positive,positive,positive,positive
805586817,"Thanks but you should be more explicit on the expected and actual output, or link your discourse thread ...",thanks explicit actual output link discourse thread,issue,negative,positive,neutral,neutral,positive,positive
805431927,"* #3570 raised for `r0.9` branch 
* #3571 raised for `master` branch",raised branch raised master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
804908317,"Noted with thanks, leave this with me, bed time now, but will get to it in about 24 hours.",noted thanks leave bed time get,issue,negative,positive,positive,positive,positive,positive
804896927,"> @KathyReid please make two PRs, one against r0.9 and one against master

Make sure you push to a branch on your fork, and open a PR against this repo. I gave you creds so you should be able to trigger  taskcluster yourself (while we still rely on it for a few days)",please make two one one master make sure push branch fork open gave able trigger still rely day,issue,positive,positive,positive,positive,positive,positive
804895711,"@KathyReid please make two PRs, one against r0.9 and one against master",please make two one one master,issue,negative,neutral,neutral,neutral,neutral,neutral
804895396,"> Happy to raise a PR for this.

yes, please",happy raise yes please,issue,positive,positive,positive,positive,positive,positive
804866850,"> > > Could you push again to make this run?
> > 
> > 
> > You mean to have it running against `mozilla/DeepSpeech` repo? I think it would run until we merge, but you can check on my fork :)
> 
> Yes. I enabled Actions on this repo. I think instead of working on a giant ""GitHub Actions"" PR we should rename this to ""macOS GitHub Actions"" and land ASAP and keep working in separate PRs. And for that we need to get it running here.

Sure, that was my goal as well",could push make run mean running think would run merge check fork yes think instead working giant rename land keep working separate need get running sure goal well,issue,positive,positive,neutral,neutral,positive,positive
804735485,@zh794390558 You keep opening issues without giving any context: this is spamming. Either file a real issue or stop.,keep opening without giving context either file real issue stop,issue,negative,positive,positive,positive,positive,positive
804258494,"> > Could you push again to make this run?
> 
> You mean to have it running against `mozilla/DeepSpeech` repo? I think it would run until we merge, but you can check on my fork :)

Yes. I enabled Actions on this repo. I think instead of working on a giant ""GitHub Actions"" PR we should rename this to ""macOS GitHub Actions"" and land ASAP and keep working in separate PRs. And for that we need to get it running here.",could push make run mean running think would run merge check fork yes think instead working giant rename land keep working separate need get running,issue,negative,negative,negative,negative,negative,negative
804194716,"> Could you push again to make this run?

You mean to have it running against `mozilla/DeepSpeech` repo? I think it would run until we merge, but you can check on my fork :)",could push make run mean running think would run merge check fork,issue,negative,negative,negative,negative,negative,negative
804173656,Hi @zh794390558 ! This looks like a support request. Best to use [Discourse](https://discourse.mozilla.org/c/deepspeech) or on [GitHub Discussions](https://github.com/coqui-ai/STT/discussions). :),hi like support request best use discourse,issue,positive,positive,positive,positive,positive,positive
804005838,Could you push again to make this run?,could push make run,issue,negative,neutral,neutral,neutral,neutral,neutral
803458148,"> It seem the file ds_ctcdecoder-0.9.3-p36-cp36m-manylinux2014_aarch64.whl or ds_ctcdecoder-0.9.3-py2.py3-none-any.whl is missing from the distribution

We dont support those platforms for this package. As @ftyers said have à look at Discourse some contributors shared steps to build it ",seem file missing distribution dont support package said look discourse build,issue,negative,negative,negative,negative,negative,negative
803436438,This looks like a support request. Best to use [Discourse](https://discourse.mozilla.org/c/deepspeech) or on [GitHub Discussions](https://github.com/coqui-ai/STT/discussions).,like support request best use discourse,issue,positive,positive,positive,positive,positive,positive
803074102,"> @lissyx I just tried but it seems that I do not have permission to force push -- could that be? I've got it checked out in local state with rebase rewritten history but when I attempt to `git push -f origin catalin/training-tweaks`, I get the error message
> 
> ```
> error: failed to push some refs to 'https://github.com/mozilla/DeepSpeech.git'
> ```
> 
> <img alt=""Screen Shot 2021-03-19 at 11 33 03"" width=""913"" src=""https://user-images.githubusercontent.com/332459/111827380-11886700-88a7-11eb-8075-46c0141b0295.png"">

You should not push directly on `mozilla` but on your fork, and open the PR from your fork",tried permission force push could got checked local state rebase history attempt git push origin get error message error push screen shot push directly fork open fork,issue,negative,positive,neutral,neutral,positive,positive
803033152,"@lissyx I just tried but it seems that I do not have permission to force push -- could that be? I've got it checked out in local state with rebase rewritten history but when I attempt to `git push -f origin catalin/training-tweaks`, I get the error message

```
error: failed to push some refs to 'https://github.com/mozilla/DeepSpeech.git'
```

<img width=""913"" alt=""Screen Shot 2021-03-19 at 11 33 03"" src=""https://user-images.githubusercontent.com/332459/111827380-11886700-88a7-11eb-8075-46c0141b0295.png"">",tried permission force push could got checked local state rebase history attempt git push origin get error message error push screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
802821614,@CatalinVoss Do you mind rewriting history and  remove the commit instead of having a revert? Force push is fine.,mind history remove commit instead revert force push fine,issue,negative,positive,positive,positive,positive,positive
802658326,"Please use discourse for support request. Also, deepspeech 0.6.0 is quite old.",please use discourse support request also quite old,issue,positive,positive,neutral,neutral,positive,positive
802656774,"As stated in the github template, please use discourse for support. ",stated template please use discourse support,issue,positive,neutral,neutral,neutral,neutral,neutral
802301350,"@cnair-83  did you solve your problem? I am having the same problem with audio files from length of 7 secs or less.
I always get a wrong start_time and duration",solve problem problem audio length le always get wrong duration,issue,negative,negative,negative,negative,negative,negative
800744807,"I am also facing the same issue. Do you found any solution?

I have trained deep speech on English language and I am also getting blank inference",also facing issue found solution trained deep speech language also getting blank inference,issue,negative,neutral,neutral,neutral,neutral,neutral
800367017,"> > > > Since you dont care about sharing requested infos i can only speculate on the code you wrote but this seems to be your issue and valid solution https://stackoverflow.com/a/62935174
> > > 
> > > 
> > > Thanks for your reply
> > > `word = '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94'`,
> > > this is invalid to transcode to mandarin .
> > 
> > 
> > As I said, I'm no speaker, but this looks to be a valid python string.
> > > https://stackoverflow.com/a/62935174, this link don't give a solution.\
> > 
> > 
> > Again, please use Discourse.
> 
> I am almost pretty sure '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94' not valid.
> this mandarin encode range using Unicode ：
> ![Unicode-中文编码范围](https://user-images.githubusercontent.com/25787391/111334531-978d8d80-86ae-11eb-8e73-e53ab0add7b3.png)
> 
> thanks.

Maybe. But until you follow the discourse steps to reach for support https://discourse.mozilla.org/t/what-and-how-to-report-if-you-need-support/62071:
 - we don't know what you did,
 - we don't know how you did,
 - other people have reported successfully using the mandarin model,
 - this is provided as experimental,

There's basically nothing I can do to help. Please follow the steps on Discourse.",since dont care speculate code wrote issue valid solution thanks reply word invalid mandarin said speaker valid python string link give please use discourse almost pretty sure valid mandarin encode range thanks maybe follow discourse reach support know know people successfully mandarin model provided experimental basically nothing help please follow discourse,issue,positive,positive,positive,positive,positive,positive
800358984,"> > > Since you dont care about sharing requested infos i can only speculate on the code you wrote but this seems to be your issue and valid solution https://stackoverflow.com/a/62935174
> > 
> > 
> > Thanks for your reply
> > `word = '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94'`,
> > this is invalid to transcode to mandarin .
> 
> As I said, I'm no speaker, but this looks to be a valid python string.
> 
> > https://stackoverflow.com/a/62935174, this link don't give a solution.\
> 
> Again, please use Discourse.

I am almost  pretty sure  '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94' not valid.
 this mandarin encode range using Unicode ：
![Unicode-中文编码范围](https://user-images.githubusercontent.com/25787391/111334531-978d8d80-86ae-11eb-8e73-e53ab0add7b3.png)

thanks.
",since dont care speculate code wrote issue valid solution thanks reply word invalid mandarin said speaker valid python string link give please use discourse almost pretty sure valid mandarin encode range thanks,issue,positive,positive,positive,positive,positive,positive
800123961,"> > Since you dont care about sharing requested infos i can only speculate on the code you wrote but this seems to be your issue and valid solution https://stackoverflow.com/a/62935174
> 
> Thanks for your reply
> `word = '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94'`,
> this is invalid to transcode to mandarin .

As I said, I'm no speaker, but this looks to be a valid python string.

> 
> https://stackoverflow.com/a/62935174, this link don't give a solution.\

Again, please use Discourse.",since dont care speculate code wrote issue valid solution thanks reply word invalid mandarin said speaker valid python string link give please use discourse,issue,positive,positive,positive,positive,positive,positive
800114094,"> Since you dont care about sharing requested infos i can only speculate on the code you wrote but this seems to be your issue and valid solution https://stackoverflow.com/a/62935174

Thanks for your reply
`word = '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94'`,  
this is invalid to transcode to mandarin .

 https://stackoverflow.com/a/62935174, this link don't give a solution.\
",since dont care speculate code wrote issue valid solution thanks reply word invalid mandarin link give,issue,negative,positive,positive,positive,positive,positive
799617841,"Thanks @lissyx and @reuben !

> > I checked checkpointing compatibility. I ran 2 nodes each 2 GPUs with horovod and used this checkpoints for 1 gpu on one node without horovod successfully.
> 
> Does that means ""yes"" to reuben's question ?

It was a yes. It works. No problems.
",thanks checked compatibility ran used one node without successfully yes question yes work,issue,negative,positive,positive,positive,positive,positive
799608471,"> @lissyx yeah, there is no point to target one platform with netcore or netstandard, so I can create separate PR using github actions when you finish the initial fork. Code itself it's not a problem at all, or net core/netstandard support, the main problem here (for me at least smile ) is to build it using taskcluster. I think/hope it will be much easier with github actions, so it make sense to wait until initial migration to new CI is completed

If you agree, then you can fix your PR by removing the TaskCluster bits for now, and we merge that (with green TC of course for now) and within a few days when GitHub Actions is live you can pick up :)",yeah point target one platform create separate finish initial fork code problem net support main problem least smile build much easier make sense wait initial migration new agree fix removing merge green course within day live pick,issue,positive,positive,neutral,neutral,positive,positive
799606277,"It ain't breaking badly, let's merge.",ai breaking badly let merge,issue,negative,negative,negative,negative,negative,negative
799560943,"@lissyx yeah, there is no point to target one platform with netcore or netstandard, so I can create separate PR using github actions when you finish the initial fork. Code itself it's not a problem at all, or net core/netstandard support, the main problem here (for me at least 😄  ) is to build it using taskcluster. I think/hope it will be much easier with github actions, so it make sense to wait until initial migration to new CI is completed ",yeah point target one platform create separate finish initial fork code problem net support main problem least build much easier make sense wait initial migration new,issue,positive,positive,neutral,neutral,positive,positive
799558648,"> What was the result of your CI tests?

None yet, but I just triggered TC run (maybe one of the last, see #3317)",result none yet triggered run maybe one last see,issue,negative,neutral,neutral,neutral,neutral,neutral
799557343,"> I checked checkpointing compatibility. I ran 2 nodes each 2 GPUs with horovod and used this checkpoints for 1 gpu on one node without horovod successfully.

Does that means ""yes"" to reuben's question ?",checked compatibility ran used one node without successfully yes question,issue,negative,positive,positive,positive,positive,positive
799557085,"> I think if this is passing training tests and doesn't break compatibility with loading existing checkpoints then it's OK to land as-is. The TF2 path is looking like an almost complete training code rewrite anyway, so I don't think it makes sense to block this PR on that.

Good for me.",think passing training break compatibility loading land path looking like almost complete training code rewrite anyway think sense block good,issue,negative,positive,positive,positive,positive,positive
799554843,"@stepkillah If you are okay, we are going to try with @reuben to start laying the basis for GitHub Actions very soon (I'm working on my fork for now), and maybe you might want to stick to only one platform to land this for now, but leverage the easier hackability of GitHub Actions to cover more software and hardware later.

Your feedback on how such a mess our current CI is could be very valuable into simplifying as part of GitHub Actions :)",going try start laying basis soon working fork maybe might want stick one platform land leverage easier cover hardware later feedback mess current could valuable part,issue,positive,negative,neutral,neutral,negative,negative
799550689,"@stepkillah Sorry, we are now going to move out of TaskCluster as highlighted on #3317. it might not be such a big deal in your case, but I don't know yet the extends of the change to GitHub Actions for Windows side.

Sorry about this extra work, I understand you already spent a lot of time on that. I will have a new pass of review with this in mind. You might also want to have a look at their guides: https://docs.github.com/en/actions/guides

We hope it will make it easier for people like you to contribute ! :)

Happy to review changes :)",sorry going move might big deal case know yet change side sorry extra work understand already spent lot time new pas review mind might also want look hope make easier people like contribute happy review,issue,positive,negative,neutral,neutral,negative,negative
799548682,">     * Still need to implement a solution for macOS workers (or do we? If we go ahead with #3550 is the TFLite build fast enough to just do it every time?)

We can get caching via GitHub Actions artifacts. A full blown tensorflow build seem to be consitent ~3h on their hardware (good surprise, I was expecting much worse), and a TFLite only build is ~10m ; current door-to-door workflow is ~15m when re-using cache of full blown tensorflow ; it would be ~25-30 min with no cache and only TFLite.

Currently, it requires a small piece of specific JS code for a specific GitHub Actions implem, because the default handling of artifacts makes it too tied to the workflow. This needs to be reviewed to ensure it is an acceptable augmentation of the surface of code.",still need implement solution go ahead build fast enough every time get via full blown build seem hardware good surprise much worse build current cache full blown would min cache currently small piece specific code specific default handling tied need ensure acceptable augmentation surface code,issue,positive,positive,neutral,neutral,positive,positive
799540629,"What was the result of your CI tests?

I checked checkpointing compatibility. I ran 2 nodes each 2 GPUs  with horovod and used this checkpoints for 1 gpu on one node without horovod successfully.
",result checked compatibility ran used one node without successfully,issue,negative,positive,positive,positive,positive,positive
799477508,"> So:
> 
>     * the process on macOS kinda works, but still having a weird issue of artifact uploaded but not found until running a new workflow
> 
>     * tflite seems to build, package, and `./deepspeech --version` and `./deepspeech --help` works
> 
>     * tf seems to build, package, but `./deepspeech --version` and `./deepspeech --help` dont works, `libdeepspeech` is somehow corrupted
> 
> 
> Weirdly, it's only corrupted in `native_client.tar.xz` artifact, not within `libdeepspeech.zip` one ...

I could get something green, using `gnutar` instead of the default `bsdtar`. So there are just oddities about the interaction between artifacts and workflow on GitHub Actions now.",process work still weird issue artifact found running new build package version help work build package version help dont work somehow corrupted weirdly corrupted artifact within one could get something green instead default interaction,issue,negative,negative,negative,negative,negative,negative
799211313,Since you dont care about sharing requested infos i can only speculate on the code you wrote but this seems to be your issue and valid solution https://stackoverflow.com/a/62935174,since dont care speculate code wrote issue valid solution,issue,negative,neutral,neutral,neutral,neutral,neutral
799209578,"> word = '\udce5\udcb8\udce5\udce5\udcb9\udcb3\udce6\udcba\udca6\udce5\udc8f\udce6\udcb1\udc89\udce5\udc94'

I'm no mandarin speaker but this looks as valid utf8 for that lang. 

> UnicodeEncodeError: 'utf-8' codec can't encode characters in position 0-15: surrogates not allowed

This sounds more of a python / utf8 / Windows issue. ",word mandarin speaker valid ca encode position python issue,issue,negative,neutral,neutral,neutral,neutral,neutral
799187078,"> Why this issue closed ? I didn't find solution in Discourse. and other similar questions in Discouse and here didn't get a solution. I think this is a bug , it need to be fixed ...

Please follow the guidelines for reaching for support and use discourse. ",issue closed find solution discourse similar get solution think bug need fixed please follow reaching support use discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
799035159,"Sorry, I haven't had a great deal of time so this isn't likely to proceed much for a bit. I'll try a bit more next weekend",sorry great deal time likely proceed much bit try bit next weekend,issue,positive,positive,neutral,neutral,positive,positive
798829584,Hey there! Looks like [Discourse](https://discourse.mozilla.org/c/deepspeech/247) is the right way to go for this :),hey like discourse right way go,issue,negative,positive,positive,positive,positive,positive
798729744,"> No, I did not noticed a merge request was already in progress.
> We can forget about this one.

Well, help would be welcome on the other PR, if you are willing ? We're preparing switching from taskcluster to github actions as well and most of the remaining work on that pr is about ci 😊",merge request already progress forget one well help would welcome willing switching well work,issue,positive,positive,positive,positive,positive,positive
798724995,"No, I did not noticed a merge request was already in progress.
We can forget about this one.",merge request already progress forget one,issue,negative,neutral,neutral,neutral,neutral,neutral
797623136,"So:
 - the process on macOS kinda works, but still having a weird issue of artifact uploaded but not found until running a new workflow
 - tflite seems to build, package, and `./deepspeech --version` and `./deepspeech --help` works
 - tf seems to build, package, but `./deepspeech --version` and `./deepspeech --help` dont works, `libdeepspeech` is somehow corrupted

Weirdly, it's only corrupted in `native_client.tar.xz` artifact, not within `libdeepspeech.zip` one  ...",process work still weird issue artifact found running new build package version help work build package version help dont work somehow corrupted weirdly corrupted artifact within one,issue,negative,negative,negative,negative,negative,negative
797416797,"> I think re-creating tc-decision is switching TC for an bad TC imitation. We should try to stick to the happy path in Google Actions as much as possible. Dealing with repetitive YAML files are way better than having to understand a custom dispatch solution.

Yes, that was implied in my comment, better having smaller scope and/or repetitive but ownable than recreate perfection relying on us and that people would end up rewrite anyway to own it. ",think switching bad imitation try stick happy path much possible dealing repetitive way better understand custom dispatch solution yes comment better smaller scope repetitive recreate perfection u people would end rewrite anyway,issue,positive,positive,neutral,neutral,positive,positive
797394599,I think re-creating tc-decision is switching TC for an bad TC imitation. We should try to stick to the happy path in Google Actions as much as possible. Dealing with repetitive YAML files are way better than having to understand a custom dispatch solution.,think switching bad imitation try stick happy path much possible dealing repetitive way better understand custom dispatch solution,issue,positive,positive,neutral,neutral,positive,positive
797389992,"> I hope by viable you're joking hehe. That's just as as workflow_run :P

No, I was actually serious, there's no mention of the limitations of `workflow_run` for this one, but you have to play with the API to trigger the workflow.",hope viable actually serious mention one play trigger,issue,positive,negative,negative,negative,negative,negative
797376192,"I guess the only viable alternative would be https://docs.github.com/en/rest/reference/actions#create-a-workflow-dispatch-event

And somehow, we will end up re-creating `tc-decision.py` with less flexibility :). But first, I need to sort out this mess of tensorflow artifact, it worked well on the tflite prebuild only, and it's a mess since I do full tensorflow + tflite ; there's no error, the upload seems to succeed, it's weird.",guess viable alternative would somehow end le flexibility first need sort mess artifact worked well mess since full error succeed weird,issue,negative,negative,neutral,neutral,negative,negative
797369656,"> Also, this is starting to get a bit messy in the YAML file, but maybe we can refine the workflow into several smaller pieces and rely on https://docs.github.com/en/actions/reference/events-that-trigger-workflows#workflow_run however I still lack proper understanding of `Note: This event will only trigger a workflow run if the workflow file is on the default branch.` ; it sounds like you would have the YAML infrastructure required to be on the default branch of the repo to run, which would not be the branch you work on ...

Yes. The need to have task definitions already merged before you trigger them makes using `workflow_run` a no-go, I would say. The development process would be super messy and pollute the commit log.",also starting get bit messy file maybe refine several smaller rely however still lack proper understanding note event trigger run file default like would infrastructure default branch run would branch work yes need task already trigger would say development process would super messy pollute commit log,issue,negative,negative,neutral,neutral,negative,negative
797367110,"So far I have been able to start getting a GitHub Actions workflow ""working"" for macOS build process:
 - a build job building tensorflow, exposing as a `home.tar.xz` artifact as on TC
 - a build job building our lib and native client binary, re-using the previous artifacts

I could get this to work end-to-end with the artifact serving as a cache and being properly re-populated / used as expected:
 - https://github.com/lissyx/STT/actions/runs/643518222
 - https://github.com/lissyx/STT/actions/runs/643580442

Since yesterday, I'm trying to get full blown tensorflow and while the build of tensorflow itself could complete successfully several times (~3h of build, better than expected), there were issues related to artifact handling, basically making the caching I have put in place not working (artifact missing when I see it on the UI).

Also, this is starting to get a bit messy in the YAML file, but maybe we can refine the workflow into several smaller pieces and rely on https://docs.github.com/en/actions/reference/events-that-trigger-workflows#workflow_run however I still lack proper understanding of `Note: This event will only trigger a workflow run if the workflow file is on the default branch.` ; it sounds like you would have the YAML infrastructure required to be on the default branch of the repo to run, which would not be the branch you work on ...",far able start getting working build process build job building artifact build job building native client binary previous could get work artifact serving cache properly used since yesterday trying get full blown build could complete successfully several time build better related artifact handling basically making put place working artifact missing see also starting get bit messy file maybe refine several smaller rely however still lack proper understanding note event trigger run file default like would infrastructure default branch run would branch work,issue,negative,positive,neutral,neutral,positive,positive
797091435,I'm having a hard time getting both the remote and the local cache to work when building multiple targets of the same Dockerfile in a row to be able to tag all the intermediate images. But I found this approach which should let me avoid building more than once: https://forums.docker.com/t/tag-intermediate-build-stages-multi-stage-build/34795,hard time getting remote local cache work building multiple row able tag intermediate found approach let avoid building,issue,negative,positive,neutral,neutral,positive,positive
796941065,"> Quick update: I got unexpectedly delayed with some things that came up, so I made less progress than I'd hoped but I'll continue it in the evenings this week/next weekend to get this sorted.

Gentle ping?",quick update got unexpectedly came made le progress hoped continue weekend get sorted gentle ping,issue,positive,positive,positive,positive,positive,positive
796937772,"Thanks! Have you had a look at #3373 ? This was already an effort toward that, trying to cover CI and many platforms.",thanks look already effort toward trying cover many,issue,negative,positive,positive,positive,positive,positive
795224885,"Looks like generically we can use a sequence somewhat like this:

```bash
docker login
docker pull docker.pkg.github.com/.../image:stage1 || true
docker pull docker.pkg.github.com/.../image:stage2 || true
...
docker pull docker.pkg.github.com/.../image:stageN || true

docker build -t image:stage1 --target stage1 --cache-from=docker.pkg.github.com/.../image:stage1 .
docker build -t image:stage2 --target stage2 --cache-from=docker.pkg.github.com/.../image:stage1 --cache-from=docker.pkg.github.com/.../image:stage2 .
...
docker build -t image:stage2 --target stage2 --cache-from=docker.pkg.github.com/.../image:stage1 --cache-from=docker.pkg.github.com/.../image:stage2 ... --cache-from=docker.pkg.github.com/.../image:stageN --out artifacts .
docker tag && docker push
# upload artifacts from artifacts/ folder
```

Which should cache all the intermediate stages and allow for easy sharing between workflows/jobs as well.",like generically use sequence somewhat like bash docker login docker pull stage true docker pull stage true docker pull true docker build image stage target stage stage docker build image stage target stage stage stage docker build image stage target stage stage stage docker tag docker push folder cache intermediate allow easy well,issue,positive,positive,positive,positive,positive,positive
795181167,"Posting for posterity here a multi-stage Dockerfile I've been playing with to build Python wheels and also start playing with the caching situation. It's written for our coqui-ai/STT fork but the only difference is repo and artifact names.

```Dockerfile
FROM quay.io/pypa/manylinux_2_24_x86_64 as base
RUN git clone https://github.com/coqui-ai/STT.git STT
WORKDIR /STT
RUN git submodule sync tensorflow/
RUN git submodule update --init tensorflow/

FROM base as tfbuild
RUN curl -L https://github.com/bazelbuild/bazelisk/releases/download/v1.7.5/bazelisk-linux-amd64 > /usr/local/bin/bazel && chmod +x /usr/local/bin/bazel
WORKDIR /STT/tensorflow/
ENV VIRTUAL_ENV=/tmp/cp36-cp36m-venv
RUN /opt/python/cp36-cp36m/bin/python3 -m venv $VIRTUAL_ENV
ENV PATH=""$VIRTUAL_ENV/bin:$PATH""
ENV TF_ENABLE_XLA=0
ENV TF_NEED_JEMALLOC=1
ENV TF_NEED_OPENCL_SYCL=0
ENV TF_NEED_MKL=0
ENV TF_NEED_VERBS=0
ENV TF_NEED_MPI=0
ENV TF_NEED_IGNITE=0
ENV TF_NEED_GDR=0
ENV TF_NEED_NGRAPH=0
ENV TF_DOWNLOAD_CLANG=0
ENV TF_SET_ANDROID_WORKSPACE=0
ENV TF_NEED_TENSORRT=0
ENV TF_NEED_ROCM=0
RUN echo """" | TF_NEED_CUDA=0 ./configure
RUN bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=noaws --config=nogcp --config=nohdfs --config=nonccl --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libstt.so

FROM base as pybase
RUN mkdir -p /STT/tensorflow/bazel-bin/native_client
COPY --from=tfbuild /STT/tensorflow/bazel-bin/native_client/libstt.so /STT/tensorflow/bazel-bin/native_client/libstt.so
WORKDIR /STT/native_client/python
RUN apt-get update && apt-get install -y --no-install-recommends wget && rm -rf /var/lib/apt/lists/*

FROM pybase as py36
ENV VIRTUAL_ENV=/tmp/cp36-cp36m-venv
RUN /opt/python/cp36-cp36m/bin/python3 -m venv $VIRTUAL_ENV
ENV PATH=""$VIRTUAL_ENV/bin:$PATH""
RUN pip install -U pip
RUN pip install numpy==1.7.0
ENV NUMPY_DEP_VERSION="">=1.7.0""
RUN make bindings TFDIR=/STT/tensorflow

FROM scratch as py36-artifact
COPY --from=py36 /STT/native_client/python/dist/STT-*-cp36* /
```

```bash
$ docker images
REPOSITORY                           TAG             IMAGE ID       CREATED          SIZE
linux-py-wheels                      latest          258d85e4a936   5 minutes ago    10.3MB
linux-py-wheels                      py36-artifact   258d85e4a936   5 minutes ago    10.3MB
linux-py-wheels                      py36            d2413e500df9   5 minutes ago    1.76GB
linux-py-wheels                      pybase          b31d4f23682f   8 minutes ago    1.68GB
linux-py-wheels                      tfbuild         16120c3975b7   31 minutes ago   2.42GB
linux-py-wheels                      base            dba6ce2faceb   54 minutes ago   1.64GB
```",posting posterity build python also start situation written fork difference artifact base run git clone run git sync run git update base run curl run path run echo run build bash opt base run copy run update install run path run pip install pip run pip install run make scratch copy bash docker repository tag image id size latest ago ago ago ago ago base ago,issue,negative,negative,negative,negative,negative,negative
795142272,"On a specific hardware requirement we have: KVM-enabled VMs. GitHub hosted workers don't have it, but Cirrus CI provides some level of free support for OSS and has KVM enabled workers: https://cirrus-ci.org/guide/linux/#kvm-enabled-privileged-containers

Could be something to look into. Another more exotic possibility I read somewhere is running Android emulator task on macOS hosts. I don't know if that would work on GitHub workers tho and it can also be a net negative due to macOS tasks being harder to maintain than Linux ones.",specific hardware requirement cirrus level free support could something look another exotic possibility read somewhere running android emulator task know would work tho also net negative due harder maintain,issue,negative,positive,neutral,neutral,positive,positive
795106581,"Please reach for support on Discourse, as documented in the github template. https://discourse.mozilla.org/t/read-first-what-and-how-to-report-if-you-need-support/62071",please reach support discourse template,issue,positive,neutral,neutral,neutral,neutral,neutral
795094891,"Some useful things I found in the process:

 - Tool to run workflows locally: https://github.com/nektos/act
 - We can actually do proper manylinux Python package builds using the [manylinux_2_24 images (Debian 9)](https://github.com/pypa/manylinux)
 - If GitHub Packages Docker registry caching is a viable replacement for our TC artifact + index caching system, we can probably use [multi-stage builds](https://docs.docker.com/develop/develop-images/multistage-build/) (possibly across multiple Dockerfiles) to cleanly separate different levels of needed caching to have the most optimal build times. For example, tasks to build the language binding packages only need a couple of artifacts from the build: libdeepspeech.so and deepspeech.h. With a multi-stage Docker setup you can carve out an image with just those two files and cache it side-by-side with the full image with all build artifacts.",useful found process tool run locally actually proper python package docker registry viable replacement artifact index system probably use possibly across multiple cleanly separate different optimal build time example build language binding need couple build docker setup carve image two cache full image build,issue,positive,positive,positive,positive,positive,positive
795088407,"I've been taking a look at GitHub Actions lately and it seems like a good fit:

 - Free hosted Linux, macOS and Windows workers for open source projects (allows us to move away from self-managed macOS workers right away)
 - Free unlimited package storage for OSS as well which can be used for artifact caching
 - Supports self managed workers for specific hardware or platform needs
 - Attached to the repository so makes onboarding new maintainers easier (and detached from eg. Mozilla IT)

The biggest caveat seems to be that the [self-managed workers don't have a really good security story for public repositories](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners#self-hosted-runner-security-with-public-repositories), to avoid random PRs with new CI code exploiting your infra. The best solution to that problem seems to be an approach based the idea detailed [here](https://github.com/actions/runner/issues/494#issuecomment-778613660):

> My use case would be running hardware tests using Github Actions, the only workaround I can see right now is using https://github.blog/changelog/2020-12-15-github-actions-environments-environment-protection-rules-and-environment-secrets-beta/ to have a protected environment. But these approvals depend on the service where you deploy rejecting the request if someone makes a PR where the environment section is removed from the workflow.
> 
> You could use this by having the runner under a restricted user and use the environment secrets to elevate it's access, but you would have to make sure they can't do anything malicious under the restricted user which is probably very hard.

The main questions about porting from TaskCluster to GitHub Actions from my looking seem to be:

 - How to replicate our build caching mechanism, specially for TensorFlow builds
   - I think using Docker caching pointing at GitHub Packages might be the easiest solution here, meaning we can eliminate our own caching setup for Linux and Windows jobs. Still need to implement a solution for macOS workers (or do we? If we go ahead with #3550 is the TFLite build fast enough to just do it every time?)
 - We have some dependencies from the local build system to TaskCluster artifacts (such as ds-swig), as well as things like `util/taskcluster.py`. GitHub has an artifacts REST API that we could use to reimplement the logic, but I guess this would be a good opportunity to re-evaluate the need for these hosted artifacts on a case by case basis. For stuff like, download a `native_client.tar.xz` package from the CLI as opposed to grabbing a link from GitHub Releases, I feel like it's not worth the time investment to port it. But the cases need to be listed out and evaluated.
 - Understanding better how dependencies work across jobs and particular across jobs from different workflows (can we even have multiple workflows for the ""CI task group""?) The docs mention a limitation of a maximum of 256 jobs spawned in a job matrix for a single workflow, but it's not clear to me if that applies to just when you use the `matrix` syntax, if it's per-`matrix`, or if it's a global limit per workflow.",taking look lately like good fit free open source u move away right away free unlimited package storage well used artifact self specific hardware platform need attached repository new easier detached biggest caveat really good security story public avoid random new code infra best solution problem approach based idea detailed use case would running hardware see right environment depend service deploy request someone environment section removed could use runner restricted user use environment elevate access would make sure ca anything malicious restricted user probably hard main looking seem replicate build mechanism specially think docker pointing might easiest solution meaning eliminate setup still need implement solution go ahead build fast enough every time local build system well like rest could use logic guess would good opportunity need case case basis stuff like package opposed link feel like worth time investment port need listed understanding better work across particular across different even multiple task group mention limitation maximum job matrix single clear use matrix syntax matrix global limit per,issue,positive,positive,positive,positive,positive,positive
794014008,"I think if this is passing training tests and doesn't break compatibility with loading existing checkpoints then it's OK to land as-is. The TF2 path is looking like an almost complete training code rewrite anyway, so I don't think it makes sense to block this PR on that.",think passing training break compatibility loading land path looking like almost complete training code rewrite anyway think sense block,issue,negative,positive,neutral,neutral,positive,positive
793984322,"> We know you only have sparse time but what is the current state of checking this PR? Can we support it e.g. providing further information and explanations? Are their preconditions for you like TF2 integration?

Well, I asked about tf2 specifically because I know it will take me some time to properly test this, and I wanted to avoid you waste your time on something that would be requiring complete rewrite. Unfortunately, I have not yet been able to dedicate time, but if planets gets aligned properly tonight, this might change quickly.",know sparse time current state support providing information like integration well specifically know take time properly test avoid waste time something would complete rewrite unfortunately yet able dedicate time properly tonight might change quickly,issue,negative,positive,neutral,neutral,positive,positive
793950131,"We know you only have sparse time but what is the current state of checking this PR? Can we support it e.g. providing further information and explanations? Are their preconditions for you like TF2 integration?

We already checked the problem in #3485 because @lissyx mentioned it here but we don't have any clue how to fix it. Horovod does not change performance on a single worker (single GPU). You could just blow your batch size by using multiple horovod workers (and so GPUs) to it's previous value but that's not what you want by efficiency.",know sparse time current state support providing information like integration already checked problem clue fix change performance single worker single could blow batch size multiple previous value want efficiency,issue,positive,negative,neutral,neutral,negative,negative
790444576,Please respect the GitHub issue template and reach for support on Discourse: https://discourse.mozilla.org/c/deepspeech/247,please respect issue template reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
789901263,"> Wouldn't be the same then also be true for Windows?

Yes. But Windows servers despite rare at least are a thing, and the platform is not as hard to support as macOS. Official TensorFlow builds on macOS don't have GPU support anymore so I don't see how doing the work to move to them would be beneficial.",would also true yes despite rare least thing platform hard support official support see work move would beneficial,issue,positive,positive,neutral,neutral,positive,positive
789893705,"> One thing we could do is simply drop support for the full TF runtime on macOS. I can't think of a reason to use the TF runtime on anything that isn't a server-based deployment, where everyone will be running Linux.

Wouldn't be the same then also be true for Windows?

<br>

Maybe another option would be to use the official tensorflow builds, and let users install those if they really want to use the extra gpu power?",one thing could simply drop support full ca think reason use anything deployment everyone running would also true maybe another option would use official let install really want use extra power,issue,positive,positive,positive,positive,positive,positive
789885956,"> The TFLite setup is much simpler to support and also much more useful for everyone deploying DeepSpeech client-side/on-device.

That being said, macOS ""free tier"" infra that I could test on AppVeyor only allows one parallel build, so even if we limit the amount of things, it'd be complicated.",setup much simpler support also much useful everyone said free tier infra could test one parallel build even limit amount complicated,issue,positive,positive,neutral,neutral,positive,positive
789880075,The TFLite setup is much simpler to support and also much more useful for everyone deploying DeepSpeech client-side/on-device.,setup much simpler support also much useful everyone,issue,positive,positive,positive,positive,positive,positive
789878197,"One thing we could do is simply drop support for the full TF runtime on macOS. I can't think of a reason to use the TF runtime on anything that isn't a server-based deployment, where everyone will be running Linux.",one thing could simply drop support full ca think reason use anything deployment everyone running,issue,negative,positive,positive,positive,positive,positive
789875202,"> > @DanBmh @opensorceror @stepkillah Do you know something that would allow us to have beefy managed macOS (and Windows) instances on GitLab CI ? After a few weeks of hacking over there, I'm afraid we'd be exactly in the same position as we are today with TaskCluster, with the big difference that we know taskcluster, and we are still in direct contact with the people managing it so fixing issues is quite simple for us.
> > I insist on beefy, because building tensorflow on the machines we have (MacBook Pro circa 2017, running several VMs) even on bare-metal already takes **hours**. Now we have some caching in place everywhere to limit the impact, but even `brew` needs).
> 
> Define ""beefy"".

At least 8GB of RAM, preferably 16GB, and at least 8 CPUs.



> Could you please remind me, what was the reason for building tensorflow ourself?
> 
> If building tensorflow is really that complicated an time consuming, wouldn't be using a prebuilt version for all gpu devices and using the tflite runtime (optionally with a non quantized model) for all other devices an easier option?

`libdeepspeech.so` statically links TensorFlow, plus we need to have some patches.

We already on TaskCluster have some prebuilding in place, but producing this artifact takes various times
 - ~3h on our current macOS infra
 - ~20min on our current linux builders

So each time we work on TensorFlow (upgrading to newer releases, etc.), it's ""complicated"". Currently, what we achieve is ""sustainable"" altough painful. However, given the performances of what I could test on GitLab CI  / AppVeyor, it's not impossible this would take our build time much more skyrocketting, and thus it would significantly slow down things.",know something would allow u beefy hacking afraid exactly position today big difference know still direct contact people fixing quite simple u insist beefy building pro circa running several even already place everywhere limit impact even brew need define beefy least ram preferably least could please remind reason building ourself building really complicated time consuming would version optionally non model easier option statically link plus need already place artifact various time current infra current time work complicated currently achieve sustainable painful however given could test impossible would take build time much thus would significantly slow,issue,negative,negative,negative,negative,negative,negative
789861632,"Could you please remind me, what was the reason for building tensorflow ourself?

If building tensorflow is really that complicated an time consuming, wouldn't be using a prebuilt version for all gpu devices and using the tflite runtime (optionally with a non quantized model) for all other devices an easier option?",could please remind reason building ourself building really complicated time consuming would version optionally non model easier option,issue,positive,negative,negative,negative,negative,negative
789856689,"> @DanBmh @opensorceror @stepkillah Do you know something that would allow us to have beefy managed macOS (and Windows) instances on GitLab CI ? After a few weeks of hacking over there, I'm afraid we'd be exactly in the same position as we are today with TaskCluster, with the big difference that we know taskcluster, and we are still in direct contact with the people managing it so fixing issues is quite simple for us.
> 
> I insist on beefy, because building tensorflow on the machines we have (MacBook Pro circa 2017, running several VMs) even on bare-metal already takes **hours**. Now we have some caching in place everywhere to limit the impact, but even `brew` needs).

Define ""beefy"".",know something would allow u beefy hacking afraid exactly position today big difference know still direct contact people fixing quite simple u insist beefy building pro circa running several even already place everywhere limit impact even brew need define beefy,issue,negative,positive,neutral,neutral,positive,positive
789754951,"@DanBmh @opensorceror @stepkillah Do you know something that would allow us to have beefy managed macOS (and Windows) instances on GitLab CI ? After a few weeks of hacking over there, I'm afraid we'd be exactly in the same position as we are today with TaskCluster, with the big difference that we know taskcluster, and we are still in direct contact with the people managing it so fixing issues is quite simple for us.

I insist on beefy, because building tensorflow on the machines we have (MacBook Pro circa 2017, running several VMs) even on bare-metal already takes **hours**. Now we have some caching in place everywhere to limit the impact, but even `brew` needs).",know something would allow u beefy hacking afraid exactly position today big difference know still direct contact people fixing quite simple u insist beefy building pro circa running several even already place everywhere limit impact even brew need,issue,negative,positive,neutral,neutral,positive,positive
789603344,"@carlfm01 I checked in the repo and the namespace is still `NAudio.Wave`: https://github.com/naudio/NAudio/blob/v2.0.0/NAudio.Core/Wave/WaveOutputs/WaveBuffer.cs#L4

I have no idea why it's not picking `WaveBuffer` and `WaveFileReader` anymore and I can't find proper usages examples of NAudio 2.0.0.",checked still idea ca find proper,issue,negative,neutral,neutral,neutral,neutral,neutral
789597245,"Ok, it's not as trivial as expected:
```
Build FAILED.

""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechConsole\DeepSpeechConsole.csproj"" (default target) (1) ->
(CoreCompile target) -> 
  Program.cs(84,42): error CS0246: The type or namespace name 'WaveBuffer' could not be found (are you missing a using directive or an assembly reference?) [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechConsole\DeepSpeechConsole.csproj]
  Program.cs(85,47): error CS0246: The type or namespace name 'WaveFileReader' could not be found (are you missing a using directive or an assembly reference?) [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechConsole\DeepSpeechConsole.csproj]
```",trivial build default target target error type name could found missing directive assembly reference error type name could found missing directive assembly reference,issue,negative,negative,negative,negative,negative,negative
788727157,"> > * cp 'NAudio*/lib/net35/NAudio.dll' /c/builds/tc-workdir//tmp/ds/
> 
> Hello, with version 2 the lib changed to `/lib/netstandard2.0/NAudio.dll`, I think is better to specify the version, just like your fix, without a specific version there's no guarantee that the path will stay the same under `/lib/netstandard2.0/`

Ok, but several questions then:
 - is it safe to move to 2.0.0 ?
 - shouldn't we set the version somewhere else than on the command line? won't people run into issues otherwise?",hello version think better specify version like fix without specific version guarantee path stay several safe move set version somewhere else command line wo people run otherwise,issue,positive,positive,positive,positive,positive,positive
788315652,"
> + cp 'NAudio*/lib/net35/NAudio.dll' /c/builds/tc-workdir//tmp/ds/

Hello, with version 2 the lib changed to `/lib/netstandard2.0/NAudio.dll`, I think is better to specify the version, just like your fix, without a specific version there's no guarantee that the path will stay the same under `/lib/netstandard2.0/`",hello version think better specify version like fix without specific version guarantee path stay,issue,positive,positive,positive,positive,positive,positive
788154567,"Yeah, all three of the `get_sample_size` functions in `bin/import_swb.py`, `bin/import_fisher.py`, and `bin/import_swc.py` are duplicates. Reuben had mentioned keeping each importer separate, which is why I duplicated them, but they could easily be centralized in the `util/importers.py` function. Then, the `_split_sets` function should also be centralized because it is duplicated in `import_swb.py` and `import_fisher.py`. ",yeah three keeping importer separate could easily function function also,issue,positive,positive,positive,positive,positive,positive
787544763,"Quick update: I got unexpectedly delayed with some things that came up, so I made less progress than I'd hoped but I'll continue it in the evenings this week/next weekend to get this sorted.",quick update got unexpectedly came made le progress hoped continue weekend get sorted,issue,positive,positive,positive,positive,positive,positive
787525811,"Thanks @reuben for the link to the `get_sample_size` function in import_swc.py. That made the updates to the `_split_sets` function trivial. I just submitted the PR that updates both `bin/import_swb.py` and `bin/import_fisher.py`. 

I duplicated the `get_sample_size` and `_split_sets` functions in each importer instead of centralizing them in the `utils.py` to keep the importers isolated. ",thanks link function made function trivial importer instead keep isolated,issue,negative,positive,positive,positive,positive,positive
787471493,Please reach for support on Discourse and look at examples repo where there is already voice activity detection ,please reach support discourse look already voice activity detection,issue,positive,neutral,neutral,neutral,neutral,neutral
787087928,"You already have a thread open for that on Discourse, it's not needed to file an issue. ",already thread open discourse file issue,issue,negative,neutral,neutral,neutral,neutral,neutral
786363034,"@reuben @lissyx I gave up on fixing this and just took the accuracy hit from splitting the audio file into 5-minute segments. I've published the app using this, [ReLearn](https://relearn.fyi), to the Android/iOS App Stores. It uses DeepSpeech to transcribe long video recordings of lectures for free on-device in the background (it also transcribes audio in-person recordings on Android, but uses Apple's solution for that on iOS for now). ",gave fixing took accuracy hit splitting audio file relearn transcribe long video free background also audio android apple solution,issue,positive,positive,positive,positive,positive,positive
786129066,"Oh yeah, we will also have to cover this usecase in CI, you might want to have a look at `taskcluster/tc-scorer-tests.sh`: https://github.com/mozilla/DeepSpeech/blob/385c8c769bc4aed5e6979a239591486c44f3471d/taskcluster/tc-scorer-tests.sh",oh yeah also cover might want look,issue,negative,neutral,neutral,neutral,neutral,neutral
786089160,Keeping this open until we figure out a proper fix.,keeping open figure proper fix,issue,negative,neutral,neutral,neutral,neutral,neutral
785928802,"That's great news!

I haven't been too busy on my voice project in a while but at some point I'll get back to it.",great news busy voice project point get back,issue,positive,positive,positive,positive,positive,positive
785863316,"@carlfm01 As a quick fix, I've prepared a force of `NAudio` v1.10.0 in my PR https://github.com/mozilla/DeepSpeech/pull/3539, but do you think we should investigate further?",quick fix prepared force think investigate,issue,negative,positive,positive,positive,positive,positive
785728785,"> Any assistance or direction that can be provided for us to help the developer would be appreciated.

The developer should be the one reaching to us, not end users: this is wasting everyone's time, giving us unactionable issues on code we don't own nor package, and lacking most of the useful informations.",assistance direction provided u help developer would developer one reaching u end wasting everyone time giving u code package useful,issue,positive,positive,positive,positive,positive,positive
785693526,"> We are an end user of software platform that has incorporate deepspeech into their product. They say it works in their environment but it doesn't work in ours.

I guess you need to complain to those people ? It's not like we know their code ...",end user platform incorporate product say work environment work guess need complain people like know code,issue,negative,neutral,neutral,neutral,neutral,neutral
785691692,"Please follow template, and use discourse for support request. No screenshots.",please follow template use discourse support request,issue,positive,neutral,neutral,neutral,neutral,neutral
785418901,"> > but because the toolchain at some point can't find some files and has template instantiation errors later in other libraries
> 
> It would be useful and welcome if you'd shared that on Discourse, this is not normal.

Sure, I'll make a detailed post there when I have some time soon.",point ca find template later would useful welcome discourse normal sure make detailed post time soon,issue,positive,positive,positive,positive,positive,positive
785380336,"Note: This is a VMWare Virtual Machine
![image](https://user-images.githubusercontent.com/79605987/109065186-3d099e80-76b9-11eb-87bc-6194afec3eae.png)
",note virtual machine image,issue,negative,neutral,neutral,neutral,neutral,neutral
785007093,"Ouh ok I'm sorry. I only thought is because of this documentary:
https://deepspeech.readthedocs.io/en/latest/Java-API.html
But thanks for the answer.",sorry thought documentary thanks answer,issue,negative,negative,neutral,neutral,negative,negative
785004506,We don't have Java support outside of Android for now. See #3503 ,support outside android see,issue,negative,neutral,neutral,neutral,neutral,neutral
783465421,"> but because the toolchain at some point can't find some files and has template instantiation errors later in other libraries

It would be useful and welcome if you'd shared that on Discourse, this is not normal.",point ca find template later would useful welcome discourse normal,issue,positive,positive,positive,positive,positive,positive
783451099,"I'm sorry I think you misunderstand what I wanted to say. deepspeech is converting int16 samples directly to float. Right now I have voice audio samples in float format, but to feed them to deepspeech I have to convert them to int16 and deepspeech will convert them right back to float, and that's a waste. I wish there was an API to directly feed the sampels in the float format.",sorry think misunderstand say converting directly float right voice audio float format feed convert convert right back float waste wish directly feed float format,issue,negative,positive,neutral,neutral,positive,positive
783448739,Audio format comes from the trained model. Switching means conversion... ,audio format come trained model switching conversion,issue,negative,neutral,neutral,neutral,neutral,neutral
782482616,"> It's impossible AFAIK to know whether you installed `deepspeech-tflite` or `deepspeech` or `deepspeech-gpu` after the fact.

`pip list` show shows `deepspeech`, `deepspeech-gpu` or `deepspeech-tflite`



> (1) that `deepspeech --version` produces information on which kind of client was installe

Previously, `TFLite` runtime would advise itself on `stdout` or `stderr`, it looks like it is not the case anymore.
Technically, exposing into `--version` is doable, but my fear is that people will start to want to have that and others informations exposed, while we want to keep the lib as agnostic as possible.

We already had people trying to do nasty things on CUDA and asking for us to expose CUDA infos ...



> (2) a clear error message if you try to mix incompatible models and clients

I'm not sure what room we have here for improvement without doing hacky things for a low outcome: we don't open the file ourselves, so when it fails to open it's already to late.

Here https://github.com/mozilla/DeepSpeech/blob/7b2eeb6734a49c3d9439644e9fe0685cb46ad695/native_client/tflitemodelstate.cc#L166-L170 we detect the error from TFLite runtime, but if we want to provide more meaningful error, we would have to:
 - open ourselves the file
 - start some parsing (painful to maintain potentially)
 - introduce a new error code (easy)

And from there, what better error message would you build?

I fail to get the usecase to address here, people are supposed to know what they have installed, we have different package names for the different runtimes so a package manager list operation is enough to know what runtime runs, and the error message indicates it's not the correct file. Yes, maybe it could be nicer to have a better error message, but I'm not really sure it's super critical as of now, given the downsides it pulls ...",impossible know whether fact pip list show version information kind client previously would advise like case technically version doable fear people start want exposed want keep agnostic possible already people trying nasty u expose clear error message try mix incompatible sure room improvement without hacky low outcome open file open already late detect error want provide meaningful error would open file start painful maintain potentially introduce new error code easy better error message would build fail get address people supposed know different package different package manager list operation enough know error message correct file yes maybe could better error message really sure super critical given,issue,negative,positive,neutral,neutral,positive,positive
781287130,"If you run both processes in the same container, I do not see any problems since there communication and so on.
Just install DeepSpeech as usual, but set set `DS_WITH_HOROVOD`. It will take some time longer, since Horovod will be build from PyPi (no prebuild packages). 
Without having MPI installed it should use Gloo and NCCL (already configured in your docker example?) which is fine in your setup.

Finally run
`horovodrun -np 2 python DeepSpeech --hororov [...]`",run container see since communication install usual set set take time longer since build without use already docker example fine setup finally run python,issue,negative,positive,neutral,neutral,positive,positive
781281054,"I guess I should have been more clear in my question, it's not in the context of leveraging distributed training, but on a single machine: I was thinking of giving a test run between non horovod training and horovod enabled here on my 2x RTX 2080 Ti. So, I would not care about MPI and others.",guess clear question context distributed training single machine thinking giving test run non training ti would care,issue,positive,positive,neutral,neutral,positive,positive
781224931,"As read in the [docs](https://horovod.readthedocs.io/en/stable/docker_include.html) Horovod should run within a Docker. 
As docker is not supported by our hpc system and I don't have to capability to test it locally I can not give first hand support for this.

Other people on our HPC system use Horovod within [Singularity](https://singularity.lbl.gov/) which is a HPC container environment simular to docker and mostly compatible as far as I know.",read run within docker docker system capability test locally give first hand support people system use within singularity container environment simular docker mostly compatible far know,issue,positive,positive,positive,positive,positive,positive
781223236,"Hey,

I have never tried, but there is no principle limitation I am aware of. However, using MPI, there might be some gotchas:

* If you use multiple Container the Containers need to see each other. There is a [StackOverflow entry](https://stackoverflow.com/questions/48078889/using-mpi-with-docker-containers) which discusses this. 
* Some MPI implementations try to use Kernel modules doing zero copies between processes. I am not sure how this works with Docker. However, as I remember they do have a fallback (though they might not be as fast)

I am not sure if Gloo is an alternative here.

BTW: do you know [Singularity](https://sylabs.io/singularity/ )? It's an HPC container environment, so it focuses on performance. It might be worth a look.

Best,

Andreas",hey never tried principle limitation aware however might use multiple container need see entry try use kernel zero sure work docker however remember fallback though might fast sure alternative know singularity container environment performance might worth look best,issue,positive,positive,positive,positive,positive,positive
781193284,"@NanoNabla @AndreasGocht Dumb question, but are there limitations that might make Horovod not working within a Docker context?",dumb question might make working within docker context,issue,negative,negative,negative,negative,negative,negative
780793366,@doctorwho-123 Please avoid spamming multiple repos with the same question.,please avoid multiple question,issue,negative,neutral,neutral,neutral,neutral,neutral
780790347,"Dear @doctorwho-123, please take this question to Mozilla's [Discourse](https://discourse.mozilla.org/c/deepspeech/247). GitHub issues are not a support channel.",dear please take question discourse support channel,issue,positive,neutral,neutral,neutral,neutral,neutral
779965675,"> I had this issue and using python 3.6 solved it. For anyone that run into this issue and googles it :-)

Thank you! It solve my problem and help me a lot!!",issue python anyone run issue thank solve problem help lot,issue,positive,neutral,neutral,neutral,neutral,neutral
779914102,"We will be blocked for **pushing** new packages, but hosting should still be available for at least one year:
```
UPDATE: To better support the community in this migration, JFrog has extended the JCenter new package versions submission deadline through March 31st 2021.

To clarify, the JCenter repository will keep serving packages for 12 months until February 1st 2022. Only the JCenter REST API and UI will be sunsetted on May 1st 2021.
```",blocked pushing new hosting still available least one year update better support community migration extended new package submission deadline march st clarify repository keep serving st rest may st,issue,positive,positive,positive,positive,positive,positive
779872700,"@NanoNabla Also, you'll want @reuben to have a look, but he's generally busy and currently not available for at least one full week, so please be patient :-).",also want look generally busy currently available least one full week please patient,issue,negative,positive,positive,positive,positive,positive
779839539,"> Horovod works fine with TensorFlow 2. I already took a look at #3485. There should be not problem to get it compatible with reuben's code

""no problem"" as in ""it's a piece of cake and can be folded with the tensorflow upgrade"" or as in ""it will break badly until it is fixed""

I know @reuben was having perfs issues on his PR, it'd be super nice if you have feedback / time to check if horovod helps there as well.",work fine already took look problem get compatible code problem piece cake folded upgrade break badly fixed know super nice feedback time check well,issue,negative,positive,positive,positive,positive,positive
779837865,Horovod works fine with TensorFlow 2. I already took a look at #3485. There should be not problem to get it compatible with reuben's code,work fine already took look problem get compatible code,issue,negative,positive,positive,positive,positive,positive
779836187,"> We copied your `train`-function to `train_with_horovod` but I can also provide an merge by using some `if FLAGS.horovod`. This would reduce code duplication. It is just to improve readability at the moment.

I do think this makes it very difficult to review.

One question: how can this interact with TensorFlow 2 ? @reuben is working to upgrade the training path to TF2, so if Horovod breaks or requires significant changes it might be problematic?",copied train also provide merge would reduce code duplication improve readability moment think difficult review one question interact working upgrade training path significant might problematic,issue,negative,negative,neutral,neutral,negative,negative
779805222,"I have no idea how much those splitted APKs usages are common, I'd like to avoid relying on people finding a closed issue on GitHub to know how to avoid this, that's all :)",idea much common like avoid people finding closed issue know avoid,issue,negative,negative,negative,negative,negative,negative
779803840,"I think this issue is doc enough, so we can close :)",think issue doc enough close,issue,negative,neutral,neutral,neutral,neutral,neutral
779801725,"@erksch If you think it's worth doc or example somewhere, don't hesitate to share a PR, otherwise I guess we could just close this ?",think worth doc example somewhere hesitate share otherwise guess could close,issue,negative,positive,positive,positive,positive,positive
779775743,"> Dumb question, but have you tried this code ? It could be that the linker will see the objects are already loaded and this way of loading could be enough?

You may be just completely right. I just tested it using the public DeepSpeech dependency and it works with just loading the libraries beforehand. I guess I was confused thinking that `loadLibrary` will always fail and because the guides state ""use the API *instead* of System.load()"". Thank you :D ",dumb question tried code could linker see already loaded way loading could enough may completely right tested public dependency work loading beforehand guess confused thinking always fail state use instead thank,issue,negative,negative,negative,negative,negative,negative
779712968,"BTW @stepkillah I'm sorry but I don't see any of the last review comments I left being addressed. I can understand you're busy, can you just confirm me whether this is expected or not ? Do you need more help to complete the PR ?",sorry see last review left understand busy confirm whether need help complete,issue,negative,negative,neutral,neutral,negative,negative
779709531,"> > merge again, my IDE did this automatically this time, sorry for not rebase, but seems to be good
> 
> Can you rebase on current master, fix the conflicts, and ensure you have some clear history?

Clear history is crucial, otherwise your PR does not really trigger correctly because of your merge commit.",merge ide automatically time sorry rebase good rebase current master fix ensure clear history clear history crucial otherwise really trigger correctly merge commit,issue,positive,positive,neutral,neutral,positive,positive
779708224,"> merge again, my IDE did this automatically this time, sorry for not rebase, but seems to be good

Can you rebase on current master, fix the conflicts, and ensure you have some clear history?",merge ide automatically time sorry rebase good rebase current master fix ensure clear history,issue,positive,positive,neutral,neutral,positive,positive
779690232,@lissyx I have solved the issue with support from community. Thank you.,issue support community thank,issue,positive,neutral,neutral,neutral,neutral,neutral
779483248,"> > need to adjust the call we have on our side
> 
> An idea would be that you wrap the `System.loadLibrary` calls with a try catch and allow them to fail with a loud warning but thus allowing for a user of dynamic feature modules to just call
> 
> ```
> SplitInstallHelper.loadLibrary(context, ""deepspeech"")
> SplitInstallHelper.loadLibrary(context, ""deepspeech-jni"")
> ```
> 
> right before calling any DeepSpeech functionality.
> 
> Would look like this:
> 
> ```java
> public class DeepSpeechModel {
> 
>   static {
>     try {
>         System.loadLibrary(""deepspeech-jni"");
>         System.loadLibrary(""deepspeech"");
>      } catch (UnsatisfiedLinkError e) {
>         println(""Libraries not found"")
>         // or for more android style
>         // Log.d(""DeepSpeech"", ""Libraries not found"");
>      } 
>    } 
> ```
> 
> and then in usage
> 
> ```java
> SplitInstallHelper.loadLibrary(context, ""deepspeech"")
> SplitInstallHelper.loadLibrary(context, ""deepspeech-jni"")
> DeepSpeechModel model = new DeepSpeechModel(...)
> ```

Dumb question, but have you tried this code ? It could be that the linker will see the objects are already loaded and this way of loading could be enough?",need adjust call side idea would wrap try catch allow fail loud warning thus user dynamic feature call context context right calling functionality would look like public class static try catch found android style found usage context context model new dumb question tried code could linker see already loaded way loading could enough,issue,negative,positive,neutral,neutral,positive,positive
779450256,Hmm yeah since the libraries are loaded in the `static` block we can't add a parameter like `allowLibraryLoadFail` without moving the loading to the constructor. But loading libraries in the constructor would not feel right. ,yeah since loaded static block ca add parameter like without moving loading constructor loading constructor would feel right,issue,negative,positive,positive,positive,positive,positive
779446250,"If you can confirm it works this could be a start, although I'd prefer we have a way for the user to say its okay to fail, so that people disable it on purpose. ",confirm work could start although prefer way user say fail people disable purpose,issue,negative,negative,negative,negative,negative,negative
779407020,"> need to adjust the call we have on our side

An idea would be that you wrap the `System.loadLibrary` calls with a try catch and allow them to fail with a loud warning but thus allowing for a user of dynamic feature modules to just call  
``` 
SplitInstallHelper.loadLibrary(context, ""deepspeech"")
SplitInstallHelper.loadLibrary(context, ""deepspeech-jni"")
``` 
right before calling any DeepSpeech functionality.

Would look like this:

```java
public class DeepSpeechModel {

  static {
    try {
        System.loadLibrary(""deepspeech-jni"");
        System.loadLibrary(""deepspeech"");
     } catch (UnsatisfiedLinkError e) {
        println(""Libraries not found"")
        // or for more android style
        // Log.d(""DeepSpeech"", ""Libraries not found"");
     } 
   } 
``` 

and then in usage

```java
SplitInstallHelper.loadLibrary(context, ""deepspeech"")
SplitInstallHelper.loadLibrary(context, ""deepspeech-jni"")
DeepSpeechModel model = new DeepSpeechModel(...)
````",need adjust call side idea would wrap try catch allow fail loud warning thus user dynamic feature call context context right calling functionality would look like public class static try catch found android style found usage context context model new,issue,negative,positive,neutral,neutral,positive,positive
779406802,"FTR, we already have higher-level DeepSpeech usage in https://github.com/mozilla/androidspeech/, so it would not be so uncommon.",already usage would uncommon,issue,negative,positive,positive,positive,positive,positive
779405366,"Doh, `SplitInstallSessionStatus` depends on Google Play? That would mean we make `libdeepspeech` tied to the Play Store API ? That does not sounds super-good.

@erksch Given that we want the bindings to stay as dumb and as clean as possible, wouldn't it make sense to have a wrapper on top of it for the usecase of Split APKs ? We would, I guess, need to adjust the call we have on our side, but if you write wrapper that properly loads using `SplitInstallHelper.loadLibrary()` then the symbols should be found by the linker when required.",play would mean make tied play store given want stay dumb clean possible would make sense wrapper top split would guess need adjust call side write wrapper properly found linker,issue,positive,positive,neutral,neutral,positive,positive
779404172,"> Let anybody who needs this type of library loading just change it in the Android bindings and let them build and use it themselves (pretty easy but not super maintainable)

Maybe much more maintainable on our side, in fact, but it kills the ease-of-use



> Use a library loader that is able to handle split APKs and all that stuff out of the box (e.g. [Facebook's SoLoader](https://github.com/facebook/soloader))

Not a big fan of adding third-party deps, it's going to draw issues of its own



> Find some condition to determine wether to use `System.loadLibrary(...)` or `SplitInstallHelper.loadLibrary(...)` (but I don't know any right now)

You link seems to give some hints, but I don't know about this splitted feature, so I'm unsure about the behavior of the code

```
public void onStateUpdate(SplitInstallSessionState state) {
    if (state.sessionId() == mySessionId) {
        switch (state.status()) {
            case SplitInstallSessionStatus.INSTALLED:
                // Updates the app’s context as soon as a module is installed.
                Context newContext = context.createPackageContext(context.getPackageName(), 0);
                // To load C/C++ libraries from an installed module, use the following API
                // instead of System.load().
                SplitInstallHelper.loadLibrary(newContext, “my-cpp-lib”);
                ...
        }
    }
}
```

Woudnd't this be ran to explicitely detect we have a split install session ?",let anybody need type library loading change android let build use pretty easy super maintainable maybe much maintainable side fact use library loader able handle split stuff box big fan going draw find condition determine wether use know right link give know feature unsure behavior code public void state switch case context soon module context load module use following instead ran detect split install session,issue,positive,positive,positive,positive,positive,positive
779373187,"> Please consider distribute DeepSpeech German in pbmm format.
> If this is available in the original sites, please provide the link

Please understand we don't have:
 - enough people speaking german
 - enough data for training german

So we can't support German and currently only officially provide an English model.

Next time, please make an effort and look at Discourse as documented in the GitHub template you removed: there are people sharing links to models they train.",please consider distribute german format available original please provide link please understand enough people speaking german enough data training german ca support german currently officially provide model next time please make effort look discourse template removed people link train,issue,positive,positive,neutral,neutral,positive,positive
779129986,@kunalait Read the github issue template and read the documentation.,read issue template read documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
778597339,@reuben Can you respond with an estimate on when you can look at this? It's been over a month and a half. I've given it my best shot but have run out of ideas for now. ,respond estimate look month half given best shot run,issue,positive,positive,positive,positive,positive,positive
778385350,"> 
> 
> @Ideefixze It looks good, can I ask you one last step? Can you squash all your commits into just one :)

I think it's ready now. It took me some time but I've squashed them all :> ",good ask one last step squash one think ready took time,issue,positive,positive,positive,positive,positive,positive
778306180,"@Ideefixze It looks good, can I ask you one last step? Can you squash all your commits into just one :)",good ask one last step squash one,issue,negative,positive,positive,positive,positive,positive
778093100,"More ops might have been added, but according to the docs you linked custom
ops are still a no go.

On Fri, Feb 12, 2021 at 4:48 AM lissyx <notifications@github.com> wrote:

> Whoops, the word I was looking for was ops, not instructions. Were the
> custom ops and SPLIT removed as implied in the earlier comments on this
> issue? Or is that one of the items that wasn't completed in time?
>
> Nah, I was hacking YOLO, like ""ok, let's removing the offending ops not
> caring about the output: is it enough for runtime? what about perfs?"". I
> have not had a look at the current status, maybe delegations has more ops
> now?
>
> At first when we tested TFLite it was the same, and over time it's now
> good, so we can only hope.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2270#issuecomment-778091397>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAMJTRU7VN5ZMMPY6FMMMU3S6T2ODANCNFSM4IGMGE3Q>
> .
>
",might added according linked custom still go wrote whoop word looking custom split removed issue one time hacking like let removing output enough look current status maybe first tested time good hope reply directly view,issue,positive,positive,positive,positive,positive,positive
778091397,"> Whoops, the word I was looking for was ops, not instructions. Were the custom ops and SPLIT removed as implied in the earlier comments on this issue? Or is that one of the items that wasn't completed in time?

Nah, I was hacking YOLO, like ""ok, let's removing the offending ops not caring about the output: is it enough for runtime? what about perfs?"". I have not had a look at the current status, maybe delegations has more ops now?

At first when we tested TFLite it was the same, and over time it's now good, so we can only hope.",whoop word looking custom split removed issue one time hacking like let removing output enough look current status maybe first tested time good hope,issue,positive,positive,positive,positive,positive,positive
778090074,"It's possible, but it's a new PR, probably doesn't make any sense to try and adapt or rebase this one.",possible new probably make sense try adapt rebase one,issue,negative,positive,neutral,neutral,positive,positive
778085870,"Whoops, the word I was looking for was ops, not instructions. Were the custom ops and SPLIT removed as implied in the earlier comments on this issue? Or is that one of the items that wasn't completed in time?",whoop word looking custom split removed issue one time,issue,negative,neutral,neutral,neutral,neutral,neutral
778075313,"Whatever's easiest. A new alpha would probably be fine as afaik there haven't been any breaking changes for a while now.

If not, I can make the changes again and resubmit tomorrow.",whatever easiest new alpha would probably fine breaking make resubmit tomorrow,issue,positive,positive,positive,positive,positive,positive
778074280,"> Or just download it here and drop it in: https://community-tc.services.mozilla.com/tasks/DoV-Ms9WRNKXsC_1yTPBxA

Yes, but PRs artifact expires after seven days, merges artifacts expires after a bit more, but quite quickly.
And that does not change the fact it's only on `master`, while the original report was on `0.9.3`, though I'm unsure we would release a new stable version for just that, we could do a new alpha on `master`.",drop yes artifact seven day bit quite quickly change fact master original report though unsure would release new stable version could new alpha master,issue,negative,positive,positive,positive,positive,positive
778072968,"> So this whole time I’ve been running inference only on iPhone 11’s performance CPU cores? It’s already at like 4X real-time (impressive). I’d love to start looking into this after we fix the iOS crashing.

It's possible, I already get faster than realtime on Android on a QM215 chip :)


>  Idk which instructions you guys use and whether they’re compatible with the Neural Engine, though.

We really mostly depend on TensorFlow Lite, at that level.",whole time running inference performance already like impressive love start looking fix possible already get faster android chip use whether compatible neural engine though really mostly depend lite level,issue,positive,positive,positive,positive,positive,positive
778072239,@reuben It looks like we could benefit from r2.4 for TFLite CoreML delegates that @zaptrem seems to be interested in. Do you think we could decouple this PR from the TensorFlow 2 training upgrading ?,like could benefit interested think could training,issue,positive,positive,positive,positive,positive,positive
778071868,"So this whole time I’ve been running inference only on iPhone 11’s performance CPU cores? It’s already at like 4X real-time (impressive). I’d love to start looking into this after we fix the iOS crashing. 

In a perfect world (for my specific use case) I’d target 18X, which should be possible based on Apple’s claims of “15X faster ML performance.” Idk which instructions you guys use and whether they’re compatible with the Neural Engine, though.  ",whole time running inference performance already like impressive love start looking fix perfect world specific use case target possible based apple faster use whether compatible neural engine though,issue,positive,positive,positive,positive,positive,positive
778070206,"@KathyReid I guess from out last discussion, this is not needed anymore? Can you close it if so? Thanks!",guess last discussion close thanks,issue,negative,positive,neutral,neutral,positive,positive
778068977,"@zaptrem According to https://www.tensorflow.org/lite/performance/coreml_delegate it is now available as experimental from r2.4, but upgrading to that version still requires some work: https://github.com/mozilla/DeepSpeech/pull/3482",according available experimental version still work,issue,negative,positive,positive,positive,positive,positive
778068441,"Also, as you can see on https://github.com/mozilla/tensorflow/tree/r2.3/tensorflow/lite/delegates there's Hexagon delegate, but I can't find a CoreML one anyway.",also see hexagon delegate ca find one anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
778067632,"> Was the CoreML delegate ever enabled? If so, are there benchmarks I can compare against?

Unfortunately, no, we have no benchmark: as documented in the releases, we have setup the infra in the code to enable the use of delegates, but:
 - we have had no time to work further on that
 - last time I worked on that, as you can see on this issue, there were hard limitations to the way the model is built that required complex changes
 - I don't have an iOS device, and when this landed we had no iOS support

You should try and hack with https://github.com/mozilla/DeepSpeech/blob/cc038c1263352b6364ec0ba2e0e313a8cf21d279/native_client/tflitemodelstate.cc#L102-L156 to be able to get things running.",delegate ever compare unfortunately setup infra code enable use time work last time worked see issue hard way model built complex device landed support try hack able get running,issue,negative,negative,negative,negative,negative,negative
777771454,"As said in the error, its over quota and we stopped using git-lfs. Browse github releases to get the files.",said error quota stopped browse get,issue,negative,neutral,neutral,neutral,neutral,neutral
777766618,"I'm facing similar issue and on executing *git-lfs pull*, I'm getting this error. 
```
batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.
error: failed to fetch some objects from 'https://github.com/mozilla/DeepSpeech.git/info/lfs'
```",facing similar issue pull getting error batch response repository data quota account responsible purchase data restore access error fetch,issue,negative,positive,neutral,neutral,positive,positive
777623017,"> > > I added that to the framework's build settings in Xcode a while ago and it started working for me.
> > 
> > 
> > You should make a PR then.
> 
> I would, but I don’t know whether the Xcode GUI settings interact with your build system or if I have to modify some script somewhere.

Our CI simply calls `xcodebuild` which respects the GUI settings.",added framework build ago working make would know whether interact build system modify script somewhere simply,issue,negative,neutral,neutral,neutral,neutral,neutral
777321088,"> Maybe I misunderstood how PRs work? I thought I’m only supposed to open one when I’ve built the feature/fix (like I did when I submitted the last commit changes to that Swift folder you linked to). What’s it supposed to look like when there is no change yet?

We can discuss on this issue, and then you can open the PR, for example. But I really really hate it if you know a fix, and we have other people facing an issue than can be solved by that fix.


> but it’s 4:30am here

I guess you should be sleeping :)



> I wanted to see if I could catch Reuben while he was awake/online for the other issue

Reuben and myself are on the same timezone, and it's 10:47 now, but I know he's working on other things and I'm unsure he has time in the next hours / days to look at that. But when he can, I know he will look at it, no worries. It's not we don't care, it's just we lack of time (and we still have to babysit the macOS CI infra, which is painful ...)",maybe misunderstood work thought supposed open one built like last commit swift folder linked supposed look like change yet discus issue open example really really hate know fix people facing issue fix guess sleeping see could catch issue know working unsure time next day look know look care lack time still infra painful,issue,negative,negative,negative,negative,negative,negative
777312629,"> > > > I added that to the framework's build settings in Xcode a while ago and it started working for me.
> > > 
> > > 
> > > You should make a PR then.
> > 
> > 
> > I would, but I don’t know whether the Xcode GUI settings interact with your build system or if I have to modify some script somewhere.
> 
> And I have no idea where this needs to be applied: env variable, config?
> 
> Please open a PR, we can help you, it's better than letting issues like that lay around.

Maybe I misunderstood how PRs work? I thought I’m only supposed to open one when I’ve built the feature/fix (like I did when I submitted the last commit changes to that Swift folder you linked to). What’s it supposed to look like when there is no change yet? 

If I’m not misunderstanding you I’ll definitely submit it, but it’s 4:30am here (I wanted to see if I could catch Reuben while he was awake/online for the other issue) so I’ll do it tomorrow.",added framework build ago working make would know whether interact build system modify script somewhere idea need applied variable please open help better like lay around maybe misunderstood work thought supposed open one built like last commit swift folder linked supposed look like change yet misunderstanding definitely submit see could catch issue tomorrow,issue,positive,positive,neutral,neutral,positive,positive
777310405,"> > > I added that to the framework's build settings in Xcode a while ago and it started working for me.
> > 
> > 
> > You should make a PR then.
> 
> I would, but I don’t know whether the Xcode GUI settings interact with your build system or if I have to modify some script somewhere.

And I have no idea where this needs to be applied: env variable, config?

Please open a PR, we can help you, it's better than letting issues like that lay around.",added framework build ago working make would know whether interact build system modify script somewhere idea need applied variable please open help better like lay around,issue,positive,positive,positive,positive,positive,positive
777309975,@reuben Any idea what I’m doing wrong in the proposed Swift code above?,idea wrong swift code,issue,negative,negative,negative,negative,negative,negative
777309321,"> > I added that to the framework's build settings in Xcode a while ago and it started working for me.
> 
> You should make a PR then.

I would, but I don’t know whether the Xcode GUI settings interact with your build system or if I have to modify some script somewhere. ",added framework build ago working make would know whether interact build system modify script somewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
777308267,"> I added that to the framework's build settings in Xcode a while ago and it started working for me.

You should make a PR then.",added framework build ago working make,issue,negative,neutral,neutral,neutral,neutral,neutral
777145231,"> BUILD_LIBRARY_FOR_DISTRIBUTION=YES

 @erksch I added that to the framework's build settings in Xcode a while ago and it started working for me. If you want, you can download the framework from my repo [here](https://github.com/zaptrem/react-native-transcription/blob/master/ios/Frameworks/deepspeech_ios.framework/deepspeech_ios).

However, the framework crashes completely on iOS when files are too long. I've been trying to fix the issue and provide information [here,](https://github.com/mozilla/DeepSpeech/issues/3061) but the devs haven't commented on this significant issue in nearly a month in a half. I proposed a potential fix in the most recent comment, but it isn't quite working so I haven't opened a PR yet. Would you be willing to take a look at it?",added framework build ago working want framework however framework completely long trying fix issue provide information significant issue nearly month half potential fix recent comment quite working yet would willing take look,issue,negative,positive,neutral,neutral,positive,positive
777080733,"> Spinning this off into a new project is beyond the scope of the PlayBook work - my role here is not to provide ongoing support, but to reduce _existing_ support load by creating the PlayBook.

My point is, reducing ongoing support for the usecase you want to cover in the playbook is best addressed by finding an answer to that question



>     * Add instructions to `ENVIRONMENT.md` file for deriving an image and/or adding dependencies

If at least we advertise clearly that:
 - our docker image is bare and provided as a basis to build on, but people should refrain to hack into it, except if they know what they are doing
 - how to build on top of it through `FROM:` with CV as a usecase
 
I think it should be okay.",spinning new project beyond scope playbook work role provide ongoing support reduce support load playbook point reducing ongoing support want cover playbook best finding answer question add file image least advertise clearly docker image bare provided basis build people refrain hack except know build top think,issue,positive,positive,positive,positive,positive,positive
777079063,">  Other sources suggest adding the flag `BUILD_LIBRARY_FOR_DISTRIBUTION=YES` in the build process.

I have no idea where to do that. @reuben maybe?",suggest flag build process idea maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
777078798,"> I guess a quick fix would be to update the XCode in CI that builds the releases to 12.4.

That's actually not a quick fix",guess quick fix would update actually quick fix,issue,negative,positive,positive,positive,positive,positive
777078555,"### `DATA_FORMATTING.md` comes before `ENVIRONMENT.md` in the sequence but the Docker environment is set up in `ENVIRONMENT.md`

Previously, I had instructions to `git clone` DeepSpeech and create a Python `venv`. I rewrote these instructions for `ENVIRONMENT.md` and for `TRAINING.md`, but missed `DATA_FORMATTING.md`, which assumes that there is a local copy of DeepSpeech on the filesystem. That is, the user is downloading, extracting and importing the Common Voice data on their _local filesystem_ instead of from within a Docker container.

Which is _not_ what we want to do - we want to get the user comfortable with using a Docker container for their activities. 

So the task here is:

* Move the position of `DATA_FORMATTING.md` to come _after_ `ENVIRONMENT.md`, and ensure that the tasks in `DATA_FORMATTING` use Docker, not the local host. 

### Ruled out - using inference `DockerFile`

We've ruled out this option, but I'm just stating it to be clear

### Add instructions to the `ENVIRONMENT.md` file for deriving an image and/or adding dependencies 

This is the section that deals with setting up Docker and spinning up a container. This is the place where I should talk about adding dependencies to the image if needed - ie `sox` or other dependencies for other importers. 

Task: 

* Add instructions to `ENVIRONMENT.md` file for deriving an image and/or adding dependencies 

### French Common Voice and DeepSpeech work 
https://github.com/mozilla/DeepSpeech/pull/3488#issuecomment-757811032

My understanding of this work is that it: 
* Uses `FROM` to create a new Docker image 
* Installs dependencies required for the new language 
* Uses the Docker image to create a new scorer file for the language
* New alphabet file for the language 

Is this a correct understanding? Or have I misunderstood?

Spinning this off into a new project is beyond the scope of the PlayBook work - my role here is not to provide ongoing support, but to reduce _existing_ support load by creating the PlayBook. 

## Summary

To reach resolution on this, here is what I propose as tasks: 

* Move the position of `DATA_FORMATTING.md` to come _after_ `ENVIRONMENT.md`, and ensure that the tasks in `DATA_FORMATTING` use Docker, not the local host. 

* Add instructions to `ENVIRONMENT.md` file for deriving an image and/or adding dependencies 

Are you comfortable with this approach? ",come sequence docker environment set previously git clone create python local copy user common voice data instead within docker container want want get user comfortable docker container task move position come ensure use docker local host inference option clear add file image section setting docker spinning container place talk image ie task add file image common voice work understanding work create new docker image new language docker image create new scorer file language new alphabet file language correct understanding misunderstood spinning new project beyond scope playbook work role provide ongoing support reduce support load playbook summary reach resolution propose move position come ensure use docker local host add file image comfortable approach,issue,positive,positive,neutral,neutral,positive,positive
777019685,">     * I add instructions to the PlayBook for adding dependencies like `sox` to the Docker image - and it's likely that other dependencies would be required for other Importers, so if they get stuck they know how to addd

people should derive using `FROM` from our docker image yes. Please note we don't have CI on any of the importers, so breakages are more than expected



>     * I get the user to pull down the image intended for _inference_ which does have the `sox` deps? To me that's overkill, and makes the onramp to using DeepSpeech harder

no that's no good

You forget #3: finally address my suggestion stated in https://github.com/mozilla/DeepSpeech/pull/3488#issuecomment-757811032",add playbook like docker image likely would get stuck know people derive docker image yes please note get user pull image intended harder good forget finally address suggestion stated,issue,positive,positive,positive,positive,positive,positive
777015084,"OK, so the alternatives I can see here are; 

- I add instructions to the PlayBook for adding dependencies like `sox` to the Docker image - and it's likely that other dependencies would be required for other Importers, so if they get stuck they know how to addd

- I get the user to pull down the image intended for _inference_ which does have the `sox` deps? To me that's overkill, and makes the onramp to using DeepSpeech harder 

So I think option #1 would be better - what do you think? ",see add playbook like docker image likely would get stuck know get user pull image intended harder think option would better think,issue,positive,positive,positive,positive,positive,positive
777006809,">  but the actual developer workflow that people are going to use to experiment with DeepSpeech means they will probably use the Docker Hub image to import data from CV.

I'm really not sure we should enable that, as I stated earlier.",actual developer people going use experiment probably use docker hub image import data really sure enable stated,issue,negative,positive,positive,positive,positive,positive
776999072,"I re-tested this with the Docker Hub image (not one I built myself) and tried to do data formatting for CV datasets, which is the example given in the PlayBook, and it fails on `sox` dependencies as below. 

**Can we please have this pulled into DeepSpeech so that the Docker Hub image includes `sox` deps? I know it's not _strictly_ for training, but the actual developer workflow that people are going to use to experiment with DeepSpeech means they will probably use the Docker Hub image to import data from CV.**

```
root@c7f3e6f3c302:/DeepSpeech# bin/import_cv2.py deepspeech-data/cv-corpus-6.1-2020-12-11/vi
/bin/sh: 1: sox: not found
SoX could not be found!

    If you do not have SoX, proceed here:
     - - - http://sox.sourceforge.net/ - - -

    If you do (or think that you should) have SoX, double-check your
    path variables.
    
Loading TSV file:  /DeepSpeech/deepspeech-data/cv-corpus-6.1-2020-12-11/vi/test.tsv
Importing mp3 files...
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
WARNING: No --validate_label_locale specified, your might end with inconsistent dataset.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
multiprocessing.pool.RemoteTraceback: 
""""""
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""bin/import_cv2.py"", line 65, in one_sample
    _maybe_convert_wav(mp3_filename, wav_filename)
  File ""bin/import_cv2.py"", line 185, in _maybe_convert_wav
    transformer.build(mp3_filename, wav_filename)
  File ""/usr/local/lib/python3.6/dist-packages/sox/transform.py"", line 594, in build
    input_filepath, input_array, sample_rate_in
  File ""/usr/local/lib/python3.6/dist-packages/sox/transform.py"", line 496, in _parse_inputs
    input_format['channels'] = file_info.channels(input_filepath)
  File ""/usr/local/lib/python3.6/dist-packages/sox/file_info.py"", line 82, in channels
    output = soxi(input_filepath, 'c')
  File ""/usr/local/lib/python3.6/dist-packages/sox/core.py"", line 149, in soxi
    stderr=subprocess.PIPE
  File ""/usr/lib/python3.6/subprocess.py"", line 356, in check_output
    **kwargs).stdout
  File ""/usr/lib/python3.6/subprocess.py"", line 423, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""/usr/lib/python3.6/subprocess.py"", line 729, in __init__
    restore_signals, start_new_session)
  File ""/usr/lib/python3.6/subprocess.py"", line 1364, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'sox': 'sox'
""""""This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""bin/import_cv2.py"", line 221, in <module>
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
    main()
  File ""bin/import_cv2.py"", line 216, in main
    _preprocess_data(PARAMS.tsv_dir, audio_dir, PARAMS.space_after_every_character)
  File ""bin/import_cv2.py"", line 172, in _preprocess_data
    set_samples = _maybe_convert_set(dataset, tsv_dir, audio_dir, space_after_every_character)
  File ""bin/import_cv2.py"", line 127, in _maybe_convert_set
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
    for i, processed in enumerate(pool.imap_unordered(one_sample, samples), start=1):
This install of SoX cannot process .mp3 files.
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 735, in next
This install of SoX cannot process .mp3 files.
This install of SoX cannot process .mp3 files.
    raise value
FileNotFoundError: [Errno 2] No such file or directory: 'sox': 'sox'
This install of SoX cannot process .mp3 files.
```",docker hub image one built tried data example given playbook please docker hub image know training actual developer people going use experiment probably use docker hub image import data root found could found proceed think path loading file warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent warning might end inconsistent install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process recent call last file line worker result true file line file line file line build file line file line output file line file line file line run process file line file line raise file directory install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process exception direct cause following exception recent call last file line module install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process install process main file line main file line file line install process install process enumerate install process file line next install process install process raise value file directory install process,issue,negative,positive,neutral,neutral,positive,positive
776914102,">  As I understand correctly, those fix in comments should be pushed against `r0.9` right?

And `master`, we would welcome it to both branches",understand correctly fix right master would welcome,issue,negative,positive,positive,positive,positive,positive
776894038,"Thanks for the review, I fix this doc as you proposed and add up info you pointed out to the binding code comments.
As I understand correctly, those fix in comments should be pushed against ``r0.9`` right? ",thanks review fix doc add pointed binding code understand correctly fix right,issue,negative,positive,positive,positive,positive,positive
776877995,"@Ideefixze Do you think you can address all the comments ? In both case, can you also send a PR against `r0.9` branch ?",think address case also send branch,issue,negative,neutral,neutral,neutral,neutral,neutral
776509913,"> I would appreciate it if this request was reconsidered, now that there are no more technical limitations

That's a bit of a long shot, it's still on current master, and we would need to update to the release branch containing this. If you want this feature, now that upstream allows, you might need to send PR though.",would appreciate request technical bit long shot still current master would need update release branch want feature upstream might need send though,issue,negative,negative,neutral,neutral,negative,negative
776399760,"I would like this issue to be reopened. This issue was closed because we deferred the action to upstream. Today upstream just implemented their part to support the functionality (https://github.com/tensorflow/tensorflow/commit/555034bfad7571f9f4d68ca56e47e4da65ead7b2). I would appreciate it if this request was reconsidered, now that there are no more technical limitations",would like issue issue closed deferred action upstream today upstream part support functionality would appreciate request technical,issue,positive,neutral,neutral,neutral,neutral,neutral
776199055,"@CatalinVoss Thanks for getting back! I could split it into chunks, but it would likely mess with transcriptions mid-sentence and paragraph, as well as reset the time part of tokens (I'm using intermediateDecodeWithMetadata as finishStreamWithMetadata also has an unknown crash... one problem at a time). 

It's called floatBufPointer because originally I was passing floats instead of 16bit ints and I forgot to change it. As you can see here:
```swift
 guard let format = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: file.fileFormat.sampleRate, channels: 1, interleaved: false) else { fatalError(""Couldn't read the audio file"") }

...

let floatBufPointer = UnsafeBufferPointer(start: buf.int16ChannelData?[0], count: Int(buf.frameLength))
```
I am passing the int16ChannelData. TypeOf tells me this is a pointer to an int16 array. I can also wrap it in a swift Array() and typeOf is int16[]. Weirdly enough, when I pass the Swift Array() I get a different (but still jibberish) result. 

Would it be helpful if I opened a pull request with these changes so they're easy for others to look at? 
",thanks getting back could split would likely mess paragraph well reset time part also unknown crash one problem time originally passing instead bit forgot change see swift guard let format false else could read audio file let start count passing pointer array also wrap swift array weirdly enough pas swift array get different still result would helpful pull request easy look,issue,positive,positive,neutral,neutral,positive,positive
776195299,"Sorry for the delay.

I never used the audio file recognition path that goes through `render()` so an error there could explain why you're facing issues and I'm not. I'm just capturing mic output.

As a hackky workaround, are you just calling `finishStream()` on the stream once at the very end? Is there any way you can split your monsterous audio file into chunks, passing a few chunks at at a time and ""finalize"" the stream a few times in between?

Another way to isolate the issue may be to see if you encounter the issue with long-running mic detection (which, again, I don't see), but I'm not doing hours and hours of it either.

As for your `newRender()`, hard to debug without playing with it. This kinda stuff is tricky to get right, but you only have to do it once. I am not sure why you're calling this guy a `floatBufPointer`, since the stream takes 16-bit int samples. With what you'e doing now, it certainly looks like you need to be 100% sure that your input is PCM single channel at 16 kHz.",sorry delay never used audio file recognition path go render error could explain facing output calling stream end way split audio file passing time finalize stream time another way isolate issue may see encounter issue detection see either hard without stuff tricky get right sure calling guy since stream certainly like need sure input single channel,issue,negative,positive,neutral,neutral,positive,positive
775674671,"@CatalinVoss (and @reuben if you're still here) I continued testing and I think the issue might(????) have something to do a bug in render() caused by however FFMPEG/SoX converts 48000mhz to 16000mhz.

I rewrote the render function in iOS to be much simpler and (I would think) more robust due to the utilization of higher-level Apple APIs that are file-format independent. The crash disappeared (hooray!) but I'm now getting jibberish short transcriptions (whereas the same files on Android give me acceptable results). Any idea where I went wrong here?: 

```swift
private func newRender(url: URL, stream: DeepSpeechStream) {
        let file = try! AVAudioFile(forReading: url)
        guard let format = AVAudioFormat(commonFormat: .pcmFormatInt16, sampleRate: file.fileFormat.sampleRate, channels: 1, interleaved: false) else { fatalError(""Couldn't read the audio file"") }
        print(""reading file"")
        var done = false;
        while(!done){
            let buf = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: 8096)!
            do {
                try file.read(into: buf)
            } catch {
                print(""end of file"");
                done = true
                return;
            }
            print(""read 8096 frames"")
            let floatBufPointer = UnsafeBufferPointer(start: buf.int16ChannelData?[0], count: Int(buf.frameLength))
            stream.feedAudioContent(buffer: floatBufPointer);
        }
    }

```",still continued testing think issue might something bug render however render function much simpler would think robust due utilization apple independent crash getting short whereas android give acceptable idea went wrong swift private stream let file try guard let format false else could read audio file print reading file done false done let format try catch print end file done true return print read let start count buffer,issue,negative,negative,neutral,neutral,negative,negative
775460622,"I found some relevant information from the Scala community:

https://medium.com/rahasak/publish-scala-library-project-to-maven-central-with-sonatype-d7edaa67d275

https://github.com/xerial/sbt-sonatype",found relevant information scala community,issue,negative,positive,positive,positive,positive,positive
775427015,"Hm, looks like the Java buildpack on Heroku does not expose the `mvn` executable to the worker :(",like expose executable worker,issue,negative,neutral,neutral,neutral,neutral,neutral
775425040,"We separate the building of packages and the publishing in completely different environments. Only the publishing environment has access to the necessary credentials to publish packages in our official accounts. We keep the publishing script as simple as possible, just collecting the artifacts from all the build tasks and pushing them to the relevant services. Needing a Java runtime and dependencies in that environment in order to run `mvn deploy` wouldn't fit that. I see that `maven deploy` has a `deploy-file` subcommand that would maybe be enough, specially if we can just leverage the Java buildpack to get `maven`.",separate building completely different environment access necessary publish official keep script simple possible build pushing relevant needing environment order run deploy would fit see deploy would maybe enough specially leverage get,issue,negative,positive,positive,positive,positive,positive
775420159,"I've been looking at sonatype,  which is what mavencentral works with.

Looking at the [following resource](https://support.sonatype.com/hc/en-us/articles/115006744008-How-can-I-programmatically-upload-files-into-Nexus-3-) it looks like we can use http requests to upload jars to the central repository.

[This resource](https://dzone.com/articles/publish-your-artifacts-to-maven-central) explains quite clear how to get onto the central repository.

I do think it would be easier to use `mvn deplyo` or similar tools to do this, rather than trying to use HTTP requests. Though I'm not sure how much work that would require on the backside.",looking work looking following resource like use central repository resource quite clear get onto central repository think would easier use similar rather trying use though sure much work would require backside,issue,positive,positive,positive,positive,positive,positive
774545921,"@reuben I tried converting from MKV files encoded with vorbis instead of the .ogg I was using before. Didn't work. I tried converting with Audacity manually. Didn't work. 

I wonder if it has nothing to do with the conversion and it's actually just the length of the recording. Do you know of any long conversations recorded in PCM 16 natively we can test with? 

I'm lead to this conclusion not just from my testing, but because @CatalinVoss  suggested it's a decoder issue (implying to me the audio file had already been successfully read/inference had completed). 

EDIT: Recording the WAV natively with Audacity results in no crash. Exporting the exact same recording as OGG and converting with FFMPEG crashes.",tried converting instead work tried converting audacity manually work wonder nothing conversion actually length recording know long natively test lead conclusion testing issue audio file already successfully edit recording natively audacity crash exact recording converting,issue,negative,positive,positive,positive,positive,positive
774522659,"> ok did not know that was not listed.
> Can you point me to which packages I need to download?
> thx

As i said, linux python wheel for aarch64 ",know listed point need said python wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
774522529,"Read github template, use discourse for support. ",read template use discourse support,issue,negative,neutral,neutral,neutral,neutral,neutral
774521648,"@hackebike those look to be related to your sound setup and not DeepSpeech. If you like to continue the conversation, could I recommend [DeepSpeech on Discourse](https://discourse.mozilla.org/c/deepspeech/247). Thanks!",look related sound setup like continue conversation could recommend discourse thanks,issue,positive,positive,positive,positive,positive,positive
774520570,"The exmaple works but I am seeing some ""warnings"" ?

python3 mic_vad_streaming.py -m deepspeech-0.9.3-models.tflite -s deepspeech-0.9.3-models.scorer -v 3
Initializing model...
INFO:root:ARGS.model: deepspeech-0.9.3-models.tflite
TensorFlow: v2.3.0-6-g23ad988
DeepSpeech: v0.9.3-0-gf2e9c85
INFO:root:ARGS.scorer: deepspeech-0.9.3-models.scorer
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline
ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'defaults.bluealsa.device'
ALSA lib conf.c:4568:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5036:(snd_config_expand) Args evaluate error: No such file or directory
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM bluealsa
ALSA lib confmisc.c:1281:(snd_func_refer) Unable to find definition 'defaults.bluealsa.device'
ALSA lib conf.c:4568:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory
ALSA lib conf.c:5036:(snd_config_expand) Args evaluate error: No such file or directory
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM bluealsa
ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port
ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port
ALSA lib pulse.c:243:(pulse_connect) PulseAudio: Unable to connect: Connection refused

ALSA lib pulse.c:243:(pulse_connect) PulseAudio: Unable to connect: Connection refused

ALSA lib pcm_a52.c:823:(_snd_pcm_a52_open) a52 is only for playback
ALSA lib conf.c:5014:(snd_config_expand) Unknown parameters {AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2  CARD 0}
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM iec958:{AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2  CARD 0}
ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card
ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card
ALSA lib pcm_hw.c:1822:(_snd_pcm_hw_open) Invalid value for card
ALSA lib pcm_hw.c:1822:(_snd_pcm_hw_open) Invalid value for card
ALSA lib pcm.c:2565:(snd_pcm_open_noupdate) Unknown PCM input
Listening (ctrl-C to exit)...
Recognized:",work seeing python model root gad root unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown unable find definition function returned error file directory evaluate error file directory unknown unable find definition function returned error file directory evaluate error file directory unknown unknown field port unknown field port unable connect connection unable connect connection playback unknown aes aes aes aes card unknown aes aes aes aes card invalid type card invalid type card invalid value card invalid value card unknown input listening exit,issue,negative,negative,negative,negative,negative,negative
774515803,"I was able to run it on the Raspberry PI OS 64 bit.
I tested the ~/deepspeech/DeepSpeech-examples/mic_vad_streaming $ python3 mic_vad_streaming.py -m deepspeech-0.9.3-models.tflite -s deepspeech-0.9.3-models.scorer

btw, sorry, I am new to this, so doing a lot of reading!
",able run raspberry pi o bit tested python sorry new lot reading,issue,negative,positive,neutral,neutral,positive,positive
774507772,"ok did not know that was not listed.
Can you point me to which packages I need to download?
thx",know listed point need,issue,negative,neutral,neutral,neutral,neutral,neutral
774506701,"Third, as rpi os 64 bits is still relatively new we have not had time to verify and add ci, though our Linux aarch64 python wheel are tested on armbian buster so it should work well. ",third o still relatively new time verify add though python wheel tested buster work well,issue,negative,positive,neutral,neutral,positive,positive
774506484,"First, follow the github template and seek support on Discourse. Second, aarch64 is not allowed on pypi. Please use github release linux aarch64 python wheel. ",first follow template seek support discourse second please use release python wheel,issue,positive,positive,positive,positive,positive,positive
774341335,"In general I prefer to avoid lifting functionality out of the importers into shared scripts to avoid having importers break on changes that aren't made directly to them. Datasets are mostly immutable so the importer code should also be mostly immutable. In this case, I don't expect this math will ever change anyway so it's OK to lift it into utils. I also remembered that there's already a computation in the tree for it here:

https://github.com/mozilla/DeepSpeech/blob/962a117f7ed5720435904e3ac864cc8420256ca1/bin/import_swc.py#L103-L118

And yes, updating Fisher and other affected importers is welcome. Thanks for the help!",general prefer avoid lifting functionality avoid break made directly mostly immutable importer code also mostly immutable case expect math ever change anyway lift also already computation tree yes fisher affected welcome thanks help,issue,positive,positive,positive,positive,positive,positive
774247000,"I'm open to the confidence-level approach but needed an explanation as I haven't seen dataset splits like that before. Thanks for the link. 

I see the formula for calculating the sample size on the link you shared. To check my understanding of how to implement the tool you shared in this context, here is some pseudo-code:  

```
sample_size = calc_sample_size(population_size, confidence_level, error_margin)
where:
sample_size = size of the validation and test sets.
population_size = the size of the entire dataset. 
confidence_level and error_margin  = constants set by the user. 
```

And then the training/validation/test split would be: 
```
train_size = population_size - 2*sample_size
validation_size = sample_size
test_size = sample_size
```

Is my understanding correct? 

Do you think 99% and 1% are good default values for confidence level and error margin, respectively? 

I see Fisher also uses the same `_split_sets` function. I could put the `_split_sets` function in a `./bin/utils.py` file and import that function into `./bin/import_swb.py` and `./bin/import_fisher.py` but that may be overkill for a single function, so I may instead just duplicate the function in the switchboard and fisher scripts. 

Thanks for the input!",open approach explanation seen like thanks link see formula calculating sample size link check understanding implement tool context size validation test size entire set user split would understanding correct think good default confidence level error margin respectively see fisher also function could put function file import function may single function may instead duplicate function switchboard fisher thanks input,issue,positive,positive,positive,positive,positive,positive
774227132,"That'd be my preferred approach but I don't feel too strongly about this as we're no longer using Switchboard for our trainings, so if you don't think it's reasonable I'lll take the PR with your original suggestions too :)",preferred approach feel strongly longer switchboard think reasonable take original,issue,positive,positive,positive,positive,positive,positive
774226346,"Sorry @dzubke, I missed the first email here! By confidence level I mean going for e.g. a 99% confidence level and 1% margin of error based on the number of samples in your dataset. You can use a tool such as [this one](https://www.surveymonkey.com/mp/sample-size-calculator/) for example.",sorry first confidence level mean going confidence level margin error based number use tool one example,issue,positive,negative,negative,negative,negative,negative
774210041,"Unless you have strong feelings about using the confidence level estimation approach, @reuben, I will aim to submit a PR with the changes I outlined next week.",unless strong confidence level estimation approach aim submit outlined next week,issue,positive,positive,positive,positive,positive,positive
771631671,The new graph wrecks memory utilization during training. On Quadro 6000's we used to be able to get a batch size of 128 and now even 64 runs OOM. I hope this is due to it not using the cuDNN kernel but I'm not entirely sure... Need to investigate more. Without a fix for this it's hard to justify the upgrade.,new graph memory utilization training used able get batch size even hope due kernel entirely sure need investigate without fix hard justify upgrade,issue,positive,positive,positive,positive,positive,positive
771168967,"Confirming that this is now building correctly after I pulled from master again, thank you for such a quick fix 🎉 ",confirming building correctly master thank quick fix,issue,negative,positive,positive,positive,positive,positive
770931241,"> I'm building out the DeepSpeech Playbook, and am trying to build a DeepSpeech images to train on on a different host.

As I said, it's recommended to derive from the published docker image for this kind of usecase.



> wget -O - """"https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.linux.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.0/artifacts/public/ds-swig.tar.gz"""" | tar -C /DeepSpeech/native_client/ds-swig -zxf -

it's just expired?

https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.linux.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.6/artifacts/public/ds-swig.tar.gz seems good",building playbook trying build train different host said derive docker image kind tar good,issue,positive,positive,positive,positive,positive,positive
770695487,"@reuben Does any of this help? Is there potentially an FFMPEG setting that is causing this, since it doesn't happen with non-converted WAV files?  It's been over a month since your last response, so is there any more experimentation/testing I can do to help this along?",help potentially setting causing since happen month since last response help along,issue,positive,neutral,neutral,neutral,neutral,neutral
770038736,"Yeah, I thought the validation and test sets ended up being a bit large and awkward that they aren't the same size. It also wasn't clear from the function comments that the training set would be 64% instead of 80%.  

I'm happy to submit a PR, though I'm not sure, @reuben, what a ""confidence level estimate"" is for the dataset split. What would that entail? ",yeah thought validation test ended bit large awkward size also clear function training set would instead happy submit though sure confidence level estimate split would entail,issue,positive,positive,positive,positive,positive,positive
769709169,"> Please use Discourse for support. We don't support training on Windows.

Ok dude. I install virtual machine ubuntu and try again.",please use discourse support support training dude install virtual machine try,issue,positive,neutral,neutral,neutral,neutral,neutral
769684162,Please use Discourse for support. We don't support training on Windows.,please use discourse support support training,issue,positive,neutral,neutral,neutral,neutral,neutral
769169822,"it's not a bug, no. It's just undesired behavior -- a side-effect of the algorithm with extreme values. Any attempt to ""fix"" this problem would involve some ad hoc hacking of the algorithm, which isn't a good idea without a more sound mathematical understanding of what's going on.

That being said, the hotwords algorithm isn't set in stone, and it would be welcome for someone to propose a more robust algorithm. However, the current behavior isn't a real ""bug"".",bug undesired behavior algorithm extreme attempt fix problem would involve ad hacking algorithm good idea without sound mathematical understanding going said algorithm set stone would welcome someone propose robust algorithm however current behavior real bug,issue,positive,positive,positive,positive,positive,positive
769083438,"I don't think this is a math error, just a judgement error. The .64/.16/.20 split is intended, but I do think the validation and test sets end up too large and should be based on a confidence level estimation rather than a set percentage.",think math error error split intended think validation test end large based confidence level estimation rather set percentage,issue,negative,positive,positive,positive,positive,positive
768160217,"> WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU

One of the checks for the CuDNN implementation is whether TF is running eagerly outside of any tf.functions, which means the training code as it is in this PR fails to meet the constraints and doesn't use CuDNN :/",warning layer use kernel since meet kernel criterion use generic kernel fallback running one implementation whether running eagerly outside training code meet use,issue,negative,neutral,neutral,neutral,neutral,neutral
768091793,Use Discourse and follow support guidelines.,use discourse follow support,issue,negative,neutral,neutral,neutral,neutral,neutral
767806376,"Great, thank you so much!

As for the need for channel conversion on the fly, it is for being able to train or extract raw CTCs with stereo audio files, indeed. I wasn't aware that TF's AudioSpectogram can deal with stereo audio -- that is great. However, it looks like the training code still demands mono audio:

In current master within `audio.py` in `pcm_to_np(pcm_data, audio_format=DEFAULT_FORMAT)`, we raise when audio isn't mono.

https://github.com/mozilla/DeepSpeech/blob/f27908e7e3781b4ebed228a27439d9988b13a5c7/training/deepspeech_training/util/audio.py#L583

That function gets called along the path of `change_audio_type()`, so in effect, for every sample, as you mentioned. It seems like this would be the place to update that then by not throwing (or by performing the conversion there if it turns out that something downstream indeed requires mono).",great thank much need channel conversion fly able train extract raw stereo audio indeed aware deal stereo audio great however like training code still mono audio current master within raise audio mono function along path effect every sample like would place update throwing conversion turn something downstream indeed mono,issue,positive,positive,positive,positive,positive,positive
767431186,"@CatalinVoss sorry, I haven't had time to review your comment.

> Aaaahh I see. With `NormalizeSampleRate`, that makes sense. Hmm.
> 
> I see that that only gets called in train mode, by design? (I'm trying to use some raw CTC features for something and thinking through how this fits together.) It seems like there are two things going on
> 
>     * Transformations caused by `change_audio_type`
> 
>     * Resampling using `NormalizeSampleRate`
> 
> 
> Which is causing the sample rate change and which is causing the channel change?

`NormalizeSampleRate` is causing the sample rate change, as its name implies. I was too quick in commenting on this PR about `change_audio_type` - it decodes audio (say, from a WAV file buffer or an Opus file buffer to PCM samples), but it does not change channel count or width etc. TF's AudioSpectrogram op always takes a float32 signal input and can handle mono and stereo, so the training code is actually more flexible than the inference code in that regard. Which actually makes me come back around to the very beginning on this PR: why do you want to do sample width and mono/stereo conversion? For the sample rate I completely understand the need, and that's why I added `NormalizeSampleRate`, since TF's feature extraction ops don't support variable sample rate inputs, but for channel count and sample width I don't see the reason.",sorry time review comment see sense see train mode design trying use raw something thinking together like two going causing sample rate change causing channel change causing sample rate change name quick audio say file buffer opus file buffer change channel count width always float signal input handle mono stereo training code actually flexible inference code regard actually come back around beginning want sample width conversion sample rate completely understand need added since feature extraction support variable sample rate channel count sample width see reason,issue,positive,negative,neutral,neutral,negative,negative
767206694,"I am working on a PR, should be already in the list of open PRs. It's not ready yet though.",working already list open ready yet though,issue,negative,positive,neutral,neutral,positive,positive
767204810,@TheDutchMC Can you put your fix into a fork and then link it? Nmv I found it.,put fix fork link found,issue,negative,neutral,neutral,neutral,neutral,neutral
767036178,@reuben friendly bump on this. I tried to join your Matrix chat but it didn't allow me to create an account,friendly bump tried join matrix chat allow create account,issue,positive,positive,positive,positive,positive,positive
767034178,"merge again, my IDE did this automatically this time, sorry for not rebase, but seems to be good",merge ide automatically time sorry rebase good,issue,negative,positive,neutral,neutral,positive,positive
767030424,@CatalinVoss Any idea why it would still be failing when the external scorer is disabled?,idea would still failing external scorer disabled,issue,negative,negative,neutral,neutral,negative,negative
766694527,"`tc-decision.py` is part of the CI system, which is arbitrary code execution by design :)

But I guess we should be using `safe_load` regardless. Thanks for the PR!",part system arbitrary code execution design guess regardless thanks,issue,negative,positive,neutral,neutral,positive,positive
766691652,"@stepkillah FTR I have cherry-picked your commit for `master` and merged this, and fixed the decision task on `r0.9` as well, please rebase when you can :)",commit master fixed decision task well please rebase,issue,positive,positive,neutral,neutral,positive,positive
766187984,"> > @stepkillah try to update the base image to 18.04: https://github.com/mozilla/DeepSpeech/blob/master/.taskcluster.yml#L56
> > if it fixes, please send a PR, it might just be because of Python 3.5
> 
> @lissyx great, that worked, thanks a lot :)

Please send a separate PR to fix that, against both branch `r0.9` as well as `master`",try update base image please send might python great worked thanks lot please send separate fix branch well master,issue,positive,positive,neutral,neutral,positive,positive
766154693,"> @stepkillah try to update the base image to 18.04: https://github.com/mozilla/DeepSpeech/blob/master/.taskcluster.yml#L56
> 
> if it fixes, please send a PR, it might just be because of Python 3.5

@lissyx  great, that worked, thanks a lot :)",try update base image please send might python great worked thanks lot,issue,positive,positive,neutral,neutral,positive,positive
766153829,"> @stepkillah try to update the base image to 18.04: https://github.com/mozilla/DeepSpeech/blob/master/.taskcluster.yml#L56
> 
> if it fixes, please send a PR, it might just be because of Python 3.5

trying now",try update base image please send might python trying,issue,negative,negative,negative,negative,negative,negative
766153110,"@stepkillah try to update the base image to 18.04: https://github.com/mozilla/DeepSpeech/blob/master/.taskcluster.yml#L56

if it fixes, please send a PR, it might just be because of Python 3.5",try update base image please send might python,issue,negative,negative,negative,negative,negative,negative
766152462,"> > @stepkillah it looks like you broke decision task?
> 
> hehe) yeah, trying to figure out what's wrong

there was quite some changes for taskcluster, I see you did a merge, usually it's better to rebase.",like broke decision task yeah trying figure wrong quite see merge usually better rebase,issue,negative,neutral,neutral,neutral,neutral,neutral
766151605,"> @stepkillah it looks like you broke decision task?

hehe) yeah, trying to figure out what's wrong",like broke decision task yeah trying figure wrong,issue,negative,negative,negative,negative,negative,negative
766150870,@stepkillah it looks like you broke decision task?,like broke decision task,issue,negative,neutral,neutral,neutral,neutral,neutral
765891773,"@reuben  Okay, poking at Xcode's debugging options/info is like trying to reverse engineer an alien spaceship at my current knowledge level, so I haven't learned much from a few hours trying that. 

*However,* I did get some interesting results from messing around with the scorer/models. Disabling the external scorer allowed the transcription process to run for much longer before eventually crashing (similar to the length it took my Android build to complete the same transcription task) with the same error. Additionally, using the Chinese model and scorer lasted the same extended amount of time as disabling the external scorer. Also, sometimes across all tests the ""reading samples"" message varied exactly once near the beginning of the job like so:

```
...
reading 8192 samples
reading 7425 (or some other nearby number) samples
reading 8192 samples
...
```

With No/Chinese scorer there is a drop/spike in thread activity right[ before the crash](https://cdn.discordapp.com/attachments/397167094619176962/802464472593727518/unknown.png). 
This isn't present on the [English model](https://user-images.githubusercontent.com/1612230/105574321-cc760780-5d31-11eb-9041-1a8cd97c8884.png)
). 

Is the transcription job being run on the AVAudioSession Notify Thread instead of another thread when using the English model? Alternatives have constant utilization on Thread 4 with a spike on the AV Notify Thread before the crash, whereas English has constant utilization on the AV Notify Thread.

Also, the English model resulted in much higher CPU usage during transcription than Chinese/no scorer. 

English runtime: 1 minute
None/Chinese runtime: 5 minutes


Unlikely theory: Maybe it's an ARM-specific issue? I've been testing Android with an x86 emulator and have no way to verify this one way or another (my ARM emulator isn't working). ",poking like trying reverse engineer alien spaceship current knowledge level learned much trying however get interesting messing around external scorer transcription process run much longer eventually similar length took android build complete transcription task error additionally model scorer extended amount time external scorer also sometimes across reading message varied exactly near beginning job like reading reading nearby number reading scorer thread activity right crash present model transcription job run notify thread instead another thread model constant utilization thread spike notify thread crash whereas constant utilization notify thread also model much higher usage transcription scorer minute unlikely theory maybe issue testing android emulator way verify one way another arm emulator working,issue,negative,positive,neutral,neutral,positive,positive
765850892,"(Separately, shall I cherry-pick https://github.com/mozilla/DeepSpeech/pull/3512/commits/e4bb082f8051d02be386d31b890e618acf5729b6 into a separate PR? That is still wrong as it stands.)",separately shall separate still wrong,issue,negative,negative,negative,negative,negative,negative
765839983,"I can see that `change_audio_type` is always applied, even if the augmentations list is empty. However, I don't see how that alone transforms channels and sample rate.

The sample starts off with `AUDIO_TYPE_WAV`. Then it seems that we go from wav to `AUDIO_TYPE_PCM` to `AUDIO_TYPE_NP` if I follow this correctly. The first step calls `read_audio` which calls `read_wav` but on a byte stream, not a file. Then `pcm_to_np` is called, but that already assumes a mono buffer and doesn't change sample rate.",see always applied even list empty however see alone sample rate sample go follow correctly first step stream file already mono buffer change sample rate,issue,negative,positive,neutral,neutral,positive,positive
765830632,"Aaaahh I see. With `NormalizeSampleRate`, that makes sense. Hmm.

I see that that only gets called in train mode, by design? (I'm trying to use some raw CTC features for something and thinking through how this fits together.) It seems like there are two things going on

- Transformations caused by `change_audio_type`
- Resampling using `NormalizeSampleRate`

Which is causing the sample rate change and which is causing the channel change?",see sense see train mode design trying use raw something thinking together like two going causing sample rate change causing channel change,issue,negative,negative,negative,negative,negative,negative
765750576,"This is already done here: https://github.com/mozilla/DeepSpeech/blob/fcbd92d0d75beee36473aa44669fa330ca522cdc/training/deepspeech_training/util/augmentations.py#L165

(It's called even if no augmentations are applied)

There was a bug where the actual sample rate from the file was only read after signal augmentations had already been applied, but this was fixed as part of #3493 where I added a sample rate normalization ""augmentation"".",already done even applied bug actual sample rate file read signal already applied fixed part added sample rate normalization augmentation,issue,negative,positive,neutral,neutral,positive,positive
765726667,This looks awesome! Hopefully with lots of positive downstream impact.,awesome hopefully lot positive downstream impact,issue,positive,positive,positive,positive,positive,positive
765247394,"> > Yes, I'm already doing that because the Metadata and Token arrays were (erroneously?) marked as `private(set)` instead of `public private(set)`.
> 
> PRs are welcome.

@reuben It's a bit late, but I just proposed those quick changes here: https://github.com/mozilla/DeepSpeech/pull/3510

I also think there's some more debug info I can provide about the decoder issue, I'll test it tomorrow.",yes already token erroneously marked private set instead public private set welcome bit late quick also think provide issue test tomorrow,issue,positive,positive,positive,positive,positive,positive
764612170,"> I looked into the TensorFlow code. It seems that, sadly, only file paths not file descriptors are supported. I will have to find another solution then

Maybe try to open the issue upstream ? Tensorflow folks might be interested. They are usually open. ",code sadly file file find another solution maybe try open issue upstream might interested usually open,issue,negative,negative,neutral,neutral,negative,negative
764608899,"> already relies on mmap() on

This is what I would like to keep doing

> Putting the model into the app data directory

There are two data directories on Android:

- `/data/data/org.deepspeechdemo`: To get the file here, we would need to copy it from internal storage. This would lead to duplicating 1 GiB of data, and there isn't that much storage on a phone. There is a potential alternative of using internet instead, but that is even worse
- `/sdcard/Android/data/org.deepspeechdemo`: This is what we were using before my PR. Android 11 has removed the ability for users and apps to access that directory. A USB cable has become required, and that is not convenient for the user

> TensorFlow does not allows us to do this

I looked into the TensorFlow code. It seems that, sadly, only file paths not file descriptors are supported. I will have to find another solution then",already would like keep model data directory two data android get file would need copy internal storage would lead gib data much storage phone potential alternative instead even worse android removed ability access directory cable become convenient user u code sadly file file find another solution,issue,negative,negative,negative,negative,negative,negative
764566480,"> > See
> 
> That PR adds the option of using an array or string instead of the path. I have an `int` file descriptor, not an array or string. If I wanted to read the file descriptor myself, I would have used a temporary file. Reading it to an array is not ideal because RAM is at a premium on Anhroid devices. This is why I want to pass in the file descriptor and have it `mmap`ed

Yes, please have a look at the discussions about that: long story short, as much as I can remember, TensorFlow does not allows us to do this.

Current implementation already relies on `mmap()` on all platforms.

Putting the model into the app data directory should avoid requesting extra permissions.",see option array string instead path file array string read file would used temporary file reading array ideal ram premium want pas file yes please look long story short much remember u current implementation already model data directory avoid extra,issue,positive,positive,positive,positive,positive,positive
764520929,"> See

That PR adds the option of using an array or string instead of the path. I have an `int` file descriptor, not an array or string. If I wanted to read the file descriptor myself, I would have used a temporary file. Reading it to an array is not ideal because RAM is at a premium on Anhroid devices. This is why I want to pass in the file descriptor and have it `mmap`ed",see option array string instead path file array string read file would used temporary file reading array ideal ram premium want pas file,issue,positive,positive,positive,positive,positive,positive
764000166,Fixed by #3505. @NanoNabla Don't hesitate to send new PR for the doc counter part to help people how to do this in the future :),fixed hesitate send new doc counter part help people future,issue,negative,positive,neutral,neutral,positive,positive
763999547,">  It should also be mentioned to use https://github.com/lissyx/swig/tree/taskcluster instead of plain swig when there are no prebuilds. I did not found this in the docu.

I remember  I documented that in the past. Please make a new PR against `doc/` to make sure we cover this.

Maybe introduce some ""Building CTC Decoder for training on unsupported platforms"" ?",also use instead plain swig found remember past please make new make sure cover maybe introduce building training unsupported,issue,negative,positive,neutral,neutral,positive,positive
763946727,I had this issue and using python 3.6 solved it. For anyone that run into this issue and googles it :-),issue python anyone run issue,issue,negative,neutral,neutral,neutral,neutral,neutral
763927748,"I nearly forgot:
It should also be mentioned to use https://github.com/lissyx/swig/tree/taskcluster instead of plain swig when there are no prebuilds. I did not found this in the docu.",nearly forgot also use instead plain swig found,issue,negative,negative,neutral,neutral,negative,negative
763909305,"> I'm not sure how we can document that in a way that does not get messy

I think at a minimum somehow in a discourse thread. Since ppc64le is used on IBM's AC922 their should be some user which are targeted.",sure document way get messy think minimum somehow discourse thread since used user targeted,issue,negative,positive,positive,positive,positive,positive
763895497,"@NanoNabla Let's see if it's green with that, and thanks!",let see green thanks,issue,negative,neutral,neutral,neutral,neutral,neutral
763894201,"> For `ppc64le` set `PYTHON_PLATFORM_NAME=""--plat-name linux_ppc64le""`. This should be mentioned somehow in docu

I'm not sure how we can document that in a way that does not get messy",set somehow sure document way get messy,issue,negative,positive,positive,positive,positive,positive
763806186,"@NanoNabla This diff should fix being able to override the `SWIG_DIST_URL`:
```
diff --git a/native_client/definitions.mk b/native_client/definitions.mk
index 69fe4539..b2f8a985 100644
--- a/native_client/definitions.mk
+++ b/native_client/definitions.mk
@@ -207,6 +207,7 @@ define copy_missing_libs
 endef
 
 SWIG_DIST_URL ?= 
+ifeq ($(SWIG_DIST_URL),)
 ifeq ($(findstring Linux,$(OS)),Linux)
 SWIG_DIST_URL := ""https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.linux.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.0/artifacts/public/ds-swig.tar.gz""
 else ifeq ($(findstring Darwin,$(OS)),Darwin)
@@ -215,7 +216,8 @@ else ifeq ($(findstring _NT,$(OS)),_NT)
 SWIG_DIST_URL := ""https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.swig.win.amd64.1a4c14945012f1282c2eddc174fb7674d5295de8.0/artifacts/public/ds-swig.tar.gz""
 else
 $(error There is no prebuilt SWIG available for your platform. Please produce one and set SWIG_DIST_URL.)
-endif
+endif # findstring()
+endif # ($(SWIG_DIST_URL),)
 
 # Should point to native_client/ subdir by default
 SWIG_ROOT ?= $(abspath $(shell dirname ""$(lastword $(MAKEFILE_LIST))""))/ds-swig
```

I'll let you fix also the case of `PYTHON_PLATFORM_NAME` as suggested and test that on your side, and I'll welcome it as a PR.",fix able override git index fe define o else o else o else error swig available platform please produce one set point default shell let fix also case test side welcome,issue,negative,positive,positive,positive,positive,positive
763800079,"> I'm not that familiar with your build system.

This is not ours per choice, this is a side-effect from using TensorFlow.



> Moreover, do I have to create a `config_setting` target in `BUILD`?

I dont think you need that to be able to build, and we have no mean to support a ppc64le builds, except if you can provide hw and babysit this, which I suspect you don't have bandwith as well :)



>  Simply running `SWIG_DIST_URL=https://[...] TARGET=ppc64le make bindings` results in echoing `There is no prebuilt SWIG available for ppc64le. Please produce one and set SWIG_DIST_URL`

Well, this is something we put in place to help people in your case, but since we don't use it it's not surprising it might not work as expected.

It's handled in the `Makefile`: https://github.com/mozilla/DeepSpeech/blob/master/native_client/definitions.mk#L209-L218



> I did a commit on my fork https://github.com/tud-zih-tools/DeepSpeech/tree/ppc64le_integration but setting `SWIG_DIST_URL` seems not to work.

Since you change code, you should have
```
ifeq ($(TARGET),ppc64le)
SWIG_DIST_URL := url/to/your/build
else
```

@NanoNabla Maybe just change all `:=` to `?=` so `make` can  pick your `SWIG_DIST_URL` from CLI? And do the same for `PYTHON_PLATFORM_NAME` so you don't have to change `TARGET` (because it's going to introduce other issues, in your case the correct value is `TARGET=host`)",familiar build system per choice moreover create target build dont think need able build mean support except provide suspect well simply running make swig available please produce one set well something put place help people case since use surprising might work handled commit fork setting work since change code target else maybe change make pick change target going introduce case correct value,issue,positive,positive,positive,positive,positive,positive
763770942,"I'm working on a proper PR. I did a commit on my fork https://github.com/tud-zih-tools/DeepSpeech/tree/ppc64le_integration but setting `SWIG_DIST_URL` seems not to work.
Simply running `SWIG_DIST_URL=https://[...] TARGET=ppc64le make bindings` results in echoing `There is no prebuilt SWIG available for ppc64le. Please produce one and set SWIG_DIST_URL`

Moreover, do I have to create a `config_setting` target in `BUILD`?

I'm not that familiar with your build system.",working proper commit fork setting work simply running make swig available please produce one set moreover create target build familiar build system,issue,positive,positive,positive,positive,positive,positive
763605231,"> @stepkillah Gentle ping, have you had time to look at that PR ?

really thanks for pinging, totally forgot about this PR. I'll look into that during this week 💯 ",gentle ping time look really thanks totally forgot look week,issue,positive,positive,positive,positive,positive,positive
762990534,"> > 
> 
> The swig in `ds-swig` was not runable on PPC.

The prebuilt ones, it's expected, we don't have binaries for PPC



> Therefore I simply build it from source into a directory named the same `ds-swig`.

I just advise to use my tree for building



> but the generated whl in (maybe corrupted?) manylinux1_x86_64 format. Changing `PYTHON_PLATFORM_NAME` fixed this problem.

That's not really a bug, we force `manulinux1_x86_64` on any linux platform, I guess we could relax that and check the arch somehow, so we allow people to override `PYTHON_PLATFORM_NAME` as you need to.



> I could supply a PR for this `PYTHON_PLATFORM_NAME` but I do not know how to deal for swig.

Please do so, and for swig, rebuilding is fine, just build it from  https://github.com/lissyx/swig/tree/taskcluster. If you send a PR, it's a good thing to also ensure we document that.",swig therefore simply build source directory advise use tree building maybe corrupted format fixed problem really bug force platform guess could relax check arch somehow allow people override need could supply know deal swig please swig fine build send good thing also ensure document,issue,positive,positive,positive,positive,positive,positive
762977242,"> Don't use that, it was documented (but it seems to have disappeared) to use https://github.com/lissyx/swig/tree/taskcluster (it includes fixed for nodejs)
Thanks for this hint. We did not use nodejs, so there was no problem.

> So it was simply PYTHON_PLATFORM_NAME to change? Send
Changing `PYTHON_PLATFORM_NAME` was needed and building swig. 

The swig in `ds-swig` was not runable on PPC. Therefore I simply build it from source into a directory named the same `ds-swig`. Building ctcdecoder  was no problem with this swig building but the generated whl in (maybe corrupted?) manylinux1_x86_64 format. Changing `PYTHON_PLATFORM_NAME` fixed this problem.

I could supply a PR for this `PYTHON_PLATFORM_NAME` but I do not know how to deal for swig.",use use fixed thanks hint use problem simply change send building swig swig therefore simply build source directory building problem swig building maybe corrupted format fixed problem could supply know deal swig,issue,negative,positive,neutral,neutral,positive,positive
762945287,"> # build your own SWIG
> mv ds-swig ds-swig.orig
> wget http://prdownloads.sourceforge.net/swig/swig-4.0.2.tar.gz
> tar xfz swig-4.0.2.tar.gz
> cd swig-4.0.2
> ./configure --prefix=`realpath ../ds-swig`
> make
> make install

Don't use that, it was documented (but it seems to have disappeared) to use https://github.com/lissyx/swig/tree/taskcluster (it includes fixed for nodejs)



> For should be a better solution for `PYTHON_PLATFORM_NAME` than simply change it by hand, but it worked.

So it was simply PYTHON_PLATFORM_NAME to change? Send a PR to make it overrideable from CLI, that would be welcome.",build swig tar make make install use use fixed better solution simply change hand worked simply change send make would welcome,issue,positive,positive,positive,positive,positive,positive
762940949,"I know the problem is solved on the cluster of TUD and already reported it to @NormanTUD.

To put the solution on record for everybody else with the same problem on PowerPC.

```
# build your own SWIG
mv ds-swig ds-swig.orig
wget http://prdownloads.sourceforge.net/swig/swig-4.0.2.tar.gz
tar xfz swig-4.0.2.tar.gz
cd swig-4.0.2
./configure --prefix=`realpath ../ds-swig`
make
make install

cd ctcdecode
# in ../definitions.mk replace ""PYTHON_PLATFORM_NAME := --plat-name manylinux1_x86_64"" by ""PYTHON_PLATFORM_NAME := --plat-name linux_ppc64le""
make bindings
pip install dist/ds_ctcdecoder-0.9.1-cp37-cp37m-linux_ppc64le.whl
```
For should be a better solution for `PYTHON_PLATFORM_NAME` than simply change it by hand, but it worked.

Ticket can be closed then.

",know problem cluster already put solution record everybody else problem build swig tar make make install replace make pip install better solution simply change hand worked ticket closed,issue,positive,positive,positive,positive,positive,positive
762895103,"@stepkillah Gentle ping, have you had time to look at that PR ?",gentle ping time look,issue,negative,positive,positive,positive,positive,positive
762751835,"Let me finish my sport, i might have a better idea than gradle composition ",let finish sport might better idea composition,issue,negative,positive,positive,positive,positive,positive
762383035,"This should allow mixing sample rates by normalizing all training files to `--audio_sample_rate`. Validation and test sets are not normalized by default and should be taken care of manually, I felt like it's better to leave those sets as untouched as possible.",allow sample training validation test default taken care manually felt like better leave untouched possible,issue,positive,positive,positive,positive,positive,positive
762198214,"Short update. I've been able to compile the required .so's and get it to compile and run in Java. Not sure if it *actually* works, because I've still got no clue how to use DeepSpeech, but at least there are no errors.

**Get it up and running**
./native_client/java/libdeepspeech/CMakeLists.txt:
```cmake
cmake_minimum_required(VERSION 3.10)

include_directories( ${CMAKE_JAVA_} $ENV{JAVA_HOME}/include $ENV{JAVA_HOME}/include/linux )

add_library( deepspeech-jni SHARED ../jni/deepspeech_wrap.cpp )

find_library(deepspeech-lib NAMES deepspeech PATHS ${CMAKE_SOURCE_DIR}/libs/ REQUIRED)
message(STATUS ${deepspeech-lib})

add_custom_command( TARGET deepspeech-jni POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy ${CMAKE_SOURCE_DIR}/libs/libdeepspeech.so ${CMAKE_LIBRARY_OUTPUT_DIRECTORY}/libdeepspeech.so )

target_link_libraries( deepspeech-jni ${deepspeech-lib} )
```
Create java bindings with SWIG:
1. in `./native_client/java`:
```bash
swig -c++ -java -package org.deepspeech.libdeepspeech -outdir libdeepspeech/src/main/java/org/deepspeech/libdeepspeech/ -o jni/deepspeech_wrap.cpp jni/deepspeech.i
```

Modify `./native_client/java/libdeepspeech/src/main/java/org/deepspeech/libdeepspeech/DeepSpeechModel.java`:
Replace the current static block with:
```java
    static {
        String jniName = ""libdeepspeech-jni.so"";
        String libName = ""libdeepspeech.so"";
        URL jniUrl = DeepSpeechModel.class.getResource(""/jni/x86_64/"" + jniName);
        URL libUrl = DeepSpeechModel.class.getResource(""/jni/x86_64/"" + libName);
        File tmpDir = null;
		try {
			tmpDir = Files.createTempDirectory(""libdeepspeech"").toFile();
		} catch (IOException e) {
			e.printStackTrace();
		}
        tmpDir.deleteOnExit();
    	
        File jniTmpFile = new File(tmpDir, jniName);
        jniTmpFile.deleteOnExit();
        File libTmpFile = new File(tmpDir, libName);
        libTmpFile.deleteOnExit();
        
        try (
        		InputStream jniIn = jniUrl.openStream();
        		InputStream libIn = libUrl.openStream();
        ) {
            Files.copy(jniIn, jniTmpFile.toPath());
            Files.copy(libIn, libTmpFile.toPath());
        } catch (IOException e) {
			e.printStackTrace();
		}
        
        System.load(jniTmpFile.getAbsolutePath());
        System.load(libTmpFile.getAbsolutePath());
    }
```
Compile with Gradle:
1. in `./native_client/java`:`./gradlew build`

Compile `libdeepspeech-jni.so`
1. in `./native_client/java/libdeepspeech`: `cmake .`
2. in `./native_client/java/libdeepspeech`: `sudo make` (I had permission issues without sudo`

Use in your own project:
1. Copy `./native_client/java/libdeepspeech/libdeepspeech-jni.so` to `./{YOUR PROJECT}/src/main/resources/jni/x86_64/libdeepspeech-jni.so`
2. Copy `./native_client/java/libdeepspeech/libs/libdeepspeech.so` to `./{YOUR PROJECT}/src/main/resources/jni/x86_64/libdeepspeech.so`
3. Copy `./native_client/java/libdeepspeech/build/libs/libdeepspeech.jar` to `./{YOUR PROJECT}/libs/libdeepspeech.jar`
4. Modify build.gradle
```groovy
plugins {
    id 'com.github.johnrengelman.shadow' version '5.0.0'
}

repositories {
    flatDir {
        dirs 'libs'
    }
}

dependencies {
    compile ':libdeepspeech'
}
```
5. in `./{YOUR PROJECT}`  run `./gradlew shadowJar`

This should be all steps necessary to include DeepSpeech in a Non-Android Java application.

**Todo**
- Automate all this
- This way will only support x86-64 Linux, fine for me but maybe not for others

I've not yet tested if it works, since I have not yet fully figured out how to work with DeepSpeech, but my console output is as follows:
```
TensorFlow: v2.3.0-6-g23ad988
DeepSpeech: v0.9.3-0-gf2e9c85
2021-01-18 12:26:49.869005: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Extracting audio features...
Running inference...

Finished! Took 1848
```

It runs without errors though it does not seem to produce any useful output (hence the blank line)

Test code: https://paste.md-5.net/qujujoneha.java

",short update able compile get compile run sure actually work still got clue use least get running version message status target command copy create swig bash swig modify replace current static block static string string file null try catch file new file file new file try catch compile build compile make permission without use project copy project copy project copy project modify groovy id version compile project run necessary include application way support fine maybe yet tested work since yet fully figured work console output gad binary deep neural network library use following enable rebuild appropriate compiler audio running inference finished took without though seem produce useful output hence blank line test code,issue,positive,positive,positive,positive,positive,positive
762052603,"> @TheDutchMC I know nothing about Java, will this work on non Android systems?
> https://github.com/mozilla/DeepSpeech/blob/master/native_client/java/libdeepspeech/src/main/java/org/deepspeech/libdeepspeech/DeepSpeechModel.java#L8-L11

Yes that will definitely work! That's 'vanilla' Java",know nothing work non android yes definitely work,issue,positive,neutral,neutral,neutral,neutral,neutral
761912608,"@TheDutchMC I know nothing about Java, will this work on non Android systems?
https://github.com/mozilla/DeepSpeech/blob/master/native_client/java/libdeepspeech/src/main/java/org/deepspeech/libdeepspeech/DeepSpeechModel.java#L8-L11",know nothing work non android,issue,negative,neutral,neutral,neutral,neutral,neutral
761912116,"> I think the last item to fix is going to be the native .so files that are required. libdeepspeech.so is working, however I'm not quite sure where deepspeech-jni.so is supposed to come from.

As I said on Matrix, it's being built by the `bindings` target in the `Makefile`",think last item fix going native working however quite sure supposed come said matrix built target,issue,negative,positive,positive,positive,positive,positive
761902834,"I have now yes, and have been able to produce a jar which can be loaded by Gradle in a non-android project.

I think the last item to fix is going to be the native .so files that are required. libdeepspeech.so is working, however I'm not quite sure where deepspeech-jni.so is supposed to come from. ",yes able produce jar loaded project think last item fix going native working however quite sure supposed come,issue,positive,positive,positive,positive,positive,positive
761864093,"> Running `./gradlew build`, which I think is the correct command to use, produces the following now: https://paste.md-5.net/etigohuneg.coffeescript

Have you followed the documented steps to rebuild the android bindings?",running build think correct command use following rebuild android,issue,negative,neutral,neutral,neutral,neutral,neutral
761848885,"The error looks like something to do with SWIG, there is documentation here: http://www.swig.org/Doc1.3/Java.html",error like something swig documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
761792594,"Right okay. So I've kindof cleaned up the build.gradle files, as to not include anything Android specific.  ``gradle wrapper`` now runs at least:
[./native_client/java/build.gradle](https://paste.md-5.net/adeqemijoc.bash)
[./native_client/java/libdeepspeech/build.gradle](https://paste.md-5.net/udexirozob.cs)

Running ``./gradlew build``, which I think is the correct command to use, produces the following now: https://paste.md-5.net/etigohuneg.coffeescript

I'm not at all familiar with Android flavoured Gradle, so there's a very real chance I took out the wrong bits (hence why they're commented out).",right include anything android specific wrapper least running build think correct command use following familiar android real chance took wrong hence,issue,negative,positive,neutral,neutral,positive,positive
761684623,"> Is there any chance the build.gradle could be modified, or a seperate non-Android version be made, for those that don't use Android?

There's no non-Android Java because nobody asked or stepped to do it. If you know Java well, then you are welcome.



> I'd love to do it myself, but know nothing about bindings etc.

For the binding part you can rely on the existing.",chance could version made use android nobody stepped know well welcome love know nothing binding part rely,issue,positive,positive,positive,positive,positive,positive
761648691,"@the-nose-knows it's never to early to start. What is the ""Android specific gradle stuff"" that you would like it to not rely on? Perhaps start there, and feel free to join us on [Matrix](https://chat.mozilla.org/#/room/#machine-learning:mozilla.org) to discuss further.",never early start android specific stuff would like rely perhaps start feel free join u matrix discus,issue,positive,positive,positive,positive,positive,positive
761594750,"> @lissyx i am calling the function directly
> 
> `from ds_ctcdecoder import Scorer, Alphabet, ctc_beam_search_decoder hot_words = {""monday"":1.5} alphabet = Alphabet(""alphabet.path"") scorer = Scorer(1, 2.5, scorer_path=""scorer.path"", alphabet=alphabet) res = ctc_beam_search_decoder( probs_list, alphabet, beam_size=10, cutoff_prob=1, cutoff_top_n=40, scorer=scorer, hot_words=hot_words )`

Well, this is not supported, it's not a bug. Please reach for support on Discourse.",calling function directly import scorer alphabet alphabet alphabet scorer scorer alphabet well bug please reach support discourse,issue,positive,positive,neutral,neutral,positive,positive
761590708,"@lissyx i am calling the function directly

`
from ds_ctcdecoder import Scorer, Alphabet, ctc_beam_search_decoder
hot_words = {""monday"":1.5} 
alphabet = Alphabet(""alphabet.path"") 
scorer = Scorer(1, 2.5, scorer_path=""scorer.path"", alphabet=alphabet) 
res = ctc_beam_search_decoder( probs_list, alphabet, beam_size=10, cutoff_prob=1, cutoff_top_n=40, scorer=scorer, hot_words=hot_words )
`",calling function directly import scorer alphabet alphabet alphabet scorer scorer alphabet,issue,negative,positive,neutral,neutral,positive,positive
761589224,"It will be impossible to help if you dont share code to repro and more context. Hot words is exposed through the libdeepspeech api and bindings, not the decoder. ",impossible help dont share code context hot exposed,issue,negative,negative,negative,negative,negative,negative
760961636,@djmitche This was merged on master but we still have an active release branch using the older format.,master still active release branch older format,issue,negative,positive,neutral,neutral,positive,positive
760957765,"@reuben did this get wrapped up?  It's fine if there's more time required, but I will stop pinging if it's done :)",get wrapped fine time stop done,issue,negative,positive,positive,positive,positive,positive
760944602,I had already filed #2914 for this a long time ago.,already long time ago,issue,negative,negative,neutral,neutral,negative,negative
760710313,"This is not a bug, please use Discourse for reaching support.",bug please use discourse reaching support,issue,positive,neutral,neutral,neutral,neutral,neutral
759259333,"Oh cool I had not seen that!

Yes this still looks like decoder. :/

On Tue, Jan 12, 2021 at 23:13 zaptrem <notifications@github.com> wrote:

> @CatalinVoss <https://github.com/CatalinVoss> Cool stuff! I can see why
> it's necessary in that case, detecting specific mispronunciations is more
> than hotword-boosting can do. Coincidentally, I stumbled across this Google
> feature that might interest you
> <https://www.theverge.com/2019/11/14/20964401/google-search-pronunciation-guide-feedback-machine-learning-ai>
> about 10 minutes ago in a discussion with someone.
>
> I ran the test again on an iPad Pro late 2018 (before it was an iPhone 11
> Pro Max) and got a slightly different result. Does this still indicate
> Decoder issues?
>
> frame #4739: 0x000000010bb6bcf8 deepspeech_ios`PathTrie::iterate_to_vec(std::__1::vector<PathTrie*, std::__1::allocator<PathTrie*> >&) + 64
>     frame #4740: 0x000000010bb6bcf8 deepspeech_ios`PathTrie::iterate_to_vec(std::__1::vector<PathTrie*, std::__1::allocator<PathTrie*> >&) + 64
>     frame #4741: 0x000000010ba99114 deepspeech_ios`DecoderState::next(double const*, int, int) + 404
>     frame #4742: 0x000000010b903470 deepspeech_ios`StreamingState::processBatch(std::__1::vector<float, std::__1::allocator<float> > const&, unsigned int) + 296
>     frame #4743: 0x000000010b903300 deepspeech_ios`StreamingState::pushMfccBuffer(std::__1::vector<float, std::__1::allocator<float> > const&) + 236
>     frame #4744: 0x000000010b902e88 deepspeech_ios`StreamingState::feedAudioContent(short const*, unsigned int) + 396
>   * frame #4745: 0x0000000101a80808 ReLearn`closure #1 in Transcription.render(samples=Swift.UnsafeRawBufferPointer @ 0x000000017032dc20, stream=(streamCtx = 0x000000010bfd2670)) at Transcription.swift:85:24
>     frame #4746: 0x0000000101a80830 ReLearn`thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
>     frame #4747: 0x0000000101a823d0 ReLearn`partial apply for thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
>     frame #4748: 0x00000001942f5174 libswiftFoundation.dylib`Foundation.Data.withUnsafeBytes<A>((Swift.UnsafeRawBufferPointer) throws -> A) throws -> A + 392
>     frame #4749: 0x0000000101a7ff68 ReLearn`Transcription.render(audioContext=0x0000000282e94930, stream=(streamCtx = 0x000000010bfd2670), self=0x0000000282f28cc0) at Transcription.swift:83:26
>     frame #4750: 0x0000000101a80eb8 ReLearn`closure #1 in Transcription.recognizeFile(audioContext=0x0000000282e94930, self=0x0000000282f28cc0, stream=(streamCtx = 0x000000010bfd2670), audioPath=Swift.String @ 0x000000017032e458, start=2021-01-13 02:00:54 EST) at Transcription.swift:107:18
>     frame #4751: 0x0000000101a7e23c ReLearn`closure #1 in static AudioContext.load(asset=0x000000028278c8a0, assetTrack=0x00000002822ea6d0, audioURL=<unavailable; try printing with ""vo"" or ""po"">, completionHandler=0x0000000101a8248c ReLearn`partial apply forwarder for closure #1 (Swift.Optional<react_native_transcription.AudioContext>) -> () in react_native_transcription.Transcription.(recognizeFile in _79B1BC2F893AB0135086535C16DBA135)(audioPath: Swift.String) -> () at <compiler-generated>) at AudioContext.swift:58:17
>     frame #4752: 0x0000000101a5a490 ReLearn`thunk for @escaping @callee_guaranteed () -> () at <compiler-generated>:0
>     frame #4753: 0x000000010bd83bcc libdispatch.dylib`_dispatch_call_block_and_release + 32
>     frame #4754: 0x000000010bd856c0 libdispatch.dylib`_dispatch_client_callout + 20
>     frame #4755: 0x000000010bd8d354 libdispatch.dylib`_dispatch_lane_serial_drain + 736
>     frame #4756: 0x000000010bd8e0c0 libdispatch.dylib`_dispatch_lane_invoke + 448
>     frame #4757: 0x000000010bd9a644 libdispatch.dylib`_dispatch_workloop_worker_thread + 1520
>     frame #4758: 0x00000001db297804 libsystem_pthread.dylib`_pthread_wqthread + 276
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3061#issuecomment-759255079>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AACRFK6SXCOM2VR4MLOUKEDSZVB2ZANCNFSM4N5MDJDQ>
> .
>
",oh cool seen yes still like tue wrote cool stuff see necessary case specific coincidentally across feature might interest ago discussion someone ran test pro late pro got slightly different result still indicate frame frame frame double frame float float unsigned frame float float frame short unsigned frame relearn closure frame relearn unowned error error frame relearn partial apply unowned error error frame frame relearn frame relearn closure frame relearn closure static unavailable try printing po relearn partial apply forwarder closure frame relearn frame frame frame frame frame frame reply directly view,issue,negative,positive,neutral,neutral,positive,positive
759255079,"@CatalinVoss Cool stuff! I can see why it's necessary in that case, detecting specific mispronunciations is more than hotword-boosting can do. Coincidentally, I stumbled across this [Google feature that might interest you](https://www.theverge.com/2019/11/14/20964401/google-search-pronunciation-guide-feedback-machine-learning-ai) about 10 minutes ago in a discussion with someone.

I ran the test again on an iPad Pro late 2018 (before it was an iPhone 11 Pro Max) and got a slightly different result. Does this still indicate Decoder issues?
```
frame #4739: 0x000000010bb6bcf8 deepspeech_ios`PathTrie::iterate_to_vec(std::__1::vector<PathTrie*, std::__1::allocator<PathTrie*> >&) + 64
    frame #4740: 0x000000010bb6bcf8 deepspeech_ios`PathTrie::iterate_to_vec(std::__1::vector<PathTrie*, std::__1::allocator<PathTrie*> >&) + 64
    frame #4741: 0x000000010ba99114 deepspeech_ios`DecoderState::next(double const*, int, int) + 404
    frame #4742: 0x000000010b903470 deepspeech_ios`StreamingState::processBatch(std::__1::vector<float, std::__1::allocator<float> > const&, unsigned int) + 296
    frame #4743: 0x000000010b903300 deepspeech_ios`StreamingState::pushMfccBuffer(std::__1::vector<float, std::__1::allocator<float> > const&) + 236
    frame #4744: 0x000000010b902e88 deepspeech_ios`StreamingState::feedAudioContent(short const*, unsigned int) + 396
  * frame #4745: 0x0000000101a80808 ReLearn`closure #1 in Transcription.render(samples=Swift.UnsafeRawBufferPointer @ 0x000000017032dc20, stream=(streamCtx = 0x000000010bfd2670)) at Transcription.swift:85:24
    frame #4746: 0x0000000101a80830 ReLearn`thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #4747: 0x0000000101a823d0 ReLearn`partial apply for thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #4748: 0x00000001942f5174 libswiftFoundation.dylib`Foundation.Data.withUnsafeBytes<A>((Swift.UnsafeRawBufferPointer) throws -> A) throws -> A + 392
    frame #4749: 0x0000000101a7ff68 ReLearn`Transcription.render(audioContext=0x0000000282e94930, stream=(streamCtx = 0x000000010bfd2670), self=0x0000000282f28cc0) at Transcription.swift:83:26
    frame #4750: 0x0000000101a80eb8 ReLearn`closure #1 in Transcription.recognizeFile(audioContext=0x0000000282e94930, self=0x0000000282f28cc0, stream=(streamCtx = 0x000000010bfd2670), audioPath=Swift.String @ 0x000000017032e458, start=2021-01-13 02:00:54 EST) at Transcription.swift:107:18
    frame #4751: 0x0000000101a7e23c ReLearn`closure #1 in static AudioContext.load(asset=0x000000028278c8a0, assetTrack=0x00000002822ea6d0, audioURL=<unavailable; try printing with ""vo"" or ""po"">, completionHandler=0x0000000101a8248c ReLearn`partial apply forwarder for closure #1 (Swift.Optional<react_native_transcription.AudioContext>) -> () in react_native_transcription.Transcription.(recognizeFile in _79B1BC2F893AB0135086535C16DBA135)(audioPath: Swift.String) -> () at <compiler-generated>) at AudioContext.swift:58:17
    frame #4752: 0x0000000101a5a490 ReLearn`thunk for @escaping @callee_guaranteed () -> () at <compiler-generated>:0
    frame #4753: 0x000000010bd83bcc libdispatch.dylib`_dispatch_call_block_and_release + 32
    frame #4754: 0x000000010bd856c0 libdispatch.dylib`_dispatch_client_callout + 20
    frame #4755: 0x000000010bd8d354 libdispatch.dylib`_dispatch_lane_serial_drain + 736
    frame #4756: 0x000000010bd8e0c0 libdispatch.dylib`_dispatch_lane_invoke + 448
    frame #4757: 0x000000010bd9a644 libdispatch.dylib`_dispatch_workloop_worker_thread + 1520
    frame #4758: 0x00000001db297804 libsystem_pthread.dylib`_pthread_wqthread + 276
(lldb)
```",cool stuff see necessary case specific coincidentally across feature might interest ago discussion someone ran test pro late pro got slightly different result still indicate frame frame frame double frame float float unsigned frame float float frame short unsigned frame relearn closure frame relearn unowned error error frame relearn partial apply unowned error error frame frame relearn frame relearn closure frame relearn closure static unavailable try printing po relearn partial apply forwarder closure frame relearn frame frame frame frame frame frame,issue,negative,positive,neutral,neutral,positive,positive
759245000,"> @CatalinVoss Thanks for pointing that out! I'm curious; what about your use case required building an alternate decoder? Is it open source? 

Working on child literacy. Closed source I'm afraid",thanks pointing curious use case building alternate open source working child literacy closed source afraid,issue,positive,negative,neutral,neutral,negative,negative
759244283,"@CatalinVoss Thanks for pointing that out! I'm curious; what about your use case required building an alternate decoder? Is it open source? 

@reuben What do you make of this error? Or is there a different person who worked on the beam decoder I should ping? Is this something I should move to its own, non-platform-specific bug report?",thanks pointing curious use case building alternate open source make error different person worked beam ping something move bug report,issue,negative,positive,neutral,neutral,positive,positive
759242690,"Ah. The relevant part is at the bottom

```
deepspeech_ios`PathTrie::iterate_to_vec(std::__1::vector<PathTrie*, std::__1::allocator<PathTrie*> >&) + 64
    frame #4742: 0x000000010fee1114 deepspeech_ios`DecoderState::next(double const*, int, int) + 404
    frame #4743: 0x000000010fd4b470 deepspeech_ios`StreamingState::processBatch(std::__1::vector<float, std::__1::allocator<float> > const&, unsigned int) + 296
    frame #4744: 0x000000010fd4b300 deepspeech_ios`StreamingState::pushMfccBuffer(std::__1::vector<float, std::__1::allocator<float> > const&) + 236
    frame #4745: 0x000000010fd4ae88 deepspeech_ios`StreamingState::feedAudioContent(short const*, unsigned int) + 396
  * frame #4746: 0x0000000105f1c808 ReLearn`closure #1 in Transcription.render(samples=Swift.UnsafeRawBufferPointer @ 0x000000016b295c30, stream=(streamCtx = 0x000000011031e420)) at Transcription.swift:85:24
    frame #4747: 0x0000000105f1c830 ReLearn`thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #4748: 0x0000000105f1e3d0 ReLearn`partial apply for thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #4749: 0x00000001f031ca8c libswiftFoundation.dylib`Foundation.Data.withUnsafeBytes<A>((Swift.UnsafeRawBufferPointer) throws -> A) throws -> A + 504
    frame #4750: 0x0000000105f1bf68 ReLearn`Transcription.render(audioContext=0x0000000280435b30, stream=(streamCtx = 0x000000011031e420), self=0x00000002805e2130) at Transcription.swift:83:26
    frame #4751: 0x0000000105f1ceb8 ReLearn`closure #1 in Transcription.recognizeFile(audioContext=0x0000000280435b30, self=0x00000002805e2130, stream=(streamCtx = 0x000000011031e420), audioPath=Swift.String @ 0x000000016b2964a8, start=2021-01-13 01:27:08 EST) at Transcription.swift:107:18
    frame #4752: 0x0000000105f1a23c ReLearn`closure #1 in static AudioContext.load(asset=0x0000000280c2a500, assetTrack=0x00000002808f4420, audioURL=<unavailable; try printing with ""vo"" or ""po"">, completionHandler=0x0000000105f1e48c ReLearn`partial apply forwarder for closure #1 (Swift.Optional<react_native_transcription.AudioContext>) -> () in react_native_transcription.Transcription.(recognizeFile in _79B1BC2F893AB0135086535C16DBA135)(audioPath: Swift.String) -> () at <compiler-generated>) at AudioContext.swift:58:17
    frame #4753: 0x0000000105ef6490 ReLearn`thunk for @escaping @callee_guaranteed () -> () at <compiler-generated>:0
    frame #4754: 0x00000001101c9d10 libdispatch.dylib`_dispatch_call_block_and_release + 32
    frame #4755: 0x00000001101cb18c libdispatch.dylib`_dispatch_client_callout + 20
    frame #4756: 0x00000001101d2968 libdispatch.dylib`_dispatch_lane_serial_drain + 724
    frame #4757: 0x00000001101d3580 libdispatch.dylib`_dispatch_lane_invoke + 440
    frame #4758: 0x00000001101df0f0 libdispatch.dylib`_dispatch_workloop_worker_thread + 1344
    frame #4759: 0x00000001b96f3714 libsystem_pthread.dylib`_pthread_wqthread + 276
(lldb) 
```

This looks like a crash in the beam search decoder. I'm not actually using the DeepSpeech decoder -- have my own -- so unfortunately I can't help :( it appears to be unrelated to the bug I saw",ah relevant part bottom frame double frame float float unsigned frame float float frame short unsigned frame relearn closure frame relearn unowned error error frame relearn partial apply unowned error error frame frame relearn frame relearn closure frame relearn closure static unavailable try printing po relearn partial apply forwarder closure frame relearn frame frame frame frame frame frame like crash beam search actually unfortunately ca help unrelated bug saw,issue,negative,positive,neutral,neutral,positive,positive
759238069,@CatalinVoss Here you go. I had to use a text file since I exceeded pastebin's size limit: [deepSpeechCrashST.txt](https://github.com/mozilla/DeepSpeech/files/5806797/deepSpeechCrashST.txt),go use text file since size limit,issue,negative,neutral,neutral,neutral,neutral,neutral
759233710,"Can you get a backtrace from inside deepspeech by typing `bt` on the lldb console? I do see one sporadic issue that crashes within tensorflow in my application, but it's fairly rare.",get inside console see one sporadic issue within application fairly rare,issue,negative,positive,positive,positive,positive,positive
758538172,"@reuben Trying again in case I sent it too early in the morning last week. 

@CatalinVoss Are you able to reproduce this with your binary?",trying case sent early morning last week able reproduce binary,issue,negative,positive,positive,positive,positive,positive
757850102,"Sorry, thought this was a bug.  Didn't know CXX ABI version was so standardised.",sorry thought bug know version,issue,negative,negative,negative,negative,negative,negative
757811032,"> I don't have strong opinions either way on your suggestion - my guiding principle here is ""what does the community need to reduce the hurdle of getting to train a model?"". For me, that's likely to be a ""batteries included"" Dockerfile that allows someone to train a model from say the CV corpus, with minimal preparation work.

The truth is that I was working on that on a spare project: https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/

This is the project you want. And the goal was that our `train` Docker here is a base for this. Which I have not had time to finish yet. Hence the two docker in the repo:
 - `build`: to allow people to more easily rebuild the lib if required for their own purpose
 - `train`: to provide a very basic minimal working setup that should be the base of others.

@KathyReid @reuben Maybe it is time for https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/ to move somewhere else and be more supported?",strong either way suggestion principle community need reduce hurdle getting train model likely included someone train model say corpus minimal preparation work truth working spare project project want goal train docker base time finish yet hence two docker build allow people easily rebuild purpose train provide basic minimal working setup base maybe time move somewhere else,issue,positive,negative,negative,negative,negative,negative
757691512,"This is not a bug, please use DIscourse for seeking support. You need to rebuild for your system.",bug please use discourse seeking support need rebuild system,issue,positive,neutral,neutral,neutral,neutral,neutral
757492579,"> I have installed required CUDA, cuDNN and Tensorflow-gpu correct versions. Without ""--train_cudnn"" flag I can do the training. How can I fix this error?

Your error explicitely stipulates that your CuDNN setup is broken. When reaching for support, be respectful of the time of those who are going to help you and provide context, setup steps and versions you followed. DONT just ""I did as the doc said"", 99% of those statements turns out to show people followed something somehow wrong or missed steps.",correct without flag training fix error error setup broken reaching support respectful time going help provide context setup dont doc said turn show people something somehow wrong,issue,negative,negative,negative,negative,negative,negative
757492290,@Varuzhan97 Please respect the template and reach for support on Discourse.,please respect template reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
757473336,"Thanks @carlfm01 and @stepkillah I will hold off (it wasn't pressing I was more just playing around with it for my sake) let me know if there is something I can do to help.

I feel like we keep this PR open until those changes are in, then we can test that they work and close it.",thanks hold pressing around sake let know something help feel like keep open test work close,issue,positive,positive,neutral,neutral,positive,positive
757435916,"I still want to finish PR for net core support, it's not too much left, but was lack of time, hope can pick that up on next week
@aolszowka in PR discussion mentioned by @carlfm01 there is a link to prebuilt nuget with net core support, but it's probably outdated already.",still want finish net core support much left lack time hope pick next week discussion link net core support probably outdated already,issue,positive,negative,neutral,neutral,negative,negative
757386431,"Hello @aolszowka, thanks for the example, to support net core we need something similar to https://github.com/mozilla/DeepSpeech/pull/3100/files
It is harder to pack since it needs the native client for all the platforms it will support and not only Windows.",hello thanks example support net core need something similar harder pack since need native client support,issue,positive,positive,neutral,neutral,positive,positive
757385692,"Net core WIP here
https://github.com/mozilla/DeepSpeech/pull/3373
 https://github.com/mozilla/DeepSpeech/blob/2e16d388ce0445b9642718df579d19ec6a82abc3/native_client/dotnet/DeepSpeechClient/DeepSpeechClient.csproj#L4 by @stepkillah 

With that change on the csproj should work, sadly there was a severe issue in one of my apps that took all my time :(, so I couldn't help @stepkillah to finish the cluster stuff.",net core change work sadly severe issue one took time could help finish cluster stuff,issue,negative,negative,negative,negative,negative,negative
757083163,"Thanks @nmstoker for the feedback - appreciated.

I don't have strong opinions either way on your suggestion - my guiding principle here is ""what does the community need to reduce the hurdle of getting to train a model?"". For me, that's likely to be a ""batteries included"" Dockerfile that allows someone to train a model from say the CV corpus, with minimal preparation work. 

There are already two `Dockerfile`s that ship with  DeepSpeech - the `makefile` takes a parameter of either `train` or `build`, with dependencies tailored to either using DeepSpeech for training or for inference. A concern with increasing the number of `Dockerfile`s is that it then makes providing support, or replicating issues, harder. 

Sorry I'm not more helpful on this one, but it's probably Lissy or Reuben's call here. 

",thanks feedback strong either way suggestion principle community need reduce hurdle getting train model likely included someone train model say corpus minimal preparation work already two ship parameter either train build either training inference concern increasing number providing support harder sorry helpful one probably call,issue,positive,negative,neutral,neutral,negative,negative
757081145,"I may be showing my inexperience with docker here, but would it be feasible to have two dockerfiles?
Eg 1. A ""Lite"" version for the purists without the editors, possibly not the dependencies for the importers (or only minimal depencies if Common Voice is in)
2. A slightly more ""batteries included"" version, derived from the Lite version but which has the editors and Sox.

For those looking to apply it in their own version with specialist needs, they'd potentially start with the lite one but for use in the playbook/with beginners, the batteries included one would be the place to start because it's simple to get going and will reduce support confusion stemming from those who are less experienced",may showing inexperience docker would feasible two lite version without possibly minimal common voice slightly included version derived lite version looking apply version specialist need potentially start lite one use included one would place start simple get going reduce support confusion stemming le experienced,issue,negative,positive,neutral,neutral,positive,positive
756711952,"Looks like the Windows worker specifically doesn't like the added attribute, tasks fail with ""malformed payload"". Oh well :(",like worker specifically like added attribute fail malformed oh well,issue,negative,negative,negative,negative,negative,negative
756062818,Maybe that's also related to intermittent disk space problems on macOS workers? The `rm -fr` command wasn't actually doing anything.,maybe also related intermittent disk space command actually anything,issue,negative,neutral,neutral,neutral,neutral,neutral
756057247,"Looks like it was just some macOS specific bash craziness:

```diff
-        (rm -fr ../tc-workdir/ ; mkdir ../tc-workdir/) && cd ../tc-workdir/ &&
+        (ls -lh .. && rm -fr ../tc-workdir && mkdir ../tc-workdir && ls -lh ..) && cd ../tc-workdir &&
```",like specific bash craziness,issue,negative,neutral,neutral,neutral,neutral,neutral
756022494,"Looking at the whole output of `bazel info` it's even mixing the two taskdirs:

```
bazel-bin: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/execroot/org_tensorflow/bazel-out/darwin-opt/bin
bazel-genfiles: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/execroot/org_tensorflow/bazel-out/darwin-opt/bin
bazel-testlogs: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/execroot/org_tensorflow/bazel-out/darwin-opt/testlogs
character-encoding: file.encoding = ISO-8859-1, defaultCharset = ISO-8859-1
command_log: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/command.log
committed-heap-size: 511MB
execution_root: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/execroot/org_tensorflow
gc-count: 15
gc-time: 1483ms
install_base: /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/install/1d6d7a22a62da56414387a04bacbf619
java-home: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/install/1d6d7a22a62da56414387a04bacbf619/embedded_tools/jdk
java-runtime: OpenJDK Runtime Environment (build 11.0.6+10-LTS) by Azul Systems, Inc.
java-vm: OpenJDK 64-Bit Server VM (build 11.0.6+10-LTS, mixed mode) by Azul Systems, Inc.
max-heap-size: 2147MB
output_base: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output
output_path: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/execroot/org_tensorflow/bazel-out
package_path: %workspace%
release: release 3.1.0
repository_cache: /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/cache/repos/v1
server_log: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/.bazel_cache/output/java.log.ds-worker-vm-tf-build-b992a325.build-user.log.java.20210107-015341.94028
server_pid: 94028
used-heap-size: 36MB
workspace: /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/DeepSpeech/ds/tensorflow
```",looking whole output even two iso iso environment build server build mixed mode release release,issue,negative,positive,neutral,neutral,positive,positive
756017737,"In the old build it correctly uses tc-workdir for the build:

```
+ bazel --output_user_root /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/ --output_base /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache//output/ build -s --explain bazel_monolithic_tf.log --verbose_explanations --experimental_strict_action_env --config=monolithic -c opt --config=ios_arm64 --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV //tensorflow/lite/c:libtensorflowlite_c.so
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
INFO: Reading rc options for 'build' from /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/DeepSpeech/ds/tensorflow/.bazelrc:
```",old build correctly build build explain opt provided client reading,issue,negative,positive,neutral,neutral,positive,positive
756016178,"Huh. bazel seems to be picking up some random taskdir, not even the same one from the task...

From [this run](https://community-tc.services.mozilla.com/tasks/RCB6cpUER1qB9IkpEE_DtQ/runs/0/logs/live/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FRCB6cpUER1qB9IkpEE_DtQ%2Fruns%2F0%2Fartifacts%2Fpublic%252Flogs%252Flive.log%3Fbewit%3DZ2l0aHViLzQ3NzE0MnxyZXViZW5cMTYxMDAxNDA3Mlx6cFpXSEZ0bGVIL1dvQkV4eitMemgwOTI5Yml2a2YyN1FuQWdCWWQzU1AwPVxleUpqWlhKMGFXWnBZMkYwWlNJNmV5SjJaWEp6YVc5dUlqb3hMQ0p6WTI5d1pYTWlPbHNpWVhOemRXMWxPbWRwZEdoMVlpMTBaV0Z0T20xdmVtbHNiR0V0WWpKbkwyTm9aV1p6SWl3aVlYTnpkVzFsT21kcGRHaDFZaTEwWldGdE9tMXZlbWxzYkdFdmNtVnpaV0Z5WTJndGJXRmphR2x1WlMxc1pXRnlibWx1WnlJc0ltRnpjM1Z0WlRwbmFYUm9kV0l0ZEdWaGJUcHRiM3BwYkd4aExXd3hNRzR2Ykc5allXeHBlbVZ5Y3lJc0ltRnpjM1Z0WlRwbmFYUm9kV0l0ZEdWaGJUcHRiM3BwYkd4aEwyRmtiV2x1TFdGc2JDMXZjbWN0YldWdFltVnljeUlzSW1GemMzVnRaVHBuYVhSb2RXSXRkR1ZoYlRwdGIzcHBiR3hoTDIxaGJXd2lMQ0poYzNOMWJXVTZiRzluYVc0dGFXUmxiblJwZEhrNloybDBhSFZpTHpRM056RTBNbnh5WlhWaVpXNGlYU3dpYzNSaGNuUWlPakUyTVRBd01USXhORFE1TWprc0ltVjRjR2x5ZVNJNk1UWXhNREF4TXprME5Ea3lPU3dpYzJWbFpDSTZJazlYYjFaU1RHSTRVVXR0VlRZelpqZzVVMWxLTUdkSE1GZDNZbXRCVVZGbmNXSldWREpTUlVjd0xYTm5JaXdpYzJsbmJtRjBkWEpsSWpvaVlYSmhVbTlWVWtVMFdHOWxSbmwyUkhGMFIzZHZUM0ZwZVd0elNtSkxNbVZVWkRRNFMwMVFlbnB2VlQwaUxDSnBjM04xWlhJaU9pSnpkR0YwYVdNdmRHRnphMk5zZFhOMFpYSXZkMlZpTFhObGNuWmxjaUo5ZlE9PQ#L1169):

```

++ pwd
+ export TASKCLUSTER_ARTIFACTS=/Users/build-user/TaskCluster/Workdir/tasks/task_160978434177740/public/
+ TASKCLUSTER_ARTIFACTS=/Users/build-user/TaskCluster/Workdir/tasks/task_160978434177740/public/
++ pwd
+ export TASKCLUSTER_ORIG_TASKDIR=/Users/build-user/TaskCluster/Workdir/tasks/task_160978434177740
+ TASKCLUSTER_ORIG_TASKDIR=/Users/build-user/TaskCluster/Workdir/tasks/task_160978434177740
```

And then later when bazel is run, this random task dir comes up:

```
+ bazel --output_user_root /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/ --output_base /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache//output/ info
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
INFO: Reading rc options for 'info' from /Users/build-user/TaskCluster/Workdir/tasks/task_159956485967440/DeepSpeech/ds/tensorflow/.bazelrc:
```

`task_159956485967440` then gets used throughout the build...",huh random even one task run export export later run random task come installation starting local server provided client reading used throughout build,issue,negative,negative,negative,negative,negative,negative
756007006,"Oh, maybe it's related to the .taskcluster.yml v1 transition...",oh maybe related transition,issue,negative,neutral,neutral,neutral,neutral,neutral
756005059,"new_tf_cache = https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r2.3.4c4c6accdd524ac50150860031184bb1b17a0350.0.ios_arm64/artifacts/public/home.tar.xz - built from the commits in this PR

```
/private/tmp/scratch $ ls -lh new_tf_cache/DeepSpeech/ds/tensorflow/bazel-*
lrwxr-xr-x  1 build-user  wheel   136B Jan  4 06:06 new_tf_cache/DeepSpeech/ds/tensorflow/bazel-bin -> /Users/build-user/TaskCluster/Workdir/tasks/task_159957318579746/.bazel_cache/output/execroot/org_tensorflow/bazel-out/ios_arm64-opt/bin
lrwxr-xr-x  1 build-user  wheel   118B Jan  4 06:06 new_tf_cache/DeepSpeech/ds/tensorflow/bazel-out -> /Users/build-user/TaskCluster/Workdir/tasks/task_159957318579746/.bazel_cache/output/execroot/org_tensorflow/bazel-out
lrwxr-xr-x  1 build-user  wheel   108B Jan  4 06:06 new_tf_cache/DeepSpeech/ds/tensorflow/bazel-tensorflow -> /Users/build-user/TaskCluster/Workdir/tasks/task_159957318579746/.bazel_cache/output/execroot/org_tensorflow
lrwxr-xr-x  1 build-user  wheel   141B Jan  4 06:06 new_tf_cache/DeepSpeech/ds/tensorflow/bazel-testlogs -> /Users/build-user/TaskCluster/Workdir/tasks/task_159957318579746/.bazel_cache/output/execroot/org_tensorflow/bazel-out/ios_arm64-opt/testlogs
```

old_tf_cache = https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r2.3.23ad988fcde60fb01f9533e95004bbc4877a9143.0.ios_arm64/artifacts/public/home.tar.xz - the current master cache

```
lrwxr-xr-x  1 build-user  wheel   126B Aug 26 02:57 old_tf_cache/DeepSpeech/ds/tensorflow/bazel-bin -> /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/output/execroot/org_tensorflow/bazel-out/ios_arm64-opt/bin
lrwxr-xr-x  1 build-user  wheel   108B Aug 26 02:57 old_tf_cache/DeepSpeech/ds/tensorflow/bazel-out -> /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/output/execroot/org_tensorflow/bazel-out
lrwxr-xr-x  1 build-user  wheel    98B Aug 26 02:57 old_tf_cache/DeepSpeech/ds/tensorflow/bazel-tensorflow -> /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/output/execroot/org_tensorflow
lrwxr-xr-x  1 build-user  wheel   131B Aug 26 02:57 old_tf_cache/DeepSpeech/ds/tensorflow/bazel-testlogs -> /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/.bazel_cache/output/execroot/org_tensorflow/bazel-out/ios_arm64-opt/testlogs
```",built wheel wheel wheel wheel current master cache wheel wheel wheel wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
756000739,"Hm, it seems despite nothing having changed on the TF or DS build system side of things with this PR, the newly built TF cache contains broken links, instead of referring to tc-workdir they refer to the place tc-workdir points to, eg. `/Users/build-user/TaskCluster/Workdir/tasks/task_159957318579746`. This includes some links that are required by bazel to work, as they define the CXX toolchain.",despite nothing build system side newly built cache broken link instead refer place link work define,issue,negative,negative,negative,negative,negative,negative
754280129,"I think what you propose is a good way forward; with `vim` and `nano` people have the ability to tinker around _within_ the current Docker image, and I can add some information to the Playbook on how to add additional deps / requirements to the `Dockerfile` and have people build their own image from that `Dockerfile`. 

The one downside I can see from this approach is that by encouraging people to train a model from a Docker environment, we are trying to standardise or reduce the variability of environments that are trained with - thus reducing the range of issues that come up for support, and reducing support volume. If we encourage people to modify their own Docker images for training, that will increase variability in support issues. Should we add something to the `ISSUE.md` template asking for their modified `Dockerfile` if they're using a modified one? ",think propose good way forward vim people ability tinker around current docker image add information playbook add additional people build image one downside see approach encouraging people train model docker environment trying reduce variability trained thus reducing range come support reducing support volume encourage people modify docker training increase variability support add something template one,issue,positive,positive,positive,positive,positive,positive
754086515,I still feel like advising people to product their own image based on ours and thus managing their deps would be a good requirements. (and we could still merge those anyway) what do you think @KathyReid ? ,still feel like people product image based thus would good could still merge anyway think,issue,positive,positive,positive,positive,positive,positive
753997262,"Instructions on how our language model is built are available here: https://deepspeech.readthedocs.io/en/latest/Scorer.html#reproducing-our-external-scorer

You should be able to build modified versions of the scorer with your own dataset or pruning parameters following those.",language model built available able build scorer pruning following,issue,negative,positive,positive,positive,positive,positive
753994153,"Yes, I too had some weird words. Doesn't Deepspeech contain a language model when predicting the words?. if so why do you think such words have been recognized. As in a generic English LM, these words must have had a very tiny probability right.",yes weird contain language model think generic must tiny probability right,issue,negative,negative,neutral,neutral,negative,negative
753979323,"All fair and valid points. 

The reason that I'm using a `Dockerfile` for training is to help build out a DeepSpeech Playbook to make training models easier - and in doing so, reduce the support load presented by DeepSpeech. While using Docker for training (to streamline dependency management), it's useful to have editing tools like `vim` and `nano` available, for example to edit `alphabet.txt` (which is how I discovered I didn't have an editor). 

",fair valid reason training help build playbook make training easier reduce support load docker training streamline dependency management useful like vim available example edit discovered editor,issue,positive,positive,positive,positive,positive,positive
753970882,"I have literally never used the Dockerfiles so my opinion counts very little I'm afraid. I agree with you that adding all required deps of all importers will quickly become untenable, but I guess Common Voice is ""first-party"" enough that it's warranted to add a dep for that importer. So overall I'm OK with this PR as is.",literally never used opinion little afraid agree quickly become untenable guess common voice enough warranted add importer overall,issue,negative,negative,negative,negative,negative,negative
753748735,Note I have also added `vim` and `nano` editors to the Dockerfile for ease of editing files within Docker. ,note also added vim ease within docker,issue,negative,neutral,neutral,neutral,neutral,neutral
753626279,"Hey @patrickvonplaten, thanks for reaching out. Our inference API is built around a C++ library (with a C API), which has bindings for several languages/runtimes, including Python, JS on Node.JS/Electron, C# on .NET, Rust, Java on Android, Swift on iOS, Raspberry Pi, etc.

We try to maintain parity between the language bindings which means in order to land in core this integration would have to be implemented in the C++ library itself and exposed to the bindings. The model loading code works on all the platforms above, and is tested in CI for a subset of them.

For a Python only solution, it would be best placed in a separate library that leverages the [DeepSpeech Python bindings](https://deepspeech.readthedocs.io/en/latest/Python-API.html). It can either live in, or be linked from, the [DeepSpeech-examples repository](https://github.com/mozilla/DeepSpeech-examples).

> In addition, DeepSpeech users could directly try out the model online: _e.g._ for text-to-speech models this currently looks as follows: https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train?text=Hello%2C+how+are+you+doing%3F and we're working on a speech-to-text inference API as well: https://huggingface.co/julien-c/mini_an4_asr_train_raw_bpe_valid so that audio files can be drag & dropped online to be transcribed directly.
>
> Public models will always be hosted for free :-)

Will the online inference endpoint also be always free?",hey thanks reaching inference built around library several python rust android swift raspberry pi try maintain parity language order land core integration would library exposed model loading code work tested subset python solution would best separate library python either live linked repository addition could directly try model currently working inference well audio drag directly public always free inference also always free,issue,positive,positive,positive,positive,positive,positive
753624995,@DanBmh cool stuff! By the way I've also experimented with a full train loop rewrite path here: https://github.com/reuben/DeepSpeech/commit/cc8a774ff62e0df74d85d686f9ac3edf0eb93666 ,cool stuff way also experimented full train loop rewrite path,issue,negative,positive,positive,positive,positive,positive
753623136,"> DeepSpeech version (0.10.0-alpha.3) and CTC decoder version (0.9.3) do not match. Please ensure matching versions are in use.
> 
> not able to run deepspeech.py program any solution?

Or use `0.9.3 for everything. By the way, this is not a bug so please use Discourse for requesting support.",version version match please ensure matching use able run program solution use everything way bug please use discourse support,issue,positive,positive,positive,positive,positive,positive
753620210,@shs-odoo I didn't tried but `pip3 install ds-ctcdecoder==0.10.0-alpha.3` should solve your issue.,tried pip install solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
753619603,"Hi @reuben,
I think updating the code to tensorflow2 is a great idea.
But before you put to much work into it, I wanted to notify you that I already started something similar.

Instead of your low-touch upgrade, I'm trying to do a native tensorflow2 implementation. Main goal of it is to replace the old DeepSpeech network with something newer and more accurate. I found a complete reimplementation using the new tf2 features was a cleaner way than mixing this into the current training code. By the way, I also did rework the flags handling, which could be an idea for #3476.

Currently its very experimental, you can only do single gpu trainings now and I'm still missing a lot of the features DeepSpeech has, but my plan is to make it compatible to the DS bindings in the long run. You can find it here: https://gitlab.com/Jaco-Assistant/deepspeech-polyglot/-/merge_requests/7

I wanted to talk with you after the Christmas holidays, but it seems you are working too fast^^
Greetings
Daniel",hi think code great idea put much work notify already something similar instead upgrade trying native implementation main goal replace old network something accurate found complete new cleaner way current training code way also rework handling could idea currently experimental single still missing lot plan make compatible long run find talk working,issue,positive,positive,positive,positive,positive,positive
753592861,"Thanks, and please don't hesitate to open PRs due to their smallness! Merging is a single button away :)",thanks please hesitate open due smallness single button away,issue,negative,positive,neutral,neutral,positive,positive
753382866,"Sorry, it's clearly out of my scope if knowledges, will have to wait either @carlfm01 has a look or i come back from pto on two weeks and can have a look. ",sorry clearly scope wait either look come back two look,issue,negative,negative,negative,negative,negative,negative
753381000,It for sure works (that's what the work around does) and is able to transcribe the samples (well to the best of its ability). There definitely seems to be some type of packaging issue though for .NET Core.,sure work work around able transcribe well best ability definitely type issue though core,issue,positive,positive,positive,positive,positive,positive
753378954,"The .Net Core work is not finished / merged, i dont know if you can expect anything to work (I dont know .Net) ",core work finished dont know expect anything work dont know,issue,negative,neutral,neutral,neutral,neutral,neutral
752923562,It seems upstream is no longer affected by this so we should just update our vendored copy.,upstream longer affected update copy,issue,negative,neutral,neutral,neutral,neutral,neutral
752785325,"Excellent feedback, thanks @reuben. 
I did a `diff` with the upstream `kenlm` and the upstream is a little different. 
I have created a patchfile and will submit this to the `kenlm` via an Issue rather than a PR, that way they can cherry pick what they would like to include. 

I suggest we close this PR now? ",excellent feedback thanks upstream upstream little different submit via issue rather way cherry pick would like include suggest close,issue,positive,positive,positive,positive,positive,positive
752393319,"Eigen is an optional dependency for us, and the modified code is in KenLM, a vendored library, so I'd suggest making a PR there so we keep close to upstream as much as possible: https://github.com/kpu/kenlm",optional dependency u code library suggest making keep close upstream much possible,issue,negative,neutral,neutral,neutral,neutral,neutral
751668774,"This is not a bug, please reach for support on Discourse. Use CUDA env var for selecting GPUs. ",bug please reach support discourse use,issue,positive,neutral,neutral,neutral,neutral,neutral
751459547,"> @reuben Another interesting bug I discovered while trying to find clues: the iOS example happily transcribed non-16khz wav files while Android example refused them. Also weird is Android and iOS give different transcriptions for the same noisy input despite using the exact same pretrained model and audio files.

Its not surprising and not a bug, @reuben already explained it: android example wav reading is hardcoded to reduce dependencies required by CI, so it only handles 16khz and it's not robust to broken wav files.",another interesting bug discovered trying find example happily android example also weird android give different noisy input despite exact model audio surprising bug already android example reading reduce robust broken,issue,positive,positive,positive,positive,positive,positive
751443267,@fender You've gotta compile the framework yourself using [these ](https://github.com/mozilla/DeepSpeech/pull/3436)instructions. You can use the Swift example in the repo.,fender got ta compile framework use swift example,issue,negative,neutral,neutral,neutral,neutral,neutral
751442719,@zaptrem @CatalinVoss What's the installation process for testing on iOS? There isn't a cocoapod yet is there?,installation process testing yet,issue,negative,neutral,neutral,neutral,neutral,neutral
751442355,@reuben Another interesting bug I discovered while trying to find clues: the iOS example happily transcribed non-16khz wav files while Android example refused them. Also weird is Android and iOS give different transcriptions for the same noisy input despite using the exact same pretrained model and audio files.,another interesting bug discovered trying find example happily android example also weird android give different noisy input despite exact model audio,issue,positive,positive,positive,positive,positive,positive
751341694,"@reuben Thanks, that solved the Android issue! It also allowed me to compare memory usage between iOS and Android. On the D-Day speech, Android climbs to ~200mb usage almost immediately and stays there, whereas iOS climbs more slowly to a similar number (or crashes on longer speeches). It seems like you were right to assume there was no memory leak, though it's weird to me that memory use is >10x the size of the input file.

However, on longer files, the crash on iOS is still present. Memory usage on Android balloons to >500MB on the Reagan RNC speech and run for a long while (I'm virtualizing Android on a beefy PC), so I'll update if it finishes.

Additionally, (this might be related to the -bitexact issue), on iOS on the shorter speeches there are long periods of sparse (one word for a minute of speech) transcription in between chunks of near-perfect transcription. The audio quality doesn't noticeably decrease in those areas when I listen. 

Finally, in the process of updating react-native-transcription to the latest DeepSpeech version I noticed that Android DeepSpeech 0.9.3 hadn't been published to Maven yet, only 0.9.2. 
",thanks android issue also compare memory usage android speech android usage almost immediately stay whereas slowly similar number longer like right assume memory leak though weird memory use size input file however longer crash still present memory usage android speech run long android beefy update additionally might related issue shorter long sparse one word minute speech transcription transcription audio quality noticeably decrease listen finally process latest version android yet,issue,negative,positive,neutral,neutral,positive,positive
751340050,"The Android code does not use a robust WAV parser, it just encodes direct offsets into the file, so it struggles with inconsistent header formats, including the one generated by `ffmpeg`. You can workaround by passing `-bitexact` to `ffmpeg` when converting, hopefully that should fix it.",android code use robust parser direct file inconsistent header one passing converting hopefully fix,issue,positive,positive,neutral,neutral,positive,positive
751339303,"I was able to reproduce this by taking[ long speeches from Wikipedia](https://commons.wikimedia.org/wiki/Category:Audio_files_of_speeches) (e.g., https://upload.wikimedia.org/wikipedia/commons/7/7c/Reagan_at_1980_Republican_National_Convention.ogg), converting them to 16khz 1ch WAV using FFMPEG
```
ffmpeg -i file.ogg  -ar 16000 -ac 1 output.wav
```
Then running them through the example app. Weirdly enough, *none* of the speeches work at all on Android, where the transcription instantly finishes with an empty result. However, Android live transcription works fine and certain wavs (e.g., https://www2.cs.uic.edu/~i101/SoundFiles/gettysburg.wav) also work just fine. I wonder if something about the output of FFMPEG is revealing some weird bug about the way the audio is fed to the model?

Finally, when the speeches are short enough to work (~20-30 minutes?) the RAM usage on iOS is still at leaking levels. The model increased RAM usage slowly by >200MBs before finishing, whereas the file itself wasn't close to that size. (e.g., https://upload.wikimedia.org/wikipedia/commons/6/6b/D-Day_speech_%28Reagan%29.ogg). Note: that audio doesn't work at all on Android, but works on iOS. ",able reproduce taking long converting running example weirdly enough none work android transcription instantly empty result however android live transcription work fine certain also work fine wonder something output revealing weird bug way audio fed model finally short enough work ram usage still model ram usage slowly finishing whereas file close size note audio work android work,issue,negative,positive,neutral,neutral,positive,positive
750694798,"There is a small race condition with the microphone capture on the stop() call in the sample code that needs to be fixed with a Semaphore that I've seen crash, but I haven't seen any other crashing behavior.",small race condition microphone capture stop call sample code need fixed semaphore seen crash seen behavior,issue,negative,negative,neutral,neutral,negative,negative
750493683,"> I haven't seen conclusive evidence that there's any leak here yet, memory usage goes up over time until you hit the beam width limit. The crash is definitely weird. Can you share the audio file that triggers it?

I just emailed the address on your GitHub account. Would rather not leave a permanent link here in case it contains copyrighted material (it was shared in a bug report from a tester and I haven't listened to it). 

Edit: also, this was with the 0.9.3 pretrained English model.",seen conclusive evidence leak yet memory usage go time hit beam width limit crash definitely weird share audio file address account would rather leave permanent link case material bug report tester edit also model,issue,negative,negative,negative,negative,negative,negative
750480660,"Also is this with one of our pre-trained models or your own? If the latter, does the problem reproduce with our pre-trained models?",also one latter problem reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
750480534,"I haven't seen conclusive evidence that there's any leak here yet, memory usage goes up over time until you hit the beam width limit. The crash is definitely weird. Can you share the audio file that triggers it?",seen conclusive evidence leak yet memory usage go time hit beam width limit crash definitely weird share audio file,issue,negative,negative,negative,negative,negative,negative
750477280,"@reuben Enabling/disabling ASAN and Zombie Object detection makes no difference, leak and crash still appear.",zombie object detection difference leak crash still appear,issue,negative,neutral,neutral,neutral,neutral,neutral
750120849,@reuben I can confirm that this error is not thrown when using a scorer.,confirm error thrown scorer,issue,negative,neutral,neutral,neutral,neutral,neutral
750054297,"Ah, it looks like you're not passing a scorer. I guess for development using 'ignore'/'replace' is a reasonable workaround, but you definitely want to use a scorer, exactly for this reason, it's the component responsible for preventing the model from exploring invalid beams.",ah like passing scorer guess development reasonable definitely want use scorer exactly reason component responsible model exploring invalid,issue,positive,positive,positive,positive,positive,positive
750051881,"The idea is that as long as you don't have invalid UTF-8 byte sequences in the text you use to generate the scorer, it'll prevent the model from predicting those. Adding 'ignore' or 'replace' to the decode call will patch the problem but the goal is to avoid predicting those things at all.",idea long invalid text use generate scorer prevent model decode call patch problem goal avoid,issue,negative,negative,neutral,neutral,negative,negative
750042221,"Away from my PC for the night/morning now, but I’ll definitely remember
that in the future.

This was completely unmodified latest commit deepspeech_ios_test (small
exception of adding the file name where the comments instructed and a
single “hello” print statement before anything runs to verify my changes to
that array were applying).


Sorry, it actually was slightly modified. I disabled Address Sanitizer and
some Zombie Detection option in order to enable memory profiling.
On Wed, Dec 23, 2020 at 4:36 AM Reuben Morais <notifications@github.com>
wrote:

> We have a policy of no screenshots here, it's not accessible and hard to
> read. Just copy the logs over as text when reporting these things.
>
> That stack and error looks like the input buffer passed to
> feedAudioContent is a broken pointer, how is the caller reading the audio
> file? Is it the unmodified deepspeech_ios_test project?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3061#issuecomment-750039953>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAMJTRQFNHOOCFVRNWYMWJDSWG2YPANCNFSM4N5MDJDQ>
> .
>
",away definitely remember future completely unmodified latest commit small exception file name instructed single hello print statement anything verify array sorry actually slightly disabled address zombie detection option order enable memory wed wrote policy accessible hard read copy text stack error like input buffer broken pointer caller reading audio file unmodified project reply directly view,issue,negative,negative,neutral,neutral,negative,negative
750039953,"We have a policy of no screenshots here, it's not accessible and hard to read. Just copy the logs over as text when reporting these things.

That stack and error looks like the input buffer passed to `feedAudioContent` is a broken pointer, how is the caller reading the audio file? Is it the unmodified `deepspeech_ios_test` project?",policy accessible hard read copy text stack error like input buffer broken pointer caller reading audio file unmodified project,issue,negative,negative,negative,negative,negative,negative
750018552,"@reuben I tested this on a larger file and it appears the file recognition has both a memory leak that always occurs and a crash that only occurs with larger/longer recordings. Here's a screenshot of the memory behavior and crash info with an unmodified version of the test app in the latest commit with a ~50 minute file: 
![memory usage at moment of crash, ](https://user-images.githubusercontent.com/1612230/102978360-626c0780-44d2-11eb-8dfc-98b303260f29.png) 
![image](https://user-images.githubusercontent.com/1612230/102978421-79aaf500-44d2-11eb-9216-ebd4e413473e.png)

Thankfully (unlike the previous Android leak I reported) it's super reliable and easy to reproduce. All you've gotta do is try to run a long audio file job. 

",tested file file recognition memory leak always crash memory behavior crash unmodified version test latest commit minute file memory usage moment crash image thankfully unlike previous android leak super reliable easy reproduce got ta try run long audio file job,issue,negative,positive,positive,positive,positive,positive
748643860,"after install tensorflow using the packagemanger, it didnt fail to install anymore.",install didnt fail install,issue,negative,negative,negative,negative,negative,negative
748643765,"You are right,
seems that pypi has some issues with DDoS currently see: https://status.python.org/
the issue was the missing tensorflow dependency:

19:23 [chrys@blackbeast fenrir] master :) $ pip search tensorflow
ERROR: Exception:
Traceback (most recent call last):
  File ""/usr/lib/python3.9/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main
    status = self.run(options, args)
  File ""/usr/lib/python3.9/site-packages/pip/_internal/commands/search.py"", line 60, in run
    pypi_hits = self.search(query, options)
  File ""/usr/lib/python3.9/site-packages/pip/_internal/commands/search.py"", line 80, in search
    hits = pypi.search({'name': query, 'summary': query}, 'or')
  File ""/usr/lib/python3.9/xmlrpc/client.py"", line 1116, in __call__
    return self.__send(self.__name, args)
  File ""/usr/lib/python3.9/xmlrpc/client.py"", line 1456, in __request
    response = self.__transport.request(
  File ""/usr/lib/python3.9/site-packages/pip/_internal/network/xmlrpc.py"", line 45, in request
    return self.parse_response(response.raw)
  File ""/usr/lib/python3.9/xmlrpc/client.py"", line 1348, in parse_response
    return u.close()
  File ""/usr/lib/python3.9/xmlrpc/client.py"", line 662, in close
    raise Fault(**self._stack[0])
xmlrpc.client.Fault: <Fault -32500: ""RuntimeError: PyPI's XMLRPC API has been temporarily disabled due to unmanageable load and will be deprecated in the near future. See https://status.python.org/ for more information."">

sorry about the missing information, it was late here, maybe i should have been already stop working. so i didnt read the information and deleted it subconscious. Sorry for that.

I use most up to date ArchLinux, with 
python --version
Python 3.9.1

uname -a
Linux hostnamet 5.9.14-arch1-1 #1 SMP PREEMPT Sat, 12 Dec 2020 14:37:12 +0000 x86_64 GNU/Linux

but it seems not to be related here anyway, thanks for bringing me on the right trail.

",right currently see issue missing dependency master pip search error exception recent call last file line status file line run query file line search query query file line return file line response file line request return file line return file line close raise fault fault temporarily disabled due unmanageable load near future see information sorry missing information late maybe already stop working didnt read information subconscious sorry use date python version python sat related anyway thanks right trail,issue,negative,negative,neutral,neutral,negative,negative
748637530,"> pip install deepspeech

works well here:
```
$ pip install deepspeech
Collecting deepspeech
  Downloading deepspeech-0.9.3-cp39-cp39-manylinux1_x86_64.whl (9.2 MB)
     |████████████████████████████████| 9.2 MB 1.3 MB/s 
Requirement already satisfied: numpy>=1.19.4 in /usr/lib/python3/dist-packages (from deepspeech) (1.19.4)
Installing collected packages: deepspeech
Successfully installed deepspeech-0.9.3
```

the stack is weird and it seems more to be relaterd to pip itself, there's nothing deepspeech specific there.

But you don't care to share any of the required details we ask for in the github template, so we can't help you.",pip install work well pip install requirement already satisfied collected successfully stack weird pip nothing specific care share ask template ca help,issue,positive,positive,positive,positive,positive,positive
748323578,No rush on our account -- this functionality won't be removed immediately.  If you'd rather wait for the next release branch that's probably fine!,rush account functionality wo removed immediately rather wait next release branch probably fine,issue,negative,positive,positive,positive,positive,positive
748307081,"Merged on master (thanks for the `payload.env` tip, looks cleaner now!), but we still have an active release branch to merge it on.",master thanks tip cleaner still active release branch merge,issue,positive,positive,neutral,neutral,positive,positive
748147180,"LGTM, just make sure it works well on tags as well, but reading the code it seems okay",make sure work well well reading code,issue,positive,positive,positive,positive,positive,positive
748113895,I'm curious why the variables are in the command and not in the `env:..` map?  I'm not disagreeing -- if it works it works :),curious command map work work,issue,negative,negative,neutral,neutral,negative,negative
748088440,"This should be ready for review now. I tried to keep changes as contained to .taskcluster.yml as possible to avoid having to modify extensively every single task template, but we may want to clean things up going forward.",ready review tried keep possible avoid modify extensively every single task template may want clean going forward,issue,positive,positive,neutral,neutral,positive,positive
747922967,"> I've got a WIP that seems to be working in #3473, basically by emulating the v0 GITHUB_* variables by hand. Seems self contained enough but I'll wait for Alex to be back to get this reviewed and merged.

is it ready yet?",got working basically hand self enough wait back get ready yet,issue,positive,positive,neutral,neutral,positive,positive
747794696,"I get `framework not found deepspeech_ios` when building the xcworkspace folder found here: https://github.com/mozilla/DeepSpeech/tree/master/native_client/swift. 

I've tried unlinking / relinking the lib and changing the Framework search path, but no success. Does anybody have a fix for this issue?

Also another question: What's the CPU usage of this model? Would it be possible to run it on background for a long time without draining the battery, or is it more advisable to use a wakeword detection model in conjunction with it (kind of like a Siri / Alexa type setup).

",get framework found building folder found tried framework search path success anybody fix issue also another question usage model would possible run background long time without battery advisable use detection model conjunction kind like type setup,issue,positive,positive,positive,positive,positive,positive
747774891,"I've got a WIP that seems to be working in #3473, basically by emulating the v0 GITHUB_* variables by hand. Seems self contained enough but I'll wait for Alex to be back to get this reviewed and merged.",got working basically hand self enough wait back get,issue,negative,neutral,neutral,neutral,neutral,neutral
747746700,"<details>

<summary>Uh oh! Looks like an error! Details</summary>

InterpreterError at template.tasks[""decision_task""].payload.command[3]: object has no property ""url""

</details>",summary oh like error object property,issue,negative,neutral,neutral,neutral,neutral,neutral
747643092,"<details>

<summary>Uh oh! Looks like an error! Details</summary>

incomplete explicit mapping pair; a key node is missed; or followed by a non-tabulated empty line at line 57, column 31:
                expires: ${fromNow: '7 days'}
                                  ^

</details>",summary oh like error incomplete explicit pair key node empty line line column day,issue,negative,negative,neutral,neutral,negative,negative
747610147,"This will also apply on the `tensorflow` repo.  It doesn't support issues so I can't file a separate issue to track that.

The timing on this drop is flexible -- we just want something sooner than ""never"" :)",also apply support ca file separate issue track timing drop flexible want something sooner never,issue,negative,neutral,neutral,neutral,neutral,neutral
747308328,"> Have you tried setting the `--use_allow_growth` flag to `True`? This fixed the OOM issue for me

I have been trying around with a larger corpus and keep getting https://github.com/tensorflow/tensorflow/issues/14433#issuecomment-343403513 with ever-decreasing batch sizes. That comment suggests the same solution. I have tried that flag, and although memory usage starts low, it ends up erroring in the same way. Might be my setup or other parameters causing issues though. I'll keep that flag set at all times though, since it likely helps, if anything. Thanks for confirming.

> I filed #3471 to track this

Thanks for stepping in, even if it's not fixed any time soon, it's good to know that it's acknowledged and being tracked. I'll be sure to watch that issue.",tried setting flag true fixed issue trying around corpus keep getting batch size comment solution tried flag although memory usage low way might setup causing though keep flag set time though since likely anything thanks confirming track thanks stepping even fixed time soon good know acknowledged tracked sure watch issue,issue,positive,positive,positive,positive,positive,positive
747293934,"> > 
> 
> I would expect a well-structured Python program that, when I pressed Ctrl+C, would cleanly unlock every point where the threads or processes are locked (e.g. stuck waiting in queues) and finish. Not to need to repeatedly send `KeyboardInterrupt`. But if you consider this a ""feature"" of Python and not a bug in `DeepSpeech.py`, that's fine by me.

It bothers me too and I took a brief look at it but could not identify any specific reasons in our code, thus reaching the same conclusion as @lissyx: this is a weird Python behavior. But to be clear, I would happily review and accept a patch to fix this, I just have no idea where the problem comes from. I filed https://github.com/mozilla/DeepSpeech/issues/3471 to track this, you're welcome to take a look.",would expect python program would cleanly unlock every point locked stuck waiting finish need repeatedly send consider feature python bug fine took brief look could identify specific code thus reaching conclusion weird python behavior clear would happily review accept patch fix idea problem come track welcome take look,issue,positive,positive,positive,positive,positive,positive
747111070,@i-sf Have you tried setting the `--use_allow_growth` flag to `True`? This fixed the OOM issue for me,tried setting flag true fixed issue,issue,negative,positive,positive,positive,positive,positive
747109012,"This is not a bug, please reach for support on Discourse.",bug please reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
745414486,"This is not a bug, please use discourse for reaching support and make sure to read the sticky post documenting guidelines. ",bug please use discourse reaching support make sure read sticky post,issue,positive,positive,positive,positive,positive,positive
744683904,"When re-exporting the tflite model the segmentation fault is gone:

~~~
../venv_tools/bin/python DeepSpeech.py --export_tflite --export_dir . --alphabet_config_path=deepspeech-german/alphabet.txt --checkpoint_dir=deepspeech-german
~~~

I'm closign this one and will ask the creators what they did to cause an segmentation fault.",model segmentation fault gone one ask cause segmentation fault,issue,negative,neutral,neutral,neutral,neutral,neutral
744582277,"The error is the same, see above. I will try now to convert the functional ""pb"" version to a ""tflite"" version, maybe the provider of the model was using some problematic versions here.",error see try convert functional version version maybe provider model problematic,issue,negative,neutral,neutral,neutral,neutral,neutral
744451269,"> Where is this core dump?

This is dependant on how your system is configured, I think. But maybe just run under `gdb`, if the stack is the same ...
But really, I'm sorry but I don't have time to investigate that.",core dump system think maybe run stack really sorry time investigate,issue,negative,negative,negative,negative,negative,negative
744449403,"> > I tried now and the shipped `deepspeech-0.9.3-models.tflite` works without a segmentation fault. So it seems to be a problem with the generation of the tflite file.
> 
> It would really help if you took the time to verify using directly the C++ binary instead of the Python bindings, there's still several layers intersecting which could bring issues ...

native_client.amd64.tflite.linux_dbg/deepspeech --model deepspeech/output_graph.tflite  --audio deepspeech/test-noisy.wav 
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.9.3-0-gf2e9c858
INFO: Initialized TensorFlow Lite runtime.
Segmentation fault (core dumped)

~~~
GNU gdb (Ubuntu 9.2-0ubuntu1~20.04) 9.2
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from /home/widerstand/Downloads/native_client.amd64.tflite.linux_dbg/deepspeech...
(gdb) r
Starting program: /home/widerstand/Downloads/native_client.amd64.tflite.linux_dbg/deepspeech --model deepspeech/output_graph.tflite --audio deepspeech/test-noisy.wav
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.9.3-0-gf2e9c858
INFO: Initialized TensorFlow Lite runtime.

Program received signal SIGSEGV, Segmentation fault.
__memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
321     ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S: No such file or directory.
(gdb) bt
#0  __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
#1  0x00007ffff71d2376 in tflite::ops::builtin::reshape::Eval (context=0x55555568b338, node=0x5555556a5120) at tensorflow/lite/kernels/reshape.cc:160
#2  0x00007ffff7365eae in tflite::impl::Subgraph::OpInvoke (this=0x55555568b310, op_reg=..., node=0x5555556a5120) at ./tensorflow/lite/core/subgraph.h:408
#3  0x00007ffff7363c2a in tflite::impl::Subgraph::Invoke (this=0x55555568b310) at tensorflow/lite/core/subgraph.cc:947
#4  0x00007ffff7370517 in tflite::impl::Interpreter::Invoke (this=0x55555568b240) at tensorflow/lite/interpreter.cc:238
#5  0x00007ffff6f7724c in TFLiteModelState::init (this=0x555555684520, model_path=0x7fffffffd7b7 ""deepspeech/output_graph.tflite"") at native_client/tflitemodelstate.cc:242
#6  0x00007ffff6f69caa in DS_CreateModel (aModelPath=0x7fffffffd7b7 ""deepspeech/output_graph.tflite"", retval=0x7fffffffce90) at native_client/deepspeech.cc:298
#7  0x0000555555567b37 in main (argc=5, argv=0x7fffffffd268) at client.cc:456
(gdb) 

~~~",tried shipped work without segmentation fault problem generation file would really help took time verify directly binary instead python still several could bring model audio lite segmentation fault core gnu copyright free foundation license gnu version later free free change redistribute warranty extent permitted law type show show warranty type show configuration configuration bug please see find manual documentation help type help type apropos word search related word reading starting program model audio thread host library lite program received signal segmentation fault file directory main,issue,positive,positive,positive,positive,positive,positive
744446921,"> I tried now and the shipped `deepspeech-0.9.3-models.tflite` works without a segmentation fault. So it seems to be a problem with the generation of the tflite file.

It would really help if you took the time to verify using directly the C++ binary instead of the Python bindings, there's still several layers intersecting which could bring issues ...",tried shipped work without segmentation fault problem generation file would really help took time verify directly binary instead python still several could bring,issue,positive,positive,positive,positive,positive,positive
744446627,"> I guess, they have just used the deepspeech tools.

Yeah, but who knows: maybe there is a subtle bug in the way they used it, or in their env, or in tensorflow, or in our code, or in python bindings.",guess used yeah maybe subtle bug way used code python,issue,negative,negative,negative,negative,negative,negative
744446150,"> What do you need to find the reason, why the deepspeech tflite generation failed?

Mostly, time. Which is a very scarce resource, even more when I'm on holidays.",need find reason generation mostly time scarce resource even,issue,negative,positive,positive,positive,positive,positive
744445244,"> So there's nothing we can do until people who produced that model investigates this issue.

I guess, they have just used the deepspeech tools. What do you need to find the reason, why the deepspeech tflite generation failed? I can also try to follow the steps in https://deepspeech.readthedocs.io/en/v0.9.2/TRAINING.html#exporting-a-model-for-tflite to export a version for tflite.",nothing people produced model issue guess used need find reason generation also try follow export version,issue,negative,neutral,neutral,neutral,neutral,neutral
744429105,"> I tried now and the shipped `deepspeech-0.9.3-models.tflite` works without a segmentation fault. So it seems to be a problem with the generation of the tflite file.

So there's nothing we can do until people who produced that model investigates this issue.",tried shipped work without segmentation fault problem generation file nothing people produced model issue,issue,positive,neutral,neutral,neutral,neutral,neutral
744428819,"> > I trying to use a tflite model from https://github.com/AASHISHAG/deepspeech-german for version 0.9.0 (at the bottom of the page). It is the file `output_graph.tflite` in the [Google Drive folder](https://drive.google.com/drive/folders/1L7ILB-TMmzL8IDYi_GW8YixAoYWjDMn1). When loading the model I get a segmentation fault. I have raised an issue also [at the project's issue page](https://github.com/AASHISHAG/deepspeech-german/issues/29)
> 
> do you repro with the model we ship?

I tried now and the shipped `deepspeech-0.9.3-models.tflite` works without a segmentation fault. So it seems to be a problem with the generation of the tflite file.",trying use model version bottom page file drive folder loading model get segmentation fault raised issue also project issue page model ship tried shipped work without segmentation fault problem generation file,issue,negative,neutral,neutral,neutral,neutral,neutral
744425491,"

> > #0  __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
> > #1  0x00007ffff33c10e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> > #2  0x00007ffff347a4e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> > #3  0x00007ffff347d3ec in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> > #4  0x00007ffff3227daf in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> 
> please repro with debug symbols:
> 
> * download https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/native_client.amd64.tflite.linux_dbg.tar.xz
> * replace `/home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so` with the one in the `tar.xz`

~~~
GNU gdb (Ubuntu 9.2-0ubuntu1~20.04) 9.2
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from venv/bin/python3...
(No debugging symbols found in venv/bin/python3)
(gdb) r
Starting program: /home/widerstand/Projekte/hands-free-tv/venv/bin/python3 deepspeech_test.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff46fe700 (LWP 78149)]
[New Thread 0x7ffff3efd700 (LWP 78150)]
[New Thread 0x7fffef6fc700 (LWP 78151)]
[New Thread 0x7fffecefb700 (LWP 78152)]
[New Thread 0x7fffea6fa700 (LWP 78153)]
[New Thread 0x7fffe7ef9700 (LWP 78154)]
[New Thread 0x7fffe76f8700 (LWP 78155)]
[Thread 0x7fffe76f8700 (LWP 78155) exited]
[Thread 0x7fffe7ef9700 (LWP 78154) exited]
[Thread 0x7fffea6fa700 (LWP 78153) exited]
[Thread 0x7fffecefb700 (LWP 78152) exited]
[Thread 0x7fffef6fc700 (LWP 78151) exited]
[Thread 0x7ffff3efd700 (LWP 78150) exited]
[Thread 0x7ffff46fe700 (LWP 78149) exited]
[Detaching after fork from child process 78156]
Loading model from file ./deepspeech/output_graph.tflite
TensorFlow: v2.3.0-6-g23ad988fcd
DeepSpeech: v0.9.3-0-gf2e9c858
INFO: Initialized TensorFlow Lite runtime.

Thread 1 ""python3"" received signal SIGSEGV, Segmentation fault.
__memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
321     ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S: No such file or directory.
(gdb) bt
#0  __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
#1  0x00007fffdf615376 in tflite::ops::builtin::reshape::Eval (context=0xc200d8, node=0xdb2c20) at tensorflow/lite/kernels/reshape.cc:160
#2  0x00007fffdf7a8eae in tflite::impl::Subgraph::OpInvoke (this=0xc200b0, op_reg=..., node=0xdb2c20) at ./tensorflow/lite/core/subgraph.h:408
#3  0x00007fffdf7a6c2a in tflite::impl::Subgraph::Invoke (this=0xc200b0) at tensorflow/lite/core/subgraph.cc:947
#4  0x00007fffdf7b3517 in tflite::impl::Interpreter::Invoke (this=0xc1da00) at tensorflow/lite/interpreter.cc:238
#5  0x00007fffdf3ba24c in TFLiteModelState::init (this=0xbca590, model_path=0x975e30 ""./deepspeech/output_graph.tflite"") at native_client/tflitemodelstate.cc:242
#6  0x00007fffdf3accaa in DS_CreateModel (aModelPath=0x975e30 ""./deepspeech/output_graph.tflite"", retval=0x7fffffffc5b0) at native_client/deepspeech.cc:298
#7  0x00007ffff44f26d6 in _wrap_CreateModel (args=<optimized out>, kwargs=<optimized out>) at impl_wrap.cpp:4010
#8  0x00000000005f4249 in PyCFunction_Call ()
#9  0x00000000005f46d6 in _PyObject_MakeTpCall ()
#10 0x0000000000570936 in _PyEval_EvalFrameDefault ()
#11 0x00000000005f7146 in _PyFunction_Vectorcall ()
#12 0x0000000000570286 in _PyEval_EvalFrameDefault ()
#13 0x00000000005f7146 in _PyFunction_Vectorcall ()
#14 0x000000000059c95d in ?? ()
#15 0x00000000005f463f in _PyObject_MakeTpCall ()
#16 0x00000000005704b9 in _PyEval_EvalFrameDefault ()
#17 0x00000000005f7146 in _PyFunction_Vectorcall ()
#18 0x000000000056b26e in _PyEval_EvalFrameDefault ()
#19 0x00000000005f7146 in _PyFunction_Vectorcall ()
#20 0x000000000056b26e in _PyEval_EvalFrameDefault ()
#21 0x000000000056955a in _PyEval_EvalCodeWithName ()
#22 0x000000000068c4a7 in PyEval_EvalCode ()
#23 0x000000000067bc91 in ?? ()
#24 0x000000000067bd0f in ?? ()
#25 0x000000000067bdcb in PyRun_FileExFlags ()
#26 0x000000000067de4e in PyRun_SimpleFileExFlags ()
#27 0x00000000006b6032 in Py_RunMain ()
#28 0x00000000006b63bd in Py_BytesMain ()
#29 0x00007ffff7dd60b3 in __libc_start_main (main=0x4eea30 <main>, argc=2, argv=0x7fffffffd2d8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, 
    stack_end=0x7fffffffd2c8) at ../csu/libc-start.c:308
#30 0x00000000005fa4de in _start ()
(gdb) 
~~~",please replace one gnu copyright free foundation license gnu version later free free change redistribute warranty extent permitted law type show show warranty type show configuration configuration bug please see find manual documentation help type help type apropos word search related word reading found starting program thread host library new thread new thread new thread new thread new thread new thread new thread thread thread thread thread thread thread thread fork child process loading model file lite thread python received signal segmentation fault file directory main,issue,positive,positive,positive,positive,positive,positive
744415323,"> __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321

this is really weird, please share more context on your setup, hardware, ...",really weird please share context setup hardware,issue,negative,negative,negative,negative,negative,negative
744414855,"> Python version from Ubuntu does not fix it:

please also try to repro without python bindings but directly the C++ binary (debug version please)",python version fix please also try without python directly binary version please,issue,positive,positive,neutral,neutral,positive,positive
744413542,"Python version from Ubuntu does not fix it:

~~~
Copyright (C) 2020 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from venv/bin/python3...
(No debugging symbols found in venv/bin/python3)
(gdb) r
Starting program: /home/widerstand/Projekte/hands-free-tv/venv/bin/python3 deepspeech_test.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff46fe700 (LWP 75950)]
[New Thread 0x7ffff3efd700 (LWP 75951)]
[New Thread 0x7fffef6fc700 (LWP 75952)]
[New Thread 0x7fffecefb700 (LWP 75953)]
[New Thread 0x7fffec6fa700 (LWP 75954)]
[New Thread 0x7fffe7ef9700 (LWP 75955)]
[New Thread 0x7fffe76f8700 (LWP 75956)]
[Thread 0x7fffe76f8700 (LWP 75956) exited]
[Thread 0x7fffe7ef9700 (LWP 75955) exited]
[Thread 0x7fffec6fa700 (LWP 75954) exited]
[Thread 0x7fffecefb700 (LWP 75953) exited]
[Thread 0x7fffef6fc700 (LWP 75952) exited]
[Thread 0x7ffff3efd700 (LWP 75951) exited]
[Thread 0x7ffff46fe700 (LWP 75950) exited]
[Detaching after fork from child process 75957]
Loading model from file ./deepspeech/output_graph.tflite
TensorFlow: v2.3.0-6-g23ad988
DeepSpeech: v0.9.3-0-gf2e9c85

Thread 1 ""python3"" received signal SIGSEGV, Segmentation fault.
__memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
321     ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S: No such file or directory.
(gdb) bt
#0  __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
#1  0x00007ffff42b50e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
#2  0x00007ffff436e4e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
#3  0x00007ffff43713ec in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
#4  0x00007ffff411bdaf in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
#5  0x00007ffff4118260 in DS_CreateModel () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
#6  0x00007ffff44f26d6 in _wrap_CreateModel (args=<optimized out>, kwargs=<optimized out>) at impl_wrap.cpp:4010
#7  0x00000000005f4249 in PyCFunction_Call ()
#8  0x00000000005f46d6 in _PyObject_MakeTpCall ()
#9  0x0000000000570936 in _PyEval_EvalFrameDefault ()
#10 0x00000000005f7146 in _PyFunction_Vectorcall ()
#11 0x0000000000570286 in _PyEval_EvalFrameDefault ()
#12 0x00000000005f7146 in _PyFunction_Vectorcall ()
#13 0x000000000059c95d in ?? ()
#14 0x00000000005f463f in _PyObject_MakeTpCall ()
#15 0x00000000005704b9 in _PyEval_EvalFrameDefault ()
#16 0x00000000005f7146 in _PyFunction_Vectorcall ()
#17 0x000000000056b26e in _PyEval_EvalFrameDefault ()
#18 0x00000000005f7146 in _PyFunction_Vectorcall ()
#19 0x000000000056b26e in _PyEval_EvalFrameDefault ()
#20 0x000000000056955a in _PyEval_EvalCodeWithName ()
#21 0x000000000068c4a7 in PyEval_EvalCode ()
#22 0x000000000067bc91 in ?? ()
#23 0x000000000067bd0f in ?? ()
#24 0x000000000067bdcb in PyRun_FileExFlags ()
#25 0x000000000067de4e in PyRun_SimpleFileExFlags ()
#26 0x00000000006b6032 in Py_RunMain ()
#27 0x00000000006b63bd in Py_BytesMain ()
#28 0x00007ffff7dd60b3 in __libc_start_main (main=0x4eea30 <main>, argc=2, argv=0x7fffffffd2d8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, 
    stack_end=0x7fffffffd2c8) at ../csu/libc-start.c:308
#29 0x00000000005fa4de in _start ()
(gdb) 
~~~

Testing next instructions ...",python version fix copyright free foundation license gnu version later free free change redistribute warranty extent permitted law type show show warranty type show configuration configuration bug please see find manual documentation help type help type apropos word search related word reading found starting program thread host library new thread new thread new thread new thread new thread new thread new thread thread thread thread thread thread thread thread fork child process loading model file gad thread python received signal segmentation fault file directory main testing next,issue,positive,positive,positive,positive,positive,positive
744403869,"> The test.csv file is like this

Please avoid screenshots and share pure text content. ",file like please avoid share pure text content,issue,positive,positive,positive,positive,positive,positive
744403627,"This is no à bug, please reach for support on Discourse. Chinese model, as documented, relies on bytes output mode and not an alphabet. ",bug please reach support discourse model output mode alphabet,issue,positive,neutral,neutral,neutral,neutral,neutral
744313606,"> Again, feeding and running the graph is not that simple.

I am certain that I am very likely underestimating the difficulty in solving this issue, but my primary goal is making sure we understand that all known issues are acknowledged and tracked, even if there is no time to solve them in the near or mid future.

> If I was able to predict future, I would be rich.

Not quite my point, rather, if you think the issue should be tracked at all when it's so unlikely anyone has the time or interest to ever fix it. It technically works, but it could be improved. I am asking for your opinion on the importance to **track** this bug (having an issue open for it in this repository).

> we are unlikely to have time to investigate.

This is completely understandable, the project's goals do not necessarily align with mine. But given it's an open source, anyone can step in and make the library better for everyone as long as the additions are reasonable (worst case, a new fork is born). The first step is to have a way to track these features, for which I've now opened the above linked issue.",feeding running graph simple certain likely difficulty issue primary goal making sure understand known acknowledged tracked even time solve near mid future able predict future would rich quite point rather think issue tracked unlikely anyone time interest ever fix technically work could opinion importance track bug issue open repository unlikely time investigate completely understandable project necessarily align mine given open source anyone step make library better everyone long reasonable worst case new fork born first step way track linked issue,issue,positive,positive,neutral,neutral,positive,positive
744296352,"> Now that we've agreed that this could be solved but it would potentially take a large amount of effort and time, do you think there should be a report open to track progress on this work, or is it so unlikely to ever be fixed that it's not worth tracking? Maybe someone would eventually step in and tackle it, was the report present.

If I was able to predict future, I would be rich.



> Okay thanks, I will open a new issue tracking improvements to that feature then, with steps to reproduce.

Thanks, but please understand we are unlikely to have time to investigate.",agreed could would potentially take large amount effort time think report open track progress work unlikely ever fixed worth maybe someone would eventually step tackle report present able predict future would rich thanks open new issue feature reproduce thanks please understand unlikely time investigate,issue,positive,positive,neutral,neutral,positive,positive
744295064,"> Regardless, I would argue this behaviour should change, to enable people (like me) to train on very large datasets, with a small percentage of the data at a time.

Please also understand that your usecase is quite a specific one, and to be honest this is the first time someone reports. It's not surprising you run into issues.



> I expect my system to be able to handle 1000 audio clips at a time.

Which turned out to be true.



>  I expect the `--limit_*` flags to tell `DeepSpeech.py` how much data it should load and train with at a time.

Which was supposed to be how it works, but the feeding is non trivial, so there could be bugs from us, bugs from the tensorflow runtime. This is where it should be dealt with: https://github.com/mozilla/DeepSpeech/blob/3e10163ec8c8941d1a5afb45f8b1c5b1e0c9592c/training/deepspeech_training/util/feeding.py#L106-L120

So above `num_samples` we should stop yielding, but maybe we already read and transformed WAV.

> At the very least, the help could be updated to clarify that it limits the amount of in-use audios, and that are not freed after the epoch completes.

Again, feeding and running the graph is not that simple.",regardless would argue behaviour change enable people like train large small percentage data time please also understand quite specific one honest first time someone surprising run expect system able handle audio clip time turned true expect tell much data load train time supposed work feeding non trivial could u dealt stop yielding maybe already read least help could clarify amount freed epoch feeding running graph simple,issue,positive,positive,positive,positive,positive,positive
744294786,"> Please, search about python, multithreading and killing with CTRL+C. If you are willing to fix that properly, and this is likely going to be a can of worms, you are welcome to send a patch.

Now that we've agreed that this could be solved but it would potentially take a large amount of effort and time, do you think there should be a report open to track progress on this work, or is it so unlikely to ever be fixed that it's not worth tracking? Maybe someone would eventually step in and tackle it, was the report present.

> That feature has been broken for ages until we fix it a few months ago and we don't rely on it. So the hard truth is, it can be bugged.

Okay thanks, I will open a new issue tracking improvements to that feature then, with steps to reproduce.",please search python killing willing fix properly likely going welcome send patch agreed could would potentially take large amount effort time think report open track progress work unlikely ever fixed worth maybe someone would eventually step tackle report present feature broken fix ago rely hard truth thanks open new issue feature reproduce,issue,positive,positive,neutral,neutral,positive,positive
744290072,"> I would expect a well-structured Python program that, when I pressed Ctrl+C, would cleanly unlock every point where the threads or processes are locked (e.g. stuck waiting in queues) and finish. Not to need to repeatedly send `KeyboardInterrupt`. But if you consider this a ""feature"" of Python and not a bug in `DeepSpeech.py`, that's fine by me.

Please, search about python, multithreading and killing with CTRL+C. If you are willing to fix that properly, and this is likely going to be a can of worms, you are welcome to send a patch.



> I expect my system to be able to handle 1000 audio clips at a time. I expect the `--limit_*` flags to tell `DeepSpeech.py` how much data it should load and train with at a time. At the very least, the help could be updated to clarify that it limits the amount of in-use audios, and that are not freed after the epoch completes. Regardless, I would argue this behaviour should change, to enable people (like me) to train on very large datasets, with a small percentage of the data at a time.

That feature has been broken for ages until we fix it a few months ago and we don't rely on it. So the hard truth is, it can be bugged. 

If you think the help is not clear enough, please send a patch ...



> I am not familiar with the abbreviation ""STR"", if you could explain it, I would be grateful.

Steps To Reproduce",would expect python program would cleanly unlock every point locked stuck waiting finish need repeatedly send consider feature python bug fine please search python killing willing fix properly likely going welcome send patch expect system able handle audio clip time expect tell much data load train time least help could clarify amount freed epoch regardless would argue behaviour change enable people like train large small percentage data time feature broken fix ago rely hard truth think help clear enough please send patch familiar abbreviation could explain would grateful reproduce,issue,positive,positive,positive,positive,positive,positive
744286181,"> (gdb) bt
> #0  __memmove_avx_unaligned_erms () at ../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:321
> #1  0x00007ffff33c10e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> #2  0x00007ffff347a4e0 in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> #3  0x00007ffff347d3ec in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> #4  0x00007ffff3227daf in ?? () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> #5  0x00007ffff3224260 in DS_CreateModel () from /home/widerstand/Projekte/hands-free-tv/venv/lib/python3.8/site-packages/deepspeech/lib/libdeepspeech.so
> #6  0x00007ffff35fe6d6 in _wrap_CreateModel (args=<optimized out>, kwargs=<optimized out>) at impl_wrap.cpp:4010
> #7  0x00007ffff7b1851c in cfunction_call_varargs () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #8  0x00007ffff7b18ad1 in _PyObject_MakeTpCall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #9  0x00007ffff7af6b46 in _PyEval_EvalFrameDefault () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #10 0x00007ffff7aee6f0 in function_code_fastcall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #11 0x00007ffff7af6c26 in _PyEval_EvalFrameDefault () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #12 0x00007ffff7aee6f0 in function_code_fastcall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #13 0x00007ffff7b1a3fa in _PyObject_FastCallDict () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #14 0x00007ffff7b1a4f2 in _PyObject_Call_Prepend () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #15 0x00007ffff7b6b061 in slot_tp_init () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #16 0x00007ffff7b67253 in type_call () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #17 0x00007ffff7b18ad1 in _PyObject_MakeTpCall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #18 0x00007ffff7af5213 in _PyEval_EvalFrameDefault () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #19 0x00007ffff7aee6f0 in function_code_fastcall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #20 0x00007ffff7af5252 in _PyEval_EvalFrameDefault () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #21 0x00007ffff7aee6f0 in function_code_fastcall () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #22 0x00007ffff7af5252 in _PyEval_EvalFrameDefault () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #23 0x00007ffff7bd2b94 in _PyEval_EvalCodeWithName () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #24 0x00007ffff7bd2d9e in PyEval_EvalCodeEx () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #25 0x00007ffff7bd2dcb in PyEval_EvalCode () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #26 0x00007ffff7c08528 in run_eval_code_obj () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #27 0x00007ffff7c085e0 in run_mod () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #28 0x00007ffff7c0aec5 in PyRun_FileExFlags () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> --Type <RET> for more, q to quit, c to continue without paging--c
> #29 0x00007ffff7c0b036 in PyRun_SimpleFileExFlags () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #30 0x00007ffff7c25708 in Py_RunMain () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #31 0x00007ffff7c25b39 in Py_BytesMain () from /home/linuxbrew/.linuxbrew/Cellar/python@3.8/3.8.5/lib/libpython3.8.so.1.0
> #32 0x00007ffff786d0b3 in __libc_start_main (main=0x4008a0 <main>, argc=2, argv=0x7fffffffd2d8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffd2c8) at ../csu/libc-start.c:308
> #33 0x00000000004008d9 in _start ()

Python 3.8 from brew on linux ? This is not a setup we test, things could go wrong. Please verify using vanilla python from ubuntu and a virtualenv as documented (according to the stack, you did the venv part).",type ret quit continue without main python brew setup test could go wrong please verify vanilla python according stack part,issue,negative,negative,negative,negative,negative,negative
744286109,"> that's not a bug, that's a feature of python

I would expect a well-structured Python program that, when I pressed <kbd>Ctrl+C</kbd>, would cleanly unlock every point where the threads or processes are locked (e.g. stuck waiting in queues) and finish. Not to need to repeatedly send `KeyboardInterrupt`. But if you consider this a ""feature"" of Python and not a bug in `DeepSpeech.py`, that's fine by me.

> you only have showed weird behaviors when you push **your** system to the limits

I expect my system to be able to handle 1000 audio clips at a time. I expect the `--limit_*` flags to tell `DeepSpeech.py` how much data it should load and train with at a time. At the very least, the help could be updated to clarify that it limits the amount of in-use audios, and that are not freed after the epoch completes. Regardless, I would argue this behaviour should change, to enable people (like me) to train on very large datasets, with a small percentage of the data at a time.

> if you have clear STR, you are welcome to file a bug

I am not familiar with the abbreviation ""STR"", if you could explain it, I would be grateful.",bug feature python would expect python program would cleanly unlock every point locked stuck waiting finish need repeatedly send consider feature python bug fine weird push system expect system able handle audio clip time expect tell much data load train time least help could clarify amount freed epoch regardless would argue behaviour change enable people like train large small percentage data time clear welcome file bug familiar abbreviation could explain would grateful,issue,positive,positive,positive,positive,positive,positive
744283866,"> I trying to use a tflite model from https://github.com/AASHISHAG/deepspeech-german for version 0.9.0 (at the bottom of the page). It is the file `output_graph.tflite` in the [Google Drive folder](https://drive.google.com/drive/folders/1L7ILB-TMmzL8IDYi_GW8YixAoYWjDMn1). When loading the model I get a segmentation fault. I have raised an issue also [at the project's issue page](https://github.com/AASHISHAG/deepspeech-german/issues/29)

do you repro with the model we ship?",trying use model version bottom page file drive folder loading model get segmentation fault raised issue also project issue page model ship,issue,negative,neutral,neutral,neutral,neutral,neutral
744283348,"> No point in opening a new issue if it's not considered a bug, so I will ask first. Is `DeepSpeech.py` not freeing the memory used after each epoch something that could be considered a bug that needs fixing? If it is, then I would consider this issue to still be valid (it's running out of memory when it shouldn't because it should be freeing the data it loaded after each epoch).

you only have showed weird behaviors when you push **your** system to the limits. if you have clear STR, you are welcome to file a bug.",point opening new issue considered bug ask first freeing memory used epoch something could considered bug need fixing would consider issue still valid running memory freeing data loaded epoch weird push system clear welcome file bug,issue,positive,positive,positive,positive,positive,positive
744282816,"> Another issue is that cancellation does not seem to be clean (I need to press Ctrl+C a few times or else it won't actually terminate), but that might need to be a separate issue, if you consider it to be one.

that's not a bug, that's a feature of python",another issue cancellation seem clean need press time else wo actually terminate might need separate issue consider one bug feature python,issue,negative,positive,positive,positive,positive,positive
744280768,"Another issue is that cancellation does not seem to be clean (I need to press <kbd>Ctrl+C</kbd> a few times or else it won't actually terminate), but that might need to be a separate issue, if you consider it to be one.",another issue cancellation seem clean need press time else wo actually terminate might need separate issue consider one,issue,negative,positive,positive,positive,positive,positive
744279489,"No point in opening a new issue if it's not considered a bug, so I will ask first. Is `DeepSpeech.py` not freeing the memory used after each epoch something that could be considered a bug that needs fixing? If it is, then I would consider this issue to still be valid (it's running out of memory when it shouldn't because it should be freeing the data it loaded after each epoch).",point opening new issue considered bug ask first freeing memory used epoch something could considered bug need fixing would consider issue still valid running memory freeing data loaded epoch,issue,positive,positive,positive,positive,positive,positive
744275963,"> I would like to know why was this closed as invalid?

because there seems to be no bug that you first described


> If I were to send a patch for this, would it mean it would be rejected?

if you have a clear bug,  STRs and a patch, that's not the same story.",would like know closed invalid bug first send patch would mean would clear bug patch story,issue,positive,negative,neutral,neutral,negative,negative
744269525,"By the way, after training completes, it seems to get stuck and use a lot of CPU (and the memory isn't freed, either):

<details><summary>Last lines of output</summary>

```
--------------------------------------------------------------------------------
I Exporting the model...
I Loading best validating checkpoint from /mnt/corpus/tiny-ds-train/checkpoints/best_dev-393
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
I Loading variable from checkpoint: layer_1/bias
I Loading variable from checkpoint: layer_1/weights
I Loading variable from checkpoint: layer_2/bias
I Loading variable from checkpoint: layer_2/weights
I Loading variable from checkpoint: layer_3/bias
I Loading variable from checkpoint: layer_3/weights
I Loading variable from checkpoint: layer_5/bias
I Loading variable from checkpoint: layer_5/weights
I Loading variable from checkpoint: layer_6/bias
I Loading variable from checkpoint: layer_6/weights
I Models exported at /mnt/corpus/tiny-ds-train/exported
I Model metadata file saved to /mnt/corpus/tiny-ds-train/exported/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.
```

</details>

<details><summary>A few of the many lines after pressing <kbd>Ctrl+C</kbd></summary>

```
Process ForkPoolWorker-491:
Process ForkPoolWorker-444:
Process ForkPoolWorker-552:
Process ForkPoolWorker-283:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 108, in worker
    task = get()
  File ""/usr/lib/python3.6/multiprocessing/queues.py"", line 335, in get
    res = self._reader.recv_bytes()
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 407, in _recv_bytes
    buf = self._recv(4)
  File ""/usr/lib/python3.6/multiprocessing/connection.py"", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt

---snip---

KeyboardInterrupt
KeyboardInterrupt
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 108, in worker
    task = get()
  File ""/usr/lib/python3.6/multiprocessing/queues.py"", line 334, in get
    with self._rlock:
  File ""/usr/lib/python3.6/multiprocessing/synchronize.py"", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap
    self.run()
^C  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
KeyboardInterrupt
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
```

</details>

<details><summary>First few lines of <code>top</code> before killing <code>DeepSpeech.py</code></summary>

```
top - 08:23:33 up 4 days, 15:26,  4 users,  load average: 2.16, 39.16, 27.86
Tasks: 729 total,   1 running, 728 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1.4 us,  6.4 sy,  0.0 ni, 92.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :  15746.5 total,    176.0 free,  13959.3 used,   1611.3 buff/cache
MiB Swap:  98303.0 total,  52354.2 free,  45948.8 used.    378.2 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
27090 root      20   0   36.1g   1.4g 420212 S  35.2   9.4   1619:55 DeepSpeech.py
 7968 admin     20   0   11788   4344   3032 R   0.7   0.0   0:00.19 top
```

</details>

<details><summary><code>top</code> after killing <code>DeepSpeech.py</code></summary>

```
top - 08:33:31 up 4 days, 15:36,  2 users,  load average: 2.49, 64.29, 57.94
Tasks: 114 total,   1 running, 113 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.1 us,  0.0 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
MiB Mem :  15746.5 total,  14974.8 free,    259.3 used,    512.5 buff/cache
MiB Swap:  98303.0 total,  98168.2 free,    134.8 used.  15168.2 avail Mem
```

</details>

35% CPU usage after being done, 45948MB of swap usage and 13959MB of RAM in use after completing does not feel right. At least the GPU is not in use (even if memory is still allocated there).
",way training get stuck use lot memory freed either summary last output model loading best loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable model file saved model make sure information file correct complete summary many pressing process process process process recent call last file line file line run file line worker task get file line get file line file line file line chunk read handle file line file line run file line worker task get file line get file line return file line file line run file line run file line run summary first code top killing code top day load average total running sleeping stopped zombie u ni id wa hi si st mib mem total free used mib swap total free used avail mem user ni mem command root top summary code top killing code top day load average total running sleeping stopped zombie u ni id wa hi si st mib mem total free used mib swap total free used avail mem usage done swap usage ram use feel right least use even memory still,issue,positive,positive,positive,positive,positive,positive
744259363,"I would like to know why was this closed as invalid? Why is wanting to adjust the behaviour of `--limit_*` to be adjusted to free the memory it used after each epoch invalid? If I were to send a patch for this, would it mean it would be rejected?",would like know closed invalid wanting adjust behaviour free memory used epoch invalid send patch would mean would,issue,positive,negative,neutral,neutral,negative,negative
743726256,"> Not found: deepspeech-0.9.1-models.pbmm; No such file or directory

And this is likely your problem... ",found file directory likely problem,issue,negative,neutral,neutral,neutral,neutral,neutral
743726220,"This is not a support channel, use discourse. ",support channel use discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
743203029,"Running `DeepSpeech.py` as above but with batch size 10, given the following `.csv` sizes:

```
$ wc /mnt/corpus/clips/{train,dev,test}.csv
  1001   9759  97198 /mnt/data/corpus/cv-es-5.1/clips/train.csv
   151   1466  14613 /mnt/data/corpus/cv-es-5.1/clips/dev.csv
   151   1398  14156 /mnt/data/corpus/cv-es-5.1/clips/test.csv
```

When this is done, memory usage is around the 4.5GB mark. It still increases, but far more slowly.

Not knowing how `DeepSpeech.py` is working, perhaps it's loading all the `.wav` files randomly and never freeing them? Even if it only trains with 1K at a time, it has 381K to choose from. If this was the case, then I misunderstood how the limits work, as I thought it would only choose the same first 1000, not 1000 random every time. This is a plausible explanation with no additional knowledge of the code.

Assuming that's the case, I presume the solution would be to have the script free the loaded files after it completes the training step. This can potentially cause a lot more reads from disk, but will keep the memory usage reasonable, and with so many files but such a low limit, it's probably unlikely the cache would be reused anyway. Regardless, I expect the bottleneck to be training itself, not reading from disk.

Thank you both so much for helping me investigate this issue.",running batch size given following size train dev test done memory usage around mark still far slowly knowing working perhaps loading randomly never freeing even time choose case misunderstood work thought would choose first random every time plausible explanation additional knowledge code assuming case presume solution would script free loaded training step potentially cause lot disk keep memory usage reasonable many low limit probably unlikely cache would anyway regardless expect bottleneck training reading disk thank much helping investigate issue,issue,positive,positive,neutral,neutral,positive,positive
743194147,"> > Most clips are in the range of 100KB to 200KB
>
> Have you verified this?

I've checked with `ls -lh | head` and the 10 first files fall roughly in the range (of course there are outliers). If you take the average of 381K files over 58G, the math also checks out (roughly ~160KB). I could provide a more accurate representation of the file sizes if needed, but I don't think that's necessary:

```
$ ls -lh clips | head
total 57G
-rw-r--r-- 1 admin admin 149K Dec  9 09:44 common_voice_es_18306544.wav
-rw-r--r-- 1 admin admin 183K Dec  9 09:44 common_voice_es_18306545.wav
-rw-r--r-- 1 admin admin 104K Dec  9 09:44 common_voice_es_18306546.wav
-rw-r--r-- 1 admin admin 146K Dec  9 09:44 common_voice_es_18306547.wav
-rw-r--r-- 1 admin admin 228K Dec  9 09:44 common_voice_es_18306548.wav
-rw-r--r-- 1 admin admin 145K Dec  9 16:14 common_voice_es_18306564.wav
-rw-r--r-- 1 admin admin 145K Dec  9 10:19 common_voice_es_18306565.wav
-rw-r--r-- 1 admin admin 182K Dec  9 09:44 common_voice_es_18306566.wav
-rw-r--r-- 1 admin admin 112K Dec  9 10:19 common_voice_es_18306567.wav

```",clip range checked head first fall roughly range course take average math also roughly could provide accurate representation file size think necessary clip head total,issue,negative,positive,neutral,neutral,positive,positive
743189821,">  I could run the same command but on a trimmed-down version `head -n1001` of the `train.csv` set.

Please do.



> Most clips are in the range of 100KB to 200KB

Have you verified this?",could run command version head set please clip range,issue,negative,neutral,neutral,neutral,neutral,neutral
743189250,">  However, I don't think this is the issue.

Please prove this. So far you just prove you get to the limit of your memory and `fork()` failing is just a side-effect.",however think issue please prove far prove get limit memory fork failing,issue,negative,positive,neutral,neutral,positive,positive
743183198,"> Maybe there is a bug in limitation

If you think it's worth investigating, I could run the same command but on a trimmed-down version `head -n1001` of the `train.csv` set. However, I don't think this is the issue. With a limit of 1000 for the training set as above but a batch size of 10 to run out of memory faster, training only takes 100 steps, which checks out with the limit. Each epoch takes roughly 20 seconds:

```
--------------------------------------------------------------------------------
Epoch 4 |   Training | Elapsed Time: 0:00:18 | Steps: 100 | Loss: 73.963538
Epoch 4 | Validation | Elapsed Time: 0:00:01 | Steps: 15 | Loss: 90.087933 | Dataset: /mnt/corpus/clips/dev.csv
--------------------------------------------------------------------------------
Epoch 5 |   Training | Elapsed Time: 0:00:18 | Steps: 100 | Loss: 73.619752
Epoch 5 | Validation | Elapsed Time: 0:00:01 | Steps: 15 | Loss: 85.446852 | Dataset: /mnt/corpus/clips/dev.csv
I Saved new best validating model with loss 85.446852 to: /mnt/corpus/tiny-ds-train/checkpoints/best_dev-593
--------------------------------------------------------------------------------
```


> Memory usage without running

226MB. tmux, Docker and this program is pretty much all that running.

> Memory usage evolution over time?

The usage of the GPU memory is constant, which the script preallocates to use 14852MiB / 15109MiB. The issue is with fork, so I don't think GPU memory plays a role here.

I am not sure what the right way to check the usage evolution is, so I've ran the following command instead (using the same command as above but batch size 10 to trigger the issue faster):

<details><summary>while true; do date | tee -a memgrow.txt; free | tee -a memgrow.txt; sleep 60; done</summary>

```
Fri 11 Dec 2020 12:57:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420      274508    15012452       12136      837460    15502952
Swap:      16776188      116856    16659332
Fri 11 Dec 2020 12:58:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420      548084    14491164       22384     1085172    15219260
Swap:      16776188      116856    16659332
Fri 11 Dec 2020 12:59:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420     2406724    12110048       28536     1607648    13354836
Swap:      16776188      116856    16659332
Fri 11 Dec 2020 01:00:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420     4499868     6649652     1109968     4974900    10180312
Swap:      16776188      116856    16659332
Fri 11 Dec 2020 01:01:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420     6825728     2207724     1110064     7090968     7854376
Swap:      16776188      116856    16659332
Fri 11 Dec 2020 01:02:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420     8538276      680608     1110148     6905536     6141500
Swap:      16776188      115832    16660356

---reaches epoch 9 and 10 in between here---

Fri 11 Dec 2020 01:03:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420     9948224      154812     1110228     6021384     4731280
Swap:      16776188      115832    16660356
Fri 11 Dec 2020 01:04:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    11480604      169436     1110328     4474380     3199056
Swap:      16776188      115832    16660356
Fri 11 Dec 2020 01:05:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    13135940      169088     1110424     2819392     1562976
Swap:      16776188      115832    16660356
Fri 11 Dec 2020 01:06:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14224344      169036     1109884     1731040      492428
Swap:      16776188      115832    16660356
Fri 11 Dec 2020 01:07:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14521380      265876     1099016     1337164      216736
Swap:      16776188      909176    15867012
Fri 11 Dec 2020 01:08:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14728960      171644     1099172     1223816       65888
Swap:      16776188     1988728    14787460
Fri 11 Dec 2020 01:09:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14664816      192540     1098984     1267064      108348
Swap:      16776188     2756216    14019972
Fri 11 Dec 2020 01:10:04 PM UTC

--- epoch 27 around here ---

              total        used        free      shared  buff/cache   available
Mem:       16124420    14644392      166136     1099264     1313892      105112
Swap:      16776188     3880568    12895620
Fri 11 Dec 2020 01:11:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14738060      151316     1099336     1235044       50900
Swap:      16776188     5313144    11463044
Fri 11 Dec 2020 01:12:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14712056      141320     1099400     1271044       58972
Swap:      16776188     6291832    10484356
Fri 11 Dec 2020 01:13:04 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14676488      239760     1098324     1208172      126212
Swap:      16776188     7539320     9236868
Fri 11 Dec 2020 01:14:05 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14688264      148956     1099388     1287200       74468
Swap:      16776188     8494200     8281988
Fri 11 Dec 2020 01:15:05 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14753864      160104     1098520     1210452       47828
Swap:      16776188     9502840     7273348
Fri 11 Dec 2020 01:16:05 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14710208      152024     1099400     1262188       65216
Swap:      16776188    10391160     6385028
Fri 11 Dec 2020 01:17:05 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14721708      156044     1099376     1246668       61372
Swap:      16776188    11234936     5541252
Fri 11 Dec 2020 01:18:06 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14721520      161928     1099632     1240972       64540
Swap:      16776188    12201592     4574596
Fri 11 Dec 2020 01:19:06 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14656676      151076     1099656     1316668       91208
Swap:      16776188    12897912     3878276
Fri 11 Dec 2020 01:20:06 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14691776      181720     1098808     1250924       89288
Swap:      16776188    13916024     2860164
Fri 11 Dec 2020 01:21:06 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14713644      148652     1099040     1262124       61736
Swap:      16776188    14586232     2189956
Fri 11 Dec 2020 01:22:06 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14638776      261568     1098568     1224076      155980
Swap:      16776188    15592056     1184132
Fri 11 Dec 2020 01:23:09 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14773328      135128     1098372     1215964       25756
Swap:      16776188    16374860      401328
Fri 11 Dec 2020 01:24:13 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    14654352      186240     1099128     1283828      110336
Swap:      16776188    16730856       45332
Fri 11 Dec 2020 01:25:13 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420    10425528     4425436     1099344     1273456     4344408
Swap:      16776188    16704296       71892

---died, killed it, last epoch reads the following (exception cut, already pasted above, eventually fails at fork)---
    --------------------------------------------------------------------------------
    Epoch 45 |   Training | Elapsed Time: 0:00:27 | Steps: 100 | Loss: 61.188060
    Epoch 45 | Validation | Elapsed Time: 0:00:09 | Steps: 15 | Loss: 59.810799 | Dataset: /mnt/corpus/clips/dev.csv
    I Saved new best validating model with loss 59.810799 to: /mnt/corpus/tiny-ds-train/checkpoints/best_dev-4592
    --------------------------------------------------------------------------------
    Epoch 46 |   Training | Elapsed Time: 0:01:00 | Steps: 100 | Loss: 61.542710
    Epoch 46 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: /mnt/corpus/clips/dev.csv                                  T
    raceback (most recent call last):
    File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call

Fri 11 Dec 2020 01:26:13 PM UTC
              total        used        free      shared  buff/cache   available
Mem:       16124420      220396    15690492        1824      213532    15628320
Swap:      16776188      130088    16646100
```

</details>

> Kernel logs showing OOM 

Sorry, I do not have enough experience with this. I've put OOM in the title mostly to make this easier to find (the script does run Out Of Memory and can't fork anymore, after all). `dmesg` seems to not show anything relevant, unless I don't know what to look for. I do not think the kernel is running out of memory, the script simply halts when trying to fork, but it does this close to 15G, not the maximum amount (15.4G). This is the last line of the traceback I posted above where it halts:

```
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 66, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
```

> `ulimit` ?

```
$ ulimit
unlimited
```",maybe bug limitation think worth investigating could run command version head set however think issue limit training set batch size run memory faster training limit epoch roughly epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss saved new best model loss memory usage without running docker program pretty much running memory usage evolution time usage memory constant script use mib mib issue fork think memory role sure right way check usage evolution ran following command instead command batch size trigger issue faster summary true date tee free tee sleep done total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap epoch total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap epoch around total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap total used free available mem swap last epoch following exception cut already pasted eventually fork epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss recent call last file line total used free available mem swap kernel showing sorry enough experience put title mostly make easier find script run memory ca fork show anything relevant unless know look think kernel running memory script simply trying fork close maximum amount last line posted file line allocate memory unlimited,issue,positive,positive,positive,positive,positive,positive
743172827,"> The clips have a sample rate of 16KHZ, converted from CommonVoice's `.mp3` files via the `sox` command (used `bin/import_cv2.py`, basically). Most clips are in the range of 100KB to 200KB, and in theory, `--limit_train 1000` is capping that to 1000 clips only. Way below the 16GB of RAM. The total set consists of 381K files, roughly 57GB, but as I understand it, I'm using only 1000 with the limit.

Maybe there is a bug in limitation

Memory usage without running ? Memory usage evolution over time?
Kernel logs showing OOM ?
`ulimit` ?",clip sample rate converted via command used basically clip range theory capping clip way ram total set roughly understand limit maybe bug limitation memory usage without running memory usage evolution time kernel showing,issue,negative,negative,neutral,neutral,negative,negative
743165157,"> Please provide accurate specs

For the graphics card, [NVIDIA T4 website](https://www.nvidia.com/en-us/data-center/tesla-t4/) claims the following:

- Turing Tensor Cores: 320
- NVIDIA CUDA® cores: 2,560
- Single Precision Performance (FP32): 8.1 TFLOPS
- Mixed Precision (FP16/FP32): 65 FP16 TFLOPS
- INT8 Precision: 130 INT8 TOPS
- INT4 Precision: 260 INT4 TOPS
- Interconnect: Gen3 x16 PCIe
- Memory Capacity: 16 GB GDDR6
- Bandwidth: 320+ GB/s
- Power: 70 watts

As reported by `screenfetch`:
- CPU: Intel Xeon Platinum 8259CL @ 4x 3.222GHz
- RAM: 15746MiB

Disk space should not be an issue, but the data is in a 256GB volume.

> NO swap is bad practice, 16GB might be not enough given your dataset

The clips have a sample rate of 16KHZ, converted from CommonVoice's `.mp3` files via the `sox` command (used `bin/import_cv2.py`, basically). Most clips are in the range of 100KB to 200KB, and in theory, `--limit_train 1000` is capping that to 1000 clips only. Way below the 16GB of RAM. The total set consists of 381K files, roughly 57GB, but as I understand it, I'm using only 1000 with the limit.

Skimming through previous issues seemed to indicate swap was fine, and if it's indeed unused memory, I can't see how swap would be harmful.

> reusing this makes sure you don't do silly mistakes

I have made sure to carefully follow [Training Your Own Model](https://deepspeech.readthedocs.io/en/v0.9.2/TRAINING.html) from the documentation, and given I'm using the docker image, I'd hope everything is configured correctly already. The only thing that is different here is the way I run `DeepSpeech.py` and the parameters I use.

> `wc` outputs `lines words bytes`, so that's actually 134 processes

Apologies, you're right, I misread that output. In any case, if I leave it running for longer, I reach 345 processes (16GB RAM, 16GB swap) before it ran out of space again. Thank you both for the prompt response.",please provide accurate spec graphic card following tensor registered single precision performance mixed precision precision top precision top interconnect gen memory capacity power platinum ram mib disk space issue data volume swap bad practice might enough given clip sample rate converted via command used basically clip range theory capping clip way ram total set roughly understand limit skimming previous indicate swap fine indeed unused memory ca see swap would harmful sure silly made sure carefully follow training model documentation given docker image hope everything correctly already thing different way run use actually right misread output case leave running longer reach ram swap ran space thank prompt response,issue,positive,positive,neutral,neutral,positive,positive
743155097,"> I expect to **not** see this happen:
> 
> ```
> $ ps aux | grep ""python3 DeepSpeech"" | wc
>     134    5067   70446
> ```
> 
> Over 5000 instances of the process running makes no sense. I do not understand why there are so many of them, but it's not a surprise forking fails...

`wc` outputs `lines words bytes`, so that's actually 134 processes, not 5067.

What's the output of `python -c 'import os; print(os.cpu_count())'`?",expect see happen python process running sense understand many surprise actually output python o print,issue,negative,positive,positive,positive,positive,positive
743154578,"> GPU model and memory: Tesla T4 ([Amazon G4 instance](https://aws.amazon.com/es/ec2/instance-types/g4/))

Please provide accurate specs, I don't have time to dig into the mess of Amazon EC2



> The machine runs out with 16GB of memory and no swap partition.

NO swap is bad practice, 16GB might be not enough given your dataset


Also please try, reuse and contribute to https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/ which is already used by other languages communities to manage their training: reusing this makes sure you don't do silly mistakes.",model memory instance please provide accurate spec time dig mess machine memory swap partition swap bad practice might enough given also please try reuse contribute already used manage training sure silly,issue,negative,negative,neutral,neutral,negative,negative
742782830,"Let's see.

On (1), hmm I'm not sure what fell apart there. I don't have too many use cases for submitting with bitcode. The main reason is for Apple to be able to rebuild your app independently of you when they make platform improvements, but the symbol mess can get complicated and as long as you update the app yourself regularly, you should be OK just disabling bitcode as I describe in the PR.

On (2), this looks like an address sanitization issue. You should be able to fix this by disabling address sanitization in the build chain?",let see sure fell apart many use main reason apple able rebuild independently make platform symbol mess get complicated long update regularly describe like address issue able fix address build chain,issue,negative,positive,positive,positive,positive,positive
740641439,"> For the second problem maybe a new flag like `augment_growth_epochs` could be helpful for better combination with early-stopping.

Yeah, that could be useful, usually for hyperparameter schedules there's a separate start/ramp-up/ramp-down/stop range compared to the number of steps/epochs for the whole training run.",second problem maybe new flag like could helpful better combination yeah could useful usually separate range number whole training run,issue,positive,positive,positive,positive,positive,positive
740636717,"Might have found a reason for the accuracy problem. First I did misunderstand the augmentation flag description and the _pitch_ and _tempo_ flags are not converted correctly. Second, the new `start:stop` logic could be another reason. I normally use a high training epoch number like 1000, because the training is stopped with early-stopping. But I assume that the `:stop` is related to the _epochs_ flag and I'm therefore using only the start values for the augmentations instead of the full range.

Will try to run a test in the next time, but I don't believe this will also solve the slower training.

For the second problem maybe a new flag like `augment_growth_epochs` could be helpful for better combination with early-stopping.",might found reason accuracy problem first misunderstand augmentation flag description converted correctly second new start stop logic could another reason normally use high training epoch number like training stopped assume stop related flag therefore start instead full range try run test next time believe also solve training second problem maybe new flag like could helpful better combination,issue,negative,positive,positive,positive,positive,positive
740631120,"> @imrahul361 Thanks for the work, I took the liberty to finish your PR and land it: 

Sorry for the inconvenience and delay in completing the work...please do take it. ",thanks work took liberty finish land sorry inconvenience delay work please take,issue,positive,negative,negative,negative,negative,negative
740629905,Thanks @imrahul361 I've taken your last PR and landed it.,thanks taken last landed,issue,negative,positive,neutral,neutral,positive,positive
740628746,"@imrahul361 Thanks for the work, I took the liberty to finish your PR and land it: #3416 and #3461",thanks work took liberty finish land,issue,positive,positive,positive,positive,positive,positive
740592251,"> > https://community-tc.services.mozilla.com/tasks/Eh2O5dknTqiAP9QmpzppVQ
> > > No JSDoc documentation was found for object ""Stream"" or any path ending with that.
> 
> This task points to [72004d8](https://github.com/mozilla/DeepSpeech/commit/72004d8f719af7b0b0095e8ac3e26c460659fd02) which is not on r0.9.

Doh, you're right, I mixed up things.",documentation found object stream path ending task right mixed,issue,negative,positive,positive,positive,positive,positive
740590643,"> https://community-tc.services.mozilla.com/tasks/Eh2O5dknTqiAP9QmpzppVQ
> 
> > No JSDoc documentation was found for object ""Stream"" or any path ending with that.

This task points to 72004d8f719af7b0b0095e8ac3e26c460659fd02 which is not on r0.9.",documentation found object stream path ending task,issue,negative,neutral,neutral,neutral,neutral,neutral
740589874,None of the causing PRs landed on r0.9 so I don't think it's that.,none causing landed think,issue,negative,neutral,neutral,neutral,neutral,neutral
740559889,"@reuben Maybe it's worth merging this also on `r0.9`? A 0.9.3 could benefit from this, too bad we shipped 0.9.2 a few days ago :)",maybe worth also could benefit bad shipped day ago,issue,negative,negative,negative,negative,negative,negative
740488659,Done! Hope I did everything correctly,done hope everything correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
740475404,"@sholtrop After you switch to `StreamImpl`, please make sure you have squashed all your commits into one on the PR, then we'll run CI to make sure. Thanks for spotting that!",switch please make sure one run make sure thanks spotting,issue,positive,positive,positive,positive,positive,positive
740457857,"@CatalinVoss Thank you so much for these changes! It's great that iOS support is finally almost there. However, I've run into two issues:
1. I can't seem to include bitcode once I copy the framework from the test app to my own. The error:
```

Showing All Errors Only
Bitcode bundle could not be generated because '/Users/ryantremblay/ReLearnApp/node_modules/react-native-transcription/ios/Frameworks/deepspeech_ios.framework/deepspeech_ios' was built without full bitcode. All frameworks and dylibs for bitcode must be generated from Xcode Archive or Install build file '/Users/ryantremblay/ReLearnApp/node_modules/react-native-transcription/ios/Frameworks/deepspeech_ios.framework/deepspeech_ios' for architecture arm64



```
2. I can't submit an archive of the app to App Store Connect. I get the error: 
```
ITMS-90338: Non-public API usage - The app references non-public symbols in Frameworks/deepspeech_ios.framework/deepspeech_ios: ___asan_alloca_poison, ___asan_allocas_unpoison, ___asan_handle_no_return, ___asan_init, ___asan_memset, ___asan_option_detect_stack_use_after_return, ___asan_register_image_globals, ___asan_report_load1, ___asan_report_load4, ___asan_report_load8, ___asan_report_store1, ___asan_report_store4, ___asan_report_store8, ___asan_set_shadow_f5, ___asan_shadow_memory_dynamic_address, ___asan_stack_free_5, ___asan_stack_malloc_0, ___asan_stack_malloc_1, ___asan_stack_malloc_2, ___asan_stack_malloc_3, ___asan_stack_malloc_5, ___asan_unregister_image_globals, ___asan_version_mismatch_check_apple_clang_1200. If method names in your source code match the private Apple APIs listed above, altering your method names will help prevent this app from being flagged in future submissions. In addition, note that one or more of the above APIs may be located in a static library that was included with your app. If so, they must be removed. For further information, visit the Technical Support Information at http://developer.apple.com/support/technical/

```
*EDIT: Solution: Just build the framework again with bitcode turned on and Address Sanitization turned off*

I think it relates to the Address Sanitizer (asan) option in the Xcode build settings. Disabling asan results in this crash on launch:
```
dyld: Library not loaded: @rpath/libclang_rt.asan_ios_dynamic.dylib
  Referenced from: /private/var/containers/Bundle/Application/A268CC69-A458-45F9-95F6-D2DEDA2700FB/ReLearn.app/Frameworks/deepspeech_ios.framework/deepspeech_ios
  Reason: image not found
dyld: launch, loading dependent libraries
DYLD_LIBRARY_PATH=/usr/lib/system/introspection
DYLD_INSERT_LIBRARIES=/Developer/usr/lib/libBacktraceRecording.dylib:/Developer/usr/lib/libMainThreadChecker.dylib:/Developer/Library/PrivateFrameworks/DTDDISupport.framework/libViewDebuggerSupport.dylib
(lldb) 
```

Thanks for contributing to this issue!",thank much great support finally almost however run two ca seem include copy framework test error showing bundle could built without full must archive install build file architecture arm ca submit archive store connect get error usage method source code match private apple listed method help prevent future addition note one may static library included must removed information visit technical support information edit solution build framework turned address turned think address option build crash launch library loaded reason image found launch loading dependent thanks issue,issue,positive,positive,positive,positive,positive,positive
740438979,"I think we should flip the naming, `export type Stream` and name the class `StreamImpl` (and update its users)",think flip naming export type stream name class update,issue,negative,neutral,neutral,neutral,neutral,neutral
740436151,"> @reuben it feels like this is something we, want to do, right ?

Yep.",like something want right yep,issue,positive,positive,positive,positive,positive,positive
740230016,"I've named its exported type `StreamType`. This means this now works:
```typescript
import {StreamType, Model} from './native_client/javascript'

const model = new Model(`path/to/model`)
let stream: StreamType | null = null
if (true)
  stream = model.createStream()
```",type work typescript import model model new model let stream null null true stream,issue,negative,positive,positive,positive,positive,positive
740213575,">  Exporting ONLY the type information is also possible, if that is preferred.

Yes, I think it would be better in light of that. Can you update your PR?",type information also possible preferred yes think would better light update,issue,positive,positive,positive,positive,positive,positive
740183706,"Thanks for the quick reply!
Exporting it means the class as well as its type information can be imported/used by users of the library.
The only downside is that the `Stream` class is not meant to be instantiated by users directly (as is noted in the docs). This will make it possible for users to do so erroneously.
Exporting ONLY the type information is also possible, if that is preferred. ",thanks quick reply class well type information library downside stream class meant directly noted make possible erroneously type information also possible preferred,issue,negative,positive,neutral,neutral,positive,positive
740172322,"@reuben it feels like this is something we, want to do, right ?

@sholtrop i know nothing about typescript, what would be the consequences ? ",like something want right know nothing typescript would,issue,negative,positive,positive,positive,positive,positive
740154404,"<details>

<summary>No Taskcluster jobs started for this pull request</summary>


```js

The `allowPullRequests` configuration for this repository (in `.taskcluster.yml` on the
default branch) does not allow starting tasks for this pull request.
```

</details>",summary pull request configuration repository default branch allow starting pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
739873720,Sorry for forgetting to come back here.,sorry forgetting come back,issue,negative,negative,negative,negative,negative,negative
739532145,"sorry @stepkillah if it looks like a lot, but it should not be that much, and once you address those I think you'll get very close from the goal: adding support for all those flavors is a non trivial impact on how things were done, so it's not surprising :)",sorry like lot much address think get close goal support non trivial impact done surprising,issue,positive,positive,positive,positive,positive,positive
739527785,">  should I maybe set `artifacts` path to `path: ""/tmp/artifacts/""` ?

please, as i said earlier look at the log file completely, this artifact error is just a side effect of the previous failures: https://community-tc.services.mozilla.com/tasks/T4Jiy2DJSpSNYQEvukxPFQ/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FT4Jiy2DJSpSNYQEvukxPFQ%2Fruns%2F0%2Fartifacts%2Fpublic%2Flogs%2Flive.log#L910-918",maybe set path path please said look log file completely artifact error side effect previous,issue,negative,negative,neutral,neutral,negative,negative
739527117,"> @lissyx in latest build - I see tests failed, hopefully, fixed that locally, but can't figure out why `DeepSpeech dotnet CPU package` fails
> should I maybe set `artifacts` path to `path: ""/tmp/artifacts/""` ?
> 
> ```
> Uploading error artifact public/ from file public/ with message ""Could not read directory 'C:\\Users\\task_160726145306496\\public'"", reason ""file-missing-on-worker"" and expiry 2020-12-13T12:55:22.997Z
> ```

I dont see any failure, only an exception, and it is still related to your task using the wrong worker

@stepkillah i was looking at the wrong group: it is good pratice you directly link to the error, otherwise its complicated to know what you are talking about",latest build see hopefully fixed locally ca figure package maybe set path path error artifact file message could read directory reason expiry dont see failure exception still related task wrong worker looking wrong group good directly link error otherwise complicated know talking,issue,negative,negative,neutral,neutral,negative,negative
739520371,"@lissyx in latest build - I see tests failed, hopefully, fixed that locally, but can't figure out why `DeepSpeech dotnet CPU package` fails
should I maybe set `artifacts` path to `path: ""/tmp/artifacts/""` ?

```
Uploading error artifact public/ from file public/ with message ""Could not read directory 'C:\\Users\\task_160726145306496\\public'"", reason ""file-missing-on-worker"" and expiry 2020-12-13T12:55:22.997Z
```",latest build see hopefully fixed locally ca figure package maybe set path path error artifact file message could read directory reason expiry,issue,negative,positive,positive,positive,positive,positive
739498297,"> > > @lissyx so, current error ` * data should have required property 'image'\n * data.artifacts should be object""` - possible fix for `data.artifacts` - use same way as node e.g.
> > > ```
> > >     artifacts:
> > >       ""public"":
> > >         type: ""directory""
> > >         path: ""/tmp/artifacts/""
> > >         expires:
> > >           $if: '(event.event == ""push"") || (event.event == ""tag"")'
> > >           then: { $fromNow: '6 months' }
> > >           else: { $fromNow: '7 days' }
> > > ```
> > > 
> > > 
> > > but didn't find how to set `image` for windows?
> > 
> > 
> > this is super weird, I'm not sure what you did there ...
> 
> hm, that's how it's done with [node](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package-opt-base.tyml#L51), will it work for win? or it was failing because of the wrong image (not win) and current artifact set up is correct?

no, you also need to adapt: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/win-opt-base.tyml#L89-L95",current error data property object possible fix use way node public type directory path push tag else day find set image super weird sure done node work win failing wrong image win current artifact set correct also need adapt,issue,positive,positive,positive,positive,positive,positive
739497696,"> > @lissyx so, current error ` * data should have required property 'image'\n * data.artifacts should be object""` - possible fix for `data.artifacts` - use same way as node e.g.
> > ```
> >     artifacts:
> >       ""public"":
> >         type: ""directory""
> >         path: ""/tmp/artifacts/""
> >         expires:
> >           $if: '(event.event == ""push"") || (event.event == ""tag"")'
> >           then: { $fromNow: '6 months' }
> >           else: { $fromNow: '7 days' }
> > ```
> > 
> > 
> > but didn't find how to set `image` for windows?
> 
> this is super weird, I'm not sure what you did there ...

hm, that's how it's done with [node](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package-opt-base.tyml#L51), will it work for win? or it was failing because of the wrong image (not win) and current artifact set up is correct?",current error data property object possible fix use way node public type directory path push tag else day find set image super weird sure done node work win failing wrong image win current artifact set correct,issue,positive,positive,positive,positive,positive,positive
739494494,"@lissyx so, current error ` * data should have required property 'image'\n  * data.artifacts should be object""` - possible fix for `data.artifacts` - use same way as node e.g.
```
    artifacts:
      ""public"":
        type: ""directory""
        path: ""/tmp/artifacts/""
        expires:
          $if: '(event.event == ""push"") || (event.event == ""tag"")'
          then: { $fromNow: '6 months' }
          else: { $fromNow: '7 days' }
```

but didn't find how to set `image` for windows? ",current error data property object possible fix use way node public type directory path push tag else day find set image,issue,negative,neutral,neutral,neutral,neutral,neutral
739489570,"> @stepkillah now there's one Windows failure and it is your changes, the zip command fails to find a DeepSpeechNetCore.exe pay attention, when you look at the logs, there's an unrelated side effect at the end you need to scroll back to see your actual error

yeah, seeing it, pushing fix now",one failure zip command find pay attention look unrelated side effect end need scroll back see actual error yeah seeing pushing fix,issue,negative,negative,negative,negative,negative,negative
739489240,"@stepkillah now there's one Windows failure and it is your changes, the zip command fails to find a DeepSpeechNetCore.exe pay attention, when you look at the logs, there's an unrelated side effect at the end you need to scroll back to see your actual error ",one failure zip command find pay attention look unrelated side effect end need scroll back see actual error,issue,negative,negative,negative,negative,negative,negative
739487929,"Nice, its scheduling. I'll keep an eye, dont worry about some failures we know there are some intermittent ones, i'll rerun because i dont think you have creds 😉 ",nice keep eye dont worry know intermittent rerun dont think,issue,positive,positive,positive,positive,positive,positive
739481934,"> > I see two on line 70 and two on line 81
> 
> yeah, thanks, I got, it also in another files,so will fix them all

There are instructions somewhere on how to locally run this decision task step to verify that kind of errors locally but i have no idea if it's okay under Windows, and i dont remember where i wrote it 😂",see two line two line yeah thanks got also another fix somewhere locally run decision task step verify kind locally idea dont remember wrote,issue,positive,positive,positive,positive,positive,positive
739481366,"> I see two on line 70 and two on line 81

yeah, thanks, I got, it also in another files,so will fix them all",see two line two line yeah thanks got also another fix,issue,positive,positive,positive,positive,positive,positive
739480814,I see two on line 70 and two on line 81,see two line two line,issue,negative,neutral,neutral,neutral,neutral,neutral
739480509,"> @stepkillah I verified locally and you have a ""\t"" (tab) char on line 33, that's what the error is telling you. You have others in the file, please remove all of them.

oh, it's tab, thanks a lot :) ",locally tab char line error telling file please remove oh tab thanks lot,issue,negative,positive,neutral,neutral,positive,positive
739480404,"@stepkillah I verified locally and you have a ""\t"" (tab) char on line 33, that's what the error is telling you. You have others in the file, please remove all of them.",locally tab char line error telling file please remove,issue,negative,neutral,neutral,neutral,neutral,neutral
739480050,"> @lissyx trying to run CI to test if scripts I added works, but it fails at the very beginning with the same error all the time (somewhere in [`.tyml`](https://github.com/stepkillah/DeepSpeech/blob/master/taskcluster/dotnet-package-opt-base.tyml) file), no matter what I put into `artifacts` prop, do you have any suggestions on how to fix it? it looks like I missing something, but didn't found out what yet
> 
> `Artifact ""public"" not found at ""/tmp/artifacts/"": (HTTP code 404) no such container - Could not find the file /tmp/artifacts/ in container`

https://community-tc.services.mozilla.com/tasks/ME01budKR_GdawMJnLpuJQ/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FME01budKR_GdawMJnLpuJQ%2Fruns%2F0%2Fartifacts%2Fpublic%252Flogs%252Flive.log#L1162-1164

it's pretty explicit:
> yaml.scanner.ScannerError: while scanning for the next token
> found character '\t' that cannot start any token
>  in ""/home/build-user/DeepSpeech/ds/taskcluster/dotnet-package-opt-base.tyml"", line 33, column 1",trying run test added work beginning error time somewhere file matter put prop fix like missing something found yet artifact public found code container could find file container pretty explicit scanning next token found character start token line column,issue,negative,positive,neutral,neutral,positive,positive
739421574,"@lissyx trying to run CI to test if scripts I added works, but it fails at the very beginning with the same error all the time (somewhere in [`.tyml`](https://github.com/stepkillah/DeepSpeech/blob/master/taskcluster/dotnet-package-opt-base.tyml) file), no matter what I put into `artifacts` prop, do you have any suggestions on how to fix it?  it looks like I missing something, but didn't found out what yet

`Artifact ""public"" not found at ""/tmp/artifacts/"": (HTTP code 404) no such container - Could not find the file /tmp/artifacts/ in container`",trying run test added work beginning error time somewhere file matter put prop fix like missing something found yet artifact public found code container could find file container,issue,negative,negative,neutral,neutral,negative,negative
739080152,CircleCI got killed bc of some limit and I can't re-run. The TC failures now look unrelated.,got limit ca look unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
738895907,"Dear @iProMC thanks for getting in contact with us. As this doesn't seem like a bug in DeepSpeech, we would like to ask you if you could take your request to [Mozilla's Discourse](https://discourse.mozilla.org/c/mozilla-voice-stt/). Thanks! ",dear thanks getting contact u seem like bug would like ask could take request discourse thanks,issue,positive,positive,positive,positive,positive,positive
738781133,(Please delete the upstream branch once you're done working on it),please delete upstream branch done working,issue,negative,neutral,neutral,neutral,neutral,neutral
738666108,"> @CatalinVoss Sorry, but valgrind metadata tests on linux shows a memory leak regression: https://community-tc.services.mozilla.com/tasks/VizPwDWmRa-rx6i2f2z_1w/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FVizPwDWmRa-rx6i2f2z_1w%2Fruns%2F0%2Fartifacts%2Fpublic%252Fvalgrind_extended.log

@CatalinVoss It might just be some false-positive from Valgrind:
```
==4364== LEAK SUMMARY:
==4364==    definitely lost: 0 bytes in 0 blocks
==4364==    indirectly lost: 0 bytes in 0 blocks
==4364==      possibly lost: 0 bytes in 0 blocks
==4364==    still reachable: 96 bytes in 2 blocks
==4364==                       of which reachable via heuristic:
==4364==                         newarray           : 9,280 bytes in 11 blocks
```

And you would just have to update the exclusion lists: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-valgrind-utils.sh#L5-L9",sorry memory leak regression might leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic would update exclusion,issue,negative,negative,negative,negative,negative,negative
738649202,"@CatalinVoss Sorry, but valgrind metadata tests on linux shows a memory leak regression: https://community-tc.services.mozilla.com/tasks/VizPwDWmRa-rx6i2f2z_1w/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FVizPwDWmRa-rx6i2f2z_1w%2Fruns%2F0%2Fartifacts%2Fpublic%252Fvalgrind_extended.log",sorry memory leak regression,issue,negative,negative,negative,negative,negative,negative
737329356,"> @lissyx you can also look into azure pipelines, it has a free tier and self-hosted agents that can be run locally

Thanks, but I'm sorry I can't spend more time than I already spent, I'm not 100% anymore on DeepSpeech, and I have been spending too much time on it in the past weeks.",also look azure free tier run locally thanks sorry ca spend time already spent spending much time past,issue,positive,negative,neutral,neutral,negative,negative
737292344,"@lissyx you can also look into azure pipelines, it has a free tier and self-hosted agents that can be run locally",also look azure free tier run locally,issue,positive,positive,positive,positive,positive,positive
737176761,"> @stepkillah Are you able to navigate through all of that? I know it might looks like it is a lot, but at the end of the day, it's really simple once you get through it :). Don't hesitate.

@lissyx sorry for the delay, a bit of lack of time in that period, so can take a bit longer than I expected
Yeah, I checked your links and at least have a vision of what to do based on examples, so will try to play with it during the week/weekend. I also can try to run CI myself, so that should help a lot",able navigate know might like lot end day really simple get hesitate sorry delay bit lack time period take bit longer yeah checked link least vision based try play also try run help lot,issue,negative,negative,neutral,neutral,negative,negative
737090004,"Ok, thanks. I  will use Discourse for further disscussion.

Started thread on Discourse: https://discourse.mozilla.org/t/how-can-i-use-intel-tensorflow-for-inference-of-deepspeech/71491",thanks use discourse thread discourse,issue,negative,positive,positive,positive,positive,positive
737085074,"@stepkillah Are you able to navigate through all of that? I know it might looks like it is a lot, but at the end of the day, it's really simple once you get through it :). Don't hesitate.",able navigate know might like lot end day really simple get hesitate,issue,negative,positive,positive,positive,positive,positive
736753349,"> @olafthiele Maybe you can advice me where should I start looking in code of DeepSpeech to do modification so I can use intel-tensorflow ?

Maybe you can start by explaining what kind of inference usage you have, `libdeepspeech.so` ?
Maybe you can start by documenting ""rather slow""? How much? What CPU? What use-case? What are your expectations?

And do all of that on Discourse, as requested ?",maybe advice start looking code modification use maybe start explaining kind inference usage maybe start rather slow much discourse,issue,positive,positive,positive,positive,positive,positive
736725090,"Please start reading what we write, continue on Discourse ...",please start reading write continue discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
736710291,@olafthiele Maybe you can advice me where should I start looking in code of DeepSpeech to do modification so I can use intel-tensorflow ?,maybe advice start looking code modification use,issue,negative,neutral,neutral,neutral,neutral,neutral
736298532,"As you read in the first line of opening an issue, this is support and should live at [Discourse](https://discourse.mozilla.org/c/mozilla-voice-stt/247). Please close the issue here. Short answer: You can't and even if you could it would be way too slow. Use colab for smaller projects.",read first line opening issue support live discourse please close issue short answer ca even could would way slow use smaller,issue,positive,positive,neutral,neutral,positive,positive
735663110,"@stepkillah Thanks. You might also find more details on TaskCluster usage in https://github.com/mozilla/DeepSpeech/issues/3317. I've invited you to the repo, so you should be able to push to your PR and run TaskCluster alone.",thanks might also find usage able push run alone,issue,negative,positive,positive,positive,positive,positive
735594657,"Please read the first line in posting an issue, support and questions on Discourse.[ Check this post ](https://discourse.mozilla.org/t/problem-with-fine-tuning-0-81-checkpoint-for-specific-domain-like-biology/71071/18)for an idea of what works.

Please close the issue here and open a new post on Discourse if you need more information.",please read first line posting issue support discourse check post idea work please close issue open new post discourse need information,issue,positive,positive,positive,positive,positive,positive
735382989,"also @stepkillah :
 - keep existing nuget build for test coverage of arch-specific without waiting on all deps
 - we will want to add test coverage for this new multiarch nuget on all platforms we want to support
 - see https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/test-nodejs_13x_16k_multiarchpkg-linux-amd64-opt.yml and specifically the ""node-package-cpu"" dep https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/test-nodejs_13x_16k_multiarchpkg-linux-amd64-opt.yml#L5",also keep build test coverage without waiting want add test coverage new want support see specifically,issue,negative,positive,positive,positive,positive,positive
735382058,"> yeah, that's why I'm hoping it can be done in a way that will use artifacts from different steps/stages for different targets, but didn't found out if it's doable yet

from the description, it really looks like we want to do the same as we already do for npm package, as described above",yeah done way use different different found doable yet description really like want already package,issue,positive,positive,neutral,neutral,positive,positive
735381929,"> `dll` files can be built on any arch, net core has cross-compilation by default.

Perfect, so I would suggest:
 - cross compile all arch we want to support
 - add a new template like https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package-opt-base.tyml
 - add new tasks like https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package-cpu.yml and https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package-tflite.yml
 - we do the nodejs repackage in https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-build.sh
 - we do the final multiarch package in https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/node-package.sh

implems are in:
 - https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-build-utils.sh#L151-L180
 - fetching the deps: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-node-utils.sh#L5-L25",built arch net core default perfect would suggest cross compile arch want support add new template like add new like repackage final package fetching,issue,positive,positive,positive,positive,positive,positive
735381669,"> > `net core` client can be built on linux/macos/windows and contain all needed architecture, it only requires net core SDK
> 
> You are missing the point here: if it cannot be cross compiled from Windows, it means we need to setup everything also on macos and Linux builds, and it's a lot of extra work.

yeah, that's why I'm hoping it can be done in a way that will use artifacts from different steps/stages for different targets, but didn't found out if it's doable yet",net core client built contain architecture net core missing point cross need setup everything also lot extra work yeah done way use different different found doable yet,issue,negative,negative,neutral,neutral,negative,negative
735381273,"> > > I know nothing of nuget so I'm unsure hence my question
> > 
> > 
> > it's just like a zip archive, with a specific folder structure.
> 
> But there is still `DeepSpeechClient.dll` no ?

`dll` files can be built on any arch, net core has cross-compilation by default.
we already adding `dll` files to nuget in this PR, so only thing is missing is that

> move the do_nuget_build into a specific task that depends on all the other's. But you will want also to keep it in existing tasks",know nothing unsure hence question like zip archive specific folder structure still built arch net core default already thing missing move specific task want also keep,issue,negative,negative,neutral,neutral,negative,negative
735379954,"> As far as we already have all these `.so` files built, I don't think we need to build them separately for nuget

If you only depend on `libdeepspeech.so` the  yes, you need to move the `do_nuget_build` into a specific task that depends on all the other's. But you will want also to keep it in existing tasks, otherwise it makes a long dependency to run tests and it's painful.",far already built think need build separately depend yes need move specific task want also keep otherwise long dependency run painful,issue,negative,negative,negative,negative,negative,negative
735379389,"> > I know nothing of nuget so I'm unsure hence my question
> 
> it's just like a zip archive, with a specific folder structure.

But there is still `DeepSpeechClient.dll` no ? ",know nothing unsure hence question like zip archive specific folder structure still,issue,positive,neutral,neutral,neutral,neutral,neutral
735379294,"> `net core` client can be built on linux/macos/windows and contain all needed architecture, it only requires net core SDK

You are missing the point here: if it cannot be cross compiled from Windows, it means we need to setup everything also on macos and Linux builds, and it's a lot of extra work. ",net core client built contain architecture net core missing point cross need setup everything also lot extra work,issue,negative,negative,neutral,neutral,negative,negative
735376074,"![image](https://user-images.githubusercontent.com/10140906/100540037-59757680-3243-11eb-85c9-6b290494da93.png)

Need to access these files (screenshot from release (not archive, but `so` file from archives)) during taskcluster build, and put them in the corresponding nuget folder. 
As far as we already have all these `.so` files built, I don't think we need to build them separately for nuget",image need access release archive file build put corresponding folder far already built think need build separately,issue,negative,positive,neutral,neutral,positive,positive
735375581,"> > I was checking build for NodeJS but didn't get how to build arch-specific build tasks and how then package them, I'm might miss where to look, so if you can point to specific places with links - that might be helpful
> 
> Basically each platform build its own nodejs for this arch only and we have a nodejs repackage task that depends on all arch specific tasks to pull the packages and merge all into one. I cant give links at the moment im not on my laptop.

hm, it sounds like we do not need to build `. net core` client in different architectures, but we need to build or get already built `libdeepspeech.so` files for different archs and put them in specific folder.",build get build build package might miss look point specific link might helpful basically platform build arch repackage task arch specific pull merge one cant give link moment like need build net core client different need build get already built different put specific folder,issue,positive,neutral,neutral,neutral,neutral,neutral
735374891,"> I know nothing of nuget so I'm unsure hence my question

it's just like a zip archive, with a specific folder structure.

",know nothing unsure hence question like zip archive specific folder structure,issue,positive,neutral,neutral,neutral,neutral,neutral
735374768,"> > how to build arch-specific build tasks
> 
> Can we cross compile from win/amd64 to address all the linux variants ?

`net core` client can be built on linux/macos/windows and contain all needed architecture, it only requires net core SDK",build build cross compile address net core client built contain architecture net core,issue,negative,neutral,neutral,neutral,neutral,neutral
735374743,"> > I was checking build for NodeJS but didn't get how to build arch-specific build tasks and how then package them, I'm might miss where to look, so if you can point to specific places with links - that might be helpful
> 
> Basically each platform build its own nodejs for this arch only and we have a nodejs repackage task that depends on all arch specific tasks to pull the packages and merge all into one. I cant give links at the moment im not on my laptop.

So if we can cross compile from Windows its much easier than if we need to setup new build tasks on linux ",build get build build package might miss look point specific link might helpful basically platform build arch repackage task arch specific pull merge one cant give link moment cross compile much easier need setup new build,issue,positive,positive,neutral,neutral,positive,positive
735374605,">  I was checking build for NodeJS but didn't get how to build arch-specific build tasks and how then package them, I'm might miss where to look, so if you can point to specific places with links - that might be helpful

Basically each platform build its own nodejs for this arch only and we have a nodejs repackage task that depends on all arch specific tasks to pull the packages and merge all into one. I cant give links at the moment im not on my laptop.",build get build build package might miss look point specific link might helpful basically platform build arch repackage task arch specific pull merge one cant give link moment,issue,negative,neutral,neutral,neutral,neutral,neutral
735373281,"> Do we need to move [this step](https://github.com/stepkillah/DeepSpeech/blob/master/taskcluster/win-build.sh#L58) to some new packaging task? or we can add some additional steps before `do_nuget_build`

I know nothing of nuget so I'm unsure hence my question 

> (I'm not familiar with taskcluster and definitely not a bash expert)

That's fine, there's not a lot of people hacking this, so we welcome newcomers 

> I'm also not quite sure - should I create a new `yml` task with some dependencies (like below), or it's done through the script itself (`sh`).

One task = one `.yml`, and dependency name is the filename without extension, pretty basic. ",need move step new task add additional know nothing unsure hence question familiar definitely bash expert fine lot people hacking welcome also quite sure create new task like done script sh one task one dependency name without extension pretty basic,issue,positive,positive,positive,positive,positive,positive
735372924,"> how to build arch-specific build tasks

Can we cross compile from win/amd64 to address all the linux variants ? ",build build cross compile address,issue,negative,neutral,neutral,neutral,neutral,neutral
735372244,"@lissyx I was checking build for NodeJS but didn't get how to build arch-specific build tasks and how then package them, I'm might miss where to look, so if you can point to specific places with links - that might be helpful. (I'm not familiar with taskcluster and definitely not a bash expert)
I'm also not quite sure - should I create a new `yml` task with some dependencies (like below), or it's done through the script itself (`sh`).

```
  dependencies:
    - ""darwin-amd64-cpu-opt""
    - ""linux-amd64-cpu-opt""
    - ""linux-rpi3-cpu-opt""
    - ""linux-arm64-cpu-opt""
    - ""win-amd64-cpu-opt""
```

Do we need to move [this step](https://github.com/stepkillah/DeepSpeech/blob/master/taskcluster/win-build.sh#L58)  to some new packaging task?  or we can add some additional steps before `do_nuget_build`

so - if someone who knows bash and familiar with taskcluster can assist to complete this PR (`Allow edits by maintainers
` is allowed) - that will speed up merging this PR and therefore - allow to use it with C# cross-platform without any additional work",build get build build package might miss look point specific link might helpful familiar definitely bash expert also quite sure create new task like done script sh need move step new task add additional someone bash familiar assist complete allow speed therefore allow use without additional work,issue,positive,positive,positive,positive,positive,positive
734449614,"> Looks like I don't have permissions to re-trigger that one failing windows test, but it doesn't look related

Yeah dont worry about this one, it's past deadline Anyway and it's just an intermittent ",like one failing test look related yeah dont worry one past deadline anyway intermittent,issue,negative,negative,negative,negative,negative,negative
734419782,"Looks like I don't have permissions to re-trigger that one failing windows test, but it doesn't look related",like one failing test look related,issue,negative,neutral,neutral,neutral,neutral,neutral
734417310,@lissyx ok I can repro locally. It's my bug -- my bad. Lemme finish.,locally bug bad finish,issue,negative,negative,negative,negative,negative,negative
734386802,"Right right. OK, I was under the mistaken impression that those were sporadic. Let me have a quick look and also figure out how to re-run tests...",right right mistaken impression sporadic let quick look also figure,issue,negative,positive,positive,positive,positive,positive
734191359,I don't think so. Not suitable for a point release in its current state. Would like to get more testing on it. I'll take a closer look at the PR as well this week.,think suitable point release current state would like get testing take closer look well week,issue,positive,positive,positive,positive,positive,positive
734162437,"> @reuben I think this passes all the TC tests that were broken before now.

It does not, you still have failure on the ""transcribe Py"" for all python versions",think broken still failure transcribe python,issue,negative,negative,negative,negative,negative,negative
734161542,"@CatalinVoss Looks good, there were two things I'm unsure about, please let us know if you need further changes or if that is good to go.

Also @reuben can correct me but I think we would like to have that on r0.9 as well ?",good two unsure please let u know need good go also correct think would like well,issue,positive,positive,positive,positive,positive,positive
734159129,"> Yeah those didn't look related to me. OK

They were not, but they were blocking executing a lot of the tests :)",yeah look related blocking lot,issue,negative,neutral,neutral,neutral,neutral,neutral
734007027,"@reuben I think this passes all the TC tests that were broken before now. The changes are slightly more invasive, but I think this still makes sense (at least for my training setup). If the whole `PackedSample` stuff feels like too much, I'm also happy to keep this in a fork of course.",think broken slightly invasive think still sense least training setup whole stuff like much also happy keep fork course,issue,negative,positive,neutral,neutral,positive,positive
733959403,"> I think we're good on TC?

There were à few failures but its all green after rerun. I'll gave à look tomorrow, hopefully. Thanks !",think good green rerun gave look tomorrow hopefully thanks,issue,positive,positive,positive,positive,positive,positive
733691625,"> @stepkillah What's your status on that, can you continue hacking on it?

I will take a look into NodeJS as an example during this week and will try to adjust that for this PR",status continue hacking take look example week try adjust,issue,negative,neutral,neutral,neutral,neutral,neutral
733673509,"[Check the docs and source code a bit more](https://deepspeech.readthedocs.io/en/v0.9.1/NodeJS-Examples.html) and you'll find some examples. As this is usage related, ask further questions on Discourse as described in the first line of opening an issue.",check source code bit find usage related ask discourse first line opening issue,issue,negative,positive,positive,positive,positive,positive
732916818,"> I tried my best to update the Taskcluster command, but don't want to overpromise.

Please @CatalinVoss, feel free to push as much as you need to complete taskcluster green, do not worry about abusing the resources: current usage is quite low, and we have implemented back in august optimizations that ensures high usages do not results in too high costs. Current figures shows this has been successfull, and your PR is more than welcome, so push as much as you need.",tried best update command want overpromise please feel free push much need complete green worry current usage quite low back august high high current welcome push much need,issue,positive,positive,positive,positive,positive,positive
732150263,"This error is also used for a missing scorer file during normal inference, so changing the error message here would make the `generate_scorer_package` message clearer but the inference one confusing. So I guess catching and rewriting in `generate_scorer_package` is better.",error also used missing scorer file normal inference error message would make message clearer inference one guess catching better,issue,negative,positive,positive,positive,positive,positive
731806777,"> I made it work yesterday as a static framework with cocoa pods, though integrated into another code base for a fairly specific application. TestFlight went through. I think I can turn it into a PR for you this week. Send some good karma.

@CatalinVoss That would be awesome! I can't wait to see where I went wrong in my earlier attempts. Thanks!",made work yesterday static framework cocoa though another code base fairly specific application went think turn week send good karma would awesome ca wait see went wrong thanks,issue,positive,positive,positive,positive,positive,positive
731806191,"I made it work yesterday as a static framework with cocoa pods, though integrated into another code base for a fairly specific application. TestFlight went through. I think I can turn it into a PR for you this week. Send some good karma.",made work yesterday static framework cocoa though another code base fairly specific application went think turn week send good karma,issue,negative,positive,neutral,neutral,positive,positive
731804650,@reuben  Can I pay to open a bug bounty for this? I’d love to ship the feature built on DeepSpeech that has been shelved for months now.,pay open bug bounty love ship feature built,issue,positive,positive,positive,positive,positive,positive
731363834,"@lissyx : Thank you for the pointer. I created a new environment (pip), and the issue is resolved. Closing the ticket.",thank pointer new environment pip issue resolved ticket,issue,negative,positive,positive,positive,positive,positive
731357200,"@DanBmh @opensorceror I have been able to play with a small project of mine with GitLab CI, and I have to admit after scratching the surface, it seems to be nice. I'm pretty sure we can replicate the same things, but obviously it requires rework of the CI handling.

However, I doubt this can work well on a ""free tier plan"", so I think if there's a move in that direction it will require some investments, including to have support for Windows and macOS. We have been able to get access to our current TaskCluster cost usages, and thanks to the latest optimization we landed back in august, we could run the same workload as previously for a fairly small amount of money.

I guess it's mostly a question of people stepping up and doing, at some point :)",able play small project mine admit scratching surface nice pretty sure replicate obviously rework handling however doubt work well free tier plan think move direction require support able get access current cost thanks latest optimization landed back august could run previously fairly small amount money guess mostly question people stepping point,issue,positive,positive,positive,positive,positive,positive
731300122,"> miniconda3

please avoid conda



> 2020-11-20 17:32:51.662478: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1296] Check failed: op->start_indices.size() == dim_count : Incorrect number of start indices supplied to StridedSlice op with output ""cudnn_lstm/rnn/multi_rnn_cell/strided_slice"". Op requires 3 start indices

not something we repro",please avoid check incorrect number start index output start index something,issue,negative,neutral,neutral,neutral,neutral,neutral
731204163,"> Hmm okay then, I thought this was an easy problem, closing.

We still don't know what dependency(ies) is(are) problematic.
At some point, if you need it, you should do it.",thought easy problem still know dependency problematic point need,issue,negative,positive,positive,positive,positive,positive
731176363,"> I don't think it's required to support training on windows. But transcribe.py is obviously not related to training. It just happens to use functions from deepspeech_training. (Mostly from the util submodule).

No, but basically, supporting `transcribe.py` under Windows is more or less the same work as supporting training.



> Maybe what's needed is to add those functions to pypl's deepspeech, or extract them to a new separate module. Maybe stuff like deepspeech_training.train.create_model already has equivalents in the deepspeech?

No, seriously. The whole purpose of `transcribe.py` is for when you need to do lot of batching, GPU supported.

Please, I've given several hints earlier, but if you keep us in the vague ""some code requires compilation"", we definitively can't help you.",think support training obviously related training use mostly basically supporting le work supporting training maybe add extract new separate module maybe stuff like already seriously whole purpose need lot please given several keep u vague code compilation definitively ca help,issue,positive,positive,positive,positive,positive,positive
731175744,You're missing the delayed imports. `transcribe.py` leverages the training code heavily.,missing training code heavily,issue,negative,negative,negative,negative,negative,negative
731169959,"I don't think it's required to support training on windows. But
transcribe.py is obviously not related to training. It just happens to use
functions from deepspeech_training. (Mostly from the util submodule).
Maybe what's needed is to add those functions to pypl's deepspeech, or
extract them to a new separate module.
Maybe stuff like deepspeech_training.train.create_model already has
equivalents in the deepspeech?
",think support training obviously related training use mostly maybe add extract new separate module maybe stuff like already,issue,positive,positive,positive,positive,positive,positive
731159015,"> The complexity arises because `pip install .` compiles the c/cpp (I don't remember) code. While this is mostly easy in ubuntu, it isn't on windows. Usually windows users who install python packages that contain native code depend on python wheels. This could be a solution. Alternatively, a pyinstaller bundle of transcribe.py with all its dependencies could also work. Sorry for being that unclear see_no_evil before..
> […](#)

We don't support training on Windows, so that's not unsurprising. If you care about, please send PR and step up to maintain.

Our packages, including `ds-ctcdecoder` DOES have Python wheels on Windows. TensorFlow as well. If it's some other third-party dep that requires compilation step, I'm sorry, but it is out of our hands.",complexity pip install remember code mostly easy usually install python contain native code depend python could solution alternatively bundle could also work sorry unclear support training unsurprising care please send step maintain python well compilation step sorry,issue,positive,negative,negative,negative,negative,negative
731157936,"The complexity arises because `pip install .` compiles the c/cpp (I don't
remember) code.
While this is mostly easy in ubuntu, it isn't on windows.
Usually windows users who install python packages that contain native code
depend on python wheels.
This could be a solution.
Alternatively, a pyinstaller bundle of transcribe.py with all its
dependencies could also work.
Sorry for being that unclear 🙈 before..

>
",complexity pip install remember code mostly easy usually install python contain native code depend python could solution alternatively bundle could also work sorry unclear,issue,negative,negative,negative,negative,negative,negative
731154250,"@NoamDev that's basically it. so, again, please elaborate on where is the complexity: if you can't, I'm afraid we won't be able to help because we just don't know what to fix ...",basically please elaborate complexity ca afraid wo able help know fix,issue,positive,positive,positive,positive,positive,positive
731153951,"```
$ docker run --rm -it ""ubuntu:18.04""
root@docker # apt update && apt install git python3-pip
root@docker # cd /opt && git clone https://github.com/mozilla/DeepSpeech/ && cd DeepSpeech && git checkout v0.9.1
root@docker # pip3 install --upgrade pip==20.2.2 wheel==0.34.2 setuptools==49.6.0
root@docker # pip3 install --upgrade -e .
root@docker # python3 transcribe.py
```",docker run root docker apt update apt install git root docker git clone git root docker pip install upgrade root docker pip install upgrade root docker python,issue,negative,positive,positive,positive,positive,positive
731149381,"

>  This installation process is not easy.

That's your opinion. Please explain where is the complexity, otherwise your issue is unactionable.

> transcribe.py mainly uses stuff from deepspeech_training and ds_ctcdecoder.

`deepspeech_training` is installing deepspeech deps and that's it. It just requires `pip install --upgrade .`, including `ds_ctcdecoder` which is also published on pypi: https://pypi.org/simple/ds-ctcdecoder/

So for now, this request is still unclear.",installation process easy opinion please explain complexity otherwise issue mainly stuff pip install upgrade also request still unclear,issue,negative,positive,positive,positive,positive,positive
731148470,"transcribe.py mainly uses stuff from deepspeech_training and ds_ctcdecoder.
The only way to use this libraries is two install deepspeech **from source** as described [here](https://deepspeech.readthedocs.io/en/v0.9.1/TRAINING.html).
This installation process is not easy.",mainly stuff way use two install source installation process easy,issue,negative,positive,positive,positive,positive,positive
731144267,"> No, installing tensorflow isn't that much of a hassle.
> However, transcribe.py require you to build deepspeech from source, as it depends on parts of the library that cannot be found in the pypl's deepspeech-gpu.

@NoamDev I'm not sure what you are referring to, there is no `from deepspeech import xxx` in `transcribe.py`. Please be more explicit.",much hassle however require build source library found sure import please explicit,issue,positive,positive,positive,positive,positive,positive
731133809,"No, installing tensorflow isn't that much of a hassle.
However, transcribe.py require you to build deepspeech from source, as it depends on parts of the library that cannot be found in the pypl's deepspeech-gpu.",much hassle however require build source library found,issue,negative,positive,positive,positive,positive,positive
731084625,"> Some people would like to transcribe a long sound file and use the batching capabilities of transcribe.py.
> However, those people don't have the tools to install deepspeech from source.

@NoamDev `transcribe.py` directly depends on TensorFlow. Please elaborate on ""those people don't have the tools to install deepspeech from source"", because if those people can't install TensorFlow, there's not much we can do.",people would like transcribe long sound file use however people install source directly please elaborate people install source people ca install much,issue,positive,positive,positive,positive,positive,positive
731030800,"@NoamDev if I understand you correctly, you think of extending the native client to not just taking a single wav file as an argument but a whole directory of files that is transcribed one after the other?

If you have the time, we are happy for a PR. In the meantime, why not write a script that uses the native client to do that and post it on [Discourse ](https://discourse.mozilla.org/c/mozilla-voice-stt/247)for others to find?",understand correctly think extending native client taking single file argument whole directory one time happy write script native client post discourse find,issue,negative,positive,positive,positive,positive,positive
730533719,"I've reverted the changes on master and pushed a new branch with all of your remote IO commits cherry picked onto it: https://github.com/mozilla/DeepSpeech/commits/reapply-remote-io

You should be able to start a PR from that branch and iterate on it to get tests green!",master new branch remote io cherry picked onto able start branch iterate get green,issue,negative,positive,neutral,neutral,positive,positive
730479336,Thanks to both of you! Ping me if you need me to do more cleanup here somewhere.,thanks ping need cleanup somewhere,issue,negative,positive,positive,positive,positive,positive
730391638,"> What do you think @lissyx?

The issue is very vague, I don't understand what is the need here ...",think issue vague understand need,issue,negative,negative,negative,negative,negative,negative
730300802,After the PRs are done I'll back out the previously landed changes so the entire remote IO functionality can be merged as a single working PR.,done back previously landed entire remote io functionality single working,issue,negative,negative,neutral,neutral,negative,negative
730292310,"I'm fixing in #3429 but on a tentative PR, it shows there are many regressions on training / inference for python since this has landed",fixing tentative many training inference python since landed,issue,negative,positive,positive,positive,positive,positive
730230351,"> They're all supposed to pass but there's something weird going on. I'll take a look.

It looks like TaskCluster changed something about how it deals with some artifacts uploads and we get gz-compressed when we should not",supposed pas something weird going take look like something get,issue,negative,negative,negative,negative,negative,negative
729896287,They're all supposed to pass but there's something weird going on. I'll take a look.,supposed pas something weird going take look,issue,negative,negative,negative,negative,negative,negative
729884017,"@reuben I'm a tad confused by the TaskCluster checks. Is there a general rule about which tests are supposed to pass/fail. A lot of the failures look unrelated and there may be some caching going on as well? The ones that look related are from this one extended training test: https://community-tc.services.mozilla.com/api/queue/v1/task/TdIY1v-XQZig0iRLGjT_OQ but when I try to reproduce that locally, all works fine now and I don't see the error:

```
python -u bin/import_ldc93s1.py ./data/smoke_test

python -u bin/data_set_tool.py ./data/smoke_test/ldc93s1.csv ./data/smoke_test/ldc93s1.sdb

python -u DeepSpeech.py --noshow_progressbar --noearly_stop --train_files ./data/smoke_test/ldc93s1.sdb --train_batch_size 1 --dev_files ./data/smoke_test/ldc93s1.sdb --dev_batch_size 1 --test_files ./data/smoke_test/ldc93s1.sdb --test_batch_size 1 --n_hidden 100 --epochs 220 --max_to_keep 1 --checkpoint_dir /tmp/ckpt_sdb --learning_rate 0.001 --dropout_rate 0.05 --export_dir /tmp/train_sdb --scorer_path data/smoke_test/pruned_lm.scorer --audio_sample_rate 8000

python -u DeepSpeech.py --noshow_progressbar --noearly_stop --train_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --train_batch_size 1 --feature_cache /tmp/ldc93s1_cache_sdb_csv --dev_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --dev_batch_size 1 --test_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --test_batch_size 1 --n_hidden 100 --epochs 109 --max_to_keep 1 --checkpoint_dir /tmp/ckpt_sdb_csv --learning_rate 0.001 --dropout_rate 0.05 --export_dir /tmp/train_sdb_csv --scorer_path data/smoke_test/pruned_lm.scorer --audio_sample_rate 8000
```

Just want to make sure I leave things intact here!",tad confused general rule supposed lot look unrelated may going well look related one extended training test try reproduce locally work fine see error python python python python want make sure leave intact,issue,negative,positive,neutral,neutral,positive,positive
729518613,"First, follow the rules and post support request to Discourse. Second, read the error reported by KenLM.",first follow post support request discourse second read error,issue,negative,positive,positive,positive,positive,positive
729260356,"If you are worried about people running into this, I could add stubbed methods for `change_audio_type()` and the `audio_type` field to `PackedSample` that print an error message like ""Did you mean to unpack the sample?"" but that may be overkill.",worried people running could add stubbed field print error message like mean unpack sample may,issue,negative,negative,negative,negative,negative,negative
729259929,"@reuben Sorry for this little mess! I went through the failures on TaskCluster. I don't think all of them are related to my PR (a few sporadic things running out of space and the odd android failure), but caught a couple more things. Most of all, I updated the few places where `PackedSample` was now unintentionally used as a `Sample`",sorry little mess went think related sporadic running space odd android failure caught couple unintentionally used sample,issue,negative,negative,negative,negative,negative,negative
729085962,"> For evaluating model performance I'd strongly encourage you to use `evaluate.py` rather than the clients, as it's optimized for throughput rather than latency. It takes the same arguments as `DeepSpeech.py` but only does evaluation, so it'll only look at `test_files`, `test_batch_size`, etc. You'll need to point it at a checkpoint (with `--checkpoint_dir`) rather than at a frozen model.

It is also possible to load a frozen graph like this (posting it just in case someone else needs it). Model_path was added to the FLAGS.
```Python
if FLAGS.model_path:
    with tfv1.gfile.FastGFile(FLAGS.model_path, 'rb') as fin:
        graph_def = tfv1.GraphDef()
        graph_def.ParseFromString(fin.read())

    var_names = [v.name for v in tfv1.trainable_variables()]
    var_tensors = tfv1.import_graph_def(graph_def, return_elements=var_names)

    # build a { var_name: var_tensor } dict
    var_tensors = dict(zip(var_names, var_tensors))

    training_graph = tfv1.get_default_graph()

    assign_ops = []
    for name, restored_tensor in var_tensors.items():
        training_tensor = training_graph.get_tensor_by_name(name)
        assign_ops.append(tfv1.assign(training_tensor, restored_tensor))

    init_from_frozen_model_op = tfv1.group(*assign_ops)
    session.run(init_from_frozen_model_op)
else:
    load_graph_for_evaluation(session)
```
",model performance strongly encourage use rather throughput rather latency evaluation look need point rather frozen model also possible load frozen graph like posting case someone else need added python fin build zip name name else session,issue,positive,positive,positive,positive,positive,positive
729037172,"> @lissyx How can we retrieve all OS-Arch dependent (win-x64, linux-x64, linux-arm64, win-arm64, ...) artifacts (libdeepspeech.so) from the script? Is there a artifact repository that we can fetch to get those ?

You can have a look at how it is done for NodeJS already:
 - make an arch-specific build task
 - make a generic packaging task that depends on all those and fetches the artifacts",retrieve dependent script artifact repository fetch get look done already make build task make generic task,issue,negative,neutral,neutral,neutral,neutral,neutral
729029163,"Sounds like a good idea. Unfortunately, the team probably doesn't have the resources to make the necessary changes. If you got the time, we would be very grateful for a PR. What do you think @lissyx?",like good idea unfortunately team probably make necessary got time would grateful think,issue,positive,positive,neutral,neutral,positive,positive
729017829,"@lissyx How can we retrieve all OS-Arch dependent (win-x64, linux-x64, linux-arm64, win-arm64, ...) artifacts (libdeepspeech.so) from the script? Is there a artifact repository that we can fetch to get those ?
",retrieve dependent script artifact repository fetch get,issue,negative,neutral,neutral,neutral,neutral,neutral
728904482,"Were there important changes to the augmentations in between? I didn't check for it.

I didn't run further tests, just the ones above. For my own trainings I still use the old version.",important check run still use old version,issue,negative,positive,positive,positive,positive,positive
728155981,"Further testing looks fine, so just need to address the comments above before merging.",testing fine need address,issue,negative,positive,positive,positive,positive,positive
728109724,"> I haven't bothered updating `CSVWriter` or `TarWriter` since I didn't see them used anywhere and figured they're part of the dataset creation process, which you'd probably run locally.

Sounds reasonable. FYI I'm starting to review this PR now.",since see used anywhere figured part creation process probably run locally reasonable starting review,issue,negative,positive,neutral,neutral,positive,positive
727944305,"> Please continue on Discourse, this is not the place to discuss the training on accents.

Moreover, read the release notes they documents the training corpus.",please continue discourse place discus training moreover read release training corpus,issue,negative,neutral,neutral,neutral,neutral,neutral
727931165,"Please continue on Discourse, this is not the place to discuss the training on accents.",please continue discourse place discus training,issue,negative,neutral,neutral,neutral,neutral,neutral
727930240,"> You need to train it for indian accent....

I assume the out of the box model is trained with the below distributions based on the data published at https://commonvoice.mozilla.org/en/datasets . A total of 61,528 people have voiced.  5% of the population is with Indian accent (which is roughly 3076 people). 

When you say the model has to be trained, roughly how many people voice are you expecting more to be given to the model ?

**Accent**
23% - United States English
8% - England English
5% - India and South Asia (India, Pakistan, Sri Lanka)
4% - Australian English
3% - Canadian English
2% - Scottish English
1% - Irish English
1% - Southern African (South Africa, Zimbabwe, Namibia)
1% - New Zealand English",need train accent assume box model trained based data total people voiced population accent roughly people say model trained roughly many people voice given model accent united south sri southern south zimbabwe new,issue,negative,positive,positive,positive,positive,positive
727889276,"I could get subtitles for an audio file with speaker with indian accent https://www.youtube.com/watch?v=BZ7v0wVrKDo - 
[english (copy).txt](https://github.com/mozilla/DeepSpeech/files/5545623/english.copy.txt)

It will work - better if you fine tune it...


",could get audio file speaker accent copy work better fine tune,issue,positive,positive,positive,positive,positive,positive
727887521,"Model is trained on american english as documented, other accents might give less good results. Please read and act on issue template and reach for support on Discourse, this is not a bug. ",model trained might give le good please read act issue template reach support discourse bug,issue,positive,positive,positive,positive,positive,positive
727887086,"Please follow the advice in the first line of opening a new issue, post questions like that on [Discourse](https://discourse.mozilla.org/c/mozilla-voice-stt/247).",please follow advice first line opening new issue post like discourse,issue,positive,positive,positive,positive,positive,positive
727139341,"@olafthiele Yeah, I mean it's always preferred to have files sitting next to the GPU on an SSD, but sometimes that's hard to spin up quickly, as you say. It's certainly pretty common to do this sort of thing, I think, especially if you have a lot of data coming into a bucket somewhere. Tensorflow and GCP do this for a lot of their training samples on ImageNet. It should perform OK as long as you have sufficient parallel readers.

Here, the file reading actually wasn't parallelized. I now did that by [wrapping `Sample`](https://github.com/mozilla/DeepSpeech/pull/3420/commits/be39d3354dc71499b5fa461c8ce2983779b9f262) with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance a lot.

It made this PR a little bit bigger than what I was going for. If you intend to accept, it may be good to test the reader/writer classes affected. I've mainly worried about training and made sure that that all works. Everything should be compatible still with local file-reading and default to the standard builtin functions.

I haven't bothered updating `CSVWriter` or `TarWriter` since I didn't see them used anywhere and figured they're part of the dataset creation process, which you'd probably run locally.",yeah mean always preferred sitting next sometimes hard spin quickly say certainly pretty common sort thing think especially lot data coming bucket somewhere lot training perform long sufficient parallel file reading actually wrapping sample little class worker process rather parent process performance lot made little bit bigger going intend accept may good test class affected mainly worried training made sure work everything compatible still local default standard since see used anywhere figured part creation process probably run locally,issue,positive,positive,neutral,neutral,positive,positive
726690066,"@lissyx Please close, discussion moved to [Discourse](https://discourse.mozilla.org/t/two-fatal-issues-encountered-while-testing-self-trained-model/70489/).",please close discussion discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
726636695,"No worries, this is a legitimate problem, just post it on Discourse, there are some other Chinese users as well.",legitimate problem post discourse well,issue,negative,neutral,neutral,neutral,neutral,neutral
726632996,"> Please read the first line when opening a new issue:
> 
> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).

Hi. Sorry if this post causes any inconvenience. I thought my issues were bugs or something. Thanks anyway. I will post again on your Discourse. ",please read first line opening new issue support please use discourse hi sorry post inconvenience thought something thanks anyway post discourse,issue,positive,positive,neutral,neutral,positive,positive
726623107,My 2 cents: The limiting factor for us is GPU costs. Even a regular hard drive is really slow in comparison to an SSD drive. So loading individual files over the network seems like a bad idea in itself for a large corpus as you can't feed enough data to the GPU. But this is just us and it might be great for testing or first steps as it is quite tedious to fire up a new VM and copy all data there first.,limiting factor u even regular hard drive really slow comparison drive loading individual network like bad idea large corpus ca feed enough data u might great testing first quite tedious fire new copy data first,issue,negative,negative,neutral,neutral,negative,negative
726614811,"Please read the first line when opening a new issue:

For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).",please read first line opening new issue support please use discourse,issue,positive,positive,positive,positive,positive,positive
726582106,"**More supported info produced using the origin client.py of deepspeech**:

**Issue One**:
```
root@cd69049a871f:/DeepSpeech/asr_test_server# deepspeech --model new_lm_19_train/output_graph.pb --scorer new_lm_19_train/kenlm.scorer --audio empty_audio.wav 
2020-11-13 07:30:41.801501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
Loading model from file new_lm_19_train/output_graph.pb
TensorFlow: v1.15.0-29-g4e0e823493
DeepSpeech: v0.7.4-0-gfcd9563f
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2020-11-13 07:30:41.912246: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-11-13 07:30:41.913273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-13 07:30:41.945059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:41.945704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.605
pciBusID: 0000:26:00.0
2020-11-13 07:30:41.945718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-11-13 07:30:41.946654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-11-13 07:30:41.947472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-11-13 07:30:41.947661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-11-13 07:30:41.948748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-11-13 07:30:41.949540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-11-13 07:30:41.952087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-13 07:30:41.952187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:41.952822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:41.953342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-11-13 07:30:42.342786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 07:30:42.342813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-11-13 07:30:42.342818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-11-13 07:30:42.342932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:42.343459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:42.343972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:30:42.344458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9767 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)
Loaded model in 0.591s.
Loading scorer from files new_lm_19_train/kenlm.scorer
Loaded scorer in 0.000225s.
Running inference.
2020-11-13 07:30:43.248752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Segmentation fault (core dumped)
root@cd69049a871f:/DeepSpeech/asr_test_server#
```

**Issue Two**:
**Success Case**:
```
root@cd69049a871f:/DeepSpeech/asr_test_server# deepspeech --model new_lm_19_train/output_graph.pb --scorer new_lm_19_train/kenlm.scorer --audio audio_collect_zh-HK_19be47fa770a4a12826735b395f7e8ad.wav 
2020-11-13 07:38:53.148996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
Loading model from file new_lm_19_train/output_graph.pb
TensorFlow: v1.15.0-29-g4e0e823493
DeepSpeech: v0.7.4-0-gfcd9563f
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2020-11-13 07:38:53.261789: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-11-13 07:38:53.262647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-13 07:38:53.291063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.291840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.605
pciBusID: 0000:26:00.0
2020-11-13 07:38:53.291854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-11-13 07:38:53.292750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-11-13 07:38:53.293539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-11-13 07:38:53.293701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-11-13 07:38:53.294676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-11-13 07:38:53.295394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-11-13 07:38:53.297740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-13 07:38:53.297831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.298394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.298898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-11-13 07:38:53.703120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 07:38:53.703142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-11-13 07:38:53.703147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-11-13 07:38:53.703255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.703766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.704260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:38:53.704746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)
Loaded model in 0.598s.
Loading scorer from files new_lm_19_train/kenlm.scorer
Loaded scorer in 0.000179s.
Running inference.
2020-11-13 07:38:54.636989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
將軍澳居民可價車從跨灣大橋
Inference took 1.467s for 3.840s audio file.
root@cd69049a871f:/DeepSpeech/asr_test_server#
```

**Using ""Extended"" mode**:
```
root@cd69049a871f:/DeepSpeech/asr_test_server# deepspeech --model new_lm_19_train/output_graph.pb --scorer new_lm_19_train/kenlm.scorer --audio audio_collect_zh-HK_19be47fa770a4a12826735b395f7e8ad.wav --extended
2020-11-13 07:39:02.605366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
Loading model from file new_lm_19_train/output_graph.pb
TensorFlow: v1.15.0-29-g4e0e823493
DeepSpeech: v0.7.4-0-gfcd9563f
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2020-11-13 07:39:02.715122: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-11-13 07:39:02.716027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-13 07:39:02.744854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:02.745402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.605
pciBusID: 0000:26:00.0
2020-11-13 07:39:02.745416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-11-13 07:39:02.746300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-11-13 07:39:02.747077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-11-13 07:39:02.747246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-11-13 07:39:02.748233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-11-13 07:39:02.748973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-11-13 07:39:02.751328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-13 07:39:02.751420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:02.752022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:02.752536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-11-13 07:39:03.249879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 07:39:03.249904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-11-13 07:39:03.249909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-11-13 07:39:03.250025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:03.250557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:03.251069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:03.251559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9798 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)
Loaded model in 0.699s.
Loading scorer from files new_lm_19_train/kenlm.scorer
Loaded scorer in 0.000212s.
Running inference.
2020-11-13 07:39:04.193455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Traceback (most recent call last):
  File ""/usr/local/bin/deepspeech"", line 11, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/deepspeech/client.py"", line 152, in main
    print(metadata_to_string(ds.sttWithMetadata(audio, 1).transcripts[0]))
UnicodeEncodeError: 'utf-8' codec can't encode characters in position 0-38: surrogates not allowed
root@cd69049a871f:/DeepSpeech/asr_test_server#
```

**Using ""Json"" mode**:
```
root@cd69049a871f:/DeepSpeech/asr_test_server# deepspeech --model new_lm_19_train/output_graph.pb --scorer new_lm_19_train/kenlm.scorer --audio audio_collect_zh-HK_19be47fa770a4a12826735b395f7e8ad.wav --json
2020-11-13 07:39:17.533590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
Loading model from file new_lm_19_train/output_graph.pb
TensorFlow: v1.15.0-29-g4e0e823493
DeepSpeech: v0.7.4-0-gfcd9563f
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2020-11-13 07:39:17.642701: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-11-13 07:39:17.643614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-11-13 07:39:17.672544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:17.673301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.605
pciBusID: 0000:26:00.0
2020-11-13 07:39:17.673321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-11-13 07:39:17.674439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-11-13 07:39:17.675416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-11-13 07:39:17.675613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-11-13 07:39:17.676623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-11-13 07:39:17.677360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-11-13 07:39:17.679744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-11-13 07:39:17.679845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:17.680468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:17.681029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-11-13 07:39:18.073182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 07:39:18.073203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-11-13 07:39:18.073208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-11-13 07:39:18.073316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:18.073853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:18.074362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-13 07:39:18.074851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9790 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:26:00.0, compute capability: 7.5)
Loaded model in 0.586s.
Loading scorer from files new_lm_19_train/kenlm.scorer
Loaded scorer in 0.000177s.
Running inference.
2020-11-13 07:39:18.927302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
{
  ""transcripts"": [
    {
      ""confidence"": -251.61355590820312,
      ""words"": [
        {
          ""word"": ""\udce5\udcb0\udc87\udce8\udcbb\udc8d\udce6\udcbe\udcb3\udce5\udcb1\udc85\udce6\udcb0\udc91\udce5\udc8f\udcaf\udce5\udc83\udcb9\udce8\udcbb\udc8a\udce5\udcbe\udc9e\udce8\udcb7\udca8\udce7\udc81\udca3\udce5\udca4\udca7\udce6\udca9\udc8b"",
          ""start_time "": 0.0,
          ""duration"": 3.8
        }
      ]
    },
    {
      ""confidence"": -252.30313110351562,
      ""words"": [
        {
          ""word"": ""\udce5\udcb0\udc87\udce8\udcbb\udc8d\udce6\udcbe\udcb3\udce5\udcb1\udc85\udce6\udcb0\udc91\udce5\udc8f\udcaf\udce5\udc81\udc87\udce8\udcbb\udc8a\udce5\udcbe\udc9e\udce8\udcb7\udca8\udce7\udc81\udca3\udce5\udca4\udca7\udce6\udca9\udc8b"",
          ""start_time "": 0.0,
          ""duration"": 3.8
        }
      ]
    },
    {
      ""confidence"": -253.93341064453125,
      ""words"": [
        {
          ""word"": ""\udce5\udcb0\udc87\udce8\udcbb\udc8d\udce6\udcbe\udcb3\udce5\udcb1\udc85\udce6\udcb0\udc91\udce5\udc8f\udcaf\udce9\udc81\udc87\udce8\udcbb\udc8a\udce5\udcbe\udc9e\udce8\udcb7\udca8\udce7\udc81\udca3\udce5\udca4\udca7\udce6\udca9\udc8b"",
          ""start_time "": 0.0,
          ""duration"": 3.8
        }
      ]
    }
  ]
}
Inference took 1.365s for 3.840s audio file.
root@cd69049a871f:/DeepSpeech/asr_test_server#
```

Hope that these extra info would be helpful.
Thanks again.
Dow",produced origin issue one root model scorer audio successfully dynamic library loading model file gee warning reading entire model file memory transform model file graph reduce heap usage binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library segmentation fault core root issue two success case root model scorer audio successfully dynamic library loading model file gee warning reading entire model file memory transform model file graph reduce heap usage binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library inference took audio file root extended mode root model scorer audio extended successfully dynamic library loading model file gee warning reading entire model file memory transform model file graph reduce heap usage binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library recent call last file line module main file line main print audio ca encode position root mode root model scorer audio successfully dynamic library loading model file gee warning reading entire model file memory transform model file graph reduce heap usage binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library confidence word duration confidence word duration confidence word duration inference took audio file root hope extra would helpful thanks dow,issue,positive,positive,neutral,neutral,positive,positive
726489511,"…and indeed, it seems that this is pretty slow with files on a network volume. It seems that what's going on is that the `LimitPool` parallelizes over the augmentation, but file loading is still all handled by the parent process – that part is never actually parallelized. So the assumption is that bottleneck is augmentation rather than `load_sample`.",indeed pretty slow network volume going augmentation file loading still handled parent process part never actually assumption bottleneck augmentation rather,issue,negative,negative,neutral,neutral,negative,negative
726318136,@DanBmh -- did you ever reach a conclusion on this? have you been running augmentation with newer releases?,ever reach conclusion running augmentation,issue,negative,neutral,neutral,neutral,neutral,neutral
726024869,"> > an those be indexed like what TaskCluster has?
> 
> Not sure what you mean by this. You can give them custom names or save folders depending on your branch names for example, if this is what you mean.

Ok, I think I will try and use GitLab CI on gitlab for a pet-project of mine that lacks CI :), that will help me get a grasp of the landscape.",indexed like sure mean give custom save depending branch example mean think try use mine help get grasp landscape,issue,positive,negative,neutral,neutral,negative,negative
724597337,"> Tensorflow-js can be used here but I see that models for tensorflow-js has not been made yet and some people are facing troubles converting existing models to tensorflowjs compatible format #2233 .

You already have it there, read and act on that.",used see made yet people facing converting compatible format already read act,issue,negative,neutral,neutral,neutral,neutral,neutral
724174119,"@Modanisa-deep So, after spamming existing Discourse thread, not articulating correctly a question on discourse, spamming by force-notifying people, you decided to spam our github issues ?

This is my last warning. Next time, you will be banned and it will be escalated on both GitHub and Discourse.",discourse thread correctly question discourse people decided last warning next time discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
724053562,"As documented, please reach for support on Discourse and please provide precise details on your setup. Very likely your CPU does not support AVX.",please reach support discourse please provide precise setup likely support,issue,positive,positive,positive,positive,positive,positive
723652345,"As documented, the apk is only here for ci purpose. Please look at the deepspeech-example repo for real apps, and understand those might not be perfect and are supported only by contributors. ",purpose please look real understand might perfect,issue,positive,positive,positive,positive,positive,positive
723483350,"> Hello . When I downloaded deepspeech and run it on Windows, it unfortunately turned bad speech into text.
> 
> For example, when I say:
> HI ----> i
> you are ->you are
> 
> hello -> halow
> 
> How can I increase the accuracy or efficiency of speech to text conversion?
> 
> I just want to use only the Deep Speech model and I do not want to teach on any datasets? Is there a way or not?
> 
> When I say a word through a microphone, do I already have to make certain settings in the Windows environment?..

Please stop your spam on existing Github issues and use Discourse for support after reading the documentation.",hello run unfortunately turned bad speech text example say hi hello increase accuracy efficiency speech text conversion want use deep speech model want teach way say word microphone already make certain environment please stop use discourse support reading documentation,issue,positive,negative,negative,negative,negative,negative
723482459,"Hello . When I downloaded deepspeech and run it on Windows, it unfortunately turned bad speech into text.

For example, when I say:
HI ----> i
you are ->you are

hello -> halow

How can I increase the accuracy or efficiency of speech to text conversion?

I just want to use only the Deep Speech model and I do not want to teach on any datasets? Is there a way or not?

When I say a word through a microphone, do I already have to make certain settings in the Windows environment?..",hello run unfortunately turned bad speech text example say hi hello increase accuracy efficiency speech text conversion want use deep speech model want teach way say word microphone already make certain environment,issue,negative,negative,negative,negative,negative,negative
723481472,@reuben  @lissyx @erksch Hello . How can I translate audio very accurately through a microphone using C #? Do I have to make very specific settings?,hello translate audio accurately microphone make specific,issue,negative,positive,positive,positive,positive,positive
723475406,"@DanBmh : `--load_cudnn`  resolved the issue. Thank you.

@ DeepSpeech: Is this the right approach?",resolved issue thank right approach,issue,negative,positive,positive,positive,positive,positive
723473738,"> an those be indexed like what TaskCluster has?

Not sure what you mean by this. You can give them custom names or save folders depending on your branch names for example, if this is what you mean.",indexed like sure mean give custom save depending branch example mean,issue,positive,negative,neutral,neutral,negative,negative
723461356,"> See here for a guideline on how to make code citable:
https://guides.github.com/activities/citable-code/

As per the previous mention, Zenodo is the preferred way according to the Github Guidelines. The DOI would, however, need to reference a specific release.",see guideline make code citable per previous mention preferred way according would however need reference specific release,issue,negative,negative,neutral,neutral,negative,negative
723434036,"Not sure what caused the issue, but you might be able to solve it by just reinitializing the missing Adam tensors.

Check out `training/deepspeech_training/util/checkpoints.py` and there the code below ` if FLAGS.load_cudnn:` in `def _load_checkpoint`. Maybe it's enough to add the `--load_cudnn` flag, but I'm not sure it does change some other things too. ",sure issue might able solve missing check code maybe enough add flag sure change,issue,negative,positive,positive,positive,positive,positive
723293370,"Please use discourse for support. Avoid screenshots, read the docs. Share context on what you are doing. ",please use discourse support avoid read share context,issue,positive,neutral,neutral,neutral,neutral,neutral
723075977,"> That would be possible, it's also called _artifacts_ in gitlab. You should be able to run the job periodically or only if certain files did change in the repo.
> 
> I'm doing something similar [here](https://gitlab.com/Jaco-Assistant/jacolib/-/blob/master/.gitlab-ci.yml#L62), saving the following [image](https://gitlab.com/Jaco-Assistant/jacolib/-/jobs/artifacts/master/raw/badges/rcc.svg?job=analysis), which I later use in my readme.

Nice, and can those be indexed like what TaskCluster has?",would possible also able run job periodically certain change something similar saving following image later use nice indexed like,issue,positive,positive,positive,positive,positive,positive
723072234,"That would be possible, it's also called _artifacts_ in gitlab. You should be able to run the job periodically or only if certain files did change in the repo.

I'm doing something similar [here](https://gitlab.com/Jaco-Assistant/jacolib/-/blob/master/.gitlab-ci.yml#L62), saving the following [image](https://gitlab.com/Jaco-Assistant/jacolib/-/jobs/artifacts/master/raw/badges/rcc.svg?job=analysis), which I later use in my readme.",would possible also able run job periodically certain change something similar saving following image later use,issue,negative,positive,positive,positive,positive,positive
722432094,"> FWIW, I did [a test connecting a GitHub repo with GitLab CI](https://github.com/opensorceror/deepspeech-websocket-server/blob/main/.gitlab-ci.yml)...works pretty well.

Can it do something like we do with TC, i.e., precompile bits and fetch them at need?
This is super-important, because when you have to rebuild TensorFlow with CUDA, we're talking about **hours** even on decent systems.

So to overcome this, we have https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/generic_tc_caching-linux-opt-base.tyml + e.g., https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tf_linux-amd64-cpu-opt.yml

It basically:
 - do a setup + bazel build step on tensorflow with the parameters we need
 - produce a tar we can re-use later
 - store it on taskcluster index infrastructure

Which allows us to have caching we can periodically update, as you can see there: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/.shared.yml#L186-L260

We use the same mechanisms for many components (SWIG, pyenv, homebrew, etc.) to make sure we can keep build time decent on PRs (~10-20min of build more or less, ~2min for tests) so that a PR can complete under 30-60 mins.",test pretty well something like precompile fetch need rebuild talking even decent overcome basically setup build step need produce tar later store index infrastructure u periodically update see use many swig make sure keep build time decent build le complete,issue,positive,positive,positive,positive,positive,positive
722429373,"> 
> 
> > @lissyx can't we use ffmpeg?
> 
> Question is more: do we want to **support** this? Do we want to have to deal with specific weird bugs coming from that?

Well, personally dealing with more bugs it is not the most efficient thing we can choose...",ca use question want support want deal specific weird coming well personally dealing efficient thing choose,issue,positive,negative,negative,negative,negative,negative
722427226,"> @lissyx can't we use ffmpeg?

Question is more: do we want to **support** this? Do we want to have to deal with specific weird bugs coming from that?",ca use question want support want deal specific weird coming,issue,negative,negative,negative,negative,negative,negative
722341887,"Thanks @dag7dev for pushing the work, I have merged that to `master` and `r0.9`: when we do a 0.9.2 release, it will publish Python 3.9 packages. Let's see the feedback we get on 0.9.1 and if there are any bugfixes required or not.",thanks pushing work master release publish python let see feedback get,issue,negative,positive,positive,positive,positive,positive
721980568,"> This is for the inference part only? Tensorflow 1.x isn't available for python 3.8 or 3.9

Yes, that's right. ",inference part available python yes right,issue,negative,positive,positive,positive,positive,positive
721965309,This is for the inference part only? Tensorflow 1.x isn't available for python 3.8 or 3.9,inference part available python,issue,negative,positive,positive,positive,positive,positive
721856637,"> @lissyx don't understand where you got it, but I have updated the hash as you suggested!

Maybe you missed my messages on Matrix, but it's just the sha1 of the git repo: https://github.com/pyenv/pyenv/commit/806b30d6ce5b263a765648fbcdd68266833b7289",understand got hash maybe matrix sha git,issue,negative,neutral,neutral,neutral,neutral,neutral
721848370,"> > > LGTM, but you need to update the install of `pyenv` to current sha1, I don't think the version we have right now knows about Python 3.9
> > 
> > 
> > Do you mean dc67df621a1c91e136b651231cc2daf96c000df3 taken from https://updates.jenkins-ci.org/download/plugins/pyenv-pipeline/ or what?
> 
> no use 806b30d6ce5b263a765648fbcdd68266833b7289 instead of 20a1f0cd7a3d2f95800d8e0d5863b4e98f25f4df :)

like there: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L27 @dag7dev ",need update install current sha think version right python mean taken use instead like,issue,negative,negative,neutral,neutral,negative,negative
721847491,"> > LGTM, but you need to update the install of `pyenv` to current sha1, I don't think the version we have right now knows about Python 3.9
> 
> Do you mean dc67df621a1c91e136b651231cc2daf96c000df3 taken from https://updates.jenkins-ci.org/download/plugins/pyenv-pipeline/ or what?

no use 806b30d6ce5b263a765648fbcdd68266833b7289 instead of 20a1f0cd7a3d2f95800d8e0d5863b4e98f25f4df :)",need update install current sha think version right python mean taken use instead,issue,negative,negative,neutral,neutral,negative,negative
721843923,"> LGTM, but you need to update the install of `pyenv` to current sha1, I don't think the version we have right now knows about Python 3.9

Do you mean dc67df621a1c91e136b651231cc2daf96c000df3 taken from  https://updates.jenkins-ci.org/download/plugins/pyenv-pipeline/ or what?",need update install current sha think version right python mean taken,issue,negative,negative,neutral,neutral,negative,negative
721788240,"> Also, not sure how to deal with DISABLED file in taskcluster, just created another one, better than safe than sorry.

The example about Python 3.8 for SCIPY is because when we landed py38 support, there was no SciPy version for Python 3.8. Looks like it's not the case anymore, so you can try and take a change by renaming the file, it **should** work :)",also sure deal disabled file another one better safe sorry example python landed support version python like case try take change file work,issue,positive,positive,positive,positive,positive,positive
721787206,"Yes, Zenodo would be a solution to give us a DOI.",yes would solution give u,issue,positive,neutral,neutral,neutral,neutral,neutral
721756829,"> Is there a way to energize the repo admins to lift this onto master? An official BibTeX would be nice

What is blocking here is getting a DOI I think, @reuben can correct me. Maybe we should just go with bibtex to cite with a `\url{}`",way energize lift onto master official would nice blocking getting think correct maybe go cite,issue,positive,positive,positive,positive,positive,positive
721721372,"Adding a new Python version should, hopefully, /just/ be:
 - `git grep ""3\.8"" taskcluster/`: see where Python 3.8 is referenced,
 - update `SUPPORTED_PYTHON_VERSIONS` to add new python version,
 - update `maybe_numpy_min_version()` to set min deps for numpy wheels for new python version,
 - update `install_pyenv()` to use newer `pyenv` that knows about the new python version
 - update `pyenv` URLs in `taskcluster/.shared.yml` (increment digit) to re-generate cache
 - add new `.yml` test files for new python version",new python version hopefully git see python update add new python version update set min new python version update use new python version update increment digit cache add new test new python version,issue,negative,positive,positive,positive,positive,positive
721674035,"I'll close this in favor of using [Discourse](https://discourse.mozilla.org/c/deep-speech) for this topic, as it is not a bug or feature request.",close favor discourse topic bug feature request,issue,negative,neutral,neutral,neutral,neutral,neutral
721652200,"It's not completely unexpected. The 0.9.0 model is the first one trained with data augmentation, but due to [recent changes at Mozilla](https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/) we haven't been able to fully adjust all hyperparameters after the introduction of the new augmentation ones. This is reflected for example on the slightly worse WER on LibriSpeech-test-clean. Our hope is that it at least represents an improvement in noisy conditions, since that's the main focus of the data augmentation. In any case, the 0.8.2 model should be compatible with the 0.9.0 clients, so you can also stick to the previous model/checkpoints. Another possibility is doing some fine tuning of the 0.9.0 checkpoint, if you have some data. Maybe that would cover the accuracy gap for you. If you do that I'd be very interested in hearing what results you got.",completely unexpected model first one trained data augmentation due recent able fully adjust introduction new augmentation reflected example slightly worse wer hope least improvement noisy since main focus data augmentation case model compatible also stick previous another possibility fine tuning data maybe would cover accuracy gap interested hearing got,issue,negative,positive,neutral,neutral,positive,positive
721628060,"Faced with same issue. My recognition quality is even lower, for example, the word `hello` is recognized as `hlo`. I try to amplify input wav file, use good mic and etc. Nothing changed.",faced issue recognition quality even lower example word hello try amplify input file use good nothing,issue,negative,positive,positive,positive,positive,positive
721570730,"There was an issue on  readthedocs.io, breaking 0.9.0. It's fixed and /latest redirect to r0.9. We will have to issue a 0.9.1 there is no other way.",issue breaking fixed redirect issue way,issue,negative,positive,neutral,neutral,positive,positive
721427116,"Looks like [Travis supports macOS builds](https://docs.travis-ci.com/user/reference/osx).

Never used it though, not aware of the limitations if any.",like travis never used though aware,issue,negative,positive,positive,positive,positive,positive
721394358,"> Personally I'm a bit hesitant to work on this by myself, because the CI config of this repo seems too complex for a lone newcomer to tackle.


Of course


> 
> FWIW, I did [a test connecting a GitHub repo with GitLab CI](https://github.com/opensorceror/deepspeech-websocket-server/blob/main/.gitlab-ci.yml)...works pretty well.

That's nice, i will have a look. 


> 
> I'm not sure where we would find _hosted_ macOS options though.

That might be the biggest pain point.",personally bit hesitant work complex lone newcomer tackle course test pretty well nice look sure would find though might biggest pain point,issue,negative,positive,positive,positive,positive,positive
721381625,"Personally I'm a bit hesitant to work on this by myself, because the CI config of this repo seems too complex for a lone newcomer to tackle.

FWIW, I did [a test connecting a GitHub repo with GitLab CI](https://github.com/opensorceror/deepspeech-websocket-server/blob/main/.gitlab-ci.yml)...works pretty well. 

I'm not sure where we would find _hosted_ macOS options though.",personally bit hesitant work complex lone newcomer tackle test pretty well sure would find though,issue,positive,positive,positive,positive,positive,positive
721136505,"@DanBmh @opensorceror Let me be super-clear: what you shared looks very interesting, but I have no time to dig into that myself. If you guys are willing, please go ahead. One thing I should add is that for macOS, we would really need something to be **hosted**: the biggest pain was on maintaining this. If we move to GitLab CI but there is still need to babysit those, it's not really worth the effort.",let interesting time dig willing please go ahead one thing add would really need something biggest pain move still need really worth effort,issue,negative,positive,positive,positive,positive,positive
721008382,"Correct, thanks for submitting a PR. Could you also fix `create_inference_graph`?",correct thanks could also fix,issue,negative,positive,positive,positive,positive,positive
720533765,"Thanks @ftyers for the hint on French, Asma didn't pick that up and asked the exact same question without more information ... so I hinted again :-)",thanks hint pick exact question without information,issue,negative,positive,positive,positive,positive,positive
720517121,"Dear @Asma-droid thanks for getting in contact with us. As this doesn't seem like a bug in DeepSpeech, we would like to ask you if you could take your request to [Mozilla's Discourse](https://discourse.mozilla.org/c/mozilla-voice-stt/). Thanks! 

PS. When you open the topic on Discourse I recommend that you include more information, such as which version of DeepSpeech, exactly which commands you ran before receiving that error, etc. The more information you provide, the faster people on Discourse will be able to help you.

PPS. Note that in addition there is a [pretrained model](https://github.com/Common-Voice/commonvoice-fr/releases/tag/fr-v0.5.2) for French if you are interested in the model and not in the training.",dear thanks getting contact u seem like bug would like ask could take request discourse thanks open topic discourse recommend include information version exactly ran error information provide faster people discourse able help note addition model interested model training,issue,positive,positive,positive,positive,positive,positive
720463660,This is not a bug. Please use Discourse for support.,bug please use discourse support,issue,positive,neutral,neutral,neutral,neutral,neutral
719652509,"> Windows builds might be covered with some of their beta features:
> https://about.gitlab.com/blog/2020/01/21/windows-shared-runner-beta/
> 
> For iOS I think you would need to create your own runners on the macbooks and link them to the CI. They made a blog post for this:
> https://about.gitlab.com/blog/2016/03/10/setting-up-gitlab-ci-for-ios-projects/

I have no time to take a look at that, sadly.",might covered beta think would need create link made post time take look sadly,issue,negative,negative,negative,negative,negative,negative
719650889,"Windows builds might be covered with some of their beta features:
https://about.gitlab.com/blog/2020/01/21/windows-shared-runner-beta/

For iOS I think you would need to create your own runners on the macbooks and link them to the CI. They made a blog post for this:
https://about.gitlab.com/blog/2016/03/10/setting-up-gitlab-ci-for-ios-projects/",might covered beta think would need create link made post,issue,negative,neutral,neutral,neutral,neutral,neutral
719632515,"> @lissyx I believe GitLab CI supports all the requirements you listed above - I've personally used most of those features.

Don't hesitate if you want, I'd be happy to see how you can do macOS or Windows builds / tests.",believe listed personally used hesitate want happy see,issue,negative,positive,positive,positive,positive,positive
719017126,"I have been using GitLab CI (the on-prem community edition) for about three years at my workplace, and so far I have been very happy with it. @lissyx I believe GitLab CI supports all the requirements you listed above - I've personally used most of those features.

The thing I really like about GitLab CI is that it seems to be a very important feature for the company - they release updates frequently.",community edition three workplace far happy believe listed personally used thing really like important feature company release frequently,issue,positive,positive,positive,positive,positive,positive
718971855,"> time to review the CI

It might look complicated, so don't hesitate to read #3317 and ask for help here, on Discourse, or better on Matrix.",time review might look complicated hesitate read ask help discourse better matrix,issue,positive,neutral,neutral,neutral,neutral,neutral
718971083,"Alright, you made some good points and convinced me 🙂 I'll close this PR and create one in the examples repo.

> FTR, we have Examples integrated in our CI, so you could add your server as an example and maintain it there, and add CI here to ensure it does not break. We'd be happy to guide you on that.

About this, let me take some time to review the CI. For now, once I create the PR in the examples repo, I'll create an issue in that repo to track this.",alright made good convinced close create one could add server example maintain add ensure break happy guide let take time review create create issue track,issue,positive,positive,positive,positive,positive,positive
718966067,"> One could argue that the clients should also be in a separate repo (or several), but that is not my viewpoint - I think it makes sense to include them in the core repo.

It makes sense, and we discussed about that back then, and decided that given the current (at the time) status of the project, our bandwidth, it was simpler and more efficient. This is coming with costs in term of complexity, because then people can (and are right) to expect consistency accross everything, even feature wise.

Some bindings are happily living outside: Rust, Go.



> I think we should provide an official server API as part of the core project,

Maybe, but here we are moving from basic building blocks (bindings are required to access the library without a lot of pain), while a server is a higher-level piece. Also, it comes opiniated: people will want other archs, other languages as you said. It risk becoming a lot of not-core-related codebase, adding noise and complexity.



> By providing an official server as part of the core project, we also encourage community contribution to it.

By providing an official server, people might also expect server-grade performances. Having worked a few weeks on that, there were some non trivial bottlenecks we had not enough bandwidth to address.



> I'm also happy to create and maintain official Docker images

We already have some, so if you have PRs on that it's more than welcome.



> Just my thoughts. If you still think the server should be part of the examples repo, I am happy to move it there.

Yeah, sorry, I hate to bring messages like that on PRs properly baked, but for the focus, and the future of the project, it's better.

FTR, we have Examples integrated in our CI, so you could add your server as an example and maintain it there, and add CI here to ensure it does not break. We'd be happy to guide you on that.",one could argue also separate several viewpoint think sense include core sense back decided given current time status project simpler efficient coming term complexity people right expect consistency everything even feature wise happily living outside rust go think provide official server part core project maybe moving basic building access library without lot pain server piece also come people want said risk becoming lot noise complexity providing official server part core project also encourage community contribution providing official server people might also expect worked non trivial enough address also happy create maintain official docker already welcome still think server part happy move yeah sorry hate bring like properly baked focus future project better could add server example maintain add ensure break happy guide,issue,positive,positive,positive,positive,positive,positive
718936169,"@lissyx @olafthiele It makes sense to me that this should be in the examples repo, and I'm fine doing that. Before I do that though, let me make a case for including it in this (core) repo.

Currently, besides the core DeepSpeech code itself, the code for native clients is also included in this repo. One could argue that the clients should also be in a separate repo (or several), but that is not my viewpoint - I think it makes sense to include them in the core repo. Following similar logic though, I think we should provide an official server API as part of the core project, that will be maintained going forward (I'm happy to become a maintainer for this piece). I believe that it will result in increased adoption of this project, because many teams who use DeepSpeech may end up creating a server anyway. By providing an official server as part of the core project, we also encourage community contribution to it. 
Besides maintaining the server piece, I'm also happy to create and maintain official Docker images and Helm charts for new releases.

As a future plan: Similar to how we have clients in multiple languages as part of the core repo, we could also provide servers in multiple languages. I have a plan to contribute a Scalatra-based server, for users who prefer the JVM ecosystem.

Just my thoughts. If you still think the server should be part of the examples repo, I am happy to move it there.",sense fine though let make case core currently besides core code code native also included one could argue also separate several viewpoint think sense include core following similar logic though think provide official server part core project going forward happy become maintainer piece believe result adoption project many use may end server anyway providing official server part core project also encourage community contribution besides server piece also happy create maintain official docker helm new future plan similar multiple part core could also provide multiple plan contribute server prefer ecosystem still think server part happy move,issue,positive,positive,positive,positive,positive,positive
718795671,"@opensorceror Thanks for that PR, I had a look at it, and it is well done. However, it does diverge a bit from the purpose of that repository which is to provide basic building blocks for the project. As @olafthiele suggested, that level of integration fits much better in the examples repository, and so your PR is welcome there on both `r0.8` as well as `master` branch !",thanks look well done however diverge bit purpose repository provide basic building project level integration much better repository welcome well master branch,issue,positive,positive,positive,positive,positive,positive
718716575,"Great idea, the wish for a server is something that was mentioned a couple of times. I am not sure whether @lissyx and @reuben think this might be better added to the examples over here: 

https://github.com/mozilla/DeepSpeech-examples

And maybe leave out the gitignore files?",great idea wish server something couple time sure whether think might better added maybe leave,issue,positive,positive,positive,positive,positive,positive
718700661,"> but it did not work

How did it not work ?



> I spent way too much time trying to get it to work without any usable results

I'm really sorry about that, but it's not really hardware I can access to, so it's hard for me to assert what comes from ppc, what comes from your distro, what might be misdocumented.",work work spent way much time trying get work without usable really sorry really hardware access hard assert come come might,issue,negative,negative,neutral,neutral,negative,negative
718549347,"@lissyx I've tried to do it with the original, unmodified build-files and as the manual suggested me to do it, but it did not work and I moved away from trying it on PPC because I spent way too much time trying to get it to work without any usable results.",tried original unmodified manual work away trying spent way much time trying get work without usable,issue,negative,positive,positive,positive,positive,positive
718159316,"> Interesting, I'll have to explore `Model.__del__` to see what goodies await. Are you saying that the DS_DreeModel is indirectly exposed there?

https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/__init__.py#L41-L44



> From what I can tell, python will never GC the model until the primary thread/process dies (even if left running for 24hours).

So that would be consistent.



> Alternate solution to consider: Just run DS_FreeModel after sttWithMetadata? If that doesn't make sense in every scenario possibly control that behavior with an input param?

No, unfortunately, it does not make sense and it will complexify the API for nothing, and in case like yours, `Model.__del__` would be the way to go.",interesting explore see await saying indirectly exposed tell python never model primary even left running would consistent alternate solution consider run make sense every scenario possibly control behavior input param unfortunately make sense complexify nothing case like would way go,issue,negative,positive,neutral,neutral,positive,positive
717787033,"> @lissyx @carlfm01 if you can assist a bit with getting all needed `.so` files, that goes to `Github Release` (I used Release to generate nuget manually).
> If there is a way to get access to `libdeepspeech.so` in `do_nuget_build` (snippet below) for `linux-arm64, linux-x64, linux-arm, osx-x64, win-x64, win-arm64` that would be great
> 
> I pushed some WIP commit for CI, but it's not finished yet
> 
> ```
>   # We copy the generated SO files into the Nuget runtime dirs
> 
>   mkdir -p nupkg/runtimes/win-x64/native/  
>   cp ${DS_TFDIR}/bazel-bin/native_client/libdeepspeech.so nupkg/runtimes/win-x64/native/    
> 
>   mkdir -p nupkg/runtimes/win-arm64/native/
>   cp ${DS_TFDIR}/bazel-bin/native_client/libdeepspeech.so nupkg/runtimes/win-arm64/native/
> ```

I'm stuck on this one, not sure how to get all needed `.so` files, if someone can assist me in that - that would be great @lissyx @carlfm01 

Regarding `NAudio` it's not a big deal, it's just a sample, we can merge this PR with `NAudio` and then simply remove it, it will not require too much effort",assist bit getting go release used release generate manually way get access snippet would great commit finished yet copy stuck one sure get someone assist would great regarding big deal sample merge simply remove require much effort,issue,positive,positive,positive,positive,positive,positive
717614684,"Interesting, I'll have to explore `Model.__del__` to see what goodies await. Are you saying that the DS_DreeModel is indirectly exposed there?


Exposing that call directly sounds like a good idea, especially considering that anyone using this DS python binding in an interactive python session or jupyter notebook will encounter unexpected exhausted GPU memory resources after a few consecutive runs. 


From what I can tell, python will never GC the model until the primary thread/process dies (even if left running for 24hours). 


Alternate solution to consider: Just run DS_FreeModel after sttWithMetadata? If that doesn't make sense in every scenario possibly control that behavior with an input param?


I'm currently working around the issue in 3 different ways:
### Jupyter Notebooks Workaround:
Kill the notebook's virtual python kernel manually and restart it.
### Interactive Python Session
Manually restart the interactive python session.
### Production Server Running DS behind an API
Make sure all celery handlers die/restart after processing an API call with DS.


Providing direct access DS_FreeModel is probably your best bet. If it can be accessed indirectly via `Model.__del__` I'll test to confirm it clears GPU memory as expected.


I've been kind of busy putting out some other fires but I'll test out more where I can. Would love to get some PRs up for docs/improvements if possible.
",interesting explore see await saying indirectly exposed call directly like good idea especially considering anyone python binding interactive python session notebook encounter unexpected exhausted memory consecutive tell python never model primary even left running alternate solution consider run make sense every scenario possibly control behavior input param currently working around issue different way kill notebook virtual python kernel manually restart interactive python session manually restart interactive python session production server running behind make sure celery call providing direct access probably best bet indirectly via test confirm memory kind busy test would love get possible,issue,positive,positive,positive,positive,positive,positive
717510778,"> I agree, I would say to merge this PR first, and then create a new PR which removes NAudio dep.

Removing naudio would make more sense before, it would make less work on this patch, it seems easier, and we could benefit of it on 0.9 for sure.",agree would say merge first create new removing would make sense would make le work patch easier could benefit sure,issue,positive,positive,positive,positive,positive,positive
717505197,"I agree, I would say to merge this PR first, and then create a new PR which removes NAudio dep.",agree would say merge first create new,issue,positive,positive,positive,positive,positive,positive
717308293,"> > > I still think would better to remove the dependency and read read the wav stream without using NAudio.
> > > Maybe just taking what Naudio does and creating a local class in the project?
> > 
> > 
> > I guess any PR on that is welcome!
> 
> I think this could be done in a separate PR and doesn't need to block the current PR to be merged.

Yep, that was exactly my point, this is a nice PR to welcome and it would simplify work on this one.",still think would better remove dependency read read stream without maybe taking local class project guess welcome think could done separate need block current yep exactly point nice welcome would simplify work one,issue,positive,positive,positive,positive,positive,positive
717289993,"> > I still think would better to remove the dependency and read read the wav stream without using NAudio.
> > Maybe just taking what Naudio does and creating a local class in the project?
> 
> I guess any PR on that is welcome!

I think this could be done in a separate PR and doesn't need to block the current PR to be merged.",still think would better remove dependency read read stream without maybe taking local class project guess welcome think could done separate need block current,issue,negative,positive,positive,positive,positive,positive
717269884,"> I still think would better to remove the dependency and read read the wav stream without using NAudio.
> 
> Maybe just taking what Naudio does and creating a local class in the project?

I guess any PR on that is welcome!",still think would better remove dependency read read stream without maybe taking local class project guess welcome,issue,positive,positive,positive,positive,positive,positive
717102214,"I think what may be happening is that the Model instance, despite running out of scope in your example code, does not immediately get GC'd by the Python interpreter and so DS_FreeModel never gets called and the session is not closed. Unfortunately we do not expose DS_FreeModel directly in the Python bindings, instead relying exclusively on `Model.__del__`. Maybe we should expose for cases like this.",think may happening model instance despite running scope example code immediately get python interpreter never session closed unfortunately expose directly python instead exclusively maybe expose like,issue,negative,negative,negative,negative,negative,negative
716436087,"> Any help will be appreciated! Thanks!

Please reach for support on Discourse, not Github.",help thanks please reach support discourse,issue,positive,positive,positive,positive,positive,positive
716210785,"Hi, I am trying to perform fine-tuning on DeepSpeech's model in Colab. Here are the installation steps I am following- 

```
!git clone https://github.com/mozilla/DeepSpeech
!pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==46.1.3
!pip3 install --upgrade --force-reinstall -e .

```

But, I receive this error upon trying to run it - 

```
ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION) (from versions: 0.6.1, 0.7.0, 0.7.1, 0.7.3, 0.7.4, 0.8.0a3, 0.8.0a4, 0.8.0a5, 0.8.0a6, 0.8.0a7, 0.8.0a8, 0.8.0, 0.8.1, 0.8.2, 0.9.0a0, 0.9.0a1, 0.9.0a2, 0.9.0a3, 0.9.0a4, 0.9.0a5, 0.9.0a8, 0.9.0a9, 0.9.0a10, 0.9.0a11)
ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION)

```

Any help will be appreciated! Thanks!",hi trying perform model installation git clone pip install upgrade pip install upgrade receive error upon trying run error could find version requirement error matching distribution found help thanks,issue,negative,positive,positive,positive,positive,positive
716030673,"> It was very interesting following this thread! Learned a lot!
> Wanted to confirm that the suggested fix works:
> System Specs: Ubuntu 18.04, Nvidia Driver 410.104, Cuda 10.0, CUDNN 7.6.5, Ryzen 3700x, Nvidia GTX 1080
> 
> Added `export TF_CUDNN_RESET_RND_GEN_STATE=1` and made my training batch size divisible by the number of training samples.
> 
> I didn't notice any significant loss in performance.

You should not need those with TensorFlow 1.15.4``",interesting following thread learned lot confirm fix work system spec driver added export made training batch size divisible number training notice significant loss performance need,issue,negative,positive,positive,positive,positive,positive
715925580,"It was very interesting following this thread! Learned a lot!
Wanted to confirm that the suggested fix works:
System Specs: Ubuntu 18.04, Nvidia Driver 410.104, Cuda 10.0, CUDNN 7.6.5, Ryzen 3700x, Nvidia GTX 1080

Added `export TF_CUDNN_RESET_RND_GEN_STATE=1` and made my training batch size divisible by the number of training samples.

I didn't notice any significant loss in performance.

Edit: I am using the `tensorflow/tensorflow:1.15.4-gpu-py3` Docker image as well",interesting following thread learned lot confirm fix work system spec driver added export made training batch size divisible number training notice significant loss performance edit docker image well,issue,positive,positive,positive,positive,positive,positive
715568570,"> But, I do think it could help if the docs refer to the master version of the instructions (e.g., the docs they recommend checking out the master when building from source, but then refer to bazel version 2.0.0)

This is what we did in the past, and we had to handle a lot of noise in the other way, people being pointed to master when they were expecting stable,following master instructions and complaining of other things.

So we gave up and did that to stop wasting our time. Truth is, it more or less worked much better. 

> After re-activating the virtual environment, and trying again with bazel-3.1.0 (for some reason, need to use `bazel-3.1.0` instead of `bazel`), it builds without a problem. Sorry about the time wasting, and thanks for your help

Thanks, at least this can help others",think could help refer master version recommend master building source refer version past handle lot noise way people pointed master stable following master gave stop wasting time truth le worked much better virtual environment trying reason need use instead without problem sorry time wasting thanks help thanks least help,issue,positive,negative,neutral,neutral,negative,negative
715554606,Cancelled because I need to redo & branch from r0.9 before making the fix,need redo branch making fix,issue,negative,neutral,neutral,neutral,neutral,neutral
715530739,"After re-activating the virtual environment, and trying again with bazel-3.1.0 (for some reason, need to use `bazel-3.1.0` instead of `bazel`), it builds without a problem. Sorry about the time wasting, and thanks for your help

But, I do think it could help if the docs refer to the master version of the instructions (e.g., the docs they recommend checking out the master when building from source, but then refer to bazel version 2.0.0)",virtual environment trying reason need use instead without problem sorry time wasting thanks help think could help refer master version recommend master building source refer version,issue,positive,negative,negative,negative,negative,negative
715522984,"@william-vw It might help if you shared a bit more than just the error, like the full stdout/stderr from the `bazel build` step.",might help bit error like full build step,issue,negative,positive,positive,positive,positive,positive
715519819,"> I didn't claim otherwise

No, but you did not explicitely said, and you shared two informations that points to different versions, so it's unclear: do you work on `master` or `v0.8.2` ?

> `ERROR: Config value monolithic is not defined in any .rc file`

Sorry to insist, but this is really a symptom of running `bazel build` from the wrong directory or a wrong / broken release / setup.",claim otherwise said two different unclear work master error value monolithic defined file sorry insist really symptom running build wrong directory wrong broken release setup,issue,negative,negative,negative,negative,negative,negative
715513680,"> > When using bazel-3.1.0 (as enforced in `tensorflow/.bazelversion`) to run
> 
> This implies you are working on `master`

I didn't claim otherwise

> 
> > This is the link I followed from [the GitHub repo](https://github.com/mozilla/DeepSpeech) ; also isn't 0.8.2 the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2)?
> 
> This suggests you want 0.8.2

It's not something I want but rather given by instructions linked from the master's README",enforced run working master claim otherwise link also latest release want something want rather given linked master,issue,negative,positive,positive,positive,positive,positive
715511923,"> When using bazel-3.1.0 (as enforced in `tensorflow/.bazelversion`) to run

This implies you are working on `master`



> This is the link I followed from [the GitHub repo](https://github.com/mozilla/DeepSpeech) ; also isn't 0.8.2 the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2)?

This suggests you want 0.8.2",enforced run working master link also latest release want,issue,negative,positive,positive,positive,positive,positive
715508621,"> bazel-2.0.0 but this gives me a different error (`ERROR: Unrecognized option: --experimental_repo_remote_exec`)

Are you really sure this is running 2.0.0 ? It has this, according to their docs https://docs.bazel.build/versions/2.0.0/command-line-reference.html#flag--experimental_repo_remote_exec",different error error unrecognized option really sure running according,issue,negative,positive,positive,positive,positive,positive
715508083,"> This is the link I followed from [the GitHub repo](https://github.com/mozilla/DeepSpeech) ; also isn't 0.8.2 the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2)?

If you are working on 0.8.2, please stick to Bazel 2.0.0 as required. This is not a dependency we impose, this is TensorFlow, and it is quite picky on that point.",link also latest release working please stick dependency impose quite picky point,issue,negative,positive,positive,positive,positive,positive
715506856,"> Fair enough, but doesn't this imply that building from source would better in this case (i.e., improve performance)

Maybe.



> This is the link I followed from [the GitHub repo](https://github.com/mozilla/DeepSpeech) ; also isn't 0.8.2 the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2)?

That's the stable release. You have not mentionned anything specific, so I cannot know in advance what version you want to build ...



> > > `ERROR: Config value monolithic is not defined in any .rc file`
> > 
> > 
> > Are you running `bazel build` from the `tensorflow` subdirectory, as documented?
> 
> Yes

Well, then I'm sorry but I have no idea what is wrong there. Bazel 3.1.0 works very well on CI for `master`.",fair enough imply building source would better case improve performance maybe link also latest release stable release anything specific know advance version want build error value monolithic defined file running build yes well sorry idea wrong work well master,issue,positive,positive,neutral,neutral,positive,positive
715505074,"> > (The only reason I'm building from source is because there doesn't seem to be a suitable pre-compiled native_client for my system, getting the error `Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2`)
> 
> This is not an error, this is a warning produced by tensorflow.

Fair enough, but doesn't this imply that building from source would better in this case (i.e., improve performance)

> 
> > `ERROR: Config value monolithic is not defined in any .rc file`
> 
> Are you running `bazel build` from the `tensorflow` subdirectory, as documented?
> 

Yes

> > (Note that the [docs even recommend](https://deepspeech.readthedocs.io/en/v0.8.2/BUILDING.html) bazel-2.0.0 but this gives me a different error (`ERROR: Unrecognized option: --experimental_repo_remote_exec`)
> 
> Those docs are for 0.8.2 that do not depend against the same TensorFlow version.
> The `master` does properly document 3.1.0: https://deepspeech.readthedocs.io/en/master/BUILDING.html#building-deepspeech-binaries

This is the link I followed from [the GitHub repo](https://github.com/mozilla/DeepSpeech) ; also isn't 0.8.2 the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.8.2)? ",reason building source seem suitable system getting error binary use error warning produced fair enough imply building source would better case improve performance error value monolithic defined file running build yes note even recommend different error error unrecognized option depend version master properly document link also latest release,issue,negative,positive,positive,positive,positive,positive
715499833,"I confirm that the wav reader method from NAudio used in the demo project, doesn't rely on any Windows specific API, hence why it works on Rpi.

I still think would better to remove the dependency and read read the wav stream without using NAudio.

Maybe just taking what Naudio does and creating a local class in the project?",confirm reader method used project rely specific hence work still think would better remove dependency read read stream without maybe taking local class project,issue,negative,positive,positive,positive,positive,positive
715497732,"> (The only reason I'm building from source is because there doesn't seem to be a suitable pre-compiled native_client for my system, getting the error `Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2`)

This is not an error, this is a warning produced by tensorflow.


> `ERROR: Config value monolithic is not defined in any .rc file`

Are you running `bazel build` from the `tensorflow` subdirectory, as documented?



> (Note that the [docs even recommend](https://deepspeech.readthedocs.io/en/v0.8.2/BUILDING.html) bazel-2.0.0 but this gives me a different error (`ERROR: Unrecognized option: --experimental_repo_remote_exec`)

Those docs are for 0.8.2 that do not depend against the same TensorFlow version.
The `master` does properly document 3.1.0: https://deepspeech.readthedocs.io/en/master/BUILDING.html#building-deepspeech-binaries",reason building source seem suitable system getting error binary use error warning produced error value monolithic defined file running build note even recommend different error error unrecognized option depend version master properly document,issue,negative,positive,positive,positive,positive,positive
715495101,"Sorry but this should only have one commit with your fix. I dont know what you did, but its not good ",sorry one commit fix dont know good,issue,negative,positive,neutral,neutral,positive,positive
715270027,"> However it also seems like tensorflow is being baked into some executable that's being wrapped by python here?

Yes `libdeepspeech.so`



>  I'd like to get this fixed as the leak is quite extreme 0 to max GPU memory usage on the master GPU after a single run of like 30secs of audio and then like a 65mb incremental bump on all the slave GPUs every execution. I don't have the exact errors this inevitably causes on hand unfortunately.

By default, tensorflow will allocate the whole gpu memory, this is something you see at training as well, so its unclear there how much depends on that expected behavior and how much is actual leak. ",however also like baked executable wrapped python yes like get fixed leak quite extreme memory usage master single run like audio like incremental bump slave every execution exact inevitably hand unfortunately default allocate whole memory something see training well unclear much behavior much actual leak,issue,positive,positive,neutral,neutral,positive,positive
715247833,"Thanks for taking the time to address my issue in such detail and push me in the right direction. I'd like to get this fixed as the leak is quite extreme 0 to max GPU memory usage on the master GPU after a single run of like 30secs of audio and then like a 65mb incremental bump on all the slave GPUs every execution. I don't have the exact errors this inevitably causes on hand unfortunately.


I've played with valgrind before and I'm happy to dig into this more, but I'm not sure it's warranted just yet.


From my due diligence I agree with your summation that this could be a binding level issue. And hopefully a fix is easy but I need to look into the code further. 


From what I understand, Tensorflow will release your GPU memory if you ask really nicely. 


However it also seems like tensorflow is being baked into some executable that's being wrapped by python here?


EDIT: Ohh I have a nifty idea to repro without the python bindings, will test and report back (not rn though 4am). I think I can get the search space a lot more narrow if not PR in a fix. Thanks again @lissyx !

",thanks taking time address issue detail push right direction like get fixed leak quite extreme memory usage master single run like audio like incremental bump slave every execution exact inevitably hand unfortunately happy dig sure warranted yet due diligence agree summation could binding level issue hopefully fix easy need look code understand release memory ask really nicely however also like baked executable wrapped python edit nifty idea without python test report back though think get search space lot narrow fix thanks,issue,positive,positive,positive,positive,positive,positive
715188791,"Also, we have valgrind coverage on the lib level (not binding level), aand non gpu is not leaking anything under our control. Given the differences between gpu and non gpu lib, its likely if there are leaks, its outsider of our scope anyway.

I dont have time in the forseable future to take a deeper look,sso if you can investigate with valgrind on pure lib and bindings to reduce the search space... ",also coverage level binding level non anything control given non likely outsider scope anyway dont time future take look investigate pure reduce search space,issue,negative,positive,neutral,neutral,positive,positive
715117922,"> So I actually get back the `sttWithMetadata` results fine, however the GPU memory is never free'd, eventually causing out of GPU memory errors after multiple runs.

What errors ?

Also, sharing `nvidia-smi` might not be the best way to track memory leaks.",actually get back fine however memory never free eventually causing memory multiple also might best way track memory,issue,positive,positive,positive,positive,positive,positive
715116363,"> Anyone should be able to reproduce by running `sttWithMetadata()` from the deepspeech-gpu python lib. This is the code I'm using:

Please try and repro without the python bindings ?",anyone able reproduce running python code please try without python,issue,negative,positive,positive,positive,positive,positive
715114630,"> Memory should be cleared after `sttWithMetadata` completes correct? Seems like these TF memory zombies are kinda common.

TensorFlow has a tendance to keep its memory until the process is gone, there's not a lot we can do there.",memory correct like memory common tendance keep memory process gone lot,issue,negative,negative,negative,negative,negative,negative
714494740,"> Is there a reason why it's targeting netstandard2.1 instead of netstandard2.0 ?
> Because unity doesn't support .netstandard2.1 (yet https://forum.unity.com/threads/net-standard-2-1.757007/), i think it would be a great value to also allow unity engine to use this library. Unity use Mono for Linux and MacOs and currently the Mono BCL doesn't support NetStandard 2.1

yeah, sure, will add it to target frameworks",reason instead unity support yet think would great value also allow unity engine use library unity use mono currently mono support yeah sure add target,issue,positive,positive,positive,positive,positive,positive
714482670,"> Is there a reason why it's targeting netstandard2.1 instead of netstandard2.0 ?
> Because unity doesn't support .netstandard2.1 (yet https://forum.unity.com/threads/net-standard-2-1.757007/), i think it would be a great value to also allow unity engine to use this library. Unity use Mono for Linux and MacOs and currently the Mono BCL doesn't support NetStandard 2.1

From https://docs.microsoft.com/en-us/dotnet/core/install/linux-ubuntu it only mentions 2.1. Maybe @stepkillah and @carlfm01 can elaborate, I know nothing about .Net.",reason instead unity support yet think would great value also allow unity engine use library unity use mono currently mono support maybe elaborate know nothing,issue,positive,positive,positive,positive,positive,positive
714478242,"Is  there a reason why it's targeting netstandard2.1 instead of netstandard2.0 ?
Because unity doesn't support .netstandard2.1 (yet https://forum.unity.com/threads/net-standard-2-1.757007/), i think it would be a great value to also allow unity engine to use this library. Unity use Mono for Linux and MacOs and currently the Mono BCL doesn't support NetStandard 2.1",reason instead unity support yet think would great value also allow unity engine use library unity use mono currently mono support,issue,positive,positive,positive,positive,positive,positive
714472932,"> Maybe it's because the part that the demo use doesn't interact with code that exploited platform specific code/dll.

I'm thinking the same",maybe part use interact code platform specific thinking,issue,negative,neutral,neutral,neutral,neutral,neutral
714471016,"> > Do you think we could have a demo that doesn't use NAudio since NAudio only works on windows ?
> 
> strange thing - I tested `NetCore` sample on raspberry and macos with `NAudio` and it works fine

Because on the nuget : https://www.nuget.org/packages/NAudio/
On NetStandard2.0 and NetCoreApp 3.0 they need to use the package https://www.nuget.org/packages/Microsoft.Win32.Registry/ and just by the name it's look like it's windows only (maybe i'm wrong) and when i go to linux support in the github of the project it doesn't seem that is support linux neither macos (https://github.com/naudio/NAudio/issues/184, https://github.com/naudio/NAudio/issues/591).

Maybe it's because the part that the demo use doesn't interact with code that exploited platform specific code/dll.
",think could use since work strange thing tested sample raspberry work fine need use package name look like maybe wrong go support project seem support neither maybe part use interact code platform specific,issue,positive,negative,neutral,neutral,negative,negative
714465675,"@stepkillah @Davilink worst case, you can always setup manual WAVE file reading like we do on Android/bionic `deepspeech` binary and for APK for CI, this can work for sure.",worst case always setup manual wave file reading like binary work sure,issue,negative,negative,negative,negative,negative,negative
714459871,"> Do you think we could have a demo that doesn't use NAudio since NAudio only works on windows ?

strange thing - I tested `NetCore` sample on raspberry and macos with `NAudio` and it works fine",think could use since work strange thing tested sample raspberry work fine,issue,negative,positive,positive,positive,positive,positive
714376294,Do you think we could have a demo that doesn't use NAudio since NAudio only works on windows ?,think could use since work,issue,negative,neutral,neutral,neutral,neutral,neutral
713634810,@dsteinman Do you want to try and pick this task?,want try pick task,issue,negative,neutral,neutral,neutral,neutral,neutral
713541678,"Is there a way to energize the repo admins to lift this onto master? An official BibTeX would be nice

> It has to be done by repo admins. I looked into it and got stuck in support limbo for the citation service, because the admins for the Mozilla org didn't want to enable the app globally, so the webhook had to be added manually and the repo enabled by support.",way energize lift onto master official would nice done got stuck support limbo citation service want enable globally added manually support,issue,positive,positive,positive,positive,positive,positive
711487906,"@reuben I spent a few days weeks ago trying to figure that part out, but couldn't figure out how to make it recognize the correct header files/binary files/etc.",spent day ago trying figure part could figure make recognize correct header,issue,negative,negative,neutral,neutral,negative,negative
711381704,"@zaptrem the CI build just calls Xcode with `xcodebuild`, so if you can make it work on Xcode.app, it will also work on the CI build.",build make work also work build,issue,negative,neutral,neutral,neutral,neutral,neutral
711365963,@reuben Is it possible to configure your build process to embed libdeepspeech.so into a .framework to make Apple happy?,possible configure build process embed make apple happy,issue,positive,positive,positive,positive,positive,positive
711156933,@carlfm01 checked logs from CI - pushed fix for failing build,checked fix failing build,issue,negative,neutral,neutral,neutral,neutral,neutral
711109503,"> 
> 
> > I pushed some WIP commit for CI, but it's not finished yet
> 
> And you dont have creds 😉 but @carlfm01 can run for you by fetching your pr and opening a new one

Done https://github.com/mozilla/DeepSpeech/pull/3381

I'll review again tomorrow ",commit finished yet dont run fetching opening new one done review tomorrow,issue,negative,positive,positive,positive,positive,positive
711057392,"@Davilink this is great news! Thanks for this.
I will spend some time in this and report back.

Would be good to have your changes merged in the main project once proved fully working.",great news thanks spend time report back would good main project proved fully working,issue,positive,positive,positive,positive,positive,positive
710937077,"> using https://github.com/asticode/go-astideepspeech - however i am not sure it will support future models

Btw the dev of that is quite reactive, and either take cares of api changes or review our patches quickly, so there should not be any fear on that. We are close to 1.0 so the api is rather stable. ",however sure support future dev quite reactive either take review quickly fear close rather stable,issue,negative,positive,positive,positive,positive,positive
710934889,"> Just adding my use case here - I am using this model in golang using https://github.com/asticode/go-astideepspeech - however i am not sure it will support future models. If you could support ONNX we can use models easily in any other language without depending on a binding repo or python.
> Also none of the frameworks (pytorch, tensorflow .etc) are easily usable in golang. Tensorflow go support makes it hard to use in production .etc.

We welcome anyone who is willing to expriment, but again, the offering of the project is model and lib. Changing to onnx brings a lot of work, much more we can take, for exactly no win. ",use case model however sure support future could support use easily language without depending binding python also none easily usable go support hard use production welcome anyone willing offering project model lot work much take exactly win,issue,positive,positive,positive,positive,positive,positive
710914843,"Just adding my use case here - I am using this model in golang using https://github.com/asticode/go-astideepspeech - however i am not sure it will support future models. If you could support ONNX we can use models easily in any other language without depending on a binding repo or python.
Also none of the frameworks (pytorch, tensorflow .etc) are easily usable in golang. Tensorflow go support makes it hard to use in production .etc.
",use case model however sure support future could support use easily language without depending binding python also none easily usable go support hard use production,issue,positive,positive,positive,positive,positive,positive
710163046,"> I pushed some WIP commit for CI, but it's not finished yet

And you dont have creds 😉 but @carlfm01 can run for you by fetching your pr and opening a new one ",commit finished yet dont run fetching opening new one,issue,negative,positive,positive,positive,positive,positive
710093898,"@lissyx @carlfm01 if you can assist a bit with getting all needed `.so` files, that goes to `Github Release` (I used Release to generate nuget manually).
If there is a way to get access to `libdeepspeech.so` in `do_nuget_build` (snippet below) for `linux-arm64, linux-x64, linux-arm, osx-x64, win-x64, win-arm64` that would be great

I pushed some WIP commit for CI, but it's not finished yet

```
  # We copy the generated SO files into the Nuget runtime dirs

  mkdir -p nupkg/runtimes/win-x64/native/  
  cp ${DS_TFDIR}/bazel-bin/native_client/libdeepspeech.so nupkg/runtimes/win-x64/native/    

  mkdir -p nupkg/runtimes/win-arm64/native/
  cp ${DS_TFDIR}/bazel-bin/native_client/libdeepspeech.so nupkg/runtimes/win-arm64/native/
```",assist bit getting go release used release generate manually way get access snippet would great commit finished yet copy,issue,positive,positive,positive,positive,positive,positive
709943893,"> I insists we do document to use it, and your reports would show you might have weird behavior just because of that

There's no good reason for you to have to change definitions.mk, for example. Virtualenv already takes care of making sure `python` matches what you have in the venv. Here you might end up with weird mixes. And i already lost days in debugging such à case of someone else who was refusing to follow docs. And venv, when this person decided to listen, made everything work as intended. ",document use would show might weird behavior good reason change example already care making sure python might end weird already lost day case someone else refusing follow person decided listen made everything work intended,issue,negative,positive,neutral,neutral,positive,positive
709940880,"


> ImportError: cannot import name '_swigwrapper' from 'ds_ctcdecoder' (/home/s3811141/.local/lib/python3.7/site-packages/ds_ctcdecoder/**init**.py)

Have you checked the lib swigwrapper is there ? 
Have you checked what the dynamic linker does with `LD_DEBUG=all` ? 

Anyway im sorry but its really on your side so far, nothing much i can do especially since il supposed to be on holidays. 

> You were right that this was partly a python2/python3 problem. I changed python to python3 in the definitions.mk and this problem was solved

That would make me question how you virtualenv is actually working. 



> I'm using singularity, so the build process is all inside the container

Container is unrelated to python virtualenv. I insists we do document to use it, and your reports would show you might have weird behavior just because of that. ",import name checked checked dynamic linker anyway sorry really side far nothing much especially since supposed right partly problem python python problem would make question actually working singularity build process inside container container unrelated python document use would show might weird behavior,issue,negative,negative,neutral,neutral,negative,negative
709935562,"Thanks for the replies so far.

@lissyx You were right that this was partly a python2/python3 problem. I changed python to python3 in the definitions.mk and this problem was solved, but there was another one. (See end of this post). But swig 3.0.x did not work because in the 3.0.x libraries the unordered_map does not work (it says at the beginning of the swig file that it does not and it produces tons of errors). Also, I'm using singularity, so the build process is all inside the container.

@olafthiele I did not know that, but I solved the webrtc problems on PPC myself and submitted it as a patch ( https://github.com/NormanTUD/webrtc )

My problem now is that, even though I was able to build the .so for and with python3 file, I still get:

ImportError: cannot import name '_swigwrapper' from 'ds_ctcdecoder' (/home/s3811141/.local/lib/python3.7/site-packages/ds_ctcdecoder/__init__.py)
",thanks far right partly problem python python problem another one see end post swig work work beginning swig file also singularity build process inside container know patch problem even though able build python file still get import name,issue,negative,positive,positive,positive,positive,positive
709898683,"> python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .

You also lack the `--arch osx`, but i my previous comment still holds ",python source artifact branch target also lack arch previous comment still,issue,negative,negative,negative,negative,negative,negative
709881945,"This is what i said earlier, this old artifact expired and we cant republish it. ",said old artifact cant republish,issue,negative,positive,neutral,neutral,positive,positive
709862002,"Sorry, just remembered that was for webrtcvad on PowerPC, but I remember that I could build everything else on PPC architecture just fine. ",sorry remember could build everything else architecture fine,issue,negative,negative,neutral,neutral,negative,negative
709832958,"The command line here fails, does not work

https://deepspeech.readthedocs.io/en/v0.8.2/TRAINING.html#making-a-mmap-able-model-for-inference has the correct command line

(venv) (base) BCODE-iMac:DeepSpeech bcode$ python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .
Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.osx/artifacts/public/convert_graphdef_memmapped_format ...
Traceback (most recent call last):
  File ""util/taskcluster.py"", line 12, in <module>
    dsu_taskcluster.main()
  File ""/Users/bcode/Desktop/p/DeepSpeech/DeepSpeech/training/deepspeech_training/util/taskcluster.py"", line 128, in main
    maybe_download_tc(target_dir=args.target, tc_url=get_tc_url(args.arch, args.artifact, args.branch))
  File ""/Users/bcode/Desktop/p/DeepSpeech/DeepSpeech/training/deepspeech_training/util/taskcluster.py"", line 58, in maybe_download_tc
    _, headers = urllib.request.urlretrieve(tc_url, target_file, reporthook=(report_progress if progress else None))
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 247, in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 222, in urlopen
    return opener.open(url, data, timeout)
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 531, in open
    response = meth(req, response)
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 641, in http_response
    'http', request, response, code, msg, hdrs)
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 569, in error
    return self._call_chain(*args)
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 503, in _call_chain
    result = func(*args)
  File ""/opt/anaconda3/lib/python3.7/urllib/request.py"", line 649, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 404: Not Found",command line work correct command line base python source artifact branch target recent call last file line module file line main file line progress else none file line data file line return data file line open response response file line request response code file line error return file line result file line raise code error found,issue,negative,negative,negative,negative,negative,negative
709538995,"I think I saw a post by someone on Discourse who made it work by some neat trick. Did you search there before posting here?

",think saw post someone discourse made work neat trick search posting,issue,negative,neutral,neutral,neutral,neutral,neutral
709472949,"This is a no-op for samples that aren't broken and CV is not in a position to make releases with fixes right now, so I'd say we just merge it.",broken position make right say merge,issue,negative,negative,neutral,neutral,negative,negative
709330114,"Another thing : our fork of swig is really needed only for nodejs bindings. For python i would advise to keep using your distro's one,and 18.04 should have 3.0.2 which should work well ",another thing fork swig really python would advise keep one work well,issue,negative,positive,positive,positive,positive,positive
709321688,"@carlfm01 I was able to verify that  nuget above works on `osx`, so I suggest it works on Linux as well. so waiting until your confirmation. Btw it works on OSX with `NAudio`

**Update**
Also was able to verify it on rpi3 ",able verify work suggest work well waiting confirmation work update also able verify,issue,negative,positive,positive,positive,positive,positive
709242584,"Especially, using a virtualenv can help ensure the whole build process is consistent ",especially help ensure whole build process consistent,issue,positive,positive,positive,positive,positive,positive
709228059,Btw googling for your missing symbol links to a lot of cases of py2/py3 mismatch. Please cross check you are using the proper versions at all time. ,missing symbol link lot mismatch please cross check proper time,issue,negative,negative,neutral,neutral,negative,negative
709225980,"This is not hardware we have access, and i dont have time to investigate. I have no idea why you have that missing symbol. Please also understand we are consumer of swig, so if the issue is here its really even more out of our hands. ",hardware access dont time investigate idea missing symbol please also understand consumer swig issue really even,issue,negative,neutral,neutral,neutral,neutral,neutral
708920942,"@verloka Yeah, i tested linux and windows, i don't have a mac so cannot promise that it work on mac (it should... but not tested)",yeah tested mac promise work mac tested,issue,positive,neutral,neutral,neutral,neutral,neutral
708916246,"I would like to help but i'm not sure how to ...
I create an unofficial package and used in a demo project: https://github.com/Davilink/MyRecorder/tree/deepspeech-integration (if you want to make it work on window you need to install https://openal.org/) hoping that could help @carlfm01.
",would like help sure create unofficial package used project want make work window need install could help,issue,positive,positive,positive,positive,positive,positive
708478458,"> ok Im sorry for that

Please follow the Discourse guidelines when you post there: https://discourse.mozilla.org/t/what-and-how-to-report-if-you-need-support/62071",sorry please follow discourse post,issue,negative,negative,negative,negative,negative,negative
708471877,"> How not where to reach. Isnt it where the model and the code is

Details where within the issue template you ignored and wiped.",reach model code within issue template,issue,negative,neutral,neutral,neutral,neutral,neutral
708470121,@abdullah249 This is not a place to reach for support. Please use Discourse for that.,place reach support please use discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
708451093,"
> so we basically need to adjust build steps to be able to create a similar folder structure
> ![image](https://user-images.githubusercontent.com/10140906/95970323-7d5a3580-0e18-11eb-9787-30e786f1b1eb.png)
> 
I want to see what happens if we try to run the NuGet with that structure for the .net core example on Linux

",basically need adjust build able create similar folder structure image want see try run structure core example,issue,negative,positive,positive,positive,positive,positive
708449760,"@stepkillah Thanks for your help here. The first thing we need to do is confirming that we can use the already existing native library for Linux and call it using `nativeImp` @stepkillah can you grab them from other packages and generate a nuget for me? I can use the net core console example on my vm with the nuget to see what happens, if we can't run it out of the box we are in trouble :)

Summary: Let's generate a NuGet with the native libs for Linux manually, if we can run it with the existing native libs then we can start working on how to put them into the Nuget package on `do_deepspeech_netframework_build `

",thanks help first thing need confirming use already native library call grab generate use net core console example see ca run box trouble summary let generate native manually run native start working put package,issue,negative,positive,neutral,neutral,positive,positive
708366998,"@lissyx let me prepare some requirements for the environment. I also will try to write some explanations about what I want to achieve. thanks a lot for your assistance. 

I will take a closer look at how this CI works (thanks for your link to some sort of specs). I don't think we will need to add extra workers, because everything we need - already built, we just need to pick correct `.so` files and pack them into nuget. 
And tests, of course, I didn't cover test at all yet.
Net core supports self-contained apps, which means it might be built once on windows or whatever platform, and it will run successfully on others, so we need to build it once and deploy to different platforms.

Note about macOS - there are no restrictions for macOS so it worth nothing to make `DeepSpeechClient` work on macOS too, so C# devs can use it cross-platform.",let prepare environment also try write want achieve thanks lot assistance take closer look work thanks link sort spec think need add extra everything need already built need pick correct pack course cover test yet net core might built whatever platform run successfully need build deploy different note worth nothing make work use,issue,positive,positive,positive,positive,positive,positive
708324697,">  I assume `DeepSpeechConsole` is built for test, so the same applies for `DeepSpeechConsoleNetCore`

Yes, but `DeepSpeechConsole` only targets Windows, while your addition targets other platforms: knowing nothing about .Net, I assumed your first goal was just to broaden our Windows support, not that you were interested in linux as well. Thing is, the whole .Net support has been built and written under the assumption of Windows. Hence why we really need to address the first steps:
 - getting a clear view of your expectations: I understand macOS could also be supported, do we want that?
 - writing down docs, like existing ones for .Net Framework, on setup and build phases, like manual
 - this does include, and I am really insistent on that, cross-compilation for ARMv7 and Aarch64: first, we don't have the hardware to handle builds on those, second we don't have the time to refactor CI to add new workers that may be powerful enough. If we want those ARM flavors, it will have to be done via cross-compilation.
 - from those docs with manual steps (that should be accurate and be what we direct people who want to re-produce our builds), we can see how / what needs to be changed to support on CI all the flavors we want and we can help you through it.

I hope you understand I'm not trying to avoid your contribution but actually I do welcome it, but if we are to add those builds, they need to be CI-supported and tested, otherwise it will break sooner or later, and we will be unable to properly support them.",assume built test yes addition knowing nothing assumed first goal broaden support interested well thing whole support built written assumption hence really need address first getting clear view understand could also want writing like framework setup build phase like manual include really insistent first hardware handle second time add new may powerful enough want arm done via manual accurate direct people want see need support want help hope understand trying avoid contribution actually welcome add need tested otherwise break sooner later unable properly support,issue,positive,positive,positive,positive,positive,positive
708319497,"> Those are the complicated questions. We cant address ci until we know where we are going.

Or, reworded, i dont understand what we need to change to support those, so i really need your help on explaining clearly what you want to achieve and document how we are supposed to do it. From there i should be able to figure out what needs to change on our ci and help guide you through it efficiently.

You are welcome to read about our ci also from #3317 but that's still à lot to grasp from ",complicated cant address know going dont understand need change support really need help explaining clearly want achieve document supposed able figure need change help guide efficiently welcome read also still lot grasp,issue,positive,positive,positive,positive,positive,positive
708315780,"> you mean `if` in a script or `native_client` ? for the script we don't need `if` because we will need almost all `.so` files, they will be placed in separate folders

Thats not the problem, check the callers. 

> > Also, its not sure the build env will be similar between net framework build on Windows and net Core on linux...
> 
> that's right, need to be sure build env has net core installed, is there a way to check this?

First, again, i dont know that ecosystem so i dont know what you need.

This is really getting hairy and complicated, i fear you are getting yourself lost. Can we please lay out your expectations on term of support ?

Can you please check on your side the Windows and Linux requirements to perform those builds, including arm cross compilation ? Can you add to docs for supporting those ?

Those are the complicated questions. We cant address ci until we know where we are going. ",mean script script need need almost separate thats problem check also sure build similar net framework build net core right need sure build net core way check first dont know ecosystem dont know need really getting hairy complicated fear getting lost please lay term support please check side perform arm cross compilation add supporting complicated cant address know going,issue,positive,positive,neutral,neutral,positive,positive
708312078,"> Also, its not sure the build env will be similar between net framework build on Windows and net Core on linux...

that's right, need to be sure build env has net core installed, is there a way to check this?",also sure build similar net framework build net core right need sure build net core way check,issue,positive,positive,positive,positive,positive,positive
708311637,"> > > It was my understanding that Net Framework was Windows only ?
> > 
> > 
> > you're right, but the build process is very similar, for this case, it seems just a matter of replacing `TargetFramework` [here](https://github.com/mozilla/DeepSpeech/blob/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/taskcluster/tc-build-utils.sh#L256) (example) for new net core steps to be `netcoreapp3.1` and `netstandard2.1`
> 
> Yes but if you do so, you end up having to `if` inside the function while if you add a new one you can just call it on platforms where it makes sense only.
> 
> So maintenance wise i prefer we have two sets of well scoped functions that one doing multiplatforms in a weird way.

you mean `if` in a script or `native_client` ? for the script we don't need `if` because we will need almost all `.so` files, they will be placed in separate folders, and there is no need for `if` in the native client, because nuget will resolve correct `.so` automatically based on runtime, or if runtime is not set it will deploy all runtimes, and select correct one during start again based on runtime.

if you talking about sample `net core console app` - it's not related to `.dll` of `DeepSpeechClient`, console app it's just a sample that should be built as self-contained for specific runtimes - `linux-x64, linux-arm64, win-x64, win-arm64,osx-x64` . so it will contain all necessary things to run upon linux/windows/osx, I assume `DeepSpeechConsole` is built for test, so the same applies for `DeepSpeechConsoleNetCore`",understanding net framework right build process similar case matter example new net core yes end inside function add new one call sense maintenance wise prefer two well one weird way mean script script need need almost separate need native client resolve correct automatically based set deploy select correct one start based talking sample net core console related console sample built specific contain necessary run upon assume built test,issue,positive,positive,neutral,neutral,positive,positive
708299987,"Also, its not sure the build env will be similar between net framework build on Windows and net Core on linux... ",also sure build similar net framework build net core,issue,negative,positive,positive,positive,positive,positive
708298237,"> > It was my understanding that Net Framework was Windows only ?
> 
> you're right, but the build process is very similar, for this case, it seems just a matter of replacing `TargetFramework` [here](https://github.com/mozilla/DeepSpeech/blob/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/taskcluster/tc-build-utils.sh#L256) (example) for new net core steps to be `netcoreapp3.1` and `netstandard2.1`

Yes but if you do so, you end up having to `if` inside the function while if you add a new one you can just call it on platforms where it makes sense only.

So maintenance wise i prefer we have two sets of well scoped functions that one doing multiplatforms in a weird way. ",understanding net framework right build process similar case matter example new net core yes end inside function add new one call sense maintenance wise prefer two well one weird way,issue,positive,positive,neutral,neutral,positive,positive
708296174,"> It was my understanding that Net Framework was Windows only ?

you're right, but the build process is very similar, for this case, it seems just a matter of replacing `TargetFramework` [here](https://github.com/mozilla/DeepSpeech/blob/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/taskcluster/tc-build-utils.sh#L256) (example) for new net core steps to be `netcoreapp3.1` and `netstandard2.1`",understanding net framework right build process similar case matter example new net core,issue,negative,positive,neutral,neutral,positive,positive
708294312,"Remember also that each flavor you add will require testing on the CI, and this can be a lot of efforts. ",remember also flavor add require testing lot,issue,negative,neutral,neutral,neutral,neutral,neutral
708293482,"> it seems like the easiest way is to update the current steps by:
> `do_deepspeech_netframework_build` - add builds for more runtimes (Linux,arm)

It was my understanding that Net Framework was Windows only ?

But i advise strongly against updating and i really prefer we have a different codepath for Net Core. ",like easiest way update current add arm understanding net framework advise strongly really prefer different net core,issue,positive,positive,neutral,neutral,positive,positive
708292103,"> Actually Linux it's the main reason for doing it :)

You should have mentionned that from the start, because supporting that usecase is a whole lot more efforts CI wise. 

> hm, not completely sure how cross-compiling works,

Please read the docs, the `tc-build-utils.sh` script as well as the makefiles.

I have no idea how .Net Core works on linux, and not even how/if it can handle cross compilation. But the thing tht we cannot do is native build on ARM hardware. ",actually main reason start supporting whole lot wise completely sure work please read script well idea core work even handle cross compilation thing native build arm hardware,issue,positive,positive,positive,positive,positive,positive
708291129,"> But again I'd really prefer if we could avoid over complexify the problem here. Maybe you can just add the .Net Core support to Windows and from there we can figure out how to support all Linux flavors.

I'm also interested to avoid complexity, so trying to find the easiest and effortless way to do that, and for now, it seems like the easiest way is to update the current steps by:
`do_deepspeech_netframework_build` - add builds for more runtimes (Linux,arm) and then in `do_nuget_build` pack it with appropriate `.so` files. that's should be enough to make it work in net core on all basic platforms like win, osx, linux..",really prefer could avoid complexify problem maybe add core support figure support also interested avoid complexity trying find easiest effortless way like easiest way update current add arm pack appropriate enough make work net core basic like win,issue,positive,positive,positive,positive,positive,positive
708287912,"> > I don't have ""full"" linux machine, so will use raspberry with raspbian os for test, will it be sufficient?
> 
> I'm not sure we should focus all our energy on linux right now for .Net, and please keep in mind that `libdeepspeech` for linux/armv7 and linux/aarch64 is cross-compiled, we don't build on native hardware (too slow).
> 
> Can't you also rely on cross-compilation ?

Actually Linux it's the main reason for doing it :)

hm, not completely sure how cross-compiling works, but if `.so` file that nuget contains will work on the target platform - that shouldn't be a problem. for example, `.so` file for `amd64.cpu.linux` - it's seems to be `linux-x64` runtime, and `arm64.cpu.linux` it's `linux-arm64` etc.",full machine use raspberry o test sufficient sure focus energy right please keep mind build native hardware slow ca also rely actually main reason completely sure work file work target platform problem example file,issue,positive,positive,positive,positive,positive,positive
708284395,But again I'd really prefer if we could avoid over complexify the problem here. Maybe you can just add the .Net Core support to Windows and from there we can figure out how to support all Linux flavors.,really prefer could avoid complexify problem maybe add core support figure support,issue,negative,positive,positive,positive,positive,positive
708283313,"> Also question - do we need to separate net core from net framework builds? I don't see too much difference, but if it will be the same build - probably need to update its name

If you want to be able to handle building on linux, you will need to. This way you can add calls on linux build scripts.



> Not sure what is the best way to accomplish this, but we need to do it before packing nuget [here](https://github.com/mozilla/DeepSpeech/blob/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/taskcluster/tc-build-utils.sh#L337). That's seems to be a good place to insert additional dll's and `.so`.

Just consider we can add a new taskcluster task that just does the nuget pack step, pulling `.so` from other task.",also question need separate net core net framework see much difference build probably need update name want able handle building need way add build sure best way accomplish need good place insert additional consider add new task pack step task,issue,positive,positive,positive,positive,positive,positive
708280905,"> > So wondering if I can access all needed `.so` files for different architectures during call `do_nuget_build` to generate an updated nuget structure?
> 
> Maybe do like we d o with NodeJS: build platform nuget everywhere, and merge all platforms after?

Not sure what is the best way to accomplish this, but we need to do it before packing nuget [here](https://github.com/mozilla/DeepSpeech/blob/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/taskcluster/tc-build-utils.sh#L337). That's seems to be a good place to insert additional dll's and `.so`.

so we basically need to adjust build steps to be able to create a similar folder structure
![image](https://user-images.githubusercontent.com/10140906/95970323-7d5a3580-0e18-11eb-9787-30e786f1b1eb.png)

Also question - do we need to separate net core from net framework builds? I don't see too much difference, but if it will be the same build - probably need to update its name 

",wondering access different call generate structure maybe like build platform everywhere merge sure best way accomplish need good place insert additional basically need adjust build able create similar folder structure image also question need separate net core net framework see much difference build probably need update name,issue,positive,positive,positive,positive,positive,positive
708249749,"> I don't have ""full"" linux machine, so will use raspberry with raspbian os for test, will it be sufficient?

I'm not sure we should focus all our energy on linux right now for .Net, and please keep in mind that `libdeepspeech` for linux/armv7 and linux/aarch64 is cross-compiled, we don't build on native hardware (too slow).

Can't you also rely on cross-compilation ?",full machine use raspberry o test sufficient sure focus energy right please keep mind build native hardware slow ca also rely,issue,positive,positive,positive,positive,positive,positive
708246407,"> So wondering if I can access all needed `.so` files for different architectures during call `do_nuget_build` to generate an updated nuget structure?

Maybe do like we d o with NodeJS: build platform nuget everywhere, and merge all platforms after?",wondering access different call generate structure maybe like build platform everywhere merge,issue,negative,neutral,neutral,neutral,neutral,neutral
708068214,"@carlfm01 after playing around with libraries I was able to build nuget manually. It unpacking native lib based on runtime, which allows putting `.so` files with the same name in different folders, and use correct `.so` at runtime. (can't attach nuget here since it's bigger than 10mb).

Still was not able to test it on Linux because noticed that my raspberry running on `linux-arm` runtime, which is 32bit, but deployment was successful, an error that occurred for me was exact when lib for a different architecture.
Btw - not sure how to use `.so` for raspberry cpu from nuget, since for runtime it still will be one of the RID's which already have `.so` (`linux-x64`,`linux-arm64`), but I assume it's an edge case. and a workaround is by replacing `.so` file after build.

So wondering if I can access all needed `.so` files for different architectures during call `do_nuget_build` to generate an updated nuget structure?",around able build manually native based name different use correct ca attach since bigger still able test raspberry running bit deployment successful error exact different architecture sure use raspberry since still one rid already assume edge case file build wondering access different call generate structure,issue,positive,positive,positive,positive,positive,positive
707871653,"> Thanks for the PR, few questions
> 
> ¿Have you tested what happens on Linux?
> Since we only pack the .so for Windows we need it for non Windows as well, we need the NuGet to be able to unpack the so with the same name as Windows, if the Nuget is not able to unpack with the same name wee need to add conditional compilation or patch `NativeImp.cs` to select the so to select the name based on the platform.
> ¿Naudio keeps the same API surface for .NetCore?

Was not able to test it on Linux yet (will try to test it today) but after a closer look - yeah, need to think about how to do it correctly, since net core is cross-platform we need to include `so` files (cpu and gpu)  for - osx, linux, windows, raspberry.
Hope it's possible through build, to avoid adjusting `NativeImpl`
I will investigate that and will try to adjust build pipeline

Seems like `NAudio` doesn't work on linux out of the box, so probably will need to adjust the code. I'll check that after running on Linux.

I don't have ""full"" linux machine, so will use raspberry with raspbian os for test, will it be sufficient?",thanks tested since pack need non well need able unpack name able unpack name wee need add conditional compilation patch select select name based platform surface able test yet try test today closer look yeah need think correctly since net core need include raspberry hope possible build avoid investigate try adjust build pipeline like work box probably need adjust code check running full machine use raspberry o test sufficient,issue,positive,positive,positive,positive,positive,positive
707750795,"> @lissyx thanks a lot for your feedback, I will review/fix PR and will try to set up build and tests for that

Thanks @stepkillah ! One thing I thought about after is that you don't provide doc update / dependencies infos, I'm sure we need some ; just to even be able to add missing bits on our CI: https://github.com/mozilla/DeepSpeech/tree/51e351e895b845e48f64f2ccb84d3bbb2b0d3379/native_client/dotnet#building-deepspeech-native-client-for-windows",thanks lot feedback try set build thanks one thing thought provide doc update sure need even able add missing,issue,positive,positive,positive,positive,positive,positive
707730849,"@lissyx thanks a lot for your feedback, I will review/fix PR and will try to set up build and tests for that",thanks lot feedback try set build,issue,negative,positive,positive,positive,positive,positive
707688284,"@stepkillah It's mostly about bash glue to perform the builds, so you should be able to add your own dotnetcore alternatives and @carlfm01 and myself we can help you working on that.

Given I know nothing about .Net, I can't really judge your current PR and I'm unable to check whether it works or not (no Windows either), so having CI is kind of critical here.

Don't hesitate to reach for help on those matters on Matrix: https://chat.mozilla.org/#/room/#machinelearning:mozilla.org",mostly bash glue perform able add help working given know nothing ca really judge current unable check whether work either kind critical hesitate reach help matrix,issue,positive,positive,positive,positive,positive,positive
707584614,"> The command line here fails, does not work
> 
> https://deepspeech.readthedocs.io/en/v0.8.2/TRAINING.html#making-a-mmap-able-model-for-inference has the correct command line

""does not work"" is not useful feedback. ",command line work correct command line work useful feedback,issue,negative,positive,positive,positive,positive,positive
707515764,"The command line here fails, does not work

https://deepspeech.readthedocs.io/en/v0.8.2/TRAINING.html#making-a-mmap-able-model-for-inference has the correct command line",command line work correct command line,issue,negative,neutral,neutral,neutral,neutral,neutral
707171562,"Also even with the correct URL, artifact expired and we cant republish it for macos. ",also even correct artifact cant republish,issue,negative,neutral,neutral,neutral,neutral,neutral
704962869,"@FurkanGozukara merhaba! Discourse [burada](https://discourse.mozilla.org/c/mozilla-voice-stt/247) bulabilirsin. Burada GitHub issues'da kullancılara yardım edebilmiyoruz, maalesef. Discourse'ta bir yeni post yap lütfen!",discourse yeni post yap,issue,negative,neutral,neutral,neutral,neutral,neutral
704842154,Next time i'll report to github for harrasment if you keep ignoring our code of conduct and use github issues instead of Discourse. ,next time report keep code conduct use instead discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
704785578,"@imrahul361 Note for later: can you rebase your PR this way? First commit should be the JS binding fix, then a second commit should be all your changes to add hot words to the JS client and the run of tests on CI.",note later rebase way first commit binding fix second commit add hot client run,issue,positive,positive,positive,positive,positive,positive
704783385,"> Hello. Can anyone point a tutorial to use DeepSpeech with C#? I just need where to download latest database and how to convert an MP3 audio file to text
> 
> @carlfm01

Are you going to spam all the issues ? This is my last warning.",hello anyone point tutorial use need latest convert audio file text going last warning,issue,negative,positive,positive,positive,positive,positive
704781611,"> @lissyx can you please point me a link where it is extensively covered?

Have you had a look at our documentation ? It does not looks like you did.

Two first links:
 - ""Using a pre-trained model"" https://deepspeech.readthedocs.io/en/v0.8.2/USING.html
 - ""Training your own model"" https://deepspeech.readthedocs.io/en/v0.8.2/TRAINING.html
 - .Net API reference: https://deepspeech.readthedocs.io/en/v0.8.2/DotNet-API.html
 - .Net usage example: https://deepspeech.readthedocs.io/en/v0.8.2/DotNet-Examples.html

What part did you not understand in ""this is not a discussion space, please reach for support on Discourse"" ?",please point link extensively covered look documentation like two first link model training model reference usage example part understand discussion space please reach support discourse,issue,positive,positive,positive,positive,positive,positive
704781353,"Hello. Can anyone point a tutorial to use DeepSpeech with C#? I just need where to download latest database and how to convert an MP3 audio file to text

@carlfm01 ",hello anyone point tutorial use need latest convert audio file text,issue,negative,positive,positive,positive,positive,positive
704780044,@lissyx can you please point me a link where it is extensively covered?,please point link extensively covered,issue,negative,neutral,neutral,neutral,neutral,neutral
704779076,"@FurkanGozukara Please read and apply the issue template: this is a support request, so please ask on Discourse. All of your questions are extensively covered by our docs and forums.",please read apply issue template support request please ask discourse extensively covered,issue,positive,neutral,neutral,neutral,neutral,neutral
704352034,"Hi @lucalazzaroni thanks for your interest, [as @lissyx says](https://github.com/mozilla/DeepSpeech/issues/3064#issuecomment-644219503) this is probably not going to work in the short term. I suggest opening a post on [Discourse](https://discourse.mozilla.org/c/mozilla-voice-stt/) or joining us on [Matrix](https://chat.mozilla.org/#/room/#machine-learning:mozilla.org) if you are interested in participating in getting this working. I'll close this for now as a duplicate of #2332.",hi thanks interest probably going work short term suggest opening post discourse joining u matrix interested getting working close duplicate,issue,positive,positive,positive,positive,positive,positive
704208183,Hmm unfortunately I can't reproduce with what I thought could trigger it (run training and validation on the same sorted by wav_size csv's). :(,unfortunately ca reproduce thought could trigger run training validation sorted,issue,negative,negative,negative,negative,negative,negative
704087248,"> > > Thanks @imrahul361 that's a good start. Can you also add `run_hotword_tests` calls to `taskcluster/tc-node-tests.sh` and `taskcluster/tc-node_tflite-tests.sh` to cover for CI ?
> > 
> > 
> > I need to check for that once. Last time, I had tried to run the binary on local. I messed few things up.
> > _I need some time to be comfortable with it_ @lissyx
> 
> It's not intended to be run locally

ok then please guide me how can I  do that task? @lissyx ",thanks good start also add cover need check last time tried run binary local need time comfortable intended run locally please guide task,issue,positive,positive,positive,positive,positive,positive
704085927,"> > Thanks @imrahul361 that's a good start. Can you also add `run_hotword_tests` calls to `taskcluster/tc-node-tests.sh` and `taskcluster/tc-node_tflite-tests.sh` to cover for CI ?
> 
> I need to check for that once. Last time, I had tried to run the binary on local. I messed few things up.
> _I need some time to be comfortable with it_ @lissyx

It's not intended to be run locally",thanks good start also add cover need check last time tried run binary local need time comfortable intended run locally,issue,positive,positive,positive,positive,positive,positive
704082761,"> Thanks @imrahul361 that's a good start. Can you also add `run_hotword_tests` calls to `taskcluster/tc-node-tests.sh` and `taskcluster/tc-node_tflite-tests.sh` to cover for CI ?

I need to check for that once. Last time, I had tried to run the binary on local. I messed few things up.
_I need some time to be comfortable with it_   @lissyx ",thanks good start also add cover need check last time tried run binary local need time comfortable,issue,positive,positive,positive,positive,positive,positive
703754672,Can you push another commit where you don't make all those spacing changes? :),push another commit make spacing,issue,negative,neutral,neutral,neutral,neutral,neutral
703554719,"Just writing down some notes from my talk with Bernardo last week on the status of this PR:

- We fixed out a segfault due to passing an address of a temporary
- Bernardo is going to do add some timing calls in the scorer loading code to figure out if the slowdown is coming from the extra copy on the client.cc side (in which case it doesn't matter) or if the slowdown is inside libdeepspeech, in which case it needs to be addressed.
- Then we need to make sure all the bindings get covered and there's test coverage as mentioned by @lissyx above",writing talk last week status fixed due passing address temporary going add timing scorer loading code figure slowdown coming extra copy side case matter slowdown inside case need need make sure get covered test coverage,issue,negative,positive,neutral,neutral,positive,positive
702557793,"> Is there any update on .NetCore side? Are you guys going to look into this?

As I already stated, .Net is maintained by only @carlfm01 and he could use some help.",update side going look already stated could use help,issue,negative,neutral,neutral,neutral,neutral,neutral
702552731,Is there any update on .NetCore side? Are you guys going to look into this?,update side going look,issue,negative,neutral,neutral,neutral,neutral,neutral
702347162,"Yeah it is still on my todo list, but I also still have seen the error at least once.
I think you can still have a cache hit while other stuff in the descriptor still differs (from memory .. , I thought rnn_mode was a likely candidate).

I think the pattern for this is when you have the same sequence lengths etc. in both train and dev set. Should be easy testable (just use the same csv (and keep the ordering the same) for both train and dev datasets), but I haven't come around to actually do it. I hope to get to testing this tomorrow or this weekend.

Still wondering if the whole caching idea doesn't do more harm than good. 
It seems error prone, and if you need to check everything element the cost for checking each time seems non-negligible (as your test seemed to indicate where you didn't find that much difference in training times
with or without the TF_CUDNN_RESET_RND_GEN_STATE env var.

Unfortunately there was no reaction from the nvidia guy, seems like it is needed to open a new report. I will after testing.

But perhaps it is still a good idea to implement setting the environment var from deepspeech training code any way ?
As I don't think there will be a Tensorflow (1.15.5) release any time soon and most certainly not before a probable deepspeech 1.0 release.",yeah still list also still seen error least think still cache hit stuff still memory thought likely candidate think pattern sequence train dev set easy testable use keep train dev come around actually hope get testing tomorrow weekend still wondering whole idea harm good error prone need check everything element cost time test indicate find much difference training time without unfortunately reaction guy like open new report testing perhaps still good idea implement setting environment training code way think release time soon certainly probable release,issue,positive,positive,positive,positive,positive,positive
702204567,"@zaptrem we now have test coverage of valgrind on linux/amd64 (#3356) on both non metadata and metadata API usages, and it does not show any `definitely` lost on deepspeech side, so hopefully you can manage time to investigate more closely here, provided that we will have those debug builds available out of taskcluster as well for you to use. I don't know Android Studio, but I guess with debug symbol it will be easier to spot?",test coverage non show definitely lost side hopefully manage time investigate closely provided available well use know android studio guess symbol easier spot,issue,positive,positive,positive,positive,positive,positive
702160133,">     * 
> 
> 
> The work that needs to be completed remains:
> 
>     * generate well known tensorflow, tflite and sox suppressions lists
> 
>     * get 0 error on CI with those suppressions lists
> 
>     * enable `--error-exitcode=1` on valgrind runs

Done and green on TC.",work need remains generate well known get error enable done green,issue,negative,negative,negative,negative,negative,negative
702158560,I think @applied-machinelearning mentionned something like that on upstream issue ?,think something like upstream issue,issue,negative,neutral,neutral,neutral,neutral,neutral
702151300,"> Can you triple check if you run 1.15.4 ?

Running `python3 -c 'import tensorflow as tf; print(tf.__version__)'` gives me exactly `1.15.4`.

> I'm unfortunately not in the position to have the time to investigate like that anymore for the forseeable future.

No problem for me, the solution is easy, so I just will add the extra flag everywhere.

<br>

Not sure this helps, but for me the error always gets thrown in validation phase, the first training epoch is finishing without errors.
This also happens if I switch train and dev datasets. So I don't think the problem lies in the dataset here.",triple check run running python print exactly unfortunately position time investigate like future problem solution easy add extra flag everywhere sure error always thrown validation phase first training epoch finishing without also switch train dev think problem,issue,negative,positive,positive,positive,positive,positive
702136451,"> Still not working for me with up to date master and newly created docker container.

Can you triple check if you run 1.15.4 ?

> But as mentioned somewhere above, running `export TF_CUDNN_RESET_RND_GEN_STATE=1` solved my problem.

Maybe there are some other bugs. As you can see, it was quite painful to investigate already even with a small repro dataset. I'm unfortunately not in the position to have the time to investigate like that anymore for the forseeable future.",still working date master newly docker container triple check run somewhere running export problem maybe see quite painful investigate already even small unfortunately position time investigate like future,issue,negative,negative,negative,negative,negative,negative
702131940,"Still not working for me with up to date master and newly created docker container. 
But as mentioned somewhere above, running `export TF_CUDNN_RESET_RND_GEN_STATE=1` solved my problem.",still working date master newly docker container somewhere running export problem,issue,negative,positive,positive,positive,positive,positive
702038943,"> I like to work on it? Is it available? @lissyx

Yes, you are welcome. I guess it'd be more efficient if you can join us on Matrix for helping you about the codebase!",like work available yes welcome guess efficient join u matrix helping,issue,positive,positive,positive,positive,positive,positive
701989730,"We have basic valgrind running on the C++ client in:
 - non streaming mode
 - streaming mode
 - non streaming, metadata interface
 - streaming, metadata interface

The work that needs to be completed remains:
 - generate well known tensorflow, tflite and sox suppressions lists
 - get 0 error on CI with those suppressions lists
 - enable `--error-exitcode=1` on valgrind runs",basic running client non streaming mode streaming mode non streaming interface streaming interface work need remains generate well known get error enable,issue,negative,neutral,neutral,neutral,neutral,neutral
701988932,"This will only be on linux/android for the moment. People interesting in other platforms, patches are welcome.",moment people interesting welcome,issue,positive,positive,positive,positive,positive,positive
701964890,"@zaptrem This should be a first Android ARM64 debug build of `libdeepspeech.so` https://community-tc.services.mozilla.com/api/queue/v1/task/HLaulg-PTOiFoqGLLH-EOg/runs/0/artifacts/public/native_client.tar.xz based on current master. It would really be useful if you could investigate on Android side with this debug build, so we can identify where the leak comes from, since I can't repro here.

(this link will be valid for 7 days)",first android arm build based current master would really useful could investigate android side build identify leak come since ca link valid day,issue,negative,positive,positive,positive,positive,positive
701961457,"> even when the metadata calls are commented out (that’s why both are there)

Which is what I tested as non leaky on C++ client, and verified that the Java generated code was properly calling `DS_FreeString` as stated above.



> Were you able to reproduce by running the example app?

I'm sorry but I will not be able to investigate this code: I don't know Kotlin, I have not written the example code, it would take me way too much time to get up to speed there.",even tested non leaky client code properly calling stated able reproduce running example sorry able investigate code know written example code would take way much time get speed,issue,negative,positive,positive,positive,positive,positive
701938270,"> > That’s great news, right?
> > […](#)
> > On Tue, Sep 29, 2020 at 8:42 AM lissyx _**@**_.***> wrote: The definitely lost seems to be a hint but the leak is low (but only one file analyzed). And I can confirm this is because of the implementation in client.cc, JNI part seems to be okay. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#3271 (comment)](https://github.com/mozilla/DeepSpeech/issues/3271#issuecomment-700676669)>, or unsubscribe https://github.com/notifications/unsubscribe-auth/AAMJTRRSOEBSXOLNQ2SMEG3SIHI4HANCNFSM4QI7OFOQ .
> 
> So, since it looks like your code also calls the Metadata, all the analysis I did was for nothing, since I assumed you were calling the non metadata functions ...

Thanks for mentioning that delete function. HOWEVER, the leak remains (as far as I can remember, it’s been over a month, I’ll double check in the morning) even when the metadata calls are commented out (that’s why both are there). Were you able to reproduce by running the example app?",great news right tue wrote definitely lost hint leak low one file confirm implementation part reply directly view comment since like code also analysis nothing since assumed calling non thanks delete function however leak remains far remember month double check morning even able reproduce running example,issue,positive,positive,positive,positive,positive,positive
701597100,"> That’s great news, right?
> […](#)
> On Tue, Sep 29, 2020 at 8:42 AM lissyx ***@***.***> wrote: The definitely lost seems to be a hint but the leak is low (but only one file analyzed). And I can confirm this is because of the implementation in client.cc, JNI part seems to be okay. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#3271 (comment)](https://github.com/mozilla/DeepSpeech/issues/3271#issuecomment-700676669)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAMJTRRSOEBSXOLNQ2SMEG3SIHI4HANCNFSM4QI7OFOQ> .

So, since it looks like your code also calls the Metadata, all the analysis I did was for nothing, since I assumed you were calling the non metadata functions ...",great news right tue wrote definitely lost hint leak low one file confirm implementation part reply directly view comment since like code also analysis nothing since assumed calling non,issue,positive,positive,positive,positive,positive,positive
701595003,"@zaptrem I know nothing about kotlin nor your code, but there is something I don't get there:
```
    model?.let { model ->
      streamContext?.let { streamContext ->
        val shortArray = ShortArray(audioRecordData.size / 2) {
          (audioRecordData[it * 2].toUByte().toInt() + (audioRecordData[(it * 2) + 1].toInt() shl 8)).toShort()
        }
        model.feedAudioContent(streamContext, shortArray, shortArray.size)
        val decoded = model.intermediateDecodeWithMetadata(streamContext, 1)
        val decodedString = model.intermediateDecode(streamContext)

        if(decodedString != lastTranscription){
          lastTranscription = decodedString
          val map = packageTranscription(decoded)
          emitDeviceEvent(""onRecordingChange"", map)
          Log.d(""transcription"", decodedString)
        }
      }
    }
```

Aside, it took me half an hour navigating in your code to find where the calls where. We would have saved everybody a lot of time if you had directly linked to the ""streaming transcription uses"" you referred to instead of just linking to the repo.

First, why do you call both `intermediateDecodeWithMetadata` and `intermediateDecode` ?

Second, I don't see any `finalize()` nor `delete()` call on the `Metadata` object, which is how the bindings will call `DS_FreeMetadata()` and that is, as much as we know, the canonical way to handle that in Java. I have no idea if it is up to you or the VM's job to call `delete()`.

```
$ cat native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/Metadata.java 
/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 4.0.2
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package org.mozilla.deepspeech.libdeepspeech;

public class Metadata {
  private transient long swigCPtr;
  protected transient boolean swigCMemOwn;

  protected Metadata(long cPtr, boolean cMemoryOwn) {
    swigCMemOwn = cMemoryOwn;
    swigCPtr = cPtr;
  }

  protected static long getCPtr(Metadata obj) {
    return (obj == null) ? 0 : obj.swigCPtr;
  }

  @SuppressWarnings(""deprecation"")
  protected void finalize() {
    delete();
  }

  public synchronized void delete() {
    if (swigCPtr != 0) {
      if (swigCMemOwn) {
        swigCMemOwn = false;
        implJNI.delete_Metadata(swigCPtr);
      }
      swigCPtr = 0;
    }
  }

  public long getNumTranscripts() {
    return implJNI.Metadata_NumTranscripts_get(swigCPtr, this);
  }

  public CandidateTranscript getTranscript(int i) {
    return new CandidateTranscript(implJNI.Metadata_getTranscript(swigCPtr, this, i), false);
  }

}
```

So if `DS_FreeMetadata()` is never called, it would not be surprising you observe a leak, but it is obviously not a bug on our side if that is the case.",know nothing code something get model model map map transcription aside took half hour code find would saved everybody lot time directly linked streaming transcription instead linking first call second see finalize delete call object call much know canonical way handle idea job call delete cat file automatically swig version make file unless know modify swig interface file instead package public class private transient long transient long static long return null deprecation void finalize delete public synchronized void delete false public long return public return new false never would surprising observe leak obviously bug side case,issue,negative,positive,neutral,neutral,positive,positive
701586647,"I might have found a middle-ground to provide debug builds + valgrind, with the following limitations:
 - valgrind only on linux/amd64
 - debug builds on all linux flavors, as much as I can hope, but still to be confirmed
 - this should also cover android
 - this might work on macOS and Windows, but I will not spend too much time on that
 - CUDA might be too painful for that (`libdeepspeech.so` for CUDA > 2GB, that is triggering infra issues)
 - you would have to use those `libdeepspeech.so` debug build by swapping the `libdeepspeech.so` inside packages, building full blown two flavors efficiently would require too much CI work",might found provide following much hope still confirmed also cover android might work spend much time might painful infra would use build swapping inside building full blown two efficiently would require much work,issue,negative,positive,neutral,neutral,positive,positive
701480062,"@lissyx yep, I'm trying to squash the commits, sorry.",yep trying squash sorry,issue,negative,negative,negative,negative,negative,negative
701477896,"@bernardohenz I see some merges, can you make sure this branch is clean of merges ?",see make sure branch clean,issue,positive,positive,positive,positive,positive,positive
701292464,"Unfortunately:
 - tensorflow does not seems to care much about debug builds, given how `-c dbg` fails mostly everywhere on CI
 - tensorflow or bazel does not respect `--strip=never` nor anything
 - so there's mostly no way to produce debug builds / symbols on CI (i've already burnt a few days on that, with no success)
 - there's also no way to separately generate debug symbols, so it's mostly useless to run `valgrind` on our CI",unfortunately care much given mostly everywhere respect anything mostly way produce already burnt day success also way separately generate mostly useless run,issue,positive,positive,neutral,neutral,positive,positive
700698010,"> That’s great news, right?
> […](#)
> On Tue, Sep 29, 2020 at 8:42 AM lissyx ***@***.***> wrote: The definitely lost seems to be a hint but the leak is low (but only one file analyzed). And I can confirm this is because of the implementation in client.cc, JNI part seems to be okay. — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#3271 (comment)](https://github.com/mozilla/DeepSpeech/issues/3271#issuecomment-700676669)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAMJTRRSOEBSXOLNQ2SMEG3SIHI4HANCNFSM4QI7OFOQ> .

That depends, if you confirm or not my analysis ...",great news right tue wrote definitely lost hint leak low one file confirm implementation part reply directly view comment confirm analysis,issue,negative,positive,positive,positive,positive,positive
700690265,"The sources I sent seem to indicate dynamic libraries are allowed
(otherwise, how would any TensorFlow app work on iOS?) but they must be
wrapped in a framework. I tried setting the project to also embed
libdeepspeech, but then it acted like the .so wasn’t included at all. I
tried embedding, copying to the bundle as a resource, and copying as a
“framework” and none seemed to work. One of the sources suggested using a
really low level tool to convert the file to a specific binary format to
insert it into a framework manually, but that seems like the sort of thing
that needs to be built into the TaskCluster.

On Tue, Sep 29, 2020 at 5:00 AM Reuben Morais <notifications@github.com>
wrote:

>
>
> I'm seeing conflicting answers in the discussion here: is the problem that
> dynamic libraries aren't allowed at all? Is it that the dynamic library
> must be inside a framework? The latter is probably easier to fix than the
> former. You should be able to set the deepspeech_ios project to also embed
> libdeepspeech.so. If that works, please send a PR with the relevant
> changes. For static builds it's a much more complicated situation as I
> mentioned above: #3061 (comment)
> <https://github.com/mozilla/DeepSpeech/issues/3061#issuecomment-680839647>
>
>
>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3061#issuecomment-700568162>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAMJTRR4OW7NCVH4B2VKKIDSIGO4RANCNFSM4N5MDJDQ>
> .
>
>
>
",sent seem indicate dynamic otherwise would work must wrapped framework tried setting project also embed like included tried bundle resource framework none work one really low level tool convert file specific binary format insert framework manually like sort thing need built tue wrote seeing conflicting discussion problem dynamic dynamic library must inside framework latter probably easier fix former able set project also embed work please send relevant static much complicated situation comment reply directly view,issue,positive,positive,neutral,neutral,positive,positive
700687662,"That’s great news, right?

On Tue, Sep 29, 2020 at 8:42 AM lissyx <notifications@github.com> wrote:

>
>
>
>
> The definitely lost seems to be a hint but the leak is low (but only one
> file analyzed).
>
>
>
>
> And I can confirm this is because of the implementation in client.cc, JNI
> part seems to be okay.
>
>
>
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3271#issuecomment-700676669>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAMJTRRSOEBSXOLNQ2SMEG3SIHI4HANCNFSM4QI7OFOQ>
> .
>
>
>
",great news right tue wrote definitely lost hint leak low one file confirm implementation part reply directly view,issue,negative,positive,positive,positive,positive,positive
700676669,"> The `definitely lost` seems to be a hint but the leak is low (but only one file analyzed).

And I can confirm this is because of the implementation in `client.cc`, JNI part seems to be okay.",definitely lost hint leak low one file confirm implementation part,issue,negative,neutral,neutral,neutral,neutral,neutral
700670929,"> I've performed a small time benchmark for running the client (both for loading a .b and a .tflite):

Just for the sake of completeness, can you add figures for **before** your changes?



> I've fixed the API functions exposition, tested the loading for TFLite.

Good, so now it's just about:
 - exposing through all our bindings,
 - gettings builds green,
 - and adding some test coverage,

Right?",small time running client loading sake completeness add fixed exposition tested loading good green test coverage right,issue,negative,positive,positive,positive,positive,positive
700666037,"One can verify the JNI part:
```
$ less native_client/java/jni/deepspeech_wrap.cpp
[...]
SWIGEXPORT jstring JNICALL Java_org_mozilla_deepspeech_libdeepspeech_implJNI_IntermediateDecode(JNIEnv *jenv, jclass jcls, jlong jarg1) {
  jstring jresult = 0 ;
  StreamingState *arg1 = (StreamingState *) 0 ;
  char *result = 0 ;
  
  (void)jenv;
  (void)jcls;
  arg1 = *(StreamingState **)&jarg1; 
  result = (char *)DS_IntermediateDecode((StreamingState const *)arg1);
  if (result) jresult = jenv->NewStringUTF((const char *)result);
  DS_FreeString(result);
  return jresult;
}
[...]
```

So there is an explicit call to `DS_FreeString`",one verify part le jarg char result void void jarg result char result char result result return explicit call,issue,negative,neutral,neutral,neutral,neutral,neutral
700642350,"@zaptrem ping? Have you been able to qualify better the issue? I have been able to have a look, comparing non stream vs stream uses via the C++ client,

(this is on current master, c7d58d628e6f701ce3575a44ef9282730ec02ab3)

Non Stream:
```
==1401849== LEAK SUMMARY:
==1401849==    definitely lost: 0 bytes in 0 blocks
==1401849==    indirectly lost: 0 bytes in 0 blocks
==1401849==      possibly lost: 0 bytes in 0 blocks
==1401849==    still reachable: 8,260 bytes in 103 blocks
==1401849==         suppressed: 0 bytes in 0 blocks
```

The `still reachable` are all from `libsox` according to what I could analyze.

Stream:
```
==2125011== LEAK SUMMARY:
==2125011==    definitely lost: 20 bytes in 3 blocks
==2125011==    indirectly lost: 0 bytes in 0 blocks
==2125011==      possibly lost: 0 bytes in 0 blocks
==2125011==    still reachable: 8,260 bytes in 103 blocks
==2125011==         suppressed: 0 bytes in 0 blocks
```

And it would come from the intermediate decode:
```
 240 ==2125011== 20 bytes in 3 blocks are definitely lost in loss record 17 of 104                                                                                                                                                                                                                                                                                            241 ==2125011==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                            242 ==2125011==    by 0x5E93F0A: strdup (strdup.c:42)                                                                                                                                                                                                                                                                                                                        243 ==2125011==    by 0x4A12003: ModelState::decode(DecoderState const&) const (modelstate.cc:36)                                                                                                                                                                                                                                                                            244 ==2125011==    by 0x4A067AD: StreamingState::intermediateDecode() const (deepspeech.cc:137)                                                                                                                                                                                                                                                                             
 245 ==2125011==    by 0x4A0776B: DS_IntermediateDecode (deepspeech.cc:458)                                                                                                                                                                                                                                                                                                   246 ==2125011==    by 0x11ADBF: LocalDsSTT(ModelState*, short const*, unsigned long, bool, bool) (in /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx/native_client/deepspeech)                                                                                                                                                                          247 ==2125011==    by 0x11B3A7: ProcessFile(ModelState*, char const*, bool) (in /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx/native_client/deepspeech)                                                                                                                                                                                               248 ==2125011==    by 0x11BB05: main (in /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx/native_client/deepspeech)                                                                                                                                                                                                                                     
```

The  `definitely lost` seems to be a hint but the leak is low (but only one file analyzed).

Does this matches your experience? Do you have higher volume of leaking?",ping able qualify better issue able look non stream stream via client current master non stream leak summary definitely lost indirectly lost possibly lost still reachable suppressed still reachable according could analyze stream leak summary definitely lost indirectly lost possibly lost still reachable suppressed would come intermediate decode definitely lost loss record short unsigned long bool bool char bool main definitely lost hint leak low one file experience higher volume,issue,negative,positive,positive,positive,positive,positive
700568162,"I'm seeing conflicting answers in the discussion here: is the problem that dynamic libraries aren't allowed at all? Is it that the dynamic library must be inside a framework? The latter is probably easier to fix than the former. You should be able to set the deepspeech_ios project to also embed libdeepspeech.so. If that works, please send a PR with the relevant changes. For static builds it's a much more complicated situation as I mentioned above: https://github.com/mozilla/DeepSpeech/issues/3061#issuecomment-680839647",seeing conflicting discussion problem dynamic dynamic library must inside framework latter probably easier fix former able set project also embed work please send relevant static much complicated situation,issue,positive,positive,positive,positive,positive,positive
700566681,"> Yes, I'm already doing that because the Metadata and Token arrays were (erroneously?) marked as `private(set)` instead of `public private(set)`.

PRs are welcome.",yes already token erroneously marked private set instead public private set welcome,issue,positive,positive,positive,positive,positive,positive
700469534,"Pleases don't double post, we'll let it stay here as it is a more technical question.",double post let stay technical question,issue,negative,neutral,neutral,neutral,neutral,neutral
700330258,"@lissyx @reuben @xiaoqunSun @erksch looks like the libdeepspeech.so file must be bundled with the framework somehow. You aren’t allowed to put dynamic libraries directly in the main project, they must be wrapped in a .framework. I spent today trying to do that but haven’t been able to get the library to load when called by deepspeech_ios framework (misconfigured search paths/embedding strategy?). I hope these can help.

https://developer.apple.com/forums/thread/125796
https://stackoverflow.com/questions/57755276/create-ios-framework-with-dylib
https://stackoverflow.com/questions/53818772/embedding-a-dylib-inside-a-framework-for-ios
Thx Adidas?: https://www.runtastic.com/blog/en/frameworks-ios/",like file must framework somehow put dynamic directly main project must wrapped spent today trying able get library load framework search strategy hope help,issue,positive,positive,positive,positive,positive,positive
700172496,"Specifying the extension it should load the required file. Very strange it doesn't.

The extension should be automatically added only if not specified.

Doing something like:
[​DllImport​(​""​libdeepspeech.so""​)]

Should find the lib if available in the bin folder (in Windows).",extension load file strange extension automatically added something like find available bin folder,issue,negative,positive,positive,positive,positive,positive
700169659,"> You don't need to name the extension.
> Windows will use the .dll , Linux the .so

Exactly my point: we currently ship it named `libdeepspeech.so` on Windows, if the `DllImport()` code tries to be clever and only loads `libdeepspeech.dll` that might explain why it cannot find it ...",need name extension use exactly point currently ship code clever might explain find,issue,negative,positive,positive,positive,positive,positive
700168498,"Not tried this for this library, but I used it in other situations 
 My point is that if there is a problem with NetCore, it is not in the DllImport directive. ",tried library used point problem directive,issue,negative,neutral,neutral,neutral,neutral,neutral
700145842,"> You don't need to name the extension.
> Windows will use the .dll , Linux the .so
> 
> [​DllImport​(​""​libdeepspeech""​)]
> 
> In Linux you need to set the LD_ var. In Windows you need the lib available in bin folder.

Does this work for you?",need name extension use need set need available bin folder work,issue,negative,positive,positive,positive,positive,positive
700144277,"You don't need to name the extension.
Windows will use the .dll , Linux the .so

[​DllImport​(​""​libdeepspeech""​)]

In Linux you need to set the LD_ var. In Windows you need the lib available in bin folder.",need name extension use need set need available bin folder,issue,negative,positive,positive,positive,positive,positive
700143318,"> And so what happens on Windows if you name `.so` ?

the name does not matter, i've experimented with different names: .dll, .so, without extension for Windows it works for Linux no",name name matter experimented different without extension work,issue,negative,neutral,neutral,neutral,neutral,neutral
700141647,"> The not found exception might be that the lib path has not been added to env variable: LD_LIBRARY_PATH

That is only valid on linux, i think the previous comment about that refers to Windows ?



>  You don't need to specify the extension,you just need to specify the class name

And so what happens on Windows if you name `.so` ? ",found exception might path added variable valid think previous comment need specify extension need specify class name name,issue,negative,negative,negative,negative,negative,negative
700135046,"Just to clarify and avoid adding more confusion to this thread:

DllImport attribute IS supported by NetCore and would work in Linux:
https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.dllimportattribute?view=netcore-3.1

Not sure why has been stated otherwise, but even the .so extension is not an issue, since the .so imports would work in Linux , the .dll imports would work in Windows. You don't need to specify the extension,you just need to specify the class name.

The not found exception might be that the lib path has not been added to env variable: LD_LIBRARY_PATH",clarify avoid confusion thread attribute would work sure stated otherwise even extension issue since would work would work need specify extension need specify class name found exception might path added variable,issue,negative,positive,positive,positive,positive,positive
700130009,"I've fixed the API functions exposition, tested the loading for TFLite.

I've performed a small time benchmark for running the client (both for loading a .b and a .tflite):

Loading a dummy .pb
| Inputs                                                                          | Time for running ./deepspeech  <br/> Avg from 20 calls |
|---------------------------------------------------------------------------------|:------------------------------------------------:|
| model output_graph.pb                                                           | 0.54                                             |
| model output_graph.pb --init_from_bytes                                         | 0.55                                             |
| model output_graph.pb --scorer deepspeech-0.8.1-models.scorer                   | 1.45                                             |
| model output_graph.pb --scorer deepspeech-0.8.1-models.scorer --init_from_bytes | 4.56                                             |

Loading a .tflite
| Inputs                                                                                         | Time for running ./deepspeech  <br/> Avg from 20 calls |
|------------------------------------------------------------------------------------------------|:------------------------------------------------:|
| model deepspeech-0.8.2-models.tflite                                                           | 1.72                                             |
| model deepspeech-0.8.2-models.tflite --init_from_bytes                                         | 1.85                                             |
| model deepspeech-0.8.2-models.tflite --scorer deepspeech-0.8.1-models.scorer                   | 2.50                                              |
| model deepspeech-0.8.2-models.tflite --scorer deepspeech-0.8.1-models.scorer --init_from_bytes | 5.66                                             |

",fixed exposition tested loading small time running client loading loading dummy time running model model model scorer model scorer loading time running model model model scorer model scorer,issue,negative,negative,neutral,neutral,negative,negative
700124347,Hi @yashsehgal you could start by joining us on [#machinelearning](https://chat.mozilla.org/#/room/#machine-learning:mozilla.org) on Matrix. It will be a bit difficult to guide you through GitHub issues! Thanks for your interest :),hi could start joining u matrix bit difficult guide thanks interest,issue,positive,negative,negative,negative,negative,negative
700076109,"Hey Developers,
I am Yash Sehgal. I just started this project as my first open-source project. I think I can work on this feature and help you to remove the bug, Please guide me throughout the process.
Thanks",hey project first project think work feature help remove bug please guide throughout process thanks,issue,positive,positive,positive,positive,positive,positive
699991130,"> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).
> 
> Please describe the problem clearly. Be sure to convey here why it's a bug or a feature request.
> 
> Include any logs or source code that would be helpful to diagnose the problem. For larger logs, link to a Gist, not a screenshot. > If including tracebacks, please include the full traceback. Try to provide a reproducible test case.

@mayankpathaklumiq What don't you understand there?

Also, this is the second post in a row that you post without following basic guidelines, and providing 0 informations.",support please use discourse please describe problem clearly sure convey bug feature request include source code would helpful diagnose problem link gist please include full try provide reproducible test case understand also second post row post without following basic providing,issue,positive,positive,positive,positive,positive,positive
699947095,"> @lissyx dllimport is a built-in Windows feature, so it only works fine on Windows. Other platforms like linux or macos don't. I've ask the .net development team and they said they are working on a new modern feature to import native libraries.
> The problem is that the app doesn't provide enough information. Just throws FileNotFound exception.

This is still very much unclear here, no context What app are you talking about ? How does `DLLImport` relates to everything ? Have you traced the system calls ? DLL search path might be wrong ? `DLLImport` might be lurred because we name the lib `libdeepspeech.so` and not `libdeepspeech.dll` ?",feature work fine like ask development team said working new modern feature import native problem provide enough information exception still much unclear context talking everything system search path might wrong might name,issue,negative,positive,neutral,neutral,positive,positive
699945987,"@lissyx dllimport is a built-in Windows feature, so it only works fine on Windows. Other platforms like linux or macos don't. I've ask the .net development team and they said they are working on a new modern feature to import native libraries.
The problem is that the app doesn't provide enough information. Just throws FileNotFound exception.",feature work fine like ask development team said working new modern feature import native problem provide enough information exception,issue,negative,positive,positive,positive,positive,positive
699940787,"> he problem is that DLLImport does not see the deepspeech.so lib in the .Net Standard.

Could you please elaborate ? Again I insist, @carlfm01 could use some help from other people that are .Net knowledgeable.",problem see standard could please elaborate insist could use help people knowledgeable,issue,negative,positive,positive,positive,positive,positive
699933942,@bernardohenz Please don't change file's mode from 644 to 755.,please change file mode,issue,negative,neutral,neutral,neutral,neutral,neutral
699905908,"Great choice for the subject line :-) Looks like you are missing a file. 

I guess this can be closed.",great choice subject line like missing file guess closed,issue,positive,positive,neutral,neutral,positive,positive
699866589,"@dev-bre, @carlfm01 - The problem is that DLLImport does not see the deepspeech.so lib in the .Net Standard. DLLImport only correct works on Windows and this is a problem with the .Net Standard. ",problem see standard correct work problem standard,issue,negative,neutral,neutral,neutral,neutral,neutral
699863292,"@dev-bre As you can see, @carlfm01 is mostly alone on that, so any help here is welcome.",see mostly alone help welcome,issue,positive,positive,positive,positive,positive,positive
699860627,Thanks for the reference. Feels like it is better to keep the conversation in the other thread maybe?,thanks reference like better keep conversation thread maybe,issue,positive,positive,positive,positive,positive,positive
699860086,Would be very helpful to have a NetCore compatible version. Any idea of when this would be started?,would helpful compatible version idea would,issue,negative,neutral,neutral,neutral,neutral,neutral
699857506,"> Hi,
> I can see there is a nuget package available, is this compatible with .NetCore running on Linux?

As documented, there is only .Net Framework compatiblity.

#3285 is already open for .Net Standard, I don't know the differences between all those variants, maybe @carlfm01 can enlight us.

If you are interested in this support, the best way is to submit patches.",hi see package available compatible running framework already open standard know maybe enlight u interested support best way submit,issue,positive,positive,positive,positive,positive,positive
698942932,"> Have you read the releases notes about that feature?

My bad, it looks like it was indeed missing. I've clarified that.",read feature bad like indeed missing,issue,negative,negative,negative,negative,negative,negative
698940456,"@cnair-83 You're welcome to experiment and share on that feature, but until you have some code to share, I'd be better we take that discussion to Discourse.",welcome experiment share feature code share better take discussion discourse,issue,positive,positive,positive,positive,positive,positive
698936684,"> When I run 0.8.2 pre-trained release model with gpu delegate enabled is giving following error
> 
> TensorFlow: v2.2.0-24-g1c1b2b9
> DeepSpeech: v0.8.2-0-g02e4c76
> INFO: Initialized TensorFlow Lite runtime.
> INFO: Created TensorFlow Lite delegate for NNAPI.
> ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.

Have you read the releases notes about that feature? It's here for you to experiment, but it's clearly explained that released model are not expected to work out of the box.",run release model delegate giving following error lite lite delegate error use delegate graph read feature experiment clearly model work box,issue,negative,positive,neutral,neutral,positive,positive
698779122,"This is not a bug, please reach for support on Discourse. Your distro is too old for our prebuilt packages, please rebuild. ",bug please reach support discourse old please rebuild,issue,positive,positive,neutral,neutral,positive,positive
698565861,"@lissyx -- it's one commit, but all the previous commit messages got appended into the one commit message :/ it doesn't look pretty, but yes it is one commit",one commit previous commit got one commit message look pretty yes one commit,issue,positive,positive,neutral,neutral,positive,positive
698452216,Is there forum or useful keywords for search a guide DeepSpeech for Ubuntu 18.04?,forum useful search guide,issue,negative,positive,positive,positive,positive,positive
698449755,"@neodeepspeech Please reach for support on Discourse.


> I only see about DeepSpeech only for Ubuntu 16.04 at this guide, but it does not work
> https://progur.com/2018/02/how-to-use-mozilla-deepspeech-tutorial.html

This is not our tutorial, we can't provide support for that.



> Is possible to install DeepSpeech on Ubuntu 18.04?

Yes. Everything should work.",please reach support discourse see guide work tutorial ca provide support possible install yes everything work,issue,positive,neutral,neutral,neutral,neutral,neutral
698367904,"> Another idea would be to write up a technical report/paper and post it to ArXiv or somewhere.

Write it, I'll gladly put my name as first author on it. :D",another idea would write technical post somewhere write gladly put name first author,issue,negative,positive,positive,positive,positive,positive
698360397,Another idea would be to write up a technical report/paper and post it to ArXiv or somewhere.,another idea would write technical post somewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
698345466,"> > If I understood correctly, they would be much slower than loading from path, but still it's good to have this option than not having any option at all (we could put a message warning that this loading is slower for the sake of clarification).
> 
> I want to make sure we don't put ourselves in a position where people will misuse and have unrealistic expectations

Maybe this should be warned about in the docs: ""using this feature can have negative impact on the amount of memory consumed by your application""",understood correctly would much loading path still good option option could put message warning loading sake clarification want make sure put position people misuse unrealistic maybe feature negative impact amount memory application,issue,negative,positive,positive,positive,positive,positive
698342429,"It’s English (UK) accent

Many thanks,

Ofer Rosenberg
www.AGATSoftware.com<http://www.agatsoftware.com/>
SIP: oferr@agatsoftware.com<mailto:oferr@agatsoftware.com>
  [logo-agat]

From: lissyx <notifications@github.com>
Sent: Thursday, September 24, 2020 4:25 PM
To: mozilla/DeepSpeech <DeepSpeech@noreply.github.com>
Cc: Ofer Rosenberg <OferR@agatsoftware.com>; Mention <mention@noreply.github.com>
Subject: Re: [mozilla/DeepSpeech] Bad analysis (#3333)


with different accents and eventually got really bad results.

It is also explicitely stated in the release page that the model can perform badly depending on the accents.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/mozilla/DeepSpeech/issues/3333#issuecomment-698341787>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/APLA6OURL4LSEMIDVDRIVRTSHNCA7ANCNFSM4RYJNOKQ>.
",accent many thanks sip sent mention mention subject bad analysis different eventually got really bad also stated release page model perform badly depending reply directly view,issue,negative,negative,negative,negative,negative,negative
698341787,"> with different accents and eventually got really bad results.

It is also explicitely stated in the release page that the model can perform badly depending on the accents.",different eventually got really bad also stated release page model perform badly depending,issue,negative,negative,negative,negative,negative,negative
698306805,"@bernardohenz can you:
 - check tflite code path on your side
 - force-push without `D_GLIBCXX_USE_CXX11_ABI`

I could take a look and run CI on that, so we can cross-check",check code path side without could take look run,issue,negative,neutral,neutral,neutral,neutral,neutral
698304927,"> If I understood correctly, they would be much slower than loading from path, but still it's good to have this option than not having any option at all (we could put a message warning that this loading is slower for the sake of clarification).

I want to make sure we don't put ourselves in a position where people will misuse and have unrealistic expectations



> When set to 0, the libs ended up having segmentation fault. I still haven't figured out what `D_GLIBCXX_USE_CXX11_ABI` does differently on what I've implemented. If you have any thoughts about this, it would be much appreciated.

This does impact how C++ code handles strings, so maybe it depends on your env and in your case it makes sense? If you can share more of a stack, for example.",understood correctly would much loading path still good option option could put message warning loading sake clarification want make sure put position people misuse unrealistic set ended segmentation fault still figured differently would much impact code maybe case sense share stack example,issue,negative,positive,positive,positive,positive,positive
698302217,"@lissyx I will be addressing the implementation of new methods for the API.
The points I should need some help is the implementation of loading from buffer of pdmm and tflite models. If I understood correctly, they would be much slower than loading from path, but still it's good to have this option than not having any option at all (we could put a message warning that this loading is slower for the sake of clarification).
Although I had implemented the code for tflite (just because I've found the ```tflite::FlatBufferModel::BuildFromBuffer```), I haven't tested it yet, I have never compiled with tflite and I will try that in the next week.

I have no answer for using ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling. When set to 0, the libs ended up having segmentation fault. I still haven't figured out what ```D_GLIBCXX_USE_CXX11_ABI``` does differently on what I've implemented. If you have any thoughts about this, it would be much appreciated.",implementation new need help implementation loading buffer understood correctly would much loading path still good option option could put message warning loading sake clarification although code found tested yet never try next week answer set ended segmentation fault still figured differently would much,issue,negative,positive,positive,positive,positive,positive
698238363,"no, but retraining Kenlm is well documented (generating an external scorer / custom scorer) and the logic of interpreting the recognized tokens would be custom to a usecase (what to make of the confidence scores and other details).",well generating external scorer custom scorer logic would custom make confidence,issue,positive,neutral,neutral,neutral,neutral,neutral
698163410,I'm not super happy to see that you are cross-posting on discourse and on github and still lack to share the required informations: this is making debugging super-painful and is wasting valuable time.,super happy see discourse still lack share making wasting valuable time,issue,positive,positive,positive,positive,positive,positive
697897881,would you know where to find an example of this ?,would know find example,issue,negative,neutral,neutral,neutral,neutral,neutral
697889233,"the functionality is basically available.
deepspeech delivers decent accuracy, but with a very general language model, plausible but incorrect sentences happen.

i recommend: you refit kenlm on a specific corpus (commands, and the artists names)
it will improve accuracy greatly.
language model generality and accuracy are a tradeoff (new artist names but without no refitting the lm)
and delivering new models is common (in enterprise)

or else, you can still disable and build your own lm ontop of the acoustic model or finetune it too.

as for interpretation of the language model output:
the api (python) already exposes:
intermediate decoding
multiple candidate transcripts with metadata (confidences)
with tokens that can range from letter to multiple words.

see the python api:
intermediateDecodeWithMetadata

which should suffice for scripting word disambiguitation, and context based interpretation and more",functionality basically available decent accuracy general language model plausible incorrect happen recommend refit specific corpus improve accuracy greatly language model generality accuracy new artist without new common enterprise else still disable build acoustic model interpretation language model output python already intermediate multiple candidate range letter multiple see python suffice word context based interpretation,issue,positive,positive,positive,positive,positive,positive
697330148,"> @lissyx I used prebuilt binaries and i have 6GB GPU memory

System ram ? Did you tried gpu binaries ? Non gpu ? Tflite model ? Pbmm model ? ",used memory system ram tried non model model,issue,negative,neutral,neutral,neutral,neutral,neutral
697209819,"@lissyx Sorry for the missing details.
I run on Linux, ubuntu 18.04. I don't use any prebuilt model, i trained my own model from scratch.
CUDA Version: 10.2
GPU: nvidia GeForce RTX 2060",sorry missing run use model trained model scratch version,issue,negative,negative,negative,negative,negative,negative
697127111,"> Just wanted to note that this PR still has an important feature which is missing in @tilmankamp's overlay implementation: The possibility to run tests with noise mixing.

This needs rebasing anyway, but if someone wants to do it and address the issues, it's welcome",note still important feature missing overlay implementation possibility run noise need anyway someone address welcome,issue,negative,positive,positive,positive,positive,positive
697125543,"> This PR allows the loading of model and ExtScorer through array of bytes (`string`)
> 
> Some observations:
> 
>     1. For this implementation to work, I had to use `D_GLIBCXX_USE_CXX11_ABI=1` when compiling the lib
> 
>     2. I've added a new argument (`--init_from_bytes`) in the client for testing the loading
> 
>     3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with `DS_CreateModel` for instance)
> 
>     4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.

@bernardohenz I see you have code already for TFLite, can you describe what kind of help you need?",loading model array string implementation work use added new argument client testing loading know wan na handle naming want keep backwards compatibility instance tested loading need help loading see code already describe kind help need,issue,positive,positive,positive,positive,positive,positive
697124737,"> > Does it? From looking at the implem, I'm unsure this can work without trashing memory of the device: https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/model_builder.cc#L104-L115
> 
> That's a good point, maybe we need to modify TensorFlow to take ownership of the pointer, or assume it'll outlive the session.

That's much more invasive and risky, except if we can upstream that, but we know how long it can take. Depending on @bernardohenz use-case, maybe it makes sense to just expose that for non protobuf mmap files ? or even only for TFLite models ?",looking unsure work without memory device good point maybe need modify take ownership pointer assume outlive session much invasive risky except upstream know long take depending maybe sense expose non even,issue,negative,positive,positive,positive,positive,positive
697023244,"> I set these as `unsafe void` in

Sorry, I forgot to delete the public, you did it right.",set unsafe void sorry forgot delete public right,issue,negative,negative,neutral,neutral,negative,negative
697019260,"> Nice @JRMeyer, just missing the following on the IDeepSpeech interface:
> 
> ```
>         /// <summary>
>         /// Add a hot-word.
>         /// </summary>
>         /// <param name=""aWord"">Some word</param>
>         /// <param name=""aBoost"">Some boost</param>
>         /// <exception cref=""ArgumentException"">Thrown on failure.</exception>
>         public void AddHotWord(string aWord, float aBoost);
> 
>         /// <summary>
>         /// Erase entry for a hot-word.
>         /// </summary>
>         /// <param name=""aWord"">Some word</param>
>         /// <exception cref=""ArgumentException"">Thrown on failure.</exception>
>         public void EraseHotWord(string aWord);
> 
>         /// <summary>
>         /// Clear all hot-words.
>         /// </summary>
>         /// <exception cref=""ArgumentException"">Thrown on failure.</exception>
>         public void ClearHotWords();
> ```

I set these as `unsafe void` in 5432f56a87fae04b438438557716d6aa11edb8d9",nice missing following interface summary add param word param boost exception thrown public void string float summary erase entry param word exception thrown public void string summary clear exception thrown public void set unsafe void,issue,positive,positive,neutral,neutral,positive,positive
696946467,@reuben Is there any solution in sight for the Missing SwiftSupport Folder error when uploading a binary with this framework included to AppStore Connect? There’s a major feature depending on this working that is ready on Android but has been completely blocked on iOS for nearly a month now. ,solution sight missing folder error binary framework included connect major feature depending working ready android completely blocked nearly month,issue,negative,positive,neutral,neutral,positive,positive
696911304,Just wanted to note that this PR still has an important feature which is missing in @tilmankamp's overlay implementation: The possibility to run tests with noise mixing.,note still important feature missing overlay implementation possibility run noise,issue,negative,positive,neutral,neutral,positive,positive
696773703,"> NB: I’ve already done the decoding with this command with no errors but it appeared when I tested with a new model.

Do you repro with our models? Do you repro with our binaries?",already done command tested new model,issue,negative,positive,positive,positive,positive,positive
696772559,"> TensorFlow: v2.2.0-15-g518c1d0
> DeepSpeech: v0.9.0-alpha.3-0-g78ae08c

This is old, please try and reproduce with current master and/or git bisect it.



> terminate called after throwing an instance of 'std::length_error'
> what():  vector::_M_default_append
> Abandon (core dumped)

There's nothing really actionable here ....

You don't even share your hardware. Is this x86-64 ? arm64 ? armv7 ? linux ? windows ? macOS ? android ?
Are those binaries you self-built or are those prebuilt binaries?
How did you trained the model?",old please try reproduce current master git bisect terminate throwing instance vector abandon core nothing really actionable even share hardware arm android trained model,issue,negative,positive,positive,positive,positive,positive
696764130,"> Does it? From looking at the implem, I'm unsure this can work without trashing memory of the device: https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/model_builder.cc#L104-L115

That's a good point, maybe we need to modify TensorFlow to take ownership of the pointer, or assume it'll outlive the session.",looking unsure work without memory device good point maybe need modify take ownership pointer assume outlive session,issue,negative,positive,positive,positive,positive,positive
696759098,"> > I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with `DS_CreateModel` for instance)
> 
> Please introduce a new `DS_CreateModelFromBuffer` for example ?

Also, when you introduce that, please try and expose it in as much bindings as you can.",know wan na handle naming want keep backwards compatibility instance please introduce new example also introduce please try expose much,issue,positive,positive,neutral,neutral,positive,positive
696748576,"> @lissyx #3152 is one example

Does it? From looking at the implem, I'm unsure this can work without trashing memory of the device: https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/model_builder.cc#L104-L115",one example looking unsure work without memory device,issue,negative,neutral,neutral,neutral,neutral,neutral
696746218,"@bernardohenz I fail to get the usecase where this can be useful for mmap-able file formats (PBMM, TFLite), given how much this is going to force TensorFlow to allocate some memory.",fail get useful file given much going force allocate memory,issue,negative,neutral,neutral,neutral,neutral,neutral
696740928,"> For this implementation to work, I had to use `D_GLIBCXX_USE_CXX11_ABI=1` when compiling the lib

this will be problematic for compatibility with some systems



> I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with `DS_CreateModel` for instance)

Please introduce a new `DS_CreateModelFromBuffer` for example ?



> I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.

I really don't see how this feature can work well with the tensorflow infra without forcing allocating huge strings",implementation work use problematic compatibility know wan na handle naming want keep backwards compatibility instance please introduce new example tested loading need help loading really see feature work well infra without forcing huge,issue,negative,positive,positive,positive,positive,positive
696189189,"> @lissyx Yes, it adds some complexity to your release process, but I'd argue that adding a line or two to the final upload script is a minimal addition.

It's not that simple.


> I don't know where you see wasted disk space, I'd expect to either store the compressed or uncompressed version locally.

We still have to host compressed and uncompressed versions.



> If you feel like this suggestion does not provide a benefit to DeepSpeech, feel free to ignore it and close this issue.

I'd like to understand if there's a usecase where this could be a game-changer.



> @ftyers I'm probably not going to create an account there, as this is just a suggestion.

You can login on Discourse using Github. We use Github only for tracking bugs and features, so for the purpose of the discussion and discoverability of support / debates, it's better if things sticks to their places.",yes complexity release process argue line two final script minimal addition simple know see wasted disk space expect either store compressed uncompressed version locally still host compressed uncompressed feel like suggestion provide benefit feel free ignore close issue like understand could probably going create account suggestion login discourse use purpose discussion discoverability support better stick,issue,positive,positive,neutral,neutral,positive,positive
696175574,"@lissyx Yes, it adds some complexity to your release process, but I'd argue that adding a line or two to the final upload script is a minimal addition.

As for the use case, for me it's just getting started faster. Maybe one could argue for mobile users and their data caps. Though I see no major drawbacks to compressing the model files. Compression takes a bit of time, I agree, but it's only done once. Decompression is also very fast, so no problem either.

> Is there really a usecase where a 730MB download VS a 900MB makes sense and is useful for the extra disk space wasting?

I don't know where you see wasted disk space, I'd expect to either store the compressed or uncompressed version locally.

@ftyers I'm probably not going to create an account there, as this is just a suggestion.

If you feel like this suggestion does not provide a benefit to DeepSpeech, feel free to ignore it and close this issue.",yes complexity release process argue line two final script minimal addition use case getting faster maybe one could argue mobile data though see major model compression bit time agree done decompression also fast problem either really sense useful extra disk space wasting know see wasted disk space expect either store compressed uncompressed version locally probably going create account suggestion feel like suggestion provide benefit feel free ignore close issue,issue,positive,positive,neutral,neutral,positive,positive
696156861,"There has been quite a lot of activity on r1.15 branch on TensorFlow, I think we can safely hope for a 1.15.4 that ships without fix now (current upstream r1.15 has merged the fix). I'll close this issue when 1.15.4 ships.",quite lot activity branch think safely hope without fix current upstream fix close issue,issue,positive,positive,positive,positive,positive,positive
696155038,"It's been more than a month without news, and you are the only one reporting this weird behavior. There's something unclear, but we can't keep this issue open with no activity.",month without news one weird behavior something unclear ca keep issue open activity,issue,negative,negative,negative,negative,negative,negative
696147575,"Perhaps this could be made into a topic on [Discourse](https://discourse.mozilla.org/) under the [Mozilla STT](https://discourse.mozilla.org/c/mozilla-voice-stt/) topic and further information could be gathered as to the effectiveness, you could also give us details of your use case. I've been ""out in a field"" a lot of the time and know how frustrating it is trying to download gigabytes of data over a dodgy connection. But in general, GitHub issues is not really the place for this kind of suggestion.",perhaps could made topic discourse topic information could effectiveness could also give u use case field lot time know trying data dodgy connection general really place kind suggestion,issue,negative,positive,positive,positive,positive,positive
696143790,"This adds extra complexity to producing a release, and I'm not convinced about the 20% win given the amount of data: if the connection is slow, it's still going to take quite some time to download. Is there really a usecase where a 730MB download VS a 900MB makes sense and is useful for the extra disk space wasting?

Also, `xz` is fast at decompression, but it's quite intensive at compression time, and models, as you can see, do not compress super well.",extra complexity release convinced win given amount data connection slow still going take quite time really sense useful extra disk space wasting also fast decompression quite intensive compression time see compress super well,issue,positive,positive,positive,positive,positive,positive
696139971,"KenLM Windows builds is too painful to drive for now, generating Visual Studio project using `cmake` does not yield proper outcome, and it might be required to also handle `boost` build, if not also `liblzma`.",painful drive generating visual studio project yield proper outcome might also handle boost build also,issue,negative,negative,negative,negative,negative,negative
696132457,"Hi @soheilpaper, this looks like a support request, not an issue with DeepSpeech. We use GitHub issues to manage issues with the code, not for end-user help. If you'd like end-user help, you can make a new post on [Discourse](https://discourse.mozilla.org/) under the [Mozilla STT](https://discourse.mozilla.org/c/mozilla-voice-stt/) topic and members of the DeepSpeech community will be able to help you there. Hope this helps and thanks for your interest in DeepSpeech!",hi like support request issue use manage code help like help make new post discourse topic community able help hope thanks interest,issue,positive,positive,positive,positive,positive,positive
695930853,"> But when i am using this GitHub project :
> 
> https://github.com/abhirooptalasila/AutoSub
> 
> which is using the **deepspeech-0.8.2**, by this kind of command:

We cant provide support for third party tools, sorry. ",project kind command cant provide support third party sorry,issue,positive,positive,neutral,neutral,positive,positive
694974554,"It has to be done by repo admins. I looked into it and got stuck in support limbo for the citation service, because the admins for the Mozilla org didn't want to enable the app globally, so the webhook had to be added manually and the repo enabled by support.

> Am 18.09.2020 um 12:47 schrieb lissyx <notifications@github.com>:
> 
> ﻿
> This has been requested a few times, PRs to add that are welcome.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",done got stuck support limbo citation service want enable globally added manually support um time add welcome thread reply directly view,issue,positive,positive,positive,positive,positive,positive
694780011,@engmubarak48 Please respect documented process and reach for support on Discourse.,please respect process reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
694722870,"Thanks. TensorFlow team merged the r1.15 PR a few hours ago, so hopefully they are making 1.15.4 and we will be able to bump our dependency",thanks team ago hopefully making able bump dependency,issue,positive,positive,positive,positive,positive,positive
694722210,I tried this and it worked. Thanks a lot :+1: ,tried worked thanks lot,issue,negative,positive,positive,positive,positive,positive
694719838,"> I checked the thread. From what I could understand, the workaround is experimenting with different versions of `tensorflow + nvidia driver + cuda + cudnn` and check what's best for your particular GPU right? according to the experiments mentioned here [#3088 (comment)](https://github.com/mozilla/DeepSpeech/issues/3088#issuecomment-656583170)

No, the workaround is an env variable until the proper fix is released by TensorFlow: https://github.com/mozilla/DeepSpeech/issues/3088#issuecomment-663466075",checked thread could understand different driver check best particular right according comment variable proper fix,issue,positive,positive,positive,positive,positive,positive
694718472,"I checked the thread. From what I could understand, the workaround is experimenting with different versions of `tensorflow + nvidia driver + cuda + cudnn` and check what's best for your particular GPU right? according to the experiments mentioned here https://github.com/mozilla/DeepSpeech/issues/3088#issuecomment-656583170",checked thread could understand different driver check best particular right according,issue,positive,positive,positive,positive,positive,positive
694712478,"Have you tried the documented workaround from #3088 ?
It matches your exact error message and experiments ...",tried exact error message,issue,negative,positive,positive,positive,positive,positive
694452562,"Thanks for the excellent contribution and for keeping up with the review process, I know it can be tiring sometimes!",thanks excellent contribution keeping review process know tiring sometimes,issue,positive,positive,positive,positive,positive,positive
694436580,"Cool ! 
This was quick, with useful feedback (testing) and constructive comments, leading to several improvements compared to the beginning. I am quite happy with that. Thanks !",cool quick useful feedback testing constructive leading several beginning quite happy thanks,issue,positive,positive,positive,positive,positive,positive
694419238,"Honestly, you seems to have nailed it pretty well, let's not hold it too long. Maybe good to do a new alpha release with that ? ",honestly pretty well let hold long maybe good new alpha release,issue,positive,positive,positive,positive,positive,positive
694331891,Licensing is done. I have assumed that the CC0 license allows you to do more or less anything without worrying if it is allowed or not.,done assumed license le anything without worrying,issue,negative,neutral,neutral,neutral,neutral,neutral
694258384,"Well, for this one, I guess the CC0 (public domain) will be good.",well one guess public domain good,issue,positive,positive,positive,positive,positive,positive
694244809,"I am interested in finding a good license for my projects in general, so I am looking into it.
If you don't know in advance what is compatible, don't waste your time, I will find it.",interested finding good license general looking know advance compatible waste time find,issue,negative,positive,positive,positive,positive,positive
694234388,"> Ok. I have wondered a few times what licence I would choose.
> I think I like Creative Commons licenses, and this one in particular CC BY-SA.
> 
> From their website, it says :
> 
> > This license lets others remix, adapt, and build upon your work even for commercial purposes, as long as they credit you and license their new creations under the identical terms. This license is often compared to “copyleft” free and open source software licenses. All new works based on yours will carry the same license, so any derivatives will also allow commercial use. This is the license used by Wikipedia, and is recommended for materials that would benefit from incorporating content from Wikipedia and similarly licensed projects.
> 
> I am open to choose something else if needed. Do you have any advice on this point ?

I'm unsure this is going to mix well with the rest of the codebase, though, but I'm no license expert.",time would choose think like creative common one particular license remix adapt build upon work even commercial long credit license new identical license often free open source new work based carry license also allow commercial use license used would benefit content similarly licensed open choose something else advice point unsure going mix well rest though license expert,issue,positive,positive,neutral,neutral,positive,positive
694233691,"I see that DeepSpeech has ""Mozilla Public License 2.0"". I don't know what license is compatible with what...
Obviously, I need to choose something compatible with this one. ",see public license know license compatible obviously need choose something compatible one,issue,negative,neutral,neutral,neutral,neutral,neutral
694231422,"Ok. I have wondered a few times what licence I would choose. 
I think I like Creative Commons licenses, and this one in particular CC BY-SA.

From their website, it says :
> This license lets others remix, adapt, and build upon your work even for commercial purposes, as long as they credit you and license their new creations under the identical terms. This license is often compared to “copyleft” free and open source software licenses. All new works based on yours will carry the same license, so any derivatives will also allow commercial use. This is the license used by Wikipedia, and is recommended for materials that would benefit from incorporating content from Wikipedia and similarly licensed projects. 

I am open to choose something else if needed. Do you have any advice on this point ?",time would choose think like creative common one particular license remix adapt build upon work even commercial long credit license new identical license often free open source new work based carry license also allow commercial use license used would benefit content similarly licensed open choose something else advice point,issue,positive,positive,neutral,neutral,positive,positive
694221027,"Also, as this is not a bug in our codebase, please use Discourse as advised for reaching support.",also bug please use discourse advised reaching support,issue,positive,neutral,neutral,neutral,neutral,neutral
694216442,"> @alexivaner Please, can you avoid sharing errors as screenshots? It makes them not accessible and painful to read.

Sorry, I already edited my error.

For the cuda and cudnn, I refer to this article:
https://www.tensorflow.org/install/source#linux
![image](https://user-images.githubusercontent.com/57290644/93473726-ee492300-f928-11ea-9996-061048273182.png)

Okay will try to upgrade the cudnn to 7.6",please avoid accessible painful read sorry already error refer article image try upgrade,issue,negative,negative,negative,negative,negative,negative
694215112,"> make sure my CUDA and CUDNN compatible with tensorflow-gpu version by running this mnist example with gpu https://www.tensorflow.org/tutorials/keras/classification, it works really well.

I don't know what you tested, but this error is textbook CUDNN / CUDA incompatible.",make sure compatible version running example work really well know tested error textbook incompatible,issue,negative,positive,positive,positive,positive,positive
694214814,"> **CUDA/cuDNN version**: cuda 10.0/cudnn7.4.2

TensorFlow documentation specified CUDNN v7.6, not v7.4



> Do we need minimum of GPU memory 8 GB to train DeepSpeech? Thank you,

The more memory, the better, but we don't have hardware to test with 8GB or below so we don't know.

",version documentation need minimum memory train thank memory better hardware test know,issue,positive,positive,positive,positive,positive,positive
694213604,"@alexivaner Please, can you avoid sharing errors as screenshots? It makes them not accessible and painful to read.",please avoid accessible painful read,issue,negative,negative,negative,negative,negative,negative
694212340,"Oh, that's a good point I forgot to mention. Could you add a `third_party/object_pool/README.mozilla` text file saying basically ""This code was imported from this repository on this date, commit SHA1. It's licensed under X license."" (And you should probably add licensing details to your repo too!).",oh good point forgot mention could add text file saying basically code repository date commit sha licensed license probably add,issue,positive,positive,positive,positive,positive,positive
694202923,"Regarding the object pool, I have published it there https://github.com/godefv/memory.
For now, you have your own copy and can do whatever you like with it. 

In my version, I have removed the namespace `memory::`, which is not very useful.
",regarding object pool copy whatever like version removed memory useful,issue,positive,positive,positive,positive,positive,positive
693360956,"One file at a time, it works.
Of course, my object pool is not thread safe, so...
thread_local object pool solved this !",one file time work course object pool thread safe object pool,issue,negative,positive,positive,positive,positive,positive
692939734,"Well, sorry about those bugs. I hope it is good now.
The root of the timestep tree was not handled properly and it also forced the first timestep of each path to be 0 (which was wrong).

On my samples, The first timestep is always zero because my CTC loss converged that way. So, I didn't see any issue.",well sorry hope good root tree handled properly also forced first path wrong first always zero loss way see issue,issue,negative,negative,neutral,neutral,negative,negative
692710352,"Ok, thanks, `deepspeech-0.8.2-checkpoint.tar.gz` is indeed available in addition to `deepspeech-0.8.2-models.pbmm`",thanks indeed available addition,issue,negative,positive,positive,positive,positive,positive
692671155,"Could you give me the command you have used ?
If I use `./deepspeech --model deepspeech-0.8.1-models.pbmm --scorer deepspeech-0.8.1-models.scorer --audio /tmp/8455-210777-0000.wav`, it does not use the decoder I have compiled and installed.
If I use `transcribe.py`, I don't know how to specify what model to use.",could give command used use model scorer audio use use know specify model use,issue,negative,neutral,neutral,neutral,neutral,neutral
692313434,"Fixed ! 

After all, unrelated code was not so unrelated, and it indeed prevents crashes.

The reason is that the algorithm from master does not prune paths with zero probability. When such a path is being extended with a character which also has a probability of zero, then the following code is skipped and `timesteps` remains `nullptr`:
```
          if (prefix_new->log_prob_nb_cur < log_p) {
            // record data needed to update timesteps
            // the actual update will be done if nothing better is found
            prefix_new->previous_timesteps = prefix->timesteps;
            prefix_new->new_timestep = abs_time_step_;
          }
```
I could hve fixed it by adding a condition like ` || (refix_new->log_prob_nb_cur == -NUM_FLT_INF && prefix_new->timesteps == nullptr` but it seems quite artificial to support all those paths with zero probability.
Moreover, the check I have put back have prevented crashes twice already, and it looks like a very reasonable check.",fixed unrelated code unrelated indeed reason algorithm master prune zero probability path extended character also probability zero following code remains record data update actual update done nothing better found could fixed condition like quite artificial support zero probability moreover check put back twice already like reasonable check,issue,positive,positive,neutral,neutral,positive,positive
692274539,"It seems that the DeepSpeech code is using `pip` and `python` to run scripts everywhere, but it actually requires python3 (I got ""deepspeech-training requires Python '>=3.5, <4' but the running Python is 2.7.17""). So, I solved the above error by replacing `python` by `python3`",code pip python run everywhere actually python got python running python error python python,issue,negative,neutral,neutral,neutral,neutral,neutral
692247403,"Hum, it says :
```
 ./bin/run-ldc93s1.sh --epochs 1
+ [ ! -f DeepSpeech.py ]
+ [ ! -f data/ldc93s1/ldc93s1.csv ]
+ echo Downloading and preprocessing LDC93S1 example data, saving in ./data/ldc93s1.
Downloading and preprocessing LDC93S1 example data, saving in ./data/ldc93s1.
+ python -u bin/import_ldc93s1.py ./data/ldc93s1
Traceback (most recent call last):
  File ""bin/import_ldc93s1.py"", line 7, in <module>
    from mozilla_voice_stt_training.util.downloader import maybe_download
ImportError: No module named mozilla_voice_stt_training.util.downloader
```
",hum echo example data saving example data saving python recent call last file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
692228792,"Can you try building the decoder package and running a test set? From what I understand you're testing with the deepspeech binary rather than by doing a test epoch. You should be able to just do this, from the root of the repo:

```
cd native_client/ctcdecode && (make bindings-debug NUM_PROCESSES=12 && pip install -U dist/*.whl); cd ../..
./bin/run-ldc93s1.sh --epochs 1
```

And it should reproduce the failure. By the way, this warning might be relevant:

```
In file included from path_trie.cpp:1:
In file included from ./path_trie.h:12:
third_party/object_pool/object_pool.h:63:28: warning: field 'free_object_slots_end' is uninitialized when used here [-Wuninitialized]
                free_object_slots_begin{ free_object_slots_end }, // At the begining, set the 2 iterators at the same value to simulate a full pool.
                                         ^
./path_trie.h:112:63: note: in instantiation of member function 'godefv::memory::object_pool_t<TreeNode<unsigned int>, allocator, 1024>::object_pool_t' requested here
    static godefv::memory::object_pool_t<TreeNode<NodeDataT>> tree_node_pool;
                                                              ^
path_trie.cpp:183:23: note: in instantiation of function template specialization 'add_child<unsigned int, unsigned int &>' requested here
          timesteps = add_child(previous_timesteps, new_timestep);
                      ^
1 warning generated.
```",try building package running test set understand testing binary rather test epoch able root make pip install reproduce failure way warning might relevant file included file included warning field used set value simulate full pool note member function unsigned allocator static note function template specialization unsigned unsigned warning,issue,negative,positive,positive,positive,positive,positive
692227170,"Unfortunately, it works on my side with my files.
It seems that you have this issue with all your files, whereas I have it with none of mine. So, it may not depend on the the file used.
What compiler do you use ?",unfortunately work side issue whereas none mine may depend file used compiler use,issue,negative,negative,negative,negative,negative,negative
692142364,"Ah, no, just one per thread, of course.",ah one per thread course,issue,negative,neutral,neutral,neutral,neutral,neutral
692141986,"With a debug build I get tons of assertion failures before the crash:

```
python: ctc_beam_search_decoder.cpp:99: void DecoderState::next(const double*, int, int): Assertion `prefix->is_empty() || prefix->timesteps != nullptr' failed.
```",build get assertion crash python void double assertion,issue,negative,neutral,neutral,neutral,neutral,neutral
692134331,"```
[Switching to Thread 0x7fffa578f700 (LWP 46388)]
0x00007ffef96ae615 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
(gdb) bt
#0  0x00007ffef96ae615 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#1  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#2  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#3  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#4  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#5  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#6  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#7  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#8  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#9  0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#10 0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#11 0x00007ffef96ae624 in PathTrie::iterate_to_vec(std::vector<PathTrie*, std::allocator<PathTrie*> >&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#12 0x00007ffef96b633c in DecoderState::next(double const*, int, int) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#13 0x00007ffef96b7f19 in ctc_beam_search_decoder(double const*, int, int, Alphabet const&, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long) ()
   from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#14 0x00007ffef96bae46 in std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> (), std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::vector<Output, std::allocator<Output> > >, std::__future_base::_Result_base::_Deleter>, std::__future_base::_Task_state<std::_Bind<std::vector<Output, std::allocator<Output> > (*(double const*, int, int, Alphabet, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long))(double const*, int, int, Alphabet const&, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long)>, std::allocator<int>, std::vector<Output, std::allocator<Output> > ()>::_M_run()::{lambda()#1}, std::vector<Output, std::allocator<Output> > > >::_M_invoke(std::_Any_data const&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#15 0x00007ffef96b9229 in std::__future_base::_State_baseV2::_M_do_set(std::function<std::unique_ptr<std::__future_base::_Result_base, std::__future_base::_Result_base::_Deleter> ()>*, bool*) ()
   from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#16 0x00007ffff75d2827 in __pthread_once_slow (once_control=0x4d94938, init_routine=0x7fff6c6f58a0 <__once_proxy>) at pthread_once.c:116
#17 0x00007ffef96b9c5c in std::_Function_handler<void (), std::future<std::result_of<std::vector<Output, std::allocator<Output> > (&(double const*, int const&, int&, Alphabet const&, unsigned long&, double&, unsigned long&, std::shared_ptr<Scorer>&, unsigned long&))(double const*, int, int, Alphabet const&, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long)>::type> ThreadPool::enqueue<std::vector<Output, std::allocator<Output> > (&)(double const*, int, int, Alphabet const&, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long), double const*, int const&, int&, Alphabet const&, unsigned long&, double&, unsigned long&, std::shared_ptr<Scorer>&, unsigned long&>(std::vector<Output, std::allocator<Output> > (&)(double const*, int, int, Alphabet const&, unsigned long, double, unsigned long, std::shared_ptr<Scorer>, unsigned long), double const*&&, int const&, int&, Alphabet const&, unsigned long&, double&, unsigned long&, std::shared_ptr<Scorer>&, unsigned long&)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#18 0x00007ffef96b9900 in std::thread::_State_impl<std::thread::_Invoker<std::tuple<ThreadPool::ThreadPool(unsigned long)::{lambda()#1}> > >::_M_run() ()
   from /tmp/venv/lib/python3.6/site-packages/ds_ctcdecoder/_swigwrapper.cpython-36m-x86_64-linux-gnu.so
#19 0x00007fff6c6f66df in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#20 0x00007ffff75ca6db in start_thread (arg=0x7fffa578f700) at pthread_create.c:463
#21 0x00007ffff7903a3f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
```",switching thread double double alphabet unsigned long double unsigned long scorer unsigned long output output output output double alphabet unsigned long double unsigned long scorer unsigned long double alphabet unsigned long double unsigned long scorer unsigned long output output lambda output output bool void output output double alphabet unsigned long double unsigned long scorer unsigned long double alphabet unsigned long double unsigned long scorer unsigned long output output double alphabet unsigned long double unsigned long scorer unsigned long double alphabet unsigned long double unsigned long scorer unsigned long output output double alphabet unsigned long double unsigned long scorer unsigned long double alphabet unsigned long double unsigned long scorer unsigned long lambda unsigned long lambda clone,issue,negative,negative,neutral,neutral,negative,negative
692133838,I'm getting a segfault on the first test batch.,getting first test batch,issue,negative,positive,positive,positive,positive,positive
692105878,"Yes, sorry, massif took so long to finish that I forgot to comment here. Memory usage looks OK with ec55597 but there was still a significant runtime regression. Testing the latest version now.",yes sorry massif took long finish forgot comment memory usage still significant regression testing latest version,issue,negative,positive,neutral,neutral,positive,positive
692030228,"Oh, and I have just copy-pasted my object pool from another project. I don't know if you want something special about it. 
You can change namespaces or whatever you don't like.",oh object pool another project know want something special change whatever like,issue,positive,positive,positive,positive,positive,positive
692028226,"@reuben Hi, have you got a picture of the memory usage ? I have the impression that it is ok on my samples.

On my side, I have tested the object pool with unique pointers stored in the timestep tree. It is 13% faster on my samples than the previous version in this PR (and normally the same memory usage). So, in terms of speed, I expect that it should be roughly equivalent to the current master.

The memory is recycled by the object pool when the PathTrie is destroyed, so it should not leak.",hi got picture memory usage impression side tested object pool unique tree faster previous version normally memory usage speed expect roughly equivalent current master memory object pool leak,issue,negative,positive,neutral,neutral,positive,positive
692022276,"Our current usage of TaskCluster:

### We leverage the current features:
 - building a graph of tasks with dependencies: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-decision.py
 - artifact with indexes: https://community-tc.services.mozilla.com/tasks/index/project.deepspeech
 - building multiple archs:
   - linux/amd64 (via docker-worker)
   - linux/aarch64 (cross-compilation, docker-worker)
   - linux/rpi3 (cross-compilation, docker-worker)
   - android/armv7 (cross-compilation, docker-worker)
   - android/aarch64 (cross-compilation, docker-worker)
   - macOS/amd64 (native, generic-worker, deepspeech-specific hardware deployment, generic-worker)
   - iOS/x86_64 (native, reusing the macOS infra)
   - iOS/aarch64 (native, reusing the macOS infra)
   - Windows/amd64 (native, generic-worker, deepspeech pool managed by taskcluster team)
 - testing on multiple archs:
   - linux/amd64 (docker-worker)
   - linux/aarch64 (native, deepspeech specific hardware, docker-worker)
   - linux/rpi3 (native, deepspeech specific hardware, docker-worker)
   - android/armv7 (docker-worker + nested virt)
   - android/aarch64 (docker-worker + nested virt)
   - macOS/amd64 (native, deepspeech specific hardware deployment, generic-worker)
   - iOS/x86_64 (native, reusing macOS infra)
   - Windows/amd64 (native, generic-worker, deepspeech pool managed by taskcluster team)
   - Windows/CUDA (native, generic-worker with NVIDIA GPU, deepspeech pool managed by taskcluster team)
 - Documentation on ReadTheDocs + Github webhook to generate on PR/push/tag
 - Pushing to repos:
  - Docker Hub via CircleCI
  - Everything else via scriptworker instance running on Heroku:
    - NPM
    - Pypi
    - Nuget
    - JCenter
    - Github

### Hardware:
 - Set of GCP VMs for Linux+Android builds/tests
 - Set of AWS VMs for Windows builds/tests
 - 4x MacBook Pro for macOS setups, with VMare Fusion and sets of builds/tests VMs configured
 - ARM hardware self-hosted:
   - 6x LePotato boards for Linux/Aarch64 tests
   - 6x RPi3 boards for Linux/ARMv7 tests
   - ![DSC_1401](https://user-images.githubusercontent.com/1645737/93103050-6e168980-f6ac-11ea-98ba-c146396c7107.JPG)


### `tc-decision.py` is in charge of building the whole graph of tasks describing a PR or a Push/Tag:
 - PRs runs tests
 - Push runs builds
 - Tag runs builds + uploads to repositories
 - YAML description files in `taskcluster/*.yml` to describe tasks
 - dependencies between tasks based on `.yml` filename (without `.yml`)
 - decision task created by `.taskcluster.yml` (canonical entry point of tasckluster / github integration) + `taskcluster/tc-schedule.sh` 
 - https://community-tc.services.mozilla.com/docs
 - ` LC_ALL=C GITHUB_EVENT=""pull_request.synchronize"" TASK_ID=""aa"" GITHUB_HEAD_BRANCHORTAG=""branchName"" GITHUB_HEAD_REF=""refs/heads/branchName"" GITHUB_HEAD_BRANCH=""branchName"" GITHUB_HEAD_REPO_URL=""aa"" GITHUB_HEAD_SHA=""a"" GITHUB_HEAD_USER=""a"" GITHUB_HEAD_USER_EMAIL=""a"" python3 taskcluster/tc-decision.py  --dry`
 - ` LC_ALL=C GITHUB_EVENT=""tag"" TASK_ID=""aa"" GITHUB_HEAD_BRANCHORTAG=""branchName"" GITHUB_HEAD_REF=""refs/heads/branchName"" GITHUB_HEAD_BRANCH=""branchName"" GITHUB_HEAD_REPO_URL=""aa"" GITHUB_HEAD_SHA=""a"" GITHUB_HEAD_USER=""a"" GITHUB_HEAD_USER_EMAIL=""a"" python3 taskcluster/tc-decision.py  --dry`

### Execution encapsulated within bash scripts:
 - Only bash for ease of hacking
 - Re-usable accross all platforms (Linux, macOS, Windows) whereas Docker would cover only Linux
 - TensorFlow build:
   - `tf_tc-setup.sh` : perform setup steps for TensorFlow builds (install Bazel, CUDA, etc.)
   - `tf_tc-build.sh`: perform build of TensorFlow
   - `tf_tc-package.sh`: package the TensorFlow build dir as `home.tar.xz` for re-use
   - exact re-use of tensorflow is required for Bazel to properly re-use its caching
 - DeepSpeech build
   - same architecture, span over:
   - `taskcluster/tc-all-utils.sh`
   - `taskcluster/tc-all-vars.sh`
   - `taskcluster/tc-android-utils.sh`
   - `taskcluster/tc-asserts.sh`
   - `taskcluster/tc-build-utils.sh`
   - `taskcluster/tc-dotnet-utils.sh`
   - `taskcluster/tc-node-utils.sh`
   - `taskcluster/tc-package.sh`
   - `taskcluster/tc-py-utils.sh`
",current usage leverage current building graph artifact building multiple via native hardware deployment native infra native infra native pool team testing multiple native specific hardware native specific hardware native specific hardware deployment native infra native pool team native pool team documentation generate pushing docker hub via everything else via instance running hardware set set pro fusion arm hardware charge building whole graph push tag description describe based without decision task canonical entry point integration aa aa python dry tag aa aa python dry execution within bash bash ease hacking whereas docker would cover build perform setup install perform build package build exact properly build architecture span,issue,negative,positive,neutral,neutral,positive,positive
691996416,"> in a docker container

We also need support for Windows, macOS and iOS that cannot be covered by Docker",docker container also need support covered docker,issue,negative,neutral,neutral,neutral,neutral,neutral
691790537,"
@xiaoqunSun  does this actually work? AFAIK TensorFlow and Basel don't work with static libraries.

Until this issue is fixed this library is essentially unstable on iOS.",actually work work static issue fixed library essentially unstable,issue,negative,positive,positive,positive,positive,positive
691773536,"I found a way to build static framework


copy      tf_cc_shared_object(
                    name = ""libdeepspeech.so"",
                    ...................
               )
rename  cc_library(
                    name = ""static"",
                    ...................
               )
add 
ios_static_framework(
    name = ""deepspeech_ios"",
    deps = ["":static""],
    families = [""iphone"",""ipad""],
    minimum_os_version = ""9.0"",
)


",found way build static framework copy name rename name static add name static,issue,negative,positive,positive,positive,positive,positive
691464011,"> That would mean moving to gitlab

No, you can use it with github too.

<br>

From: https://docs.gitlab.com/ee/ci/ci_cd_for_external_repos/
```
Instead of moving your entire project to GitLab, you can connect your external repository to get the benefits of GitLab CI/CD.

Connecting an external repository will set up repository mirroring and create a lightweight project with issues, merge requests, wiki, and snippets disabled. These features can be re-enabled later.

To connect to an external repository:

    From your GitLab dashboard, click New project.
    Switch to the CI/CD for external repo tab.
    Choose GitHub or Repo by URL.
    The next steps are similar to the import flow. 
```

<br>

> Maybe i should post a detailed explanation of our usage of taskcluster to help there ?

I think this is a good idea. But you should be able to do everything on gitlab ci as soon you can run it in a docker container without special flags.",would mean moving use instead moving entire project connect external repository get external repository set repository create lightweight project merge disabled later connect external repository dashboard click new project switch external tab choose next similar import flow maybe post detailed explanation usage help think good idea able everything soon run docker container without special,issue,positive,positive,positive,positive,positive,positive
691354642,Maybe it would be possible package libdeepspeech.so and its’ header files as a SEPERATE cocoapod that a hypothetical deepspeech_ios would depend on. ,maybe would possible package header hypothetical would depend,issue,negative,neutral,neutral,neutral,neutral,neutral
691209322,"Thanks for YouTube anders, i will check your recommandations. Is it working
with Windows?

lissyx <notifications@github.com> schrieb am Di., 8. Sept. 2020, 17:35:

> Looks you are using Visual Studio 2019, I confirm it is working well with
> v0.8 and vs 2019, please check the installed NuGets.
>
> So this is indeed a support request, not a bug. @avmetze
> <https://github.com/avmetze> Please follow instructions and reach for
> support on Discourse.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3311#issuecomment-688959384>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/APSRE3BCLMNZIUAP2D2Q6EDSEZFL5ANCNFSM4QYN5YYQ>
> .
>
",thanks check working visual studio confirm working well please check indeed support request bug please follow reach support discourse reply directly view,issue,positive,positive,positive,positive,positive,positive
691180491,"> What do you think about GitLabs builtin CI features?

That would mean moving to gitlab, which raises other questions. I dont have experience with their ci even though i use gitlab for some personal project (from gitorious.org).

Maybe i should post a detailed explanation of our usage of taskcluster to help there ? ",think would mean moving dont experience even though use personal project maybe post detailed explanation usage help,issue,negative,positive,neutral,neutral,positive,positive
691179055,"> Sorry I wasn't able to get to this @lissyx
> 
> It's a bit unfortunate they keep bumping the Electron version so often.

Fortunately its easy so far to update 😉",sorry able get bit unfortunate keep bumping electron version often fortunately easy far update,issue,negative,positive,neutral,neutral,positive,positive
691161670,"Sorry I wasn't able to get to this @lissyx

It's a bit unfortunate they keep bumping the Electron version so often.",sorry able get bit unfortunate keep bumping electron version often,issue,negative,negative,negative,negative,negative,negative
690976204,"What do you think about GitLabs builtin CI features? 

I'm using it for my [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Jaco-Master) project and I'm quite happy with it because currently it supports almost all my requirements. The pipeline does linting checks and some code statistics calculation and I'm using it to provide prebuilt container images (You could build and provide the training images from there for example). See my CI setup file [here](https://gitlab.com/Jaco-Assistant/Jaco-Master/-/blob/master/.gitlab-ci.yml).

There is also an official tutorial for usage with github: https://about.gitlab.com/solutions/github/
And its free for open source projects.
",think project quite happy currently almost pipeline code statistic calculation provide container could build provide training example see setup file also official tutorial usage free open source,issue,positive,positive,positive,positive,positive,positive
690824043,"> @reuben尝试在0.8.2存储库中将DeepSpeech Test应用程序的存档上传到App Store Connect时，结果为电子邮件：
> 
> ```
> ITMS-90426: Invalid Swift Support - The SwiftSupport folder is missing. Rebuild your app using the current public (GM) version of Xcode and resubmit it.
> ```
> 
> 我认为@xiaoqunSun可能正确或接近它。

Yes,   same error",store invalid swift support folder missing rebuild current public version resubmit yes error,issue,negative,negative,neutral,neutral,negative,negative
690743475,"@reuben Attempting to upload an archive of the DeepSpeech Test app in the 0.8.2 repo to App Store Connect results in an email saying:

```
ITMS-90426: Invalid Swift Support - The SwiftSupport folder is missing. Rebuild your app using the current public (GM) version of Xcode and resubmit it.
```

I think @xiaoqunSun might be right or close to it.",archive test store connect saying invalid swift support folder missing rebuild current public version resubmit think might right close,issue,negative,positive,neutral,neutral,positive,positive
690339672,"Direct use of the dynamic library ""so"" will be rejected when submitted to the apple store



I tried to build the static library "". a"",     but it didn't make any progress. Can you help me",direct use dynamic library apple store tried build static library make progress help,issue,positive,positive,positive,positive,positive,positive
690336635,"> > To be clear, you don't actually need to rebuild libdeepspeech.so yourself, you can use the copy from our CI infra. Building just the wrapper framework library should be easily doable from source, just open it with Xcode or use xcodebuild like we do in CI (see `do_deepspeech_ios_framework_build` in `taskcluster/tc-build-utils.sh`).
> 
> Yes, I'm already doing that because the Metadata and Token arrays were (erroneously?) marked as `private(set)` instead of `public private(set)`.
> 
> > @zaptrem Unfortunately, I also know very little about what it takes to bring this library to CocoaPods, but it is also in my best interest that submitting to the store works (but maybe not as urgent as for you). Maybe we can combine our efforts and get it to work, although @reuben seems to have greatest expertise in building the library for iOS.
> > You can write me on Telegram under the same username maybe we can setup a little Sprint for that.
> 
> Just did.



> It seems like it's impossible to submit an app that includes the DeepSpeech RN module to App Store Connect and Test Flight. Depending on how you compile the .framework it either fails to Archive with missing symbols (despite running fine on a real device in Release mode), is unable to upload at all for a million different reasons, or uploads and is rejected for ""ITMS-90426: Invalid Swift Support - The SwiftSupport folder is missing. Rebuild your app using the current public (GM) version of Xcode and resubmit it.""
> 
> One solution on the internet suggested disabling bitcode, but that just caused a million upload errors related to misaligned segmentations of some sort. I've been working at this for days and I'm completely stumped! @reuben If you'd be able to bundle the framework in a cocoapod even without libdeepspeech.so that would be extremely helpful. I think my understanding of how linkers and compilers work isn't at the point yet where I can solve this problem without tripping over the solution after a significant amount of random trial (if ever).



> It seems like it's impossible to submit an app that includes the DeepSpeech RN module to App Store Connect and Test Flight. Depending on how you compile the .framework it either fails to Archive with missing symbols (despite running fine on a real device in Release mode), is unable to upload at all for a million different reasons, or uploads and is rejected for ""ITMS-90426: Invalid Swift Support - The SwiftSupport folder is missing. Rebuild your app using the current public (GM) version of Xcode and resubmit it.""
> 
> One solution on the internet suggested disabling bitcode, but that just caused a million upload errors related to misaligned segmentations of some sort. I've been working at this for days and I'm completely stumped! @reuben If you'd be able to bundle the framework in a cocoapod even without libdeepspeech.so that would be extremely helpful. I think my understanding of how linkers and compilers work isn't at the point yet where I can solve this problem without tripping over the solution after a significant amount of random trial (if ever).



Have you found a solution?

My IOS app also encountered this problem when it was submitted to the store",clear actually need rebuild use copy infra building wrapper framework library easily doable source open use like see yes already token erroneously marked private set instead public private set unfortunately also know little bring library also best interest store work maybe urgent maybe combine get work although building library write telegram maybe setup little sprint like impossible submit module store connect test flight depending compile either archive missing despite running fine real device release mode unable million different invalid swift support folder missing rebuild current public version resubmit one solution million related sort working day completely able bundle framework even without would extremely helpful think understanding work point yet solve problem without tripping solution significant amount random trial ever like impossible submit module store connect test flight depending compile either archive missing despite running fine real device release mode unable million different invalid swift support folder missing rebuild current public version resubmit one solution million related sort working day completely able bundle framework even without would extremely helpful think understanding work point yet solve problem without tripping solution significant amount random trial ever found solution also problem store,issue,positive,negative,neutral,neutral,negative,negative
690127066,Tentative PR #3316 shows we have a bug on node-gyp-cache: electron and nodejs headers gets merged together.,tentative bug electron together,issue,negative,neutral,neutral,neutral,neutral,neutral
689903945,"> > For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we multiply this number by `0.5`, we get `-1.75`, therefore _doubling_ the likelihood of that sequence.
> 
> This isn't how log probabilities work, you're making exponential increases in the probability here. exp(-3.5) ~= 0.03 and exp(-1.75) ~= 0.17. This, combined with the fact that a single word will be boosted several times in the same beam as it appears in multiple n-grams, makes it hard to reason about the behavior of the coefficient. It should probably be an additive factor (multiplication in probability space).

Even though my initial intuition was wrong about how the boosting compounds, I still like the UX. Namely, if you're using this feature, and trying to find the right boosting coefficient for your data, you would know to sweep between 0 and 1, which isn't hard. 

with an additive effect, the search space now goes from `(0,1)` to `(0,infinity)`. The math is better, but the UX seems worse. I make the changes in 184189c5149b9644b0c1dd32f872609922e1174c, but I still have doubts. Thoughts? ",example likelihood word sequence like cheese multiply number get therefore likelihood sequence log work making exponential probability combined fact single word several time beam multiple hard reason behavior coefficient probably additive factor multiplication probability space even though initial intuition wrong still like namely feature trying find right coefficient data would know sweep hard additive effect search space go infinity math better worse make still,issue,negative,negative,neutral,neutral,negative,negative
689558852,"> Sorry @lissyx, I thought we were still discussing, it currently is the old version, I didn't change it yet. Will do and see whether I can attach it to this pr. Haven't changed a merged one yet.

my bad, just open a new PR and fix it :)",sorry thought still currently old version change yet see whether attach one yet bad open new fix,issue,negative,negative,negative,negative,negative,negative
689554365,"Sorry @lissyx, I thought we were still discussing, it currently is the old version, I didn't change it yet. Will do and see whether I can attach it to this pr. Haven't changed a merged one yet.",sorry thought still currently old version change yet see whether attach one yet,issue,negative,negative,negative,negative,negative,negative
689551612,"Fine, if you both agree it's enough let's ship it!",fine agree enough let ship,issue,positive,positive,positive,positive,positive,positive
689532407,"Agree with Olaf, just telling people to clone the latest stable version should be fine. No amount of extra warning will prevent some people from messing up, we just want to have *some* explicit mention of using the stable version in the training docs.


> Am 09.09.2020 um 10:39 schrieb Olaf Thiele <notifications@github.com>:
> 
> ﻿
> I understand what @lissyx wants to state, but it sounds a bit overly complicated to me. You don't have to justify yourselves in the first paragraph, this is a great project :-) This PR is just meant to reduce the number of people who don't read and simply copy from the docs and then file bug reports. How about we just put
> 
> Clone the latest released stable branch from Github (e.g. 0.8.2, check here):
> 
> and leave all the rest out? We state to use the master branch in the next sentence and people who want to start right away can do so. And those who do have a programming background and want to contribute know to look into the contributing file. @reuben?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",agree telling people clone latest stable version fine amount extra warning prevent people messing want explicit mention stable version training um understand state bit overly complicated justify first paragraph great project meant reduce number people read simply copy file bug put clone latest stable branch check leave rest state use master branch next sentence people want start right away background want contribute know look file reply directly view,issue,positive,positive,positive,positive,positive,positive
689530917,"I guess we never stopped wanting it. But this is connected to tag-specific CI and heavily affected by the decisions made in #3317 so should probably wait for it.

>> Am 09.09.2020 um 10:18 schrieb lissyx <notifications@github.com>:
> ﻿
> This might be something we want now? cc @reuben
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",guess never stopped wanting connected heavily affected made probably wait um might something want reply directly view,issue,negative,negative,neutral,neutral,negative,negative
689427495,"Thanks for your patience, now that we have ensured renaming has been properly reverted, and we have fixed our macOS CI, I have been able to push a new alpha, which should avoid this error.",thanks patience properly fixed able push new alpha avoid error,issue,negative,positive,positive,positive,positive,positive
689425098,"It should basically be about:
 - adding new versions to `taskcluster/tc-all-vars.sh:SUPPORTED_ELECTRONJS_VERSIONS`
 - adding new versions test files (copy 9.2, rename, change version reference inside):
```
$ ll taskcluster/test-electronjs_v9.2*
-rw-rw-r-- 1 alex alex 788 sept.  9 10:22 taskcluster/test-electronjs_v9.2_16k-linux-amd64-opt.yml
-rw-rw-r-- 1 alex alex 783 sept.  9 10:22 taskcluster/test-electronjs_v9.2_8k-linux-amd64-opt.yml
-rw-rw-r-- 1 alex alex 575 sept.  9 10:22 taskcluster/test-electronjs_v9.2-darwin-amd64-opt.yml
-rw-rw-r-- 1 alex alex 596 sept.  9 10:22 taskcluster/test-electronjs_v9.2_multiarchpkg-win-amd64-opt.yml
-rw-rw-r-- 1 alex alex 603 sept.  9 10:22 taskcluster/test-electronjs_v9.2_multiarchpkg-win-cuda-opt.yml
-rw-rw-r-- 1 alex alex 612 sept.  9 10:22 taskcluster/test-electronjs_v9.2_multiarchpkg-win-tflite-opt.yml
-rw-rw-r-- 1 alex alex 561 sept.  9 10:22 taskcluster/test-electronjs_v9.2-win-amd64-opt.yml
```",basically new new test copy rename change version reference inside,issue,negative,positive,positive,positive,positive,positive
689418151,"I understand what @lissyx wants to state, but it sounds a bit overly complicated to me. You don't have to justify yourselves in the first paragraph, this is a great project :-) This PR is just meant to reduce the number of people who don't read and simply copy from the docs and then file bug reports. How about we just put

`Clone the latest released stable branch from Github (e.g. 0.8.2, check here):`

and leave all the rest out? We state to use the master branch in the next sentence and people who want to start right away can do so. And those who do have a programming background and want to contribute know to look into the contributing file. @reuben?",understand state bit overly complicated justify first paragraph great project meant reduce number people read simply copy file bug put clone latest stable branch check leave rest state use master branch next sentence people want start right away background want contribute know look file,issue,positive,positive,positive,positive,positive,positive
689405605,"Without more information and no feedback, I'm closing this bug. Please reopen / send PR if you need to.",without information feedback bug please reopen send need,issue,negative,neutral,neutral,neutral,neutral,neutral
688960192,"While this looks interesting, Github issues are here to discuss about issues. Please continue that discussion on Discourse.",interesting discus please continue discussion discourse,issue,positive,positive,positive,positive,positive,positive
688959384,"> Looks you are using Visual Studio 2019, I confirm it is working well with v0.8 and vs 2019, please check the installed NuGets.

So this is indeed a support request, not a bug. @avmetze Please follow instructions and reach for support on Discourse.",visual studio confirm working well please check indeed support request bug please follow reach support discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
688911631,"Current status:
 - `--disk_cache` does not seem to cache everything as expected on some builds (macOS rebuilds too many things)
 - removal of `tc-workdir` turns out to be not as easy as possible:
   - pyenv breaks because of task_dir name containing a timestamp
   - homebrew breaks because of the same
   - windows builds breaks because of the same
 - symlinking `tc-workdir` does not work either so far:
   - pyenv / homebrew does a mix of things that ends up in picking the task_dir with the timestamp
   - windows / bazel / 7zip chokes on relative symlinks somehow",current status seem cache everything many removal turn easy possible name work either far mix zip relative somehow,issue,negative,positive,positive,positive,positive,positive
688832126,"I'm the student of @ftyers. We have tried using the HDF5 embedding produced by wav2vec to train DeepSpeech. Currently the implementation is a customized Docker image (on Docker Hub) and a monkey-patch to DeepSpeech (soon I'll tidy it up and modify on top of a fork of DeepSpeech instead). The code and instructions are available in repository [Contextualist/DeepSpeech-build](https://github.com/Contextualist/DeepSpeech-build).

Summary of what the monkey-patch does:
- Loader for `.h5context` files (read as HDF5 and extract field `'features'`).
- Disable audio transcoding and augmentation.
- Disable MFCC featurization
- Set input dimension to 512 instead of 26 (which is for MFCC).

We've tried this on 136hrs of speech for pre-training + 0.5hr speech for training, and it yields result comparable to transfer learning (using DeepSpeech's released English model) result. We got a CER of 0.465.
",student tried produced train currently implementation docker image docker hub soon tidy modify top fork instead code available repository summary loader read extract field disable audio augmentation disable set input dimension instead tried speech speech training result comparable transfer learning model result got,issue,negative,positive,positive,positive,positive,positive
688824920,"If the memory usage is acceptable (you will tell me), I will use `unique_ptr` instead `shared_ptr` and deallocate at the end of each stream.",memory usage acceptable tell use instead end stream,issue,negative,neutral,neutral,neutral,neutral,neutral
688820534,"> maybe the standard library implementation pools them internaly ?

In any case that could vary across standard libraries. Instead of using a shared_ptr can't you just do a full pool deallocation at the end of a stream?",maybe standard library implementation case could vary across standard instead ca full pool end stream,issue,negative,positive,positive,positive,positive,positive
688819399,"Just to be clear, my object pool provides unique_ptr that I move to shared_ptr. So, the control block is still allocated dynamically (maybe the standard library implementation pools them internaly ?).",clear object pool move control block still dynamically maybe standard library implementation,issue,negative,positive,neutral,neutral,positive,positive
688816373,"Ok, good.

I have just tried the object pool I have, and it seems that it speeds up again by about 6% on my samples. ",good tried object pool,issue,negative,positive,positive,positive,positive,positive
688814510,"I'm doing some memory profiling but it's going very slowly, will report results once I have them.",memory going slowly report,issue,negative,negative,negative,negative,negative,negative
688766507,"This version is the fastest one yet, averaging a LibriSpeech-test-clean test epoch in 272s, which is a 13% slowdown from current master.",version one yet test epoch slowdown current master,issue,negative,neutral,neutral,neutral,neutral,neutral
688761243,"On my samples, which are inferences on one file at a time, the current code is roughly 10% faster than before the timestep tree. But I have some overhead around so it might be better on your test set.

I have done some research on shared_ptr and object pools yesterday, and I need some feedback before going further. I will fix spaces when we agree on the implementation. 

I have not tried the two other improvements that I have suggested. Because there is no standard object pool, and last time I checked, open source implementations have issues. An object pool providing `std::shared_ptr` is even more problematic, because `std::shared_ptr` dynamically allocates a control block. Allocating the object in an object pool and leaving the control block dynamically allocated does not reduce the number of dynamic allocations compared to using `std::make_shared`. Unfortunately, the standard library does not expose the type of the control block, so that we cannot create an object pool of ""control block+object"".

So, having both the object pool and the shared_ptr requires to reimplement a shared_ptr and an object pool, which represents some work. 

I would like to know, with the current code, on your test set, if the speed should be improved more and if the memory usage is acceptable.
If only the speed should be improved, I can use `unique_ptr` and an object pool that I have or one of your choice.
If only the memory should be improved, I can fix it quite easily the way I said.
If both should be improved, do you agree that I need a custom shared_ptr and a custom object pool ?",one file time current code roughly faster tree overhead around might better test set done research object yesterday need feedback going fix agree implementation tried two standard object pool last time checked open source object pool providing even problematic dynamically control block object object pool leaving control block dynamically reduce number dynamic unfortunately standard library expose type control block create object pool control object pool object pool work would like know current code test set speed memory usage acceptable speed use object pool one choice memory fix quite easily way said agree need custom custom object pool,issue,positive,positive,neutral,neutral,positive,positive
688735817,"> I have implemented the timestep tree. There are still two potential issues :
> 
>     1. There should be less copies of timesteps but the number of dynamic allocation will not be lower, because I have replaced each vector copy by a dynamic allocation of a new timestep tree node. This can be solved by using an object pool.
> 
>     2. Obsolete data in the timestep tree is not removed, which might cause too much memory to be used. To solve this, I could remove the `children` field and use a vector of timestep nodes at current timestep instead (there is no forward traversal of the timestep tree). Then, `shared_ptr`s would destroy unreferenced data when `remove()` is called on the `PathTrie` nodes.

Have you been able to run figures to compare the impact before / after ? That would really help us!",tree still two potential le number dynamic allocation lower vector copy dynamic allocation new tree node object pool obsolete data tree removed might cause much memory used solve could remove field use vector current instead forward traversal tree would destroy unreferenced data remove able run compare impact would really help u,issue,negative,positive,neutral,neutral,positive,positive
688720466,"> > > @lissyx how is this issue supposed to be solved ? do i need to change the version file ? i don't understand ?
> > 
> > 
> > Use a stable version, as documented
> 
> FYI I'm running into the same issue following the documentation (https://deepspeech.readthedocs.io/en/latest/TRAINING.html), which just instructs to clone the master, and doesn't specify a version.

Burning versions everywhere turns to be a maintenance nightmare, https://deepspeech.readthedocs.io/en/latest/ already refers to 0.8.1 stable version.

Please send PR to improve the doc if you can find correct wording that is maintainable.",issue supposed need change version file understand use stable version running issue following documentation clone master specify version burning everywhere turn maintenance nightmare already stable version please send improve doc find correct wording maintainable,issue,positive,neutral,neutral,neutral,neutral,neutral
688717456,"> > @lissyx how is this issue supposed to be solved ? do i need to change the version file ? i don't understand ?
> 
> Use a stable version, as documented

FYI I'm running into the same issue following the documentation (https://deepspeech.readthedocs.io/en/latest/TRAINING.html), which just instructs to clone the master, and doesn't specify a version.",issue supposed need change version file understand use stable version running issue following documentation clone master specify version,issue,negative,neutral,neutral,neutral,neutral,neutral
688520855,Hi @caseybasichis I have a student who has been working on integrating `wav2vec` into DeepSpeech. I'll ask him to comment here.,hi student working ask comment,issue,negative,neutral,neutral,neutral,neutral,neutral
688362642,"Looks you are using Visual Studio 2019, I confirm it is working well with v0.8 and vs 2019, please check the installed NuGets.",visual studio confirm working well please check,issue,positive,neutral,neutral,neutral,neutral,neutral
688360410,"Ugh @avmetze sorry for the delay, can you check if Visual Studio restored packages? Under references, manage NuGet packages and restore. ",ugh sorry delay check visual studio manage restore,issue,negative,negative,negative,negative,negative,negative
688275085,"I have implemented the timestep tree. There are still two potential issues :
1. There should be less copies of timesteps but the number of dynamic allocation will not be lower, because I have replaced each vector copy by a dynamic allocation of a new timestep tree node. This can be solved by using an object pool. 
2. Obsolete data in the timestep tree is not removed, which might cause too much memory to be used. To solve this, I could remove the `children` field and use a vector of timestep nodes at current timestep instead (there is no forward traversal of the timestep tree). Then, `shared_ptr`s would destroy unreferenced data when `remove()` is called on the `PathTrie` nodes.",tree still two potential le number dynamic allocation lower vector copy dynamic allocation new tree node object pool obsolete data tree removed might cause much memory used solve could remove field use vector current instead forward traversal tree would destroy unreferenced data remove,issue,negative,positive,neutral,neutral,positive,positive
688118104,I see so the problem is to find a way that it will be maintainable after it released right? But it really possible to do that? because I need some clue before I really do the research about this.,see problem find way maintainable right really possible need clue really research,issue,negative,positive,positive,positive,positive,positive
687308401,"> To be clear, you don't actually need to rebuild libdeepspeech.so yourself, you can use the copy from our CI infra. Building just the wrapper framework library should be easily doable from source, just open it with Xcode or use xcodebuild like we do in CI (see `do_deepspeech_ios_framework_build` in `taskcluster/tc-build-utils.sh`).

Yes, I'm already doing that because the Metadata and Token arrays were (erroneously?) marked as `private(set)` instead of `public private(set)`.



> @zaptrem Unfortunately, I also know very little about what it takes to bring this library to CocoaPods, but it is also in my best interest that submitting to the store works (but maybe not as urgent as for you). Maybe we can combine our efforts and get it to work, although @reuben seems to have greatest expertise in building the library for iOS.
> 
> You can write me on Telegram under the same username maybe we can setup a little Sprint for that.

Just did.",clear actually need rebuild use copy infra building wrapper framework library easily doable source open use like see yes already token erroneously marked private set instead public private set unfortunately also know little bring library also best interest store work maybe urgent maybe combine get work although building library write telegram maybe setup little sprint,issue,positive,positive,neutral,neutral,positive,positive
687207674,@lissyx indeed you are right I got many other issues with `v0.8.0-alpha.4` but this one advertised on github works well `DeepSpeech 0.8.2`,indeed right got many one work well,issue,negative,positive,positive,positive,positive,positive
687194378,"> @lissyx I installed this version `v0.8.0-alpha.4` and the `pip3 install --upgrade -e .` command successfully worked. i hope you fix the issue with the master version in the future. for now thanks.

There is no bug, its expected behavior because we unfortunately had to revert name change.

Latest stable release is advertised on github releases page",version pip install upgrade command successfully worked hope fix issue master version future thanks bug behavior unfortunately revert name change latest stable release page,issue,positive,positive,positive,positive,positive,positive
687147693,@lissyx I installed this version `v0.8.0-alpha.4` and the `pip3 install --upgrade -e .` command successfully worked. i hope you fix the issue with the master version in the future. for now thanks. ,version pip install upgrade command successfully worked hope fix issue master version future thanks,issue,positive,positive,positive,positive,positive,positive
687116228,"> @lissyx how is this issue supposed to be solved ? do i need to change the version file ? i don't understand ?

Use a stable version, as documented ",issue supposed need change version file understand use stable version,issue,negative,neutral,neutral,neutral,neutral,neutral
686937482,"@lissyx how is this issue supposed to be solved ? do i need to change the version file ? i don't understand ?

the issue comes while installing with this command from the deepspeech documentation. 
`pip3 install --upgrade -e .`

And the output of the version file is 
`(deepspeech-train-venv) root@ac551c260a1a:/content/gdrive//DeepSpeech# cat training/deepspeech_training/VERSION`

`0.9.0-alpha.7`",issue supposed need change version file understand issue come command documentation pip install upgrade output version file root cat,issue,negative,neutral,neutral,neutral,neutral,neutral
686717305,"> FWIW think this would be an excellent addition, TF or torch model, maybe leverage transformer library or something similar

I agree. The current model seems to underperform the competition In the real world while requiring a much larger filesize.  In the last two years transformers have revolutionized the LM landscape. Architectures like BERT/DistilBERT/XLM also open interesting opportunities for improving a transcribed word based on context heard afterwards.
",think would excellent addition torch model maybe leverage transformer library something similar agree current model competition real world much last two landscape like also open interesting improving word based context afterwards,issue,positive,positive,positive,positive,positive,positive
686694714,"FWIW think this would be an excellent addition, TF or torch model, maybe leverage transformer library or something similar",think would excellent addition torch model maybe leverage transformer library something similar,issue,positive,positive,positive,positive,positive,positive
686644016,"As documented, please use discourse for that kind of support request. ",please use discourse kind support request,issue,positive,positive,positive,positive,positive,positive
685755390,@DewiBrynJones Do you mind also sending a PR for `master` and for `r0.8` to update our documentation: `doc/TRAINING.rst`?,mind also sending master update documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
685746246,"I can do it eventually, but I don't know when. 
I wonder if it would be a good case to throw an exception instead of an error code. I usually don't like exception, but python already have them and I guess C++ exceptions could be converted somehow to python exceptions.",eventually know wonder would good case throw exception instead error code usually like exception python already guess could converted somehow python,issue,negative,positive,positive,positive,positive,positive
685696324,"Ah, I was just about to create this pull request after verifying with:

```
$ make Dockerfile.train DEEPSPEECH_REPO=https://github.com/techiaith/DeepSpeech.git  DEEPSPEECH_SHA=r0.8
$ docker build --rm -t mozilla/deepspeech:r0.8 -f Dockerfile.train .
```

which builds and completes LDC93S1 test successfully.

Cheers!
",ah create pull request make docker build test successfully,issue,positive,positive,positive,positive,positive,positive
685690231,"@zaptrem even getting android debug build requires non trivial amount of work, there are several tensorflow r2.3 debug build specific breakages reported upstream, some not yet with a fix, some only fixed on master. This, added to the complex stack up to kotlin makes me unable to quickly investigate: we really need your help here into trying and reproduce the bogus behavior with pure linux/amd64 builds.",even getting android build non trivial amount work several build specific upstream yet fix fixed master added complex stack unable quickly investigate really need help trying reproduce bogus behavior pure,issue,negative,positive,neutral,neutral,positive,positive
685688624,"Looks like there are many TF 2.3 issues for debug builds, I'm not sure it can be added as easily as I would have hoped.",like many sure added easily would hoped,issue,positive,positive,positive,positive,positive,positive
685602979,"@godefv Given the recent changes, I think we should take the time to properly do that change. Do you want to take care of that?",given recent think take time properly change want take care,issue,positive,neutral,neutral,neutral,neutral,neutral
685588467,"I am using 0.7.4 DeepSpeech version and seeing the confidence value is negative and not correct among the candidate transcripts
where the transcripts is correct , the confidence value is less and where the transcript is not correct , confidence value is more.",version seeing confidence value negative correct among candidate correct confidence value le transcript correct confidence value,issue,positive,negative,negative,negative,negative,negative
685505122,"Yep, definitely out of scope for our project, and I have a hard time picturing how we could land this into our code in a way that is maintainable. Leveraging the architecture and the pre-trained checkpoints to target this new task should be possible though.",yep definitely scope project hard time could land code way maintainable architecture target new task possible though,issue,positive,negative,neutral,neutral,negative,negative
685502717,"> is it possible that we could modify deep speech architecture

Hacking is always welcome, but I'm unsure it is in the current scope of our project and whether this can be sustainable. cc @reuben ?",possible could modify deep speech architecture hacking always welcome unsure current scope project whether sustainable,issue,negative,positive,positive,positive,positive,positive
685489554,"> > I took the liberty to assign you the bug and I'm waiting on your PR since you have nailed that down quite well :)
> 
> Ha ha! me and my big mouth. i'll get on it.

No, it's really welcome, but if you can't do it I'll take care of it, no pressure here.",took liberty assign bug waiting since quite well ha ha big mouth get really welcome ca take care pressure,issue,positive,positive,positive,positive,positive,positive
685480605,">  I took the liberty to assign you the bug and I'm waiting on your PR since you have nailed that down quite well :)

Ha ha! me and my big mouth. i'll get on it. ",took liberty assign bug waiting since quite well ha ha big mouth get,issue,positive,neutral,neutral,neutral,neutral,neutral
685477826,@DewiBrynJones I took the liberty to assign you the bug and I'm waiting on your PR since you have nailed that down quite well :),took liberty assign bug waiting since quite well,issue,positive,neutral,neutral,neutral,neutral,neutral
685476173,"> I got the 0.8.2 release to build and train models with the following workaround to use 49.6.3:

It seems to work here as well.

I'd welcome a PR against `r0.8` and against `master` that:
 - bumps pip==20.2.2 version
 - bumps setuptools==49.6.0 version
 - updates the documentation as well

And we could make a 0.8.3 to release the fix as well.",got release build train following use work well welcome master version version documentation well could make release fix well,issue,positive,positive,positive,positive,positive,positive
685471950,"It looks like we are facing https://github.com/pypa/setuptools/issues/2350:
```
Step 16/22 : RUN DS_NODECODER=y DS_NOTENSORFLOW=y pip3 install --upgrade .
 ---> Using cache
 ---> 5c5492c4b3b1
Step 17/22 : RUN find / -type f | grep deepspeech_training
 ---> Running in dc44939c8fac
/usr/local/lib/python3.6/dist-packages/deepspeech_training/GRAPH_VERSION
/usr/local/lib/python3.6/dist-packages/deepspeech_training/VERSION
/usr/local/lib/python3.6/dist-packages/deepspeech_training/__init__.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/__pycache__/__init__.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/__pycache__/evaluate.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/__pycache__/train.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/evaluate.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/train.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__init__.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/__init__.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/audio.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/augmentations.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/check_characters.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/checkpoints.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/config.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/downloader.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/evaluate_tools.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/feeding.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/flags.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/gpu.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/helpers.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/importers.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/logging.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/sample_collections.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/stm.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/taskcluster.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/__pycache__/text.cpython-36.pyc
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/audio.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/augmentations.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/check_characters.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/checkpoints.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/config.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/downloader.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/evaluate_tools.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/feeding.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/flags.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/gpu.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/helpers.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/importers.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/logging.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/sample_collections.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/stm.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/taskcluster.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training/util/text.py
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/INSTALLER
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/LICENSE
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/METADATA
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/RECORD
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/REQUESTED
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/WHEEL
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/direct_url.json
/usr/local/lib/python3.6/dist-packages/deepspeech_training-0.9.0a7.dist-info/top_level.txt
/DeepSpeech/training/deepspeech_training/GRAPH_VERSION
/DeepSpeech/training/deepspeech_training/VERSION
/DeepSpeech/training/deepspeech_training/__init__.py
/DeepSpeech/training/deepspeech_training/evaluate.py
/DeepSpeech/training/deepspeech_training/train.py
/DeepSpeech/training/deepspeech_training/util/__init__.py
/DeepSpeech/training/deepspeech_training/util/audio.py
/DeepSpeech/training/deepspeech_training/util/augmentations.py
/DeepSpeech/training/deepspeech_training/util/check_characters.py
/DeepSpeech/training/deepspeech_training/util/checkpoints.py
/DeepSpeech/training/deepspeech_training/util/config.py
/DeepSpeech/training/deepspeech_training/util/downloader.py
/DeepSpeech/training/deepspeech_training/util/evaluate_tools.py
/DeepSpeech/training/deepspeech_training/util/feeding.py
/DeepSpeech/training/deepspeech_training/util/flags.py
/DeepSpeech/training/deepspeech_training/util/gpu.py
/DeepSpeech/training/deepspeech_training/util/helpers.py
/DeepSpeech/training/deepspeech_training/util/importers.py
/DeepSpeech/training/deepspeech_training/util/logging.py
/DeepSpeech/training/deepspeech_training/util/sample_collections.py
/DeepSpeech/training/deepspeech_training/util/stm.py
/DeepSpeech/training/deepspeech_training/util/taskcluster.py
/DeepSpeech/training/deepspeech_training/util/text.py
Removing intermediate container dc44939c8fac
```

```
 ---> c4ad9c34f035
Step 16/22 : RUN DS_NODECODER=y DS_NOTENSORFLOW=y pip3 install --upgrade -e .
 ---> Using cache            
 ---> 807b068dd581                                                      
Step 17/22 : RUN find / -type f | grep deepspeech_training        
 ---> Running in 483fa03cf9ff                                         
/DeepSpeech/training/deepspeech_training/GRAPH_VERSION                                        
/DeepSpeech/training/deepspeech_training/VERSION                                              
/DeepSpeech/training/deepspeech_training/__init__.py                                       
/DeepSpeech/training/deepspeech_training/evaluate.py                  
/DeepSpeech/training/deepspeech_training/train.py                  
/DeepSpeech/training/deepspeech_training/util/__init__.py                  
/DeepSpeech/training/deepspeech_training/util/audio.py                                             
/DeepSpeech/training/deepspeech_training/util/augmentations.py                                  
/DeepSpeech/training/deepspeech_training/util/check_characters.py                                                                                                                                       
/DeepSpeech/training/deepspeech_training/util/checkpoints.py                                                                                                                                            
/DeepSpeech/training/deepspeech_training/util/config.py                                                                                                                                                 
/DeepSpeech/training/deepspeech_training/util/downloader.py                                      
/DeepSpeech/training/deepspeech_training/util/evaluate_tools.py                                                                                                                                         
/DeepSpeech/training/deepspeech_training/util/feeding.py                                                                                                                                                
/DeepSpeech/training/deepspeech_training/util/flags.py                                            
/DeepSpeech/training/deepspeech_training/util/gpu.py                                            
/DeepSpeech/training/deepspeech_training/util/helpers.py                                      
/DeepSpeech/training/deepspeech_training/util/importers.py                                        
/DeepSpeech/training/deepspeech_training/util/logging.py                                                                                                                                                
/DeepSpeech/training/deepspeech_training/util/sample_collections.py                               
/DeepSpeech/training/deepspeech_training/util/stm.py                                                                                                                                                    
/DeepSpeech/training/deepspeech_training/util/taskcluster.py                                  
/DeepSpeech/training/deepspeech_training/util/text.py                                                                                                                                                   
/DeepSpeech/training/deepspeech_training.egg-info/PKG-INFO                                     
/DeepSpeech/training/deepspeech_training.egg-info/SOURCES.txt           
/DeepSpeech/training/deepspeech_training.egg-info/dependency_links.txt          
/DeepSpeech/training/deepspeech_training.egg-info/requires.txt                     
/DeepSpeech/training/deepspeech_training.egg-info/top_level.txt               
Removing intermediate container 483fa03cf9ff                             
 ---> c3ba6f5990f0                                                           
Step 18/22 : RUN python3 util/taskcluster.py --source tensorflow --branch r1.15         --artifact convert_graphdef_memmapped_format  --target .
 ---> Running in 51030dd88d0d                                             
Training package is not installed. See training documentation.          
Traceback (most recent call last):                                    
  File ""util/taskcluster.py"", line 7, in <module>                         
    from deepspeech_training.util import taskcluster as dsu_taskcluster     
ModuleNotFoundError: No module named 'deepspeech_training'                
The command '/bin/bash -c python3 util/taskcluster.py --source tensorflow --branch r1.15         --artifact convert_graphdef_memmapped_format  --target .' returned a non-zero code: 1
```",like facing step run pip install upgrade cache step run find running removing intermediate container step run pip install upgrade cache step run find running removing intermediate container step run python source branch artifact target running training package see training documentation recent call last file line module import module command python source branch artifact target returned code,issue,negative,neutral,neutral,neutral,neutral,neutral
685464602,"Great!

 I got the 0.8.2 release to build and train models with the following workaround to use 49.6.3:

 - I take my own copy of Dockerfile.train.tmpl and update the setuptools version:  https://github.com/techiaith/docker-deepspeech-cy/blob/deepspeech-0.8.2/Dockerfile.train.tmpl#L44

 - Then copy into cloned DS and build: https://github.com/techiaith/docker-deepspeech-cy/blob/deepspeech-0.8.2/Makefile#L21

I could try and debug pip/setuptools the latest on master (?) if it's any help (although I'm no expert)



",great got release build train following use take copy update version copy build could try latest master help although expert,issue,positive,positive,positive,positive,positive,positive
685452551,"This really comes at a very bad time, we have so much to do that is equally important, I can't spare the time to try and debug pip/setuptools as well ...",really come bad time much equally important ca spare time try well,issue,negative,negative,neutral,neutral,negative,negative
685452219,"> > People report that `SETUPTOOLS_USE_DISTUTILS=stdlib` env var helps.
> 
> in the case of Docker, that would still need a change in the Dockerfile (you can't set and pass an environment variable in a `docker build` command) . So it's not a fix for older releases or even the current 0.8.2 stable release. For the next release, you might as well update the setuptools version number (?)

There's so much mess, I really don't get. Some of what seems to be one of the maintainer's  of the project seems to imply there is no bug here, but seeing how this explodes everywhere it looks suspicious.

As to the setuptools version, in my testing it was not enough.",people report case docker would still need change ca set pas environment variable docker build command fix older even current stable release next release might well update version number much mess really get one maintainer project imply bug seeing everywhere suspicious version testing enough,issue,negative,positive,neutral,neutral,positive,positive
685076994,"> 
> 
> People report that `SETUPTOOLS_USE_DISTUTILS=stdlib` env var helps.

in the case of Docker, that would still need a change in the Dockerfile (you can't set and pass an environment variable in a `docker build` command) . So it's not a fix for older releases or even the current 0.8.2 stable release. For the next release, you might as well update the setuptools version number (?)
 ",people report case docker would still need change ca set pas environment variable docker build command fix older even current stable release next release might well update version number,issue,positive,positive,neutral,neutral,positive,positive
684837380,"I agree...
I had thought about making a second tree as well, but I was hoping that the simpler change I have made would be enough.",agree thought making second tree well simpler change made would enough,issue,positive,neutral,neutral,neutral,neutral,neutral
684782271,"@JRMeyer To keep your API simpler, I suggest you move to a single entry point:
```
DEEPSPEECH_EXPORT
int DS_AddHotWord(ModelState* aCtx, const char* word, float boostCoefficient)
```

This entry point would add a new `word` to your `std::vector` (or set, maybe, because it would guarantee unicity). If the hot word does not exists, we add it with the given boost, and if it is already in the set, we update the coefficient

Depending on usecase, it could also be cool to expose (though I'm unsure it is really required):
```
DEEPSPEECH_EXPORT
int DS_ClearHotWords(ModelState* aCtx)
```
This would simply re-init the set of hot words

With this API, you could more easily expose and update all our bindings (`const char **` are a bit painful via SWIG) to make the feature available.",keep simpler suggest move single entry point char word float entry point would add new word set maybe would guarantee unicity hot word add given boost already set update coefficient depending could also cool expose though unsure really would simply set hot could easily expose update char bit painful via swig make feature available,issue,negative,positive,positive,positive,positive,positive
684775274,"To be clear, you don't actually need to rebuild libdeepspeech.so yourself, you can use the copy from our CI infra. Building just the wrapper framework library should be easily doable from source, just open it with Xcode or use xcodebuild like we do in CI (see `do_deepspeech_ios_framework_build` in `taskcluster/tc-build-utils.sh`).",clear actually need rebuild use copy infra building wrapper framework library easily doable source open use like see,issue,positive,positive,positive,positive,positive,positive
684774674,"Some searching turned this up, which apparently needs to be used when building deepspeech_ios.framework: https://stackoverflow.com/a/36546996/346048",searching turned apparently need used building,issue,negative,positive,neutral,neutral,positive,positive
684767739,"> For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we multiply this number by `0.5`, we get `-1.75`, therefore _doubling_ the likelihood of that sequence.

This isn't how log probabilities work, you're making exponential increases in the probability here. exp(-3.5) ~= 0.03 and exp(-1.75) ~= 0.17. This, combined with the fact that a single word will be boosted several times in the same beam as it appears in multiple n-grams, makes it hard to reason about the behavior of the coefficient. It should probably be an additive factor (multiplication in probability space).",example likelihood word sequence like cheese multiply number get therefore likelihood sequence log work making exponential probability combined fact single word several time beam multiple hard reason behavior coefficient probably additive factor multiplication probability space,issue,negative,negative,neutral,neutral,negative,negative
684755561,"I suspect in order to minimize the regression, the timesteps sequence itself needs to be a tree structure as well. Even only copying the sequences once per time step that's still a lot of redundant data copying over the whole decoding process. If the timesteps sequence is an independent tree with PathTrie pointing to its nodes, then it can be walked up to obtain the final sequence at decoding end, and there's no heavy allocation and copying of timesteps vectors during decoding.",suspect order minimize regression sequence need tree structure well even per time step still lot redundant data whole process sequence independent tree pointing obtain final sequence end heavy allocation,issue,negative,negative,neutral,neutral,negative,negative
684751326,"> Could you run your performance test again with these last changes ?

It speeds it up a bit, to 324s per run.",could run performance test last bit per run,issue,negative,neutral,neutral,neutral,neutral,neutral
684643346,"> This PR enables hot-word boosting (from the C client) with the two new flags `--hot_words` and `--boost_coefficient`.

Can we not limit that to the C-client? It's very much likely people will want to use this part of the API from elsewhere, and in the current state, it's completely unknown whether this works or not.",client two new limit much likely people want use part elsewhere current state completely unknown whether work,issue,negative,positive,neutral,neutral,positive,positive
684492279,"@zaptrem Unfortunately, I also know very little about what it takes to bring this library to CocoaPods, but it is also in my best interest that submitting to the store works (but maybe not as urgent as for you). Maybe we can combine our efforts and get it to work, although @reuben seems to have greatest expertise in building the library for iOS. 

You can write me on Telegram under the same username maybe we can setup a little Sprint for that. 

",unfortunately also know little bring library also best interest store work maybe urgent maybe combine get work although building library write telegram maybe setup little sprint,issue,positive,positive,neutral,neutral,positive,positive
684373785,"It seems like it's impossible to submit an app that includes the DeepSpeech RN module to App Store Connect and Test Flight. Depending on how you compile the .framework it either fails to Archive with missing symbols (despite running fine on a real device in Release mode), is unable to upload at all for a million different reasons, or uploads and is rejected for ""ITMS-90426: Invalid Swift Support - The SwiftSupport folder is missing. Rebuild your app using the current public (GM) version of Xcode and resubmit it.""

One solution on the internet suggested disabling bitcode, but that just caused a million upload errors related to misaligned segmentations of some sort. I've been working at this for days and I'm completely stumped! @reuben If you'd be able to bundle the framework in a cocoapod even without libdeepspeech.so that would be extremely helpful. I think my understanding of how linkers and compilers work isn't at the point yet where I can solve this problem without tripping over the solution after a significant amount of random trial (if ever).

",like impossible submit module store connect test flight depending compile either archive missing despite running fine real device release mode unable million different invalid swift support folder missing rebuild current public version resubmit one solution million related sort working day completely able bundle framework even without would extremely helpful think understanding work point yet solve problem without tripping solution significant amount random trial ever,issue,negative,negative,neutral,neutral,negative,negative
684010078,Yeah there are a lot of reports of bad breakages because of 50.0.0. Unfortunately we wont be able to issue that kind of fix for older release so i prefer to wait and see for pypa/setuptools feedback on all those issues. ,yeah lot bad unfortunately wont able issue kind fix older release prefer wait see feedback,issue,negative,positive,neutral,neutral,positive,positive
683994986,"It builds successfully for me if you instead specify the last version of setuptools before today's 50.0.0 release:

`RUN pip3 install --upgrade pip==20.0.2 wheel==0.34.2 setuptools==49.6.0`



",successfully instead specify last version today release run pip install upgrade,issue,negative,positive,positive,positive,positive,positive
683908765,"Thanks for the feedback. 
There were indeed too many copies of timesteps vectors, so I have improved on that point in my last commit.
But I have only tested single inference. Could you run your performance test again with these last changes ?",thanks feedback indeed many point last commit tested single inference could run performance test last,issue,positive,positive,positive,positive,positive,positive
683805012,"> FWIW I'm getting this error as well when trying to rebuild DeepSpeech from my docker scripts for 0.7.4

Unfortunately, we can't upgrade this release. Also, forcing `setuptools==50.0.0` get past this error for me, but the `deepspeech_training` package does not get installed, it seems.",getting error well trying rebuild docker unfortunately ca upgrade release also forcing get past error package get,issue,negative,negative,negative,negative,negative,negative
683797533,"It's an issue at pypa setuptools...

https://github.com/pypa/setuptools/issues/2353

Hopefully this doesn't require any changes or workarounds on DeepSpeech's side. ",issue hopefully require side,issue,negative,neutral,neutral,neutral,neutral,neutral
683793121,"FWIW I'm getting this error as well when trying to rebuild DeepSpeech from my docker scripts for 0.7.4 

https://github.com/techiaith/docker-deepspeech-cy/blob/deepspeech-0.7.4/Makefile#L19

it used to build! If I change to 0.8.2 or latest on master, the same bug appears.
",getting error well trying rebuild docker used build change latest master bug,issue,negative,positive,positive,positive,positive,positive
683790730,"No, I don't think so. I'll close this thread and hope anyone can help with libopus :)",think close thread hope anyone help,issue,positive,neutral,neutral,neutral,neutral,neutral
683787953,"> [](https://github.com/orion-labs/opuslib/issues/18)
> 
> I do know where the issue is, my attempts to fix it have been unsuccessful. It's in this file:
> https://github.com/orion-labs/opuslib/blob/master/opuslib/api/__init__.py
> The find_library method always returns None on Windows by design. https://docs.python.org/3/library/ctypes.html?highlight=find_library
> If I find something I'll let you know :)

Ok, so the bug is absolutely not on our side? Then I really don't see how we can help :/. Still good to know it works.
If it's upstream, should we close this?",know issue fix unsuccessful file method always none design find something let know bug absolutely side really see help still good know work upstream close,issue,positive,positive,positive,positive,positive,positive
683786367,"> Also @coen22 just to be clear, while we don't support Windows training for the moment, several people reported successfully doing it but nobody cared enough to:
> 
> * share extended details
> * fix code
> * fix doc
> 
> So we simply can't know if ""it should work"" or if there are some pieces here and here that needs to be fixed. That's why even though I can't help on Windows-specific bits, I'd like we get it to work for you so maybe we can have a chance to fix code / doc?

Thank you, but mostly everything is working. training and inference are going great. The docs are also great, with some common sense I was able to work out how to set everything up on Windows. The augmentation s the only minor issue that isn't working and it's actually due to the python opuslib wrapper.

I've also reported the issue to the appropriate repository, as this isn't maintained by Mozilla.
https://github.com/orion-labs/opuslib/issues/18

I do know where the issue is, my attempts to fix it have been unsuccessful. It's in this file:
https://github.com/orion-labs/opuslib/blob/master/opuslib/api/__init__.py
The find_library method always returns None on Windows by design. https://docs.python.org/3/library/ctypes.html?highlight=find_library
If I find something I'll let you know :)",also clear support training moment several people successfully nobody enough share extended fix code fix doc simply ca know work need fixed even though ca help like get work maybe chance fix code doc thank mostly everything working training inference going great also great common sense able work set everything augmentation minor issue working actually due python wrapper also issue appropriate repository know issue fix unsuccessful file method always none design find something let know,issue,positive,positive,positive,positive,positive,positive
683753122,"I've benchmarked this PR with the 0.8.2 checkpoint and the Librispeech test clean dataset, by doing test epochs. Unfortunately, there's a significant performance regression, the epoch time went from 240s average to 360s with this PR applied. I think the idea is sound and does get us better timings, but the implementation needs to be different to avoid trashing memory with copying the entire timesteps vector for all prefixes.",test clean test unfortunately significant performance regression epoch time went average applied think idea sound get u better implementation need different avoid memory entire vector,issue,negative,positive,positive,positive,positive,positive
683733808,"Also @coen22 just to be clear, while we don't support Windows training for the moment, several people reported successfully doing it but nobody cared enough to:
 - share extended details
 - fix code
 - fix doc

So we simply can't know if ""it should work"" or if there are some pieces here and here that needs to be fixed. That's why even though I can't help on Windows-specific bits, I'd like we get it to work for you so maybe we can have a chance to fix code / doc?",also clear support training moment several people successfully nobody enough share extended fix code fix doc simply ca know work need fixed even though ca help like get work maybe chance fix code doc,issue,positive,positive,positive,positive,positive,positive
683730655,"> The issue isn't that the python opuslib isn't there, but rather that the opus binaries can't be found.

Well, sorry, but this is a Windows-level issue, I can't help.



> I simply downloaded the 0.8.0 source code and followed the install guide.

There's a reason we ask: simply saying you followed docs does not help us catch mistakes you might have made by looking at wrong doc, or misinterpreting.

e.g ""I simply downloaded the 0.8.0 source code "" do you mean a zip file or ""git clone"" then ""git checkout"" ?
Training from a zip can be broken, especially since we don't support training on Windows.



> Tensorflow works, I've already trained a model without augmentation

And we know there are TensorFlow-level bugs wrt CUDA and CUDNN, so if you add unsupported versions in the mix, it's going to make it more complex to debug. Yes, it's unrelated at that point, but if you already don't follow the docs on that point what kind of guarantee do we have you properly followed others docs?",issue python rather opus ca found well sorry issue ca help simply source code install guide reason ask simply saying help u catch might made looking wrong doc simply source code mean zip file git clone git training zip broken especially since support training work already trained model without augmentation know add unsupported mix going make complex yes unrelated point already follow point kind guarantee properly,issue,positive,negative,negative,negative,negative,negative
683704937,At the bottom of the changes page GitHub shows: You are viewing a condensed version of this merge commit. You can view the full changes here. ,bottom page condensed version merge commit view full,issue,negative,positive,positive,positive,positive,positive
683691727,"I can see now what you mean (clicking on your comment links) but I didn't change those files. 

Your link says: Showing 3 changed files with 10 additions and 8 deletions. 
But I can only see 1 changed file with 5 additions and 3 deletions in the overview here
",see mean comment link change link showing see file overview,issue,negative,negative,negative,negative,negative,negative
683689801,"> It's good but your commit is mixed with unrelated things, please rebase properly on master :/

?
Did you mix this up with another PR? ",good commit mixed unrelated please rebase properly master mix another,issue,positive,positive,positive,positive,positive,positive
683687485,"> > **CUDA/cuDNN version**: 10.1
> 
> Please triple check your setup, TensorFlow r1.15 is documented to require CUDA 10.0 ...

Tensorflow works, I've already trained a model without augmentation",version please triple check setup require work already trained model without augmentation,issue,negative,neutral,neutral,neutral,neutral,neutral
683686349,"> @coen22 You also don't explicitely document:
> 
> * how you setup things,
> * what version you are working on
> 
> We already have a dep against `opuslib`: https://github.com/mozilla/DeepSpeech/blob/v0.9.0-alpha.6/setup.py#L60 but since we have no stack shared I can't verify if it has been properly installed ?
> 
> > I've noticed that the 'init.py' doesn't include a case for Windows and find_library always returns 'None'.
> 
> Because we don't support training on Windows.

I'm using 0.8.0 right now. The issue isn't that the python opuslib isn't there, but rather that the opus binaries can't be found. 
But if it's really too complicated, I'll simply install Ubuntu.

I simply downloaded the 0.8.0 source code and followed the install guide.

`I Loading best validating checkpoint from ../../deepspeech-0.8.0-checkpoint\best_dev-1185136
I Loading variable from checkpoint: beta1_power
I Loading variable from checkpoint: beta2_power
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1
I Loading variable from checkpoint: global_step
I Loading variable from checkpoint: layer_1/bias
I Loading variable from checkpoint: layer_1/bias/Adam
I Loading variable from checkpoint: layer_1/bias/Adam_1
I Loading variable from checkpoint: layer_1/weights
I Loading variable from checkpoint: layer_1/weights/Adam
I Loading variable from checkpoint: layer_1/weights/Adam_1
I Loading variable from checkpoint: layer_2/bias
I Loading variable from checkpoint: layer_2/bias/Adam
I Loading variable from checkpoint: layer_2/bias/Adam_1
I Loading variable from checkpoint: layer_2/weights
I Loading variable from checkpoint: layer_2/weights/Adam
I Loading variable from checkpoint: layer_2/weights/Adam_1
I Loading variable from checkpoint: layer_3/bias
I Loading variable from checkpoint: layer_3/bias/Adam
I Loading variable from checkpoint: layer_3/bias/Adam_1
I Loading variable from checkpoint: layer_3/weights
I Loading variable from checkpoint: layer_3/weights/Adam
I Loading variable from checkpoint: layer_3/weights/Adam_1
I Loading variable from checkpoint: layer_5/bias
I Loading variable from checkpoint: layer_5/bias/Adam
I Loading variable from checkpoint: layer_5/bias/Adam_1
I Loading variable from checkpoint: layer_5/weights
I Loading variable from checkpoint: layer_5/weights/Adam
I Loading variable from checkpoint: layer_5/weights/Adam_1
I Loading variable from checkpoint: layer_6/bias
I Loading variable from checkpoint: layer_6/bias/Adam
I Loading variable from checkpoint: layer_6/bias/Adam_1
I Loading variable from checkpoint: layer_6/weights
I Loading variable from checkpoint: layer_6/weights/Adam
I Loading variable from checkpoint: layer_6/weights/Adam_1
I Loading variable from checkpoint: learning_rate
I STARTING Optimization
I Invalidating feature cache
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                            multiprocessing.pool.RemoteTraceback:
""""""
Traceback (most recent call last):
  File ""C:\Python36\lib\multiprocessing\pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""C:\Users\P70070113\Documents\Projects\DeepSpeech\deepspeech_training\util\augmentations.py"", line 158, in _augment_sample
    augmentation.apply(sample, clock)
  File ""C:\Users\P70070113\Documents\Projects\DeepSpeech\deepspeech_training\util\augmentations.py"", line 303, in apply
    sample.change_audio_type(new_audio_type=AUDIO_TYPE_OPUS, bitrate=bitrate)  # will get decoded again downstream
  File ""C:\Users\P70070113\Documents\Projects\DeepSpeech\deepspeech_training\util\audio.py"", line 111, in change_audio_type
    write_audio(new_audio_type, audio_bytes, self.audio, audio_format=self.audio_format, bitrate=bitrate)
  File ""C:\Users\P70070113\Documents\Projects\DeepSpeech\deepspeech_training\util\audio.py"", line 350, in write_audio    return write_opus(audio_file, pcm_data, audio_format=audio_format, bitrate=bitrate)
  File ""C:\Users\P70070113\Documents\Projects\DeepSpeech\deepspeech_training\util\audio.py"", line 279, in write_opus
    import opuslib  # pylint: disable=import-outside-toplevel
  File ""C:\Python36\lib\site-packages\opuslib\__init__.py"", line 19, in <module>
    from .classes import Encoder, Decoder  # NOQA
  File ""C:\Python36\lib\site-packages\opuslib\classes.py"", line 6, in <module>
    import opuslib.api.decoder
  File ""C:\Python36\lib\site-packages\opuslib\api\__init__.py"", line 22, in <module>
    'Could not find opus library. Make sure it is installed.')
Exception: Could not find opus library. Make sure it is installed.
""""""`",also document setup version working already since stack ca verify properly include case always support training right issue python rather opus ca found really complicated simply install simply source code install guide loading best loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable starting optimization feature cache epoch training time loss recent call last file line worker result true file line sample clock file line apply get downstream file line file line return file line import file line module import file line module import file line module find opus library make sure exception could find opus library make sure,issue,positive,positive,positive,positive,positive,positive
683684501,"> **CUDA/cuDNN version**: 10.1

Please triple check your setup, TensorFlow r1.15 is documented to require CUDA 10.0 ...",version please triple check setup require,issue,negative,neutral,neutral,neutral,neutral,neutral
683683205,"@coen22 You also don't explicitely document:
 - how you setup things,
 - what version you are working on

We already have a dep against `opuslib`: https://github.com/mozilla/DeepSpeech/blob/v0.9.0-alpha.6/setup.py#L60 but since we have no stack shared I can't verify if it has been properly installed ?



> I've noticed that the 'init.py' doesn't include a case for Windows and find_library always returns 'None'.

Because we don't support training on Windows.",also document setup version working already since stack ca verify properly include case always support training,issue,negative,neutral,neutral,neutral,neutral,neutral
683681708,"> Exception: Could not find Opus library. Make sure it is installed

Having a full stack could at least help have an hint where the issue is ...",exception could find opus library make sure full stack could least help hint issue,issue,negative,positive,positive,positive,positive,positive
683681354,"We don't support training on Windows, so I can't help for sure.",support training ca help sure,issue,positive,positive,positive,positive,positive,positive
683664503,"As I feared, lots of things are breaking on TensorFlow side when trying to build a debug version on CI and on setups where it is more complicated to investigate (Windows CPU and CUDA debug builds) ...",feared lot breaking side trying build version complicated investigate,issue,negative,negative,negative,negative,negative,negative
683474501,I confirm that the flag addressed my issues and that managed me to train and have a fully functioning model.,confirm flag train fully model,issue,negative,neutral,neutral,neutral,neutral,neutral
683401634,"> But that only commenting out feedAudioContent solves the memory leak makes me worry that the problem is further down.

Ftr we have tracked down other memory leak recently and this code path never showed, so it'd be great if we can confirm it is on Java, swig or c side. ",memory leak worry problem tracked memory leak recently code path never great confirm swig side,issue,negative,negative,negative,negative,negative,negative
683397864,"@zaptrem Hey sorry for being absent maybe I can look at it in the next time. But if its deep down in DeepSpeech I will not be able to help either, but I could at least reproduce it and make me my own picture.

But I guess a memory leak could easily be in the android example code because maybe some buffers are not cleaned up properly. But that only commenting out feedAudioContent solves the memory leak makes me worry that the problem is further down. ",hey sorry absent maybe look next time deep able help either could least reproduce make picture guess memory leak could easily android example code maybe properly memory leak worry problem,issue,negative,positive,neutral,neutral,positive,positive
683395167,"> Not much more digging I can do on this front for now as there’s a big launch on Tuesday coming up

Thanks for your understanding. Please note if you can find to repro in plain C on linux/amd64 it can be much quickly investigated.

I also hope we can add debug build to our CI now that we have had some work on it, that would help on such case. ",much digging front big launch coming thanks understanding please note find plain much quickly also hope add build work would help case,issue,positive,positive,positive,positive,positive,positive
683393700,"> Also, please understand we have had a very stressful month and it's the week-end, i might want to just rest for a few hours more ?

I totally understand. It’s 5am where I am and I’m just trying to get a few tasks (this was the last) checked off before I can sleep. It’s an issue forum and not text messages, so I don’t expect instant responses. I just want to make the information I have available to all of you as it comes to me.

Not much more digging I can do on this front for now as there’s a big launch on Tuesday coming up.",also please understand stressful month might want rest totally understand trying get last checked sleep issue forum text expect instant want make information available come much digging front big launch coming,issue,negative,positive,positive,positive,positive,positive
683393081,"> @erksch (and lissyx) I can confirm that the exact same issue is present on the android-streaming-demo in STT-examples. This is more evidence that the problem isn't just on my end, right?

Again, i have no idea, you are both using kotlin and i have not thoroughly verified your logic..
",confirm exact issue present evidence problem end right idea thoroughly logic,issue,negative,positive,positive,positive,positive,positive
683392935,"> If nobody can fix it now could it be marked as a bug so it doesn’t get forgotten about later?

It needs to be investigated to know if the bug is really on our side... ",nobody fix could marked bug get forgotten later need know bug really side,issue,negative,positive,positive,positive,positive,positive
683392843,"Also, please understand we have had a very stressful month and it's the week-end, i might want to just rest for a few hours more ? ",also please understand stressful month might want rest,issue,negative,neutral,neutral,neutral,neutral,neutral
683392777,"> > See a fully working example by cloning [this repo](https://github.com/zaptrem/react-native-transcription),  running yarn bootstrap, then yarn example android. Attach to it using the Android Studio profiler to watch the memory usage creep upwards.
> 
> The STT-examples implementation might be easier to follow, though.

Sorry but this is way too much.

The bug could be:
- in the c code it self 
- in the c generated by swig
- in the Java libdeepspeech part
- in the Java using it

Please try and repro to reduce the search space. ",see fully working example running yarn bootstrap yarn example android attach android studio profiler watch memory usage creep upwards implementation might easier follow though sorry way much bug could code self swig part please try reduce search space,issue,positive,negative,negative,negative,negative,negative
683392318,"> > have an example above that's extremely easy to reproduce (one command and two clicks in the emulator). Is writing a whole C interface (while closely studying the SWIG so that they match) with no prior experience absolutely necessary to move forward on fixing this bug?
> 
> Share and we'll see.

See OP:

> See a fully working example by cloning [this repo](https://github.com/zaptrem/react-native-transcription),  running yarn bootstrap, then yarn example android. Attach to it using the Android Studio profiler to watch the memory usage creep upwards.

The STT-examples implementation might be easier to follow, though.

https://github.com/mozilla/DeepSpeech-examples/tree/r0.8/android_mic_streaming


If nobody can fix it now could it be marked as a bug so it doesn’t get forgotten about later?",example extremely easy reproduce one command two emulator writing whole interface closely swig match prior experience absolutely necessary move forward fixing bug share see see see fully working example running yarn bootstrap yarn example android attach android studio profiler watch memory usage creep upwards implementation might easier follow though nobody fix could marked bug get forgotten later,issue,positive,positive,neutral,neutral,positive,positive
683392153,">  have an example above that's extremely easy to reproduce (one command and two clicks in the emulator). Is writing a whole C interface (while closely studying the SWIG so that they match) with no prior experience absolutely necessary to move forward on fixing this bug?

Share and we'll see. ",example extremely easy reproduce one command two emulator writing whole interface closely swig match prior experience absolutely necessary move forward fixing bug share see,issue,positive,positive,positive,positive,positive,positive
683391985,You seem not to understand that i really have no time right now to track a memory leak from the top down. ,seem understand really time right track memory leak top,issue,negative,positive,positive,positive,positive,positive
683377845,"@lissyx Doesn't the SWIG count as part of DeepSpeech's repo/code? The RN module I was building is basically ready for its first release, but I don't want to move forward until we can resolve this issue. I have an example above that's extremely easy to reproduce (one command and two clicks in the emulator). Is writing a whole C interface (while closely studying the SWIG so that they match) with no prior experience absolutely necessary to move forward on fixing this bug?

Also of importance, commenting out model.feedAudioContent() in the AudioRecorder loop seems to solve the memory leak.

@erksch (and lissyx) I can confirm that the exact same issue is present on the android-streaming-demo in STT-examples. This is more evidence that the problem isn't just on my end, right? ",swig count part module building basically ready first release want move forward resolve issue example extremely easy reproduce one command two emulator writing whole interface closely swig match prior experience absolutely necessary move forward fixing bug also importance loop solve memory leak confirm exact issue present evidence problem end right,issue,positive,positive,positive,positive,positive,positive
683342726,"> > Not being judgmental but i think we'll at least wait after 1.0 to merge that
> 
> We might change our opinion here, right @reuben ?

Yeah, I think it should be fine to land this once the comments here have been addressed. It's also a good opportunity to make the training functionality more fine grained instead of the huge train.py which can do a billion different things depending on the combination of flags that's passed. It's really hard to reason about what a training call is going to do unless you're deeply familiar with the code.",think least wait merge might change opinion right yeah think fine land also good opportunity make training functionality fine grained instead huge billion different depending combination really hard reason training call going unless deeply familiar code,issue,positive,positive,positive,positive,positive,positive
683290314,"@JRMeyer what do you think about reinitialization of tensors named ""Adam"" by default if they are missing? With an additional message for users that they are reinitialized because they are not in the checkpoint.

I can't think of an elegant way to reinitialize the adam-tensors before checkpoint saving at the moment. Because we would need to reinitialize them every time before we save a checkpoint (some might want to load intermediate checkpoints for some reasons).",think default missing additional message ca think elegant way saving moment would need every time save might want load intermediate,issue,positive,positive,positive,positive,positive,positive
683128062,"Hi @verloka, thanks for the interest. As this not on my immediate work path I can't work on this right now, but would be nice to start making it easier to support other frameworks such as .NET Core with a common API, I can review if anyone wants to jump into it.",hi thanks interest immediate work path ca work right would nice start making easier support core common review anyone jump,issue,positive,positive,positive,positive,positive,positive
682839119,"> Not being judgmental but i think we'll at least wait after 1.0 to merge that

We might change our opinion here, right @reuben ?",think least wait merge might change opinion right,issue,negative,negative,neutral,neutral,negative,negative
682838599,"@DanBmh Please dont let that sink, if you have some time to rebase :)",please dont let sink time rebase,issue,negative,neutral,neutral,neutral,neutral,neutral
682489205,"@piraka9011 Have you reported? I know in the current context it might be trouble some but ...
Also, have you verified your release? I'm pretty sure this is something we got report of and it was fixed.
Should we keep this open?",know current context might trouble also release pretty sure something got report fixed keep open,issue,negative,positive,positive,positive,positive,positive
682488725,"@carlfm01 is the one expert on .Net, I have no ide what "".Net Standard Library"" is, so I'll let him answer :)",one expert ide standard library let answer,issue,negative,neutral,neutral,neutral,neutral,neutral
682367429,@aszi09 Please use Discourse for support request and read the documentation.,please use discourse support request read documentation,issue,positive,neutral,neutral,neutral,neutral,neutral
682298291,"@reuben @erksch Alright, as of the latest commit we have the first working cross-platform RN module for DeepSpeech. I haven't built iOS live microphone transcription yet as I have another pressing matter to attend to for now, but .wav file transcription is cross platform and live transcription works on Android. I made a few changes to the framework (setting a bunch of important fields that should have been public-gettable but weren't) that would be great if they were added to 1.0. Finally, that memory leak is still present on Android during long live transcriptions. If you have any ideas on fixing that please let me know.

Let me know what you think!

I built it to be as simple as possible, which means there are no model options available to users for now. I want to make sure the most people get the best experience right off the bat and that transcriptions are consistent across platforms. Do you have any suggestions for tuning settings (e.g., alpha, beta, scorer) to reach that goal? I see you ran the optimizer on LibriSpeech clean. Do you have the results from running it on CommonVoice?",alright latest commit first working module built live microphone transcription yet another pressing matter attend file transcription cross platform live transcription work android made framework setting bunch important would great added finally memory leak still present android long live fixing please let know let know think built simple possible model available want make sure people get best experience right bat consistent across tuning alpha beta scorer reach goal see ran clean running,issue,positive,positive,positive,positive,positive,positive
682160440,@aszi09 it's hard to tell if there's a real issue underlying since you purposedly removed all the template we have to share details on your setup.,hard tell real issue underlying since purposedly removed template share setup,issue,negative,negative,neutral,neutral,negative,negative
681872097,"I don't know that code very well, I'm unsure to miss oddities.",know code well unsure miss,issue,negative,neutral,neutral,neutral,neutral,neutral
681824951,"@carlfm01 I think it'd be better to have the usage documentation centralized on readthedocs, as we've been moving everything to it. We used to have some stuff embedded on README's but it made it easier for changes to slip through and things to get out of sync.",think better usage documentation moving everything used stuff made easier slip get sync,issue,positive,positive,positive,positive,positive,positive
681689866,"@godefv thanks for the PR! I'll review it today.

@utunga you might be interested in trying these changes out and seeing how they affect your timings.",thanks review today might interested trying seeing affect,issue,positive,positive,positive,positive,positive,positive
681185211,"Turns out I _was_ close! The repo now has a working wav file transcription example. However, it appears the CoreML delegate isn't being used, as CPU usage was at 400% during the Wav transcription. I can't be certain as afaik there's no way to profile Neural Engine usage. GPU usage was at 0%. 

Also can't get my transcript metadata (bug or error on my part? @reuben ) 
![Screen Shot 2020-08-26 at 9 21 01 PM](https://user-images.githubusercontent.com/1612230/91372636-22c23700-e7e2-11ea-9713-807dcf84e3e3.png)
",turn close working file transcription example however delegate used usage transcription ca certain way profile neural engine usage usage also ca get transcript bug error part screen shot,issue,negative,positive,positive,positive,positive,positive
681165094,"@reuben Is the iOS 13.5 minimum deployment target intentional? 
![Screen Shot 2020-08-26 at 6 52 34 PM](https://user-images.githubusercontent.com/1612230/91364861-ac1b3e80-e7cd-11ea-87a3-7bb360b35649.png)


I found a Cocoapods plugin that allows use_frameworks! for a single pod, so it doesn't break others. I've been fighting this framework all day to start working and I'm not sure how close I'm getting.",minimum deployment target intentional screen shot found single pod break fighting framework day start working sure close getting,issue,negative,positive,positive,positive,positive,positive
681125405,"I couldn't figure out how to build a universal framework because they have to be built against different SDKs, not just architectures. I'll take a look at ""Build for Distribution"".",could figure build universal framework built different take look build distribution,issue,negative,neutral,neutral,neutral,neutral,neutral
681124622,"@reuben The deepspeech_ios.framework files your build system is distributing don't have Build for Distribution enabled. As a result, they're only compatible with the exact Swift compiler you used to build them. See [here](https://stackoverflow.com/questions/58654714/module-compiled-with-swift-5-1-cannot-be-imported-by-the-swift-5-1-2-compiler). It's a 30 second fix, but I have no clue how your massive build system works so I'm unqualified to open a PR. Also, it would be helpful for testing if your frameworks and libdeepspeech.so files were compiled as universal binaries, so I didn't have to switch them out every time I wanted to run on simulator instead of a real device. ",build system build distribution result compatible exact swift compiler used build see second fix clue massive build system work unqualified open also would helpful testing universal switch every time run simulator instead real device,issue,positive,positive,neutral,neutral,positive,positive
680839647,Also it looks like both bazel and tensorflow require changes before we can have a fully static build: https://github.com/tensorflow/tensorflow/issues/28388 https://github.com/bazelbuild/bazel/issues/1920,also like require fully static build,issue,negative,positive,positive,positive,positive,positive
680838163,I don't know anything about Cocoapods so I'm afraid I won't be helpful for the near term. Contributions always welcome.,know anything afraid wo helpful near term always welcome,issue,positive,positive,positive,positive,positive,positive
680732519,"> @lissyx @erksch the Android Studio debugger reports that the memory leak is in the ""Native Code"" section. Doesn't this indicate that it's a library issue? I'm running multi-hour recognition jobs, so maybe the issue doesn't show up in your shorter test cases?

Again, I know nothing about that tooling. If it's the case, then can you write C code reproducing ? How can we distinguish ""native"" from our library from swig wrapper?",android studio memory leak native code section indicate library issue running recognition maybe issue show shorter test know nothing tooling case write code distinguish native library swig wrapper,issue,negative,neutral,neutral,neutral,neutral,neutral
680566616,"@reuben Finished the Android portion of the module [here](https://github.com/zaptrem/react-native-transcription).  I totally understand if you haven't thought about this considering all of the craziness going on at Mozilla right now, but has there been any change on the Cocoapods front? It seems that to bundle the framework with the pod (necessary for RN modules) users would need to enable use_frameworks! which breaks many other pods. If you're able to publish a statically linked version in a cocoapod I'd be able to use DeepSpeech on the iOS side of the library as well.",finished android portion module totally understand thought considering craziness going right change front bundle framework pod necessary would need enable many able publish statically linked version able use side library well,issue,negative,positive,positive,positive,positive,positive
680402267,"@lissyx @erksch the Android Studio debugger reports that the memory leak is in the ""Native Code"" section. Doesn't this indicate that it's a library issue? I'm running multi-hour recognition jobs, so maybe the issue doesn't show up in your shorter test cases?",android studio memory leak native code section indicate library issue running recognition maybe issue show shorter test,issue,negative,neutral,neutral,neutral,neutral,neutral
679963412,"> > You can see the progress on the Community-TC link
> 
> Nice :D

macOS CI was a bit of a burden (it always is), but it's green in the end. I'm going to merge your TensorFlow part and then re-run PR with new sha1 and take care of the rest.",see progress link nice bit burden always green end going merge part new sha take care rest,issue,positive,positive,positive,positive,positive,positive
679328665,"> You can see the progress on the Community-TC link

Nice :D",see progress link nice,issue,positive,positive,positive,positive,positive,positive
679316842,"The doc is fixed now, but please use Discourse if you need further support.",doc fixed please use discourse need support,issue,positive,positive,neutral,neutral,positive,positive
679314553,"> https://mozilla-voice-stt.readthedocs.io/en/stable/BUILDING.html

This link is likely wrong, `stable` on that project is not really meaningful, this is likely a fallout from creating a new project for the new name



> since the prebuilt version of TensorFlow only utilizes a minor amount of cpu power when transcribing (due to the lack of support for AVX2, I suppose)

It is very unlikely, AVX2 to the best we could measure when the model was more complex would only account for up to 30% on the CPUs where there was the biggest difference, and around 10-15% on others.",link likely wrong stable project really meaningful likely new project new name since version minor amount power due lack support suppose unlikely best could measure model complex would account biggest difference around,issue,positive,positive,neutral,neutral,positive,positive
679312388,Though it looks like I forgot to update some part of the docs when moving to r2.3,though like forgot update part moving,issue,negative,neutral,neutral,neutral,neutral,neutral
679310945,"> I believe this is ok now. Sorry for the mess.

Thanks; one thing I forgot, can you please update `taskcluster/.build.yml` reference to tensorflow version with the value matching your `git describe --long --tags`?",believe sorry mess thanks one thing forgot please update reference version value matching git describe long,issue,positive,negative,negative,negative,negative,negative
679308465,"Support request are to be done on Discourse, and you dont give enough context on the version you are trying to build... ",support request done discourse dont give enough context version trying build,issue,negative,neutral,neutral,neutral,neutral,neutral
679292950,"@bernardohenz Can you please clean the history? No merge, no ""revert"" of the previous commit. Force-push is fine, no worries.",please clean history merge revert previous commit fine,issue,positive,positive,positive,positive,positive,positive
679285474,"> > @bernardohenz This is not complete, you have not updated `taskcluster/.shared.yml`
> 
> Yes, I was about to post asking for some help with this. What am I supposed to do? Just replace the old sha references ('4336a5b49fa6d650e24dbdba55bcef9581535244') to the new one ('6dc2a1becfd1316eb4d77240133a548e93dbff63')?
> Or should I compile anything and upload to you guys?

Just replace, that is the purpose of those references: our CI will check if the taskcluster index exists, and if not, it will build it.",complete yes post help supposed replace old sha new one compile anything replace purpose check index build,issue,positive,positive,positive,positive,positive,positive
679282189,"> @bernardohenz This is not complete, you have not updated `taskcluster/.shared.yml`

Yes, I was about to post asking for some help with this. What am I supposed to do? Just replace the old sha references ('4336a5b49fa6d650e24dbdba55bcef9581535244') to the new one ('6dc2a1becfd1316eb4d77240133a548e93dbff63')?
Or should I compile anything and upload to you guys?",complete yes post help supposed replace old sha new one compile anything,issue,positive,positive,positive,positive,positive,positive
679245174,"> If it makes the results more reliable, I wouldn't mind :)

The problem with not failing hard, is that people might not pay attention to the errors and continue with buggy dataset compared to their expectations.",reliable would mind problem failing hard people might pay attention continue buggy,issue,negative,negative,negative,negative,negative,negative
679223784,"> We have always preferred to try and keep the importers from doing work to fix datasets, and this is one case where the issue is in the dataset.

Makes sense.

> have you reported that upstream?

No, I will see if there are issues upstream and see if there's a bugfix release you mentioned.

> If you really want to wrap a try/except then it needs to be done on all the importers.

If it makes the results more reliable, I wouldn't mind :)
",always preferred try keep work fix one case issue sense upstream see upstream see release really want wrap need done reliable would mind,issue,negative,positive,positive,positive,positive,positive
679185565,"> All is working in the binaries, already create a PR for mozilla tensorflow: [mozilla/tensorflow#124](https://github.com/mozilla/tensorflow/pull/124)

Thanks @bernardohenz !

Can you send a PR against `mozilla/STT` that:
 - changes `.gitmodules` to fetch your tensorflow repo
 - changes `tensorflow` sha1 checkout to your changes
 - changes `taskcluster/.shared.yml` tensorflow SHA1 references to your new sha1

This is required for us to be able to run your PR with all your changes and ensure nothing regresses",working already create thanks send fetch sha sha new sha u able run ensure nothing,issue,positive,positive,positive,positive,positive,positive
679107373,"> If i look at: https://github.com/tensorflow/tensorflow/commits/r1.15 I do see some (non direct bug fix) commits after 1.15.3 without an immediate release. And even some very recent commits.

Then maybe they are considering a 1.15.4 ?



> Depends a bit on what you provide. For the 2.x branches I do agree, but since there is were little (relevant) movement on the 1.15
> branch that doesn't require very much (or even any) rebuilding since nothing changes. And the question is if you should build for every target. If it's the most common, x86 and only the python version from the ubuntu cuda dev image, it is all fairly limited put provides for the common training case.

You are highly underestimating:
 - the amount of work it requires to ship a tensorflow release, especially it requires quite a lot of CI-related changes
 - the amount of work we can take realistically in the current context

Just building r1.15 for the purpose of those debugging steps took several local hacks. Re-using TensorFlow's CI Docker stuff also required a non trivial amount of work.",look see non direct bug fix without immediate release even recent maybe considering bit provide agree since little relevant movement branch require much even since nothing question build every target common python version dev image fairly limited put common training case highly amount work ship release especially quite lot amount work take realistically current context building purpose took several local docker stuff also non trivial amount work,issue,negative,positive,neutral,neutral,positive,positive
679103526,"> > * First get the patch applied to the r1.15 tensorflow upstream branch, since it was filled as a bug against that, that seems reasonable and as a bonus it applies clean.
> > * Then try to get a release for that branch.
> 
> (1) and (2) goes together, it won't get picked on r1.15 if they don't intend to ship 1.15.4

If i look at: https://github.com/tensorflow/tensorflow/commits/r1.15 I do see some (non direct bug fix) commits after 1.15.3 without an immediate release. And even some very recent commits.

> > If we don't get a release, we could try to get it applied to mozilla-tensorflow.
> 
> What for? Supporting tensorflow wheel builds is a huge tasks, we stopped doing that as soon as we can
> 
> > And perhaps even provide an prebuild docker base image for training based on the Dockerfile.build.tmpl file and publish that on docker hub ?
> 
> Same, that requires us to build and support TensorFlow wheel, which is a lot of work.

Depends a bit on what you provide. For the 2.x branches I do agree, but since there is were little (relevant) movement on the 1.15
branch that doesn't require very much (or even any) rebuilding since nothing changes. And the question is if you should build for every target. If it's the most common, x86 and only the python version from the ubuntu cuda dev image, it is all fairly limited put provides for the common training case.
",first get patch applied upstream branch since filled bug reasonable bonus clean try get release branch go together wo get picked intend ship look see non direct bug fix without immediate release even recent get release could try get applied supporting wheel huge stopped soon perhaps even provide docker base image training based file publish docker hub u build support wheel lot work bit provide agree since little relevant movement branch require much even since nothing question build every target common python version dev image fairly limited put common training case,issue,positive,positive,neutral,neutral,positive,positive
679099070,"> * First get the patch applied to the r1.15 tensorflow upstream branch, since it was filled as a bug against that, that seems reasonable and as a bonus it applies clean.
> 
> * Then try to get a release for that branch.

(1) and (2) goes together, it won't get picked on r1.15 if they don't intend to ship 1.15.4



> If we don't get a release, we could try to get it applied to mozilla-tensorflow.

What for? Supporting tensorflow wheel builds is a huge tasks, we stopped doing that as soon as we can



> And perhaps even provide an prebuild docker base image for training based on the Dockerfile.build.tmpl file and publish that on docker hub ?

Same, that requires us to build and support TensorFlow wheel, which is a lot of work.",first get patch applied upstream branch since filled bug reasonable bonus clean try get release branch go together wo get picked intend ship get release could try get applied supporting wheel huge stopped soon perhaps even provide docker base image training based file publish docker hub u build support wheel lot work,issue,positive,positive,positive,positive,positive,positive
679096655,"Perhaps we should try to stage it as a multi-stage rocket:

1. First get the patch applied to the r1.15 tensorflow upstream branch, since it was filled as a bug against that, that seems reasonable and as a bonus it applies clean.
2. Then try to get a release for that branch.
3. If we don't get a release, we could try to get it applied to mozilla-tensorflow. 
4. And perhaps even provide an prebuild docker base image for training based on the Dockerfile.build.tmpl file and publish that on docker hub ?",perhaps try stage rocket first get patch applied upstream branch since filled bug reasonable bonus clean try get release branch get release could try get applied perhaps even provide docker base image training based file publish docker hub,issue,positive,positive,neutral,neutral,positive,positive
679039878,"We have always preferred to try and keep the importers from doing work to fix datasets, and this is one case where the issue is in the dataset.

In that specific case, it seems the Common Voice English relese contains buggy data:
 - have you reported that upstream?
 - have you verified SHA from the release to ensure you have had no corruption at download
 - are you sure you re using the latest release? I think I already saw mention of that and a bugfix release being issued

@piraka9011 If you really want to wrap a try/except then it needs to be done on all the importers.",always preferred try keep work fix one case issue specific case common voice buggy data upstream sha release ensure corruption sure latest release think already saw mention release really want wrap need done,issue,positive,positive,positive,positive,positive,positive
679038535,"So, unless there are other usecases where ONNX is really required, I'll close that. Feel free to re-open if you have other usecases where it makes more sense.",unless really close feel free sense,issue,positive,positive,positive,positive,positive,positive
678994547,"That looks legit, but it's not going to catch all incorrect cases: you could have the same alphabet but in another order and it would pass this check. We discussed that a long time ago in the past, maybe we should have some kind of checksum.

What's your take @reuben?",legit going catch incorrect could alphabet another order would pas check long time ago past maybe kind take,issue,positive,positive,neutral,neutral,positive,positive
678989197,@lissyx Are there other contributors with experience in this area who might be good to cc? ,experience area might good,issue,negative,positive,positive,positive,positive,positive
678983407,"> > > However, running streaming transcription uses more and more memory until the app crashes.
> > 
> > 
> > I know nothing about Kotlin and its memory model, can you ensure this is 100% NOT related to your usage of the library?
> > @lissyx
> 
> I, too, know nothing about Kotlin and its memory model apart from what I learned building this module, which I started only a few days ago. However, my usage is nearly line-for-line identical to the STT-examples Android demo. The only exception is my packaging of the Metadata object and Native Event dispatching. However, the leak remains even when those are commented out.

My point being: I have no idea whether the STT-examples code is leak-free, and in the current state of events, I can't focus time on investigate that on JNI/Java side.",however running streaming transcription memory know nothing memory model ensure related usage library know nothing memory model apart learned building module day ago however usage nearly identical android exception object native event however leak remains even point idea whether code current state ca focus time investigate side,issue,negative,positive,neutral,neutral,positive,positive
678980603,"> > However, running streaming transcription uses more and more memory until the app crashes.
> 
> 
> 
> I know nothing about Kotlin and its memory model, can you ensure this is 100% NOT related to your usage of the library?
@lissyx 

I, too, know nothing about Kotlin and its memory model apart from what I learned building this module, which I started only a few days ago. However, my usage is nearly line-for-line identical to the STT-examples Android demo. The only exception is my packaging of the Metadata object and Native Event dispatching. However, the leak remains even when those are commented out.",however running streaming transcription memory know nothing memory model ensure related usage library know nothing memory model apart learned building module day ago however usage nearly identical android exception object native event however leak remains even,issue,negative,positive,neutral,neutral,positive,positive
678978204,"> my hobbyist usecase is accelerated inference on jetson nano.
> the steps are described in [speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt](https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/)
> 
> simply an onnx export, would allow easier implementation on different platforms with high performance.
> 
> but as stated by you above, if this isn't intended, and extra work on your end,
> feel free to close this issue.

You should already be able to:
 - leverage TFLite model
 - rebuild `libmozilla_voice_stt.so` with CUDA support on that platform to leverage the GPU.",hobbyist accelerated inference simply export would allow easier implementation different high performance stated intended extra work end feel free close issue already able leverage model rebuild support platform leverage,issue,positive,positive,positive,positive,positive,positive
678977808,"> However, running streaming transcription uses more and more memory until the app crashes.

I know nothing about Kotlin and its memory model, can you ensure this is 100% NOT related to your usage of the library?",however running streaming transcription memory know nothing memory model ensure related usage library,issue,negative,neutral,neutral,neutral,neutral,neutral
678970157,"my hobbyist usecase is accelerated inference on jetson nano.
the steps are described in [speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt](https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/)

simply an onnx export, would allow easier implementation on different platforms with high performance.

but as stated by you above, if this isn't intended, and extra work on your end,
feel free to close this issue.",hobbyist accelerated inference simply export would allow easier implementation different high performance stated intended extra work end feel free close issue,issue,positive,positive,positive,positive,positive,positive
678862115,@erksch I decided to post the repo a little earlier than expected [here](https://github.com/zaptrem/react-native-transcription). Right now it only has Android live transcription support. I pushed it because I ran into a memory leak that seems to be linked to the Java native client implementation. I made an issue [here](https://github.com/mozilla/STT/issues/3271). ,decided post little right android live transcription support ran memory leak linked native client implementation made issue,issue,negative,positive,neutral,neutral,positive,positive
678824385,"> @zaptrem I have not tried out closing the app when running the model. Is that a requirement for you?
> 
> > Instead, the library would stick with SFSpeechRecognizer for live recognitionInstead, the library would stick with SFSpeechRecognizer for live recognition
> 
> Actually, I would really like to see a library that is completely powered by DeepSpeech. Many people turn to DeepSpeech because of privacy concerns and offline inference. If this is not important to me I'd use `react-native-voice`.
@erksch 


I'm using it for long-running simultaneous recording+transcription jobs that would be price (and in some cases privacy) prohibitive in the cloud. Users likely can't/won't keep their phones unlocked for two hour recording sessions, so it is a requirement. SFSpeechRecognizer has an offline-only mode, but its far-field accuracy sucks and it is extremely unreliable (i.e., the recognizer straight up fails in the middle of jobs constantly). Once you guys start mixing in reverb, noise, and different loudness levels for 1.0, DeepSpeech will hopefully perform better (especially because from my limited testing in Android you're stable for long jobs and your token timestamps actually seem to be accurate, unlike Apple's). 

The React Native library, `react-native-transcription` will be open source (I don't want to publish it until the Android half is a little more fleshed-out). However, I'm using it to power [a new class collaboration app, ReLearn](https://relearn.fyi). The Android version (going live for testing in a few days) is powered 100% by DeepSpeech, while the iOS version will stick with SFSpeechRecognizer for live recording until DeepSpeech is noise/reverb-hardened and we can verify background stability.
",tried running model requirement instead library would stick live library would stick live recognition actually would really like see library completely powered many people turn privacy inference important use simultaneous would price privacy prohibitive cloud likely keep unlocked two hour recording session requirement mode accuracy extremely unreliable recognizer straight middle constantly start reverb noise different loudness hopefully perform better especially limited testing android stable long token actually seem accurate unlike apple react native library open source want publish android half little however power new class collaboration relearn android version going live testing day powered version stick live recording verify background stability,issue,positive,positive,neutral,neutral,positive,positive
678756583,"@zaptrem I have not tried out closing the app when running the model. Is that a requirement for you? 

> Instead, the library would stick with SFSpeechRecognizer for live recognitionInstead, the library would stick with SFSpeechRecognizer for live recognition

Actually, I would really like to see a library that is completely powered by DeepSpeech. Many people turn to DeepSpeech because of privacy concerns and offline inference. If this is not important to me I'd use `react-native-voice`.",tried running model requirement instead library would stick live library would stick live recognition actually would really like see library completely powered many people turn privacy inference important use,issue,positive,positive,positive,positive,positive,positive
678743115,"@erksch Does iOS kill apps with the streaming model running in the background? I’m making progress with the Android portion of the React Native module and am almost ready to start work on iOS. However, I don’t want to invest the limited resources into DeepSpeech streaming on iOS if it Apple’s aggressive power management makes background transcription with DeepSpeech impossible. Instead, the library would stick with SFSpeechRecognizer for live recognition and use DeepSpeech for longer file recognition instead.",kill streaming model running background making progress android portion react native module almost ready start work however want invest limited streaming apple aggressive power management background transcription impossible instead library would stick live recognition use longer file recognition instead,issue,negative,negative,negative,negative,negative,negative
678737690,"Thanks for the report, it looks like the upload for that file failed half way through and I didn't notice. Fixed it!",thanks report like file half way notice fixed,issue,positive,positive,neutral,neutral,positive,positive
678422545,"Please describe the usecase, our model is intented to be used with the library, so it would require onnx support there, that's a lot of extra work. ",please describe model used library would require support lot extra work,issue,positive,neutral,neutral,neutral,neutral,neutral
677697567,"> For instance, while the 2nd dense layer from the current checkpoint (without LN) was trained to process tensors in a certain range; the 2nd dense layer in an architecture with LN will process tensors with a completely different range (not only range, but mean and var as well).

@bernardohenz you're right. I just was hoping that transfer-learning performance wasn't that bad and did a short test run.",instance dense layer current without trained process certain range dense layer architecture process completely different range range mean well right performance bad short test run,issue,negative,negative,neutral,neutral,negative,negative
677646500,"@DanBmh  you cannot take the weights (checkpoint) from a model trained without layer-norm, and use them to finetune/transferlearning to a model that uses layernorm. The model's architecture are just different.

For instance, while the 2nd dense layer from the current checkpoint (without LN) was trained to process tensors in a certain range; the 2nd dense layer in an architecture with LN will process tensors with a completely different range (not only range, but mean and var as well).

Also, that's why I've put the argument ```layer_norm``` along with ```n_hidden``` in the [*geometry* section](https://github.com/mozilla/STT/blob/3409a3a9d0f699612a7643ae90c7e51673c52caf/training/mozilla_voice_stt_training/util/flags.py#L138). These arguments dictates the geometry/architecture of your model. If you wish to finetune/transfer-learning from a trained model, you should stick right with the architecture it was trained.
",take model trained without use model model architecture different instance dense layer current without trained process certain range dense layer architecture process completely different range range mean well also put argument along geometry section model wish trained model stick right architecture trained,issue,negative,positive,neutral,neutral,positive,positive
677635536,"For training with already existing checkpoints you have to initialize the new layers first. This did work for me:

```
# training/deepspeech_training/utils/checkpoins.py

def _load_checkpoint(session, checkpoint_path, allow_drop_layers):
    [...]

    if FLAGS.layer_norm:
        for v in load_vars:
            if v.op.name not in vars_in_ckpt:
                if 'LayerNorm' in v.name:
                    init_vars.add(v)
                else:
                    msg = ""Tried to train with layer normalization but there was "" \
                          ""a missing variable other than the LayerNorm tensors: {}""
                    log_error(msg.format(v))
                    sys.exit(1)
        load_vars -= init_vars
```

<br>

I also did run a short test transfer-learning the English checkpoint to German with a small dataset (~32h), but layer-norm didn't help here:


 | Dataset  | Additional Infos                                                           | Losses                                 | Training epochs of best model | Total training duration |
 | -------- | -------------------------------------------------------------------------- | -------------------------------------- | ----------------------------- | ----------------------- |
|  Voxforge | without layer-norm                   | Test: 30.655203, Validation: 33.655750 | 9                             | 48 min          |                    
| Voxforge | with layer normalization  | Test: 57.330410, Validation: 61.025009 | 45                             | 2:37 h                  |

Maybe training the reinitialized LayerNorm tensors only and freezing the rest of the network (see #3247) before training the complete network would help here 
",training already initialize new first work session else tried train layer normalization missing variable also run short test german small help additional training best model total training duration without test validation min layer normalization test validation maybe training freezing rest network see training complete network would help,issue,positive,positive,positive,positive,positive,positive
676532074,"@erksch I'm not getting any live microphone transcription updates as I record with the demo. Only after I tap ""Stop Microphone Recognition"" does a transcription print in the console.

I'm working on integrating the Android native client into a React Native module I'm building right now. After I finish that I'll start working with this again. ",getting live microphone transcription record tap stop microphone recognition transcription print console working android native client react native module building right finish start working,issue,negative,positive,positive,positive,positive,positive
676235671,"Turns out @reuben might have found a proper fix that is not invasive as we first tought, but it will require some full rebuild so it may take a few days. Hopefully we might do 0.8.2 to ship it.",turn might found proper fix invasive first tought require full rebuild may take day hopefully might ship,issue,negative,positive,positive,positive,positive,positive
676077114,"> Yes, it is ready for review. I just wanted to avoid multiple small commits with force pushes. I hope this is fine.

It's okay by me, I just don't want to review and merge before it is said to be ready by yourself :)",yes ready review avoid multiple small force hope fine want review merge said ready,issue,positive,positive,positive,positive,positive,positive
676051104,"Yes, it is ready for review. I just wanted to avoid multiple small commits with force pushes. I hope this is fine.",yes ready review avoid multiple small force hope fine,issue,positive,positive,neutral,neutral,positive,positive
675940259,"@zaptrem The microphone transcription was written by me. It works, but if you have a better idea feel free to make a new PR. Maybe I missed AVAudioEngine in my research on processing audio data in Swift. 

> Also, is there a way to receive live transcription results like the android_mic_streaming example?

What do you mean by that? The iOS test app supports live microphone transcription.

Important for the implementation is that the audio is reliably resampled to 16000Hz, this is what made my code rather complicated. If AVAudioEngine supports this out of the box in a cleaner way, it might be the way to go here. ",microphone transcription written work better idea feel free make new maybe research audio data swift also way receive live transcription like example mean test live microphone transcription important implementation audio reliably made code rather complicated box cleaner way might way go,issue,positive,positive,positive,positive,positive,positive
675728142,"@reuben I'm going over the test project you made for iOS. Why did you decide to use AVCaptureSession and all of its intricacies instead of AVAudioEngine? In addition to working in the background, it seem like fewer raw, unsafe pointers and mallocs would be needed to accomplish the same goal. I'm relatively inexperienced with Swift and couldn't really understand what most of the code did. I built something similar for a half-finished RN Module that uses Apple's SFSpeech AudioBuffer Recognizer a while ago: https://github.com/zaptrem/react-native-transcript/blob/master/ios/TranscriptLive.swift (you can ignore anything that mentions caching, Apple doesn't allow the Speech Recognizer to be started while in background so if it stops due to an error I cache the buffer until the user resumes the app). 

The summary is I create an AVAudioEngine instance, create a Recognizer, installTap on the engine's inputNode, and append the buffer to the Recognizer in the installTap's callback. 

Also, is there a way to receive live transcription results like the android_mic_streaming example?",going test project made decide use instead addition working background seem like raw unsafe would accomplish goal relatively inexperienced swift could really understand code built something similar module apple recognizer ago ignore anything apple allow speech recognizer background due error cache buffer user summary create instance create recognizer engine append buffer recognizer also way receive live transcription like example,issue,positive,negative,neutral,neutral,negative,negative
675678097,This is a lot of extra complexity for à usecase solved by the env variable above. ,lot extra complexity variable,issue,negative,neutral,neutral,neutral,neutral,neutral
675641748,"1. Currently I did use this for my German training (0 dropped, 1 frozen). I think this makes sense for all languages with same alphabet like English and and similar pronunciation. This could also be used for transfer-learning of dialects. Instead of random initialized weights you would get somewhat matching weights at the beginning of the training.

2. You're right about this one and I think reinitialization after training is a good idea. I hope I can find some time in the next days to test it.",currently use german training frozen think sense alphabet like similar pronunciation could also used instead random would get somewhat matching beginning training right one think training good idea hope find time next day test,issue,positive,positive,neutral,neutral,positive,positive
675598532,"> Do you mind sharing more on that?

The experiments we have done are a little old right now. I performing a new training benchmark right now, soon I'll let you know.",mind done little old right new training right soon let know,issue,negative,positive,positive,positive,positive,positive
675542672,"> Ok, so you just have a few files to add?

Yes, these new files that I need to check if it works on the r2.3. But I believe this will work just fine
",add yes new need check work believe work fine,issue,positive,positive,positive,positive,positive,positive
675540408,">  I'm sending the new rule here

https://github.com/mozilla/tensorflow/blob/r2.3/tensorflow/core/kernels/BUILD#L8655-L8673

Ok, so you just have a few files to add?

Please make sure you:
 - update tensorflow submodule
 - update `taskcluster/.shared.yml` tensorflow references",sending new rule add please make sure update update,issue,positive,positive,positive,positive,positive,positive
675539183,"> I'll be compiling the binaries in the `master` to check if it still works.

Master moved to r2.3

> PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in `tensorflow/core/kernels/BUILD`).

Pretty sure we already have those",master check still work master repository included build rule nonetheless sending new rule found pretty sure already,issue,positive,positive,positive,positive,positive,positive
675492672,"> it makes sense to either specify in the docus what should be the specific structure of the .csv files to avoid the confusion

Let's take this road, I'll close this PR.",sense either specify specific structure avoid confusion let take road close,issue,negative,neutral,neutral,neutral,neutral,neutral
675492349,"> I haven't found in the documentation any information what should be the base of the `wav_filesize`, so one may select arbitrary base, for example the kB. In this case the specification of the size as a float is reasonable.
> 
> So I think it makes sense to either specify in the docus what should be the specific structure of the .csv files to avoid the confusion or to merge this change.

If you take a look at all the importers, it's in bytes. It is so obvious we never even thought about requiring documenting that, but if you think it is important, we welcome a PR to fix that!",found documentation information base one may select arbitrary base example case specification size float reasonable think sense either specify specific structure avoid confusion merge change take look obvious never even thought think important welcome fix,issue,negative,negative,neutral,neutral,negative,negative
675475961,"I haven't found in the documentation any information what should be the base of the `wav_filesize`, so one may select arbitrary base, for example the kB. In this case the specification of the size as a float is reasonable.

So I think it makes sense to either specify in the docus what should be the specific structure of the .csv files to avoid the confusion or to merge this change.",found documentation information base one may select arbitrary base example case specification size float reasonable think sense either specify specific structure avoid confusion merge change,issue,negative,negative,negative,negative,negative,negative
675466434,"> Allows the backward compatibility with the csv files.

Do you mind elaborating on that? There's no good reason a size would be a float.",backward compatibility mind good reason size would float,issue,negative,positive,positive,positive,positive,positive
675465700,"Also, changing Bazel version is kind of invasive, I'm not sure we want to do that on 0.8 ...",also version kind invasive sure want,issue,positive,positive,positive,positive,positive,positive
675463817,"> dyld: lazy symbol binding failed: Symbol not found: ____chkstk_darwin
> Referenced from: /Users/apple/Desktop/Citi/FRM/deepspeech/libdeepspeech.so (which was built for Mac OS X 10.15)

Thanks, so I fear this is a regression from using XCode for iOS support :/ cc @reuben 

There's an upstream Bazel bug matching that, where Bazel does not respect minimum sdk we force, but it was only fixed in 3.4 and TensorFlow r2.2 used for r0.8 uses Bazel 2.0.0, and I don't see any workaround so far.

We just upgraded master to r2.3, but:
 - it is using Bazel 3.1, not 3.4
 - if it fixes, it requires complete rebuild of TensorFlow and our macOS CI is not really in good shape.

I'm unsure if we can fix that soonish.",lazy symbol binding symbol found built mac o thanks fear regression support upstream bug matching respect minimum force fixed used see far master complete rebuild really good shape unsure fix soonish,issue,positive,positive,positive,positive,positive,positive
675444709,"Still does not work.

```
**(deepspeechenv) 192:deepspeech apple$** ./deepspeech --model deepspeech-0.7.0-models.pbmm --scorer deepspeech-0.7.0-models.scorer --audio audio/2830-3980-0043.wav

TensorFlow: v2.2.0-24-g1c1b2b9dd9
DeepSpeech: v0.8.1-0-gfa883eb8
2020-08-18 17:48:29.840025: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
dyld: lazy symbol binding failed: Symbol not found: ____chkstk_darwin
  Referenced from: /Users/apple/Desktop/Citi/FRM/deepspeech/libdeepspeech.so (which was built for Mac OS X 10.15)
  Expected in: /usr/lib/libSystem.B.dylib

dyld: Symbol not found: ____chkstk_darwin
  Referenced from: /Users/apple/Desktop/Citi/FRM/deepspeech/libdeepspeech.so (which was built for Mac OS X 10.15)
  Expected in: /usr/lib/libSystem.B.dylib

Abort trap: 6
```",still work apple model scorer audio binary use lazy symbol binding symbol found built mac o symbol found built mac o abort trap,issue,negative,negative,negative,negative,negative,negative
675392902,"> Can you estimate when the new `ds-ctcdecoder` will be built?

It's just a matter of issuing a new alpha, I wanted to merge tensorflow r2.3 before, which we just did, so I guess in the afternoon we might have it",estimate new built matter issuing new alpha merge guess afternoon might,issue,negative,positive,positive,positive,positive,positive
674810443,"> > Extract and run `./deepspeech --version` to see if you have the same problem?
> 
> Output: DeepSpeech 0.8.1

Can you try to run a model then?
```
./deepspeech --model deepspeech-0.7.0-models.pbmm --scorer deepspeech-0.7.0-models.scorer --audio audio/2830-3980-0043.wav
```",extract run version see problem output try run model model scorer audio,issue,negative,neutral,neutral,neutral,neutral,neutral
674810147,"> Extract and run `./deepspeech --version` to see if you have the same problem?

Output: DeepSpeech 0.8.1",extract run version see problem output,issue,negative,neutral,neutral,neutral,neutral,neutral
674806266,"> This installed this - native_client.amd64.cpu.osx.tar.xz. What to do next?

Extract and run `./deepspeech --version` to see if you have the same problem?",next extract run version see problem,issue,negative,neutral,neutral,neutral,neutral,neutral
674801415,"> @lissyx iOS build only in 0.9 alpha.

It's always nice when you trust people that are working on the project.",build alpha always nice trust people working project,issue,positive,positive,positive,positive,positive,positive
674800901,"@Arpitrf Please, can you check with `native_client.tar.xz`, to check if it is `libdeepspeech.so` build or just the Python wrapper.",please check check build python wrapper,issue,negative,neutral,neutral,neutral,neutral,neutral
674799869,"Ok I found a work-around.

pip uninstall deepspeech
pip install deepspeech==0.7.0

Version 0.7.0 works. 

Is deepseech version 0.8.1 incompatible with macOS?",found pip pip install version work version incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
674793801,"deepspeech version: 0.8.1
Python version: Python 3.6.5
pip version: pip 20.2.2 ",version python version python pip version pip,issue,negative,neutral,neutral,neutral,neutral,neutral
674771546,"Please document what version that is, because we force targetting à lower version... ",please document version force lower version,issue,negative,neutral,neutral,neutral,neutral,neutral
674714433,"@reuben hey. Where can I find libdeepspeech.so for iOS, or how can I build it by myself? I looked at links you have provided long time ago but it sends me 404. Thanks in advance.",hey find build link provided long time ago thanks advance,issue,negative,positive,neutral,neutral,positive,positive
674605077,"@reuben  
Any change on this? I'm starting the Android half of this library tonight.",change starting android half library tonight,issue,negative,negative,neutral,neutral,negative,negative
674057380,"> I don't see why you need a new flag for `load_frozen_graph

Problem is that when loading the checkpoint for the second training the frozen layers have no variables for `Adam`. They were not loaded/saved in the first training because they were not used. So we have to reinitialize them.

",see need new flag problem loading second training frozen first training used,issue,negative,positive,positive,positive,positive,positive
674052433,"@DanBmh -- I don't see why you need a new flag for `load_frozen_graph`. For reference, this is how I implemented transfer-learning + freezing layers before: https://github.com/mozilla/STT/blob/transfer-learning2/DeepSpeech.py#L264-L278",see need new flag reference freezing,issue,negative,positive,positive,positive,positive,positive
674048610,"@DanBmh -- even though my previous research with deepspeech seems to point to frozen-transfer not working, I *still* think this feature should be integrated. Your two-step approach makes perfect intuitive sense, and there's work from computer vision and NLP that shows frozen transfer works very well. 

So, I think the feature would be useful, but @lissyx is right, this is a post-1.0 feature.",even though previous research point working still think feature approach perfect intuitive sense work computer vision frozen transfer work well think feature would useful right feature,issue,positive,positive,positive,positive,positive,positive
674012975,Not being judgmental but i think we'll at least wait after 1.0 to merge that ,think least wait merge,issue,negative,negative,negative,negative,negative,negative
674008784,"I did run another test, this time I tried your approach with dropping and reinitializing the last layer. 
(As noted above, I normally don't drop the layer when training German, I just train over the English weights)

| Language | Dataset                                                                                      | Additional Infos                                                                                                                                                    | Losses                                 | Training epochs of best model / Total duration | 
| -------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------- | ----------------------------- |
| DE       | Voxforge  |  dropped last layer | Test: 42.516270, Validation: 47.105518 |   8; Time: 28min                       | 
| DE       | Voxforge  |  with frozen transfer-learning in two steps | Test: 36.600590, Validation: 40.640134 |   14+8; Time: 42min                       | 

Here you can see an improvement if using the frozen transfer-learning approach.
(Note one the dataset: Voxforge has 31h, I'm using about 5h each for dev+test, rest for training. So it's quite small)

<br>

So I would say if the network architecture did not change it's faster to train with the English weights (no dropping, no freezing), but if the network had to be changed (different alphabet) it's better to train in two steps with the frozen network.

Of course we would need to do some more test before we can say this for sure.",run another test time tried approach dropping last layer noted normally drop layer training german train language additional training best model total duration de last layer test validation time min de frozen two test validation time min see improvement frozen approach note one rest training quite small would say network architecture change faster train dropping freezing network different alphabet better train two frozen network course would need test say sure,issue,positive,positive,positive,positive,positive,positive
673956681,"Not ready yet! 
Found an error when using `--drop_source_layers` flag",ready yet found error flag,issue,negative,positive,positive,positive,positive,positive
673542313,">  So, you freeze all layers apart from the last one, and then train the last layer. Then when that has trained, you train all the layers?

Exactly

<br>

First test was not as good as planned:
(using my other pr #3245; es_epochs=7; reduce_lr_plateau_epochs=3;  es_min_delta=0.9;  no augmentation)

| Language | Dataset                                                                                      | Additional Infos                                                                                                                                                    | Losses                                 | Training epochs of best model / Total duration  | 
| -------- | -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------- | ----------------------------- |
| DE       | Voxforge  |  frozen transfer-learning, then training all layers | Test: 37.707958, Validation: 41.832220 |   12+3; Time: 42min                       | 
| DE       | Voxforge  | without frozen transfer-learning | Test: 36.630890, Validation: 41.208125 |   7; Time: 28min                       |

Not sure why, maybe some training randomness. Because I don't think this should lead to worse results.",freeze apart last one train last layer trained train exactly first test good augmentation language additional training best model total duration de frozen training test validation time min de without frozen test validation time min sure maybe training randomness think lead worse,issue,positive,positive,positive,positive,positive,positive
673540833,"@DanBmh So, you freeze all layers apart from the last one, and then train the last layer. Then when that has trained, you train all the layers?

I'd be interested in seeing the results when you have them!",freeze apart last one train last layer trained train interested seeing,issue,negative,positive,neutral,neutral,positive,positive
673514231,"@ftyers I'm working on it right now:)

But the approach I'm suggesting is a bit different to yours. It's using both steps.

My transfer-learing workflow would look like this:
1. training with frozen layers
2. training with all layers (you have to start a new training for this)

Just a side note to the topic:  I'm not reinitializing the last layer if possible, because in my experiments with German I got better results than with random initialization of the last layer",working right approach suggesting bit different would look like training frozen training start new training side note topic last layer possible german got better random last layer,issue,positive,positive,neutral,neutral,positive,positive
673500554,"@DanBmh do you have any indication that this works better than tuning the whole network? In our experiments (see earlier versions of the [Common Voice paper](https://arxiv.org/abs/1912.06670) and [Josh' thesis](http://jrmeyer.github.io/misc/MEYER_dissertation_2019.pdf) -- Chapter 8) we found that tuning all layers works quite a bit better than freezing any of them, see e.g. this figure:
![Captura de 2020-08-13 15-12-46](https://user-images.githubusercontent.com/449545/90145030-6eeb9100-dd77-11ea-8a3b-76ddcdfcb94f.png)
",indication work better tuning whole network see common voice paper josh thesis chapter found tuning work quite bit better freezing see figure de,issue,positive,positive,positive,positive,positive,positive
673336171,"Currently training looks like this:
```
epoch 5: val_loss=62
e6: vl=59
e7: vl=60
e8: vl=61
Reached a plateau, LearningRate:=LR*0.1
e9: vl=60       <- Here we're using the weights from e8, with the suggested changes we're using e6 instead
e10: vl=58   <- We have an improvement but the network has to do some more work to fix the errors from e7+e8
```

The old approach did still work well but I think we can make it even better by reloading the weights from the best_dev checkpoint.",currently training like epoch plateau instead improvement network work fix old approach still work well think make even better,issue,positive,positive,positive,positive,positive,positive
673169511,"@DanBmh Thanks, can you elaborate a little bit? My mind is kind of somewhere else, so I'm unsure I get the point here.",thanks elaborate little bit mind kind somewhere else unsure get point,issue,positive,positive,positive,positive,positive,positive
673165274,"> I'm using Anaconda Prompt to get Linux familiarity in Windows OS.

Well, I'm sorry but it's 1000% non supported setup. Please stick to at least pure Python virtualenv as we document.


>     3\. pip install deepspeech (Latest version i.e. v0.8.1 is being installed.)

Still no log of the install, so we can't verify what is happening.


>     5\. Script to load model:

Please verify with the `deepspeech` binary installed by the package, and verify it loads the correct package



>     5\. from deepspeech import Model

Same:
 - verify it loads the proper `deepspeech` python module
 - verify it loads the proper `libdeepspeech.so`

I've already asked you all those before, I'm really starting to loose patience into helping you now.",anaconda prompt get familiarity o well sorry non setup please stick least pure python document pip install latest version still log install ca verify happening script load model please verify binary package verify correct package import model verify proper python module verify proper already really starting loose patience helping,issue,positive,negative,neutral,neutral,negative,negative
673164461,"> In case anyone ends up here looking for the generate_package.py file it has now been rolled into the native_client as an executable.

Yeah, as documented in the doc and as linked above.",case anyone looking file rolled executable yeah doc linked,issue,negative,neutral,neutral,neutral,neutral,neutral
673110561,In case anyone ends up here looking for the generate_package.py file it has now been rolled into the native_client as an executable. ,case anyone looking file rolled executable,issue,negative,neutral,neutral,neutral,neutral,neutral
673083490,"I'm using Anaconda Prompt to get Linux familiarity in Windows OS. 
Following are the exact steps I'm doing:
1. Create a virtualenv using python 3.6.8: python -m venv <env-name>
2. Activate env: <env-name>/Scripts/activate
3. pip install deepspeech (Latest version i.e. v0.8.1 is being installed.)
4. downloaded the latest pre-trained model:
    https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm
    https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer
5. Script to load model:
    `from deepspeech import Model
    ds = Model('deepspeech-0.8.1-models.pbmm')

    **On initializing ds:** 
TensorFlow: v1.15.0-24-gceb46aae58
DeepSpeech: v0.7.0-0-g3fbbca2b
2020-08-13 01:29:04.289027: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
`
Above details are being printed on the terminal. Hope it will help.

    ds.enableExternalScorer('deepspeech-0.8.1-models.scorer')
    
",anaconda prompt get familiarity o following exact create python python activate pip install latest version latest model script load model import model model binary use printed terminal hope help,issue,positive,positive,positive,positive,positive,positive
671561184,We might need special care for things like SWIG: it depends on `automake` for example,might need special care like swig example,issue,positive,positive,positive,positive,positive,positive
671414679,"@carlfm01 There's a lot of .Net / UWP related renames and this does not get tested on CI, so I'll merge anyway when my PR is green, but you're more than welcome to check and send patches to fix my mistakes :)",lot related get tested merge anyway green welcome check send fix,issue,negative,positive,positive,positive,positive,positive
670930925,"- [x] Improve logo placement on left navigation
- [x] Add Twitter link
- [x] Get references to work without jekyll-scholar
- [x] Switch TTS splashes
- [ ] Write Model Card for 0.7.0 model
- [ ] Write Model Card for other 0.7.X models
- [ ] Write Model Card for 0.8.0 mode
- [ ] Rework Model Page table
- [ ] Flush Model Pages title image to top
- [ ] Add Model Page title image and flush to top
- [ ] Flush About Page title image to top
- [ ] Write copy of About page
- [ ] Size blog videos
- [ ] Change border color of captioned blog images
- [ ] Size blog JSFiddle
- [ ] On re-sizing have left land logo switch from ml to moz://ml
- [ ] Data Set Page?",improve placement left navigation add twitter link get work without switch write model card model write model card write model card mode rework model page table flush model title image top add model page title image flush top flush page title image top write copy page size change border color size left land switch data set page,issue,positive,positive,positive,positive,positive,positive
670431321,"> My first guess is that it means that all reviews have a state of ""APPROVED"", but I am not sure.

Yes.

> have classified 'reviewed and accepted' to mean any PR which has >= 2 reviews which have a state of ""APPROVED""

I'm not sure I understand what that means, often there is only going to be one person reviewing a PR.



> listing all reviews includes reviews which have since been updated. (i.e. if someone initially requests changes, but then approves a PR, there will always be a review whose state is ""CHANGES_REQUESTED""

I think we just care about the latest reviews from each of the reviewers ?
So if at time t all the reviewers set an ""APPROVED"" flag, then we can consider this is fine and proceed.



> I uploaded the bot's code to a repo [here](https://github.com/RucksP/label-reactor)

Thanks, I'll take a look!",first guess state sure yes classified accepted mean state sure understand often going one person listing since someone initially always review whose state think care latest time set flag consider fine proceed bot code thanks take look,issue,positive,positive,positive,positive,positive,positive
670390059,"> Note that when we make an alpha with this we'll again need to upload the -CUDA package by hand :/

Should we added this to the [Release Checklist](https://github.com/mozilla/DeepSpeech/wiki/Release-checklist)?",note make alpha need package hand added release,issue,negative,neutral,neutral,neutral,neutral,neutral
670281013,"Hi can you clarify what is meant by reviewed and accepted?

My first guess is that it means that all reviews have a state of ""APPROVED"", but I am not sure.

For now i have classified 'reviewed and accepted' to mean any PR which has >= 2 reviews which have a state of ""APPROVED"" because listing all reviews includes reviews which have since been updated. (i.e. if someone initially requests changes, but then approves a PR, there will always be a review whose state is ""CHANGES_REQUESTED""

I uploaded the bot's code to a repo [here](https://github.com/RucksP/label-reactor)",hi clarify meant accepted first guess state sure classified accepted mean state listing since someone initially always review whose state bot code,issue,positive,positive,positive,positive,positive,positive
670200502,Names sound good. Will use them. Thanks!,sound good use thanks,issue,positive,positive,positive,positive,positive,positive
670073701,"> I'm also fascinated by the little help you get to get the requested test implemented, essentially blocking the patch,
> most opensource communities I have encountered so far are happy when you fix or even pinpoint (a long standing) bug.

Well, I can understand why they want that, I guess in their position I'd do the same. Looks like things are moving now, I hope this can go into a 1.15.4 or in the worst case, we need statement on the consequences of the flag.",also fascinated little help get get test essentially blocking patch far happy fix even pinpoint long standing bug well understand want guess position like moving hope go worst case need statement flag,issue,positive,negative,neutral,neutral,negative,negative
670058075,"> Hi I've seen you've renamed the library.
> 
> [fa21911](https://github.com/mozilla/DeepSpeech/commit/fa2191104878fed468cb16cc8782c345c98ff7aa)
> 
> Currently the Rust bindings are still named `deepspeech` and `deepspeech-sys`. I wonder which name they should get now. Do you have any ideas?

Well, if you are okay with renaming (which we would love for consistency), I guess `mozilla-voice-stt` and `mozilla-voice-stt-sys` would be good, nope?",hi seen library fa currently rust still wonder name get well would love consistency guess would good nope,issue,positive,positive,positive,positive,positive,positive
669990150,Note that when we make an alpha with this we'll again need to upload the -CUDA package by hand :/,note make alpha need package hand,issue,negative,neutral,neutral,neutral,neutral,neutral
669962295,"> Hi I am new to contributing to open source. Just to be clear what you are asking you want a probot bot to:

Thanks for your interest!


> Upon a pull request being assigned a label do something automatically.

Yes


>  a) Is there a list of what you want to be done for every label, or do you just want a framework which can be added upon later?

It's really only one use-case here, and my understanding after quickly looking at the probot doc is that it should be fairly easy relying on that stack to add new cases after



> The bot should be added to the probot website.

I don't think so, why should we do that?

It should run on heroku under our control.",hi new open source clear want bot thanks interest upon pull request assigned label something automatically yes list want done every label want framework added upon later really one understanding quickly looking doc fairly easy stack add new bot added think run control,issue,positive,positive,positive,positive,positive,positive
669888288,"Updated first comment with a list of things to do, please add anything missing or check off completed items.",first comment list please add anything missing check,issue,negative,positive,neutral,neutral,positive,positive
669645216,"Hi I am new to contributing to open source. Just to be clear what you are asking you want a probot bot to:

1) Upon a pull request being assigned a label do something automatically. 
 a) Is there a list of what you want to be done for every label, or do you just want a framework which can be added upon later?
2) The bot should be added to the probot website.

If that is it, then I can work on this.",hi new open source clear want bot upon pull request assigned label something automatically list want done every label want framework added upon later bot added work,issue,positive,positive,neutral,neutral,positive,positive
669595710,"> Even after installing this, it detects v0.7.0

Please avoid screenshots.
Please explain how you run things, what is this shell, are you running under msys2? Under PowerShell? Under `cmd.exe`?
Can you ensure there is no `libdeepspeech.so` being hit in your `PATH`?
Can you `strace` the loading to see where the `libdeepspeech.so` is being loaded from?",even please avoid please explain run shell running ensure hit path loading see loaded,issue,positive,neutral,neutral,neutral,neutral,neutral
669595250,"> `pip install -v` + `pip list` ?
> pip 18.1

Can we be serious two seconds?
we need the installl log!",pip install pip list pip serious two need log,issue,negative,negative,negative,negative,negative,negative
669591255,"No, I downloaded pre-trained models of v0.7.4, updated deepspeech version too.

`pip install -v` + `pip list` ?
pip 18.1

```
pip freeze (pip list)
appdirs==1.4.4
audioread==2.1.8
cachetools==4.1.1
certifi==2020.6.20
cffi==1.14.0
chardet==3.0.4
cx-Freeze==6.1
decorator==4.4.2
deepspeech==0.7.4
google-api-core==1.22.0
google-api-python-client==1.10.0
google-auth==1.19.2
google-auth-httplib2==0.0.4
googleapis-common-protos==1.52.0
httplib2==0.18.1
idna==2.8
importlib-metadata==1.6.0
joblib==0.15.1
jsonpickle==1.4.1
librosa==0.8.0
llvmlite==0.33.0
numba==0.50.1
numpy==1.14.4
oauth2client==4.1.3
packaging==20.4
pocketsphinx==0.1.15
pooch==1.1.1
protobuf==3.12.2
py-wasapi-client==1.1.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
PyAudio==0.2.11
pycparser==2.20
pydub==0.24.1
pyparsing==2.4.7
pypiwin32==223
PyQRCode==1.2.1
pyqtspinner==0.1.1
PySide2==5.14.0
pytz==2020.1
pywin32==224
requests==2.22.0
resampy==0.2.2
rsa==4.6
scikit-learn==0.23.1
scipy==1.4.1
shiboken2==5.14.0
six==1.15.0
sklearn==0.0
SoundCard==0.4.0
sounddevice==0.3.15
SoundFile==0.10.3.post1
SpeechRecognition==3.8.1
threadpoolctl==2.1.0
uritemplate==3.0.1
urllib3==1.25.9
wavio==0.0.4
win10toast==0.9
zipp==3.1.0
```",version pip install pip list pip pip freeze pip list post,issue,negative,neutral,neutral,neutral,neutral,neutral
669590467,"> > python's 3.6.8 version (same is being used for both Mac & Linux).
> > pip install deepspeech
> 
> https://files.pythonhosted.org/packages/cf/44/958607ce1c95c5386c29e2b9c8a30f8bc797d07306d16e6ef7f7f468a464/deepspeech-0.7.4-cp36-cp36m-win_amd64.whl
> 
> So it's published, we really need more verbose logs and pip list logs, but I'm highly doubtful there's a bug on our side, it more feels like some setup issue on your side ...

Even after installing this, it detects v0.7.0
![image](https://user-images.githubusercontent.com/11367944/89472734-bafa6c80-d79e-11ea-8707-6a92870ca228.png)
",python version used mac pip install really need verbose pip list highly doubtful bug side like setup issue side even image,issue,negative,negative,negative,negative,negative,negative
669494563,"@lissyx It's pretty much impossible to review the diff itself I guess, but would be great if you could double check the built artifacts to see if you catch something.",pretty much impossible review guess would great could double check built see catch something,issue,positive,positive,neutral,neutral,positive,positive
669145898,"> On closer observation, the issue seems due to cuda version 10.2 vs 10.1

No, on closer observation, you are fallbacking on CPU only.",closer observation issue due version closer observation,issue,negative,negative,negative,negative,negative,negative
669112783,"> That's true, perhaps my dutch heritage that policies are nice when they make sense ;)

Well, even fixing ruy computation on just-released r2.2 was not taken and only merged on master ",true perhaps dutch heritage nice make sense well even fixing computation taken master,issue,positive,positive,positive,positive,positive,positive
669087785,"Apologies for not sending the complete logs last time. Like you mentioned, logs revealed the issue. On closer observation, the issue seems due to cuda version 10.2 vs 10.1 .The deepspeech binaries look for ""libcudart.so.10.1"", which obviously isn't  available on cuda 10.2. I'm adding the logs for running inference on 10.2 machine. You can close the issue, as its not a bug per-se. But maybe this behavior can be added somewhere in documentation. 
 

(deepspeech-venv) root:~# deepspeech --model models/deepspeech-0.8-models/deepspeech-0.8.0-models.pbmm --scorer models/deepspeech-0.8-models/deepspeech-0.8.0-models.scorer --audio models/Test1.wav
2020-08-05 09:21:33.447482: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-05 09:21:33.447509: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Loading model from file models/deepspeech-0.8-models/deepspeech-0.8.0-models.pbmm
TensorFlow: v2.2.0-17-g0854bb5
DeepSpeech: v0.8.0-0-gf56b07d
2020-08-05 09:21:33.550303: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-05 09:21:33.552163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-05 09:21:33.562171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:21:33.562666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:41:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-05 09:21:33.562726: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-08-05 09:21:33.564122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-05 09:21:33.565558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-05 09:21:33.565773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-05 09:21:33.567322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-05 09:21:33.568031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-05 09:21:33.582203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-05 09:21:33.582230: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-08-05 09:21:33.663695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 09:21:33.663718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-08-05 09:21:33.663723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
Loaded model in 0.122s.
Loading scorer from files models/deepspeech-0.8-models/deepspeech-0.8.0-models.scorer
Loaded scorer in 0.000134s.
Running inference.
i will try this one more time
Inference took 1.490s for 4.821s audio file.

",sending complete last time like revealed issue closer observation issue due version look obviously available running inference machine close issue bug maybe behavior added somewhere documentation root model scorer audio could load dynamic library open object file file directory ignore set machine loading model file binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti could load dynamic library open object file file directory successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library please make sure missing properly would like use follow guide setup platform skipping device interconnect strength edge matrix loaded model loading scorer loaded scorer running inference try one time inference took audio file,issue,positive,positive,neutral,neutral,positive,positive
669074150,"> > I think you are thinking about setting this environment var from the DS code as a workaround for not getting a TF 1.15.4 release ?
> At least know if it's a good thing to debug people with that or if we are creating underlying issues.

> > (I think it's not very wise keeping TF 1.15 that broken in the first place, it wastes a lot of resource everywhere from people having their training go bust and perhaps trying to debug that again (for all projects and people still using TF 1.15 with LSTM), while it is a straight and simple fix, so it would be a nice ""reward"" for digging in this and fixing this thing which was uncaught for so many releases), but that is my not so humble opinion about this.
> 
> Sure, but it's not in our hands nor in the hands of people who will review the PR, there's a policy and they might have their hands tied.

That's true, perhaps my dutch heritage that policies are nice when they make sense ;)
I'm also fascinated by the little help you get to get the requested test implemented, essentially blocking the patch, 
most opensource communities I have encountered so far are happy when you fix or even pinpoint (a long standing) bug.

> > Back to the environment var:
> > If remember correctly from looking at the code, it influenced some kind of ""dropout"" and as extra busted the cache (which causes things to work for us), but I don't know what the influence of changing that specific dropout behavior has on training the model. Would be nice if the TF / Nvidia guys can give some comment on that, before we perhaps DS degrade training by missing any side effects.
> 
> Exactly.

By the way, I'm wondering do you know how often do we still use the cached version on your larger dataset test ?
The difference of 20 seconds is so small, that either:
- DS doesn't get to use a cached version very often on a real life dataset
- Caching isn't very effective and about equal in cost to not caching",think thinking setting environment code getting release least know good thing people underlying think wise keeping broken first place lot resource everywhere people training go bust perhaps trying people still straight simple fix would nice reward digging fixing thing uncaught many humble opinion sure people review policy might tied true perhaps dutch heritage nice make sense also fascinated little help get get test essentially blocking patch far happy fix even pinpoint long standing bug back environment remember correctly looking code kind dropout extra busted cache work u know influence specific dropout behavior training model would nice give comment perhaps degrade training missing side effect exactly way wondering know often still use version test difference small either get use version often real life effective equal cost,issue,positive,positive,positive,positive,positive,positive
669035885,"Debian Sid, 440.100, CUDA 10.0/10.1, 2x RTX 2080 Ti, I get similar values for both runtime:

Here, 0.7.4:
```
$ LD_LIBRARY_PATH=$HOME/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.0/lib64/ ~/.local/bin/deepspeech --model 0.7.4/deepspeech-0.7.4-models.pbmm --scorer 0.7.4/deepspeech-0.7.4-models.scorer --audio 0.7.4/audio/4507-16021-0012.wav 
2020-08-05 09:37:22.402743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
Loading model from file 0.7.4/deepspeech-0.7.4-models.pbmm
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.4-0-gfcd9563
2020-08-05 09:37:22.459462: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-05 09:37:22.467616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-05 09:37:28.195019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.195842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:21:00.0
2020-08-05 09:37:28.195903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.196660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:4b:00.0
2020-08-05 09:37:28.196682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-08-05 09:37:28.197716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-08-05 09:37:28.198661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-08-05 09:37:28.198873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-08-05 09:37:28.200028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-08-05 09:37:28.200845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-08-05 09:37:28.202416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-05 09:37:28.202466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.202995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.203485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.203979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.204618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2020-08-05 09:37:28.470107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 09:37:28.470135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 
2020-08-05 09:37:28.470139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N N 
2020-08-05 09:37:28.470142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   N N 
2020-08-05 09:37:28.470271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.470793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.471291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.471786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.472271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10281 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2020-08-05 09:37:28.472628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.473124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:37:28.473599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10281 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:4b:00.0, compute capability: 7.5)
Loaded model in 6.07s.
Loading scorer from files 0.7.4/deepspeech-0.7.4-models.scorer
Loaded scorer in 0.000127s.
Running inference.
2020-08-05 09:37:28.562104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
why should one hall on the way
Inference took 0.438s for 2.735s audio file.
```

Here, 0.8.0:
```
$ LD_LIBRARY_PATH=$HOME/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.1/lib64/ ~/.local/bin/deepspeech --model 0.8.0/deepspeech-0.8.0-models.pbmm --scorer 0.8.0/deepspeech-0.8.0-models.scorer --audio 0.8.0/audio/4507-16021-0012.wav 
2020-08-05 09:36:28.999877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
Loading model from file 0.8.0/deepspeech-0.8.0-models.pbmm
TensorFlow: v2.2.0-17-g0854bb5
DeepSpeech: v0.8.0-0-gf56b07d
2020-08-05 09:36:29.060559: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-08-05 09:36:29.068770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-05 09:36:34.776973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.777499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-05 09:36:34.777531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.778008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: 
pciBusID: 0000:4b:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-08-05 09:36:34.778022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 09:36:34.778820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-05 09:36:34.779840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-05 09:36:34.780082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-05 09:36:34.780877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-05 09:36:34.781309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-05 09:36:34.783013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-05 09:36:34.783071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.783611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.784115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.784601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:34.785070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1
2020-08-05 09:36:35.083581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 09:36:35.083608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 
2020-08-05 09:36:35.083612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N 
2020-08-05 09:36:35.083615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N 
2020-08-05 09:36:35.083757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.084271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.084758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.085246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.085724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10169 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2020-08-05 09:36:35.086091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.086580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 09:36:35.087055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10169 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:4b:00.0, compute capability: 7.5)
Loaded model in 6.08s.
Loading scorer from files 0.8.0/deepspeech-0.8.0-models.scorer
Loaded scorer in 0.000127s.
Running inference.
2020-08-05 09:36:35.173568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
why should one hall on the way
Inference took 0.439s for 2.735s audio file.
```

",ti get similar model scorer audio successfully dynamic library loading model file binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti major minor successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library one hall way inference took audio file model scorer audio successfully dynamic library loading model file binary use successfully dynamic library successful node read negative value must least one node node zero found device name ti successful node read negative value must least one node node zero found device name ti successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability loaded model loading scorer loaded scorer running inference successfully dynamic library one hall way inference took audio file,issue,positive,positive,neutral,neutral,positive,positive
669031714,"@neocheema Please:
 - don't cut output so we can have versions informations
 - share setup
 - share installs steps: is this c++ client, python, nodejs?
 - share details on the audio",please cut output share setup share client python share audio,issue,positive,neutral,neutral,neutral,neutral,neutral
668685889,"> I think you are thinking about setting this environment var from the DS code as a workaround for not getting a TF 1.15.4 release ?

At least know if it's a good thing to debug people with that or if we are creating underlying issues.

> 
> (I think it's not very wise keeping TF 1.15 that broken in the first place, it wastes a lot of resource everywhere from people having their training go bust and perhaps trying to debug that again (for all projects and people still using TF 1.15 with LSTM), while it is a straight and simple fix, so it would be a nice ""reward"" for digging in this and fixing this thing which was uncaught for so many releases), but that is my not so humble opinion about this.

Sure, but it's not in our hands nor in the hands of people who will review the PR, there's a policy and they might have their hands tied.

> 
> Back to the environment var:
> If remember correctly from looking at the code, it influenced some kind of ""dropout"" and as extra busted the cache (which causes things to work for us), but I don't know what the influence of changing that specific dropout behavior has on training the model. Would be nice if the TF / Nvidia guys can give some comment on that, before we perhaps DS degrade training by missing any side effects.

Exactly.",think thinking setting environment code getting release least know good thing people underlying think wise keeping broken first place lot resource everywhere people training go bust perhaps trying people still straight simple fix would nice reward digging fixing thing uncaught many humble opinion sure people review policy might tied back environment remember correctly looking code kind dropout extra busted cache work u know influence specific dropout behavior training model would nice give comment perhaps degrade training missing side effect exactly,issue,positive,positive,positive,positive,positive,positive
668524835,"I think you are thinking about setting this environment var from the DS code as a workaround for not getting a TF 1.15.4 release ?

(I think it's not very wise keeping TF 1.15 that broken in the first place, it wastes a lot of resource everywhere from people having their training go bust and perhaps trying to debug that again (for all projects and people still using TF 1.15 with LSTM), while it is a straight and simple fix, so it would be a nice ""reward"" for digging in this and fixing this thing which was uncaught for so many releases), but that is my not so humble opinion about this.

Back to the environment var:
If remember correctly from looking at the code, it influenced some kind of ""dropout"" and as extra busted the cache (which causes things to work for us), but I don't know what the influence of changing that specific dropout behavior has on training the model. Would be nice if the TF / Nvidia guys can give some comment on that, before we perhaps DS degrade training by missing any side effects.",think thinking setting environment code getting release think wise keeping broken first place lot resource everywhere people training go bust perhaps trying people still straight simple fix would nice reward digging fixing thing uncaught many humble opinion back environment remember correctly looking code kind dropout extra busted cache work u know influence specific dropout behavior training model would nice give comment perhaps degrade training missing side effect,issue,positive,positive,positive,positive,positive,positive
668466447,"> > > @applied-machinelearning So, we've got some feedback from the nvidia dev, and it seems `TF_CUDNN_RESET_RND_GEN_STATE=1` does help here. I'm unsure of the implications, especially in term of performances, but maybe you can give that a try on your full dataset, this could help us assert:
> > > ```
> > > * it is indeed related to the issue
> > > * have an idea of the perf impact
> > > ```
> > 
> > 
> > Was away from keyboard this weekend, running tests now.
> > The short tests work with that ENV variable set, now running the longer one.
> > Edit: The long test also works.
> 
> I'm presently running one or two training epochs with `TF_CUDNN_RESET_RND_GEN_STATE=0` / `TF_CUDNN_RESET_RND_GEN_STATE=1` to assert the impact

So I could not spot any huge difference: only a 20-secs per epoch slowdown.",got feedback dev help unsure especially term maybe give try full could help u assert indeed related issue idea impact away keyboard weekend running short work variable set running longer one edit long test also work presently running one two training assert impact could spot huge difference per epoch slowdown,issue,positive,positive,neutral,neutral,positive,positive
667995050,"This should merge into master and then master into r0.8, not directly into r0.8.",merge master master directly,issue,negative,positive,neutral,neutral,positive,positive
667687700,"Thanks, it means there seems to be much more impact we anticipated / experienced ",thanks much impact experienced,issue,negative,positive,positive,positive,positive,positive
667681576,"@lissyx : Setting `TF_CUDNN_RESET_RND_GEN_STATE=1` resolved the issue.

Thank you, I am closing the ticket.",setting resolved issue thank ticket,issue,negative,neutral,neutral,neutral,neutral,neutral
667674633,"> We might be able to use `n2-highcpu-32` soonish, it does not have the nested virtualization limitation

It might be the reason why we cannot build anymore linux/cuda tensorflow: 15 retry, always claim_expired after 20/30 min. not sure yet if it's just disk space or if maybe we run out of RAM.",might able use soonish limitation might reason build retry always min sure yet disk space maybe run ram,issue,negative,positive,positive,positive,positive,positive
667541609,"Once again what was supposed to be a tiny patch with ""quite easy green CI"" turns into a huge mess ...
macOS infra is overloaded and takes ages, taskcluster workers are dying out of disk space ...",supposed tiny patch quite easy green turn huge mess infra dying disk space,issue,negative,positive,neutral,neutral,positive,positive
667481332,"If that won't require some massive overhaul it might be a good idea. Static frameworks are sometimes better for app load times than dynamic ones. Let me know how this goes, as switching from Apple's wildly unstable built-in transcription API to DeepSpeech for extremely long on-device transcription jobs is on our roadmap (after trying it on Android starting in a few days). ",wo require massive overhaul might good idea static sometimes better load time dynamic let know go switching apple wildly unstable transcription extremely long transcription trying android starting day,issue,positive,positive,positive,positive,positive,positive
667456169,I could verify it is working on linux/rpi3 and linux/arm64 so it should be green on CI quite easily ...,could verify working green quite easily,issue,negative,positive,positive,positive,positive,positive
667456057,"> removing `-shared` works: https://github.com/mozilla/tensorflow/blob/r2.2/tools/arm_compiler/linaro-gcc72-armeabi/linaro_toolchain_config.bzl#L383
> 
> so I think there's something still wrong in our toolchain definition ...

well, it's just dumb as hell: it's just wrong for executables ...",removing work think something still wrong definition well dumb hell wrong,issue,negative,negative,negative,negative,negative,negative
667453861,"removing `-shared` works: https://github.com/mozilla/tensorflow/blob/r2.2/tools/arm_compiler/linaro-gcc72-armeabi/linaro_toolchain_config.bzl#L383

so I think there's something still wrong in our toolchain definition ...",removing work think something still wrong definition,issue,negative,negative,negative,negative,negative,negative
667444148,"Debug build with `--copt=-D_GLIBCXX_USE_CXX11_ABI=1`:
```
(gdb) run
Starting program: /home/pi/ds-0.8/generate_scorer_package 

Program received signal SIGSEGV, Segmentation fault.
0x0000a134 in ?? ()
(gdb) bt
#0  0x0000a134 in ?? ()
#1  0xb6fe0592 in _GLOBAL__sub_I__Z14create_packageN4absl8optionalINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEES6_S6_S6_NS0_IbEEff ()
```",build run starting program program received signal segmentation fault,issue,negative,neutral,neutral,neutral,neutral,neutral
667440691,"Even
```
$ cat native_client/generate_scorer_package.cpp 
int
main(int argc, char** argv)
{
    return 0;
}
```

Does segfault ...",even cat main char return,issue,negative,positive,positive,positive,positive,positive
667228244,Me neither but de have been badly bitten by that during release yesterday 😕,neither de badly bitten release yesterday,issue,negative,negative,negative,negative,negative,negative
667205801,"I don't feel Ok with this code duplicated, sadly I don't see how we can avoid that :/ ",feel code sadly see avoid,issue,negative,negative,negative,negative,negative,negative
667137415,"> > @applied-machinelearning So, we've got some feedback from the nvidia dev, and it seems `TF_CUDNN_RESET_RND_GEN_STATE=1` does help here. I'm unsure of the implications, especially in term of performances, but maybe you can give that a try on your full dataset, this could help us assert:
> > ```
> > * it is indeed related to the issue
> > * have an idea of the perf impact
> > ```
> 
> Was away from keyboard this weekend, running tests now.
> The short tests work with that ENV variable set, now running the longer one.
> Edit: The long test also works.

I'm presently running one or two training epochs with `TF_CUDNN_RESET_RND_GEN_STATE=0` / `TF_CUDNN_RESET_RND_GEN_STATE=1` to assert the impact",got feedback dev help unsure especially term maybe give try full could help u assert indeed related issue idea impact away keyboard weekend running short work variable set running longer one edit long test also work presently running one two training assert impact,issue,positive,positive,neutral,neutral,positive,positive
666711465,"I'm not talking about loading dynamic code from the internet, I'm talking about having to add a shared library as a dependency or your app in Xcode. It'll then get codesigned and bundled with the application. This is because iOS does not allow linking against a framework that itself links against another shared library. Maybe I should look more seriously into static linking, which would make this way simpler.


> Am 30.07.2020 um 22:28 schrieb zaptrem <notifications@github.com>:
> 
> ﻿
> I'll look into that. Loading dynamic code from the internet isn't allowed on the AppStore.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",talking loading dynamic code talking add library dependency get application allow linking framework link another library maybe look seriously static linking would make way simpler um look loading dynamic code reply directly view,issue,positive,positive,positive,positive,positive,positive
666679908,"Also, if you still want to build natively on your system and you can send a PR, we'd be happy to take à look, but you need to understand that it is not a setup we can properly guarantee support for in the forseable future, unfortunately",also still want build natively system send happy take look need understand setup properly guarantee support future unfortunately,issue,positive,positive,neutral,neutral,positive,positive
666678393,"That being said, i would have expected our prebuilt binaries for rpi3 to work on your centos given the versions. Can you elaborate why it does not work ? ",said would work given elaborate work,issue,negative,positive,positive,positive,positive,positive
666674371,"> Result: When building DeepSpeech 0.7.4, the Python bindings make fails and also creates the wrong architecture package.

This should work if you pass `TARGET=rpi3` but in our case it does also assume cross-compilation as well as raspbian buster target.

And if you ask, we cannot really support native ARM builds because it'd require lots of CI extra hardware and complexity.

In your case, adapting cross compilation to target a centos 8 system should do the trick, but you might also have to adapt tensorflow build as well, i know they have had native build support but moved to cross compilation as well.",result building python make also wrong architecture package work pas case also assume well buster target ask really support native arm require lot extra hardware complexity case cross compilation target system trick might also adapt build well know native build support cross compilation well,issue,positive,negative,neutral,neutral,negative,negative
666673742,I'll look into that. Is it not possible to bundle `libdeepspeech.so` with the Cocoapod then use something like [use_frameworks!](http://guides.cocoapods.org/syntax/podfile.html#use_frameworks_bang) ? I'm pretty sure Google does that with all of their pods. Loading dynamic code from the internet isn't allowed on the AppStore.,look possible bundle use something like pretty sure loading dynamic code,issue,positive,positive,positive,positive,positive,positive
666670741,"It's not just the models, you also need to add the shared library, `libdeepspeech.so`, as a direct dependency of the app. Do you think it still makes sense to publish the framework on Cocoapods given this requirement? I've been hesitant to do that and then get tons of support requests from people with weird linker errors.

We could try to `dlopen` the library and give a more descriptive message but I'm not sure how that fits with App Store guidelines.",also need add library direct dependency think still sense publish framework given requirement hesitant get support people weird linker could try library give descriptive message sure store,issue,negative,positive,neutral,neutral,positive,positive
666668438,"We only support cross compilation for ARM systems, but if you need you might be able to leverage TARGET make var, see definitions.mk",support cross compilation arm need might able leverage target make see,issue,negative,positive,positive,positive,positive,positive
666653030,"Do you plan on publishing a Cocoapod for the framework portion of this? I'm going to build a React Native module for this but auto-linking requires a pod. Afterward, I can add instructions for users to drag the model file into the correct directory.",plan framework portion going build react native module pod afterward add drag model file correct directory,issue,negative,negative,neutral,neutral,negative,negative
666482150,">  please help me, thanks

Please read the doc. This flag is not good anymore: use `--scorer_path`.",please help thanks please read doc flag good use,issue,positive,positive,positive,positive,positive,positive
665746222,"> > My issue:
> > DeepSpeech version (0.7.0-alpha.2) and CTC decoder version (0.7.4) do not match. Please ensure matching versions are in use.
> > And pip can't find ds-ctcdecoder==0.7.0-alpha.2
> 
> Moreover, you reported that one month ago and did not shared any informations versions, so there was no way for us to know that, especially since we had some infra-related issue at the same time.
> 
> As @reuben said, please reach for support on Discourse. Also, the error is quite explicit: you have `ds_ctcdecoder==0.7.4` installed and your are still running 0.7.0-alpha.2 training code. Please just upgrade your training to 0.7.4.

I find the solution, Update DeepSpeech version (cloning a latest version) and I resume the configuration for all.
It just versioning problem.
nevertheless thank you",issue version version match please ensure matching use pip ca find moreover one month ago way u know especially since issue time said please reach support discourse also error quite explicit still running training code please upgrade training find solution update version latest version resume configuration problem nevertheless thank,issue,positive,positive,positive,positive,positive,positive
665053899,"Yeah, ideally we'd be available in Cocoapods or something like that, but also we use deepspeech_ios_test to make sure usage of the API builds in CI as well. Otherwise we may break stuff without noticing if we only build the binding itself.",yeah ideally available something like also use make sure usage well otherwise may break stuff without build binding,issue,positive,positive,positive,positive,positive,positive
665010383,"Awesome! 
But one question, shouldn't be a demo like this be in the examples repo? Or is that more difficult because the library would need to be available as a dependency like via cocoapods? ",awesome one question like difficult library would need available dependency like via,issue,positive,positive,positive,positive,positive,positive
664922759,"> It's just a default path if one is not specified.

I agree, but the null check it's surrounded in makes sure it's never used. So it serves no purpose as far as I can see.",default path one agree null check surrounded sure never used purpose far see,issue,positive,positive,positive,positive,positive,positive
664906453,"> @applied-machinelearning So, we've got some feedback from the nvidia dev, and it seems `TF_CUDNN_RESET_RND_GEN_STATE=1` does help here. I'm unsure of the implications, especially in term of performances, but maybe you can give that a try on your full dataset, this could help us assert:
> 
>     * it is indeed related to the issue
>     * have an idea of the perf impact

Was away from keyboard this weekend, running tests now.
The short tests work with that ENV variable set, now running the longer one.
Edit: The long test also works.",got feedback dev help unsure especially term maybe give try full could help u assert indeed related issue idea impact away keyboard weekend running short work variable set running longer one edit long test also work,issue,positive,positive,neutral,neutral,positive,positive
664558701,"I just tried your code with a single file on my iPhone Xs and it works fine. Really puzzling why you can't get loading from a file to work.

```
TensorFlow: v2.2.0-17-g0854bb5188
DeepSpeech: v0.9.0-alpha.3-44-gcbf9a8d2
2020-07-27 20:17:35.424637+0200 deepspeech_ios_test[6563:3153221] Initialized TensorFlow Lite runtime.
/private/var/containers/Bundle/Application/3C928228-453E-4C3B-A88D-8213A6DF699F/deepspeech_ios_test.app/1284-134647-0003.wav
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 2832 samples
""/private/var/containers/Bundle/Application/3C928228-453E-4C3B-A88D-8213A6DF699F/deepspeech_ios_test.app/1284-134647-0003.wav"": 3.344200015068054 - constantine easily believed that the heretics who presumed to dispute his opinions or to oppose his commands were guilty of the most absurd and criminal obstinacy and that a seasonable application of moderate severities might save those unhappy men from the danger of an everlasting condemnation
```",tried code single file work fine really puzzling ca get loading file work lite read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read read easily dispute oppose guilty absurd criminal obstinacy seasonable application moderate might save unhappy men danger everlasting condemnation,issue,negative,negative,negative,negative,negative,negative
664454622,Sorry I missed the author comment. I'll set you as the author for `AudioContext.swift` and you and me for `DeepSpeech.swift` if thats alright.,sorry author comment set author thats alright,issue,negative,negative,negative,negative,negative,negative
664453783,"[Here is the PR](https://github.com/mozilla/DeepSpeech/pull/3189)
While file transcription does still not work, the microphone streaming actually works for me :D
",file transcription still work microphone streaming actually work,issue,negative,neutral,neutral,neutral,neutral,neutral
664449357,"We might be able to use `n2-highcpu-32` soonish, it does not have the nested virtualization limitation",might able use soonish limitation,issue,negative,positive,positive,positive,positive,positive
664428386,"@gokgozf In order to help us help you, could you elaborate on what's missing?",order help u help could elaborate missing,issue,negative,positive,positive,positive,positive,positive
664406652,"> I didn't get time to work on this. I will post my results soon!

Please @SanghviChirag ? We can't move forward without your feedback, and it'd be important if we can assert if there is not a huge issue we missed before we issue a new stable release.",get time work post soon please ca move forward without feedback important assert huge issue issue new stable release,issue,positive,positive,positive,positive,positive,positive
664382095,"@erksch that is a leftover from older code, I'll remove it. You should only need `libdeepspeech.so`. ",leftover older code remove need,issue,negative,positive,positive,positive,positive,positive
664381623,"@reuben I noticed ""/deepspeech_ios/libdeepspeech.dylib"" in the .gitignore. Maybe that is what is missing for me? Where do I get this file?",maybe missing get file,issue,negative,negative,negative,negative,negative,negative
664351136,"@reuben sorry for the absence, i was a little bit occupied. I'll make a PR today! ",sorry absence little bit make today,issue,negative,negative,negative,negative,negative,negative
664196393,Models trained on data with such augmentations are in the process of being trained.,trained data process trained,issue,negative,neutral,neutral,neutral,neutral,neutral
664195962,@erksch have you had a chance to work on the microphone streaming code? I would love to include that in 0.8 if possible :),chance work microphone streaming code would love include possible,issue,positive,positive,positive,positive,positive,positive
664164802,"> I have recently came across deep-speech and I have installed all packages/dependencies for it. Then I'm using this below given script to inference from live streaming audio. But the problem here is the results are not good.

As written in the template you removed, please use Discourse for reaching support. And when you do so, please share more than ""the results are not good"": we need setup context, ground truth, model used, etc.",recently came across given script inference live streaming audio problem good written template removed please use discourse reaching support please share good need setup context ground truth model used,issue,positive,positive,positive,positive,positive,positive
663816972,"@tilmankamp Thanks! Are the pretrained models trained with reverb and these other augmentations enabled? Also, is the reverb added before or after the audio is mixed with the noise samples?",thanks trained reverb also reverb added audio mixed noise,issue,negative,positive,neutral,neutral,positive,positive
663641028,"> My issue:
> DeepSpeech version (0.7.0-alpha.2) and CTC decoder version (0.7.4) do not match. Please ensure matching versions are in use.
> 
> And pip can't find ds-ctcdecoder==0.7.0-alpha.2

Moreover, you reported that one month ago and did not shared any informations versions, so there was no way for us to know that, especially since we had some infra-related issue at the same time.

As @reuben said, please reach for support on Discourse. Also, the error is quite explicit: you have `ds_ctcdecoder==0.7.4` installed and your are still running 0.7.0-alpha.2 training code. Please just upgrade your training to 0.7.4.",issue version version match please ensure matching use pip ca find moreover one month ago way u know especially since issue time said please reach support discourse also error quite explicit still running training code please upgrade training,issue,positive,neutral,neutral,neutral,neutral,neutral
663630770,"My issue: 
DeepSpeech version (0.7.0-alpha.2) and CTC decoder version (0.7.4) do not match. Please ensure matching versions are in use.

And pip can't find ds-ctcdecoder==0.7.0-alpha.2
",issue version version match please ensure matching use pip ca find,issue,positive,neutral,neutral,neutral,neutral,neutral
663466075,"@applied-machinelearning So, we've got some feedback from the nvidia dev, and it seems `TF_CUDNN_RESET_RND_GEN_STATE=1` does help here. I'm unsure of the implications, especially in term of performances, but maybe you can give that a try on your full dataset, this could help us assert:
 - it is indeed related to the issue
 - have an idea of the perf impact",got feedback dev help unsure especially term maybe give try full could help u assert indeed related issue idea impact,issue,positive,positive,positive,positive,positive,positive
663435519,"I have thought about creating a new instance as well. I think it is the right thing to do at least in some cases like path ""AB_CD"" vs path ""A__BD"" will give two different global transcriptions ""ABCD"" and ""ABD"" where the two versions of the decoded ""B"" really have different timesteps. But it might not be easy to detect.

There is at least, one case where the update is always good, when comparing two paths with the same length and the same transcription. For example, ""ABB"" vs ""A_B"", the timestep of ""B"" should be from the most probable path.",thought new instance well think right thing least like path path give two different global two really different might easy detect least one case update always good two length transcription example abb probable path,issue,positive,positive,positive,positive,positive,positive
663217237,"Thanks for the analysis, I understand better what you are seeing now.

In the mean time I also remembered an additional reason why I removed the timestep update. It was because it makes it much harder to understand the behavior of the decoder. It modifies the PathTrie in-place, and because PathTrie nodes are shared between different beams, changing the timestep and probability of a node also changes every single beam that includes it. This makes it much harder to understand the implications of the heuristic on the global output due to compounding side effects.

The old code ""fixed"" this problem in a crude way, by only updating leaf nodes, but that is just a band-aid. The proper implementation would require handling the whole subtree in a way that doesn't break the outputs. I tried a few quick approaches but they were either impractical due to performance or didn't work.

One idea I never tried because it was too much work, was either using an immutable (copy on write) prefix tree data structure or just creating a new PathTrie instance and splicing it into the beam when applying that heuristic. The idea is that it would then keep the timestep updates from breaking unrelated beams that shared that node at the old timestep and must not be changed. Or maybe not, I haven't tried it ;)",thanks analysis understand better seeing mean time also additional reason removed update much harder understand behavior different probability node also every single beam much harder understand heuristic global output due compounding side effect old code fixed problem crude way leaf proper implementation would require handling whole way break tried quick either impractical due performance work one idea never tried much work either immutable copy write prefix tree data structure new instance splicing beam heuristic idea would keep breaking unrelated node old must maybe tried,issue,negative,positive,neutral,neutral,positive,positive
663193484,"I am closing this issue for now. If I gather enough evidence of improvement, I will submit a PR.
Thank you for your explanations.
",issue gather enough evidence improvement submit thank,issue,positive,neutral,neutral,neutral,neutral,neutral
663185102,"I understand better now. The issue is more subtle than I thought.

I have used a slightly different method (comparing probabilities of the complete path, instead of just the last bit), which provides much better accuracy in my case. 
However, I have just realized that this method is not flawless either, so it is also a heuristic.

Here is a small example. In my case, the argmax of the logits gives the following (it is french) :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_   ss'enn__ _r_é___j_uuii__rr__on_t____...
```
The decoded words are ""tous les amoureux de sport divers s'en réjouiront"".

My first order criterion is that the time range for a word should always fit the argmax output, at least when the confidence of the acoustic model is very high. Namely, ""tous"" should fit exactly ""tou_________________________________________________ss"", and ""amoureux"" should fit either ""_a__mouurreuux"" or "" a__mouurreuux"". But the range of ""divers"" is difficult to get right because it can leak onto the next word, so several possibilities are acceptable. 

With the current code, there is often an offset of about one letter between the expected range and the predicted range. In the above example, the predicted range for ""amoureux"" corresponds to ""' _a__mouurreuu'"". I consistenty get better matches by updating the timestep when the new path probability is better than the former.

I will come back on this with more data when I am back from vacation (in 3 weeks). I first thought that it was a small issue with an easy fix, but it is not so simple.",understand better issue subtle thought used slightly different method complete path instead last bit much better accuracy case however method flawless either also heuristic small example case following de de sport diver first order criterion time range word always fit output least confidence acoustic model high namely fit exactly fit either range diver difficult get right leak onto next word several acceptable current code often offset one letter range range example range get better new path probability better former come back data back vacation first thought small issue easy fix simple,issue,positive,positive,positive,positive,positive,positive
663155328,"> Actually, it seems to me that the removal of the timestep update might have been accidental.
> Maybe only removing the probability update was intended ?

I removed the timestep update because I didn't want to ""stack heuristics"", and I thought the timestep update and the late beam expansion logic (which is currently in the tree) would achieve the same result. I assume you have seen evidence to the contrary, hence this issue.

If adding the timestep update improves the bad timings you're seeing, then maybe it is the right thing to do. Can you share some audio files with timing results before and after the change to exemplify what is going on?",actually removal update might accidental maybe removing probability update intended removed update want stack thought update late beam expansion logic currently tree would achieve result assume seen evidence contrary hence issue update bad seeing maybe right thing share audio timing change exemplify going,issue,negative,negative,negative,negative,negative,negative
663154193,"Thanks, I removed the surrounding discussion as well.",thanks removed surrounding discussion well,issue,positive,positive,positive,positive,positive,positive
663153934,I have edited my first message to remove the failed funny part.,first message remove funny part,issue,negative,positive,positive,positive,positive,positive
663152985,"Actually, it seems to me that the removal of the timestep update might have been accidental.
Maybe only removing the probability update was intended ?",actually removal update might accidental maybe removing probability update intended,issue,negative,neutral,neutral,neutral,neutral,neutral
663144959,"> But since commit 33760a6, the following code was removed

The surrounding discussion is here: https://github.com/mozilla/DeepSpeech/issues/2867#issuecomment-612595999

If you can submit a PR that does not regress that behavior and improves timings, it is more than welcome. I will however repeat what I said in other timing issues, which is that if you want to significantly rework the timing logic, then you need to also present hard data to show what you're talking about. ""is almost always too early"" is not enough. Provide affected samples, compare before and after, contribute some regression tests for the timing logic.",since commit following code removed surrounding discussion submit regress behavior welcome however repeat said timing want significantly rework timing logic need also present hard data show talking almost always early enough provide affected compare contribute regression timing logic,issue,positive,positive,positive,positive,positive,positive
663045011,"I have fixed the training code path that could hit this problem, but the `abort` is still there. We're happy to review a PR converting the function to return an error code and take an outparam. All callers would also have to be adapted. Because this is a non-trivial work and it can only be reached by directly calling into the Scorer and decoder APIs outside of our training interface, we're gonna put it on the backlog for now.",fixed training code path could hit problem abort still happy review converting function return error code take would also work directly calling scorer outside training interface gon na put backlog,issue,negative,positive,positive,positive,positive,positive
662955045,"By the way, the time before getting answered on this project is amazingly short. It is pretty cool !",way time getting project amazingly short pretty cool,issue,positive,positive,positive,positive,positive,positive
662953735,"I was not using the Alphabet API myself. My issue was that I initialized my Scorer improperly before calling `ctc_beam_search_decoder()`. Maybe, the code there is also not using the Alphabet API correctly ?",alphabet issue scorer improperly calling maybe code also alphabet correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
662950171,I was missing the fact that our own training code is not using these APIs correctly. Pushed another commit fixing that as well.,missing fact training code correctly another commit fixing well,issue,negative,negative,negative,negative,negative,negative
662944459,"#3176 - basically, use the CanEncode and CanEncodeSingle methods to test for presence of a character in the alphabet.",basically use test presence character alphabet,issue,negative,neutral,neutral,neutral,neutral,neutral
662943632,"The behavior is documented, although not in the Python bindings. I'll make a PR to expose the docs there as well.",behavior although python make expose well,issue,negative,neutral,neutral,neutral,neutral,neutral
662534333,Great and thanks again for all your effort so far !,great thanks effort far,issue,positive,positive,positive,positive,positive,positive
662515081,"> I think it all of this should be enough to issue a bug and directly ping the committer from the bisected commit and the TF var_length_sequence stuff. As they also can double check the CUDNN code and have more insight in all the (data) requirements.
> 
> Ah I see you just did that, apart from mentioning the Nvidia committer (could be worthwhile to get some attention from the relevant people faster).

Indeed, I was preparing extra info and pinged this person as well. Let's hope they can quickly assert on their side and come back to us.",think enough issue bug directly ping committer commit stuff also double check code insight data ah see apart committer could get attention relevant people faster indeed extra person well let hope quickly assert side come back u,issue,positive,positive,positive,positive,positive,positive
662514376,"> I have tried to replace the `abort()` call by returning something, but I then get a segfault.

Well, I suspect because of your alphabet issue, since it's playing with array index and you have error with label 0, it would not be surprising that it segfault if you remove the `abort()`",tried replace abort call something get well suspect alphabet issue since array index error label would surprising remove abort,issue,negative,positive,positive,positive,positive,positive
662513518,"I have tried to replace the `abort()` call by returning something, but I then get a segfault.
I will let you know if I find something.",tried replace abort call something get let know find something,issue,negative,neutral,neutral,neutral,neutral,neutral
662513402,"Limiting should be no problem to implement with the new data-set approach. 

A bigger and most probably insufficient change would be required for true skipping, as the trivial approach of ""reading all samples until reaching skip offset"" would not help on ""running experiments quickly"". Background: The current data-set approach interleaves all data-sets passed on the command line on the fly while reading them from start to end during training. Skipping forward would require reading all indices and sample sizes up front, sorting them, interleaving them and then skipping to the required position.

A common problem that we once solved by skipping was determining the maximum batch-size on a GPU. This could also be done by reversing all data-sets and the interleaving-code (training longest samples first). This turns out to be cheap to implement.

So I consider implementing (fixing) limiting, dropping skip support altogether and adding `--reverse_train`, `--reverse_dev`, `--reverse_test` flags to be able to test for batch sizes.",limiting problem implement new approach bigger probably insufficient change would true skipping trivial approach reading reaching skip offset would help running quickly background current approach command line fly reading start end training skipping forward would require reading index sample size front skipping position common problem skipping maximum could also done reversing training first turn cheap implement consider fixing limiting dropping skip support altogether able test batch size,issue,positive,positive,positive,positive,positive,positive
662500279,"Not sure though if we can properly fix that very quickly, it'd need better / proper error handling from C++ to Python CTC decoder?",sure though properly fix quickly need better proper error handling python,issue,negative,positive,positive,positive,positive,positive
662499851,"> I don't know your guidelines. But I can tell that aborting the whole process, including the python interpreter which might be interactive, is a terrible way of handling errors, especially in such a trivial function, and I call it a bug.

it sounds like we broke badly some of your workflow, sorry about that.

I think that this `abort()` comes back from a long time and is here to avoid people getting into other bad situation because of invalid alphabets, and recent refactoring of Alphabet code made that exposed to Python when it was not the case in the past.",know tell whole process python interpreter might interactive terrible way handling especially trivial function call bug like broke badly sorry think abort come back long time avoid people getting bad situation invalid recent alphabet code made exposed python case past,issue,negative,negative,negative,negative,negative,negative
662488172,"I think it all of this should be enough to issue a bug and directly ping the committer from the bisected commit and the TF var_length_sequence stuff. As they also can double check the CUDNN code and have more insight in all the (data) requirements.

Ah I see you just did that, apart from mentioning the Nvidia committer (could be worthwhile to get some attention from the relevant people faster).",think enough issue bug directly ping committer commit stuff also double check code insight data ah see apart committer could get attention relevant people faster,issue,negative,positive,positive,positive,positive,positive
662482106,"@applied-machinelearning I don't know what you think, but this defies all the assumptions I can make based on cudnn api doc and what we observe. There's something that is missing to justify the trigger of the issue, and so far, hacking the ordering does not seems to really be the real trigger here, but I can't figure it out, and with just ""CUDNN_STATUS_EXECUTION_FAILED"" as a feedback and no really usable debug information because of the closedness of CUDA, I don't see how we can investigate more without wasting our time on that.",know think make based doc observe something missing justify trigger issue far hacking really real trigger ca figure feedback really usable information see investigate without wasting time,issue,negative,positive,neutral,neutral,positive,positive
662470881,"Reversing the order, and still explodes:
```
I STARTING Optimization                                                                                                                                                                                                                                                                                                                                                                                                  
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                2
020-07-22 15:59:45.113520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
generate_values <deepspeech_training.util.sample_collections.CSV object at 0x7f63846338d0>
yield generate_values 0 csvs/../data/C/175_5429_67ed7914b9a3bac4e46dd42a5721a95f-e31a33c85ca8249476596c1ff7fc2f67.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a14d0>
yield generate_values 1 csvs/../data/C/169_5271_3210ac3e97626f9c1515cb019e5fa36e-dd839274af12610f137398ddd01f85f8.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a15d0>
yield generate_values 2 csvs/../data/B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a1150>
yield generate_values 3 csvs/../data/B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a1550>
yield generate_values 4 csvs/../data/A/163_5029_3498779ce37873475394654801cc3888-8fddd9522baf442463171802a7e57489.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a1750>
batch_fn <_VariantDataset shapes: <unknown>, types: tf.string> 2 <_VariantDataset shapes: (?, 26), types: tf.float32> <_VariantDataset shapes: (), types: tf.int32>
batch_fn <_VariantDataset shapes: <unknown>, types: tf.string> 2 <_VariantDataset shapes: (?, 26), types: tf.float32> <_VariantDataset shapes: (), types: tf.int32>
yield generate_values 5 csvs/../data/A/155_4757_9bc6d6f754547a09bbcf70e42d8e2a27-b112945da6818223ab8e1daf80313a62.wav <deepspeech_training.util.sample_collections.LabeledSample object at 0x7f67465a1190>
CudnnRNNForwardOp       
ShouldUsePaddedIO time_major=1                                                                    
ShouldUsePaddedIO seq_array[0]=75
ShouldUsePaddedIO seq_array[1]=75                                                                  
ShouldUsePaddedIO [0]: seq_array[i]=75                                                       
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO [1]: seq_array[i]=75                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=false all_max_seq_length=true                                           
CudnnRNNBackwardOp                                                                                                                                                                                          
ShouldUsePaddedIO time_major=1                                                 
ShouldUsePaddedIO seq_array[0]=75                                                                                                                                                                           
ShouldUsePaddedIO seq_array[1]=75
ShouldUsePaddedIO [0]: seq_array[i]=75                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75             
ShouldUsePaddedIO [1]: seq_array[i]=75                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=75
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 1 | Loss: 189.891312                                                                                                                                                                                                                                                                                                                                              b
atch_fn <_VariantDataset shapes: <unknown>, types: tf.string> 2 <_VariantDataset shapes: (?, 26), types: tf.float32> <_VariantDataset shapes: (), types: tf.int32>                    
CudnnRNNForwardOp                                     
ShouldUsePaddedIO time_major=1                                                                                                                                                                              
ShouldUsePaddedIO seq_array[0]=75
ShouldUsePaddedIO seq_array[1]=74                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=75
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO [1]: seq_array[i]=74
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=true all_max_seq_length=false                           
2020-07-22 15:59:48.820700: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED                                                                                                          
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-07-22 15:59:48.820756: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cudnn_rnn_ops.cc:1527 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 75, 2, 2048] 
",reversing order still starting optimization epoch training time loss successfully dynamic library object yield object yield object yield object yield object yield object unknown unknown yield object epoch training time loss unknown opaque opaque opaque internal call model,issue,positive,negative,neutral,neutral,negative,negative
662443933,"> > Hm, it's not that clear. Here is a log after reversing the ordering when we read CSV file. As you can see, 75 is now first one and yet it fails.=:
> 
> Are you sure ?
> The mini-batch sequence array still seems [74, 75] and not [75, 74] ?

Are you referring to those lines?
> ShouldUsePaddedIO seq_array[0]=74
> ShouldUsePaddedIO seq_array[1]=75
",clear log reversing read file see first one yet sure sequence array still,issue,positive,positive,positive,positive,positive,positive
662440235,"Hm, it's not that clear. Here is a log after reversing the ordering when we read CSV file. As you can see, 75 is now first one and yet it fails.=:
```
I STARTING Optimization                                                                                                                                                                                                                                                                                                                                                                                                  
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                2
020-07-22 15:01:00.634318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0                                                                                                                                                                                                                                                                         
[('csvs/../data/A/163_5029_3498779ce37873475394654801cc3888-8fddd9522baf442463171802a7e57489.wav', 48366, 'en zijn huisje verlaten was'), ('csvs/../data/A/155_4757_9bc6d6f754547a09bbcf70e42d8e2a27-b112945da6818223ab8e1daf80313a62.wav', 48366, 'dat vertrokken mondje hij'), ('csvs/../data/B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav', 48368, 'was zo woest dat'), ('csvs/../d
ata/B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav', 48520, 'hij gaf geen antwoord'), ('csvs/../data/C/175_5429_67ed7914b9a3bac4e46dd42a5721a95f-e31a33c85ca8249476596c1ff7fc2f67.wav', 48524, 'en in de tien minuten die de lift'), ('csvs/../data/C/169_5271_3210ac3e97626f9c1515cb019e5fa36e-dd839274af12610f137398ddd01f85f8.wav', 48524, 'informeerde hij of die')]               
CudnnRNNForwardOp                                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
CudnnRNNBackwardOp                                                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
CudnnRNNForwardOp                                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=75                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
CudnnRNNBackwardOp                                                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=75                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 1 | Loss: 190.842316                                                                                                                                                                                                                                                                                                                                               
--------------------------------------------------------------------------------                                                                                                                                                                                                                                                                                                                                         
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                [
('csvs/../data/A/163_5029_3498779ce37873475394654801cc3888-8fddd9522baf442463171802a7e57489.wav', 48366, 'en zijn huisje verlaten was'), ('csvs/../data/A/155_4757_9bc6d6f754547a09bbcf70e42d8e2a27-b112945da6818223ab8e1daf80313a62.wav', 48366, 'dat vertrokken mondje hij'), ('csvs/../data/B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav', 48368, 'was zo woest dat'), ('csvs/../da
ta/B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav', 48520, 'hij gaf geen antwoord'), ('csvs/../data/C/175_5429_67ed7914b9a3bac4e46dd42a5721a95f-e31a33c85ca8249476596c1ff7fc2f67.wav', 48524, 'en in de tien minuten die de lift'), ('csvs/../data/C/169_5271_3210ac3e97626f9c1515cb019e5fa36e-dd839274af12610f137398ddd01f85f8.wav', 48524, 'informeerde hij of die')]                
CudnnRNNForwardOp                                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=75                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
2020-07-22 15:01:09.398352: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED                                                                                                                                                                                                                                                                                                                       
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'                                                                                                                                                                                                                       
2020-07-22 15:01:09.398438: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cudnn_rnn_ops.cc:1527 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 75, 2, 2048]                                                
CudnnRNNForwardOp                                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
",clear log reversing read file see first one yet starting optimization epoch training time loss successfully dynamic library zo de tien die de lift die epoch training time loss epoch training time loss zo de tien die de lift die opaque opaque opaque internal call model,issue,negative,positive,neutral,neutral,positive,positive
662432872,"There is some:
```
I STARTING Optimization                                                                            
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                2
020-07-22 13:18:12.007877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
[('csvs/../data/A/163_5029_3498779ce37873475394654801cc3888-8fddd9522baf442463171802a7e57489.wav', 48366, 'en zijn huisje verlaten was'), ('csvs/../data/A/155_4757_9bc6d6f754547a09bbcf70e42d8e2a27-b112945da6818223ab8e1daf80313a62.wav', 48366, 'dat vertrokken mondje hij'), ('csvs/../data/B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav', 48368, 'was zo woest dat'), ('csvs/../d
ata/B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav', 48520, 'hij gaf geen antwoord'), ('csvs/../data/C/175_5429_67ed7914b9a3bac4e46dd42a5721a95f-e31a33c85ca8249476596c1ff7fc2f67.wav', 48524, 'en in de tien minuten die de lift'), ('csvs/../data/C/169_5271_3210ac3e97626f9c1515cb019e5fa36e-dd839274af12610f137398ddd01f85f8.wav', 48524, 'informeerde hij of die')]
CudnnRNNForwardOp    
ShouldUsePaddedIO time_major=1                                                                                                                                                                              
ShouldUsePaddedIO seq_array[0]=74           
ShouldUsePaddedIO seq_array[1]=75                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=true all_max_seq_length=false
CudnnRNNBackwardOp                                                           
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                                                                                                                                                                                                                                        
ShouldUsePaddedIO seq_array[1]=75
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false
CudnnRNNForwardOp        
ShouldUsePaddedIO time_major=1
ShouldUsePaddedIO seq_array[0]=74                          
ShouldUsePaddedIO seq_array[1]=74              
ShouldUsePaddedIO [0]: seq_array[i]=74
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO [1]: seq_array[i]=74
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO rv=false all_max_seq_length=true
CudnnRNNBackwardOp                                                                                                                                                                                          
ShouldUsePaddedIO time_major=1
ShouldUsePaddedIO seq_array[0]=74                                                                 
ShouldUsePaddedIO seq_array[1]=74
ShouldUsePaddedIO [0]: seq_array[i]=74                                                             
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                        
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 1 | Loss: 189.949219                                                                                                                                                                                                                                                                                                                                               
--------------------------------------------------------------------------------                                                                                                                            
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                [
('csvs/../data/A/163_5029_3498779ce37873475394654801cc3888-8fddd9522baf442463171802a7e57489.wav', 48366, 'en zijn huisje verlaten was'), ('csvs/../data/A/155_4757_9bc6d6f754547a09bbcf70e42d8e2a27-b112945da6818223ab8e1daf80313a62.wav', 48366, 'dat vertrokken mondje hij'), ('csvs/../data/B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav', 48368, 'was zo woest dat'), ('csvs/../da
ta/B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav', 48520, 'hij gaf geen antwoord'), ('csvs/../data/C/175_5429_67ed7914b9a3bac4e46dd42a5721a95f-e31a33c85ca8249476596c1ff7fc2f67.wav', 48524, 'en in de tien minuten die de lift'), ('csvs/../data/C/169_5271_3210ac3e97626f9c1515cb019e5fa36e-dd839274af12610f137398ddd01f85f8.wav', 48524, 'informeerde hij of die')]
CudnnRNNForwardOp                                                                                                                                                                                           
ShouldUsePaddedIO time_major=1                                    
ShouldUsePaddedIO seq_array[0]=74                                                                                                                                                                           
ShouldUsePaddedIO seq_array[1]=74                  
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74 
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
CudnnRNNForwardOp            
ShouldUsePaddedIO time_major=1                                                                                                                                                                              
ShouldUsePaddedIO seq_array[0]=74
ShouldUsePaddedIO seq_array[1]=75                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=true all_max_seq_length=false                           
2020-07-22 13:18:20.837671: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED                                                                                                          
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
",starting optimization epoch training time loss successfully dynamic library zo de tien die de lift die epoch training time loss epoch training time loss zo de tien die de lift die opaque opaque opaque,issue,negative,neutral,neutral,neutral,neutral,neutral
662374051,"> Could it be handy to not short circuit the loop in the ShouldUsePaddedIO() and let it print out the whole lot of sequence sizes and their order in that mini-batch, before returning to get it completely clear (or print out the whole seq_array at the start) ?

Those latest logs where not produced by forcing any return value to `ShouldUsePaddedIO`",could handy short circuit loop let print whole lot sequence size order get completely clear print whole start latest produced forcing return value,issue,positive,positive,positive,positive,positive,positive
662372290,"Could it be handy to not short circuit the loop in the ShouldUsePaddedIO() and let it print out the whole lot of sequence sizes and their order in that mini-batch, before returning to get it completely clear (or print out the whole seq_array at the start) ?

And it doesn't seem to need it completely sorted in the minibatch either (if you look at the non-repro case [75, 74, 74, 75, 74, 74] seems to work as well. So it looks like at least the first max_sequence_length should be the or one of the largest for the mini-batch ?",could handy short circuit loop let print whole lot sequence size order get completely clear print whole start seem need completely sorted either look case work well like least first one,issue,positive,positive,positive,positive,positive,positive
662369512,"> @vasudev-hv So, have you had any luck on that matter?

Unfortunately no. Due to constraints on windows hardware(gpu and mem), we had to move to linux.",luck matter unfortunately due hardware mem move,issue,negative,negative,negative,negative,negative,negative
662359359,Those two logs seems to fit your analysis @applied-machinelearning: it crashes when the `max_seq_length=75` is not the first value we push.,two fit analysis first value push,issue,positive,positive,positive,positive,positive,positive
662350568,"Captured also the debug I added on a **non repro** case:
```
I STARTING Optimization                                                                                                                                                                                                                                                                                                                                                                                                  
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                2
020-07-22 11:30:10.205219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0                                                                                                                                                                                                                                                                         
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
Epoch 0 |   Training | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 189.949173                                                                                                                                                                                                                                                                                                                                               
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                S
houldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                            
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                     
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 107.969971                                                                                                                                                                                                                                                                                                                                               
Epoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                S
houldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                            
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                              
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                                                                                                                                                                                                                                       
ShouldUsePaddedIO time_major=1                                                                                                                                                                                                                                                                                                                                                                                           
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                                                                                                                                                                                                                                   
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                                                                                                                                                                                                                                    
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                                                                                                                                                                                                                                       
Epoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 73.916595                                                                                                                                                                                                                                                                                                                                                
I FINISHED optimization in 0:00:03.484708                                                                                                                                                                   
D Session closed.                                                                                                                                                                                           
",also added non case starting optimization epoch training time loss successfully dynamic library epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss finished optimization session closed,issue,negative,negative,neutral,neutral,negative,negative
662340192,"```
I STARTING Optimization                        
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                2
020-07-22 11:09:21.092508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
ShouldUsePaddedIO time_major=1
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                                                                                                                          
ShouldUsePaddedIO time_major=1
ShouldUsePaddedIO [0]: seq_array[i]=74                                                            
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75
ShouldUsePaddedIO rv=true all_max_seq_length=false                                                 
ShouldUsePaddedIO time_major=1                                                               
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                        
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
ShouldUsePaddedIO time_major=1                                                 
ShouldUsePaddedIO [0]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74
ShouldUsePaddedIO [1]: seq_array[i]=74                                                                                                                                                                      
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74             
ShouldUsePaddedIO rv=false all_max_seq_length=true                                                                                                                                                          
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 1 | Loss: 189.949219                                                                                                                                                                                                                                                                                                                                               
--------------------------------------------------------------------------------                                                                                                                            
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                S
houldUsePaddedIO time_major=1                                                                                                                                                                               
ShouldUsePaddedIO [0]: seq_array[i]=74                
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO [1]: seq_array[i]=74
ShouldUsePaddedIO [1]: model_shapes.max_seq_length=74                                                                                                                                                       
ShouldUsePaddedIO rv=false all_max_seq_length=true
ShouldUsePaddedIO time_major=1                                                                                                                                                                              
ShouldUsePaddedIO [0]: seq_array[i]=74
ShouldUsePaddedIO [0]: model_shapes.max_seq_length=75                                                                                                                                                       
ShouldUsePaddedIO rv=true all_max_seq_length=false                           
2020-07-22 11:09:30.528222: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED                                                                                                          
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-07-22 11:09:30.528291: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cudnn_rnn_ops.cc:1522 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 75, 2, 2048] 
",starting optimization epoch training time loss successfully dynamic library epoch training time loss epoch training time loss opaque opaque opaque internal call model,issue,negative,neutral,neutral,neutral,neutral,neutral
662332109,"> Not what I would have expected, but forcing **true** for `use_padded_io` does indeed ... work? I have four retries are that working. It's ... weird.

Or it's consistent: our data is requiring padding to be padded.",would forcing true indeed work four working weird consistent data padding,issue,negative,positive,neutral,neutral,positive,positive
662330775,"Not what I would have expected, but forcing **true** for `use_padded_io` does indeed ... work? I have four retries are that working. It's ... weird.",would forcing true indeed work four working weird,issue,negative,negative,neutral,neutral,negative,negative
662316064,"> Which functions did your test blowup with when ""forcing ShouldUsePaddedIO to return false"", cudnnRNNForwardTrainingEx() of cudnnRNNForwardTraining(), so the extended or the not extended version ?

It looks like very much the same:
```
2020-07-22 10:20:21.132203: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED                                                                                                          
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-07-22 10:20:21.132242: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 75, 2, 2048] 
```

This is with forcing this way:
```
diff --git a/tensorflow/core/kernels/cudnn_rnn_ops.cc b/tensorflow/core/kernels/cudnn_rnn_ops.cc
index 4a27394f28..c3aa386ea7 100644
--- a/tensorflow/core/kernels/cudnn_rnn_ops.cc
+++ b/tensorflow/core/kernels/cudnn_rnn_ops.cc
@@ -1463,8 +1463,8 @@ class CudnnRNNForwardOp<GPUDevice, T> : public CudnnRNNKernelCommon {
                                   context, model_types(), time_major, &input,
                                   &input_h, &input_c, &params,
                                   &sequence_lengths, num_proj, &model_shapes));
-      use_padded_io =
-          ShouldUsePaddedIO(sequence_lengths, model_shapes, time_major);
+      use_padded_io = false;
+          // ShouldUsePaddedIO(sequence_lengths, model_shapes, time_major);
     } else {
       OP_REQUIRES_OK(context,
                      ExtractForwardInput(context, model_types(), time_major,
@@ -1863,8 +1863,8 @@ class CudnnRNNBackwardOp<GPUDevice, T> : public CudnnRNNKernelCommon {
                                   context, model_types(), time_major, &input,
                                   &input_h, &input_c, &params,
                                   &sequence_lengths, num_proj, &model_shapes));
-      use_padded_io =
-          ShouldUsePaddedIO(sequence_lengths, model_shapes, time_major);
+      use_padded_io = false;
+          // ShouldUsePaddedIO(sequence_lengths, model_shapes, time_major);
     } else {
       OP_REQUIRES_OK(context,
                      ExtractForwardInput(context, model_types(), time_major,
```",test blowup forcing return false extended extended version like much opaque opaque opaque internal call model forcing way git index class public context input false else context context class public context input false else context context,issue,negative,negative,negative,negative,negative,negative
662279657,"> I have a voice note to be converted into text. Please can you help?

Please use Discourse for support.",voice note converted text please help please use discourse support,issue,positive,neutral,neutral,neutral,neutral,neutral
662138417,"Interestingly enough from the pull request it seems they also had intermittent test failures, but it seems they were not addressed.

With a stock TF 1.15 the error message indicates we are running cudnnRNNForwardTrainingEx() when it breaks.
The cudnn docs indicate it is version of the function for padded data:
https://docs.nvidia.com/deeplearning/sdk/cudnn-archived/cudnn_765/cudnn-api/index.html#cudnnRNNForwardTrainingEx

We don't get CUDNN_STATUS_BAD_PARAM back, so it seems to accept the parameters listed there and not blow up immediatly in those. We get CUDNN_STATUS_EXECUTION_FAILED.

It also lists some conditions for the data layout:
> This routine is the extended version of the cudnnRNNForwardTraining() function. The cudnnRNNForwardTrainingEx() allows the user to use unpacked (padded) layout for input x and output y.

> In the unpacked layout, each sequence in the mini-batch is considered to be of fixed length, specified by maxSeqLength in its corresponding RNNDataDescriptor. Each fixed-length sequence, for example, the nth sequence in the mini-batch, is composed of a valid segment specified by the seqLengthArray[n] in its corresponding RNNDataDescriptor; and a padding segment to make the combined sequence length equal to maxSeqLength.

And also for the order within the mini-batch in a special case:
> With the unpacked layout, both sequence major (meaning, time major) and batch major are supported. For backward compatibility, the packed sequence major layout is supported. However, similar to the non-extended function cudnnRNNForwardTraining(), the sequences in the mini-batch need to be sorted in descending order according to length. 

My interpretation of the last piece would be:
You can stuff packed/unpadded sequences into cudnnRNNForwardTrainingEx() although it is meant for unpacked/padded, on the premises that the sequences are sorted in descending order according to length.

Which functions did your test blowup with when ""forcing ShouldUsePaddedIO to return false"", cudnnRNNForwardTrainingEx() of cudnnRNNForwardTraining(), so the extended or the not extended version ?

Unfortunately it's quite a pain to get stuff printed at some interesting places ... the log output of docker images you made issue3088_7.6.5.3 etc.,  do output a lot of extra internal data, but I find it hard to interpret.",interestingly enough pull request also intermittent test stock error message running indicate version function data get back accept listed blow get also data layout routine extended version function user use unpacked layout input output unpacked layout sequence considered fixed length corresponding sequence example nth sequence composed valid segment corresponding padding segment make combined sequence length equal also order within special case unpacked layout sequence major meaning time major batch major backward compatibility sequence major layout however similar function need sorted descending order according length interpretation last piece would stuff although meant sorted descending order according length test blowup forcing return false extended extended version unfortunately quite pain get stuff printed interesting log output docker made output lot extra internal data find hard interpret,issue,negative,positive,neutral,neutral,positive,positive
662123738,"@erksch I'm running on an iPhone Xs which is also 4GB of RAM, so that's weird.

Microphone streaming would be amazing to have! Can you open a PR?",running also ram weird microphone streaming would amazing open,issue,negative,positive,neutral,neutral,positive,positive
662098081,"@reuben Btw, today I implemented microphone streaming on iOS with resampling to 16000Hz. I tested it with a different speech recognition but I think the code would transfer 100% to DeepSpeech. Do you think we could add this to the demo code?",today microphone streaming tested different speech recognition think code would transfer think could add code,issue,negative,neutral,neutral,neutral,neutral,neutral
662096516,"@reuben Hey just tried again from the current master, still the same. I am testing on brand new iPad Air with I think at least 4 GB RAM.",hey tried current master still testing brand new air think least ram,issue,negative,negative,neutral,neutral,negative,negative
662083718,"Another weird behavior:
 - r1.15 with https://github.com/tensorflow/tensorflow/commit/24297a4cb9120351643f7ac3916e7398236ccc0d but forcing `ShouldUsePaddedIO`  to return false breaks the training
 - r1.15 without https://github.com/tensorflow/tensorflow/commit/24297a4cb9120351643f7ac3916e7398236ccc0d just works

So maybe it needs more digging into that patch itself.",another weird behavior forcing return false training without work maybe need digging patch,issue,negative,negative,negative,negative,negative,negative
662072849,"looks like it's not something we have leverage on from python code, i'll run a few checks to see if there anything obvious and if not, then we'll follow up with tensorflow issue",like something leverage python code run see anything obvious follow issue,issue,negative,neutral,neutral,neutral,neutral,neutral
662049532,"> > [revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt](https://github.com/mozilla/DeepSpeech/files/4955557/revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt)
> > @applied-machinelearning revert of this is a bit non trivial, here is the diff to it, if you are willing to rebuild tensorflow gpu completely (might take some hours depending on your hw)
> 
> Do you have a docker build file for that laying around or did you do it on baremetal ?

I did it baremetal, ill continue tomorrow to see if we can act from python side instead of rebuilding ",revert bit non trivial willing rebuild completely might take depending docker build file laying around ill continue tomorrow see act python side instead,issue,negative,negative,neutral,neutral,negative,negative
662047863,"> [revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt](https://github.com/mozilla/DeepSpeech/files/4955557/revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt)
> 
> @applied-machinelearning revert of this is a bit non trivial, here is the diff to it, if you are willing to rebuild tensorflow gpu completely (might take some hours depending on your hw)

Do you have a docker build file for that laying around or did you do it on baremetal ?",revert bit non trivial willing rebuild completely might take depending docker build file laying around,issue,negative,positive,positive,positive,positive,positive
662041642,"[revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt](https://github.com/mozilla/DeepSpeech/files/4955557/revert-24297a4cb9120351643f7ac3916e7398236ccc0d.patch.txt)

@applied-machinelearning revert of this is a bit non trivial, here is the diff to it, if you are willing to rebuild tensorflow gpu completely (might take some hours depending on your hw)",revert bit non trivial willing rebuild completely might take depending,issue,negative,positive,positive,positive,positive,positive
662038396,"Hi Sorry,
I didn't get time to work on this. I will post my results soon!

Thanks

On Tue, Jul 21, 2020 at 8:13 PM lissyx <notifications@github.com> wrote:

> Please @SanghviChirag <https://github.com/SanghviChirag>, can you share
> the actionable items requested ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3167#issuecomment-661903877>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACWXMCHFJOLADZ6X52ADFTDR4WSPLANCNFSM4O643JVQ>
> .
>


-- 
Regards,
Chirag Sanghvi
",hi sorry get time work post soon thanks tue wrote please share actionable reply directly view,issue,positive,negative,neutral,neutral,negative,negative
662012420,"> Re-doing bisect yields:
> 
> ```
> 24297a4cb9120351643f7ac3916e7398236ccc0d is the first bad commit
> commit 24297a4cb9120351643f7ac3916e7398236ccc0d
> Author: Kaixi Hou <kaixih@nvidia.com>
> Date:   Fri Jul 19 13:41:25 2019 -0700
> 
>     use padded IO for cudnn rnn only when necessary
> 
>  tensorflow/core/kernels/cudnn_rnn_ops.cc           | 42 +++++++++++++++++-----
>  tensorflow/stream_executor/cuda/cuda_dnn.cc        | 13 ++++---
>  tensorflow/stream_executor/cuda/cuda_dnn.h         |  3 +-
>  tensorflow/stream_executor/dnn.h                   |  4 ++-
>  .../stream_executor/stream_executor_pimpl.cc       |  5 +--
>  tensorflow/stream_executor/stream_executor_pimpl.h |  3 +-
>  6 files changed, 52 insertions(+), 18 deletions(-)
> ```
> 
> I'll see how much that holds.

5 runs of a r1.15 build without this patch works like a charm on the repro case. I'm running 20 more, but if that holds, it means we actually have something much more actionable now.",bisect first bad commit commit author date use io necessary see much build without patch work like charm case running actually something much actionable,issue,negative,negative,neutral,neutral,negative,negative
662002736,"> @lissyx Does scorer packaging still work?

In the dockerfile? it's possible we don't take care of that yet",scorer still work possible take care yet,issue,negative,neutral,neutral,neutral,neutral,neutral
661998806,"I like this, always had to search it myself in the logs...
But I found out today that you also can run `cat your_logfile | grep -B1 Saved` to show the line before the selected line too.",like always search found today also run cat saved show line selected line,issue,positive,neutral,neutral,neutral,neutral,neutral
661996220,"> So if it's green we can merge this one?

Yes, already got the uwp console project working with a file link to reuse the .Net Framework console, the surprise was we can't run uwp .exe apps from command line out of the box :D, still on it.",green merge one yes already got console project working file link reuse framework console surprise ca run command line box still,issue,positive,negative,negative,negative,negative,negative
661996154,"@lissyx Does scorer packaging still work? I've seen that the py file was replaced by another script with extra installation steps, but didn't test it yet.",scorer still work seen file another script extra installation test yet,issue,negative,neutral,neutral,neutral,neutral,neutral
661993067,"Re-doing bisect yields:

```
24297a4cb9120351643f7ac3916e7398236ccc0d is the first bad commit
commit 24297a4cb9120351643f7ac3916e7398236ccc0d
Author: Kaixi Hou <kaixih@nvidia.com>
Date:   Fri Jul 19 13:41:25 2019 -0700

    use padded IO for cudnn rnn only when necessary

 tensorflow/core/kernels/cudnn_rnn_ops.cc           | 42 +++++++++++++++++-----
 tensorflow/stream_executor/cuda/cuda_dnn.cc        | 13 ++++---
 tensorflow/stream_executor/cuda/cuda_dnn.h         |  3 +-
 tensorflow/stream_executor/dnn.h                   |  4 ++-
 .../stream_executor/stream_executor_pimpl.cc       |  5 +--
 tensorflow/stream_executor/stream_executor_pimpl.h |  3 +-
 6 files changed, 52 insertions(+), 18 deletions(-)
```

https://github.com/tensorflow/tensorflow/commit/24297a4cb9120351643f7ac3916e7398236ccc0d
https://github.com/tensorflow/tensorflow/pull/30889

I'll see how much that holds.",bisect first bad commit commit author date use io necessary see much,issue,negative,negative,neutral,neutral,negative,negative
661983671,"> Hello @kdavis-mozilla, just rebased, I'll send test with a different PR.
> 
> @erksch Thanks.

So if it's green we can merge this one? Looking forward to it and the tests :D",hello send test different thanks green merge one looking forward,issue,negative,neutral,neutral,neutral,neutral,neutral
661982951,"Hello @kdavis-mozilla, just rebased, I'll send test with a different PR.

@erksch Thanks.",hello send test different thanks,issue,negative,positive,neutral,neutral,positive,positive
661903355,So @gokgozf can you elaborate explicitely on what is needed ? The only part of code you pasted is already there...,elaborate part code pasted already,issue,negative,positive,positive,positive,positive,positive
661859015,"> i train my model on DS 0.7

yes



>  DS Streaming Example 0.7, this should work

no, test against the c++ client using streaming feature, as I linked. that's code we support.",train model yes streaming example work test client streaming feature linked code support,issue,positive,neutral,neutral,neutral,neutral,neutral
661857488,"So, you mean to say i train my model on DS 0.7 and use DS Streaming Example 0.7, this should work ? Or i have to make certain changes in the streaming example ?",mean say train model use streaming example work make certain streaming example,issue,negative,negative,neutral,neutral,negative,negative
661844193,">  doesn't work with the same setup of Streaming API

No, you get poor results with an unsupported example that makes use of the Streaming API in an unsupported usecase on an old version

It would really be helpful if you also trained on 0.7 version, and you test the streaming api with our supported code: C++ client, https://github.com/mozilla/DeepSpeech/blob/v0.7.4/native_client/args.h#L58",work setup streaming get poor unsupported example use streaming unsupported old version would really helpful also trained version test streaming code client,issue,negative,negative,neutral,neutral,negative,negative
661841939,"Got it @lissyx, will use Discourse. My idea of putting here is, the pretrained model works well with Streaming API. Our model which is working well in normal inference and gives good output, doesn't work with the same setup of Streaming API, we just change the model location

This is confusing me..",got use discourse idea model work well streaming model working well normal inference good output work setup streaming change model location,issue,positive,positive,positive,positive,positive,positive
661839962,"> [](https://github.com/tensorflow/tensorflow/commit/9380a41290e8fb8b9ea85f614472deab56dbc481#diff-8e54a26c3d435aad346bfa12f4c6ec79)

Interesting. I'm re-doing bisect, with more runs on each test to ensure I avoid any intermittent behavior. Maybe with some luck, this will pop. (unfortunately your direct link just gives me PR, not the direct diff you expected, so I'm not sure what part of the PR you mean)

> 
> Another interesting DS change mingling with the batches could be:
> [6b1d677](https://github.com/mozilla/DeepSpeech/commit/6b1d6773de25aaf1c1c157f8c11ecdd727f00c6d)

Have you experimented before / after this commit ?

",interesting bisect test ensure avoid intermittent behavior maybe luck pop unfortunately direct link direct sure part mean another interesting change could experimented commit,issue,positive,positive,positive,positive,positive,positive
661823635,"> Convert normalized left and right wav into chunks (based on start_time, end_time written) using pydub.

Unclear what you do here. Do you convert to 8k mono or 8k stereo ? All those transformations might alter your model ...",convert left right based written unclear convert mono stereo might alter model,issue,negative,positive,positive,positive,positive,positive
661822790,"> git clone -b r0.6 https://github.com/mozilla/DeepSpeech-examples.git

Those examples are here to help demonstrate, we can't guarantee they work perfectly ...",git clone help demonstrate ca guarantee work perfectly,issue,positive,positive,positive,positive,positive,positive
661822189,"> Thanks @lissyx
> 
> Excuse me that I didn't put much of the details here. I am elaborating the steps here, it could happen there might be some issue with the examples and compatibility as well.
> 
> _How we created **our deepspeech model** and done inference, this is working fine for us._
> 
> Data:1500 hrs (8k audio files)
> 
>     1. The files are stereo format files, created separate channels using command
>        sox input.wav output.wav remix 1 (for left) and sox input.wav output.wav remix 2 (for right)
> 
>     2. Normalize the left and right audio for peak normalized, using :
> 
> 
> ffmpeg-normalize input_wav_chunk.wav --normalization-type peak --target-level -14 --output norm_wav_chunk.wav
> 
>     1. Convert normalized left and right wav into chunks (based on start_time, end_time written) using pydub.
> 
> 
> audio = AudioSegment.from([audio_cal.wav])
> audio_chunk = audio[ int((start_time-0.05)*1000) : int((end_time+0.05)*1000) ] where 0.05 sec(500 ms buffer) buffer is uesd for smooth audio cut
> chunk_size may vary between 1.5-15 sec.
> 
>     1. Create_CSV (Train,test,dev)
> 
>     2. Create LM using kenlm to make language model of around 300k lines.
> 
> 
> command:
> ../kenlm/build/bin/lmplz --text vocab.txt --arpa words.arpa --o 4 --discount_fallback --prune 0 0 1
> ../kenlm/build/bin/build_binary -a 255 -q 8 -v trie words.arpa lm.binary
> take a pull of 0.6.1 native client extract and then used:
> ./generate_trie alphabet.txt lm.binary trie
> 
>     1. Training Command
> 
> 
> python3 DeepSpeech.py
> --alphabet_config_path data/alphabet.txt
> --checkpoint_dir checkpoint_dir
> --train_files data/train.csv \
> --dev_files data/dev.csv
> --test_files data/test.csv
> --epochs 20
> --use_allow_growth True
> --use_cudnn_rnn True
> --report_count 10
> --show_progressbar true
> --train_batch_size 16
> --dev_batch_size 24
> --test_batch_size 32
> --learning_rate 0.0001
> --dropout_rate 0.20
> --n_hidden 2048
> --audio_sample_rate 8000
> --export_dir data/export_dir
> --lm data/lm/lm.binary
> --trie data/lm/trie
> --lm_alpha 0.75
> --lm_beta 1.85 \
> 
>     1. **Inference**: then used deepspeech binary for inference.
> 
> 
> ## _This is working fine_
> 
> _Using Deepspeech streaming example_
> 
> git clone -b r0.6 https://github.com/mozilla/DeepSpeech-examples.git
> 
>     1. cd mic_vad_streaming
>        source $HOME/tmp/deepspeech-venv-0.6.1
>        sudo apt install portaudio19-dev python3-dev
>        pip install -r requirements.txt
> 
> 
> Changes done in mic_vad_streaming.py
> 
> BEAM_WIDTH=1024, DEFAULT_SAMPLE_RATE = 8000.
> 
> python mic_vad_streaming.py -m ../mic_vad_streaming/deepspeech-0.6.1-models-cd/output_graph.pbmm -l ../mic_vad_streaming/deepspeech-0.6.1-models-cd/lm.binary -t ../mic_vad_streaming/deepspeech-0.6.1-models-cd/trie
> 
> _Used our custom model, lm and we are getting garbage output but then the pre trained model, English model which comes with deepspeech output is good._
> 
>     1. cd web_microphone_websocket
>        yarn install
>        yarn start
> 
> 
> changes done in server.js:
> line 41: vad.processAudio(data, 16000)-------------->vad.processAudio(data, 8000)
> line 191: recordedAudioLength += (chunk.length / 2) * (1 / 16000) * 1000; ------------------->recordedAudioLength += (chunk.length / 2) * (1 / 8000) * 1000;
> line 19 and line 20:changed model and lm paths as our custom model and lm.
> 
> In a separate window run this command
> node server.js
> 
> _Here also we get garbage outout for our custom model but pretrained model gave good output_

Again, this is a support request. Use Discourse.",thanks excuse put much could happen might issue compatibility well model done inference working fine data audio stereo format separate command remix left remix right normalize left right audio peak peak output convert left right based written audio audio sec buffer buffer smooth audio cut may vary sec train test dev create make language model around command text prune take pull native client extract used training command python true true true inference used binary inference working streaming git clone source apt install pip install done python custom model getting garbage output trained model model come output yarn install yarn start done line data data line line line model custom model separate window run command node also get garbage custom model model gave good support request use discourse,issue,positive,positive,positive,positive,positive,positive
661812975,"Thanks @lissyx 

Excuse me that I didn't put much of the details here. I am elaborating the steps here, it could happen there might be some issue with the examples and compatibility as well.

_How we created **our deepspeech model** and done inference, this is working fine for us._

Data:1500 hrs (8k audio files)

1. The files are stereo format files, created separate channels using command 
sox input.wav output.wav remix 1 (for left) and sox input.wav output.wav remix 2 (for right)

2. Normalize the left and right audio for peak normalized, using :
 
ffmpeg-normalize input_wav_chunk.wav --normalization-type peak --target-level -14 --output norm_wav_chunk.wav

3. Convert normalized left and right wav into chunks (based on start_time, end_time written) using pydub.

audio = AudioSegment.from([audio_cal.wav])
audio_chunk = audio[ int((start_time-0.05)*1000) : int((end_time+0.05)*1000) ] where 0.05 sec(500 ms buffer) buffer is uesd for smooth audio cut
chunk_size may vary between 1.5-15 sec.

4. Create_CSV (Train,test,dev)

5. Create LM using kenlm to make language model of around 300k lines.

command:
../kenlm/build/bin/lmplz --text vocab.txt --arpa words.arpa --o 4 --discount_fallback --prune 0 0 1
../kenlm/build/bin/build_binary -a 255 -q 8 -v trie words.arpa lm.binary
take a pull of 0.6.1 native client extract and then used:
./generate_trie alphabet.txt lm.binary trie 


6. Training Command

python3 DeepSpeech.py \
--alphabet_config_path data/alphabet.txt \
--checkpoint_dir checkpoint_dir \
--train_files data/train.csv \  
--dev_files data/dev.csv \
--test_files data/test.csv \
--epochs 20 \
--use_allow_growth True \
--use_cudnn_rnn True \
--report_count 10 \
--show_progressbar true \
--train_batch_size 16 \
--dev_batch_size 24 \
--test_batch_size 32 \
--learning_rate 0.0001 \
--dropout_rate 0.20 \
--n_hidden 2048 \
--audio_sample_rate 8000 \
--export_dir data/export_dir \
--lm data/lm/lm.binary \
--trie data/lm/trie \
--lm_alpha 0.75 \
--lm_beta 1.85 \

7. **Inference**: then used deepspeech binary for inference.

_This is working fine_
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------

_Using Deepspeech streaming example_

git clone -b r0.6 https://github.com/mozilla/DeepSpeech-examples.git

1. cd mic_vad_streaming
source $HOME/tmp/deepspeech-venv-0.6.1
sudo apt install portaudio19-dev python3-dev
pip install -r requirements.txt

Changes done in mic_vad_streaming.py

BEAM_WIDTH=1024, DEFAULT_SAMPLE_RATE = 8000.

python mic_vad_streaming.py -m ../mic_vad_streaming/deepspeech-0.6.1-models-cd/output_graph.pbmm -l ../mic_vad_streaming/deepspeech-0.6.1-models-cd/lm.binary -t ../mic_vad_streaming/deepspeech-0.6.1-models-cd/trie

_Used our custom model, lm and we are getting garbage output but then the pre trained model, English model which comes with deepspeech output is good._


2. cd web_microphone_websocket
yarn install
yarn start

changes done in server.js:
line 41: vad.processAudio(data, 16000)-------------->vad.processAudio(data, 8000)
line 191: recordedAudioLength += (chunk.length / 2) * (1 / 16000) * 1000; ------------------->recordedAudioLength += (chunk.length / 2) * (1 / 8000) * 1000;
line 19 and line 20:changed model and lm paths as our custom model and lm.

In a separate window run this command
node server.js

_Here also we get garbage outout for our custom model but pretrained model gave good output_





",thanks excuse put much could happen might issue compatibility well model done inference working fine data audio stereo format separate command remix left remix right normalize left right audio peak peak output convert left right based written audio audio sec buffer buffer smooth audio cut may vary sec train test dev create make language model around command text prune take pull native client extract used training command python true true true inference used binary inference working streaming git clone source apt install pip install done python custom model getting garbage output trained model model come output yarn install yarn start done line data data line line line model custom model separate window run command node also get garbage custom model model gave good,issue,positive,positive,positive,positive,positive,positive
661778032,"> What I am also wondering about is that how it could work by artificially limiting the max_sequence_length, since the data that we feed it self isn't changed.
> (so I would have expected it to blow up, because the sequences now seem longer than the max_sequence_length, or does it just not process the last bit of (padded or non-padded data in which the culprit lies ?)

There should be tensorflow code that already takes care of that. Now, maybe, for some reason, it's not working as expected in this case? Anyway, in the current state, we have not yet any criterion to do so. ",also wondering could work artificially limiting since data feed self would blow seem longer process last bit data culprit code already care maybe reason working case anyway current state yet criterion,issue,negative,negative,negative,negative,negative,negative
661759695,"> That's the next step yeah, I'd like to limit as much as possible the repro steps and summup them. I still have not been able to get a clear understanding of the triggering condition, though, because previous hacking changing the feature len value from offending 75 to other value, I could have valid passes with 75. So it's not really crystal clear to me that the issue is this specific value, and I need to qualify better what is happening here.

I agree, because batch C also gives 75 and that also passes.

What I am also wondering about is that how it could work by artificially limiting the max_sequence_length, since the data that we feed it self isn't changed. 
(so I would have expected it to blow up, because the sequences now seem longer than the max_sequence_length, or does it just not process the last bit of (padded or non-padded data in which the culprit lies ?)

Found some dicussions around this whole padding topic with @Reuben posting there:
    https://github.com/tensorflow/tensorflow/issues/23269
    https://github.com/mozilla/DeepSpeech/issues/885

A commit in TF 1.15-rc0 seemed also seemed more interessting than the bisection came up with: 
    https://github.com/tensorflow/tensorflow/commit/9380a41290e8fb8b9ea85f614472deab56dbc481#diff-8e54a26c3d435aad346bfa12f4c6ec79


Another interesting DS change mingling with the batches could be:
    https://github.com/mozilla/DeepSpeech/commit/6b1d6773de25aaf1c1c157f8c11ecdd727f00c6d

Especially the lines, I can't see any changes or explanation in the usage of returned values from create_dataset(), so why are the output_types changed ?:
    https://github.com/mozilla/DeepSpeech/commit/6b1d6773de25aaf1c1c157f8c11ecdd727f00c6d#diff-2f5b069cc3a96ce123ef7356642acb29R143-R145
But I'm not that familiar with the code, so likely I'm missing something.
**EDIT**: hmm seems I was able to miss the map() a few lines below and the changes to  entry_to_features().",next step yeah like limit much possible still able get clear understanding condition though previous hacking feature value value could valid really crystal clear issue specific value need qualify better happening agree batch also also also wondering could work artificially limiting since data feed self would blow seem longer process last bit data culprit found around whole padding topic posting commit also bisection came another interesting change could especially ca see explanation usage returned familiar code likely missing something edit able miss map,issue,positive,positive,positive,positive,positive,positive
661728836,I will restart bisection then and run it multiple times before calling good / bad ...,restart bisection run multiple time calling good bad,issue,negative,positive,neutral,neutral,positive,positive
661727437,"> > > ```
> > > 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263 is the first bad commit
> > > commit 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263
> > > Author: Ayush Dubey <ayushd@google.com>
> > > Date:   Wed Aug 14 13:19:26 2019 -0700
> > > 
> > >     Ensure that an error is returned if a collective op runs with int32 on GPU.
> > >     
> > >     This change fixes a bug that would overwrite the error status with an OK status
> > >     and cause a hang downstream.  It also adds a test that covers this scenario.
> > >     
> > >     PiperOrigin-RevId: 263414497
> > > 
> > >  .../common_runtime/base_collective_executor.cc     | 15 +++++++-------
> > >  tensorflow/python/ops/collective_ops_gpu_test.py   | 23 ++++++++++++++++++++++
> > >  2 files changed, 30 insertions(+), 8 deletions(-)
> > > ```
> > 
> > 
> > That seems like a weird bad commit, I'll verify that tomorrow ...
> 
> And yet, r1.15 and reverting this commit no more issue. So, is this bugged or is this exposing a long-standing issue ? On our side or tensorflow or CUDNN ?

Bad news: it seems the issue is somehow intermittent, and after a few retry with this reverted, it's back and still here ...",first bad commit commit author date wed ensure error returned collective change bug would overwrite error status status cause downstream also test scenario like weird bad commit verify tomorrow yet commit issue issue side bad news issue somehow intermittent retry back still,issue,negative,negative,negative,negative,negative,negative
661710271,"> Hmm weird and a small sigh, hoped that it would have delivered a more clear an pinpointed problem ...

I would have hoped as well



>  Any idea where this op would be used in the context of DeepSpeech and the max_sequence_length array and or the hidden state ?

Absolutely none. But it's interesting, because in the past we had to hack a thing: https://github.com/tensorflow/tensorflow/issues/20369 it might be a long shot, but `DT_INT32` + GPU also appears here.



>  Perhaps it would be wise to try to get some help from TF people / Nvidia based on this ?

That's the next step yeah, I'd like to limit as much as possible the repro steps and summup them. I still have not been able to get a clear understanding of the triggering condition, though, because previous hacking changing the feature len value from offending 75 to other value, I could have valid passes with 75. So it's not really crystal clear to me that the issue is this specific value, and I need to qualify better what is happening here.",weird small sigh hoped would clear problem would hoped well idea would used context array hidden state absolutely none interesting past hack thing might long shot also perhaps would wise try get help people based next step yeah like limit much possible still able get clear understanding condition though previous hacking feature value value could valid really crystal clear issue specific value need qualify better happening,issue,positive,positive,neutral,neutral,positive,positive
661708090,"Hmm weird and a small sigh, hoped that it would have delivered a more clear an pinpointed problem ...
Any idea where this op would be used in the context of DeepSpeech and the max_sequence_length array and or the hidden state ?
Perhaps it would be wise to try to get some help from TF people  / Nvidia based on this ?
We do have a commit and some docker test cases with data that triggers the issue.",weird small sigh hoped would clear problem idea would used context array hidden state perhaps would wise try get help people based commit docker test data issue,issue,positive,negative,neutral,neutral,negative,negative
661702545,"> > ```
> > 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263 is the first bad commit
> > commit 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263
> > Author: Ayush Dubey <ayushd@google.com>
> > Date:   Wed Aug 14 13:19:26 2019 -0700
> > 
> >     Ensure that an error is returned if a collective op runs with int32 on GPU.
> >     
> >     This change fixes a bug that would overwrite the error status with an OK status
> >     and cause a hang downstream.  It also adds a test that covers this scenario.
> >     
> >     PiperOrigin-RevId: 263414497
> > 
> >  .../common_runtime/base_collective_executor.cc     | 15 +++++++-------
> >  tensorflow/python/ops/collective_ops_gpu_test.py   | 23 ++++++++++++++++++++++
> >  2 files changed, 30 insertions(+), 8 deletions(-)
> > ```
> 
> That seems like a weird bad commit, I'll verify that tomorrow ...

And yet, r1.15 and reverting this commit no more issue. So, is this bugged or is this exposing a long-standing issue ? On our side or tensorflow or CUDNN ?",first bad commit commit author date wed ensure error returned collective change bug would overwrite error status status cause downstream also test scenario like weird bad commit verify tomorrow yet commit issue issue side,issue,negative,negative,negative,negative,negative,negative
661698424,Please reach for support on Discourse. There are already people sharing their work regarding chinese models.,please reach support discourse already people work regarding,issue,positive,neutral,neutral,neutral,neutral,neutral
661697113,"> @reuben I think MappedByteBuffer should be fine too. It looks like a MappedByteBuffer can be obtained through an AssetFileDescriptor. In fact I am already doing this for other TFL models.

@vikramambrose So, do you have experience on that? We're kind of overloaded so it's complicated for us, as of now, to investigate that kind of change, but if you have feedback / patches to share, that's welcome.",think fine like fact already experience kind complicated u investigate kind change feedback share welcome,issue,positive,positive,positive,positive,positive,positive
661641880,"@carlfm01 Is the remaining task now landing the PR ""Add UWP Nuget packing support""?",task landing add support,issue,negative,neutral,neutral,neutral,neutral,neutral
661338063,"> ```
> 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263 is the first bad commit
> commit 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263
> Author: Ayush Dubey <ayushd@google.com>
> Date:   Wed Aug 14 13:19:26 2019 -0700
> 
>     Ensure that an error is returned if a collective op runs with int32 on GPU.
>     
>     This change fixes a bug that would overwrite the error status with an OK status
>     and cause a hang downstream.  It also adds a test that covers this scenario.
>     
>     PiperOrigin-RevId: 263414497
> 
>  .../common_runtime/base_collective_executor.cc     | 15 +++++++-------
>  tensorflow/python/ops/collective_ops_gpu_test.py   | 23 ++++++++++++++++++++++
>  2 files changed, 30 insertions(+), 8 deletions(-)
> ```

That seems like a weird bad commit, I'll verify that tomorrow ...",first bad commit commit author date wed ensure error returned collective change bug would overwrite error status status cause downstream also test scenario like weird bad commit verify tomorrow,issue,negative,negative,negative,negative,negative,negative
661337151,"```
3c6e3868ac14fdbcaa24ddfb05624a0b55f60263 is the first bad commit
commit 3c6e3868ac14fdbcaa24ddfb05624a0b55f60263
Author: Ayush Dubey <ayushd@google.com>
Date:   Wed Aug 14 13:19:26 2019 -0700

    Ensure that an error is returned if a collective op runs with int32 on GPU.
    
    This change fixes a bug that would overwrite the error status with an OK status
    and cause a hang downstream.  It also adds a test that covers this scenario.
    
    PiperOrigin-RevId: 263414497

 .../common_runtime/base_collective_executor.cc     | 15 +++++++-------
 tensorflow/python/ops/collective_ops_gpu_test.py   | 23 ++++++++++++++++++++++
 2 files changed, 30 insertions(+), 8 deletions(-)
",first bad commit commit author date wed ensure error returned collective change bug would overwrite error status status cause downstream also test scenario,issue,negative,negative,negative,negative,negative,negative
661314381,Are there plans to run reverb filters on the datasets as well? STT might struggle in this area.,run reverb well might struggle area,issue,negative,neutral,neutral,neutral,neutral,neutral
661291737,"Please ask support questions on Discourse.


> We have built our custom deepspeech models for version 0.6.

Please document how.



> This is happening with Nodejs streaming example as well as Python base example. Is there anything specific have to be done while creating the model for streaming.

Please be clear ""nodejs streaming example as well as python base example"", are you referring to python streaming? Are you referring to exampels from https://github.com/mozilla/DeepSpeech-examples/ ?



> Do let me know if any specific information is needed from our side or please point to any specific resource which we could have missed out. We have tried multiple options but of no use.

But we don't know what you tried. There was a template, but you removed it, so we are left with absolutely nothing actionable.",please ask support discourse built custom version please document happening streaming example well python base example anything specific done model streaming please clear streaming example well python base example python streaming let know specific information side please point specific resource could tried multiple use know tried template removed left absolutely nothing actionable,issue,positive,negative,negative,negative,negative,negative
661150906,"> the stack you are relying on? I didn't get up here

Looks like you are using Python then.",stack get like python,issue,negative,neutral,neutral,neutral,neutral,neutral
661149912,"> python's 3.6.8 version (same is being used for both Mac & Linux).
> pip install deepspeech

https://files.pythonhosted.org/packages/cf/44/958607ce1c95c5386c29e2b9c8a30f8bc797d07306d16e6ef7f7f468a464/deepspeech-0.7.4-cp36-cp36m-win_amd64.whl

So it's published, we really need more verbose logs and pip list logs, but I'm highly doubtful there's a bug on our side, it more feels like some setup issue on your side ... ",python version used mac pip install really need verbose pip list highly doubtful bug side like setup issue side,issue,negative,negative,negative,negative,negative,negative
661148631,">  I've updated deepspeech version, even I uninstalled and reinstalled the latest version of deepspeech model it is showing v0.7.0.

As @reuben said, you are talking of both ""deepspeech"" and ""deepspeech model"", so we need  to really be precise on what you do ...



> I used a virtual environment for installing package. I'm using python's 3.6.8 version (same is being used for both Mac & Linux).
> pip install deepspeech

Care to share `pip install -v` + `pip list` ?


> update deepspeech version using pip install deepspeech --upgrade

This in itself should take care of running it correctly ... But without verbose upgrade log, we can't know for sure ...

Can you ensure there is no leftover `libdeepspeech.so` somewhere in your `PATH` ?",version even uninstalled latest version model showing said talking model need really precise used virtual environment package python version used mac pip install care share pip install pip list update version pip install upgrade take care running correctly without verbose upgrade log ca know sure ensure leftover somewhere path,issue,positive,positive,positive,positive,positive,positive
661138069,"Thanks, @lissyx for the response. 
I've updated deepspeech version, even I uninstalled and reinstalled the latest version of deepspeech model it is showing v0.7.0.

how I setup things?
I used a virtual environment for installing package. I'm using python's 3.6.8 version (same is being used for both Mac & Linux).
```
pip install deepspeech
```

how I upgraded model?
1. First I downloaded the latest model and replaced with the old one.
2. update deepspeech version using `pip install deepspeech --upgrade`
3. Even I uninstalled and installed again.

How I got this output?
I followed the steps mentioned on this page: https://deepspeech.readthedocs.io/en/v0.7.4/
```
deepspeech --model deepspeech-0.7.4-models.pbmm --scorer deepspeech-0.7.4-models.scorer --audio audio/2830-3980-0043.wav
```

the stack you are relying on? I didn't get up here
 
  ",thanks response version even uninstalled latest version model showing setup used virtual environment package python version used mac pip install model first latest model old one update version pip install upgrade even uninstalled got output page model scorer audio stack get,issue,negative,positive,positive,positive,positive,positive
661125364,Redirect stderr only during model creation if you have other logging that you want to keep: here's an example: https://discourse.mozilla.org/t/deepspeech-python-prevent-the-stdout-of-versions/62620/16?u=reuben,redirect model creation logging want keep example,issue,negative,neutral,neutral,neutral,neutral,neutral
661124008,What do you think is the path forward for those who want silent operation? I've provided a number of alternatives but I'm not hearing a solution.,think path forward want silent operation provided number hearing solution,issue,negative,neutral,neutral,neutral,neutral,neutral
661097065,"Ok, passes with 1.14.1 + CUDNN 7.6 built locally. But a few patches are required, this is going to make `git bisect` slower than I would have loved.",built locally going make git bisect would,issue,negative,neutral,neutral,neutral,neutral,neutral
661062748,"Note that that version info refers to the *code*, not the model. If you upgrade the model but don't upgrade the DeepSpeech package you're using, the printed version won't change.",note version code model upgrade model upgrade package printed version wo change,issue,negative,neutral,neutral,neutral,neutral,neutral
661037271,"> First would be to check if a custom build TF14 doesn't have the problem (with the 7.4.1.5 cudnn and/or the newest).
> If so it would point to a change in TF, if not ... nah don't think about that yet ..

yeah that's what I'm doing ...",first would check custom build problem would point change think yet yeah,issue,negative,positive,positive,positive,positive,positive
661036910,"First would be to check if a custom build TF14 doesn't have the problem (with the  7.4.1.5 cudnn and/or the newest).
If so it would point to a change in TF, if not ... nah don't think about that yet ..",first would check custom build problem would point change think yet,issue,negative,positive,positive,positive,positive,positive
661029418,">  There also have been some changes to TF contrib/cudnn_rnn between v1.14 and v1.15, but my limited insights couldn't spot anything very amiss:

I can always try and `git bisect` that ...",also limited could spot anything amiss always try git bisect,issue,negative,negative,neutral,neutral,negative,negative
661021249,"Bummer.
If I read: https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_7xx.html#rel_713 , it seems there have been LSTM related issues before hanging on specific sizes, in this case of the hidden state. But that was already fixed in all the cudnn versions we tested.
I still can't wrap my head around why the TF 14 image seems to behave differently, you kind of ruled out the cudnn version. 
There also have been some changes to TF contrib/cudnn_rnn between v1.14 and v1.15, but my limited insights couldn't spot anything very amiss:
https://github.com/tensorflow/tensorflow/commits/r1.15/tensorflow/contrib/cudnn_rnn 
",bummer read related hanging specific size case hidden state already fixed tested still ca wrap head around image behave differently kind version also limited could spot anything amiss,issue,negative,positive,neutral,neutral,positive,positive
661012963,"Nothing obvious pops:
```
[Switching to Thread 0x7ff74ffff700 (LWP 209659)]                                                                                                                                                           
                                                                                                                                                                                                                                                                                                                                                                                                                         
Thread 526 ""DeepSpeech.py"" hit Breakpoint 1, cudnnRNNForwardTrainingEx (handle=0x7ff71a00a5f0, rnnDesc=0x7ff748025900, xDesc=0x7ff748021870, x=0x7ff48da4dd00, hxDesc=0x7ff748017210, hx=0x7ff48b4d4300, cxDesc=0x7ff748006990, cx=0x7ff48b4d4300, wDesc=0x7ff748023f50, w=0x7ff492002900, yDesc=0x7ff74801f540, y=0x7ff48dce7d00, hyDesc=0x7ff748017210, hy=0x7ff48de0fd00, cyDesc=0x7ff748006990, cy=0x7ff48de13d00,   
    kDesc=0x0, keys=0x0, cDesc=0x0, cAttn=0x0, iDesc=0x0, iAttn=0x0, qDesc=0x0, queries=0x0, workSpace=0x7ff4aa032900, workSpaceSizeInBytes=136609792, reserveSpace=0x7ff48de17d00, reserveSpaceSizeInBytes=6062080) at ./tensorflow/stream_executor/cuda/cudnn_7_6.inc:2307                                                                                                                                             
2307    ./tensorflow/stream_executor/cuda/cudnn_7_6.inc: Aucun fichier ou dossier de ce type.                                                                                                               
(gdb) cont                                                                                                                                                                                                  
Continuing.                                                                                                                                                                                                 
[Thread 0x7ffeb4874700 (LWP 209805) exited]                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                         
Thread 526 ""DeepSpeech.py"" hit Breakpoint 1, 0x00007ff981aa0d50 in cudnnRNNForwardTrainingEx () from /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.0/lib64/libcudnn.so.7                                                                                                                                                                                                                                    
(gdb) cont                                                                                                                                                                                                                                                                                                                                                                                                               
Continuing.                                                                                                                                                                                                 
[Detaching after fork from child process 209995]                                                                                                                                                            
[Switching to Thread 0x7ff82d7fa700 (LWP 209615)]                                                                                                                                                           
                                                                                                                                                                                                                                                                                                                                                                                                                         
Thread 482 ""DeepSpeech.py"" hit Breakpoint 1, cudnnRNNForwardTrainingEx (handle=0x7ff8100081e0, rnnDesc=0x7ff1233fab70, xDesc=0x7ff1230fc010, x=0x7ff1a9a68800, hxDesc=0x7ff1233faa70, hx=0x7ff1a9d0b800, cxDesc=0x7ff123344d30, cx=0x7ff1a9d0b800, wDesc=0x7ff1230fbfd0, w=0x7ff1a150d800, yDesc=0x7ff1230fc050, y=0x7ff1a9d0f800, hyDesc=0x7ff1233faa70, hy=0x7ff1a9e3b800, cyDesc=0x7ff123344d30, cy=0x7ff1a9e3f800,   
    kDesc=0x0, keys=0x0, cDesc=0x0, cAttn=0x0, iDesc=0x0, iAttn=0x0, qDesc=0x0, queries=0x0, workSpace=0x7ff1a9e43800, workSpaceSizeInBytes=139886624, reserveSpace=0x7ff1b23ab900, reserveSpaceSizeInBytes=6144000) at ./tensorflow/stream_executor/cuda/cudnn_7_6.inc:2307                                                                                                                                             
2307    in ./tensorflow/stream_executor/cuda/cudnn_7_6.inc                                                                                                                                                                                                                                                                                                                                                               
(gdb)                                                                                                                                                                                                                                                                                                                                                                                                                    
Continuing.                                                                                                                                                                                                                                                                                                                                                                                                              
                                                                                                                                                                                                                                                                                                                                                                                                                         
Thread 482 ""DeepSpeech.py"" hit Breakpoint 1, 0x00007ff981aa0d50 in cudnnRNNForwardTrainingEx () from /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.0/lib64/libcudnn.so.7                                                                                                                                                                                                                                    
(gdb)                                                                                                                                                                                                                                                                                                                                                                                                                    
Continuing.                                                                  
Epoch 0 |   Training | Elapsed Time: 0:01:06 | Steps: 1 | Loss: 190.842316                                                                                                                                                                                                                                                                                                                                               
--------------------------------------------------------------------------------                                                                                                                                                                                                                                                                                                                                         
Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                                                                                                                                                                                                

[...]

[Switching to Thread 0x7ff74effd700 (LWP 209661)]

Thread 528 ""DeepSpeech.py"" hit Breakpoint 1, cudnnRNNForwardTrainingEx (handle=0x7ff71a00a5f0, rnnDesc=0x7ff748025900, xDesc=0x7ff74402f660, x=0x7ff48da5fc00, hxDesc=0x7ff7440293a0, hx=0x7ff48dd02c00, cxDesc=0x7ff744029310, cx=0x7ff48dd02c00, wDesc=0x7ff748023f50, w=0x7ff492002900, yDesc=0x7ff74402bfc0, y=0x7ff48dd06c00, hyDesc=0x7ff7440293a0, hy=0x7ff48de32c00, cyDesc=0x7ff744029310, cy=0x7ff48de36c00, 
    kDesc=0x0, keys=0x0, cDesc=0x0, cAttn=0x0, iDesc=0x0, iAttn=0x0, qDesc=0x0, queries=0x0, workSpace=0x7ff4aa032900, workSpaceSizeInBytes=136609792, reserveSpace=0x7ff48de3ac00, reserveSpaceSizeInBytes=6144000) at ./tensorflow/stream_executor/cuda/cudnn_7_6.inc:2307
2307    in ./tensorflow/stream_executor/cuda/cudnn_7_6.inc
(gdb) 
Continuing.
[Switching to Thread 0x7ff72effd700 (LWP 209668)]

Thread 535 ""DeepSpeech.py"" hit Breakpoint 1, cudnnRNNForwardTrainingEx (handle=0x7ff8100081e0, rnnDesc=0x7ff1233fab70, xDesc=0x7ff4290342e0, x=0x7ff1a9a56900, hxDesc=0x7ff168009dc0, hx=0x7ff1a9cf0900, cxDesc=0x7ff429001c60, cx=0x7ff1a9cf0900, wDesc=0x7ff1230fbfd0, w=0x7ff1a150d500, yDesc=0x7ff429006c40, y=0x7ff1a9cf4900, hyDesc=0x7ff168009dc0, hy=0x7ff1a9e1c900, cyDesc=0x7ff429001c60, cy=0x7ff1a9e20900, 
    kDesc=0x0, keys=0x0, cDesc=0x0, cAttn=0x0, iDesc=0x0, iAttn=0x0, qDesc=0x0, queries=0x0, workSpace=0x7ff1a9e24900, workSpaceSizeInBytes=139821088, reserveSpace=0x7ff1b237ca00, reserveSpaceSizeInBytes=6062080) at ./tensorflow/stream_executor/cuda/cudnn_7_6.inc:2307
2307    in ./tensorflow/stream_executor/cuda/cudnn_7_6.inc
(gdb) 
Continuing.
[Switching to Thread 0x7ff74effd700 (LWP 209661)]

Thread 528 ""DeepSpeech.py"" hit Breakpoint 1, 0x00007ff981aa0d50 in cudnnRNNForwardTrainingEx () from /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.0/lib64/libcudnn.so.7
(gdb) 
Continuing.
[Switching to Thread 0x7ff72effd700 (LWP 209668)]

Thread 535 ""DeepSpeech.py"" hit Breakpoint 1, 0x00007ff981aa0d50 in cudnnRNNForwardTrainingEx () from /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/CUDA-10.0/lib64/libcudnn.so.7
(gdb) 
Continuing.
2020-07-20 14:43:04.648417: E tensorflow/stream_executor/dnn.cc:588] CUDNN_STATUS_EXECUTION_FAILED
in tensorflow/stream_executor/cuda/cuda_dnn.cc(1778): 'cudnnRNNForwardTrainingEx( cudnn.handle(), rnn_desc.handle(), input_desc.data_handle(), input_data.opaque(), input_h_desc.handle(), input_h_data.opaque(), input_c_desc.handle(), input_c_data.opaque(), rnn_desc.params_handle(), params.opaque(), output_desc.data_handle(), output_data->opaque(), output_h_desc.handle(), output_h_data->opaque(), output_c_de
sc.handle(), output_c_data->opaque(), nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, workspace.opaque(), workspace.size(), reserve_space.opaque(), reserve_space.size())'
2020-07-20 14:43:04.648554: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cudnn_rnn_ops.cc:1517 : Internal: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 75, 2, 2048] ",nothing obvious switching thread thread hit dossier de ce type thread thread hit fork child process switching thread thread hit thread hit epoch training time loss epoch training time loss switching thread thread hit switching thread thread hit switching thread thread hit switching thread thread hit opaque opaque opaque internal call model,issue,negative,neutral,neutral,neutral,neutral,neutral
660994104,"> Ah yes you have to be careful with pruning since every change from a buildfile is it's own image layer due to the caching stuff.
> Works nice in sparing space, but if you want to delete old stuff it can be a nightmare. I try to get accustomed to dumping the images that a care about as a tar-file with everything included first, so I can restore that stuff if need be.

Indeed, I have been doing my house-keeping but it seems to have not had completely cleaned up some things :/. Anyway, I now have something that should have more debug infos",ah yes careful pruning since every change image layer due stuff work nice sparing space want delete old stuff nightmare try get accustomed dumping care everything included first restore stuff need indeed completely anyway something,issue,positive,positive,positive,positive,positive,positive
660989011,"The iOS build has been added to CI in #3150. So we should now have automatically built binaries that can be used with the project. Next step is building and publishing the wrapper itself, but before doing that I want to get more feedback from users, such as these memory issues... (Thanks for testing @erksch !)",build added automatically built used project next step building wrapper want get feedback memory thanks testing,issue,negative,positive,neutral,neutral,positive,positive
660987963,Out of memory maybe? What device are you running this on?,memory maybe device running,issue,negative,neutral,neutral,neutral,neutral,neutral
660979555,"Ah yes you have to be careful with pruning since every change from a buildfile is it's own image layer due to the caching stuff.
Works nice in sparing space, but if you want to delete old stuff it can be a nightmare. I try to get accustomed to dumping the images that a care about as a tar-file with everything included first, so I can restore that stuff if need be.",ah yes careful pruning since every change image layer due stuff work nice sparing space want delete old stuff nightmare try get accustomed dumping care everything included first restore stuff need,issue,positive,positive,positive,positive,positive,positive
660954124,"> Ugh the nightmare of a build-system called ""Bazel"".

I guess in this case it's just I was running out of space on `/` because of docker not properly pruning some resources.",ugh nightmare guess case running space docker properly pruning,issue,negative,neutral,neutral,neutral,neutral,neutral
660950976,"Okay weirdly enough, when I run the app multiple times, every now and then it continues feeding audio content successfully
```
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 8192 samples
read 2800 samples
```
But it always fails when calling `DS_FinishStream(streamCtx)` with a `EXC_BAD_ACCESS`.

But every other time it fails feeding the first batch of samples.

Update: on `DS_FinishStream(streamCtx)` I sometimes get an:
```
deepspeech_ios_test(26389,0x16fa6f000) malloc: can't allocate region
:*** mach_vm_map(size=11453251584, flags: 123) failed (error code=3)
deepspeech_ios_test(26389,0x16fa6f000) malloc: *** set a breakpoint in malloc_error_break to debug
libc++abi.dylib: terminating with uncaught exception of type std::bad_alloc: std::bad_alloc
```",weirdly enough run multiple time every feeding audio content successfully read read read read read read always calling every time feeding first batch update sometimes get ca allocate region error set uncaught exception type,issue,negative,positive,positive,positive,positive,positive
660929310,"You're right, DS_CreateModel seems to work fine and I can retrieve sample rate and beam width. So the issue for me has to be in sampling and memory allocation. It's weird that that part is not working for me somehow.",right work fine retrieve sample rate beam width issue sampling memory allocation weird part working somehow,issue,negative,positive,neutral,neutral,positive,positive
660892689,"> * no tests yet? maybe you plan to add them after?

Correct.

> * some files seems dead now

Yeah, thanks for the comments, will clean those up.

> * a little cleanup on the tensorflow build `if` mess with `case` might be easier to read

Will take a look.

> * since we are building the workers, maybe we can simplify the base setup and limit ourselves to just depending on XCode ?

Yeah, that'd be nice. Filed https://github.com/mozilla/DeepSpeech/issues/3169",yet maybe plan add correct dead yeah thanks clean little cleanup build mess case might easier read take look since building maybe simplify base setup limit depending yeah nice,issue,positive,negative,neutral,neutral,negative,negative
660873092,"> Note that I'm only asking for silent operation when calling in via the API. Your shipped binaries can print messages as they please.

Experience has shown this is not enough.



> I have a multi-threaded process with each thread instantiating its own copy of the DeepSpeech model. These messages get repeatedly spammed to stderr for each instantiation (particularly bad with many cores/gpus) which isn't helpful and drowns out my own warning/error messages that I send to stderr. Redirecting is not a good option since there's inherent value in seeing stderr contents.

Are you referring to ""spam"" for **two** lines on each model creation? Sorry, but even with a lot of GPUs / CPUs it's not going to be that much. How much spam is spam ?



> An alternative is that the caller provides a file descriptor or other abstraction (e.g. LogSink) into which the DeepSpeech API can write messages. At least that way the caller can decide what to do with the messages.

This is both a non trivial amount of work and a recipe for missing important informations. Experience has proven us that this will bite us back bad.",note silent operation calling via shipped print please experience shown enough process thread copy model get repeatedly particularly bad many helpful send good option since inherent value seeing content two model creation sorry even lot going much much alternative caller file abstraction write least way caller decide non trivial amount work recipe missing important experience proven u bite u back bad,issue,negative,negative,neutral,neutral,negative,negative
660864260,"Oh, OK, I was looking at the ""Build Phases"" tab, not ""General"". What I have in ""General"" matches your screenshots. It's weird that it crashes on DS_FeedAudioContent and not DS_CreateModel, maybe it's not a linking issue, unless your code has a bug and it's calling DS_FeedAudioContent first, on an invalid model/stream, which would certainly cause a segfault.",oh looking build phase tab general general weird maybe linking issue unless code bug calling first invalid would certainly cause,issue,negative,positive,neutral,neutral,positive,positive
660863312,"> What do you have there? Maybe some things have to be switched to embed & sign?

I have `libdeepspeech.so` in ""Link Binary With Libraries"" for project `deepspeech_ios`. I don't see a ""Frameworks and Libraries"" section like in your screenshot.

In `deepspeech_ios_test`, I have both `libdeepspeech.so` and `deepspeech_ios.framework` in ""Link Binary With Libraries"", and I also have `libdeepspeech.so` in ""Embed Frameworks"", with ""Code Sign On Copy"" enabled.",maybe switched embed sign link binary project see section like link binary also embed code sign copy,issue,negative,neutral,neutral,neutral,neutral,neutral
660860802,"> It seemed from the header like all I had to do was initialize a DeepSpeechModel with the .tflite file and then call speechToText with the buffer. Did I miss a step? Do I need to setup a streaming context even if I’m not streaming?

That's correct, you don't need to setup a streaming context.",header like initialize file call buffer miss step need setup streaming context even streaming correct need setup streaming context,issue,negative,neutral,neutral,neutral,neutral,neutral
660860015,"I tried a simple test app where I loaded a pre-converted file of a few seconds into memory and called DeepSpeechModel.speechToText. There are no crashes or anything, but the resulting text string is empty.

It seemed from the header like all I had to do was initialize a DeepSpeechModel with the .tflite file and then call speechToText with the buffer. Did I miss a step? Do I need to setup a streaming context even if I’m not streaming?",tried simple test loaded file memory anything resulting text string empty header like initialize file call buffer miss step need setup streaming context even streaming,issue,negative,negative,neutral,neutral,negative,negative
660705162,@carlfm01 It works! Awesome! thank you for your hard work!,work awesome thank hard work,issue,positive,positive,positive,positive,positive,positive
660694822,"After setting `deepspeech_ios.framework` to `Embed & Sign` in the `deepspeech_ios_test` target (which is just a random tryout), the code at least passes until the `DS_FeedAudioContent`, and the error occurs that I mentioned in the first post. 

Here is the full log I got for that error.
```
* thread #2, queue = 'com.apple.avfoundation.avasset.completionsQueue', stop reason = EXC_BAD_ACCESS (code=2, address=0x130800076)
    frame #0: 0x0000000103891494 libdeepspeech.so`___lldb_unnamed_symbol5$$libdeepspeech.so + 360
  * frame #1: 0x000000010385df68 deepspeech_ios`DeepSpeechStream.feedAudioContent(buffer=(_position = 0x000000016502d200, count = 8192), self=(streamCtx = 0x0000000162f32f40)) at DeepSpeech.swift:181:9
    frame #2: 0x00000001028b20b0 deepspeech_ios_test`closure #1 in render(samples=Swift.UnsafeRawBufferPointer @ 0x000000016d5e0100, stream=(streamCtx = 0x0000000162f32f40)) at AppDelegate.swift:126:20
    frame #3: 0x00000001028b2138 deepspeech_ios_test`thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #4: 0x00000001028b2198 deepspeech_ios_test`partial apply for thunk for @callee_guaranteed (@unowned UnsafeRawBufferPointer) -> (@error @owned Error) at <compiler-generated>:0
    frame #5: 0x00000001b810c348 libswiftFoundation.dylib`Foundation.Data.withUnsafeBytes<A>((Swift.UnsafeRawBufferPointer) throws -> A) throws -> A + 504
    frame #6: 0x00000001028b097c deepspeech_ios_test`render(audioContext=0x000000016760bd10, stream=(streamCtx = 0x0000000162f32f40)) at AppDelegate.swift:124:22
    frame #7: 0x00000001028b30c8 deepspeech_ios_test`closure #1 in test(audioContext=0x000000016760bd10, stream=(streamCtx = 0x0000000162f32f40), audioPath=""/private/var/containers/Bundle/Application/D6D001A2-07F7-4BD3-80E9-9DBECCA975E8/deepspeech_ios_test.app/4507-16021-0012.wav"", start=2020-07-19 21:19:15 CEST, completion=0x00000001028b83c8 deepspeech_ios_test`partial apply forwarder for closure #1 () -> () in closure #1 () -> () in deepspeech_ios_test.AppDelegate.application(_: __C.UIApplication, didFinishLaunchingWithOptions: Swift.Optional<Swift.Dictionary<__C.UIApplicationLaunchOptionsKey, Any>>) -> Swift.Bool at <compiler-generated>) at AppDelegate.swift:174:9
    frame #8: 0x00000001028acfc0 deepspeech_ios_test`closure #1 in static AudioContext.load(asset=0x000000016365fd40, assetTrack=0x00000001637212f0, audioURL=Foundation.URL @ 0x0000000163674090, completionHandler=0x00000001028b375c deepspeech_ios_test`partial apply forwarder for closure #1 (Swift.Optional<deepspeech_ios_test.AudioContext>) -> () in deepspeech_ios_test.test(model: deepspeech_ios.DeepSpeechModel, audioPath: Swift.String, completion: () -> ()) -> () at <compiler-generated>) at AppDelegate.swift:59:17
    frame #9: 0x00000001028ad9b0 deepspeech_ios_test`thunk for @escaping @callee_guaranteed () -> () at <compiler-generated>:0
    frame #10: 0x0000000102c0fefc libclang_rt.asan_ios_dynamic.dylib`__wrap_dispatch_async_block_invoke + 196
    frame #11: 0x0000000104ec605c libdispatch.dylib`_dispatch_call_block_and_release + 32
    frame #12: 0x0000000104ec74d8 libdispatch.dylib`_dispatch_client_callout + 20
    frame #13: 0x0000000104ecec20 libdispatch.dylib`_dispatch_lane_serial_drain + 720
    frame #14: 0x0000000104ecf834 libdispatch.dylib`_dispatch_lane_invoke + 440
    frame #15: 0x0000000104edb270 libdispatch.dylib`_dispatch_workloop_worker_thread + 1344
    frame #16: 0x00000001816a7718 libsystem_pthread.dylib`_pthread_wqthread + 276
```",setting embed sign target random tryout code least error first post full log got error thread queue stop reason frame frame count frame closure render frame unowned error error frame partial apply unowned error error frame frame render frame closure test cest partial apply forwarder closure closure frame closure static partial apply forwarder closure model completion frame frame frame frame frame frame frame frame,issue,positive,negative,neutral,neutral,negative,negative
660693329,"You're right. Since it crashes when communication with library happens, it's probably just included incorrectly.

So to go through what I tried:
- Cloning the repo and checking out the ios-build branch
- In XCode, set signing for the targets `deepspeech_ios` and `deepspeech_ios_test` to my team and adjust the bundle identifier to one of mine
- Trying to run deepspeech_ios_test on my device
-> Build failed with
```
clang: error: no such file or directory: '[...]/DeepSpeech/native_client/swift/libdeepspeech.so'
Command Ld failed with a nonzero exit code
```
- So downloading the ARM library from the link that you provided and moving it to the given destination
- Trying to run again 
-> Build succeeded but runtime error
```
dyld: Library not loaded: @rpath/deepspeech_ios.framework/deepspeech_ios
  Referenced from: /private/var/containers/Bundle/Application/E9B900F3-5F4C-466D-BB03-E97F5588A768/deepspeech_ios_test.app/deepspeech_ios_test
  Reason: image not found
(lldb) bt 
* thread #1, stop reason = signal SIGABRT
```

The error in the post before is after trying some things in the ""Frameworks, Libraries and Embedded Content Section"".
After doing a fresh start and just adding the library like explained above I get the following configs:
- `deepspeech_ios_test` target
<img width=""741"" alt=""Bildschirmfoto 2020-07-19 um 21 10 15"" src=""https://user-images.githubusercontent.com/19290349/87882983-500e0f00-ca04-11ea-9166-6f5d815c2c49.png"">

- `deepspeech_ios` target
<img width=""743"" alt=""Bildschirmfoto 2020-07-19 um 21 11 03"" src=""https://user-images.githubusercontent.com/19290349/87882998-6d42dd80-ca04-11ea-8823-f9664020e705.png"">

What do you have there? Maybe some things have to be switched to embed & sign?
",right since communication library probably included incorrectly go tried branch set team adjust bundle identifier one mine trying run device build clang error file directory command nonzero exit code arm library link provided moving given destination trying run build error library loaded reason image found thread stop reason signal error post trying content section fresh start library like get following target um target um maybe switched embed sign,issue,negative,positive,positive,positive,positive,positive
660681312,"Also, maybe double check the signing options in Xcode? At some point when writing the bindings I ran into some runtime exceptions due to incorrect signing options.",also maybe double check point writing ran due incorrect,issue,negative,negative,neutral,neutral,negative,negative
660681156,"The models should be compatible. I don't know what's going on there, can't reproduce it locally...",compatible know going ca reproduce locally,issue,negative,neutral,neutral,neutral,neutral,neutral
660478652,"The road to a debug build is ... complicated.
```
[12,032 / 15,573] 305 actions, 128 running
    Compiling tensorflow/core/kernels/cwise_op_gpu_bitwise_and.cu.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_bitwise_or.cu.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_bitwise_xor.cu.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_add.cu.cc [for host]; 106s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_div.cu.cc [for host]; 104s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.cc [for host]; 102s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_left_shift.cu.cc [for host]; 101s local
    Compiling tensorflow/core/kernels/cwise_op_gpu_floor_div.cu.cc [for host]; 99s local ...

Server terminated abruptly (error code: 14, error message: 'Socket closed', log file: '/home/alexandre/.cache/bazel/_bazel_alexandre/93bedb94245f10d899bd4ce902050079/server/jvm.out')

alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx$ aaa^C
alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx$ ll /home/alexandre/.cache/bazel/_bazel_alexandre/93bedb94245f10d899bd4ce902050079/server/jvm.out
-rw-r--r-- 1 alexandre alexandre 822 17 juil. 18:41 /home/alexandre/.cache/bazel/_bazel_alexandre/93bedb94245f10d899bd4ce902050079/server/jvm.out
alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx$ cat /home/alexandre/.cache/bazel/_bazel_alexandre/93bedb94245f10d899bd4ce902050079/server/jvm.out
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGBUS (0x7) at pc=0x00007fcea090109e, pid=1171461, tid=1171475
#
# JRE version: OpenJDK Runtime Environment (Zulu11.29+3-CA) (11.0.2+7) (build 11.0.2+7-LTS)
# Java VM: OpenJDK 64-Bit Server VM (11.0.2+7-LTS, mixed mode, tiered, compressed oops, parallel gc, linux-amd64)
# Problematic frame:
# V  [libjvm.so+0xc5309e]  PerfLongVariant::sample()+0x1e
#
# No core dump will be written. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again
#
# An error report file with more information is saved as:
# /home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx/hs_err_pid1171461.log
#
# If you would like to submit a bug report, please visit:
#   http://www.azulsystems.com/support/
#
```",road build complicated running host local host local host local host local host local host local host local host local server abruptly error code error message closed log file cat fatal error environment version environment build server mixed mode tiered compressed parallel problematic frame core dump written core disabled enable core dumping try unlimited starting error report file information saved would like submit bug report please visit,issue,negative,negative,neutral,neutral,negative,negative
660457949,Awesome I'll give it a try today or tomorrow.,awesome give try today tomorrow,issue,positive,positive,positive,positive,positive,positive
660452058,"You decide how its best done, im Just feeding ideas 😊",decide best done feeding,issue,positive,positive,positive,positive,positive,positive
660451968,"Not sure what tutorial you are talking about, our docs cover it. Good to know it works now, thanks ! ",sure tutorial talking cover good know work thanks,issue,positive,positive,positive,positive,positive,positive
660428210,"Sure, @lissyx  what about adding another console example for uwp and run the test on it?",sure another console example run test,issue,negative,positive,positive,positive,positive,positive
660427444,"Ok, now installing the generated NuGet by https://github.com/mozilla/DeepSpeech/pull/3100 from https://community-tc.services.mozilla.com/api/queue/v1/task/U9AVNs4CTqCR6GwmvXjhhQ/runs/0/artifacts/public/DeepSpeech.0.9.0-alpha.2.nupkg automatically adds the client, @erksch can you test in your side?

You will need to change the default target to x64(of your example), I'll do it in a PR.",automatically client test side need change default target example,issue,negative,neutral,neutral,neutral,neutral,neutral
660409870,"> > `python3.7 DeepSpeech.py --train_files ../russian/clips/train.csv --dev_files ../russian/clips/dev.csv --test_files ../russian/clips/test.csv`
> 
> If you are training on russian, where is `--alphabet_config_path` specified?

It didn't described in DeepSpeech's tutorial. I put --alphabet_config_path in comand line with alphabet.txt, and it worked. Thank you very much.",python training tutorial put line worked thank much,issue,negative,positive,positive,positive,positive,positive
660368407,"Note that I'm only asking for silent operation when calling in via the API. Your shipped binaries can print messages as they please.

I have a multi-threaded process with each thread instantiating its own copy of the DeepSpeech model. These messages get repeatedly spammed to stderr for each instantiation (particularly bad with many cores/gpus) which isn't helpful and drowns out my own warning/error messages that I send to stderr. Redirecting is not a good option since there's inherent value in seeing stderr contents.

An alternative is that the caller provides a file descriptor or other abstraction (e.g. LogSink) into which the DeepSpeech API can write messages. At least that way the caller can decide what to do with the messages.",note silent operation calling via shipped print please process thread copy model get repeatedly particularly bad many helpful send good option since inherent value seeing content alternative caller file abstraction write least way caller decide,issue,positive,positive,neutral,neutral,positive,positive
660362253,"This is what we did at first. Consequence was loosing a lot of time asking again people to share proper version informations, so we are not really looking nicely at a flag that would be disabled by default.

Nothing stops you from redirecting `stderr`, so please document the usecase where this is a problem for you.


> The DeepSpeech implementation writes messages to stderr, even when there are no errors.

Printing runtime information on `stderr` is quite common, some people even use it for `usage` informations. Please note our exit code is reflecting proper status for binaries we ship.



> If it's important to print these messages, a `debug` or `verbose` flag (defaulting to false) might be appropriate.

If you really have a usecase where this is problematic, please don't hesitate to expose it. PRs are welcome, but I'm quite firmly against a default value where it hides informations ; though you could imagine a situation where the default behavior is **showing** this and API allows to hide.

Please also consider that adding this kind of API-level toggle means having support (+ tests) on all supported bindings.",first consequence loosing lot time people share proper version really looking nicely flag would disabled default nothing please document problem implementation even printing information quite common people even use usage please note exit code reflecting proper status ship important print verbose flag false might appropriate really problematic please hesitate expose welcome quite firmly default value though could imagine situation default behavior showing hide please also consider kind toggle support,issue,positive,positive,positive,positive,positive,positive
660360490,"Quick check, the built `libdeepspeech.so` looks fine:
```
alex@portable-alex:~/tmp/deepspeech/win$ strings cpu/libdeepspeech.so|grep v0.7
v0.7.4-0-gfcd9563f
alex@portable-alex:~/tmp/deepspeech/win$ strings cuda/libdeepspeech.so|grep v0.7
v0.7.4-0-gfcd9563f
alex@portable-alex:~/tmp/deepspeech/win$ strings tflite/libdeepspeech.so|grep v0.7
v0.7.4-0-gfcd9563f
alex@portable-alex:~/tmp/deepspeech/win$ ll
total 16M
drwxrwxr-x 1 alex alex  238 juil. 18 00:15 .
drwxr-xr-x 1 alex alex 1,5K juil. 18 00:14 ..
drwxrwxr-x 1 alex alex  172 juil. 18 00:15 cpu
drwxrwxr-x 1 alex alex  172 juil. 18 00:15 cuda
-rw-rw-r-- 1 alex alex 4,3M juin  19 00:46 native_client.amd64.cpu.win.tar.xz
-rw-rw-r-- 1 alex alex  11M juin  19 00:47 native_client.amd64.cuda.win.tar.xz
-rw-rw-r-- 1 alex alex 831K juin  19 00:47 native_client.amd64.tflite.win.tar.xz
drwxrwxr-x 1 alex alex  172 juil. 18 00:15 tflite
```

So without more context we can't:
 - know how you setup things
 - know how you perform the upgrade
 - know how you get this output
 - know the stack you are relying on

And thus decide if there's a legit issue on our side or not ...",quick check built fine total without context ca know setup know perform upgrade know get output know stack thus decide legit issue side,issue,negative,positive,positive,positive,positive,positive
660352851,Hard to help and diagnose if you dont give more context here... ,hard help diagnose dont give context,issue,negative,negative,negative,negative,negative,negative
660220959,"I tried it out with the current 0.7.4 models from the release page and one of the audio files from there.

```
TensorFlow: v2.2.0-17-g0854bb5188
DeepSpeech: v0.9.0-alpha.2-34-gdd20d35c
2020-07-17 09:48:31.981587-0700 deepspeech_ios_test[9411:91040] Initialized TensorFlow Lite runtime.
/private/var/containers/Bundle/Application/F5F8492E-D9B8-4BC4-AF46-29CEB23FC3A6/deepspeech_ios_test.app/4507-16021-0012.wav
read 8192 samples
(lldb)
```

And then comes this error 
```
Thread 5: EXC_BAD_ACCESS (code=1, address=0x177000075)
```
in this line of `DeepSpeech.swift`
```swift
178    public func feedAudioContent(buffer: UnsafeBufferPointer<Int16>) {
180        precondition(streamCtx != nil, ""calling method on invalidated Stream"")
181        
182        DS_FeedAudioContent(streamCtx, buffer.baseAddress, UInt32(buffer.count)) <<<<< Thread 5: EXC_BAD_ACCESS (code=1, address=0x177000075)
183   }
```

Just leaving this here, but I don't want to bother too much before this is even called finished :D

Update: A sorry I saw the version of DeepSpeech and I guess the models are not compatible.",tried current release page one audio lite read come error thread line swift public buffer precondition nil calling method stream thread leaving want bother much even finished update sorry saw version guess compatible,issue,negative,negative,neutral,neutral,negative,negative
660181722,"After lot of hacking, I've been able to rebuild locally outside of their docker (easier for playing with gdb), building and running against a pyenv-built python, and that builds reproduces the issue, so I'm preparing a debug build.",lot hacking able rebuild locally outside docker easier building running python issue build,issue,negative,positive,positive,positive,positive,positive
660134654,">  The lowest cudnn we checked with the images you build was: issue3088:7.4.2.24, could it be worth while to also check a build with 7.4.1 ?

Downgraded to 7.4.1.5:
```
tf-docker ~ > apt-cache policy libcudnn7
libcudnn7:
  Installed: 7.4.1.5-1+cuda10.0
  Candidate: 7.6.5.32-1+cuda10.2
  Version table:
     7.6.5.32-1+cuda10.2 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.5.32-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.5.32-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.4.38-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.4.38-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.3.30-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.3.30-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.2.24-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.2.24-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.1.34-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.1.34-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.0.64-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.6.0.64-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.5.1.10-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.5.1.10-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.5.0.56-1+cuda10.1 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.5.0.56-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.4.2.24-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
 *** 7.4.1.5-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
        100 /var/lib/dpkg/status
     7.3.1.20-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
     7.3.0.29-1+cuda10.0 500
        500 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages
```

Still blows up.",checked build issue could worth also check build policy candidate version table still,issue,negative,positive,positive,positive,positive,positive
660131480,"> hacking the stride value also seems to do something (obviously, I have no idea why):
> 
> ```
> diff --git a/training/deepspeech_training/util/feeding.py b/training/deepspeech_training/util/feeding.py
> index 4c9b681d..ae50e4f9 100644
> --- a/training/deepspeech_training/util/feeding.py
> +++ b/training/deepspeech_training/util/feeding.py
> @@ -33,7 +33,7 @@ def audio_to_features(audio, sample_rate, transcript=None, clock=0.0, train_phas
>  
>      spectrogram = contrib_audio.audio_spectrogram(audio,
>                                                    window_size=Config.audio_window_samples,
> -                                                  stride=Config.audio_step_samples,
> +                                                  stride=Config.audio_step_samples+1,
>                                                    magnitude_squared=True)
>  
>      if train_phase and augmentations is not None:
> ```

I tried this patch now, and that works for the small sets. The max_sequence_length for batch B has turned from 75 into 74 now.

But if I run the larger test set (train_differ_para_sorted_wav_filesize.log), it still blows up, now on files that end up having a max_sequence_length of 75 ...

[train_debug_As_Bs_Cs.log](https://github.com/mozilla/DeepSpeech/files/4938248/train_debug_As_Bs_Cs.log)
[train_debug_mini_As_Bs_Cs.log](https://github.com/mozilla/DeepSpeech/files/4938249/train_debug_mini_As_Bs_Cs.log)
[train_differ_para_sorted_wav_filesize.log](https://github.com/mozilla/DeepSpeech/files/4938251/train_differ_para_sorted_wav_filesize.log)
",hacking stride value also something obviously idea git index audio spectrogram audio none tried patch work small batch turned run test set still end,issue,negative,negative,negative,negative,negative,negative
660123479,">  The lowest cudnn we checked with the images you build was: issue3088:7.4.2.24, could it be worth while to also check a build with 7.4.1 ?

pretty sure i dont even need to rebuild, ill check that later",checked build issue could worth also check build pretty sure dont even need rebuild ill check later,issue,positive,positive,positive,positive,positive,positive
660122154,"> @reuben super awesome that you are working on this! This is actually perfect timing as we are looking for an offline speech recognition for iOS right now. I know it's not finished yet, but could you provide a small guide on how I could try it out, is the .so library already available somewhere? Maybe then I could also help with writing an example app, if you wish.

on taskcluster, if you browse to the iOS artifacts sections you should get it",super awesome working actually perfect timing looking speech recognition right know finished yet could provide small guide could try library already available somewhere maybe could also help writing example wish browse get,issue,positive,positive,positive,positive,positive,positive
660117768,"@reuben super awesome that you are working on this! This is actually perfect timing as we are looking for an offline speech recognition for iOS right now. I know it's not finished yet, but could you provide a small guide on how I could try it out, is the .so library already available somewhere? Maybe then I could also help with writing an example app, if you wish.",super awesome working actually perfect timing looking speech recognition right know finished yet could provide small guide could try library already available somewhere maybe could also help writing example wish,issue,positive,positive,positive,positive,positive,positive
660084345,"Hmm I finally figured out the probable cudnn version of the tensorflow/tensorflow:1.14.0-gpu-py3 image.
According to: https://hub.docker.com/layers/tensorflow/tensorflow/1.14.0-gpu-py3/images/sha256-e72e66b3dcb9c9e8f4e5703965ae1466b23fe8cad59e1c92c6e9fa58f8d81dc8?context=explore
it should be CUDA 10.0.130-1 with CUDNN 7.4.1.5-1.
The lowest cudnn we checked with the images you build was:  issue3088:7.4.2.24, could it be worth while to also check a build with 7.4.1 ?
I don't see anything very obviously related in the cudnn release notes on https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_7xx.html#rel_742 though.",finally figured probable version image according checked build issue could worth also check build see anything obviously related release though,issue,negative,positive,neutral,neutral,positive,positive
660058969,"I'm trying, but failing to so far, to build tf 1.15 pip with some debug enabled, outside of the docker setup they have, so I can at least get more insight on the offending call",trying failing far build pip outside docker setup least get insight call,issue,negative,negative,neutral,neutral,negative,negative
660037478,"OK, so I have tried extra drivers released before the infamous ""v431.36"": 410.93, 418.74, 418.88, 430.34.
None of them works for me.

",tried extra infamous none work,issue,negative,negative,negative,negative,negative,negative
659951452,"> I also printed the original shape, for batch B that is 75 which seems to match the 75 max_sequence_length in the exception from cudnn when things do crash.

I thought the same, but hacking and forcing +1 on `features_len`, the crash would happen on value 76, and previous values would become 75 without problem, it seems (also the error changed).",also printed original shape batch match exception crash thought hacking forcing crash would happen value previous would become without problem also error,issue,negative,positive,positive,positive,positive,positive
659676566,"> FTR the offending call is at https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/stream_executor/cuda/cuda_dnn.cc#L1785-L1798
> 
> And that's directly within libcudnn7 :/

Yeah that was likely and unfortunately there is no such things as a neat error message.



> Here also, report that driver v431.36 downgrade fixes the very similar error: https://stackoverflow.com/questions/62612226/tensorflow-check-failed-status-cudnn-status-success-7-vs-0failed-to-set-c

Hmmm dusted off my google-foo, but still could not find a linux download of v431.36.
However, the release date (for windows at least) for v431.36 seems to be 07-09-2019.
What I tested was 430.64 which is lower in version number, but later in release date: November 5, 2019.

So tomorrow I will see if I can test with: 430.40 which has release date: July 29, 2019, so both metrics are lower.",call directly within yeah likely unfortunately neat error message also report driver downgrade similar error still could find however release date least tested lower version number later release date tomorrow see test release date metric lower,issue,negative,negative,negative,negative,negative,negative
659673834,"> @applied-machinelearning I found that hack to help locally, after getting more repro:
> 
> ```
> tf-docker ~/ds > git diff
> diff --git a/training/deepspeech_training/util/feeding.py b/training/deepspeech_training/util/feeding.py
> index 4c9b681d..4cddca22 100644
> --- a/training/deepspeech_training/util/feeding.py
> +++ b/training/deepspeech_training/util/feeding.py
> @@ -48,7 +48,7 @@ def audio_to_features(audio, sample_rate, transcript=None, clock=0.0, train_phas
>      if train_phase and augmentations is not None:
>          features = apply_graph_augmentations('features', features, augmentations, transcript=transcript, clock=clock)
>  
> -    return features, tf.shape(input=features)[0]
> +    return features, tf.shape(input=features)[0] - 1
>  
>  
>  def audiofile_to_features(wav_filename, clock=0.0, train_phase=False, augmentations=None):
> ```
> 
> I can't explain yet why, and I'd like your feedback if you can corroborate if it helps on all your repro cases or not

So this one works for me as well.

I also printed the original shape, for batch B that is 75 which seems to match the 75 max_sequence_length in the exception from cudnn when things do crash.

[train_debug_mini_As_Bs_Cs.log](https://github.com/mozilla/DeepSpeech/files/4934188/train_debug_mini_As_Bs_Cs.log)
",found hack help locally getting git git index audio none return return ca explain yet like feedback corroborate one work well also printed original shape batch match exception crash,issue,positive,positive,positive,positive,positive,positive
659601421,"Thanks, we plan to have valgrind coverage, but this still require some CI work to be able to have it in a usable way (especially generating usable suppressions). In the meantime, feedback is always welcome.",thanks plan coverage still require work able usable way especially generating usable feedback always welcome,issue,positive,positive,positive,positive,positive,positive
659591713,"Thanks @lissyx for the detailed analysis.
Looks like 0.7.3 is pretty clean, and just some allocations in python that makes it seems like there is leakage.
I think we can close this issue.

For my use case, things should improve dramatically when I switch to 0.7.3.",thanks detailed analysis like pretty clean python like leakage think close issue use case improve dramatically switch,issue,positive,positive,positive,positive,positive,positive
659565708,"Here also, report that driver v431.36 downgrade fixes the very similar error: https://stackoverflow.com/questions/62612226/tensorflow-check-failed-status-cudnn-status-success-7-vs-0failed-to-set-c",also report driver downgrade similar error,issue,negative,neutral,neutral,neutral,neutral,neutral
659560549,"> The only issue is not being able to get ""convert_graphdef_memmapped_format"" via taskcluster, since that file is gone form the mozilla infrastructure for the 1.14 branch.

You can just rebuild it, it's a bit time consuming but not complicated



> Don't know the inner-workings of training on multi-gpu, but if it is interleaving the batches, with the very small test set, your second GPU could have batch B, but as that GPU's first step, so the special case could apply there. I wonder if it still works with multi-gpu if you repeat some of the other batches before batch B, so it will never be the first step of a GPU.

Yeah; but we still don't know what that special case here is",issue able get via since file gone form infrastructure branch rebuild bit time consuming complicated know training small test set second could batch first step special case could apply wonder still work repeat batch never first step yeah still know special case,issue,positive,positive,neutral,neutral,positive,positive
659559966,"hacking the stride value also seems to do something (obviously, I have no idea why):
```
diff --git a/training/deepspeech_training/util/feeding.py b/training/deepspeech_training/util/feeding.py
index 4c9b681d..ae50e4f9 100644
--- a/training/deepspeech_training/util/feeding.py
+++ b/training/deepspeech_training/util/feeding.py
@@ -33,7 +33,7 @@ def audio_to_features(audio, sample_rate, transcript=None, clock=0.0, train_phas
 
     spectrogram = contrib_audio.audio_spectrogram(audio,
                                                   window_size=Config.audio_window_samples,
-                                                  stride=Config.audio_step_samples,
+                                                  stride=Config.audio_step_samples+1,
                                                   magnitude_squared=True)
 
     if train_phase and augmentations is not None:
```",hacking stride value also something obviously idea git index audio spectrogram audio none,issue,negative,neutral,neutral,neutral,neutral,neutral
659556909,"> > On July 13, 2020 6:03:47 PM GMT+02:00, lissyx _**@**_.***> wrote: So maybe it was just luck or we lack another parameter. Please note we don't have the same GPUs, and so the same memory. Maybe it is why.
> > What we haven't tested, is TF14 builds with those cudnn version.
> 
> I can reproduce the issue here on 7.4 as well by limiting visible GPU to only one (number 0 or 1). When I expose both, it works.

Don't know the inner-workings of training on multi-gpu, but if it is interleaving the batches, with the very small test set, your second GPU could have batch B, but as that GPU's first step, so the special case could apply there. I wonder if it still works with multi-gpu if you repeat some of the other batches before batch B, so it will never be the first step of a GPU. 

BTW last few days I have trained all my datasets on the image based on tensorflow/tensorflow:1.14.0-gpu-py3 and I haven't had a problem. The only issue is not being able to get ""convert_graphdef_memmapped_format"" via taskcluster, since that file is gone form the mozilla infrastructure for the 1.14 branch.

> @applied-machinelearning I found that hack to help locally, after getting more repro:
> ... 
> I can't explain yet why, and I'd like your feedback if you can corroborate if it helps on all your repro cases or not

I will give that a shot this evening. :)
",wrote maybe luck lack another parameter please note memory maybe tested version reproduce issue well limiting visible one number expose work know training small test set second could batch first step special case could apply wonder still work repeat batch never first step last day trained image based problem issue able get via since file gone form infrastructure branch found hack help locally getting ca explain yet like feedback corroborate give shot evening,issue,positive,positive,neutral,neutral,positive,positive
659540278,"@applied-machinelearning I found that hack to help locally, after getting more repro:
```
tf-docker ~/ds > git diff
diff --git a/training/deepspeech_training/util/feeding.py b/training/deepspeech_training/util/feeding.py
index 4c9b681d..4cddca22 100644
--- a/training/deepspeech_training/util/feeding.py
+++ b/training/deepspeech_training/util/feeding.py
@@ -48,7 +48,7 @@ def audio_to_features(audio, sample_rate, transcript=None, clock=0.0, train_phas
     if train_phase and augmentations is not None:
         features = apply_graph_augmentations('features', features, augmentations, transcript=transcript, clock=clock)
 
-    return features, tf.shape(input=features)[0]
+    return features, tf.shape(input=features)[0] - 1
 
 
 def audiofile_to_features(wav_filename, clock=0.0, train_phase=False, augmentations=None):
```

I can't explain yet why, and I'd like your feedback if you can corroborate if it helps on all your repro cases or not",found hack help locally getting git git index audio none return return ca explain yet like feedback corroborate,issue,positive,neutral,neutral,neutral,neutral,neutral
659438792,"If I run it without a --checkpoint_dir specified, is it just going to load in some weights from before or is it a raw model architecture?",run without going load raw model architecture,issue,negative,negative,negative,negative,negative,negative
659406303,"> On July 13, 2020 6:03:47 PM GMT+02:00, lissyx ***@***.***> wrote: So maybe it was just luck or we lack another parameter. Please note we don't have the same GPUs, and so the same memory. Maybe it is why.
> What we haven't tested, is TF14 builds with those cudnn version.

I can reproduce the issue here on 7.4 as well by limiting visible GPU to only one (number 0 or 1). When I expose both, it works.",wrote maybe luck lack another parameter please note memory maybe tested version reproduce issue well limiting visible one number expose work,issue,positive,neutral,neutral,neutral,neutral,neutral
659344428,"This is a support request, please reach on Discourse and read the documentation. Checkpoints are released separately from the tensorflow model.",support request please reach discourse read documentation separately model,issue,positive,neutral,neutral,neutral,neutral,neutral
659316028,"@khu834 On current master, I really cannot find anything convincing me there is an actionable leakage on our side, using your repro steps.",khu current master really find anything convincing actionable leakage side,issue,negative,positive,positive,positive,positive,positive
659309241,"> Python/TFLite:
> 
> ```
> ==103994== LEAK SUMMARY:
> ==103994==    definitely lost: 0 bytes in 0 blocks
> ==103994==    indirectly lost: 0 bytes in 0 blocks
> ==103994==      possibly lost: 187,760 bytes in 97 blocks
> ==103994==    still reachable: 1,362,814 bytes in 983 blocks
> ==103994==         suppressed: 64 bytes in 2 blocks
> ```

And there is 0 possibly lost related to tensorflow or deepspeech, it's all malloc from python itself ...",leak summary definitely lost indirectly lost possibly lost still reachable suppressed possibly lost related python,issue,negative,neutral,neutral,neutral,neutral,neutral
659308473,"Python/TFLite:
```
==103994== LEAK SUMMARY:
==103994==    definitely lost: 0 bytes in 0 blocks
==103994==    indirectly lost: 0 bytes in 0 blocks
==103994==      possibly lost: 187,760 bytes in 97 blocks
==103994==    still reachable: 1,362,814 bytes in 983 blocks
==103994==         suppressed: 64 bytes in 2 blocks
```",leak summary definitely lost indirectly lost possibly lost still reachable suppressed,issue,negative,neutral,neutral,neutral,neutral,neutral
659302179,"Running valgrind on tflite runtime from C++, hacking `native_client/client.cc` to loop 5 times over model creation / deletion:
```
$ LD_LIBRARY_PATH=$(pwd)/tensorflow/bazel-bin/native_client/ valgrind --tool=memcheck --leak-check=full --leak-resolution=high --show-reachable=yes --track-origins=yes ./native_client/deepspeech
[...]
==100766== LEAK SUMMARY:
==100766==    definitely lost: 0 bytes in 0 blocks
==100766==    indirectly lost: 0 bytes in 0 blocks
==100766==      possibly lost: 0 bytes in 0 blocks
==100766==    still reachable: 5,457 bytes in 97 blocks
==100766==         suppressed: 0 bytes in 0 blocks
```",running hacking loop time model creation deletion leak summary definitely lost indirectly lost possibly lost still reachable suppressed,issue,negative,neutral,neutral,neutral,neutral,neutral
659300859,"Running valgrind on full-blown tensorflow runtime from C++, hacking `native_client/client.cc` to loop 5 times over model creation / deletion:
```
$ LD_LIBRARY_PATH=$(pwd)/tensorflow/bazel-bin/native_client/ valgrind --tool=memcheck --leak-check=full --leak-resolution=high --show-reachable=yes --track-origins=yes ./native_client/deepspeech
[...]
==97431== 22,584 bytes in 941 blocks are possibly lost in loss record 2,570 of 2,581   
==97431==    at 0x4838DEF: operator new(unsigned long) (vg_replace_malloc.c:342)                                                                                                                            
==97431==    by 0x8A68459: google::protobuf::RepeatedField<int>::Reserve(int) (repeated_field.h:1404)                                                                                                       
==97431==    by 0x8A681F9: google::protobuf::RepeatedField<int>::MergeFrom(google::protobuf::RepeatedField<int> const&) (repeated_field.h:1273)                                                                                                                                                                                                                                                                          
==97431==    by 0x86CF37F: tensorflow::AttrValue_ListValue::MergeFrom(tensorflow::AttrValue_ListValue const&) (attr_value.pb.cc:900)                                                                                                                                                                                                                                                                                     
==97431==    by 0x86D1CA2: tensorflow::AttrValue::MergeFrom(tensorflow::AttrValue const&) (attr_value.pb.cc:1814)                                                                                                                                                                                                                                                                                                        
==97431==    by 0x85DFA46: tensorflow::KernelDef_AttrConstraint::MergeFrom(tensorflow::KernelDef_AttrConstraint const&) (kernel_def.pb.cc:492)                                                                                                                                                                                                                                                                           
==97431==    by 0x85E50F0: google::protobuf::internal::GenericTypeHandler<tensorflow::KernelDef_AttrConstraint>::Merge(tensorflow::KernelDef_AttrConstraint const&, tensorflow::KernelDef_AttrConstraint*) (repeated_field.h:703)
==97431==    by 0x85E4E2B: void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::TypeHandler>(void**, void**, int, int) (repeated_field.h:1672)
==97431==    by 0x6EDAF4D: google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInternal(google::protobuf::internal::RepeatedPtrFieldBase const&, void (google::protobuf::internal::RepeatedPtrFieldBase::*)(void**, void**, int, int)) (repeated_field.h:1642)
==97431==    by 0x85E4AE1: void google::protobuf::internal::RepeatedPtrFieldBase::MergeFrom<google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::TypeHandler>(google::protobuf::internal::RepeatedPtrFieldBase const&) (repeated_field.h:1630)
==97431==    by 0x85E43AE: google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::MergeFrom(google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint> const&) (repeated_field.h:2128)
==97431==    by 0x85E4267: google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::RepeatedPtrField(google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint> const&) (repeated_field.h:1932)
[...]
==97431== LEAK SUMMARY:
==97431==    definitely lost: 0 bytes in 0 blocks
==97431==    indirectly lost: 0 bytes in 0 blocks
==97431==      possibly lost: 22,584 bytes in 941 blocks
==97431==    still reachable: 1,042,295 bytes in 14,319 blocks
==97431==                       of which reachable via heuristic:
==97431==                         newarray           : 3,416 bytes in 4 blocks
==97431==         suppressed: 0 bytes in 0 blocks
```",running hacking loop time model creation deletion possibly lost loss record operator new unsigned long void void void void void void void leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed,issue,negative,positive,neutral,neutral,positive,positive
659296230,"Full-blown TensorFlow debug build under Python 3.8 (debian/sid), with your code adapted to run 10 iterations:
```
47898 ==91349== LEAK SUMMARY:                                                                                                                                                                                                                                                                                                                                                                                            
47899 ==91349==    definitely lost: 32 bytes in 1 blocks                                                                                                                                                                                                                                                                                                                                                                 
47900 ==91349==    indirectly lost: 72 bytes in 3 blocks                                                                                                                                                                                                                                                                                                                                                                 
47901 ==91349==      possibly lost: 4,655,700 bytes in 2,305 blocks                                                                                                                                                                                                                                                                                                                                                      
47902 ==91349==    still reachable: 2,940,649 bytes in 26,755 blocks                                                                                                                                                                                                                                                                                                                                                     
47903 ==91349==                       of which reachable via heuristic:                                                                                                                                                                                                                                                                                                                                                  
47904 ==91349==                         newarray           : 6,096 bytes in 9 blocks                                                                                                                                                                                                                                                                                                                                     
47905 ==91349==         suppressed: 105,328 bytes in 260 blocks                                                                                                                                                                                                                                                                                                                                                          
```

About the possibly lost, here we have 4211064 bytes out of 4655700 just because of those harmless tensorflow threadpool related:
```
47870 ==91349== 2,105,352 bytes in 1 blocks are possibly lost in loss record 2,783 of 2,784                                                                                                                                                                                                                                                                                                                              
47871 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47872 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   
47873 ==91349==    by 0x93F2385: Eigen::MaxSizeVector<Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadData>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                       
47874 ==91349==    by 0x93F1ADF: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             
47875 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47876 ==91349==    by 0x7FD6211: tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tensorflow::Allocator*) (local_device.cc:94)                                                                                                                                                                                                                                  
47877 ==91349==    by 0x7FD5CA0: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (local_device.cc:145)                                                                                                                                                                                                                                                      
47878 ==91349==    by 0x8064BFE: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (threadpool_device.cc:52)                                                             
47879 ==91349==    by 0x8065FA5: std::_MakeUniq<tensorflow::ThreadPoolDevice>::__single_object std::make_unique<tensorflow::ThreadPoolDevice, tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality, tensorflow::Allocator*>(tensorflow::SessionOptions const&, st      d::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>&&, tensorflow::DeviceLocality&&, tensorflow::Allocator*&&) (unique_ptr.h:857)                                                                                                                                                                                          
47880 ==91349==    by 0x8065CA8: tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (threadpool_      device_factory.cc:63)                                                                                                                                                                                                                                                                                                                                                                                              
47881 ==91349==    by 0x7F64DC2: tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (device_factory.cc:129)  
47882 ==91349==    by 0x6672486: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:188)                                                                                                                                                                                                                                                          
47883 ==91349==                                                                                                                                                                                                                                                                                                                                                                                                          
47884 ==91349== 2,105,352 bytes in 1 blocks are possibly lost in loss record 2,784 of 2,784                                                                                                                                                                                                                                                                                                                              
47885 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47886 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   47887 ==91349==    by 0x93F2385: Eigen::MaxSizeVector<Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadData>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                       
47888 ==91349==    by 0x93F1ADF: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             47889 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                47890 ==91349==    by 0x8029738: tensorflow::NewThreadPoolFromSessionOptions(tensorflow::SessionOptions const&) (process_util.cc:164)                                                                                                                                                                                                                                                                                    
47891 ==91349==    by 0x665D2DC: tensorflow::(anonymous namespace)::GlobalThreadPool(tensorflow::SessionOptions const&) (direct_session.cc:138)                                                                                                                                                                                                                                                                          47892 ==91349==    by 0x665DB3D: tensorflow::DirectSession::DirectSession(tensorflow::SessionOptions const&, tensorflow::DeviceMgr const*, tensorflow::DirectSessionFactory*) (direct_session.cc:330)                                                                                                                                                                                                                    
47893 ==91349==    by 0x667255D: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:192)                                                                                                                                                                                                                                                          47894 ==91349==    by 0x80461C7: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (session.cc:94)                                                                                                                                                                                                                                                                                        47895 ==91349==    by 0x6655BBD: TFModelState::init(char const*) (tfmodelstate.cc:55)                                                                                                                                                                                                                                                                                                                                    
47896 ==91349==    by 0x664CF0B: DS_CreateModel (deepspeech.cc:298)                                                                                                                                                                                                                                                                                                                                                      
```

That leaves us 444996 bytes to explain.

Here are some 135438 from Python itself?:

```
47827 ==91349== 135,438 bytes in 68 blocks are possibly lost in loss record 2,780 of 2,784                                                                                                                                                                                                                                                                                                                               
47828 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47829 ==91349==    by 0x58BF63: PyUnicode_New (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                    
47830 ==91349==    by 0x57E689: PyUnicode_Substring (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                              
47831 ==91349==    by 0x500952: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47832 ==91349==    by 0x567005: _PyEval_EvalFrameDefault (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
47833 ==91349==    by 0x565161: _PyEval_EvalCodeWithName (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
47834 ==91349==    by 0x5F05D2: _PyFunction_Vectorcall (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                           
47835 ==91349==    by 0x566E35: _PyEval_EvalFrameDefault (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
47836 ==91349==    by 0x565161: _PyEval_EvalCodeWithName (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
47837 ==91349==    by 0x683C82: PyEval_EvalCode (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                  
47838 ==91349==    by 0x5FAAAF: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47839 ==91349==    by 0x5BFE5B: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
```

Then a few more, taking us down to 261222:

```
47683 ==91349== 48,336 bytes in 23 blocks are possibly lost in loss record 2,769 of 2,784                                                                                                                                                                                                                                                                                                                                
47684 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47685 ==91349==    by 0x5865B2: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47686 ==91349==    by 0x54BC94: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47687 ==91349==    by 0x54B2BE: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47688 ==91349==    by 0x54B8C2: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47689 ==91349==    by 0x54B411: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47690 ==91349==    by 0x54C340: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47691 ==91349==    by 0x678C3A: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47692 ==91349==    by 0x678F80: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47693 ==91349==    by 0x5BFBFB: ??? (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                                              
47694 ==91349==    by 0x56BCD6: _PyEval_EvalFrameDefault (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
47695 ==91349==    by 0x565161: _PyEval_EvalCodeWithName (in /usr/bin/python3.8)                                                                                                                                                                                                                                                                                                                                         
```

Then back to TensorFlow threadpool, so we reach 218214 bytes:
```
47652 ==91349== 43,008 bytes in 128 blocks are possibly lost in loss record 2,767 of 2,784                                                                                                                                                                                                                                                                                                                               
47653 ==91349==    at 0x483AB65: calloc (vg_replace_malloc.c:760)                                                                                                                                                                                                                                                                                                                                                        
47654 ==91349==    by 0x4012CE6: allocate_dtv (dl-tls.c:343)                                                                                                                                                                                                                                                                                                                                                             
47655 ==91349==    by 0x4012CE6: _dl_allocate_tls (dl-tls.c:589)                                                                                                                                                                                                                                                                                                                                                         
47656 ==91349==    by 0x487DB81: allocate_stack (allocatestack.c:622)                                                                                                                                                                                                                                                                                                                                                    
47657 ==91349==    by 0x487DB81: pthread_create@@GLIBC_2.2.5 (pthread_create.c:660)                                                                                                                                                                                                                                                                                                                                      
47658 ==91349==    by 0xBF56ED4: std::thread::_M_start_thread(std::unique_ptr<std::thread::_State, std::default_delete<std::thread::_State> >, void (*)()) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.28)                                                                                                                                                                                                            
47659 ==91349==    by 0x93DCA6E: std::thread::thread<std::function<void ()>&, , void>(std::function<void ()>&) (thread:130)                                                                                                                                                                                                                                                                                              
47660 ==91349==    by 0x93DB45F: tensorflow::(anonymous namespace)::StdThread::StdThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) (env.cc:60)                                                                                                                                                                   
47661 ==91349==    by 0x93DB837: tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) (env.cc:109)                                                                                                                                                                 
47662 ==91349==    by 0x8F37A3F: tensorflow::EnvWrapper::StartThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) (env.h:400)                                                                                                                                                                                       
47663 ==91349==    by 0x93F14FA: tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>) (threadpool.cc:54)                                                                                                                                                                                                                                                                                           
47664 ==91349==    by 0x93F1D27: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:57)                                                                                                                                                                                                                             
47665 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47666 ==91349==    by 0x8029738: tensorflow::NewThreadPoolFromSessionOptions(tensorflow::SessionOptions const&) (process_util.cc:164)
```

Then again, down to 150118:
```
47541 ==91349== 34,048 bytes in 128 blocks are possibly lost in loss record 2,760 of 2,784                                                                                                                                                                                                                                                                                                                               
47542 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47543 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   
47544 ==91349==    by 0x93F3637: Eigen::MaxSizeVector<unsigned int>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                                                   
47545 ==91349==    by 0x93F276F: void Eigen::MaxSizeVector<Eigen::MaxSizeVector<unsigned int> >::emplace_back<int>(int const&) (MaxSizeVector.h:92)                                                                                                                                                                                                                                                                      
47546 ==91349==    by 0x93F1C27: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:48)                                                                                                                                                                                                                             
47547 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47548 ==91349==    by 0x7FD6211: tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tensorflow::Allocator*) (local_device.cc:94)                                                                                                                                                                                                                                  
47549 ==91349==    by 0x7FD5CA0: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (local_device.cc:145)                                                                                                                                                                                                                                                      
47550 ==91349==    by 0x8064BFE: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (threadpool_device.cc:52)                                                             
47551 ==91349==    by 0x8065FA5: std::_MakeUniq<tensorflow::ThreadPoolDevice>::__single_object std::make_unique<tensorflow::ThreadPoolDevice, tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality, tensorflow::Allocator*>(tensorflow::SessionOptions const&, st      d::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>&&, tensorflow::DeviceLocality&&, tensorflow::Allocator*&&) (unique_ptr.h:857)                                                                                                                                                                                          
47552 ==91349==    by 0x8065CA8: tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (threadpool_      device_factory.cc:63)                                                                                                                                                                                                                                                                                                                                                                                              
47553 ==91349==    by 0x7F64DC2: tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (device_factory.cc:129)  
47554 ==91349==                                                                                                                                                                                                                                                                                                                                                                                                          
47555 ==91349== 34,048 bytes in 128 blocks are possibly lost in loss record 2,761 of 2,784                                                                                                                                                                                                                                                                                                                               
47556 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47557 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   
47558 ==91349==    by 0x93F3637: Eigen::MaxSizeVector<unsigned int>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                                                   
47559 ==91349==    by 0x93F276F: void Eigen::MaxSizeVector<Eigen::MaxSizeVector<unsigned int> >::emplace_back<int>(int const&) (MaxSizeVector.h:92)                                                                                                                                                                                                                                                                      
47560 ==91349==    by 0x93F1C27: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:48)                                                                                                                                                                                                                             
47561 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47562 ==91349==    by 0x8029738: tensorflow::NewThreadPoolFromSessionOptions(tensorflow::SessionOptions const&) (process_util.cc:164)                                                                                                                                                                                                                                                                                    
47563 ==91349==    by 0x665D2DC: tensorflow::(anonymous namespace)::GlobalThreadPool(tensorflow::SessionOptions const&) (direct_session.cc:138)                                                                                                                                                                                                                                                                          
47564 ==91349==    by 0x665DB3D: tensorflow::DirectSession::DirectSession(tensorflow::SessionOptions const&, tensorflow::DeviceMgr const*, tensorflow::DirectSessionFactory*) (direct_session.cc:330)                                                                                                                                                                                                                    
47565 ==91349==    by 0x667255D: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:192)                                                                                                                                                                                                                                                          
47566 ==91349==    by 0x80461C7: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (session.cc:94)                                                                                                                                                                                                                                                                                        
47567 ==91349==    by 0x6655BBD: TFModelState::init(char const*) (tfmodelstate.cc:55)                                                                                                                                                                                                                                                                                                                                    
```

Then tensorflow/protobuf, we reach 127534:
```
7361 ==91349== 22,584 bytes in 941 blocks are possibly lost in loss record 2,749 of 2,784                                                                                                                                                                                                                                                                                                                               47362 ==91349==    at 0x4838DEF: operator new(unsigned long) (vg_replace_malloc.c:342)                                                                                                                                                                                                                                                                                                                                   
47363 ==91349==    by 0x9717459: google::protobuf::RepeatedField<int>::Reserve(int) (repeated_field.h:1404)                                                                                                                                                                                                                                                                                                              47364 ==91349==    by 0x97171F9: google::protobuf::RepeatedField<int>::MergeFrom(google::protobuf::RepeatedField<int> const&) (repeated_field.h:1273)                                                                                                                                                                                                                                                                    47365 ==91349==    by 0x937E37F: tensorflow::AttrValue_ListValue::MergeFrom(tensorflow::AttrValue_ListValue const&) (attr_value.pb.cc:900)                                                                                                                                                                                                                                                                               47366 ==91349==    by 0x9380CA2: tensorflow::AttrValue::MergeFrom(tensorflow::AttrValue const&) (attr_value.pb.cc:1814)                                                                                                                                                                                                                                                                                                  
47367 ==91349==    by 0x928EA46: tensorflow::KernelDef_AttrConstraint::MergeFrom(tensorflow::KernelDef_AttrConstraint const&) (kernel_def.pb.cc:492)                                                                                                                                                                                                                                                                     47368 ==91349==    by 0x92940F0: google::protobuf::internal::GenericTypeHandler<tensorflow::KernelDef_AttrConstraint>::Merge(tensorflow::KernelDef_AttrConstraint const&, tensorflow::KernelDef_AttrConstraint*) (repeated_field.h:703)                                                                                                                                                                                  47369 ==91349==    by 0x9293E2B: void google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInnerLoop<google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::TypeHandler>(void**, void**, int, int) (repeated_field.h:1672)                                                                                                                                                                      47370 ==91349==    by 0x7B89F4D: google::protobuf::internal::RepeatedPtrFieldBase::MergeFromInternal(google::protobuf::internal::RepeatedPtrFieldBase const&, void (google::protobuf::internal::RepeatedPtrFieldBase::*)(void**, void**, int, int)) (repeated_field.h:1642)                                                                                                                                              
47371 ==91349==    by 0x9293AE1: void google::protobuf::internal::RepeatedPtrFieldBase::MergeFrom<google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::TypeHandler>(google::protobuf::internal::RepeatedPtrFieldBase const&) (repeated_field.h:1630)                                                                                                                                                47372 ==91349==    by 0x92933AE: google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::MergeFrom(google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint> const&) (repeated_field.h:2128)                                                                                                                                                                                            
47373 ==91349==    by 0x9293267: google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint>::RepeatedPtrField(google::protobuf::RepeatedPtrField<tensorflow::KernelDef_AttrConstraint> const&) (repeated_field.h:1932)
```


Then again TensorFlow threadpool, so we are at 78054 bytes:

```
47172 ==91349== 16,456 bytes in 1 blocks are possibly lost in loss record 2,736 of 2,784                                                                                                                                                                                                                                                                                                                                 47173 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        47174 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   47175 ==91349==    by 0x93F2385: Eigen::MaxSizeVector<Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadData>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                       
47176 ==91349==    by 0x93F1ADF: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             47177 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47178 ==91349==    by 0x93EE063: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) (threadpool.cc:90)                                                                                                                                                                                                            47179 ==91349==    by 0x804D1DE: tensorflow::(anonymous namespace)::GraphRunnerThreadPool() (single_threaded_cpu_device.cc:35)                                                                                                                                                                                                                                                                                           
47180 ==91349==    by 0x804D39F: tensorflow::(anonymous namespace)::SingleThreadedCpuDevice::SingleThreadedCpuDevice(tensorflow::Env*) (single_threaded_cpu_device.cc:49)                                                                                                                                                                                                                                                47181 ==91349==    by 0x804D77A: tensorflow::NewSingleThreadedCpuDevice(tensorflow::Env*) (single_threaded_cpu_device.cc:97)                                                                                                                                                                                                                                                                                             47182 ==91349==    by 0x7FC8E00: tensorflow::GraphRunner::GraphRunner(tensorflow::Env*) (graph_runner.cc:96)                                                                                                                                                                                                                                                                                                             47183 ==91349==    by 0x80B241E: tensorflow::ShapeRefiner::ShapeRefiner(int, tensorflow::OpRegistryInterface const*) (shape_refiner.cc:46)                                                                                                                                                                                                                                                                               47184 ==91349==    by 0x80C6E83: tensorflow::ConvertGraphDefToGraph(tensorflow::GraphConstructorOptions const&, tensorflow::GraphDef const&, tensorflow::Graph*) (graph_constructor.cc:1455)                                                                                                                                                                                                                             47185 ==91349==                                                                                                                                                                                                                                                                                                                                                                                                          
47186 ==91349== 16,512 bytes in 1 blocks are possibly lost in loss record 2,737 of 2,784                                                                                                                                                                                                                                                                                                                                 
47187 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47188 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   
47189 ==91349==    by 0x93F250F: Eigen::MaxSizeVector<Eigen::EventCount::Waiter>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                                      
47190 ==91349==    by 0x93F1B12: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             
47191 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47192 ==91349==    by 0x7FD6211: tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tensorflow::Allocator*) (local_device.cc:94)                                                                                                                                                                                                                                  
47193 ==91349==    by 0x7FD5CA0: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (local_device.cc:145)                                                                                                                                                                                                                                                      47194 ==91349==    by 0x8064BFE: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (threadpool_device.cc:52)                                                             
47195 ==91349==    by 0x8065FA5: std::_MakeUniq<tensorflow::ThreadPoolDevice>::__single_object std::make_unique<tensorflow::ThreadPoolDevice, tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality, tensorflow::Allocator*>(tensorflow::SessionOptions const&, st      d::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>&&, tensorflow::DeviceLocality&&, tensorflow::Allocator*&&) (unique_ptr.h:857)                                                                                                                                                                                          47196 ==91349==    by 0x8065CA8: tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (threadpool_      device_factory.cc:63)                                                                                                                                                                                                                                                                                                                                                                                              47197 ==91349==    by 0x7F64DC2: tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (device_factory.cc:129)  47198 ==91349==    by 0x6672486: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:188)                                                                                                                                                                                                                                                          47199 ==91349==                                                                                                                                                                                                                                                                                                                                                                                                          47200 ==91349== 16,512 bytes in 1 blocks are possibly lost in loss record 2,738 of 2,784                                                                                                                                                                                                                                                                                                                                 47201 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
47202 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   47203 ==91349==    by 0x93F250F: Eigen::MaxSizeVector<Eigen::EventCount::Waiter>::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                                      47204 ==91349==    by 0x93F1B12: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             47205 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                
47206 ==91349==    by 0x8029738: tensorflow::NewThreadPoolFromSessionOptions(tensorflow::SessionOptions const&) (process_util.cc:164)                                                                                                                                                                                                                                                                                    47207 ==91349==    by 0x665D2DC: tensorflow::(anonymous namespace)::GlobalThreadPool(tensorflow::SessionOptions const&) (direct_session.cc:138)                                                                                                                                                                                                                                                                          47208 ==91349==    by 0x665DB3D: tensorflow::DirectSession::DirectSession(tensorflow::SessionOptions const&, tensorflow::DeviceMgr const*, tensorflow::DirectSessionFactory*) (direct_session.cc:330)                                                                                                                                                                                                                    47209 ==91349==    by 0x667255D: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:192)                                                                                                                                                                                                                                                          
47210 ==91349==    by 0x80461C7: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (session.cc:94)                                                                                                                                                                                                                                                                                        47211 ==91349==    by 0x6655BBD: TFModelState::init(char const*) (tfmodelstate.cc:55)                                                                                                                                                                                                                                                                                                                                    
47212 ==91349==    by 0x664CF0B: DS_CreateModel (deepspeech.cc:298)
```

TensorFlow/protobuf, down to 69070 bytes:

```
46977 ==91349== 8,984 bytes in 303 blocks are possibly lost in loss record 2,723 of 2,784                                                                                                                                                                                                                                                                                                                                
46978 ==91349==    at 0x4838DEF: operator new(unsigned long) (vg_replace_malloc.c:342)                                                                                                                                                                                                                                                                                                                                   46979 ==91349==    by 0x9717459: google::protobuf::RepeatedField<int>::Reserve(int) (repeated_field.h:1404)                                                                                                                                                                                                                                                                                                              46980 ==91349==    by 0x9716D34: google::protobuf::RepeatedField<int>::Add(int const&) (repeated_field.h:1227)                                                                                                                                                                                                                                                                                                           46981 ==91349==    by 0x7C9177D: tensorflow::AttrValue_ListValue::add_type(tensorflow::DataType) (attr_value.pb.h:1029)                                                                                                                                                                                                                                                                                                  46982 ==91349==    by 0x8F6B8B9: tensorflow::(anonymous namespace)::FinalizeAttr(absl::string_view, tensorflow::OpDef*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*) (op_def_builder.cc:221)                                                                        46983 ==91349==    by 0x8F6EDF5: tensorflow::OpDefBuilder::Finalize(tensorflow::OpRegistrationData*) const (op_def_builder.cc:642)                                                                                                                                                                                                                                                                                       
46984 ==91349==    by 0x8F625A3: tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}::operator()(tensorflow::OpRegistrationData*) const (op.cc:299)                                                                                                                                              
46985 ==91349==    by 0x8F627EE: std::_Function_handler<tensorflow::Status (tensorflow::OpRegistrationData*), tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::OpRegistrationData*&&) (std_function.h:286)                                     
46986 ==91349==    by 0x8F63AC2: std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>::operator()(tensorflow::OpRegistrationData*) const (std_function.h:688)                                                                                                                                                                                                                                             
46987 ==91349==    by 0x8F61F43: tensorflow::OpRegistry::RegisterAlreadyLocked(std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) const (op.cc:236)                                                                                                                                                                                                                                             
46988 ==91349==    by 0x8F61CE0: tensorflow::OpRegistry::MustCallDeferred() const (op.cc:214)                                                                                                                                                                                                                                                                                                                            
46989 ==91349==    by 0x8F610CF: tensorflow::OpRegistry::LookUpSlow(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const (op.cc:111)
```

Another, we are at 65150 bytes:

```
46449 ==91349== 3,920 bytes in 98 blocks are possibly lost in loss record 2,687 of 2,784                                                                                                                                                                                                                                                                                                                                 46450 ==91349==    at 0x4838DEF: operator new(unsigned long) (vg_replace_malloc.c:342)                                                                                                                                                                                                                                                                                                                                   
46451 ==91349==    by 0x9717459: google::protobuf::RepeatedField<int>::Reserve(int) (repeated_field.h:1404)                                                                                                                                                                                                                                                                                                              46452 ==91349==    by 0x9716D34: google::protobuf::RepeatedField<int>::Add(int const&) (repeated_field.h:1227)                                                                                                                                                                                                                                                                                                           46453 ==91349==    by 0x7C9177D: tensorflow::AttrValue_ListValue::add_type(tensorflow::DataType) (attr_value.pb.h:1029)                                                                                                                                                                                                                                                                                                  46454 ==91349==    by 0x8F6A930: tensorflow::(anonymous namespace)::ProcessCompoundType(absl::string_view, tensorflow::AttrValue*) (op_def_builder.cc:135)                                                                                                                                                                                                                                                               46455 ==91349==    by 0x8F6AF3D: tensorflow::(anonymous namespace)::FinalizeAttr(absl::string_view, tensorflow::OpDef*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*) (op_def_builder.cc:181)                                                                        46456 ==91349==    by 0x8F6EDF5: tensorflow::OpDefBuilder::Finalize(tensorflow::OpRegistrationData*) const (op_def_builder.cc:642)                                                                                                                                                                                                                                                                                       
46457 ==91349==    by 0x8F625A3: tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}::operator()(tensorflow::OpRegistrationData*) const (op.cc:299)                                                                                                                                              
46458 ==91349==    by 0x8F627EE: std::_Function_handler<tensorflow::Status (tensorflow::OpRegistrationData*), tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::OpRegistrationData*&&) (std_function.h:286)                                     
46459 ==91349==    by 0x8F63AC2: std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>::operator()(tensorflow::OpRegistrationData*) const (std_function.h:688)                                                                                                                                                                                                                                             
46460 ==91349==    by 0x8F61F43: tensorflow::OpRegistry::RegisterAlreadyLocked(std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) const (op.cc:236)                                                                                                                                                                                                                                             
46461 ==91349==    by 0x8F61CE0: tensorflow::OpRegistry::MustCallDeferred() const (op.cc:214)
```

And again, 62022:

```
46318 ==91349== 3,128 bytes in 23 blocks are possibly lost in loss record 2,678 of 2,784                                                                                                                                                                                                                                                                                                                                 
46319 ==91349==    at 0x4838DEF: operator new(unsigned long) (vg_replace_malloc.c:342)                                                                                                                                                                                                                                                                                                                                   46320 ==91349==    by 0x9717459: google::protobuf::RepeatedField<int>::Reserve(int) (repeated_field.h:1404)                                                                                                                                                                                                                                                                                                              46321 ==91349==    by 0x9716D34: google::protobuf::RepeatedField<int>::Add(int const&) (repeated_field.h:1227)                                                                                                                                                                                                                                                                                                           46322 ==91349==    by 0x7C9177D: tensorflow::AttrValue_ListValue::add_type(tensorflow::DataType) (attr_value.pb.h:1029)                                                                                                                                                                                                                                                                                                  46323 ==91349==    by 0x8F6A875: tensorflow::(anonymous namespace)::ProcessCompoundType(absl::string_view, tensorflow::AttrValue*) (op_def_builder.cc:131)                                                                                                                                                                                                                                                               46324 ==91349==    by 0x8F6AF3D: tensorflow::(anonymous namespace)::FinalizeAttr(absl::string_view, tensorflow::OpDef*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >*) (op_def_builder.cc:181)                                                                        
46325 ==91349==    by 0x8F6EDF5: tensorflow::OpDefBuilder::Finalize(tensorflow::OpRegistrationData*) const (op_def_builder.cc:642)                                                                                                                                                                                                                                                                                       
46326 ==91349==    by 0x8F625A3: tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}::operator()(tensorflow::OpRegistrationData*) const (op.cc:299)                                                                                                                                              
46327 ==91349==    by 0x8F627EE: std::_Function_handler<tensorflow::Status (tensorflow::OpRegistrationData*), tensorflow::register_op::OpDefBuilderReceiver::OpDefBuilderReceiver(tensorflow::register_op::OpDefBuilderWrapper<true> const&)::{lambda(tensorflow::OpRegistrationData*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::OpRegistrationData*&&) (std_function.h:286)                                     
46328 ==91349==    by 0x8F63AC2: std::function<tensorflow::Status (tensorflow::OpRegistrationData*)>::operator()(tensorflow::OpRegistrationData*) const (std_function.h:688)                                                                                                                                                                                                                                             
46329 ==91349==    by 0x8F61F43: tensorflow::OpRegistry::RegisterAlreadyLocked(std::function<tensorflow::Status (tensorflow::OpRegistrationData*)> const&) const (op.cc:236)                                                                                                                                                                                                                                             
46330 ==91349==    by 0x8F61CE0: tensorflow::OpRegistry::MustCallDeferred() const (op.cc:214)
```

Then back to ThreadPool, down to 55862 bytes:

```
46290 ==91349== 3,080 bytes in 1 blocks are possibly lost in loss record 2,676 of 2,784                                                                                                                                                                                                                                                                                                                                  
46291 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        
46292 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   46293 ==91349==    by 0x93F2466: Eigen::MaxSizeVector<Eigen::MaxSizeVector<unsigned int> >::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                            46294 ==91349==    by 0x93F1AF7: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             
46295 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                46296 ==91349==    by 0x7FD6211: tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tensorflow::Allocator*) (local_device.cc:94)                                                                                                                                                                                                                                  46297 ==91349==    by 0x7FD5CA0: tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) (local_device.cc:145)                                                                                                                                                                                                                                                      
46298 ==91349==    by 0x8064BFE: tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*) (threadpool_device.cc:52)                                                             46299 ==91349==    by 0x8065FA5: std::_MakeUniq<tensorflow::ThreadPoolDevice>::__single_object std::make_unique<tensorflow::ThreadPoolDevice, tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality, tensorflow::Allocator*>(tensorflow::SessionOptions const&, st      d::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>&&, tensorflow::DeviceLocality&&, tensorflow::Allocator*&&) (unique_ptr.h:857)                                                                                                                                                                                          
46300 ==91349==    by 0x8065CA8: tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (threadpool_      device_factory.cc:63)                                                                                                                                                                                                                                                                                                                                                                                              46301 ==91349==    by 0x7F64DC2: tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) (device_factory.cc:129)  46302 ==91349==    by 0x6672486: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:188)                                                                                                                                                                                                                                                          46303 ==91349==                                                                                                                                                                                                                                                                                                                                                                                                          46304 ==91349== 3,080 bytes in 1 blocks are possibly lost in loss record 2,677 of 2,784                                                                                                                                                                                                                                                                                                                                  46305 ==91349==    at 0x483877F: malloc (vg_replace_malloc.c:307)                                                                                                                                                                                                                                                                                                                                                        46306 ==91349==    by 0x6769B81: Eigen::internal::handmade_aligned_malloc(unsigned long, unsigned long) (Memory.h:104)                                                                                                                                                                                                                                                                                                   46307 ==91349==    by 0x93F2466: Eigen::MaxSizeVector<Eigen::MaxSizeVector<unsigned int> >::MaxSizeVector(unsigned long) (MaxSizeVector.h:38)                                                                                                                                                                                                                                                                            46308 ==91349==    by 0x93F1AF7: Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) (NonBlockingThreadPool.h:37)                                                                                                                                                                                                                             46309 ==91349==    by 0x93EE248: tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) (threadpool.cc:102)                                                                                                                                                46310 ==91349==    by 0x8029738: tensorflow::NewThreadPoolFromSessionOptions(tensorflow::SessionOptions const&) (process_util.cc:164)                                                                                                                                                                                                                                                                                    46311 ==91349==    by 0x665D2DC: tensorflow::(anonymous namespace)::GlobalThreadPool(tensorflow::SessionOptions const&) (direct_session.cc:138)                                                                                                                                                                                                                                                                          46312 ==91349==    by 0x665DB3D: tensorflow::DirectSession::DirectSession(tensorflow::SessionOptions const&, tensorflow::DeviceMgr const*, tensorflow::DirectSessionFactory*) (direct_session.cc:330)                                                                                                                                                                                                                    46313 ==91349==    by 0x667255D: tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (direct_session.cc:192)                                                                                                                                                                                                                                                          46314 ==91349==    by 0x80461C7: tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) (session.cc:94)                                                                                                                                                                                                                                                                                        46315 ==91349==    by 0x6655BBD: TFModelState::init(char const*) (tfmodelstate.cc:55)                                                                                                                                                                                                                                                                                                                                    46316 ==91349==    by 0x664CF0B: DS_CreateModel (deepspeech.cc:298)
```

etc.",build python code run leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed possibly lost harmless related possibly lost loss record unsigned long unsigned long unsigned long bool char char char bool char char char long long char char char long long st char char char long long char char char char char char possibly lost loss record unsigned long unsigned long unsigned long bool char char char bool anonymous char leaf u explain python possibly lost loss record taking u possibly lost loss record back reach possibly lost loss record void void void void thread anonymous char char char void anonymous char char char void char char char void void bool char char char bool possibly lost loss record unsigned long unsigned long unsigned unsigned long void unsigned bool char char char bool char char char long long char char char long long st char char char long long char char char char char char possibly lost loss record unsigned long unsigned long unsigned unsigned long void unsigned bool char char char bool anonymous char reach possibly lost loss record operator new unsigned long void void void void void void void possibly lost loss record unsigned long unsigned long unsigned long bool char char char bool char char char anonymous anonymous possibly lost loss record unsigned long unsigned long unsigned long bool char char char bool char char char long long char char char long long st char char char long long char char char char char char possibly lost loss record unsigned long unsigned long unsigned long bool char char char bool anonymous char possibly lost loss record operator new unsigned long anonymous char char char char char char true lambda true lambda char char char another possibly lost loss record operator new unsigned long anonymous anonymous char char char char char char true lambda true lambda possibly lost loss record operator new unsigned long anonymous anonymous char char char char char char true lambda true lambda back possibly lost loss record unsigned long unsigned long unsigned unsigned long bool char char char bool char char char long long char char char long long st char char char long long char char char char char char possibly lost loss record unsigned long unsigned long unsigned unsigned long bool char char char bool anonymous char,issue,negative,negative,neutral,neutral,negative,negative
659286518,"@khu834 Even using the Python suppression list, there is still a ton of noise from Python itself, it's hard to really be sure where we are faulty here. Add in the equation the numerous ""harmless"" leaks from tensorflow ...",khu even python suppression list still ton noise python hard really sure faulty add equation numerous harmless,issue,negative,positive,neutral,neutral,positive,positive
658912672,"> Here's the full report, this is what I ran
> 
> ```
> valgrind --tool=memcheck --suppressions=valgrind-python.supp --leak-check=full --leak-resolution=high --show-reachable=yes  python3 -E -tt mem_test.py
> ```
> 
> using vanilla python3 and DS 0.7.3
> 
> https://github.com/khu834/deepspeech_valgrind/blob/master/log

Thanks, it's hard to make a call without debug symbols, but the situation looks much better than initially when looking at definitively lost and possibly lost sections.",full report ran python vanilla python thanks hard make call without situation much better initially looking definitively lost possibly lost,issue,negative,positive,positive,positive,positive,positive
658895994,"> > r0.8 branch PR merge still running on TaskCluster, but once it is merged it should produce docker image on Docker Hub
> 
> It should be good but there are issues on both Github and CircleCI, so nothing is starting for now, and I can't be sure it's all okay.

And it worked.",branch merge still running produce docker image docker hub good nothing starting ca sure worked,issue,negative,positive,positive,positive,positive,positive
658860811,"> r0.8 branch PR merge still running on TaskCluster, but once it is merged it should produce docker image on Docker Hub

It should be good but there are issues on both Github and CircleCI, so nothing is starting for now, and I can't be sure it's all okay.",branch merge still running produce docker image docker hub good nothing starting ca sure,issue,negative,positive,positive,positive,positive,positive
658816659,"So, #3157 merged, new alpha tagged:
 - master just built and deployed as `latest` on https://hub.docker.com/r/mozilla/deepspeech-train/tags
 - current master (after some new merge) building and is deployed
 - v0.9.0-alpha.3 tag building and is deployed
 - r0.8 branch PR merge still running on TaskCluster, but once it is merged it should produce docker image on Docker Hub",new alpha tagged master built latest current master new merge building tag building branch merge still running produce docker image docker hub,issue,negative,positive,positive,positive,positive,positive
658753836,"Thanks @lissyx. Just to add cElementTree.py is essentially just importing ElementTree

https://github.com/python/cpython/blob/master/Lib/xml/etree/cElementTree.py

```
# Deprecated alias for xml.etree.ElementTree

from xml.etree.ElementTree import *
```",thanks add essentially alias import,issue,negative,positive,neutral,neutral,positive,positive
658752408,"> ElementTree is a drop-in replacement of cElementTree. cElementTree exists only as an alias for ElementTree for compatibility reasons since Python 3.4+ provides C accelerated version by default.

So it should be safe to merge, thanks!",replacement alias compatibility since python accelerated version default safe merge thanks,issue,positive,positive,positive,positive,positive,positive
658752238,"> No local packages or working download links found for tensorflow==1.15.2
> error: Could not find suitable distribution for Requirement.parse('tensorflow==1.15.2')

Looks like you are running on a too recent version of Python.",local working link found error could find suitable distribution like running recent version python,issue,negative,positive,positive,positive,positive,positive
658750139,"ElementTree is a drop-in replacement of cElementTree. cElementTree exists only as an alias for ElementTree for compatibility reasons since Python 3.4+ provides C accelerated version by default. I tried running the script and it doesn't cause ImportError due to this PR though there are other import errors due to external dependencies since I have not installed deepsearch. I am getting below error on running `python setup.py install`

```
Processing dependencies for deepspeech-training==0.9.0a2
Searching for tensorflow==1.15.2
Reading https://pypi.org/simple/tensorflow/
No local packages or working download links found for tensorflow==1.15.2
error: Could not find suitable distribution for Requirement.parse('tensorflow==1.15.2')
```",replacement alias compatibility since python accelerated version default tried running script cause due though import due external since getting error running python install searching reading local working link found error could find suitable distribution,issue,negative,positive,neutral,neutral,positive,positive
658746550,@tirkarthi Have you ran the importers to make sure it is not breaking?,ran make sure breaking,issue,negative,positive,positive,positive,positive,positive
658734703,"> > > Adding here in case if anyone facing same issue in windows. Change the value in [VERSION](https://github.com/mozilla/DeepSpeech/blob/master/VERSION) file to 0.9.0-alpha.2. Seems like the path is not getting resolved properly in windows
> > 
> > 
> > Well, again, if you read the issue, this is exactly what turned out to be the root cause, as suspected: there is no support for symlinks on Windows, so it's failing.
> 
> Are there any other symlink issues that I might face? I use windows and am still in the priliminary stage. Just want to check the feasibility if I need to switch to linux

That's why we say we don't support Windows: we don't know. If you are willing to try and test, it might not be too complicated and a PR to ensure Windows support at training would be more than welcome.",case anyone facing issue change value version file like path getting resolved properly well read issue exactly turned root cause suspected support failing might face use still stage want check feasibility need switch say support know willing try test might complicated ensure support training would welcome,issue,positive,positive,positive,positive,positive,positive
658733864,"> > Adding here in case if anyone facing same issue in windows. Change the value in [VERSION](https://github.com/mozilla/DeepSpeech/blob/master/VERSION) file to 0.9.0-alpha.2. Seems like the path is not getting resolved properly in windows
> 
> Well, again, if you read the issue, this is exactly what turned out to be the root cause, as suspected: there is no support for symlinks on Windows, so it's failing.

Are there any other symlink issues that I might face? I use windows and am still in the priliminary stage. Just want to check the feasibility if I need to switch to linux",case anyone facing issue change value version file like path getting resolved properly well read issue exactly turned root cause suspected support failing might face use still stage want check feasibility need switch,issue,positive,positive,positive,positive,positive,positive
658715663,"> Adding here in case if anyone facing same issue in windows. Change the value in [VERSION](https://github.com/mozilla/DeepSpeech/blob/master/VERSION) file to 0.9.0-alpha.2. Seems like the path is not getting resolved properly in windows

Well, again, if you read the issue, this is exactly what turned out to be the root cause, as suspected: there is no support for symlinks on Windows, so it's failing.",case anyone facing issue change value version file like path getting resolved properly well read issue exactly turned root cause suspected support failing,issue,positive,positive,positive,positive,positive,positive
658715140,Adding here in case if anyone facing same issue in windows. Change the value in [VERSION](https://github.com/mozilla/DeepSpeech/blob/master/VERSION) file to 0.9.0-alpha.2. Seems like the path is not getting resolved properly in windows,case anyone facing issue change value version file like path getting resolved properly,issue,positive,neutral,neutral,neutral,neutral,neutral
658711902,"It's hard to document more than the obvious `pip install deepspeech`, but if you can send à pr to improves docs its always welcome. ",hard document obvious pip install send always welcome,issue,negative,positive,positive,positive,positive,positive
658696767,"Thanks for the quick response!
I just couldn't find the requirement and did not know what the proper way of communication was. Maybe it would be possible to include it in the docs. I was installing it with pip3.6 as only python 3.6 and 2.7 were included Buster for the Pi, maybe Noobs messed that up...
Anyways thanks for clearing it up :)
Best Regards ",thanks quick response could find requirement know proper way communication maybe would possible include pip python included buster pi maybe anyways thanks clearing best,issue,positive,positive,positive,positive,positive,positive
658682755,">  On PyPi the listed Python Versions are 2,7, 3.4, 3.5, 3.6.

This is likely:
 - out of date
 - cannot be specific to arm package

We only support Raspbian Buster's python version there, which is 3.7.

Can you please elaborate where the problem here is? It looks like it's all working, and our doc never mentions installing with `pip3.6`.",listed python likely date specific arm package support buster python version please elaborate problem like working doc never,issue,positive,positive,positive,positive,positive,positive
658676001,"Sorry, I only noticed the support link after posting the issue. My bad.",sorry support link posting issue bad,issue,negative,negative,negative,negative,negative,negative
658666815,"> by not adding the following statements and some dependency installations

As @DanBmh said, we have that now. Can you please be clear in your wording? I'm not a big fan of mind reading, so ""some dependency"" is not really helpful. ",following dependency said please clear wording big fan mind reading dependency really helpful,issue,positive,positive,neutral,neutral,positive,positive
658665944,"This is not a bug on our side and you already have a topic for support, please avoid spam.",bug side already topic support please avoid,issue,negative,neutral,neutral,neutral,neutral,neutral
658665463,"> > External scorer we ship is 900MB so we need to be careful there...
> 
> Exactly! Making copies is not an option.
> 
> You too are starting to grasp the issue here, its not that trivial :)

Don't package it as an asset in the application ? I know it's not the most convenient way to distribute, but for the moment, alternatives, as you said, are much worse.",external scorer ship need careful exactly making option starting grasp issue trivial package asset application know convenient way distribute moment said much worse,issue,negative,negative,neutral,neutral,negative,negative
658427309,"I think so, particularly with the wording of the docs. Of course, feel free to change my pull request's wording as much as you want. I just made a perfunctory edit.",think particularly wording course feel free change pull request wording much want made perfunctory edit,issue,positive,positive,positive,positive,positive,positive
658351846,"What version are you using?
I already added the KenLM building part some time ago to the `Dockerfile.train.tmpl` file.",version already added building part time ago file,issue,negative,neutral,neutral,neutral,neutral,neutral
658321333,"> External scorer we ship is 900MB so we need to be careful there...

Exactly! Making copies is not an option. 

You too are starting to grasp the issue here, its not that trivial :)

",external scorer ship need careful exactly making option starting grasp issue trivial,issue,negative,positive,neutral,neutral,positive,positive
658114004,"If you are able to assemble a patch set that improves behavior, you are welcome, though. ",able assemble patch set behavior welcome though,issue,negative,positive,positive,positive,positive,positive
658061347,"> Apps delivered through the app store can only access assets through the AssetManager. These files are not kept individually on the filesystem. They can only be accessed through limited means.

Thanks, i know that, but you can easily download and place those files in your app storage directory, it works very well. 

> Note that whatever mechanism is added, it needs to work for everything that currently relies on a system file path, so Scorer and Alphabet would also need to be enhanced.

Yes, you are starting to grasp the issue here, its not that trivial.

External scorer we ship is 900MB so we need to be careful there... ",store access asset kept individually limited thanks know easily place storage directory work well note whatever mechanism added need work everything currently system file path scorer alphabet would also need enhanced yes starting grasp issue trivial external scorer ship need careful,issue,positive,positive,neutral,neutral,positive,positive
658050984,"@lissyx Apps delivered through the app store can only access assets through the AssetManager. These files are not kept individually on the filesystem. They can only be accessed through limited means. See https://developer.android.com/reference/kotlin/android/content/res/AssetManager The ""filename"" in the docs refers to a virtual, relative path into the ""assets"" blob. Its not something one can fopen in C. 

@reuben I think MappedByteBuffer should be fine too. It looks like a MappedByteBuffer can be obtained through an AssetFileDescriptor. In fact I am already doing this for other TFL models.

```
    public MappedByteBuffer mapAssetFD(AssetFileDescriptor afd) throws IOException {
        FileInputStream inputStream = afd.createInputStream();
        long startOffset = afd.getStartOffset();
        long declaredLength = afd.getDeclaredLength();

        FileChannel fileChannel = inputStream.getChannel();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
    }
```

Note that whatever mechanism is added, it needs to work for everything that currently relies on a system file path, so Scorer and Alphabet would also need to be enhanced. 

I would recommend looking into what NDK api is available to make this easier; https://developer.android.com/ndk/reference/group/asset",store access asset kept individually limited see virtual relative path asset blob something one think fine like fact already public long long return note whatever mechanism added need work everything currently system file path scorer alphabet would also need enhanced would recommend looking available make easier,issue,positive,positive,neutral,neutral,positive,positive
658022656,"As this is not a bug or feature request for this repo (we reserve issues for bug and/or feature requests), could you take this admittedly interesting issue to [discourse](https://discourse.mozilla.org/c/deep-speech/247)?",bug feature request reserve bug feature could take admittedly interesting issue discourse,issue,negative,positive,positive,positive,positive,positive
657952978,"I'm also trying to use hinting and substitution methods to rectify errors and improve recognition. I'm using deep speech model only as ASR. I've used deep speech 2 model to build my own pbm and scorer as I'm trying to improvise the ASR for Hindi language. I'm facing issues like while saying ""Haa"", the model is only catching ""a"". Need to rectify that, can you please suggest how can I implement 'hints' or 'substitution' for that.",also trying use substitution rectify improve recognition deep speech model used deep speech model build scorer trying improvise language facing like saying model catching need rectify please suggest implement,issue,positive,positive,positive,positive,positive,positive
657723563,"Both options are supported by the training code, but if the CV2 importer produces relative paths then I guess we shouldn't be saying that it produces absolute paths.",training code importer relative guess saying absolute,issue,negative,positive,neutral,neutral,positive,positive
657688679,"

On July 13, 2020 6:03:47 PM GMT+02:00, lissyx <notifications@github.com> wrote:
>So maybe it was just luck or we lack another parameter. Please note we
>don't have the same GPUs, and so the same memory. Maybe it is why.

What we haven't tested, is TF14 builds with those cudnn version.
",wrote maybe luck lack another parameter please note memory maybe tested version,issue,negative,neutral,neutral,neutral,neutral,neutral
657649836,"There's also a constructor that takes a `java.nio.MappedByteBuffer`, maybe that is enough?",also constructor maybe enough,issue,negative,neutral,neutral,neutral,neutral,neutral
657647282,"So maybe it was just luck or we lack another parameter. Please note we don't have the same GPUs, and so the same memory. Maybe it is why.",maybe luck lack another parameter please note memory maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
657644145,"> This doesn't work in a production environment where the Android app may not be able to provide a ""path"".

Please document this usecase, this is not one we got any report from.


> Please add one of these options.

Adding those will impair the ability to perform mmap operation and it does have a very negative impact on the performances.",work production environment android may able provide path please document one got report please add one impair ability perform operation negative impact,issue,negative,positive,neutral,neutral,positive,positive
657538749,"@dabinat tagging you because you mentioned interest in these bindings in the CoreML issue, in case you have anything to mention regarding the design of the bindings here.",interest issue case anything mention regarding design,issue,negative,neutral,neutral,neutral,neutral,neutral
657473409,"@lissyx 

My results are different, logs are attached.:
* libcudnn 7.6.5.32: fail
* libcudnn 7.5.1.10: fail
* libcudnn 7.4.2.24: fail
[issue3088_7.6.5.32.log](https://github.com/mozilla/DeepSpeech/files/4911822/issue3088_7.6.5.32.log)
[issue3088_7.5.1.10.log](https://github.com/mozilla/DeepSpeech/files/4911823/issue3088_7.5.1.10.log)
[issue3088_7.4.2.24.log](https://github.com/mozilla/DeepSpeech/files/4911824/issue3088_7.4.2.24.log)",different attached fail fail fail log log log,issue,negative,negative,negative,negative,negative,negative
657467580,"> I'm new to DeepSpeech, but I noticed when following the training instructions that the filenames _appear_ to be relative paths in the CSV. Let me know if I'm misinterpreting.
> 
> Thanks!

What makes you think of that? I do use absolute path without any issue.",new following training relative let know thanks think use absolute path without issue,issue,negative,positive,positive,positive,positive,positive
657123839,Looks like adding Xcode to the worker brings the free space to under 10GB which stops the taskcluster client from picking up any jobs... Resizing the partition does not seem to work. My next step will be to create a worker from scratch with a larger disk image.,like worker free space client partition seem work next step create worker scratch disk image,issue,positive,positive,positive,positive,positive,positive
657121869,"Thanks, ill have à close look next week. We've reworked some part of our ci so hopefully we might be able to easily add valgrind support in the future ",thanks ill close look next week reworked part hopefully might able easily add support future,issue,positive,positive,positive,positive,positive,positive
657099555,"Here's the full report, this is what I ran
```
valgrind --tool=memcheck --suppressions=valgrind-python.supp --leak-check=full --leak-resolution=high --show-reachable=yes  python3 -E -tt mem_test.py
```
using vanilla python3 and DS 0.7.3

https://github.com/khu834/deepspeech_valgrind/blob/master/log",full report ran python vanilla python,issue,negative,positive,positive,positive,positive,positive
656867100,"> Great work @lissyx !
> Will see if I can find some time this weekend to see if I can get that stuff to work .
> 
> Was 7.4.2.24 the last of the cudnn 7.4 versions ?
> That would suggest it was introduced somewhere in 7.5 series.

It could still be in a lot of places, who knows exactly. But at least even if inconvenient it might help unblocking",great work see find time weekend see get stuff work last would suggest somewhere series could still lot exactly least even inconvenient might help,issue,positive,negative,neutral,neutral,negative,negative
656861484,"Great work @lissyx !
Will see if I can find some time this weekend to see if I can get that stuff to work .

Was 7.4.2.24 the last of the cudnn 7.4 versions ?
That would suggest it was introduced somewhere in 7.5 series.",great work see find time weekend see get stuff work last would suggest somewhere series,issue,positive,positive,positive,positive,positive,positive
656805582,"I had some time to run some more tests today  (with master about two days ago).

This time an epoch did take about 4:30min on average. I also tried different dropout values:
* with `--augment dropout[p=1,rate=0.05]` which I thought should match `--augmentation_spec_dropout_keeprate 0.95` (did this change?) the network only learned for two epochs, so it almost trained nothing. 
* also  `--augment dropout[p=0.5,rate=0.05]` did produce really poor results (test loss: 43.882633).",time run today master two day ago time epoch take min average also tried different dropout augment dropout thought match change network learned two almost trained nothing also augment dropout produce really poor test loss,issue,negative,negative,negative,negative,negative,negative
656765866,"@applied-machinelearning It would be awesome if you could cross-check on your side, with just varying the cudnn version we limit the risks of the issue being just masked by different tensorflow version.",would awesome could side version limit issue masked different version,issue,positive,positive,positive,positive,positive,positive
656761723,"To repro the issue:
 - fetch https://drive.google.com/file/d/1nmMj04FgIL_WBoxemT-7O9y4Qm4sgNDL/view?usp=sharing (contains everything, data, tensorflow wheels)
 - `docker build -f Dockerfile.deepspeech-v0.7.4-reduced --build-arg cudnn=7.4.2.24 . --tag issue3088:7.4.2.24`
 - `docker build -f Dockerfile.deepspeech-v0.7.4-reduced --build-arg cudnn=7.5.1.10 . --tag issue3088:7.5.1.10`
 - `docker build -f Dockerfile.deepspeech-v0.7.4-reduced --build-arg cudnn=7.6.5.32 . --tag issue3088:7.6.5.32`
 - `docker run --runtime=nvidia --rm issue3088:7.6.5.32`
 - `docker run --runtime=nvidia --rm issue3088:7.5.1.10`
 - `docker run --runtime=nvidia --rm issue3088:7.4.2.24`
",issue fetch everything data docker build tag issue docker build tag issue docker build tag issue docker run issue docker run issue docker run issue,issue,negative,neutral,neutral,neutral,neutral,neutral
656760294,"> So, TensorFlow r1.15.2 CUDA 10.0, with host driver 440.100:
> 
>     * libcudnn 7.6.5.32: fail
> 
>     * libcudnn 7.5.1.10: fail
> 
>     * libcudnn 7.4.2.24: success

To build the TensorFlow wheels:
 - `git clone https://github.com/tensorflow/tensorflow --branch r1.15`
 - apply the patch (just to build against 18.04, skip tests)
    - [build-tf-py3.patch.txt](https://github.com/mozilla/DeepSpeech/files/4904293/build-tf-py3.patch.txt)
 - in `tensorflow/tools/ci_build/` run:
   - `CI_DOCKER_BUILD_EXTRA_PARAMS=""--build-arg cudnn=7.4.2.24"" CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.6"" BUILD_TAG=tf-py3-cudnn-7.4.2.24 ./ci_build.sh gpu tensorflow/tools/ci_build/builds/pip.sh gpu -c opt --config=cuda`
`CI_DOCKER_BUILD_EXTRA_PARAMS=""--build-arg cudnn=7.5.1.10"" CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.6"" BUILD_TAG=tf-py3-cudnn-7.5.1.10 ./ci_build.sh gpu tensorflow/tools/ci_build/builds/pip.sh gpu -c opt --config=cuda`
    - `CI_DOCKER_BUILD_EXTRA_PARAMS=""--build-arg cudnn=7.6.5.32"" CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.6"" BUILD_TAG=tf-py3-cudnn-7.6.5.32 ./ci_build.sh gpu tensorflow/tools/ci_build/builds/pip.sh gpu -c opt --config=cuda`
 - in tensorflow's root directory, for each build, collect `pip_test/whl/tensorflow_gpu-1.15.3-cp36-cp36m-manylinux1_x86_64.whl`",host driver fail fail success build git clone branch apply patch build skip run opt opt opt root directory build collect,issue,negative,negative,negative,negative,negative,negative
656757467,"So, TensorFlow r1.15.2 CUDA 10.0, with host driver 440.100:
 - libcudnn 7.6.5.32: fail
 - libcudnn 7.5.1.10: fail
 - libcudnn 7.4.2.24: success",host driver fail fail success,issue,negative,negative,negative,negative,negative,negative
656739122,"Would it be an idea to have just the more general option to not sort csv's and use them as ordered, then you can manually use any order you like with just one extra option. I just needed to use this to kind of bisect an issue around (probably) cudnn versions blowing up on certain samples.

Can make up a patch for this and send a pull request, but the naming for such an option doesn't seem to be very straight forward.
Something like:
--[no]sample_sort, reorder train, dev and test samples by wav_filesize (default: 'true') ?
",would idea general option sort use ordered manually use order like one extra option use kind bisect issue around probably blowing certain make patch send pull request naming option seem straight forward something like reorder train dev test default,issue,positive,positive,positive,positive,positive,positive
656727547,"Ok, required a bit of hacking but I leveraged TensorFlow's CI builds script to produce some 1.15.2 CUDA-enabled python 3.6 wheels with different cudnn7 linkage, currently I have 7.4 done, 7.5 in progress and soon finished. Next step are:
 - install 7.6 of those wheels in your image
 - reproduce the issue (hopefully)
 - redo with 7.5 and 7.4 to assert.",bit hacking script produce python different linkage currently done progress soon finished next step install image reproduce issue hopefully redo assert,issue,positive,neutral,neutral,neutral,neutral,neutral
656696498,"Sure @kdavis-mozilla , If that the norm being followed,  I will move it to discourse. Thank you for your response!",sure norm move discourse thank response,issue,positive,positive,positive,positive,positive,positive
656692121,"@harmandeepsinghkalsi As we reserve GitHub issues for bugs and feature requests, I'm wondering fi you could take this support question over to [discourse](https://discourse.mozilla.org/c/deep-speech/247). Thanks.",reserve feature wondering fi could take support question discourse thanks,issue,positive,positive,positive,positive,positive,positive
656643203,"Updated the table above, I think I'm convinced enough to say that the TF14 image doesn't have the problem.
Hope you succeed in pinning it to a particular cudnn version.",table think convinced enough say image problem hope succeed pinning particular version,issue,positive,positive,neutral,neutral,positive,positive
656588378,"I just verified and I repro with cudnn v7.6.1 as well. I think I should try and rebuild tf 1.15.2 docker with cudnn 7.6, 7.5 and 7.4 to assert here.",well think try rebuild docker assert,issue,negative,neutral,neutral,neutral,neutral,neutral
656583170,"I ran the test with different drivers, preliminary results (will do a long test after this):

| Nvidia host driver | docker base image                    | short tests | long test |
|--------------------|--------------------------------------|-------------|-----------|
| 440.100            | tensorflow/tensorflow:1.14.0-gpu-py3 | worked      |           |
| 440.100            | tensorflow/tensorflow:1.15.2-gpu-py3 | failed      |           |
| 430.64             | tensorflow/tensorflow:1.14.0-gpu-py3 | worked      |           |
| 430.64             | tensorflow/tensorflow:1.15.2-gpu-py3 | failed      |           |
| 450.57             | tensorflow/tensorflow:1.14.0-gpu-py3 | worked      | worked       |
| 450.57             | tensorflow/tensorflow:1.15.2-gpu-py3 | failed      | failed      |

440.100 was the driver I was using originally.
430.64 the driver downloadable just below the 431.36 that was reported as working on the TF forum (could be the versioning of Nvidia is different so it is actually not below 431.36, but it was my best guess).
450.57 the latest stable driver released yesterday.

So from this I would take that the host driver version doesn't matter.
And I haven't been able to prove that the TF14 image doesn't work :)

Will start a long test now with the TF14 image.
",ran test different preliminary long test host driver docker base image short long test worked worked worked worked driver originally driver working forum could different actually best guess latest stable driver yesterday would take host driver version matter able prove image work start long test image,issue,positive,positive,positive,positive,positive,positive
656525230,"> Hmm a bit busy and tired this evening, so I will postpone most testing till tomorrow, but I have done some tests with tensorflow/tensorflow:1.14.0-gpu-py3 and the 440.100 driver (the one I used with the failing tf1.15 image tests as well).
> 
> Done all tests except the full dataset one (so 1500, the 3x32 batches and the 3x2 batches) and all succeed with the tf-1.14 image, so I think you are correct. Still debatable if its TF or cudnn, but if I would have to bet, I would bet on the different cudnn version.
> 
> Will test the driver downgrade tomorrow and after that a run on the full dataset.

OK, good to know we make progress. I'm trying to check how sequence_length variations are related ",bit busy tired evening postpone testing till tomorrow done driver one used failing image well done except full one succeed image think correct still debatable would bet would bet different version test driver downgrade tomorrow run full good know make progress trying check related,issue,negative,positive,positive,positive,positive,positive
656359128,"Hmm a bit busy and tired this evening, so I will postpone most testing till tomorrow, but I have done some tests with tensorflow/tensorflow:1.14.0-gpu-py3 and the 440.100 driver (the one I used with the failing tf1.15 image tests as well).

Done all tests except the full dataset one (so 1500, the 3x32 batches and the 3x2 batches) and all succeed with the tf-1.14 image, so I think you are correct. Still debatable if its TF or cudnn, but if I would have to bet, I would bet on the different cudnn version.

Will test the driver downgrade tomorrow and after that a run on the full dataset.",bit busy tired evening postpone testing till tomorrow done driver one used failing image well done except full one succeed image think correct still debatable would bet would bet different version test driver downgrade tomorrow run full,issue,negative,positive,neutral,neutral,positive,positive
656329692,"> Okay, seems to be working now but I got an error for `numpy`. Is this a problem because of windows or can I fix it by chaning the version? ` Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-0.7.4-py3.6.egg Processing dependencies for deepspeech-training==0.7.4 error: numpy 1.14.4 is installed but numpy<2.0,>=1.16.0 is required by {'tensorflow'}`

Well you should change the deps against numpy. Again, not supported setup, it's not surprising, you need to check what needs to be the minimum version to get existing numpy wheel for this windows + arch + python combo and adjust.

If you get to training working, it'd be good to send PR to fix those issues: we are not users of Windows, all our training is done on linux, so it's hard for us to focus time on that, but if you get it to work, we can add it to CI and ensure it does not regress.",working got error problem fix version egg error well change setup surprising need check need minimum version get wheel arch python adjust get training working good send fix training done hard u focus time get work add ensure regress,issue,negative,positive,positive,positive,positive,positive
656298466,"Okay, seems to be working now but I got an error for `numpy`. Is this a problem because of windows or can I fix it by chaning the version? `
Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-0.7.4-py3.6.egg
Processing dependencies for deepspeech-training==0.7.4
error: numpy 1.14.4 is installed but numpy<2.0,>=1.16.0 is required by {'tensorflow'}`",working got error problem fix version egg error,issue,negative,neutral,neutral,neutral,neutral,neutral
656272653,"> > And what code for 'version_file / open(str())` ?
> 
> `def main(): version_file = os.path.join(os.path.dirname(__file__), 'VERSION') with open(version_file) as fin: version = fin.read().strip()`

```
def main():
    version_file = Path(__file__).parent / 'training' / 'deepspeech_training' / 'VERSION'
```

Should do it.
",code open main open fin version main path,issue,negative,positive,neutral,neutral,positive,positive
656271230,"> > It means the `VERSION` file. As far as I saw it tries to read the file, should get `0.7.4` and than tries to install this version of ds_ctcdecoder
> 
> I'm sorry, you are not precise here. Root file or not root file? It should **be a symlink**. `VERSION` being a symlink and your system not supporting symlinks is the only explanation that makes sense so far.
> 
> So please make an effort and be precise, I'm spending time to help you on an unsupported system.

It is also consistent with the fact it was working on 0.7.3 and not anymore on 0.7.4, explicitely because this is when we changed the symlinks directions.",version file far saw read file get install version sorry precise root file root file version system supporting explanation sense far please make effort precise spending time help unsupported system also consistent fact working,issue,positive,positive,positive,positive,positive,positive
656269107,"> It means the `VERSION` file. As far as I saw it tries to read the file, should get `0.7.4` and than tries to install this version of ds_ctcdecoder

I'm sorry, you are not precise here. Root file or not root file? It should **be a symlink**. `VERSION` being a symlink and your system not supporting symlinks is the only explanation that makes sense so far.

So please make an effort and be precise, I'm spending time to help you on an unsupported system.",version file far saw read file get install version sorry precise root file root file version system supporting explanation sense far please make effort precise spending time help unsupported system,issue,positive,positive,positive,positive,positive,positive
656268009,"It means the `VERSION` file. As far as I saw it tries to read the file, should get `0.7.4` and than tries to install this version of ds_ctcdecoder",version file far saw read file get install version,issue,negative,positive,neutral,neutral,positive,positive
656265792,"> When I flipped the direction of the version symlinks I had to reference `training/deepspeech_training/VERSION` directly in a bunch of places to get Windows working. I didn't do `/setup.py` because we don't support/test training on Windows, but maybe a similar change is needed there.

That's the only reasonnable explanation, we are reading the `/VERSION` symlink content, which is `training/deepspeech_training/VERSION`.

Yet, earlier, @SirZontax said:
> Yes VERSION is a file and that is it's content: 0.7.4

So, in this answer, does `VERSION` means the `VERSION` file at the root or `training/deepspeech_training/VERSION` ?
If it's the root, it should not be a file, but a symlink, and we are back to the begining: training on Windows is not supported, please use some shell (msys2 e.g.) and enable symlinks.",direction version reference directly bunch get working training maybe similar change explanation reading content yet said yes version file content answer version version file root root file back training please use shell enable,issue,positive,positive,neutral,neutral,positive,positive
656264767,">And what code for 'version_file / open(str())` ?

`def main():
    version_file = os.path.join(os.path.dirname(__file__), 'VERSION')
    with open(version_file) as fin:
        version = fin.read().strip()`
",code open main open fin version,issue,negative,positive,neutral,neutral,positive,positive
656264222,"When I flipped the direction of the version symlinks I had to reference `training/deepspeech_training/VERSION` directly in a bunch of places to get Windows working. I didn't do `/setup.py` because we don't support/test training on Windows, but maybe a similar change is needed there.",direction version reference directly bunch get working training maybe similar change,issue,negative,positive,neutral,neutral,positive,positive
656263826,"> ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION) (from versions: 0.7.0, 0.7.1, 0.7.3, 0.7.4, 0.8.0a3, 0.8.0a4, 0.8.0a5, 0.8.0a6, 0.9.0a0, 0.9.0a1, 0.9.0a2)
> ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION)

And what code for `version_file` / `open(str())` ?",error could find version requirement error matching distribution found code open,issue,negative,neutral,neutral,neutral,neutral,neutral
656262589,">With the risk of saying something silly because I haven't kept up with the discussion, why are you using python setup.py install instead of pip install . as documented? Those commands are not equivalent, you should always use pip install.

Output: 
```
C:\Users\bernh\Desktop\DeepSpeech-master>pip install .
Processing c:\users\bernh\desktop\deepspeech-master
Requirement already satisfied: numpy in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.14.4)
Requirement already satisfied: progressbar2 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (3.47.0)
Requirement already satisfied: six in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.13.0)
Requirement already satisfied: pyxdg in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.26)
Requirement already satisfied: attrdict in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.0.1)
Requirement already satisfied: absl-py in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.9.0)
Requirement already satisfied: semver in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.10.2)
Requirement already satisfied: opuslib==2.0.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.0.0)
Requirement already satisfied: optuna in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.5.0)
Requirement already satisfied: sox in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.3.7)
Requirement already satisfied: bs4 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.0.1)
Requirement already satisfied: pandas in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.25.3)
Requirement already satisfied: requests in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.24.0)
Requirement already satisfied: numba==0.47.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.47.0)
Requirement already satisfied: llvmlite==0.31.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.31.0)
Requirement already satisfied: librosa in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.6.1)
Requirement already satisfied: soundfile in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.10.3.post1)
ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION) (from versions: 0.7.0, 0.7.1, 0.7.3, 0.7.4, 0.8.0a3, 0.8.0a4, 0.8.0a5, 0.8.0a6, 0.9.0a0, 0.9.0a1, 0.9.0a2)
ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION)
```
So same error again

> `pip3 install --upgrade -e .`

Output:
```
C:\Users\bernh\Desktop\DeepSpeech-master>pip3 install --upgrade -e .
Obtaining file:///C:/Users/bernh/Desktop/DeepSpeech-master
Requirement already satisfied, skipping upgrade: numpy in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.14.4)
Requirement already satisfied, skipping upgrade: progressbar2 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (3.47.0)
Requirement already satisfied, skipping upgrade: six in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.13.0)
Requirement already satisfied, skipping upgrade: pyxdg in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.26)
Requirement already satisfied, skipping upgrade: attrdict in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.0.1)
Requirement already satisfied, skipping upgrade: absl-py in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.9.0)
Requirement already satisfied, skipping upgrade: semver in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.10.2)
Requirement already satisfied, skipping upgrade: opuslib==2.0.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.0.0)
Requirement already satisfied, skipping upgrade: optuna in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.5.0)
Requirement already satisfied, skipping upgrade: sox in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (1.3.7)
Requirement already satisfied, skipping upgrade: bs4 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.0.1)
Requirement already satisfied, skipping upgrade: pandas in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.25.3)
Requirement already satisfied, skipping upgrade: requests in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (2.24.0)
Requirement already satisfied, skipping upgrade: numba==0.47.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.47.0)
Requirement already satisfied, skipping upgrade: llvmlite==0.31.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.31.0)
Requirement already satisfied, skipping upgrade: librosa in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.6.1)
Requirement already satisfied, skipping upgrade: soundfile in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from deepspeech-training===training-deepspeech-training-VERSION) (0.10.3.post1)
ERROR: Could not find a version that satisfies the requirement ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION) (from versions: 0.7.0, 0.7.1, 0.7.3, 0.7.4, 0.8.0a3, 0.8.0a4, 0.8.0a5, 0.8.0a6, 0.9.0a0, 0.9.0a1, 0.9.0a2)
ERROR: No matching distribution found for ds_ctcdecoder==training/deepspeech_training/VERSION (from deepspeech-training===training-deepspeech-training-VERSION)
```",risk saying something silly kept discussion python install instead pip install equivalent always use pip install output pip install requirement already satisfied requirement already satisfied requirement already satisfied six requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied post error could find version requirement error matching distribution found error pip install upgrade output pip install upgrade file requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade six requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade requirement already satisfied skipping upgrade post error could find version requirement error matching distribution found,issue,positive,positive,positive,positive,positive,positive
656261578,"> `C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install`

Please, the issue is already strange enough, can we stick to what we document ?
I'm not 100% of the differences in behavior for that wrt `pip3 install --upgrade -e .`, we don't support training on Windows and I don't have a Windows system ...",python install please issue already strange enough stick document behavior pip install upgrade support training system,issue,negative,negative,neutral,neutral,negative,negative
656261520,"With the risk of saying something silly because I haven't kept up with the discussion, why are you using `python setup.py install` instead of `pip install .` as documented? Those commands are not equivalent, you should always use `pip install`.",risk saying something silly kept discussion python install instead pip install equivalent always use pip install,issue,negative,negative,negative,negative,negative,negative
656259830,"And there is the first error again: 

```
C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\setuptools\dist.py:397: UserWarning: The version specified ('training/deepspeech_training/VERSION') is an invalid version, this may not work as expected with newer versions of setuptools, pip, and PyPI. Please see PEP 440 for more details.
  ""details."" % self.metadata.version
running install
running bdist_egg
running egg_info
writing training\deepspeech_training.egg-info\PKG-INFO
writing dependency_links to training\deepspeech_training.egg-info\dependency_links.txt
writing requirements to training\deepspeech_training.egg-info\requires.txt
writing top-level names to training\deepspeech_training.egg-info\top_level.txt
reading manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
writing manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
installing library code to build\bdist.win-amd64\egg
running install_lib
running build_py
creating build\bdist.win-amd64\egg
creating build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\evaluate.py -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\GRAPH_VERSION -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\train.py -> build\bdist.win-amd64\egg\deepspeech_training
creating build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\audio.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\augmentations.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\checkpoints.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\check_characters.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\config.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\downloader.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\evaluate_tools.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\feeding.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\flags.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\gpu.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\helpers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\importers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\logging.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\sample_collections.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\stm.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\taskcluster.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\text.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\VERSION -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\evaluate.py to evaluate.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\train.py to train.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\audio.py to audio.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\augmentations.py to augmentations.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\checkpoints.py to checkpoints.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\check_characters.py to check_characters.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\config.py to config.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\downloader.py to downloader.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\evaluate_tools.py to evaluate_tools.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\feeding.py to feeding.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\flags.py to flags.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\gpu.py to gpu.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\helpers.py to helpers.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\importers.py to importers.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\logging.py to logging.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\sample_collections.py to sample_collections.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\stm.py to stm.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\taskcluster.py to taskcluster.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\text.py to text.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\__init__.py to __init__.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\__init__.py to __init__.cpython-36.pyc
creating build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\requires.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
zip_safe flag not set; analyzing archive contents...
deepspeech_training.__pycache__.train.cpython-36: module references __file__
deepspeech_training.util.__pycache__.helpers.cpython-36: module references __file__
deepspeech_training.util.__pycache__.taskcluster.cpython-36: module references __file__
creating 'dist\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' and adding 'build\bdist.win-amd64\egg' to it
removing 'build\bdist.win-amd64\egg' (and everything under it)
Processing deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
removing 'c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' (and everything under it)
creating c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
Extracting deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages
deepspeech-training training-deepspeech-training-VERSION is already the active version in easy-install.pth

Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_version-py3.6.egg
Processing dependencies for deepspeech-training===training-deepspeech-training-VERSION
Searching for ds_ctcdecoder==training/deepspeech_training/VERSION
Reading https://pypi.org/simple/ds_ctcdecoder/
No local packages or working download links found for ds_ctcdecoder==training/deepspeech_training/VERSION
error: Could not find suitable distribution for Requirement.parse('ds_ctcdecoder==training/deepspeech_training/VERSION')
```",first error python install version invalid version may work pip please see pep running install running running writing writing writing writing reading manifest file writing manifest file library code running running flag set archive content module module module egg removing everything egg removing egg everything egg egg already active version egg searching reading local working link found error could find suitable distribution,issue,negative,positive,positive,positive,positive,positive
656259484,"> Nope, same error like earlier: `C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install Traceback (most recent call last): File ""setup.py"", line 130, in <module> main() File ""setup.py"", line 49, in main with open(version_file) as fin: FileNotFoundError: [Errno 2] No such file or directory: '..\\VERSION'`

my bad, you don't need the `'..'`:

```
version_file = os.path.join(os.path.dirname(__file__), 'VERSION')
```",nope error like python install recent call last file line module main file line main open fin file directory bad need,issue,negative,negative,neutral,neutral,negative,negative
656258836,"Nope, same error like earlier: `C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
Traceback (most recent call last):
  File ""setup.py"", line 130, in <module>
    main()
  File ""setup.py"", line 49, in main
    with open(version_file) as fin:
FileNotFoundError: [Errno 2] No such file or directory: '..\\VERSION'`",nope error like python install recent call last file line module main file line main open fin file directory,issue,negative,positive,neutral,neutral,positive,positive
656258512,"> Again an error
> 
> ```
> C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
> C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\setuptools\dist.py:397: UserWarning: The version specified ('training/deepspeech_training/VERSION') is an invalid version, this may not work as expected with newer versions of setuptools, pip, and PyPI. Please see PEP 440 for more details.
>   ""details."" % self.metadata.version
> running install
> running bdist_egg
> running egg_info
> writing training\deepspeech_training.egg-info\PKG-INFO
> writing dependency_links to training\deepspeech_training.egg-info\dependency_links.txt
> writing requirements to training\deepspeech_training.egg-info\requires.txt
> writing top-level names to training\deepspeech_training.egg-info\top_level.txt
> reading manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
> writing manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
> installing library code to build\bdist.win-amd64\egg
> running install_lib
> running build_py
> creating build\bdist.win-amd64\egg
> creating build\bdist.win-amd64\egg\deepspeech_training
> copying build\lib\deepspeech_training\evaluate.py -> build\bdist.win-amd64\egg\deepspeech_training
> copying build\lib\deepspeech_training\GRAPH_VERSION -> build\bdist.win-amd64\egg\deepspeech_training
> copying build\lib\deepspeech_training\train.py -> build\bdist.win-amd64\egg\deepspeech_training
> creating build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\audio.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\augmentations.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\checkpoints.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\check_characters.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\config.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\downloader.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\evaluate_tools.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\feeding.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\flags.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\gpu.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\helpers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\importers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\logging.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\sample_collections.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\stm.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\taskcluster.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\text.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\util\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training\util
> copying build\lib\deepspeech_training\VERSION -> build\bdist.win-amd64\egg\deepspeech_training
> copying build\lib\deepspeech_training\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\evaluate.py to evaluate.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\train.py to train.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\audio.py to audio.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\augmentations.py to augmentations.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\checkpoints.py to checkpoints.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\check_characters.py to check_characters.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\config.py to config.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\downloader.py to downloader.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\evaluate_tools.py to evaluate_tools.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\feeding.py to feeding.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\flags.py to flags.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\gpu.py to gpu.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\helpers.py to helpers.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\importers.py to importers.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\logging.py to logging.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\sample_collections.py to sample_collections.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\stm.py to stm.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\taskcluster.py to taskcluster.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\text.py to text.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\__init__.py to __init__.cpython-36.pyc
> byte-compiling build\bdist.win-amd64\egg\deepspeech_training\__init__.py to __init__.cpython-36.pyc
> creating build\bdist.win-amd64\egg\EGG-INFO
> copying training\deepspeech_training.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
> copying training\deepspeech_training.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
> copying training\deepspeech_training.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
> copying training\deepspeech_training.egg-info\requires.txt -> build\bdist.win-amd64\egg\EGG-INFO
> copying training\deepspeech_training.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
> zip_safe flag not set; analyzing archive contents...
> deepspeech_training.__pycache__.train.cpython-36: module references __file__
> deepspeech_training.util.__pycache__.helpers.cpython-36: module references __file__
> deepspeech_training.util.__pycache__.taskcluster.cpython-36: module references __file__
> creating 'dist\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' and adding 'build\bdist.win-amd64\egg' to it
> removing 'build\bdist.win-amd64\egg' (and everything under it)
> Processing deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
> removing 'c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' (and everything under it)
> creating c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
> Extracting deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages
> deepspeech-training training-deepspeech-training-VERSION is already the active version in easy-install.pth
> 
> Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_version-py3.6.egg
> Processing dependencies for deepspeech-training===training-deepspeech-training-VERSION
> Searching for tensorflow==1.15.2
> Reading https://pypi.org/simple/tensorflow/
> Downloading https://files.pythonhosted.org/packages/06/1f/3940c7bb51e1b9cf6e526c84d3239830c8d46c9823a3605945f9abb22411/tensorflow-1.15.2-cp36-cp36m-win_amd64.whl#sha256=b6c57269009a641a74b3456ef7483e69143ed9762af321b0560db5a72cdcb01f
> Best match: tensorflow 1.15.2
> Processing tensorflow-1.15.2-cp36-cp36m-win_amd64.whl
> Installing tensorflow-1.15.2-cp36-cp36m-win_amd64.whl to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages
> writing requirements to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\tensorflow-1.15.2-py3.6-win-amd64.egg\EGG-INFO\requires.txt
> Adding tensorflow 1.15.2 to easy-install.pth file
> Installing estimator_ckpt_converter-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing estimator_ckpt_converter.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing freeze_graph-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing freeze_graph.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing saved_model_cli-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing saved_model_cli.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tensorboard-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tensorboard.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tf_upgrade_v2-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tf_upgrade_v2.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tflite_convert-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing tflite_convert.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing toco-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing toco.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing toco_from_protos-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> Installing toco_from_protos.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
> 
> Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\tensorflow-1.15.2-py3.6-win-amd64.egg
> Searching for ds_ctcdecoder==training/deepspeech_training/VERSION
> Reading https://pypi.org/simple/ds_ctcdecoder/
> No local packages or working download links found for ds_ctcdecoder==training/deepspeech_training/VERSION
> error: Could not find suitable distribution for Requirement.parse('ds_ctcdecoder==training/deepspeech_training/VERSION')
> ```

So it's `pathlib` that makes fun of us ...

```
version_file = os.path.join(os.path.dirname(__file__), '..', 'VERSION')
```

Should build the correct path and read correctly the version file, can you verify?",error python install version invalid version may work pip please see pep running install running running writing writing writing writing reading manifest file writing manifest file library code running running flag set archive content module module module egg removing everything egg removing egg everything egg egg already active version egg searching reading best match writing file script script script script script script script script script script script script script script script script searching reading local working link found error could find suitable distribution fun u build correct path read correctly version file verify,issue,positive,positive,positive,positive,positive,positive
656257291,"Again an error

```
C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\setuptools\dist.py:397: UserWarning: The version specified ('training/deepspeech_training/VERSION') is an invalid version, this may not work as expected with newer versions of setuptools, pip, and PyPI. Please see PEP 440 for more details.
  ""details."" % self.metadata.version
running install
running bdist_egg
running egg_info
writing training\deepspeech_training.egg-info\PKG-INFO
writing dependency_links to training\deepspeech_training.egg-info\dependency_links.txt
writing requirements to training\deepspeech_training.egg-info\requires.txt
writing top-level names to training\deepspeech_training.egg-info\top_level.txt
reading manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
writing manifest file 'training\deepspeech_training.egg-info\SOURCES.txt'
installing library code to build\bdist.win-amd64\egg
running install_lib
running build_py
creating build\bdist.win-amd64\egg
creating build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\evaluate.py -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\GRAPH_VERSION -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\train.py -> build\bdist.win-amd64\egg\deepspeech_training
creating build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\audio.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\augmentations.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\checkpoints.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\check_characters.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\config.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\downloader.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\evaluate_tools.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\feeding.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\flags.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\gpu.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\helpers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\importers.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\logging.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\sample_collections.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\stm.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\taskcluster.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\text.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\util\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training\util
copying build\lib\deepspeech_training\VERSION -> build\bdist.win-amd64\egg\deepspeech_training
copying build\lib\deepspeech_training\__init__.py -> build\bdist.win-amd64\egg\deepspeech_training
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\evaluate.py to evaluate.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\train.py to train.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\audio.py to audio.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\augmentations.py to augmentations.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\checkpoints.py to checkpoints.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\check_characters.py to check_characters.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\config.py to config.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\downloader.py to downloader.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\evaluate_tools.py to evaluate_tools.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\feeding.py to feeding.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\flags.py to flags.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\gpu.py to gpu.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\helpers.py to helpers.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\importers.py to importers.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\logging.py to logging.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\sample_collections.py to sample_collections.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\stm.py to stm.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\taskcluster.py to taskcluster.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\text.py to text.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\util\__init__.py to __init__.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\deepspeech_training\__init__.py to __init__.cpython-36.pyc
creating build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\requires.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying training\deepspeech_training.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
zip_safe flag not set; analyzing archive contents...
deepspeech_training.__pycache__.train.cpython-36: module references __file__
deepspeech_training.util.__pycache__.helpers.cpython-36: module references __file__
deepspeech_training.util.__pycache__.taskcluster.cpython-36: module references __file__
creating 'dist\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' and adding 'build\bdist.win-amd64\egg' to it
removing 'build\bdist.win-amd64\egg' (and everything under it)
Processing deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
removing 'c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg' (and everything under it)
creating c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg
Extracting deepspeech_training-training_deepspeech_training_VERSION-py3.6.egg to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages
deepspeech-training training-deepspeech-training-VERSION is already the active version in easy-install.pth

Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\deepspeech_training-training_deepspeech_training_version-py3.6.egg
Processing dependencies for deepspeech-training===training-deepspeech-training-VERSION
Searching for tensorflow==1.15.2
Reading https://pypi.org/simple/tensorflow/
Downloading https://files.pythonhosted.org/packages/06/1f/3940c7bb51e1b9cf6e526c84d3239830c8d46c9823a3605945f9abb22411/tensorflow-1.15.2-cp36-cp36m-win_amd64.whl#sha256=b6c57269009a641a74b3456ef7483e69143ed9762af321b0560db5a72cdcb01f
Best match: tensorflow 1.15.2
Processing tensorflow-1.15.2-cp36-cp36m-win_amd64.whl
Installing tensorflow-1.15.2-cp36-cp36m-win_amd64.whl to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages
writing requirements to c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\tensorflow-1.15.2-py3.6-win-amd64.egg\EGG-INFO\requires.txt
Adding tensorflow 1.15.2 to easy-install.pth file
Installing estimator_ckpt_converter-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing estimator_ckpt_converter.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing freeze_graph-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing freeze_graph.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing saved_model_cli-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing saved_model_cli.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tensorboard-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tensorboard.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tf_upgrade_v2-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tf_upgrade_v2.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tflite_convert-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing tflite_convert.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing toco-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing toco.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing toco_from_protos-script.py script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts
Installing toco_from_protos.exe script to C:\Users\bernh\AppData\Local\Programs\Python\Python36\Scripts

Installed c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\tensorflow-1.15.2-py3.6-win-amd64.egg
Searching for ds_ctcdecoder==training/deepspeech_training/VERSION
Reading https://pypi.org/simple/ds_ctcdecoder/
No local packages or working download links found for ds_ctcdecoder==training/deepspeech_training/VERSION
error: Could not find suitable distribution for Requirement.parse('ds_ctcdecoder==training/deepspeech_training/VERSION')
```",error python install version invalid version may work pip please see pep running install running running writing writing writing writing reading manifest file writing manifest file library code running running flag set archive content module module module egg removing everything egg removing egg everything egg egg already active version egg searching reading best match writing file script script script script script script script script script script script script script script script script searching reading local working link found error could find suitable distribution,issue,positive,positive,positive,positive,positive,positive
656256628,"> Changed and tried to run:
> 
> ```
> C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
> Traceback (most recent call last):
>   File ""setup.py"", line 130, in <module>
>     main()
>   File ""setup.py"", line 49, in main
>     with open(str(version_file)) as fin:
> FileNotFoundError: [Errno 2] No such file or directory: 'setup.py\\...\\VERSION'
> ```

Not really what I expected but that's better.
Can you revert `version_file` to the original version and instead change the `with open(str(version_file))` to `with open(version_file)` ?",tried run python install recent call last file line module main file line main open fin file directory really better revert original version instead change open open,issue,positive,positive,positive,positive,positive,positive
656255910,"Changed and tried to run:

```
C:\Users\bernh\Desktop\DeepSpeech-master>python setup.py install
Traceback (most recent call last):
  File ""setup.py"", line 130, in <module>
    main()
  File ""setup.py"", line 49, in main
    with open(str(version_file)) as fin:
FileNotFoundError: [Errno 2] No such file or directory: 'setup.py\\...\\VERSION'
```",tried run python install recent call last file line module main file line main open fin file directory,issue,negative,positive,neutral,neutral,positive,positive
656254583,"> I know it doesn't make sense

Can you change `setup.py` ?

At the very begining of `main()`, change:
```
version_file = Path(__file__).parent / 'VERSION'
```

To

```
version_file = os.path.join(__file__, '..', 'VERSION')
```",know make sense change main change path,issue,negative,positive,positive,positive,positive,positive
656252995,"> I used `pip install ds_ctcdecoder==0.7.4`

So, we are just back to square one: `training/deepspeech_training/VERSION`. And this being picked the version makes no sense, because it's a file.",used pip install back square one picked version sense file,issue,negative,neutral,neutral,neutral,neutral,neutral
656251786,"> ```
> Collecting ds_ctcdecoder==0.7.4
>   Downloading ds_ctcdecoder-0.7.4-cp36-cp36m-win_amd64.whl (2.6 MB)
>      |████████████████████████████████| 2.6 MB 1.6 MB/s
> Requirement already satisfied: numpy<1.14.5,>=1.12.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from ds_ctcdecoder==0.7.4) (1.14.4)
> ERROR: deepspeech-training training-deepspeech-training-version requires tensorflow==1.15.2, which is not installed.
> ERROR: deepspeech-training training-deepspeech-training-version has requirement ds_ctcdecoder==training/deepspeech_training/VERSION, but you'll have ds-ctcdecoder 0.7.4 which is incompatible.
> Installing collected packages: ds-ctcdecoder
> Successfully installed ds-ctcdecoder-0.7.4
> ```

Since you have not shared the full command line, I can't know if you had this error with `pip3 install --upgrade -e .` from deepspeech installation or from `pip install --upgrade ds_ctcdecoder==0.7.4`.",requirement already satisfied error error requirement incompatible collected successfully since full command line ca know error pip install upgrade installation pip install upgrade,issue,negative,positive,positive,positive,positive,positive
656251129,"```
Collecting ds_ctcdecoder==0.7.4
  Downloading ds_ctcdecoder-0.7.4-cp36-cp36m-win_amd64.whl (2.6 MB)
     |████████████████████████████████| 2.6 MB 1.6 MB/s
Requirement already satisfied: numpy<1.14.5,>=1.12.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from ds_ctcdecoder==0.7.4) (1.14.4)
ERROR: deepspeech-training training-deepspeech-training-version requires tensorflow==1.15.2, which is not installed.
ERROR: deepspeech-training training-deepspeech-training-version has requirement ds_ctcdecoder==training/deepspeech_training/VERSION, but you'll have ds-ctcdecoder 0.7.4 which is incompatible.
Installing collected packages: ds-ctcdecoder
Successfully installed ds-ctcdecoder-0.7.4
```",requirement already satisfied error error requirement incompatible collected successfully,issue,negative,positive,positive,positive,positive,positive
656250275,"> Requirement already satisfied: ds_ctcdecoder==0.7.4 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\ds_ctcdecoder-0.7.4-py3.6-win-amd64.egg (0.7.4)

It's already installed? Please uninstall and reinstall then?",requirement already satisfied already please reinstall,issue,positive,positive,positive,positive,positive,positive
656249715,"```
Non-user install because site-packages writeable
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-xz9prpmn
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-22qzklr_
Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-22qzklr_
Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-22qzklr_
Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-22qzklr_
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-1w5u45b_
Requirement already satisfied: ds_ctcdecoder==0.7.4 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\ds_ctcdecoder-0.7.4-py3.6-win-amd64.egg (0.7.4)
Requirement already satisfied: numpy<1.14.5,>=1.12.0 in c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages (from ds_ctcdecoder==0.7.4) (1.14.4)
Removed build tracker: 'C:\\Users\\bernh\\AppData\\Local\\Temp\\pip-req-tracker-22qzklr_'
```",install writeable temporary directory temporary directory build build tracker build tracker temporary directory requirement already satisfied requirement already satisfied removed build tracker,issue,positive,positive,positive,positive,positive,positive
656248319,"```
Non-user install because site-packages writeable
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-qo8nmkxi
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-8c7vvy98
ERROR: You must give at least one requirement to install (see ""pip help install"")
Exception information:
Traceback (most recent call last):
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\base_command.py"", line 188, in _main
    status = self.run(options, args)
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\req_command.py"", line 185, in wrapper
    return func(self, options, args)
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\commands\install.py"", line 302, in run
    check_supported_wheels=not options.target_dir,
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\req_command.py"", line 365, in get_requirements
    '(see ""pip help {name}"")'.format(**opts))
pip._internal.exceptions.CommandError: You must give at least one requirement to install (see ""pip help install"")
Removed build tracker: 'C:\\Users\\bernh\\AppData\\Local\\Temp\\pip-req-tracker-qo9u26z5'

C:\Users\bernh>pip install -v ds_ctcdecder==0.7.4
Non-user install because site-packages writeable
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-hw9j_5c5
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-d8a0j9t9
Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-d8a0j9t9
Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-d8a0j9t9
Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-d8a0j9t9
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-fnraxfxz
1 location(s) to search for versions of ds-ctcdecder:
* https://pypi.org/simple/ds-ctcdecder/
Fetching project page and analyzing links: https://pypi.org/simple/ds-ctcdecder/
Getting page https://pypi.org/simple/ds-ctcdecder/
Found index url https://pypi.org/simple
Looking up ""https://pypi.org/simple/ds-ctcdecder/"" in the cache
Request header has ""max_age"" as 0, cache bypassed
Starting new HTTPS connection (1): pypi.org:443
https://pypi.org:443 ""GET /simple/ds-ctcdecder/ HTTP/1.1"" 404 13
Status code 404 not in (200, 203, 300, 301)
Could not fetch URL https://pypi.org/simple/ds-ctcdecder/: 404 Client Error: Not Found for url: https://pypi.org/simple/ds-ctcdecder/ - skipping
Given no hashes to check 0 links for project 'ds-ctcdecder': discarding no candidates
ERROR: Could not find a version that satisfies the requirement ds_ctcdecder==0.7.4 (from versions: none)
ERROR: No matching distribution found for ds_ctcdecder==0.7.4
Exception information:
Traceback (most recent call last):
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\cli\base_command.py"", line 188, in _main
    status = self.run(options, args)
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\cli\req_command.py"", line 185, in wrapper
    return func(self, options, args)
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\commands\install.py"", line 333, in run
    reqs, check_supported_wheels=not options.target_dir
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\resolution\legacy\resolver.py"", line 179, in resolve
    discovered_reqs.extend(self._resolve_one(requirement_set, req))
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\resolution\legacy\resolver.py"", line 362, in _resolve_one
    abstract_dist = self._get_abstract_dist_for(req_to_install)
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\resolution\legacy\resolver.py"", line 313, in _get_abstract_dist_for
    self._populate_link(req)
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\resolution\legacy\resolver.py"", line 279, in _populate_link
    req.link = self.finder.find_requirement(req, upgrade)
  File ""c:\users\bernh\appdata\local\programs\python\python36\lib\site-packages\pip\_internal\index\package_finder.py"", line 930, in find_requirement
    req)
pip._internal.exceptions.DistributionNotFound: No matching distribution found for ds_ctcdecder==0.7.4
Removed build tracker: 'C:\\Users\\bernh\\AppData\\Local\\Temp\\pip-req-tracker-d8a0j9t9'
```",install writeable temporary directory temporary directory build build tracker build tracker temporary directory error must give least one requirement install see pip help install exception information recent call last file line status file line wrapper return self file line run file line see pip help name must give least one requirement install see pip help install removed build tracker pip install install writeable temporary directory temporary directory build build tracker build tracker temporary directory location search fetching project page link getting page found index looking cache request header cache starting new connection get status code could fetch client error found skipping given check link project error could find version requirement none error matching distribution found exception information recent call last file line status file line wrapper return self file line run file line resolve file line file line file line upgrade file line matching distribution found removed build tracker,issue,negative,negative,neutral,neutral,negative,negative
656248039,"> The complete statement from `pip install -v`

Ok, I should have been more clear: `pip install -v ds_ctcdecoder==0.7.4`",complete statement pip install clear pip install,issue,negative,positive,neutral,neutral,positive,positive
656247156,"```
Non-user install because site-packages writeable
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-qo8nmkxi
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-qo9u26z5
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-8c7vvy98
ERROR: You must give at least one requirement to install (see ""pip help install"")
Exception information:
Traceback (most recent call last):
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\base_command.py"", line 188, in _main
    status = self.run(options, args)
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\req_command.py"", line 185, in wrapper
    return func(self, options, args)
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\commands\install.py"", line 302, in run
    check_supported_wheels=not options.target_dir,
  File ""C:\Users\bernh\AppData\Local\Programs\Python\Python36\lib\site-packages\pip\_internal\cli\req_command.py"", line 365, in get_requirements
    '(see ""pip help {name}"")'.format(**opts))
pip._internal.exceptions.CommandError: You must give at least one requirement to install (see ""pip help install"")
Removed build tracker: 'C:\\Users\\bernh\\AppData\\Local\\Temp\\pip-req-tracker-qo9u26z5'
```

The complete statement from `pip install -v`

Yes it is `x86_64 system` and python version is 64-bits too",install writeable temporary directory temporary directory build build tracker build tracker temporary directory error must give least one requirement install see pip help install exception information recent call last file line status file line wrapper return self file line run file line see pip help name must give least one requirement install see pip help install removed build tracker complete statement pip install yes system python version,issue,positive,negative,neutral,neutral,negative,negative
656246396,"> I can't tell you more because there is not more to tell... It tries to get the version from the website but doesnt find `ds_ctcdecoder==0.7.4`

So we really need more context on your setup ... and real complete `pip install -v`.

Is it x86_64 system? Are you sure the Python version is also 64-bits ?",ca tell tell get version doesnt find really need context setup real complete pip install system sure python version also,issue,negative,positive,positive,positive,positive,positive
656240992,"Again, it says that the verison of ds_ctcdecoder which stands in the `training/deepspeech_training/VERSION` file is not existent. That's the whole statement. It doesnt find it... I can't tell you more because there is not more to tell... It tries to get the version from the website but doesnt find `ds_ctcdecoder==0.7.4`",file existent whole statement doesnt find ca tell tell get version doesnt find,issue,negative,positive,positive,positive,positive,positive
656238333,"> > Perfect, you are explicitely document you have not followed the documentation:
> 
> I've tried it and it doesn't work on this computer so that's why I tried it this way

Please be more specific. We already don't support training on Windows and you are not following our documentation to perform the setup, it's really hard for us to help you if you don't share more informations.

We also still don't know about `training/deepspeech_training/VERSION`: again, we can't help debug if you don't share broader picture.",perfect document documentation tried work computer tried way please specific already support training following documentation perform setup really hard u help share also still know ca help share picture,issue,positive,positive,positive,positive,positive,positive
656235597,"> Perfect, you are explicitely document you have not followed the documentation:

I've tried it and it doesn't work on this computer so that's why I tried it this way",perfect document documentation tried work computer tried way,issue,positive,positive,positive,positive,positive,positive
656228037,"> You can't use `ls -hal` on Windows and yes, like I said it is a file.

You could have been using bash under Windows. Since we lack context ...



> After downloading I unzipped the file and tried to run in cmd `python setup.py install`. After a few seconds the error appeared

Perfect, you are explicitely document you have not followed the documentation: https://deepspeech.readthedocs.io/en/v0.7.4/TRAINING.html",ca use yes like said file could bash since lack context file tried run python install error perfect document documentation,issue,positive,positive,positive,positive,positive,positive
656200387,"You can't use `ls -hal` on Windows and yes, like I said it is a file. 

> That output seems very well incomplete. 

The rest was an error message telling me I need to write an output `pip install help` (So it told me that -v is incorrect).

> Please write and explicit each and every step you take ...

I went to the python download site, clicked on Python 3.6 and installed it via the exe. Than I wrote in cmd `python -m pip install update` and so it updated pip. After that I went to this github site and clicked on `Releases` and than on the newest. After downloading I unzipped the file and tried to run in cmd `python setup.py install`. After a few seconds the error appeared",ca use yes like said file output well incomplete rest error message telling need write output pip install help told incorrect please write explicit every step take went python site python via wrote python pip install update pip went site file tried run python install error,issue,positive,neutral,neutral,neutral,neutral,neutral
656192975,"> Yes VERSION is a file and that is it's content: `0.7.4`

Can you verify with `ls -hal` so we can check precisely? And `training/deepspeech_training/VERSION` ? Is it a file ?

> 
> I installed pyhton, pip and that's it. I downloaded the files with the setup.py and ran it. Yes I noticed but it says that the version inside the file is not correct.

I'm sorry but there is still nothing to help us reproduce the issue there.
Please write and explicit each and every step you take ...


> pip install -v: `Non-user install because site-packages writeable Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-1wndwf4m Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_ Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_ Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_ Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_ Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-3yymcc1k`

That output seems very well incomplete.",yes version file content verify check precisely file pip ran yes version inside file correct sorry still nothing help u reproduce issue please write explicit every step take pip install install writeable temporary directory temporary directory build build tracker build tracker temporary directory output well incomplete,issue,positive,negative,neutral,neutral,negative,negative
656191144,"pip install -v: `Non-user install because site-packages writeable
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-ephem-wheel-cache-1wndwf4m
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_
Initialized build tracking at C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_
Created build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_
Entered build tracker: C:\Users\bernh\AppData\Local\Temp\pip-req-tracker-ir27a1v_
Created temporary directory: C:\Users\bernh\AppData\Local\Temp\pip-install-3yymcc1k`

Yes VERSION is a file and that is it's content: `0.7.4`

I installed pyhton, pip and that's it. I downloaded the files with the setup.py and ran it. Yes I noticed but it says that the version inside the file is not correct.
",pip install install writeable temporary directory temporary directory build build tracker build tracker temporary directory yes version file content pip ran yes version inside file correct,issue,positive,neutral,neutral,neutral,neutral,neutral
656169488,"> Sure will test that before changing the driver.

Like, I'm not sure if it's not just a side-effect that different tensorflow version might schedule things differently, as you said it was a point that matters, or if it's because it depends on cudnn 7.4 instead of 7.6 and it might behave differently on that point.",sure test driver like sure different version might schedule differently said point instead might behave differently point,issue,positive,positive,positive,positive,positive,positive
656165027,"@applied-machinelearning While not a workaround I like, but it seems to help moving forward that changing to TensorFlow 1.14 gets me through the small example

Is it something you could test on full / repro dataset on your side ?",like help moving forward small example something could test full side,issue,positive,positive,neutral,neutral,positive,positive
656139677,"There are some hints on some of the reports it might be related to the ordering of `sequence_length`, i'd like to get a better grasp at that, confirm and so maybe we could at least have some tooling / workaround to help about that.

@applied-machinelearning For fun, at some point, some combination of dataset, driver and tensorflow version on our codebase would trigger a power surge on my hardware at home, and it was too much for my PSU that was shutting down :/",might related like get better grasp confirm maybe could least tooling help fun point combination driver version would trigger power surge hardware home much shutting,issue,positive,positive,positive,positive,positive,positive
656120780,"> > On Buster you might have more chances to succeed compared to me on Sid.
> > Kernels should be fairly independent of the rest of the system.
> 
> Are you going to / do you know, the best way to address this with Nvidia ?
> (seems the problem itself has been noted for quite some time without a fix appearing in newer drivers)

I have no idea ?",buster might succeed fairly independent rest system going know best way address problem noted quite time without fix idea,issue,positive,positive,positive,positive,positive,positive
656120617,"> On Buster you might have more chances to succeed compared to me on Sid.
Kernels should be fairly independent of the rest of the system.

Are you going to / do you know, the best way to address this with Nvidia ?
(seems the problem itself has been noted for quite some time without a fix appearing in newer drivers)
",buster might succeed fairly independent rest system going know best way address problem noted quite time without fix,issue,positive,positive,positive,positive,positive,positive
656114292,"> > Version: 430.64
> > Operating System: Linux 64-bit
> > Release Date: November 5, 2019
> 
> And it probably means downgrading the kernel as well to something semi-ancient :(

On Buster you might have more chances to succeed compared to me on Sid.",version operating system release date probably kernel well something buster might succeed,issue,positive,neutral,neutral,neutral,neutral,neutral
656080121,"> Looks like `clean.sh` is missing, as well as `FATAL Flags parsing error: flag --alphabet_config_path=./data/lm/plaintext_alpha.txt: The file pointed to by --alphabet_config_path must exist and be readable. `. I don't want to sound rude, but if you could just assemble a dump-proof Docker or script to repro minimally the issue, there are already enough complexity and variables interacting, I really need to be 1000% sure to repro your exact step to assert whether I can reproduce the issue :/

Sorry for that, didn't expect you to run it literally.

> Several people report similar issue with NVIDIA drivers above a certain version: [tensorflow/tensorflow#35950 (comment)](https://github.com/tensorflow/tensorflow/issues/35950#issuecomment-577427083), and 431.36 would be a working one.

Thanks for figuring this out, didn't come up with my google-foo.

Hmm I will see if can give that driver a shot this evening, although I can't find  431.36 in the download archive at https://www.nvidia.com/en-us/drivers/unix/linux-amd64-display-archive/

This one seems to be the closest:
> Version: 430.64
> Operating System: Linux 64-bit
> Release Date: November 5, 2019

And it probably means downgrading the kernel as well to something semi-ancient :(
(edit: hmm from the description it should compile with kernel 5.4, not too ancient)



",like missing well fatal error flag file pointed must exist readable want sound rude could assemble docker script minimally issue already enough complexity really need sure exact step assert whether reproduce issue sorry expect run literally several people report similar issue certain version comment would working one thanks come see give driver shot evening although ca find archive one version operating system release date probably kernel well something edit description compile kernel ancient,issue,negative,positive,neutral,neutral,positive,positive
656056969,"Several people report similar issue with NVIDIA drivers above a certain version: https://github.com/tensorflow/tensorflow/issues/35950#issuecomment-577427083, and 431.36 would be a working one.",several people report similar issue certain version would working one,issue,negative,positive,neutral,neutral,positive,positive
656046428,"@applied-machinelearning Not only I repro, but `apt update && apt upgrade` changes the issue: first it was exploding at epoch 1, now at epoch 2.",apt update apt upgrade issue first epoch epoch,issue,negative,positive,positive,positive,positive,positive
656042014,"> I'm not even able to get CUDA working so far in the dockerfile :/

Seems to be the same old weird nvidia/cuda/docker bug, after `ldconfig` it works:
```
tf-docker ~ > sudo ldconfig
tf-docker ~ > nvidia-smi 
Thu Jul  9 10:16:44 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  On   | 00000000:21:00.0 Off |                  N/A |
|  0%   34C    P8     1W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce RTX 208...  On   | 00000000:4B:00.0 Off |                  N/A |
|  0%   35C    P8    20W / 250W |      0MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
tf-docker ~ > python -c ""import tensorflow as tf; tf.test.is_gpu_available()""
2020-07-09 10:16:48.233166: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-09 10:16:48.264242: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900325000 Hz
2020-07-09 10:16:48.271101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d55f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-09 10:16:48.271144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-09 10:16:48.272884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-09 10:16:54.029647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.046529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.047194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d58840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-09 10:16:54.047218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-07-09 10:16:54.047253: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-07-09 10:16:54.047656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.048468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:21:00.0
2020-07-09 10:16:54.048551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.049324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:4b:00.0
2020-07-09 10:16:54.049585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-09 10:16:54.057643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-07-09 10:16:54.061562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-07-09 10:16:54.066658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-07-09 10:16:54.077684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-07-09 10:16:54.081287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-07-09 10:16:54.107985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-09 10:16:54.108254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.109206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.110043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.110885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.111644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0, 1
2020-07-09 10:16:54.111707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-07-09 10:16:54.113783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-09 10:16:54.113802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 1 
2020-07-09 10:16:54.113811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N N 
2020-07-09 10:16:54.113821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N N 
2020-07-09 10:16:54.113979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.114808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.115627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.116444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2020-07-09 10:16:54.117023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-09 10:16:54.117508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:1 with 10311 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:4b:00.0, compute capability: 7.5)
```",even able get working far old weird bug work driver version version name volatile fan temp compute mib mib default mib mib default memory type process name usage running found python import binary use frequency service platform host guarantee used device host default version successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero service platform guarantee used device ti compute capability device ti compute capability successful node read negative value must least one node node zero found device name ti major minor successful node read negative value must least one node node zero found device name ti major minor successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successfully dynamic library successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero visible successfully dynamic library device interconnect strength edge matrix successful node read negative value must least one node node zero successful node read negative value must least one node node zero successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability successful node read negative value must least one node node zero device memory physical device name ti bus id compute capability,issue,positive,positive,neutral,neutral,positive,positive
656038052,I'm not even able to get CUDA working so far in the dockerfile :/,even able get working far,issue,negative,positive,positive,positive,positive,positive
656029539,"> > Thanks, running Sid as well here, so I'm on similar setup, except I have 2x (faster, more memory) GPUs. I hope it will still allow me to repro.
> 
> I'm running buster on that machine, when I woke up this morning it dawned on me I forgot to post the hyperparameter stuff.
> So attached is the script I used in the docker container to run the tests. Feature cache, checkpoint dir etc, all get cleaned up before the run.
> 
> [run_deepspeech_var_batchsize.sh.tar.gz](https://github.com/mozilla/DeepSpeech/files/4895165/run_deepspeech_var_batchsize.sh.tar.gz)
> 
> I hope you can reproduce and spot something !

Looks like `clean.sh` is missing, as well as `FATAL Flags parsing error: flag --alphabet_config_path=./data/lm/plaintext_alpha.txt: The file pointed to by --alphabet_config_path must exist and be readable.
`. I don't want to sound rude, but if you could just assemble a dump-proof Docker or script to repro minimally the issue, there are already enough complexity and variables interacting, I really need to be 1000% sure to repro your exact step to assert whether I can reproduce the issue :/",thanks running well similar setup except faster memory hope still allow running buster machine woke morning forgot post stuff attached script used docker container run feature cache get run hope reproduce spot something like missing well fatal error flag file pointed must exist readable want sound rude could assemble docker script minimally issue already enough complexity really need sure exact step assert whether reproduce issue,issue,positive,positive,neutral,neutral,positive,positive
655953700,"> Thanks, running Sid as well here, so I'm on similar setup, except I have 2x (faster, more memory) GPUs. I hope it will still allow me to repro.

I'm running buster on that machine, when I woke up this morning it dawned on me I forgot to post the hyperparameter stuff.
So attached is the script I used in the docker container to run the tests. Feature cache, checkpoint dir etc, all get cleaned up before the run.

[run_deepspeech_var_batchsize.sh.tar.gz](https://github.com/mozilla/DeepSpeech/files/4895165/run_deepspeech_var_batchsize.sh.tar.gz)

I hope you can reproduce and spot something !
",thanks running well similar setup except faster memory hope still allow running buster machine woke morning forgot post stuff attached script used docker container run feature cache get run hope reproduce spot something,issue,positive,positive,neutral,neutral,positive,positive
655785162,"> > > As I am also effected by this, I tried everything from python versions, different dockerbuild, different host drivers, checking my dataset for evident errors, all had no effect.
> > 
> > 
> > So I see you are basically reusing the TensorFlow official Docker image and you got inspiration from https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train :)
> > I think it was an Italian DS/CV repo I drew inspiration from, but they probably took it from the French one ;).
> > Previously I also tried with a docker build with ubuntu18.04-cuda10 image as a base, with tensorflow-gpu 1.15.3.
> 
> > That's good, that should make it easier for us to try and reproduce locally. Can you share more details on your actual underlying system and hardware, in case it might be related?
> 
> Host is an AMD Ryzen system with 32GB of mem and a GTX 1070 with 8GB of mem, running Debian.
> Host Nvidia driver is now 440.100 (but I have tried several others, still the same problems).
> If you need more specifics, please indicate what info you need more.
> 
> Thanks for looking into it !

Thanks, running Sid as well here, so I'm on similar setup, except I have 2x (faster, more memory) GPUs. I hope it will still allow me to repro.",also tried everything python different different host evident effect see basically official docker image got inspiration think drew inspiration probably took one previously also tried docker build image base good make easier u try reproduce locally share actual underlying system hardware case might related host system mem mem running host driver tried several still need please indicate need thanks looking thanks running well similar setup except faster memory hope still allow,issue,positive,positive,neutral,neutral,positive,positive
655778353,"> > As I am also effected by this, I tried everything from python versions, different dockerbuild, different host drivers, checking my dataset for evident errors, all had no effect.
> 
> So I see you are basically reusing the TensorFlow official Docker image and you got inspiration from https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train :)
I think it was an Italian DS/CV repo I drew inspiration from, but they probably took it from the French one ;).
Previously I also tried with a docker build with ubuntu18.04-cuda10 image as a base, with tensorflow-gpu 1.15.3.  

> That's good, that should make it easier for us to try and reproduce locally. Can you share more details on your actual underlying system and hardware, in case it might be related?

Host is an AMD Ryzen system with 32GB of mem and a GTX 1070 with 8GB of mem, running Debian.
Host Nvidia driver is now 440.100 (but I have tried several others, still the same problems).
If you need more specifics, please indicate what info you need more.

Thanks for looking into it !",also tried everything python different different host evident effect see basically official docker image got inspiration think drew inspiration probably took one previously also tried docker build image base good make easier u try reproduce locally share actual underlying system hardware case might related host system mem mem running host driver tried several still need please indicate need thanks looking,issue,positive,positive,neutral,neutral,positive,positive
655682887,"This is not a in our code, please use discourse to reach for support as stated in the github template. ",code please use discourse reach support stated template,issue,positive,neutral,neutral,neutral,neutral,neutral
655607820,In particular I'd be very interested in any feedback from Swift developers on how the error handling looks and how the buffer handling around `Model.speechToText` and `Stream.feedAudioContent` looks.,particular interested feedback swift error handling buffer handling around,issue,negative,positive,positive,positive,positive,positive
655605393,"(Hopefully) finished wrapping the C API, now moving on to CI work. Wrapper is here if anyone wants to take a quick look and provide any suggestions: https://github.com/mozilla/DeepSpeech/blob/ios-build/native_client/swift/deepspeech_ios/DeepSpeech.swift",hopefully finished wrapping moving work wrapper anyone take quick look provide,issue,negative,positive,positive,positive,positive,positive
655498278,"> I can't explain how to reproduce. It only says: `Didn't found the version of ds_ctcdecoder` (like i wrote above) when trying to install it. I can't document things because there are none. I tried to install it and bam there is this error message.

You could try to share `pip install -v`, as well as answer the question about `VERSION` and `training/deepspeech_training/VERSION`. Two things I asked you in the very first reply I gave you.

You could also try and document how you setup things.

In case you have not noticed, you should not have `ds_ctcdecoder==training/deepspeech_training/VERSION` but `ds_ctcdecoder==0.7.4`. We need to understand why in your case it's broken ...",ca explain reproduce found version like wrote trying install ca document none tried install bam error message could try share pip install well answer question version two first reply gave could also try document setup case need understand case broken,issue,negative,negative,neutral,neutral,negative,negative
655495209,"@lissyx @reuben 

OK I have done some more runs:

**I ran train_debug_As_Bs_Cs.csv with batch sizes 1 and 2:**
> Batch size 1 trains fine.
> Batch size 2 blows up on the step with files:
>     B/98_2923_a387275540ba5f2159c37eaee3e4e9a0-651926517a6241fd9bb5942777b1f0ff.wav
>     B/154_4738_2f841fb1af523c579414e0358ab16295-6aea9aa95b1bdbfd80703754cd8a180c.wav

**So I made some new csv files with:**
>     batch A: two files from the original batch A
>     batch B: two files B/98_2923 and B/154_4738 from batch B
>     batch C: two files from the original batch C

**And I made some variant of that:**
>     train_debug_mini_As_Bs_Cs.csv
>     train_debug_mini_Bs_As_Cs.csv
>     train_debug_mini_Bs_As_Cs_B_swapped.csv
>     train_debug_mini_As_Bs_Cs_B_swapped.csv
>     train_debug_mini_As_Bs_Cs_B_mixed_A.csv
>     train_debug_mini_As_Bs_Cs_B_mixed_C.csv
>     train_debug_mini_As_Bs_Cs_B_mixed_C_2.csv
>     train_debug_mini_As_Bs_Cs_B_swapped_C_mixed.csv

**The results of that:**
>     With batch size 1, these all workout fine (as expected).
>     With batch size 2:
>     train_debug_mini_As_Bs_Cs.csv
>         blows up in step 1, which is batch B.
> 
>     train_debug_mini_As_Bs_Cs_B_swapped.csv
>         blows up in step 1, which is batch B, so swapping the order within B doesn't make a difference.
>
>     train_debug_mini_Bs_As_Cs.csv
>         works fine, B is the first step 0.
>         as expected as the first step seems to be a special case.
> 
>     train_debug_mini_Bs_As_Cs_B_swapped.csv
>         works fine, B is the first step 0, so swapping the order in B doesn't make a difference.
>         as expected as the first step seems to be a special case.
> 
>     train_debug_mini_As_Bs_Cs_B_mixed_A.csv
>         blows up in step 1, which is:
>             A/155_4757
>             B/154_4738
> 
>     train_debug_mini_As_Bs_Cs_B_mixed_C.csv
>         blows up in step 1, which is:
>             B/98_2923
>             C/169_5271
> 
>     train_debug_mini_As_Bs_Cs_B_mixed_C_2.csv
>         blows up in step 1, which is:
>             C/169_5271
>             B/98_2923
> 
>     train_debug_mini_As_Bs_Cs_B_swapped_C_mixed.csv
>         blows up in step 2, which is:
>             B/98_2923
>             C/169_5271
> 
>         while it did complete step 1, which is:
>             B/154_4738
>             C/175_5429

**My interpretation of this all:**
- batch size 1 always works, so it is not completly file specific
- with batch size 2 both B/98_2923 and B/154_4738 appear in blowups.
- with batch size 2 B/154_4738 appears in both a blowup and a succeeded step.
- from the previous expiriments we know that when you mix batch B in a much larger pool of (more different) files, all works out well.

So it is a bit odd, I'm starting to wonder if this is some edge case where we hit some math operation blowing up.
But both files from B have slightly different file sizes and both blow up in combinations with other files with slightly different file sizes (from A and C).

So I'm a bit lost now, you have more insight in how things get processed, hopefully you have some more ideas based on that.

CSV's and logs are attached (sample files from the previous post can be used)
[train_debug_mini.tar.gz](https://github.com/mozilla/DeepSpeech/files/4890675/train_debug_mini.tar.gz)
",done ran batch size batch size fine batch size step made new batch two original batch batch two batch batch two original batch made variant batch size workout fine batch size step batch step batch swapping order within make difference work fine first step first step special case work fine first step swapping order make difference first step special case step step step step complete step interpretation batch size always work file specific batch size appear batch size blowup step previous know mix batch much pool different work well bit odd starting wonder edge case hit math operation blowing slightly different file size blow slightly different file size bit lost insight get hopefully based attached sample previous post used,issue,positive,positive,positive,positive,positive,positive
655473190,I can't explain how to reproduce. It only says: `Didn't found the version of ds_ctcdecoder` (like i wrote above) when trying to install it. I can't document things because there are none. I tried to install it and bam there is this error message.,ca explain reproduce found version like wrote trying install ca document none tried install bam error message,issue,negative,neutral,neutral,neutral,neutral,neutral
655453266,">  As I am also effected by this, I tried everything from python versions, different dockerbuild, different host drivers, checking my dataset for evident errors, all had no effect.

So I see you are basically reusing the TensorFlow official Docker image and you got inspiration from https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train :)

That's good, that should make it easier for us to try and reproduce locally. Can you share more details on your actual underlying system and hardware, in case it might be related?",also tried everything python different different host evident effect see basically official docker image got inspiration good make easier u try reproduce locally share actual underlying system hardware case might related,issue,positive,positive,positive,positive,positive,positive
655408175,"Sorry guys, but I've been moved on a different project and I couldn't make
any progress.

On Tue, Jul 7, 2020 at 4:55 PM lissyx <notifications@github.com> wrote:

> @generosocarbone <https://github.com/generosocarbone> Could you update us
> ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3017#issuecomment-654921140>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACGIO5BFDXYZ2CTR4IYIFU3R2MZOPANCNFSM4NKRJPGA>
> .
>
",sorry different project could make progress tue wrote could update u reply directly view,issue,negative,negative,negative,negative,negative,negative
655354543,Still waiting on the people who are supposed to be in charge of the mozilla org on Docker Hub.,still waiting people supposed charge docker hub,issue,negative,neutral,neutral,neutral,neutral,neutral
655333531,@carlfm01 have you changed the github workers as i told you to do ? I dont see this change here. ,told dont see change,issue,negative,neutral,neutral,neutral,neutral,neutral
655332951,"You can overload `PATH` in the task definition, see win-opt-base.tyml",overload path task definition see,issue,negative,neutral,neutral,neutral,neutral,neutral
655331109,"@lissyx Ok, it failed, looks like the recommended deps missed to add: `c:\program files\dotnet\`  where should I set it? this cluster side or the cluster image definition side? And how? for Windows should be: `set PATH=%PATH%;c:\program files\dotnet\`",like add set cluster side cluster image definition side set path,issue,negative,neutral,neutral,neutral,neutral,neutral
655170041,"> Nice @applied-machinelearning. Do you think you could even reduce batch B to a smaller set of files ? Maybe if we can know which file(s) triggers the behavior it might be easier to know about / check ?

I could try by reducing the training batch size,  see if I can find even smaller batches that fail (from previous tests I think it will end at either 2 or 4 (but not 1), will give it a try tomorrow.",nice think could even reduce batch smaller set maybe know file behavior might easier know check could try reducing training batch size see find even smaller fail previous think end either give try tomorrow,issue,negative,negative,neutral,neutral,negative,negative
655167274,Nice @applied-machinelearning. Do you think you could even reduce batch B to a smaller set of files ? Maybe if we can know which file(s) triggers the behavior it might be easier to know about / check ?,nice think could even reduce batch smaller set maybe know file behavior might easier know check,issue,positive,positive,positive,positive,positive,positive
655165414,"> Thanks @lissyx, that worked. I was working off `master` (and tried `v0.9.0-alpha.1`), as I assumed it'd work. Cheers!

It usually does, except when we break it :)",thanks worked working master tried assumed work usually except break,issue,negative,negative,neutral,neutral,negative,negative
655141987,"Thanks @lissyx, that worked. I was working off `master` (and tried `v0.9.0-alpha.1`), as I assumed it'd work. Cheers!",thanks worked working master tried assumed work,issue,negative,positive,positive,positive,positive,positive
655141071,"@lissyx @reuben 

Got the results of my extended testing based on a minimalistic dataset of 3x 32 samples, as I use a batchsize of 32, that is 3 steps. I named the batches A, B and C and as a whole they are ordered by wav_filesize.

I have done runs with all sorts of combinations of these batches (concatenated in the order of the name of the csv file), if appended with a ""s"" that batch in itself is still ordered by wav_filesize, if appended with a ""r"" that batch is randomly shuffled. The runs do 3 epochs.

**In the tar.gz file I included:**
- data dir with all the csv's used and subdirs A, B and C with the corresponding wav files.
- log dir with all the log files that came out of this test run.
- docker dir with the build file for the docker image (which is a slight adaptation of the one in de DeepSpeech repo).
- patches dir with the two patches I applied on to v0.7.4, one to print out the filenames in a batch and the other one to keep the sorting of the train csv's as is.

**As a summary of the results:**
> train_debug_Ar_Br_Cr.csv, blows up in step 1, which is batch B
train_debug_Ar_Br_Cs.csv, blows up in step 1, which is batch B
train_debug_Ar_Bs_Cs.csv, blows up in step 1, which is batch B
train_debug_As_Br_Cs.csv, blows up in step 1, which is batch B
train_debug_As_Bs_Cs.csv, blows up in step 1, which is batch B
train_debug_As_Cs_Bs.csv, blows up in step 2, which is batch B
train_debug_As_Cs.csv, OK
train_debug_Bs_Cs.csv, OK
train_debug_Cs_As_Bs.csv, blows up in step 2, which is batch B
train_debug_Cs_As.csv, OK
train_debug_Cs_Bs_As.csv, blows up in step 1, which is batch B
train_debug_Cs_Bs.csv, blows up in step 1, which is batch B
train_debug_interbatch_random: All variants: OK

**My interpretation of these results:**
1. If it blows up, it is always at a step with batch B.
2. It always blows up with the contents of this batch B, unless batch B is the very first step.
3. The order of the files within batch B doesn't matter.
4. It happens independent of the  previous batches/steps (with the exemption of B being the first batch)
5. All inter-batch randomized  variants run fine.

But what is so special about the content of batch B that it blows up with CUDNN ...

(before you ask, it is not only this batch B, there are multiple such batches in my large datasets, this is one example with the shortest samples)
[deepspeech_v0.7.4_cudnn_debug.tar.gz](https://github.com/mozilla/DeepSpeech/files/4887193/deepspeech_v0.7.4_cudnn_debug.tar.gz)
",got extended testing based use whole ordered done order name file batch still ordered batch randomly file included data used corresponding log log came test run docker build file docker image slight adaptation one de two applied one print batch one keep train summary step batch step batch step batch step batch step batch step batch step batch step batch step batch interpretation always step batch always content batch unless batch first step order within batch matter independent previous exemption first batch run fine special content batch ask batch multiple large one example,issue,positive,positive,neutral,neutral,positive,positive
655107450,"> Will there be a DeepSpeech 0.7.5 release for this, or will it be part of 0.8?

no, it will be 0.8+, but you can easily pick the fix for your own use",release part easily pick fix use,issue,negative,positive,positive,positive,positive,positive
655106410,"> It's taking more time than I would have hoped because of infra issues on our CI.

No problem, there isn't any particular rush on my end.  I've made these same changes locally for now which gets me unstuck for the time being.

Will there be a DeepSpeech 0.7.5 release for this, or will it be part of 0.8?",taking time would hoped infra problem particular rush end made locally unstuck time release part,issue,negative,positive,neutral,neutral,positive,positive
655102770,It's taking more time than I would have hoped because of infra issues on our CI.,taking time would hoped infra,issue,negative,neutral,neutral,neutral,neutral,neutral
655017359,"> @dsteinman If you can suggest a better solution than replacing `app.asar` with `app.asar.unpacked` it'd be great

Looks good to me.  I can't think of a much better way to do it.

Thank you very much for all the help.",suggest better solution great good ca think much better way thank much help,issue,positive,positive,positive,positive,positive,positive
655008169,@dsteinman If you can suggest a better solution than replacing `app.asar` with `app.asar.unpacked` it'd be great,suggest better solution great,issue,positive,positive,positive,positive,positive,positive
655006512,"> I just never clued into that replacement because both the packed and unpacked asar were always there and thought that's how it needed to be. So sorry for all the trouble. I'm glad it didn't take too long to figure out.

Well, I really don't get what you don't get, because it feels to be what I repeated. Anyway, thanks for the confirmation, I'm preparing a """"""better"""""" fix.",never replacement unpacked always thought sorry trouble glad take long figure well really get get repeated anyway thanks confirmation better fix,issue,positive,positive,neutral,neutral,positive,positive
655005268,"Looks like that's working!!!  Both from the win-unpacked and the installer.  This is terrific.

I just never clued into that replacement because both the packed and unpacked asar were always there and thought that's how it needed to be.  So sorry for all the trouble.   I'm glad it didn't take too long to figure out.",like working installer terrific never replacement unpacked always thought sorry trouble glad take long figure,issue,positive,negative,neutral,neutral,negative,negative
655004104,Maybe Common Voice is actually a better input (or additional) since it's MP3 and actually involves some codec conversion.,maybe common voice actually better input additional since actually conversion,issue,negative,positive,neutral,neutral,positive,positive
655001092,"```
User@WinDev2006Eval MINGW64 ~/deepspeech-electron/dist/win-unpacked (master)
$ ./deepspeech-electron.exe

TensorFlow: v1.15.0-24-gceb46aae58
DeepSpeech: v0.7.4-0-gfcd9563f
2020-07-07 10:07:32.672680: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
model loaded

```",user master binary use model loaded,issue,negative,neutral,neutral,neutral,neutral,neutral
655000807,"> @dsteinman So, from the begining I was right ?
> 
> The following in `deepspeech/index.js` works with `./deepspeech-electron.exe`:
> 
> ```
> if (process.platform === 'win32') {
>     const dslib_path_o = path_1.default.resolve(path_1.default.join(binding_path, '../..'));
> 	const dslib_path = dslib_path_o.replace(""app.asar"", ""app.asar.unpacked"");
> console.log(""dslib_path:"",  dslib_path);
> console.log(""process:"", process.env.PATH);
>     var oldPath = process.env.PATH;
>     process.env['PATH'] = `${dslib_path};${process.env.PATH}`;
> console.log(""process:"", process.env.PATH);
> }
> ```

Can you verify that this works on the whole workflow ? If so, it means it's just the PATH that is broken, as I was suggesting.",right following work process process verify work whole path broken suggesting,issue,negative,positive,neutral,neutral,positive,positive
654998475,"@dsteinman So, from the begining I was right ?

The following in `deepspeech/index.js` works with `./deepspeech-electron.exe`:
```
if (process.platform === 'win32') {
    const dslib_path_o = path_1.default.resolve(path_1.default.join(binding_path, '../..'));
	const dslib_path = dslib_path_o.replace(""app.asar"", ""app.asar.unpacked"");
console.log(""dslib_path:"",  dslib_path);
console.log(""process:"", process.env.PATH);
    var oldPath = process.env.PATH;
    process.env['PATH'] = `${dslib_path};${process.env.PATH}`;
console.log(""process:"", process.env.PATH);
}
```",right following work process process,issue,negative,positive,positive,positive,positive,positive
654991046,"Oops, that's a mistake on my part.  The package.json scripts can be changed from yarn to npm, I've pushed a change in:

https://github.com/dsteinman/DeepSpeech-examples/commit/c729f983f4219a69a480a642e166018710169ec9

",mistake part yarn change,issue,negative,negative,neutral,neutral,negative,negative
654988238,"```
User@WinDev2006Eval MINGW64 ~/deepspeech-electron (master)
$ npm run dist-win

> deepspeech-electron@1.0.0 dist-win C:\Users\User\deepspeech-electron
> yarn run build && electron-builder --x64

yarn run v1.22.4
$ react-scripts build
Creating an optimized production build...
Compiled successfully.

File sizes after gzip:

  40.05 KB  build\static\js\2.0472d069.chunk.js
  781 B     build\static\js\runtime-main.b2c498fc.js
  670 B     build\static\js\main.09f8e380.chunk.js

The project was built assuming it is hosted at ./.
You can control this with the homepage field in your package.json.

The build folder is ready to be deployed.

Find out more about deployment here:

  bit.ly/CRA-deploy

Done in 20.99s.
  ΓÇó electron-builder  version=22.7.0 os=10.0.19041
  ΓÇó loaded configuration  file=package.json (""build"" field)
  ΓÇó loaded parent configuration  preset=react-cra
  ΓÇó author is missed in the package.json  appPackageFile=C:\Users\User\deepspeech-electron\package.json
  ΓÇó electron-rebuild not required if you use electron-builder, please consider to remove excess dependency from devDependencies

To ensure your native dependencies are always matched electron version, simply add script `""postinstall"": ""electron-builder install-app-deps"" to your `package.json`
  Γ¿» Package ""electron"" is only allowed in ""devDependencies"". Please remove it from the ""dependencies"" section in your package.json.
npm ERR! code ELIFECYCLE
npm ERR! errno 1
npm ERR! deepspeech-electron@1.0.0 dist-win: `yarn run build && electron-builder --x64`
npm ERR! Exit status 1
npm ERR!
npm ERR! Failed at the deepspeech-electron@1.0.0 dist-win script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.

npm ERR! A complete log of this run can be found in:
npm ERR!     C:\Users\User\AppData\Roaming\npm-cache\_logs\2020-07-07T16_45_10_499Z-debug.log

User@WinDev2006Eval MINGW64 ~/deepspeech-electron (master)
```",user master run yarn run build yarn run build production build successfully file size project built assuming control field build folder ready find deployment done loaded configuration build field loaded parent configuration author use please consider remove excess dependency ensure native always electron version simply add script package electron please remove section err code err err yarn run build err exit status err err script err probably problem likely additional logging output err complete log run found err user master,issue,positive,positive,neutral,neutral,positive,positive
654987932,"> `dist-win` depends on `yarn` ?

No, nothing here relies on yarn.

FYI I'm using node v13.13.0 and npm 6.14.4 on Windows.",yarn nothing yarn node,issue,negative,negative,neutral,neutral,negative,negative
654985104,"> > You're missing the audio files. They need to be in public/audio
> 
> That was not part of your instructions, sorry, and since it downloads models ...

Oh I forgot to mention it above, but I did add it to the readme.  I should probably add a proper error message for this.",missing audio need part sorry since oh forgot mention add probably add proper error message,issue,negative,negative,negative,negative,negative,negative
654983615,"> You're missing the audio files. They need to be in public/audio

That was not part of your instructions, sorry, and since it downloads models ...",missing audio need part sorry since,issue,negative,negative,negative,negative,negative,negative
654983320,"You're missing the audio files.  They need to be in public/audio

It sounds like you've already got it pretty much working.",missing audio need like already got pretty much working,issue,positive,positive,neutral,neutral,positive,positive
654982723,"> > > Somehow I ended up with ElectronJS v9.1 when we only have support for 9.0 ...
> > 
> > 
> > Yes I noticed that as well. I thought I fixed it in the DeepSpeech-examples/electron Pull request.
> > The version of electron had to be set to exactly 9.0.5, and not ^9.0.5
> > ```
> > ""devDependencies"": {
> >     ""concurrently"": ""^5.0.0"",
> >     ""electron"": ""9.0.5"",
> > ```
> 
> Right, that seems to work better. Let's see how much I'll hate the nodejs ecosystem after that :)

`npm run dev-win` explodes with an error:
`TypeError: Cannot read property 'filter' of undefined` from `create-window.js:50`",somehow ended support yes well thought fixed pull request version electron set exactly concurrently electron right work better let see much hate ecosystem run error read property undefined,issue,negative,positive,neutral,neutral,positive,positive
654980255,"> > Somehow I ended up with ElectronJS v9.1 when we only have support for 9.0 ...
> 
> Yes I noticed that as well. I thought I fixed it in the DeepSpeech-examples/electron Pull request.
> 
> The version of electron had to be set to exactly 9.0.5, and not ^9.0.5
> 
> ```
> ""devDependencies"": {
>     ""concurrently"": ""^5.0.0"",
>     ""electron"": ""9.0.5"",
> ```

Right, that seems to work better. Let's see how much I'll hate the nodejs ecosystem after that :)",somehow ended support yes well thought fixed pull request version electron set exactly concurrently electron right work better let see much hate ecosystem,issue,positive,positive,neutral,neutral,positive,positive
654979426,"> Somehow I ended up with ElectronJS v9.1 when we only have support for 9.0 ...

Yes I noticed that as well.  I thought I fixed it in the DeepSpeech-examples/electron Pull request.

The version of electron had to be set to exactly 9.0.5, and not ^9.0.5

```
""devDependencies"": {
    ""concurrently"": ""^5.0.0"",
    ""electron"": ""9.0.5"",
```",somehow ended support yes well thought fixed pull request version electron set exactly concurrently electron,issue,positive,positive,positive,positive,positive,positive
654978108,"> > binding_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
> > dslib_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64
> > libdeepspeech.so exists? = true
> > binding error Error: The specified module could not be found.
> > \?\C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
> 
> I hate all that magic :/. Here electronjs contradicts itself, with one path `app.asar.unpacked` and two `app.asar` :/

Not exactly -- that's my fault for not explaining.  What I just pasted there is I am running the generated ""deepspeech.exe"" that located in /dist/win-unpacked.  Not the installer version.
",true binding error error module could found hate magic one path two exactly fault explaining pasted running installer version,issue,negative,positive,neutral,neutral,positive,positive
654976746,"> The pull request is there.
> 
> To replicate the issue in Windows:
> 
> ```
> npm install
> npm run rebuild
> export BROWSER=none
> npm run dev-win
> npm run dist-win
> ```
> 
> Click the resulting installer exe file in the `dist` directory. Then running the ""deepspeech-electron"" app from the system menu will fail with the error in the screenshot above.
> 
> This process works on Mac and Windows (using `npm run dev` and `npm run dist`). And I'm still confused about exactly why this isn't working in Windows, but it sure looks like it might be because of some incompatibility with that the PATH handling and the ""app.asar"" package forrmat that electron-builder uses.

Those steps are not working for me, I'm getting an error about missing module `deepspeech.node` at the `npm run dev-win` step, but that seems to be the same error.",pull request replicate issue install run rebuild export run run click resulting installer file directory running system menu fail error process work mac run dev run still confused exactly working sure like might incompatibility path handling package working getting error missing module run step error,issue,negative,negative,neutral,neutral,negative,negative
654973363,"> binding_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
> dslib_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64
> libdeepspeech.so exists? = true
> binding error Error: The specified module could not be found.
> \\?\C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node

I hate all that magic :/. Here electronjs contradicts itself, with one path `app.asar.unpacked` and two `app.asar` :/",true binding error error module could found hate magic one path two,issue,negative,positive,neutral,neutral,positive,positive
654970661,"> OK so we'd need to make sure it's also the path added to PATH

Already confirmed.

I can add some debug statements to deepspeech/index.js to confirm the files exist:

```
if (process.platform === 'win32') {
    console.log('binding_path =', binding_path)
    const dslib_path = path_1.default.resolve(path_1.default.join(binding_path, '../..'));
    console.log('dslib_path =', dslib_path)
    console.log('libdeepspeech.so exists? =',require('fs').existsSync(dslib_path+'/libdeepspeech.so').toString());
    var oldPath = process.env.PATH;
    process.env['PATH'] = `${dslib_path};${process.env.PATH}`;
}
try {
    const binding = require(binding_path);
}
catch(e) {
    console.error('binding error', e);
    process.exit();
}
```

And then when I run the code, it all looks good but it still says the module is not found:

```
Dan@DESKTOP-9KMND6F MINGW64 ~/dev/DeepSpeech-examples/electron/dist/win-unpacked (r0.7-electron)
$ ./deepspeech-electron.exe

binding_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
dslib_path = C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64
libdeepspeech.so exists? = true
binding error Error: The specified module could not be found.
\\?\C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
    at process.func [as dlopen] (electron/js2c/asar.js:140:31)
    at Object.Module._extensions..node (internal/modules/cjs/loader.js:1034:18)
    at Object.func [as .node] (electron/js2c/asar.js:149:18)
    at Module.load (internal/modules/cjs/loader.js:815:32)
    at Module._load (internal/modules/cjs/loader.js:727:14)
    at Function.Module._load (electron/js2c/asar.js:769:28)
    at Module.require (internal/modules/cjs/loader.js:852:19)
    at require (internal/modules/cjs/helpers.js:74:18)
    at Object.<anonymous> (C:\Users\Dan\dev\DeepSpeech-examples\electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\index.js:22:21)
    at Module._compile (internal/modules/cjs/loader.js:967:30)

```

> Are you doing https://www.electronjs.org/docs/tutorial/application-packaging#adding-unpacked-files-to-asar-archives ?

No, I am not running asar commands like this myself (I don't even have an ""asar"" command line executable program) because electron-builder is doing all of that stuff.

```
$ asar pack app app.asar --unpack *.node
```",need make sure also path added path already confirmed add confirm exist require try binding require catch error run code good still module found dan true binding error error module could found node require anonymous running like even command line executable program stuff pack unpack,issue,negative,positive,positive,positive,positive,positive
654957202,"@dsteinman Looking at electron's doc: https://www.electronjs.org/docs/tutorial/application-packaging#node-api

They have special handling that, how surprising it would explode ...",looking electron doc special handling surprising would explode,issue,positive,positive,positive,positive,positive,positive
654954671,"FWIW, my suggestion was simply to restore the old `util.text` API, and reduce the diff size for this fix. Otherwise I don't mind the direct imports.",suggestion simply restore old reduce size fix otherwise mind direct,issue,negative,positive,neutral,neutral,positive,positive
654953423,Regarding the re-export comment: What's the advantage of getting it indirectly through `deepspeech_training.util.text`?,regarding comment advantage getting indirectly,issue,negative,neutral,neutral,neutral,neutral,neutral
654951188,"> app.asar appears to be a ""zip' or ""tar"" or ""jar"" style file archive.

Right, so it's even weirder that `binding_path` is being constructed with `app.asar` ...",zip tar jar style file archive right even,issue,negative,positive,positive,positive,positive,positive
654946256,"> app.asar appears to be a ""zip' or ""tar"" or ""jar"" style file archive.
> 
> libdeepspeech.so is in the win32_x64, one level up from where deepspeech.node is:
> 
> ![lib](https://user-images.githubusercontent.com/3894317/86804215-bd08c880-c044-11ea-90b5-35e24d50c1e3.png)

OK so we'd need to make sure it's also the path added to `PATH`",zip tar jar style file archive one level need make sure also path added path,issue,negative,positive,positive,positive,positive,positive
654942044,"app.asar appears to be a ""zip' or ""tar"" or ""jar"" style file archive.

libdeepspeech.so is in the win32_x64, one level up from where deepspeech.node is:

![lib](https://user-images.githubusercontent.com/3894317/86804215-bd08c880-c044-11ea-90b5-35e24d50c1e3.png)
",zip tar jar style file archive one level,issue,negative,neutral,neutral,neutral,neutral,neutral
654937107,"> We do know that everything related to app.asar and deepspeech works as expected in Mac and Linux. So I'd like to assume app.asar is working as expected.

Except on your screenshot `app.asar` is not a directory, what is it? a symlink?


> I'm okay with leaving this ticket open for now, and I might submit another ticket to `electron-builder` and see if they can help.

But so far we have not yet verified what is the actual path on disk of `libdeepspeech.so` and whether the electron code does set `PATH` that matches this directory.
I'm sorry to insist, but I don't have any ready-to-use Windows environment so I can't analyze myself and I entirely depend on you for that :/",know everything related work mac like assume working except directory leaving ticket open might submit another ticket see help far yet actual path disk whether electron code set path directory sorry insist environment ca analyze entirely depend,issue,positive,negative,neutral,neutral,negative,negative
654933686,"We do know that everything related to app.asar and deepspeech works as expected in Mac and Linux.  So I'd like to assume app.asar is working as expected.

```
We still don't know if the PATH value being put into the process is good. And even if it's good, are we changing the correct process' PATH ? Who knows what electron-builder does with its processes?
```

Yeah it's very unclear what's going wrong.

I'm okay with leaving this ticket open for now, and I might submit another ticket to `electron-builder` and see if they can help.",know everything related work mac like assume working still know path value put process good even good correct process path yeah unclear going wrong leaving ticket open might submit another ticket see help,issue,positive,positive,positive,positive,positive,positive
654927284,"> The deepspeech index.js file is found correctly `win-unpacked\resources\app.asar\node_modules\deepspeech\index.js`

And this one refers to `app.asar`



> I also confirmed that the JS file can find `deepspeech.node` properly by modifying deepspeech/index.js with:

And there we know the error refers to `app.asar.unpacked`

So given I know nothing about how `electron-builder` works, I can't know if it's normal or not we have two different path referenced here.

I'm sorry, but this issue is really becoming messy and we are circling here. We still don't know if the `PATH` value being put into the process is good. And even if it's good, are we changing the correct process' `PATH` ? Who knows what `electron-builder` does with its processes?

`\\?\C:\Users\Dan\AppData\Local\Programs\mytestapp\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node` Should load `\\?\C:\Users\Dan\AppData\Local\Programs\mytestapp\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\libdeepspeech.so`, so `PATH` of the process doing the `LoadLibrary(""deepspeech.node"")` should contain `\\?\C:\Users\Dan\AppData\Local\Programs\mytestapp\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\`",file found correctly one also confirmed file find properly know error given know nothing work ca know normal two different path sorry issue really becoming messy circling still know path value put process good even good correct process path load path process contain,issue,negative,positive,positive,positive,positive,positive
654922567,"But the error is not that app.asar is failing in any way.  

The deepspeech index.js file is found correctly `win-unpacked\resources\app.asar\node_modules\deepspeech\index.js`

It loads correctly, and then it does `require(binding_path)` and fails because `deepspeech.node` is not found.  But the file exists, at least it exists in the unpacked directory.

![expand](https://user-images.githubusercontent.com/3894317/86800215-cabc4f00-c040-11ea-9881-9fa3c4c9b54d.png)

I also confirmed that the JS file can find `deepspeech.node` properly by modifying deepspeech/index.js with:

```
try {
    const binding = require(binding_path);
}
catch(e) {
    console.log('binding error', binding_path);
    console.log('binding_path exists?', require('fs').existsSync(binding_path));
    console.error(e);
    process.exit();
}
```

binding_path is the location of deepspeech.node.  So why the error is occurring is a mystery.",error failing way file found correctly correctly require found file least unpacked directory expand also confirmed file find properly try binding require catch error require location error mystery,issue,negative,positive,neutral,neutral,positive,positive
654914785,"> It gets more confusing because the win-unpacked directory contains both the packed app.asar and app.asar.unpacked.

On this image, `app.asar` is not a directory. Can you show the full tree from top-level of the electron app ?



> I think it's kinda like how jar files auto-expand.

Which I don't know about :D",directory image directory show full tree electron think like jar know,issue,negative,positive,positive,positive,positive,positive
654912821,"It gets more confusing because the win-unpacked directory contains both the packed app.asar and app.asar.unpacked.

I think it's kinda like how jar files auto-expand.

![unpacked](https://user-images.githubusercontent.com/3894317/86798350-aeb7ae00-c03e-11ea-9a7c-37efacd1aec2.png)
",directory think like jar unpacked,issue,negative,neutral,neutral,neutral,neutral,neutral
654907156,"> The error I pasted containing `win-unpacked` was from when I tried running the unpacked version.

Right, but check all path components, there's also a discrepency between the loader code vs the paht trying to be loaded involving `app.asar.unpacked` VS `app.asar` :/",error pasted tried running unpacked version right check path also loader code trying loaded,issue,negative,positive,positive,positive,positive,positive
654906495,"> > I'm not entirely sure what you mean here. It's not that app.asar isn't found, it seems like ""deepspeech.node"" is not found, but the path is correct, the file exists.
> 
> Sorry but here you quote `app.asar` and you link `app.asar.unpacked`, so it's confusing and I still don't know if we have the valid physical path being set or not.

Oh I should have clarified.  When a build is made using `npm run dist-win`, it creates a `win-unpacked` directory containing the production build, but in an ""unpacked"" format and that can be run directly from the `win-unpacked` directory.  The error I pasted containing `win-unpacked` was from when I tried running the unpacked version. 

The error also occurs if you take the fully packed .exe installer, install it, and run it.",entirely sure mean found like found path correct file sorry quote link still know valid physical path set oh build made run directory production build unpacked format run directly directory error pasted tried running unpacked version error also take fully installer install run,issue,negative,negative,neutral,neutral,negative,negative
654906111,"> I still don't 100% know what that error really means or what to change. It's very weird.

Thing is, it's not always clear on Windows if it's just wrong path or missing dependencies :/ I wish there was some equivalent of `LD_DEBUG=` there.",still know error really change weird thing always clear wrong path missing wish equivalent,issue,negative,negative,negative,negative,negative,negative
654903957,"> I'm not entirely sure what you mean here. It's not that app.asar isn't found, it seems like ""deepspeech.node"" is not found, but the path is correct, the file exists.

Sorry but here you quote `app.asar` and you link `app.asar.unpacked`, so it's confusing and I still don't know if we have the valid physical path being set or not.",entirely sure mean found like found path correct file sorry quote link still know valid physical path set,issue,positive,negative,neutral,neutral,negative,negative
654902693,"> > > Why do we have `app.asar.unpacked` VS `app.asar`
> > 
> > 
> > I can't actually answer this very well. But the asar format is what electron-builder uses, and when you make a build, it creates the unpacked version and the packed version. And when you install it, it unpacks it before running it. I'm not exactly very clear on what's going on, but it is almost certainly involved in why a `module not found` error is occurring.
> 
> that's also my reading of the issue so far, especially since your `console.log`. Could we please try and hack a hardcoded `PATH` here to `app.asar` maybe? If it's just about computing the proper path, it can be an easy fix ...

I'm not entirely sure what you mean here.  It's not that app.asar isn't found, it seems like ""deepspeech.node"" is not found, but the path is correct, the file exists.

```
Error: The specified module could not be found.
\\?\C:\Users\Dan\AppData\Local\Programs\mytestapp\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
```

I still don't 100% know what that error really means or what to change.  It's very weird.",ca actually answer well format make build unpacked version version install running exactly clear going almost certainly involved module found error also reading issue far especially since could please try hack path maybe proper path easy fix entirely sure mean found like found path correct file error module could found still know error really change weird,issue,positive,positive,neutral,neutral,positive,positive
654888056,"> > Why do we have `app.asar.unpacked` VS `app.asar`
> 
> I can't actually answer this very well. But the asar format is what electron-builder uses, and when you make a build, it creates the unpacked version and the packed version. And when you install it, it unpacks it before running it. I'm not exactly very clear on what's going on, but it is almost certainly involved in why a `module not found` error is occurring.

that's also my reading of the issue so far, especially since your `console.log`. Could we please try and hack a hardcoded `PATH` here to `app.asar` maybe? If it's just about computing the proper path, it can be an easy fix ...",ca actually answer well format make build unpacked version version install running exactly clear going almost certainly involved module found error also reading issue far especially since could please try hack path maybe proper path easy fix,issue,positive,positive,positive,positive,positive,positive
654882670,"> Why do we have `app.asar.unpacked` VS `app.asar`

I can't actually answer this very well.  But the asar format is what electron-builder uses, and when you make a build, it creates the unpacked version and the packed version.  And when you install it, it unpacks it before running it.  I'm not exactly very clear on what's going on, but it is almost certainly involved in why a `module not found` error is occurring.",ca actually answer well format make build unpacked version version install running exactly clear going almost certainly involved module found error,issue,negative,positive,positive,positive,positive,positive
654875445,"Yeah it actually took me more like a whole day to get it all working.

I could provide the .exe, I just need to regenerate it, and a place to upload it.",yeah actually took like whole day get working could provide need regenerate place,issue,positive,positive,neutral,neutral,positive,positive
654874044,"> Yes there are some other Visual Studio and Python dependencies as well to be able to compile native NodeJS modules. I would probably have to start again from a fresh Windows machine to be able to give exact instructions.

Okay, that's going to take me hours ...",yes visual studio python well able compile native would probably start fresh machine able give exact going take,issue,positive,positive,positive,positive,positive,positive
654873209,"> I only did a console log on the PATH variable, it does appear to be adding the directory that the code intends to. But I think that directory isn't the one that's necessary for the app.asar package.

Can you share a built package, maybe I can investigate and check how it should be built?",console log path variable appear directory code think directory one necessary package share built package maybe investigate check built,issue,negative,neutral,neutral,neutral,neutral,neutral
654869863,"> > but it sure looks like it might be because of some incompatibility with that the PATH handling and the ""app.asar"" package forrmat that electron-builder uses.
> 
> Have you verified the `PATH` value ? Does the code adds a valid path to that ?

I only did a console log on the PATH variable, it does appear to be adding the directory that the code intends to.  But I think that directory isn't the one that's necessary for  the app.asar package.  I don't know know a whole lot about that format but it does appear to be troublesome for locating other files as well.  This really where my comprehension of the problem breaks down because I don't know enough about electron, electron-builder, and deepspeech.",sure like might incompatibility path handling package path value code valid path console log path variable appear directory code think directory one necessary package know know whole lot format appear troublesome well really comprehension problem know enough electron,issue,negative,positive,positive,positive,positive,positive
654866640,"> > Click the resulting installer exe file in the `dist` directory. Then running the ""deepspeech-electron"" app from the system menu will fail with the error in the screenshot above.
> 
> What else do I need to install on a Windows machine to do that? NodeJS ? What version ? Any Visual Studio stuff ?

I installed Git Bash to provide a bash terminal.  I'd have to reboot to give you the NodeJS version, but I think it's the latest version (v14).

Yes there are some other Visual Studio and Python dependencies as well to be able to compile native NodeJS modules.  I would probably have to start again from a fresh Windows machine to be able to give exact instructions.

Basically I started with the Windows instructions here: 

https://github.com/nodejs/node-gyp",click resulting installer file directory running system menu fail error else need install machine version visual studio stuff git bash provide bash terminal give version think latest version yes visual studio python well able compile native would probably start fresh machine able give exact basically,issue,negative,positive,positive,positive,positive,positive
654861939,"> but it sure looks like it might be because of some incompatibility with that the PATH handling and the ""app.asar"" package forrmat that electron-builder uses.

Have you verified the `PATH` value ? Does the code adds a valid path to that ?",sure like might incompatibility path handling package path value code valid path,issue,positive,positive,positive,positive,positive,positive
654859832,"> Click the resulting installer exe file in the `dist` directory. Then running the ""deepspeech-electron"" app from the system menu will fail with the error in the screenshot above.

What else do I need to install on a Windows machine to do that? NodeJS ? What version ? Any Visual Studio stuff ?",click resulting installer file directory running system menu fail error else need install machine version visual studio stuff,issue,negative,negative,negative,negative,negative,negative
654829291,"The pull request is there.

To replicate the issue in Windows:

```
npm install
npm run rebuild
export BROWSER=none
npm run dev-win
npm run dist-win
```

Click the resulting installer exe file in the `dist` directory.  Then running the ""deepspeech-electron"" app from the system menu will fail with the error in the screenshot above.

This process works on Mac and Windows (using `npm run dev` and `npm run dist`).  And I'm still confused about exactly why this isn't working in Windows, but it sure looks like it might be because of some incompatibility with that the PATH handling and the ""app.asar"" package forrmat that electron-builder uses.",pull request replicate issue install run rebuild export run run click resulting installer file directory running system menu fail error process work mac run dev run still confused exactly working sure like might incompatibility path handling package,issue,negative,negative,neutral,neutral,negative,negative
654776862,Thanks @satishbanka for confirming it was just running master instead of 0.7.4,thanks confirming running master instead,issue,negative,positive,positive,positive,positive,positive
654775847,"@filipecatraia Please ensure you have checked out `v0.7.4` tag, there should be no problem on that version.",please ensure checked tag problem version,issue,negative,neutral,neutral,neutral,neutral,neutral
654381143,Thanks very much for your quick response guys! Truly appreciate Mozilla and mainly your dedication and hard work!,thanks much quick response truly appreciate mainly dedication hard work,issue,positive,positive,positive,positive,positive,positive
654380577,"> v0.7.4 version of that file does not import from ds_ctcdecoder, since it's before the refactoring: https://github.com/mozilla/DeepSpeech/blob/v0.7.4/training/deepspeech_training/util/config.py
> 
> It looks like you're running the master version of the code, but using the v0.7.4 version of the decoder.

Hi Reuben, Yes I am using the master version of the code. I got it cloned from
""git clone https://github.com/mozilla/DeepSpeech""

I thought that was the 0.7.4

Sorry for the confusion, I will use the 0.7.4 code now
",version file import since like running master version code version hi yes master version code got git clone thought sorry confusion use code,issue,negative,negative,negative,negative,negative,negative
654378872,"> > I have upgraded deepspeech from 0.7.1 to 0.7.4.
> 
> How ?
> 
> > running transcribe.py.
> 
> How ?

Yes Got this issue while running Transcribe.py",running yes got issue running,issue,negative,neutral,neutral,neutral,neutral,neutral
654367138,"@carlfm01 i know you are super busy, would you have suggestions to debug linkage issues at runtime ? ",know super busy would linkage,issue,positive,positive,positive,positive,positive,positive
654359988,"Yeah I'd like to submit this example to the 0.8 release.

https://github.com/dsteinman/deepspeech-electron

I can also add a better version of the [nodejs_wav](https://github.com/mozilla/DeepSpeech-examples/tree/r0.7/nodejs_wav) example code.

That way we can all get on the same page about what actually going wrong when the .exe is packaged.  I don't have really any experience in debugging C code and not in Windows either, so it'll be tough for me to make much progress on my own.

Right now I'm just trying to adjust that electron example so the package does build correctly for Mac and Linux platforms -- at the moment it's not working on any.",yeah like submit example release also add better version example code way get page actually going wrong really experience code either tough make much progress right trying adjust electron example package build correctly mac moment working,issue,positive,positive,neutral,neutral,positive,positive
654317261,@satishbanka Could you please verify if it works?,could please verify work,issue,negative,neutral,neutral,neutral,neutral,neutral
654316693,"@dsteinman We'd like to find a fix for that by 0.8, so your help is more than valuable: in the worst case, if you can pop up with a very simple and dumb-proof example to repro, that would help. But please remember we don't use Windows, so it really needs to be dump-proof to avoid making us loose any time.",like find fix help valuable worst case pop simple example would help please remember use really need avoid making u loose time,issue,positive,negative,negative,negative,negative,negative
654313638,"> What is missing from what I ran before?
> `valgrind --tool=memcheck --suppressions=valgrind-python.supp python -E -tt mem_test.py`

```
--25363-- Valgrind options:
--25363--    -v
--25363--    --log-file=std-unique_ptr.0.log
--25363--    --leak-check=full
--25363--    --leak-resolution=high
--25363--    --show-reachable=yes
```",missing ran python log,issue,negative,negative,negative,negative,negative,negative
654310075,"@kdavis-mozilla Hello, I need to confirm that this command : `--add Microsoft.VisualStudio.ComponentGroup.UWP.BuildTools;includeRecommended --add Microsoft.NetCore.Component.SDK;includeRecommended --add Microsoft.VisualStudio.Component.Windows10SDK.18362;includeRecommended`
fixes the issue, the thing is that I need to uninstall VS to confirm and can't do it on my daylight, I plan to finish this within the next two days
(with vs installed is not working)",hello need confirm command add add add issue thing need confirm ca daylight plan finish within next two day working,issue,negative,neutral,neutral,neutral,neutral,neutral
654308293,"> > Another question is, I saw the inference side of DeepSpeech seems to work now on tensorflow 2.x, how much work would the training side be ?
> 
> Lots
That is unfortunate.


> > Another question is, I saw the inference side of DeepSpeech seems to work now on tensorflow 2.x, how much work would the training side be ?
> 
> @reuben Had a look at that, he knows better.
> 
> > What would you like to have shared, only the csv or also the samples (as I think it would be somewhere in the samples and not the transcripts (but of course I could be wrong) ?
> 
> I think you should need to share audio + csv

OK, will do. 


> > > 
> > 
> > 
> > Merely reduced the problem-space, not of the tensorflow / deepspeech internals.
> > And it would be nice if people could confirm (so it can be semi-worked around by not sorting).
> 
> Sure, but given the current workload, I really cannot promise having time to reproduce that: I am still lagging behind a lot of other super-urgents matters, sadly (thank you covid-19).

OK, I will do some more experiments then, try to pinpoint it some more.
Try to find out if only the batch content matters, or also the state the graph /weights are in from the previous steps.
If only the batch content matters, I will test what happens if you only shuffle that.
",another question saw inference side work much work would training side lot unfortunate another question saw inference side work much work would training side look better would like also think would somewhere course could wrong think need share audio merely reduced internals would nice people could confirm around sure given current really promise time reproduce still lagging behind lot sadly thank try pinpoint try find batch content also state graph previous batch content test shuffle,issue,positive,negative,neutral,neutral,negative,negative
654299458,"> Another question is, I saw the inference side of DeepSpeech seems to work now on tensorflow 2.x, how much work would the training side be ?

Lots",another question saw inference side work much work would training side lot,issue,negative,positive,positive,positive,positive,positive
654291607,"> I'm not sure which module this is referring to `Error: The specified module could not be found.`. Could this mean the C binding cannot find the JS module? And if so, maybe it's because in this scenario the path being added onto process.env['PATH'] isn't valid.

Please verify that, I don't use Windows and I could not find proper documentation on how to get useful informations from the Windows linker (like `ld` with `LD_DEBUG=all`). So far, we still don't know if your `deepspeech.node` loading code can actually see `libdeepspeech.so`, i.e., `PATH` is properly populated **and** the windows linker sees it.

Maybe you should use sysinternals's `depends.exe` and check if `deepspeech.node` has extra deps that we missed, or if `libdeepspeech.so` has, etc.",sure module error module could could mean binding find module maybe scenario path added onto valid please verify use could find proper documentation get useful linker like far still know loading code actually see path properly linker maybe use check extra,issue,positive,positive,neutral,neutral,positive,positive
654284466,"> Another question is, I saw the inference side of DeepSpeech seems to work now on tensorflow 2.x, how much work would the training side be ?

@reuben Had a look at that, he knows better.



> What would you like to have shared, only the csv or also the samples (as I think it would be somewhere in the samples and not the transcripts (but of course I could be wrong) ?

I think you should need to share audio + csv



> > 
> 
> Merely reduced the problem-space, not of the tensorflow / deepspeech internals.
> And it would be nice if people could confirm (so it can be semi-worked around by not sorting).

Sure, but given the current workload, I really cannot promise having time to reproduce that: I am still lagging behind a lot of other super-urgents matters, sadly (thank you covid-19).",another question saw inference side work much work would training side look better would like also think would somewhere course could wrong think need share audio merely reduced internals would nice people could confirm around sure given current really promise time reproduce still lagging behind lot sadly thank,issue,positive,positive,neutral,neutral,positive,positive
654264327,"At Line 16, I did this:

```
try {
    const binding = require(binding_path);
}
catch(e) {
    console.log('binding error', binding_path);
    console.log('binding_path exists?', require('fs').existsSync(binding_path));
    console.error(e);
    process.exit();
}
```

So it's finding the deepspeech.node file just fine, I think the error must be coming from within it not because of it.

```
binding error C:\Users\Dan\dev\deepspeech-electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
binding_path exists? true
Error: The specified module could not be found.
\\?\C:\Users\Dan\dev\deepspeech-electron\dist\win-unpacked\resources\app.asar.unpacked\node_modules\deepspeech\lib\binding\v0.7.4\win32-x64\electron-v9.0\deepspeech.node
    at process.func [as dlopen] (electron/js2c/asar.js:140:31)
    at Object.Module._extensions..node (internal/modules/cjs/loader.js:1034:18)
    at Object.func [as .node] (electron/js2c/asar.js:149:18)
    at Module.load (internal/modules/cjs/loader.js:815:32)
    at Module._load (internal/modules/cjs/loader.js:727:14)
    at Function.Module._load (electron/js2c/asar.js:769:28)
    at Module.require (internal/modules/cjs/loader.js:852:19)
    at require (internal/modules/cjs/helpers.js:74:18)
    at Object.<anonymous> (C:\Users\Dan\dev\deepspeech-electron\dist\win-unpacked\resources\app.asar\node_modules\deepspeech\index.js:33:21)
    at Module._compile (internal/modules/cjs/loader.js:967:30)
```

I'm not sure which module this is referring to `Error: The specified module could not be found.`.  Could this mean the C binding cannot find the JS module?  And if so, maybe it's because in this scenario the path being added onto process.env['PATH'] isn't valid.",line try binding require catch error require finding file fine think error must coming within binding error true error module could found node require anonymous sure module error module could could mean binding find module maybe scenario path added onto valid,issue,negative,positive,positive,positive,positive,positive
654252255,"> > ```
> > * So I tried  with the sorting from the sample loading replaced with a random.shuffle(), and training with CUDNN now doesn't blow up. Even with the whole dataset (about 280000 samples).
> > ```
> 
> It would still be interesting if you could share the order when it works, when it fails, and where it fails.

What would you like to have shared,  only the csv or also the samples (as I think it would be somewhere in the samples and not the transcripts (but of course I could be wrong) ?",tried sample loading training blow even whole would still interesting could share order work would like also think would somewhere course could wrong,issue,positive,positive,neutral,neutral,positive,positive
654251015,"> > I think the dataset subset is small enough to provide you with (around 20mb of samples), if that could help you determine as to why it actually blows up.
> 
> If it's a bug in TensorFlow / CUDNN, it's hardly something we can help about. I'm already lacking time for a lot of other urgents matters, and it seems you have more background and knowledge on the issue than I do ...

Merely reduced the problem-space, not of the tensorflow / deepspeech internals.
And it would be nice if people could confirm (so it can be semi-worked around by not sorting).

Another question is, I saw the inference side of DeepSpeech seems to work now on tensorflow 2.x, how much work would the training side be ?
(I ask, since the whole chain of cuda 10, tensorflow 1.15 etc. is probably unsupported by Nvidia as well, so we probably won't get any support from that side as well. And as there are several people now reporting issues with training on current deepspeech in this thread ...)",think subset small enough provide around could help determine actually bug hardly something help already time lot background knowledge issue merely reduced internals would nice people could confirm around another question saw inference side work much work would training side ask since whole chain probably unsupported well probably wo get support side well several people training current thread,issue,positive,negative,neutral,neutral,negative,negative
654247761,">     * So I tried  with the sorting from the sample loading replaced with a random.shuffle(), and training with CUDNN now doesn't blow up. Even with the whole dataset (about 280000 samples).

It would still be interesting if you could share the order when it works, when it fails, and where it fails.",tried sample loading training blow even whole would still interesting could share order work,issue,positive,positive,positive,positive,positive,positive
654243300,"> I think the dataset subset is small enough to provide you with (around 20mb of samples), if that could help you determine as to why it actually blows up.

If it's a bug in TensorFlow / CUDNN, it's hardly something we can help about. I'm already lacking time for a lot of other urgents matters, and it seems you have more background and knowledge on the issue than I do ...",think subset small enough provide around could help determine actually bug hardly something help already time lot background knowledge issue,issue,positive,negative,negative,negative,negative,negative
654236879,"@lissyx 
As I am also effected by this, I tried everything from python versions, different dockerbuild, different host drivers, checking my dataset for evident errors,  all had no effect.

But because if it fails it always consistently fails on the same step and thus batch I tried to isolate stuff.
I know have a small subset of my large dataset and that always fails on epoch 27 with batch size 32, so it's under 1500 samples and thus manageable in size.

I made some discoveries though:

- Training with CPUhas succeeded in the past (not repeated yet on this small dataset).
- Training with GPU with batch size 1 has succeeded in the past (not repeated yet on this small dataset).
- If it fails, it always consistently fails on the same step.
- So I tried  with the sorting from the sample loading replaced with a random.shuffle(), and training with CUDNN now doesn't blow up. Even with the whole dataset (about 280000 samples).

So it seems that the combination (and probably order) of certain samples in a batch blows up with CUDNN consistently
(and in any other combination or order, they don't).

I think the dataset subset is small enough to provide you with (around 20mb of samples), if that could help you determine as to why it actually blows up.
(and provide the docker build script, run script, logging and the patches I applied to the v0.7.4 tree (only the printing of files in the batches and replacing the sort with the shuffle). 
",also tried everything python different different host evident effect always consistently step thus batch tried isolate stuff know small subset large always epoch batch size thus manageable size made though training past repeated yet small training batch size past repeated yet small always consistently step tried sample loading training blow even whole combination probably order certain batch consistently combination order think subset small enough provide around could help determine actually provide docker build script run script logging applied tree printing sort shuffle,issue,negative,positive,neutral,neutral,positive,positive
654187826,"> I see what you mean about the Path variable. Just looking at this code, I am pretty sure something is wrong here:
> 
> ```
> if (process.platform === 'win32') {
>     const dslib_path = path.resolve(path.join(binding_path, '../..'));
>     var oldPath = process.env.PATH;
>     process.env['PATH'] = `${dslib_path};${process.env.PATH}`;
> }
> ```
> 
> It looks like deepspeech module trying to modify the system PATH variable? Why?

Because we can't set `rpath` on Windows, and because without that it's unable to properly find the library where it is, the Windows linker searches in the same directory as `deepspeech.node` and in `PATH`. But `deepspeech-node` is dependant on the version, and so expecting the linker to find `libdeepspeech.so` next to it would mean a lot of copies of `libdeepspeech.so`, ending up in use space wasting. And given how `npm` works for publishing modules, it would explode because the package is too big (it already did when we were bundling more CUDA compute compatibility versions).",see mean path variable looking code pretty sure something wrong like module trying modify system path variable ca set without unable properly find library linker directory path version linker find next would mean lot ending use space wasting given work would explode package big already compute compatibility,issue,negative,negative,neutral,neutral,negative,negative
654174219,"I see what you mean about the Path variable.  Just looking at this code, I am pretty sure something is wrong here:

```
if (process.platform === 'win32') {
    const dslib_path = path.resolve(path.join(binding_path, '../..'));
    var oldPath = process.env.PATH;
    process.env['PATH'] = `${dslib_path};${process.env.PATH}`;
}
```

It looks like deepspeech module trying to modify the system PATH variable?  Why?",see mean path variable looking code pretty sure something wrong like module trying modify system path variable,issue,positive,negative,neutral,neutral,negative,negative
654141753,"> We tried running it with Python 3.7 but we faced the same error.

Then I'm sorry but the only way to get something actionable is bisecting on the dataset to identify the offending files and debug from there.",tried running python faced error sorry way get something actionable identify,issue,negative,negative,negative,negative,negative,negative
654138500,We tried running it with Python 3.7 but we faced the same error.,tried running python faced error,issue,negative,neutral,neutral,neutral,neutral,neutral
654127769,I think so... I triggered a new alpha on master so that `pip install -U -e .` will pick up the new decoder package.,think triggered new alpha master pip install pick new package,issue,negative,positive,positive,positive,positive,positive
654127188,"@reuben Ah yes, missed that. Could it be closed then?",ah yes could closed,issue,negative,negative,neutral,neutral,negative,negative
654123523,"v0.7.4 version of that file does not import from ds_ctcdecoder, since it's before the refactoring: https://github.com/mozilla/DeepSpeech/blob/v0.7.4/training/deepspeech_training/util/config.py

It looks like you're running the master version of the code, but using the v0.7.4 version of the decoder.",version file import since like running master version code version,issue,negative,neutral,neutral,neutral,neutral,neutral
654122084,This is a post-refactoring problem caused by de-duplication of the two alphabet classes we once had. Some of the importers are also affected.,problem two alphabet class also affected,issue,negative,neutral,neutral,neutral,neutral,neutral
654115218,"> It might not be required to know much about electron-builder to be able to fix the problem -- I don't know much about it other than I'm trying to use it to create a packaged version of my electron app. Electron-builder is one of only 2 ways to do this, the other being Electron Forge.

My point being that, as you says, there are ""only two ways to do it"", but us not being users of Electron, we can't spend all our time learning all the oddities of each ecosystem, so your feedback is valuable.

> It's actually a pretty good example, it's kind of similar to the JS examples I provided earlier but doesn't rely on sox.

Then maybe it should be run next to our current code for testing ElectronJS ?
If you add that to `DeepSpeech-examples` with a `test.sh` file similar to existing ones, it would help



> If you try this example on Windows, using `npm run dist-win` and run the executable it will show the error:

I don't know if it's meaningful, but it's like there is no mention of our code being ran. You relaly need to check if https://github.com/mozilla/DeepSpeech/blob/66d1f167fc9ac93e0903a70a56f4e2426095a9a9/native_client/javascript/index.ts#L4-L20 is doing the right expected thing.",might know much able fix problem know much trying use create version electron one way electron forge point two way u electron ca spend time learning ecosystem feedback valuable actually pretty good example kind similar provided rely maybe run next current code testing add file similar would help try example run run executable show error know meaningful like mention code ran need check right thing,issue,positive,positive,positive,positive,positive,positive
653920957,"> Again, i know nothing about electron-builder.

It might not be required to know much about electron-builder to be able to fix the problem -- I don't know much about it other than I'm trying to use it to create a packaged version of my electron app.  Electron-builder is one of only 2 ways to do this, the other being Electron Forge.

My example app is already done, it has electron-builder set up, and does duplicate the issue.  It's here:

https://github.com/dsteinman/deepspeech-electron

It's actually a pretty good example, it's kind of similar to the JS examples I provided earlier but doesn't rely on sox.

If you try this example on Windows, using `npm run dist-win` and run the executable it will show the error:

![electron-error](https://user-images.githubusercontent.com/3894317/86539124-3cbd5880-bec8-11ea-9b39-51a03659f0d8.png)

And if you run `npm run dist` on Mac or Linux it will work just fine.",know nothing might know much able fix problem know much trying use create version electron one way electron forge example already done set duplicate issue actually pretty good example kind similar provided rely try example run run executable show error run run mac work fine,issue,positive,positive,positive,positive,positive,positive
653918816,"> Perhaps we could add electron-builder to the test coverage? The whole reason to use Electron is to be able to produce a .exe/.dmg/.appimage that can be distributed and installed -- and this does not appear to be working for Windows, but does work for Mac and Linux.

Again, i know nothing about electron-builder. ",perhaps could add test coverage whole reason use electron able produce distributed appear working work mac know nothing,issue,negative,positive,positive,positive,positive,positive
653918392,"Perhaps we could add electron-builder to the test coverage?  The whole reason to use Electron is to be able to produce a .exe/.dmg/.appimage that can be distributed and installed -- and this does not appear to be working for Windows, but does work for Mac and Linux.",perhaps could add test coverage whole reason use electron able produce distributed appear working work mac,issue,negative,positive,positive,positive,positive,positive
653917911,"We already have test coverage for electron, but not using this.",already test coverage electron,issue,negative,neutral,neutral,neutral,neutral,neutral
653916216,"Yeah I'll need to debug a bit and find out what the actual file path it's looking for `deepspeech.node`, either the file isn't there or needs to be fixed/changed for electron-builder.

I'm going to add an electron example to the [DeepSpeech-examples](https://github.com/mozilla/DeepSpeech-examples) repository and make sure it replicates this problem.",yeah need bit find actual file path looking either file need going add electron example repository make sure problem,issue,negative,positive,positive,positive,positive,positive
653914669,"> but something related to how the DeepSpeech module is accessing the deepspeech.node file is not working when run inside an .exe -- either after installing, or running from the `win-unpacked` directory.

So yeah, please verify / investigate how index.ts/js loads deepspeech.node using node-pre-gyp and how we set `PATH`. ",something related module file working run inside either running directory yeah please verify investigate set path,issue,positive,neutral,neutral,neutral,neutral,neutral
653914277,"I'm sorry but i know nothing about this, i dont use electronjs nor Windows. I shared you hints, but again i don't know how to debug the linker under Windows.

Please investigate ans verify what i suggested earlier.",sorry know nothing dont use know linker please investigate verify,issue,negative,negative,negative,negative,negative,negative
653893416,"Yes it builds fine, this is a runtime error the moment I access require('deepspeech').

Everything works perfect in MacOS (dmg) and Linux (appimage).  And the Windows version works fine in development mode, but something related to how the DeepSpeech module is accessing the deepspeech.node file is not working when run inside an .exe -- either after installing, or running from the `win-unpacked` directory.

The way electron-builder uses the app.asar system to package the files is probably be the true culprit because that directly is involved with locating files in a package format.  But I don't know how to determine this.

I initially thought perhaps it was because I was running DeepSpeech inside a forked node processes, but I've just ruled that out, it also occurs when loading require('deepspeech') directly from my main electron javascript launcher file `public/electron.js`.

I'm am relying on other native modules, but they work and all get rebuilt so they are not in the same `\resources\app.asar.unpacked\node_modules\` directory where deepspeech resides.  That directory only contains one other module which I am not using, so deepspeech is the only module that is working in this manner.

I'll try make a small electron project that duplicate the problem outside the rest of my app.",yes fine error moment access require everything work perfect version work fine development mode something related module file working run inside either running directory way system package probably true culprit directly involved package format know determine initially thought perhaps running inside forked node also loading require directly main electron launcher file native work get rebuilt directory directory one module module working manner try make small electron project duplicate problem outside rest,issue,positive,positive,positive,positive,positive,positive
653862396,"> Basically, after creating the Windows exe installer (`npm run dist` from electron-builder), if I find the executable in my file system and run it directly from Git Bash, I can see the error messages in the console, and I receive this:

So the build process is fine ?

I'd suspect its the linker failing to find libdeepspeech.so,we have code somewhere to force set `PATH` on Windows to help with this, maybe its not being properly done with your setup ? It should be in index.ts/js",basically installer run find executable file system run directly git bash see error console receive build process fine suspect linker failing find code somewhere force set path help maybe properly done setup,issue,negative,positive,positive,positive,positive,positive
653845318,"Please refer to [Training Your Own Model](url) section of the documentation, in particular the exporting sections.

Also, in future, support questions should be directed to our [discourse](https://discourse.mozilla.org/c/deep-speech/247) board.

We reserve issues for bugs or new feature requests.",please refer training model section documentation particular also future support directed discourse board reserve new feature,issue,positive,positive,positive,positive,positive,positive
653784140,"> @khu834 We have had reports in the past of problem with conda / anaconda / miniconda. Can you try and repro with vanilla python? Also in this log I can't find any leak reference (except in the summary), only invalid read size / uninitialized values (which concerns me, hence the python stuff). Can you repro with proper CLI parameters for tracking leaks?

Can you provide some details about what ""proper CLI parameters for tracking leaks"" mean?
I'll get started on this but want to make sure I run it under the right conditions.

What is missing from what I ran before?
```valgrind --tool=memcheck --suppressions=valgrind-python.supp python -E -tt mem_test.py```",khu past problem anaconda try vanilla python also log ca find leak reference except summary invalid read size hence python stuff proper provide proper mean get want make sure run right missing ran python,issue,negative,positive,neutral,neutral,positive,positive
653744192,"> > Using current master doesn't work for the German model anymore, seems the graph code got changed in-between because now it wants another shape:
> > `ValueError: Cannot feed value of shape (29,) for Tensor 'layer_6/bias/Initializer/zeros:0', which has shape '(30,)'`
> 
> This might be a regression from a recent refactoring that removed the Python Alphabet implementation in favor of the C++ one.

It looks like it is indeed the case, I was able to reproduce it. Should be fixed by #3125.",current master work german model graph code got another shape feed value shape tensor shape might regression recent removed python alphabet implementation favor one like indeed case able reproduce fixed,issue,positive,positive,positive,positive,positive,positive
653587016,"> Did you modify `data/alphabet.txt` in-place? I don't see an `--alphabet` parameter specified. In any case, the error here indicates you're not passing the same `--alphabet` file at export time that you used for training this checkpoint.

Thanks, this solved it. I did try it before, but only in the current master container it seems ... (didn't help there)

",modify see alphabet parameter case error passing alphabet file export time used training thanks try current master container help,issue,negative,positive,neutral,neutral,positive,positive
653581597,"> Using current master doesn't work for the German model anymore, seems the graph code got changed in-between because now it wants another shape:
> `ValueError: Cannot feed value of shape (29,) for Tensor 'layer_6/bias/Initializer/zeros:0', which has shape '(30,)'`

This might be a regression from a recent refactoring that removed the Python Alphabet implementation in favor of the C++ one.",current master work german model graph code got another shape feed value shape tensor shape might regression recent removed python alphabet implementation favor one,issue,positive,neutral,neutral,neutral,neutral,neutral
653576148,"Did you modify `data/alphabet.txt` in-place? I don't see an `--alphabet` parameter specified. In any case, the error here indicates you're not passing the same `--alphabet` file at export time that you used for training this checkpoint.",modify see alphabet parameter case error passing alphabet file export time used training,issue,negative,neutral,neutral,neutral,neutral,neutral
653038380,"Ok, Docker Hub Automated builds can support `hooks/`, so we might be able to rely on that for push-to-tag on releases.",docker hub support might able rely,issue,negative,positive,positive,positive,positive,positive
652981603,"@carlfm01 Gentle ping, do you need anything on our side to be able to move forward ?",gentle ping need anything side able move forward,issue,negative,positive,positive,positive,positive,positive
652980263,"We already have a template for bug report. I'm not sure we need all the other ones (what difference do you make between improvement and enhancement? what would testing cover? why a PR template?), but please feel free to send PR to explicit your point of view

",already template bug report sure need difference make improvement enhancement would testing cover template please feel free send explicit point view,issue,positive,positive,positive,positive,positive,positive
652920840,"Looks like a red herring, it is properly referenced by other docs.",like red herring properly,issue,negative,neutral,neutral,neutral,neutral,neutral
652883933,"I had the same thought when I saw it, years ago I had to deal with a similar problem for a multi-threaded renderer and it was annoying to deal with.",thought saw ago deal similar problem renderer annoying deal,issue,negative,negative,negative,negative,negative,negative
652882430,"This is basically a nuisance: when you kill a training process it spams the terminal. It'd be nice to fix, but from a cursory glance it requires some hand-holding of Python's multiprocessing module, so I don't think it's enough ""bang for buck"" for my time on 0.8/1.0. Contributions welcome.",basically nuisance kill training process terminal nice fix cursory glance python module think enough bang buck time welcome,issue,negative,positive,positive,positive,positive,positive
652511323,"> CandidateTranscript.getTokens() which returns a single token

it should be an array that can be indexed with `getNum_tokens()`


> Metadata.getTranscripts() which returns a single transcript.

Same",single token array indexed single transcript,issue,negative,negative,neutral,neutral,negative,negative
652269196,">     * [x]  Decouple training from building #3056
> 
>     * [ ]  Create docker hub account
> 
>     * [ ]  Add scriptworker upload ability to docker hub

So the situation is complicated:
 - we might be able to push from scriptworker using https://pypi.org/project/dockertarpush/
 - this code depends on docker image spec v1.1
 - current docker-in-docker service on taskcluster is stuck to docker v1.6, with API v1.18 https://github.com/taskcluster/dind-service/blob/master/Dockerfile#L6
 - so the `docker save` command we issue does produce v1.0 docker image spec
 - kaniko requires being executed from a docker image, but this fails with weird ""HostConfig.NetworkMode"" errors
 - trying to build kaniko + run it (ubuntu 20.04), it fails fetching some debian packages when building the image (?)",training building create docker hub account add ability docker hub situation complicated might able push code docker image spec current service stuck docker docker save command issue produce docker image spec executed docker image weird trying build run fetching building image,issue,positive,negative,negative,negative,negative,negative
652262353,As this is not a bug or feature request could you address this support question to our [Discourse forums](https://discourse.mozilla.org/c/deep-speech) instance. Thank you.,bug feature request could address support question discourse instance thank,issue,positive,neutral,neutral,neutral,neutral,neutral
652220670,"The input to the beam search algorithm is a sequence of probability distributions, not text. See for example: https://distill.pub/2017/ctc/

It's not possible to do that. In the future, use Discourse for discussion. The issue tracker is meant for bugs and feature requests, as was explained in the issue template you deleted before posting this.",input beam search algorithm sequence probability text see example possible future use discourse discussion issue tracker meant feature issue template posting,issue,negative,neutral,neutral,neutral,neutral,neutral
652037325,"> Be aware the existing workers if you copy them to your system are meant for VMWare Fusion Pro

Ah, yes, that was also one of the complications. OK, thanks.",aware copy system meant fusion pro ah yes also one thanks,issue,positive,positive,positive,positive,positive,positive
652034638,"> I assume I can find the appropriate versions and config changes by inspecting the currently running VMs, right? In that case, I just need the IP of worker 1 to get started.

Indeed, you can fetch the json config. IPs on matrix.


> I would probably run that worker on my personal machine while I test it, since it's not meant for general availability.

Be aware the existing workers if you copy them to your system are meant for VMWare Fusion Pro",assume find appropriate currently running right case need worker get indeed fetch matrix would probably run worker personal machine test since meant general availability aware copy system meant fusion pro,issue,negative,positive,positive,positive,positive,positive
652032776,"> You'd have to use the script that is on the worker #1 `prov.sh`, and you'd have to update the base image prior to that because I have not done it:
> 
>     * `generic-worker` version
> 
>     * `taskclusterProxy`
> 
>     * `generic-worker.json` config update

I assume I can find the appropriate versions and config changes by inspecting the currently running VMs, right? In that case, I just need the IP of worker 1 to get started.

> We don't have a nicer way to spin new workers mostly because it's not something we needed to do often and because it'd require again much more tooling. Given the current status of our macOS workers ...

Yeah. I thought about making a VM copy of a worker to side-step these provisioning issues but I guess that's also prone to causing problems.

> Doing that in parallel of running existing infra is likely to be complicated because of ... resources (CPU / RAM). I thought disk would be an issue but that should be fine.

I would probably run that worker on my personal machine while I test it, since it's not meant for general availability.
",use script worker update base image prior done version update assume find appropriate currently running right case need worker get way spin new mostly something often require much tooling given current status yeah thought making copy worker guess also prone causing parallel running infra likely complicated ram thought disk would issue fine would probably run worker personal machine test since meant general availability,issue,negative,positive,neutral,neutral,positive,positive
652026015,"> My probably incomplete idea:
> 
>     1. Make PR against https://github.com/mozilla/community-tc-config/blob/master/config/projects/deepspeech.yml adding new worker instance with -b type.
> 
>     2. Wait for it to be landed and deployed.
> 
>     3. Make a copy of one of the existing worker images, change the worker type, make other modifications, start VM.
> 
>     4. Spawn tasks against new worker type.

You'd have to use the script that is on the worker #1 `prov.sh`, and you'd have to update the base image prior to that because I have not done it:
 - `generic-worker` version
 - `taskclusterProxy`
 - `generic-worker.json` config update

We don't have a nicer way to spin new workers mostly because it's not something we needed to do often and because it'd require again much more tooling. Given the current status of our macOS workers ...

Doing that in parallel of running existing infra is likely to be complicated because of ... resources (CPU / RAM). I thought disk would be an issue but that should be fine.",probably incomplete idea make new worker instance type wait landed make copy one worker change worker type make start spawn new worker type use script worker update base image prior done version update way spin new mostly something often require much tooling given current status parallel running infra likely complicated ram thought disk would issue fine,issue,negative,positive,neutral,neutral,positive,positive
652024075,"> Hello, the thing is you said you didn't changed the dependencies but it doesn't find the download site/version from the text document

Sorry, but I don't understand that statement. I've asked for several things, you've documented nothing. We can't fix bug that we don't reproduce and that you don't explain.",hello thing said find text document sorry understand statement several nothing ca fix bug reproduce explain,issue,negative,negative,negative,negative,negative,negative
652020195,"Hello, the thing is you said you didn't changed the dependencies but it doesn't find the download site/version from the text document",hello thing said find text document,issue,negative,neutral,neutral,neutral,neutral,neutral
651978158,Partially done in #3009. Updated in #3113. Going to add a reference to the main decoder doc as well.,partially done going add reference main doc well,issue,negative,positive,neutral,neutral,positive,positive
651976572,"My probably incomplete idea:
1. Make PR against https://github.com/mozilla/community-tc-config/blob/master/config/projects/deepspeech.yml adding new worker instance with -b type.
2. Wait for it to be landed and deployed.
3. Make a copy of one of the existing worker images, change the worker type, make other modifications, start VM.
4. Spawn tasks against new worker type.",probably incomplete idea make new worker instance type wait landed make copy one worker change worker type make start spawn new worker type,issue,negative,positive,positive,positive,positive,positive
651973819,"@lissyx could you give me a quick overview of what it would take to test changes to macOS workers in an isolated environment? Like, say, adding a macos-heavy-b worker type and spawning tasks with it to test.",could give quick overview would take test isolated environment like say worker type spawning test,issue,negative,positive,positive,positive,positive,positive
651769398,"Some initial tests on device (iPhone Xs), averaged across 3 runs, with the 0.7.4 models:

no scorer, cold cache: RTF 0.60x
no scorer, warm cache: RTF 0.48x
with scorer, cold cache: RTF 0.55x
with scorer, warm cache: RTF 0.24x",initial device across scorer cold cache scorer warm cache scorer cold cache scorer warm cache,issue,negative,neutral,neutral,neutral,neutral,neutral
651677547,"@andrenatal I know you already tested a lot of things, but this forum entry is interesting: https://forums.developer.nvidia.com/t/gpu-crashes-when-running-machine-learning-models/108252
 - the error message is the same
 - it's on gtx 1080 ti
 - issue seems to be related to Python 3.6

Can you give it a spin with Python 3.7 ?",know already tested lot forum entry interesting error message ti issue related python give spin python,issue,negative,positive,positive,positive,positive,positive
651387129,"""Mozilla Public License"" in the docs is referring to the MPL-2.0, there is no inconsistency: https://www.mozilla.org/en-US/MPL/

Thanks for the suggestion about the release notes, I'll add this issue to the next release project so we don't forget to mention the license in the notes.",public license inconsistency thanks suggestion release add issue next release project forget mention license,issue,negative,positive,neutral,neutral,positive,positive
651010892,"> @lissyx Maybe you can better use the github webhooks instead of the scriptworker to link to github on the docker hub page. Also, the automatic builds of docker hub could speed up the pipeline.

There's a reason we use `scriptWorker`, maintaining two different CI / CD pipeline will be a burden.",maybe better use instead link docker hub page also automatic docker hub could speed pipeline reason use two different pipeline burden,issue,negative,positive,positive,positive,positive,positive
650749945,It looks like you're not using the right version of the client to match the model version (0.6.1). Make sure you always use a client matching the version of the model you're running. You can find the 0.6.1 downloads here: https://github.com/mozilla/DeepSpeech/releases/v0.6.1 and the documentation here: https://deepspeech.readthedocs.io/en/v0.6.1/,like right version client match model version make sure always use client matching version model running find documentation,issue,positive,positive,positive,positive,positive,positive
650613048,@lissyx There is already an [existing docker hub account by mozilla](https://hub.docker.com/u/mozilla). It should be better to request access for that organization instead of creating a new one.,already docker hub account better request access organization instead new one,issue,negative,positive,positive,positive,positive,positive
650605491,"@lissyx Maybe you can better use the github webhooks instead of the scriptworker to link to github on the docker hub page. Also, the automatic builds of docker hub could speed up the pipeline.",maybe better use instead link docker hub page also automatic docker hub could speed pipeline,issue,negative,positive,positive,positive,positive,positive
650463691,"@lissyx I'm closing this. Sorry, got stuck in other work and you have a PR for this.",sorry got stuck work,issue,negative,negative,negative,negative,negative,negative
650396294,"This is not a bug in our code, so please use Discourse for support. Please run sox manually on that file to share a more actionable error.",bug code please use discourse support please run manually file share actionable error,issue,positive,neutral,neutral,neutral,neutral,neutral
650238982,"> > I'd be happy if you can send me on the good path ^^ in the meantime,
> 
> It's not that I dont want, it's just that we don't have data at all: our training on Common Voice English are with other datasets, and those parameters are already documented in releases.

Perfect 👍  Thank you a lot @lissyx ",happy send good path dont want data training common voice already perfect thank lot,issue,positive,positive,positive,positive,positive,positive
650229392,"> I'd be happy if you can send me on the good path ^^ in the meantime,

It's not that I dont want, it's just that we don't have data at all: our training on Common Voice English are with other datasets, and those parameters are already documented in releases.",happy send good path dont want data training common voice already,issue,positive,positive,positive,positive,positive,positive
650225079,"> There is no such doc, because it depends too much on what you are working on, what datasets your are mixing, etc. Best source of infos for that for the moment is digging through the Discourse forum.

Basically, I am trying to train a Speech-to-Text model based only on CommonVoice English dataset. And use it for real time captioning, later on, if satisfied enough, I will add my own dataset which has ~15h (not much I know :-) )

I'd be happy if you can send me on the good path ^^ in the meantime, I will dig deeper on discourse. 

I really appreciate your reactivity :-) ",doc much working best source moment digging discourse forum basically trying train model based use real time later satisfied enough add much know happy send good path dig discourse really appreciate reactivity,issue,positive,positive,positive,positive,positive,positive
650219066,"> I am almost sure that such a Doc is somewhere there, I just did not find it yet maybe :-)

There is no such doc, because it depends too much on what you are working on, what datasets your are mixing, etc. Best source of infos for that for the moment is digging through the Discourse forum.",almost sure doc somewhere find yet maybe doc much working best source moment digging discourse forum,issue,positive,positive,positive,positive,positive,positive
650216742,"> Is there any doc improvement that would have helped you ?

I think the doc covers really everything. Very well done @lissyx ! 
Maybe, the only thing I still did not find in the Doc is the best parameters to train models on the proposed datasets (common voice for instance). 

I am almost sure that such a Doc is somewhere there, I just did not find it yet maybe :-) 

My best regards,


",doc improvement would think doc really everything well done maybe thing still find doc best train common voice instance almost sure doc somewhere find yet maybe best,issue,positive,positive,positive,positive,positive,positive
650151157,"So I have a PR with: 
 - tensorflow as a submodule
 - taskcluster scripts / definitions from tensorflow moved into deepspeech
 - task graph dependencies between deepspeech and tensorflow
 - definitions of tensorflow builds that **should** be using the generic build/cache mechanism

still a lot to complete, but it's on track.",task graph generic mechanism still lot complete track,issue,negative,positive,neutral,neutral,positive,positive
649553619,"> Actually, you are right. I have updated ffmpeg `sudo apt install ffmpeg` then deleted all the previously created wav then restarted the `bin/import_cv2.py` and now it works fine. I hope this fix can be helpful for other users.

Is there any doc improvement that would have helped you ?


> I really apologize. It is my first time here. forgive my ignorance, I will post on Discourse next time.


At least you filled the template and exposed your issue, that could have been worse :).


Good to know you now have a working setup, thanks for you quick feedback!",actually right apt install previously work fine hope fix helpful doc improvement would really apologize first time forgive ignorance post discourse next time least filled template exposed issue could worse good know working setup thanks quick feedback,issue,positive,positive,positive,positive,positive,positive
649549220,"First, thank you a lot for the quick reply. 


> That does not give more information, since the error states that it could not find a valid WAVE file. Are you sure your `sox` setup is fine and able to convert from MP3 ?
> 
> So the file exists, but what is it ? Empty ? Something else ?
> 

Actually, you are right. I have updated ffmpeg ```sudo apt install ffmpeg``` then deleted all the previously created wav then restarted the ```bin/import_cv2.py``` and now it works fine. I hope this fix can be helpful for other users. 
 
> It would have been nice to follow the documented steps of asking support on Discourse and providing more logs, there's nothing actionable here.

I really apologize. It is my first time here. forgive my ignorance, I will post on Discourse next time. 

Thank you a lot for your time",first thank lot quick reply give information since error could find valid wave file sure setup fine able convert file empty something else actually right apt install previously work fine hope fix helpful would nice follow support discourse providing nothing actionable really apologize first time forgive ignorance post discourse next time thank lot time,issue,positive,positive,positive,positive,positive,positive
649480999,"> ``
> 
> when I run soxi command manually I get:
> `` soxi FAIL formats: can't open input file `data/commonvoice/clips/common_voice_en_18686313.wav': WAVE: RIFF header not found ``
> 
> I checked the file and it was available in the folder.

That does not give more information, since the error states that it could not find a valid WAVE file. Are you sure your `sox` setup is fine and able to convert from MP3 ?

So the file exists, but what is it ? Empty ? Something else ?



> My best guess is that there's a problem during conversion.
> 
> Any idea on how to fix this ?

It would have been nice to follow the documented steps of asking support on Discourse and providing more logs, there's nothing actionable here.",run command manually get fail ca open input file wave riff header found checked file available folder give information since error could find valid wave file sure setup fine able convert file empty something else best guess problem conversion idea fix would nice follow support discourse providing nothing actionable,issue,negative,positive,positive,positive,positive,positive
649133336,This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.,thread automatically locked since recent activity closed please open new issue related,issue,negative,positive,neutral,neutral,positive,positive
648943355,"Yes, just to let you know.
Thanks for the quick answers",yes let know thanks quick,issue,positive,positive,positive,positive,positive,positive
648941897,"> I'm in lunix but pip can't finde the version ds_ctcdecoder

Please be more precise. You could be hitting #3102.",pip ca version please precise could,issue,negative,positive,positive,positive,positive,positive
648941009,"Thanks for the report.
@dabadiesimon Yeah I moved the `VERSION` file without releasing an alpha build. As said earlier, move to a release tag or be patient and within a few hours a 0.9.0a0 should be there.",thanks report yeah version file without alpha build said move release tag patient within,issue,positive,positive,positive,positive,positive,positive
648938336,"> > I'm on windwos 10 with python 3.6.
> 
> Please note we don't support training on Windows.
> 
> > `No local packages or working download links found for ds_ctcdecoder==training/deepspeech_training/VERSION error: Could not find suitable distribution for Requirement.parse('ds_ctcdecoder==training/deepspeech_training/VERSION')`
> 
> `training/deepspeech_training/VERSION` should be a file, can you verify and share its content
> 
> > With the `version 0.7.3` and older it finds the ds_ctcdecoder but always calls that I need `numpy` in `version 1.16`, when I install 1.16 it calls me that I need `numpy 1.13.3` because of other modules and so on.
> 
> Please share more explicit `pip install -v` logs. It could also be related to the fact that ... we don't support training on Windows ?
> 
> > That's why I think my only chance to use DeepSpeech is with the newest version.
> 
> We made no change to the dependencies, so if it's your issue it's not going to be solved.

I'm in lunix but pip can't finde the version ds_ctcdecoder",python please note support training local working link found error could find suitable distribution file verify share content version older always need version install need please share explicit pip install could also related fact support training think chance use version made change issue going pip ca version,issue,positive,positive,positive,positive,positive,positive
648677375,"> I'm on windwos 10 with python 3.6.

Please note we don't support training on Windows.


> `No local packages or working download links found for ds_ctcdecoder==training/deepspeech_training/VERSION error: Could not find suitable distribution for Requirement.parse('ds_ctcdecoder==training/deepspeech_training/VERSION')`

`training/deepspeech_training/VERSION` should be a file, can you verify and share its content



> With the `version 0.7.3` and older it finds the ds_ctcdecoder but always calls that I need `numpy` in `version 1.16`, when I install 1.16 it calls me that I need `numpy 1.13.3` because of other modules and so on.

Please share more explicit `pip install -v` logs. It could also be related to the fact that ... we don't support training on Windows ?



> That's why I think my only chance to use DeepSpeech is with the newest version.

We made no change to the dependencies, so if it's your issue it's not going to be solved.",python please note support training local working link found error could find suitable distribution file verify share content version older always need version install need please share explicit pip install could also related fact support training think chance use version made change issue going,issue,positive,positive,positive,positive,positive,positive
648282795,"My observations so far:
- Regarding **batch size**: I got the biggest difference to the old implementation when switching from the former combined  `--augmentation_pitch_and_tempo_scaling` to `--augment pitch` plus `--augment tempo`. This additional memory requirement comes from the doubling of certain allocations as the involved ops are not part of one augmentation sub-graph anymore. With the refactored code I had to decrease BS from 38 to 35 to get it working.
- The new internal **`clock` tensor** has some very small overhead that should in most cases not require a BS adjustment.
- The way how **dropout** is implemented now seems to require slightly more memory, as there is a tensor of random values allocated that is of the same size as the augmentation target.
- At least when comparing dropout (more tests needed) there was no difference in regards to runtime.
- Still to do: Reliable comparison regarding accuracy and dev-loss development per augmentation...",far regarding batch size got biggest difference old implementation switching former combined augment pitch plus augment tempo additional memory requirement come doubling certain involved part one augmentation code decrease get working new internal clock tensor small overhead require adjustment way dropout require slightly memory tensor random size augmentation target least dropout difference still reliable comparison regarding accuracy development per augmentation,issue,negative,negative,neutral,neutral,negative,negative
648044681,"Same WER, 4th digit CER small change.",wer th digit small change,issue,negative,negative,negative,negative,negative,negative
648044396,"```
Test on librivox/librivox-test-clean.csv - WER: 0.071611, CER: 0.029936, loss: 0.000000
--------------------------------------------------------------------------------
Best WER: 
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file:///
 - src: ""then she suddenly remarked""
 - res: ""then she suddenly remarked""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://D
 - src: ""what was that""
 - res: ""what was that""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://p
 - src: ""i know he had it this very evening""
 - res: ""i know he had it this very evening""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://S
 - src: ""it is annoyance then""
 - res: ""it is annoyance then""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://p
 - src: ""my position was too terrible""
 - res: ""my position was too terrible""
--------------------------------------------------------------------------------
Median WER: 
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.008333, loss: 0.000000
 - wav: file://e
 - src: ""among other things on which she cast her eyes was a small crucifix of solid silver standing on a cabinet near the window""
 - res: ""among other things on which he cast her eyes was a small crucifix of solid silver standing on a cabinet near the window""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.014184, loss: 0.000000
 - wav: file://p
 - src: ""i carefully avoid any appearance of preoccupation and eccentricity which might lead those i live amongst to suspect the nature of my pursuits""
 - res: ""i carefully avoid any appearance of preoccupation and eccentricity which might lead those i live amongst a suspect the nature of my pursuits""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.015748, loss: 0.000000
 - wav: file://e
 - src: ""the king who had from this moment become in reality the principal dancer in the quadrille cast a look upon his vanquished rival""
 - res: ""the king who had from the moment become in reality the principal dancer in the quadrille cast a look upon his vanquished rival""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.018519, loss: 0.000000
 - wav: file://9
 - src: ""but in the rest of the work the power of language seems to fail him and the dramatic form is wholly given up""
 - res: ""but in the rest of the work the power of language seemed to fail him and the dramatic form is wholly given up""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.015873, loss: 0.000000
 - wav: file://6
 - src: ""from rubbing shoulders with scientists in our little universe by the botanical gardens the boy had come to know a thing or two""
 - res: ""from rubbing shoulders with scientists and our little universe by the botanical gardens the boy had come to know a thing or two""
--------------------------------------------------------------------------------
Worst WER: 
--------------------------------------------------------------------------------
WER: 0.833333, CER: 0.342857, loss: 0.000000
 - wav: file://s
 - src: ""one thinks one hears hydras talking""
 - res: ""one thing one here is high dress talking""
--------------------------------------------------------------------------------
WER: 0.857143, CER: 0.576923, loss: 0.000000
 - wav: file://1
 - src: ""who touches me am i in bed""
 - res: ""criticism and i am bad""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.444444, loss: 0.000000
 - wav: file://e
 - src: ""verse two""
 - res: ""first to""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.214286, loss: 0.000000
 - wav: file://6
 - src: ""robin fitzooth""
 - res: ""robin fits both""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.352941, loss: 0.000000
 - wav: file://L
 - src: ""stephanos dedalos""
 - res: ""stefano dead loss""
--------------------------------------------------------------------------------
```",test wer loss best wer wer loss file suddenly suddenly wer loss file wer loss file know evening know evening wer loss file annoyance annoyance wer loss file position terrible position terrible median wer wer loss file among cast small crucifix solid silver standing cabinet near window among cast small crucifix solid silver standing cabinet near window wer loss file carefully avoid appearance preoccupation eccentricity might lead live amongst suspect nature carefully avoid appearance preoccupation eccentricity might lead live amongst suspect nature wer loss file king moment become reality principal dancer quadrille cast look upon rival king moment become reality principal dancer quadrille cast look upon rival wer loss file rest work power language fail dramatic form wholly given rest work power language fail dramatic form wholly given wer loss file rubbing little universe botanical boy come know thing two rubbing little universe botanical boy come know thing two worst wer wer loss file one one talking one thing one high dress talking wer loss file bed criticism bad wer loss file verse two first wer loss file robin robin wer loss file stephanos dead loss,issue,negative,negative,negative,negative,negative,negative
648040355,"With `deepspeech-tflite` v0.7.4 r1.15:
```
Test on librivox/librivox-test-clean.csv - WER: 0.071611, CER: 0.029926, loss: 0.000000
--------------------------------------------------------------------------------
Best WER: 
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file:///
 - src: ""then she suddenly remarked""
 - res: ""then she suddenly remarked""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://e
 - src: ""what was that""
 - res: ""what was that""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://p
 - src: ""it is annoyance then""
 - res: ""it is annoyance then""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://S
 - src: ""my position was too terrible""
 - res: ""my position was too terrible""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 0.000000
 - wav: file://e
 - src: ""i know he had it this very evening""
 - res: ""i know he had it this very evening""
--------------------------------------------------------------------------------
Median WER: 
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.008333, loss: 0.000000
 - wav: file://p
 - src: ""among other things on which she cast her eyes was a small crucifix of solid silver standing on a cabinet near the window""
 - res: ""among other things on which he cast her eyes was a small crucifix of solid silver standing on a cabinet near the window""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.014184, loss: 0.000000
 - wav: file://D
 - src: ""i carefully avoid any appearance of preoccupation and eccentricity which might lead those i live amongst to suspect the nature of my pursuits""
 - res: ""i carefully avoid any appearance of preoccupation and eccentricity which might lead those i live amongst a suspect the nature of my pursuits""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.015748, loss: 0.000000
 - wav: file://p
 - src: ""the king who had from this moment become in reality the principal dancer in the quadrille cast a look upon his vanquished rival""
 - res: ""the king who had from the moment become in reality the principal dancer in the quadrille cast a look upon his vanquished rival""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.018519, loss: 0.000000
 - wav: file://-
 - src: ""but in the rest of the work the power of language seems to fail him and the dramatic form is wholly given up""
 - res: ""but in the rest of the work the power of language seemed to fail him and the dramatic form is wholly given up""
--------------------------------------------------------------------------------
WER: 0.043478, CER: 0.015873, loss: 0.000000
 - wav: file:///
 - src: ""from rubbing shoulders with scientists in our little universe by the botanical gardens the boy had come to know a thing or two""
 - res: ""from rubbing shoulders with scientists and our little universe by the botanical gardens the boy had come to know a thing or two""
--------------------------------------------------------------------------------
Worst WER: 
--------------------------------------------------------------------------------
WER: 0.833333, CER: 0.342857, loss: 0.000000
 - wav: file://e
 - src: ""one thinks one hears hydras talking""
 - res: ""one thing one here is high dress talking""
--------------------------------------------------------------------------------
WER: 0.857143, CER: 0.576923, loss: 0.000000
 - wav: file://-
 - src: ""who touches me am i in bed""
 - res: ""criticism and i am bad""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.444444, loss: 0.000000
 - wav: file://h
 - src: ""verse two""
 - res: ""first to""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.214286, loss: 0.000000
 - wav: file://-
 - src: ""robin fitzooth""
 - res: ""robin fits both""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.352941, loss: 0.000000
 - wav: file://x
 - src: ""stephanos dedalos""
 - res: ""stefano dead loss""
--------------------------------------------------------------------------------
```",test wer loss best wer wer loss file suddenly suddenly wer loss file wer loss file annoyance annoyance wer loss file position terrible position terrible wer loss file know evening know evening median wer wer loss file among cast small crucifix solid silver standing cabinet near window among cast small crucifix solid silver standing cabinet near window wer loss file carefully avoid appearance preoccupation eccentricity might lead live amongst suspect nature carefully avoid appearance preoccupation eccentricity might lead live amongst suspect nature wer loss file king moment become reality principal dancer quadrille cast look upon rival king moment become reality principal dancer quadrille cast look upon rival wer loss file rest work power language fail dramatic form wholly given rest work power language fail dramatic form wholly given wer loss file rubbing little universe botanical boy come know thing two rubbing little universe botanical boy come know thing two worst wer wer loss file one one talking one thing one high dress talking wer loss file bed criticism bad wer loss file verse two first wer loss file robin robin wer loss file stephanos dead loss,issue,negative,negative,negative,negative,negative,negative
648037641,"> Do you think you can have enough time for 0.8 for that ?

Yes.",think enough time yes,issue,negative,neutral,neutral,neutral,neutral,neutral
648032090,"> I will upgrade project type aiming for UWP and Net Core support :)

Do you think you can have enough time for 0.8 for that ?



> I mean the library is totally usable on UWP. It just requires some manual steps to get it done. If fixing that is out of scope maybe a small workaround guide would be enough.

If not, can we at least document this workaround more or less officially?",upgrade project type aiming net core support think enough time mean library totally usable manual get done fixing scope maybe small guide would enough least document le officially,issue,negative,negative,negative,negative,negative,negative
647409972,@DanBmh Augmentations `volume` `gaps` `reverb` `codec` `resample` and `overlay` are most likely not responsible for this discrepancy as their implementations have not been changed during refactoring. For the others it'd be helpful to compare them one by one with their former implementations to get a better understanding of the problem. I'll do some performance tests here.,volume reverb resample overlay likely responsible discrepancy helpful compare one one former get better understanding problem performance,issue,positive,positive,positive,positive,positive,positive
647301389,"> I think it would be a good move if it helps making the library being usable to UWP.

+1 Here, it also makes easier to introduce Net core support :)

> Maybe @erksch could help here if you are overloaded :-)

I can take, maybe later for testing. I wanted to touch .Net Core and I think this is the door.


> I mean the library is totally usable on UWP.

Just luck, digging docs we should not pack net framework build as UWP, there are even min/max win sdk versions missing on the NuGet packing. I feel it can explode any time if we pack net framework version.

I will upgrade project type aiming for UWP and  Net Core support :)",think would good move making library usable also easier introduce net core support maybe could help take maybe later testing touch core think door mean library totally usable luck digging pack net framework build even win missing feel explode time pack net framework version upgrade project type aiming net core support,issue,positive,positive,neutral,neutral,positive,positive
647141382,I mean the library is totally usable on UWP. It just requires some manual steps to get it done. If fixing that is out of scope maybe a small workaround guide would be enough. ,mean library totally usable manual get done fixing scope maybe small guide would enough,issue,negative,negative,negative,negative,negative,negative
647132222,"> the worst case I'll need to change project type completely and change cluster packing logic :/

While unfortunate, I think it would be a good move if it helps making the library being usable to UWP. Is it complicated? Maybe @erksch could help here if you are overloaded :-)",worst case need change project type completely change cluster logic unfortunate think would good move making library usable complicated maybe could help,issue,negative,negative,negative,negative,negative,negative
647087039,"Ugh this will require more effort for UWP support, best case I only add the target (Which seems not to work), and the worst case I'll need to change project type completely and change cluster packing logic :/ ",ugh require effort support best case add target work worst case need change project type completely change cluster logic,issue,negative,positive,neutral,neutral,positive,positive
647066454,"@erksch Thanks for the update and you are correct : 

> Maybe there is missing an export for target framework uap10.0 which the UWP NuGet manager can pick up?

I'm testing with NuGet locally to send a patch.",thanks update correct maybe missing export target framework manager pick testing locally send patch,issue,negative,neutral,neutral,neutral,neutral,neutral
646999545,"> Well i know nothing about the .Net framework

Today I can look into this.",well know nothing framework today look,issue,negative,neutral,neutral,neutral,neutral,neutral
646993593,Well i know nothing about the .Net framework 😢,well know nothing framework,issue,negative,neutral,neutral,neutral,neutral,neutral
646989850,"@lissyx Sorry for getting back so late, we shifted priority away from the windows recently. 
I have the same NuGet configuration as @carlfm01 suggested. 
I just created a fresh UWP app, added DeepSpeech (0.7.4) as a reference, and tried to include the DeepSpeechClient class and it is not found. So as usual. 
I still have to use the workaround as mentioned in [my comment from above](https://github.com/mozilla/DeepSpeech/issues/2937#issuecomment-618944145).

Also what is weird: When adding a reference to the UWP app, no Packages folder or Packages.config is created. Maybe UWP is just handling NuGet references differently (only in csproj file) and that doesn't work for the way the DeepSpeech package is published.

Other (uneducated) idea: I remember the NuGet package having libraries for target frameworks net46 net45 and so on. Maybe there is missing an export for target framework uap10.0 which the UWP NuGet manager can pick up?",sorry getting back late priority away recently configuration fresh added reference tried include class found usual still use comment also weird reference folder maybe handling differently file work way package uneducated idea remember package target net net maybe missing export target framework manager pick,issue,negative,negative,negative,negative,negative,negative
646966312,Hi. I'm new to open source and would like to contribute to this issue. @JRMeyer can you please link to the files that needs to be edited?,hi new open source would like contribute issue please link need,issue,positive,positive,neutral,neutral,positive,positive
646857517,"I did run another test with the code directly before the refactoring (#188a6f2c1ee53dc79acf8abceaf729b5f9a05e7a). 

This time one epoch takes 4min on average and the whole training took 1:45h. 
| Dataset | Additional Infos | Losses | Training epochs of best model | Result |
|---------|------------------|--------|-------------------------------|--------|
| Voxforge | | Test: 28.846869, Validation: 32.680268 | 16 | WER: 0.225360, CER: 0.083504 |

I now used batch size of 24 and did update the params again to better match the params above:
```
  AUG_AUDIO=""--augmentation_pitch_and_tempo_scaling \
                   --augmentation_pitch_and_tempo_scaling_min_pitch 0.95 \
                   --augmentation_pitch_and_tempo_scaling_max_pitch 1.1 \
                   --augmentation_pitch_and_tempo_scaling_max_tempo 1.25""
  AUG_ADD_DROP=""--data_aug_features_additive 0.25 \
                --augmentation_spec_dropout_keeprate 0.95""
  AUG_FREQ_TIME=""--augmentation_freq_and_time_masking True""
  AUG_EXTRA=""--augment reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0] \
      --augment gaps[p=0.05,n=1:3~2,size=10:100] \
      --augment resample[p=0.1,rate=12000:8000~4000] \
      --augment codec[p=0.1,bitrate=48000:16000] \
      --augment volume[p=0.1,dbfs=-10:-40]""
```
",run another test code directly time one epoch min average whole training took additional training best model result test validation wer used batch size update better match true augment reverb augment augment resample augment augment volume,issue,positive,positive,positive,positive,positive,positive
646796934,"I have tried reducing the batch size, but to no avail.

On Fri, Jun 19, 2020, 5:38 AM DanBmh <notifications@github.com> wrote:

> I also did get similar errors lately. In my case it often occurs at the
> end of an epoch.
> Training works normally for a few epochs before i get the error. Mine has
> some different numbers than yours:
>
> Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 1101, 30, 2048]
> 	 [[{{node tower_0/gradients/tower_0/cudnn_lstm/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]
> 	 [[tower_0/gradients/tower_0/cudnn_lstm/CudnnRNNV3_grad/CudnnRNNBackpropV3/_81]]
>
>
> Reducing the batch size helped me to get this error later in the training,
> this may be a workaround you can try.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3088#issuecomment-646613063>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAHNUTGIYIGEXRHOSPTIC6TRXNL4TANCNFSM4OCC3PYQ>
> .
>
",tried reducing batch size avail wrote also get similar lately case often end epoch training work normally get error mine different internal call model node reducing batch size get error later training may try thread reply directly view,issue,negative,negative,neutral,neutral,negative,negative
646613063,"I also did get similar errors lately. In my case it often occurs at the end of an epoch. 
Training works normally for a few epochs before i get the error. Mine has some different numbers than yours:

```
Internal: Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 2048, 1, 1101, 30, 2048] 
	 [[{{node tower_0/gradients/tower_0/cudnn_lstm/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]
	 [[tower_0/gradients/tower_0/cudnn_lstm/CudnnRNNV3_grad/CudnnRNNBackpropV3/_81]]

```

Reducing the batch size helped me to get this error later in the training, this may be a workaround you can try.",also get similar lately case often end epoch training work normally get error mine different internal call model node reducing batch size get error later training may try,issue,negative,negative,neutral,neutral,negative,negative
646522770,"The full command I use is:
```
Running training with arguments: --train_files /DeepSpeech/data_prepared/voxforge/train_azce.csv --dev_files /DeepSpeech/data_prepared/voxforge/dev_azce.csv --test_files /DeepSpeech/data_prepared/voxforge/test_azce.csv --scorer /DeepSpeech/data_prepared/lm/kenlm_az.scorer --alphabet_config_path /DeepSpeech/deepspeech-german/data/alphabet_az.txt --test_batch_size 32 --train_batch_size 32 --dev_batch_size 32 --epochs 100 --early_stop True --es_epochs 7 --reduce_lr_on_plateau True --plateau_epochs 3 --force_initialize_learning_rate True --learning_rate 0.0001 --dropout_rate 0.25 --use_allow_growth --drop_source_layers 0 --train_cudnn --export_dir /DeepSpeech/checkpoints/voxforge/ --checkpoint_dir /DeepSpeech/checkpoints/voxforge/ --summary_dir /DeepSpeech/checkpoints/voxforge/ --max_to_keep 3 --augment volume[p=0.1,dbfs=-10:-40] --augment pitch[p=0.1,pitch=1.1~0.9] --augment tempo[p=0.1,factor=1.25~0.75] --augment dropout[p=0.1,rate=0.05] --augment add[p=0.1,domain=signal,stddev=0~0.5] --augment multiply[p=0.1,domain=features,stddev=0~0.5] --augment frequency_mask[p=0.1,n=1:3,size=1:5] --augment time_mask[p=0.1,domain=signal,n=3:10~2,size=50:100~40] --augment reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0] --augment resample[p=0.1,rate=12000:8000~4000] --augment codec[p=0.1,bitrate=48000:16000] --augment overlay[p=0.3,source=/DeepSpeech/data_prepared/voxforge/train_azce.csv,layers=10:1,snr=50:20~9]

```

I think this is related to the overlay augmentation. Yesterday i did forget the `--` in the `--augment overlay` flag of my cocktailparty augmentation (it seems it left out this augmentation), I did test it again now (with the correct flag) and I have now the same problem with the speech files instead of the noise files too. In both cases it stops after the first epoch.",full command use running training scorer true true true augment volume augment pitch augment tempo augment dropout augment add augment multiply augment augment augment reverb augment resample augment augment overlay think related overlay augmentation yesterday forget augment overlay flag augmentation left augmentation test correct flag problem speech instead noise first epoch,issue,positive,positive,positive,positive,positive,positive
646487034,"@DanBmh This sounds like a problem similar to the one I am currently debugging. Up until now I thought this would be related to the (new) caching logic. But your hint on the overlay augmentation is a highly appreciated data point. Will look into it now.

A question: Is this happening only in case of the overlay augmentation?",like problem similar one currently thought would related new logic hint overlay augmentation highly data point look question happening case overlay augmentation,issue,negative,positive,neutral,neutral,positive,positive
646007526,"Closing this one - reuben was correct, not a problem with windows, just a problem with data.

thanks for your help both.

for anyone stumbling across this - I used sox's vad to clip my sentences & it was too aggressive, leading to a few 0kb files - less aggressive settings has resolved.

",one correct problem problem data thanks help anyone stumbling across used clip aggressive leading le aggressive resolved,issue,negative,positive,positive,positive,positive,positive
645953131,"> Getting following error during bazel build command in v0.6.1
> $ bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie
> 
> Starting local Bazel server and connecting to it...
> INFO: Analysed 2 targets (92 packages loaded, 5738 targets configured).
> INFO: Found 2 targets...
> ERROR: Process exited with status 128: Process exited with status 128
> ++ git describe --long --tags
> fatal: No names found, cannot describe anything.
> 
>     * tf_git_rev=
>       INFO: Elapsed time: 32.691s, Critical Path: 2.55s
>       INFO: 1 process: 1 local.
>       FAILED: Build did NOT complete successfully
> 
> 
> please help me to resolve this error

This is a support request, not a bug report. Please use Discourse as documented in the issue template you removed.

Also, have you `git clone` as documented? The error suggests no ...",getting following error build command build bash opt starting local server loaded found error process status process status git describe long fatal found describe anything time critical path process local build complete successfully please help resolve error support request bug report please use discourse issue template removed also git clone error,issue,negative,positive,neutral,neutral,positive,positive
645930142,"> Are those merged in master? We don't have test for them anyway, so it's not surprising.

Yes they got merged some weeks ago.",master test anyway surprising yes got ago,issue,positive,positive,positive,positive,positive,positive
645880106,"> The new audio augmentation options don't work with the docker container.

Are those merged in master? We don't have test for them anyway, so it's not surprising.



> ```
> 
> ```
> 
> 
> Can be solved by installing:
> 
> ```
> apt-get install -y libopus0
> apt-get install -y libsndfile1
> pip3 install --upgrade ""numba=0.48""
> pip3 install --upgrade opuslib
> ```

Well, as usual, PR welcome, you already have the patch it looks like :)",new audio augmentation work docker container master test anyway surprising install install pip install upgrade pip install upgrade well usual welcome already patch like,issue,positive,positive,positive,positive,positive,positive
645620731,"Thanks @lissyx , I posted my question [here](https://discourse.mozilla.org/t/transfer-learning-with-new-alphabets-new-vocabulary-with-common-speech-data-training-loss-is-increasing-as-epoch-is-under-progress/62134). Thank you",thanks posted question thank,issue,positive,positive,positive,positive,positive,positive
645559064,"@kdavis-mozilla Ok, here’s an updated version:

> Note that the pre-trained model is a work in progress. The model currently performs best in low-noise environments with clear recordings and has a bias towards US male accents. This does not mean the model cannot be used outside of these conditions, but that accuracy may be lower. Some users may need to train the model further to meet their intended use-case.",version note model work progress model currently best clear bias towards u male mean model used outside accuracy may lower may need train model meet intended,issue,positive,positive,positive,positive,positive,positive
645445180,"Yes, as this has been more of a discussion than a specific issue.",yes discussion specific issue,issue,negative,neutral,neutral,neutral,neutral,neutral
645418097,"Not a big enough win to be a rush, and it's 100% an implementation detail, so we can land it after 1.0. I haven't made much progress on figuring out the ds_ctcdecode build stuff.",big enough win rush implementation detail land made much progress build stuff,issue,positive,positive,positive,positive,positive,positive
645413924,"I'm going to close for lack of movement. If someone runs into this again, feel free to re-open.",going close lack movement someone feel free,issue,negative,positive,positive,positive,positive,positive
645408851,"@cnair-83 In light of the comments of @reuben and no further movement on this in the last 2 weeks, I'm going to close.",light movement last going close,issue,negative,positive,positive,positive,positive,positive
645402579,"In light of what I mentioned in my last comment, could you try again to capture what you want to be said in the release notes? Note that ""production environment"" is ill-defined, thus not a meaningful term to include in the text.",light last comment could try capture want said release note production environment thus meaningful term include text,issue,negative,positive,positive,positive,positive,positive
645389659,"As this isn't a bug or feature request but a request for support, could you take this topic of discussion to the [Discourse forums](https://discourse.mozilla.org/c/deep-speech). Thank you.",bug feature request request support could take topic discussion discourse thank,issue,positive,neutral,neutral,neutral,neutral,neutral
645359138,"First, please use Discourse for support request, as explained in the issue template you removed.

Second, the output is here, so I don't understand your question:
>  `experience proves this`

",first please use discourse support request issue template removed second output understand question experience,issue,positive,positive,positive,positive,positive,positive
645319819,"hi, I also meet the same issue, even if I create scorer file:
(deepspeech-0.7-train) parallels@parallels-Parallels-Virtual-Platform:~/Desktop/ASR/mozilla/DeepSpeech-0.7/data/lm$ python3 generate_package.py --alphabet alphabet.txt --lm lm.binary --vocab vocab-500000.txt   --package kenlm.scorer --default_alpha 0.931289039105002 --default_beta 1.1834137581510284
4173 unique words read from vocabulary file.
Looks like a character based model.
Using detected UTF-8 mode: True
Error when creating kenlm.scorer
swig/python detected a memory leak of type 'Alphabet *', no destructor found.

there is no such issue on 0.7 version, could you help to check it please?
Thanks.",hi also meet issue even create scorer file python alphabet package unique read vocabulary file like character based model mode true error memory leak type destructor found issue version could help check please thanks,issue,positive,positive,positive,positive,positive,positive
645290917,"> Sure. I just received the following message:
> 
> ```
> Hey there. We see you’ve been busy reading, which is fantastic, so we’ve promoted you up a trust level!
> 
> We’re really glad you’re spending time with us and we’d love to know more about you. Take a moment to fill out your profile, or feel free to start a new topic.
> ```
> 
> Then after this, I'm about to submit (+ create a new topic button) this question as a new topic. and when I'm submitting, I'm getting the following error:
> 
> **You are not permitted to view the requested resource.**

Should be fine now, looks like big post from copy/paste triggers spam protection. Thanks for your patience.",sure received following message hey see busy reading fantastic trust level really glad spending time u love know take moment fill profile feel free start new topic submit create new topic button question new topic getting following error permitted view resource fine like big post protection thanks patience,issue,positive,positive,positive,positive,positive,positive
645157024,"> `!fout` does locally reproduce the error when trying to pass a directory

Yes, I confirm it shows the error with a directory  as output:

```
Using detected UTF-8 mode: True
Error opening 'pack/'
Error when creating pack/
```
Thanks!",locally reproduce error trying pas directory yes confirm error directory output mode true error opening error thanks,issue,negative,positive,positive,positive,positive,positive
645029396,"Sure. I just received the following message:

```
Hey there. We see you’ve been busy reading, which is fantastic, so we’ve promoted you up a trust level!

We’re really glad you’re spending time with us and we’d love to know more about you. Take a moment to fill out your profile, or feel free to start a new topic.
```

Then after this, I'm about to submit (+ create a new topic button) this question as a new topic. and when I'm submitting, I'm getting the following error:

**You are not permitted to view the requested resource.**",sure received following message hey see busy reading fantastic trust level really glad spending time u love know take moment fill profile feel free start new topic submit create new topic button question new topic getting following error permitted view resource,issue,positive,positive,positive,positive,positive,positive
645023376,@carlfm01 Made the PR better and checking `!fout` does locally reproduce the error when trying to pass a directory,made better locally reproduce error trying pas directory,issue,negative,positive,positive,positive,positive,positive
645021551,"Okay, testing locally `.bad()` seems to not catch the open error, but `!fout` does",testing locally catch open error,issue,negative,neutral,neutral,neutral,neutral,neutral
645006939,"> This is the message I got when I tried to sign up in the discussion board:
> 
> Account temporarily on hold
> 
> system
> Robot Overlord
> 20m
> Hello,
> 
> This is an automated message from Mozilla Discourse to let you know that your account has been temporarily placed on hold as a precautionary measure.
> 
> Please do continue to browse, but you won’t be able to reply or create topics until a staff member 1 reviews your most recent posts. We apologize for the inconvenience.
> 
> For additional guidance, refer to our community guidelines.

Well this is the antispam feature, please be patient.",message got tried sign discussion board account temporarily hold system robot overlord hello message discourse let know account temporarily hold precautionary measure please continue browse able reply create staff member recent apologize inconvenience additional guidance refer community well feature please patient,issue,positive,positive,positive,positive,positive,positive
645006459,"This is the message I got when I tried to sign up in the discussion board:

Account temporarily on hold

system
Robot Overlord
20m
Hello,

This is an automated message from Mozilla Discourse to let you know that your account has been temporarily placed on hold as a precautionary measure.

Please do continue to browse, but you won’t be able to reply or create topics until a staff member 1 reviews your most recent posts. We apologize for the inconvenience.

For additional guidance, refer to our community guidelines.",message got tried sign discussion board account temporarily hold system robot overlord hello message discourse let know account temporarily hold precautionary measure please continue browse able reply create staff member recent apologize inconvenience additional guidance refer community,issue,negative,positive,positive,positive,positive,positive
645005881,"> Hi Just tried to post in the support Discourse support channel but my account is put on hold.

What do you mean, ""on hold""?",hi tried post support discourse support channel account put hold mean hold,issue,positive,negative,negative,negative,negative,negative
645003606,Hi Just tried to post in the support Discourse support channel but my account is put on hold. ,hi tried post support discourse support channel account put hold,issue,positive,neutral,neutral,neutral,neutral,neutral
644976031,"> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).
> 
> If you've found a bug, or have a feature request, then please create an issue with the following information:
> 
>     * **Have I written custom code (as opposed to running examples on an unmodified clone of the repository)**: NO
> 
>     * **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
> 
>     * **TensorFlow installed from (our builds, or upstream TensorFlow)**: Upstream tensorflow r1.15.3 (with GPU)
> 
>     * **TensorFlow version (use command below)**: tensorflow r1.15.3 (with GPU)
> 
>     * **Python version**:  Python3
> 
>     * **Bazel version (if compiling from source)**: tensorflow compiled from sources bazel version 0.26.1
> 
>     * **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
> 
>     * **CUDA/cuDNN version**: CUDA 10.2 / CUDNN v7.6.5
> 
>     * **GPU model and memory**: NVIDIA 1080 Ti (11 GB)
> 
>     * **Exact command to reproduce**:
> 
> 
> ```
> python3 DeepSpeech.py \
>     --n_hidden 2048 \
>     --drop_source_layers 1 \
>     --alphabet_config_path data/new_alphabet.txt \
>     --save_checkpoint_dir /data/Self/test/DeepSpeech/train_3/ \
>     --load_checkpoint_dir /data/Self/test/DeepSpeech/checkpoint/ \
>     --train_files   data/clips/train.csv \
>     --dev_files   data/clips/dev.csv \
>     --test_files  data/clips/test.csv \
>     --learning_rate 0.000005 \
>     --use_allow_growth true \
>     --train_cudnn \
>     --epochs 20 \
>     --export_dir /data/Self/test/DeepSpeech/train_3/ \
>     --summary_dir /data/Self/test/DeepSpeech/train_3/summary \
>     --train_batch_size 32 \
>     --dev_batch_size 32 \
>     --test_batch_size 32 \
>     --export_batch_size 1 \
>     --dropout_rate=0.30
> ```
> 
> I'm using **DeepSpeech version 0.7.3**.
> 
> I wanted to train deepspeech model with my own domain specific data. So I want to add new vocabulary such as integers, (double quote) "" and period(.) to the existing deepspeech alphabets given [here](https://github.com/mozilla/DeepSpeech/blob/master/data/alphabet.txt) .
> 
> As a first step before using my own data, I wanted to do transfer learning with the common voice data and new alphabets from existing published checkpoint give [here](https://github.com/mozilla/DeepSpeech/releases/download/v0.7.3/deepspeech-0.7.3-checkpoint.tar.gz). The intention is to use this new checkpoint to start training with my own data (since it has new alphabets) rather than using the deepspeech published checkpoint (since it has limited alphabets/vocabulary).
> 
> My new alphabets are here
> 
> ```
> # Each line in this file represents the Unicode codepoint (UTF-8 encoded)
> # associated with a numeric label.
> # A line that starts with # is a comment. You can escape it with \# if you wish
> # to use '#' as a label.
>  
> a
> b
> c
> d
> e
> f
> g
> h
> i
> j
> k
> l
> m
> n
> o
> p
> q
> r
> s
> t
> u
> v
> w
> x
> y
> z
> '
> 0
> 1
> 2
> 3
> 4
> 5
> 6
> 7
> 8
> 9
> .
> ""
> # The last (non-comment) line needs to end with a newline.
> ```
> 
> When I used the command
> 
> ```
> python3 DeepSpeech.py \
>     --n_hidden 2048 \
>     --drop_source_layers 1 \
>     --alphabet_config_path data/new_alphabet.txt \
>     --save_checkpoint_dir /data/Self/test/DeepSpeech/train_3/ \
>     --load_checkpoint_dir /data/Self/test/DeepSpeech/checkpoint/ \
>     --train_files   data/clips/train.csv \
>     --dev_files   data/clips/dev.csv \
>     --test_files  data/clips/test.csv \
>     --learning_rate 0.000005 \
>     --use_allow_growth true \
>     --train_cudnn \
>     --epochs 20 \
>     --export_dir /data/Self/test/DeepSpeech/train_3/ \
>     --summary_dir /data/Self/test/DeepSpeech/train_3/summary \
>     --train_batch_size 32 \
>     --dev_batch_size 32 \
>     --test_batch_size 32 \
>     --export_batch_size 1 \
>     --dropout_rate=0.30
> ```
> 
> My training loss is starting from lower value and increasing as the epoch is under progress.
> ![Screenshot_20200616_114830](https://user-images.githubusercontent.com/3826735/84817432-c4026500-afc9-11ea-966b-055dcba96d87.png)
> 
> Output from terminal is as follows:
> 
> ```
> 
> Epoch 0 |   Training | Elapsed Time: 0:48:14 | Steps: 7186 | Loss: 51.725979                                                                                                                                                                                                  
> Epoch 0 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 44.295110 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 44.295110 to: /data/Self/test/DeepSpeech/train_3/best_dev-739708
> --------------------------------------------------------------------------------
> Epoch 1 |   Training | Elapsed Time: 0:48:03 | Steps: 7186 | Loss: 33.749292                                                                                                                                                                                                  
> Epoch 1 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 41.206871 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 41.206871 to: /data/Self/test/DeepSpeech/train_3/best_dev-746894
> --------------------------------------------------------------------------------
> Epoch 2 |   Training | Elapsed Time: 0:48:01 | Steps: 7186 | Loss: 31.213234                                                                                                                                                                                                  
> Epoch 2 | Validation | Elapsed Time: 0:01:24 | Steps: 475 | Loss: 39.810643 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 39.810643 to: /data/Self/test/DeepSpeech/train_3/best_dev-754080
> --------------------------------------------------------------------------------
> Epoch 3 |   Training | Elapsed Time: 0:48:03 | Steps: 7186 | Loss: 29.791398                                                                                                                                                                                                  
> Epoch 3 | Validation | Elapsed Time: 0:01:24 | Steps: 475 | Loss: 39.136365 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 39.136365 to: /data/Self/test/DeepSpeech/train_3/best_dev-761266
> --------------------------------------------------------------------------------
> Epoch 4 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 28.845716                                                                                                                                                                                                  
> Epoch 4 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 38.489472 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 38.489472 to: /data/Self/test/DeepSpeech/train_3/best_dev-768452
> --------------------------------------------------------------------------------
> Epoch 5 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 28.051135                                                                                                                                                                                                  
> Epoch 5 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 37.851685 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 37.851685 to: /data/Self/test/DeepSpeech/train_3/best_dev-775638
> --------------------------------------------------------------------------------
> Epoch 6 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 27.403971                                                                                                                                                                                                  
> Epoch 6 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 37.467827 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 37.467827 to: /data/Self/test/DeepSpeech/train_3/best_dev-782824
> --------------------------------------------------------------------------------
> Epoch 7 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 26.854938                                                                                                                                                                                                  
> Epoch 7 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 37.366411 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 37.366411 to: /data/Self/test/DeepSpeech/train_3/best_dev-790010
> --------------------------------------------------------------------------------
> Epoch 8 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 26.361723                                                                                                                                                                                                  
> Epoch 8 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 37.046090 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 37.046090 to: /data/Self/test/DeepSpeech/train_3/best_dev-797196
> --------------------------------------------------------------------------------
> Epoch 9 |   Training | Elapsed Time: 0:48:02 | Steps: 7186 | Loss: 25.926279                                                                                                                                                                                                  
> Epoch 9 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 36.745385 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                    
> I Saved new best validating model with loss 36.745385 to: /data/Self/test/DeepSpeech/train_3/best_dev-804382
> --------------------------------------------------------------------------------
> Epoch 10 |   Training | Elapsed Time: 0:48:08 | Steps: 7186 | Loss: 25.514988                                                                                                                                                                                                 
> Epoch 10 | Validation | Elapsed Time: 0:01:25 | Steps: 475 | Loss: 36.442261 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                   
> I Saved new best validating model with loss 36.442261 to: /data/Self/test/DeepSpeech/train_3/best_dev-811568
> --------------------------------------------------------------------------------
> Epoch 11 |   Training | Elapsed Time: 0:48:07 | Steps: 7186 | Loss: 25.151161                                                                                                                                                                                                 
> Epoch 11 | Validation | Elapsed Time: 0:01:24 | Steps: 475 | Loss: 36.470721 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                   
> --------------------------------------------------------------------------------
> Epoch 12 |   Training | Elapsed Time: 0:48:01 | Steps: 7186 | Loss: 24.817111                                                                                                                                                                                                 
> Epoch 12 | Validation | Elapsed Time: 0:01:24 | Steps: 475 | Loss: 36.185578 | Dataset: /home/tumu/Self/Research/Work/tensorflow_work/models/try/rnnt-speech-recognition/data/clips/dev.csv                                                                                   
> I Saved new best validating model with loss 36.185578 to: /data/Self/test/DeepSpeech/train_3/best_dev-825940
> ```
> 
> I'm not getting good results with my new checkpoints (as I did the same exercise for 3 epochs and verified some results with Common speech audio files in train.tsv), seems I'm doing something wrong.
> 
>     1. When I add new alphabets, do I need to retrain the scorer as well ? My new alphabets are mostly (a-z, 0-9 and . , "" , comma (,), semi-colon ) (few of like these) ?
> 
>     2. Do I need to change my training parameters to as may be I'm doing something wrong.
> 
>     3. I followed the procedure mentioned [here](https://deepspeech.readthedocs.io/en/v0.7.3/TRAINING.html#transfer-learning-new-alphabet). Also prepared the data using the command
>        `bin/import_cv2.py --filter_alphabet data/new_alphabet.txt   <path_to_common_speech_tsv_files>`
> 
>     4. Do I need to perform any additional steps or drop more layers to train the model with new alphabets ( new vocabulary) ? Also I would like to start from the deeplearning provided checkpoint rather than from scratch.
> 
> 
> Please let me know how to proceed with training a model with new alphabets. Thank you

This is obviously not a bug but a support request. Please use Discourse, as explained in the issue template.",support please use discourse found bug feature request please create issue following information written custom code opposed running unmodified clone repository o platform distribution upstream upstream version use command python version python version source version version source version model memory ti exact command reproduce python true version train model domain specific data want add new vocabulary double quote period given first step data transfer learning common voice data new give intention use new start training data since new rather since limited new line file associated label line comment escape wish use label last line need end used command python true training loss starting lower value increasing epoch progress output terminal epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss saved new best model loss getting good new exercise common speech audio something wrong add new need retrain scorer well new mostly comma like need change training may something wrong procedure also prepared data command need perform additional drop train model new new vocabulary also would like start provided rather scratch please let know proceed training model new thank obviously bug support request please use discourse issue template,issue,positive,positive,positive,positive,positive,positive
644913270,"> > @carlfm01 Could you test the PR #3066 ?
> 
> It did not print the error messages, the ""lissyx version"" just to make sure is actually applying the change.
> 
> ```
> Looks like a character based model.
> Using detected UTF-8 mode: True
> -----------------lissyx  version-----------------------------------'pack/'
> ERROR: AlignOutput: Can't determine stream position
> ERROR: Could not align file during write after header
> Package created in pack/
> ```
> 
> > taking the dir path.
> 
> I think to avoid my error it just needs to test if it is a directory and throw a message if the directory exists, like ""please don't use a valid directory as a name for the output scorer"".
> 
> @lissyx I think your solution will work for the cases when there's no permission, issues with storage(like the user with network storage), full disk etc.

well, according to the doc, `.bad()` should also work, but maybe it is legit to open a directory as a stream?",could test print error version make sure actually change like character based model mode true version error ca determine stream position error could align file write header package taking path think avoid error need test directory throw message directory like please use valid directory name output scorer think solution work permission storage like user network storage full disk well according doc also work maybe legit open directory stream,issue,positive,positive,positive,positive,positive,positive
644902123,"> @carlfm01 Could you test the PR #3066 ?

It did not print the error messages, the ""lissyx  version"" just to make sure is actually applying the change.

```
Looks like a character based model.
Using detected UTF-8 mode: True
-----------------lissyx  version-----------------------------------'pack/'
ERROR: AlignOutput: Can't determine stream position
ERROR: Could not align file during write after header
Package created in pack/
```



> taking the dir path.

I think to avoid my error it just needs to test if it is a directory and throw a message if the directory exists, like ""please don't use a valid  directory as a name for the output scorer"".

@lissyx I think your solution will work for the cases when there's no permission, issues with storage(like the user with network storage), full disk etc. ",could test print error version make sure actually change like character based model mode true version error ca determine stream position error could align file write header package taking path think avoid error need test directory throw message directory like please use valid directory name output scorer think solution work permission storage like user network storage full disk,issue,negative,positive,positive,positive,positive,positive
644862157,"Got it, will do this week.

On Tue, Jun 16, 2020 at 3:26 AM lissyx <notifications@github.com> wrote:

> (also on 0.7.3 please)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2967#issuecomment-644677800>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACJEOTNK4MMIFGNMZKQTQFLRW5CFDANCNFSM4MWZUONQ>
> .
>
",got week tue wrote also please reply directly view,issue,negative,positive,neutral,neutral,positive,positive
644732229,"I think you can see some of the limitations in a benchmark I did run. The benchmark doesn't test transcription accuracy directly, it's a test for speech-to-intent accuracy. So DeepSpeech is not the only factor, but the most important of it.
The low performance can be explained with ""not noise-robust, biased towards US male accents"", but I think a graph with comparison to other services is also helpful for first performance estimations.

![compare_barrista_extra](https://user-images.githubusercontent.com/18572490/84764370-e6967d00-afcd-11ea-9f8c-69f68ed58b97.png)

The [benchmark](https://github.com/Picovoice/speech-to-intent-benchmark) consists of 620 spoken commands of 50 different people (part of them with stronger accents) ordering coffee in english. A detection is correct if all important parts of the order (coffee type, size, sugar amount, ...) are extracted correctly (so it can fail if only one single word was misunderstood). It also tests the influence of background noise by mixing kitchen or cafe noises into the audio files.

You can see that plain DeepSpeech transcription (Free Speech) which uses 0.7 model and scorer doesn't work well, but the performance can be greatly improved if you use domain specific language models.
Short note: The Free Speech benchmark was run only with 1/6 of the files because of long runtimes, but in other tests this did only have a small effect to overall accuracy (~±0.03).

The complete benchmark code can be found [here](https://gitlab.com/Jaco-Assistant/Benchmark-Jaco).
",think see run test transcription accuracy directly test accuracy factor important low performance towards u male think graph comparison also helpful first performance spoken different people part coffee detection correct important order coffee type size sugar amount extracted correctly fail one single word misunderstood also influence background noise kitchen audio see plain transcription free speech model scorer work well performance greatly use domain specific language short note free speech run long small effect overall accuracy complete code found,issue,positive,positive,neutral,neutral,positive,positive
644685106,"@carlfm01 Could you test the PR https://github.com/mozilla/DeepSpeech/pull/3066 ? I'd like to make sure it is able to catch your error, but I suspect for proper fix we'd like to change the prototype of `save_dictionary` and make it return a bool to know whether it could write.",could test like make sure able catch error suspect proper fix like change prototype make return bool know whether could write,issue,negative,positive,positive,positive,positive,positive
644677729,"@khu834 We have had reports in the past of problem with conda / anaconda / miniconda. Can you try and repro with vanilla python? Also in this log I can't find any leak reference (except in the summary), only invalid read size / uninitialized values (which concerns me, hence the python stuff). Can you repro with proper CLI parameters for tracking leaks?",khu past problem anaconda try vanilla python also log ca find leak reference except summary invalid read size hence python stuff proper,issue,negative,negative,negative,negative,negative,negative
644654806,"> AVX isn't a hard dependency?

It's what we target for prebuilt binaries, but it should work without as long as TensorFlow works without AVX (which should still be the case).",hard dependency target work without long work without still case,issue,negative,negative,negative,negative,negative,negative
644654096,"Wait... AVX isn't a hard dependency? I'd have tried building this from source months ago if I'd known my Athlon II X2 270 + GeForce GTX750 setup wasn't inherently incompatible.

Is that something I missed when looking at the docs or just missing?",wait hard dependency tried building source ago known setup inherently incompatible something looking missing,issue,negative,negative,negative,negative,negative,negative
644652201,"> Still having trouble making time but I thought you might want to know that, if I'm understanding things correctly, Intel's preparing to release a [brand new processor line without AVX](https://newsroom.intel.com/news/intel-hybrid-processors-uncompromised-pc-experiences-innovative-form-factors-foldables-dual-screens/?linkId=100000012863318#gs.8blsyn).

That's unfortunate, but it's a specific set of devices, we can expect that people trying to run on those are knowledgeable enough to rebuild without AVX support. Though I don't know how good performance might be then.",still trouble making time thought might want know understanding correctly release brand new processor line without unfortunate specific set expect people trying run knowledgeable enough rebuild without support though know good performance might,issue,negative,positive,neutral,neutral,positive,positive
644219503,"I've spent a lot of time on it, there are still too many limitations. Please read https://github.com/mozilla/DeepSpeech/issues/2332",spent lot time still many please read,issue,negative,positive,positive,positive,positive,positive
644219107,"> Indeed I would like to run DeepSpeech on the Coral Edge TPU from Google. The accelerator needs to have a fully quantized 8 bit model to make inferences.

This won't work.",indeed would like run coral edge accelerator need fully bit model make wo work,issue,negative,neutral,neutral,neutral,neutral,neutral
644209060,"It looks like building a fat binary for x86_64 and arm64 is not useful because you still need two separate frameworks for device and simulator, as they use different SDKs.

I've edited the first comment to reflect this.",like building fat binary arm useful still need two separate device simulator use different first comment reflect,issue,positive,positive,positive,positive,positive,positive
643976615,"The error is happening on batch 0 and is complaining about a sequence length of 0, make sure to also look for empty or very short audio files.",error happening batch sequence length make sure also look empty short audio,issue,negative,positive,positive,positive,positive,positive
643952245,">  is there any other specs on the dataset that'd help?

How long is each file? Are you sure you don't have one too big?

Also, Windows: again, we don't know if it does not comes from this. It's hard for us if you don't repro elsewhere.



> I've updated to CuDNN 7.6 & just ran again with use_allow_growth - but I get the same error, I searched plenty before asking (opening an issue is my last choice option) but I couldn't find any relevant reference to sequence length issues.

The linked ticket reports more than just use_allow_growth, so you should try them



>     * --train_batch_size 16 --test_batch_size 16 --dev_batch_size 16

Batch size 1 please ?",spec help long file sure one big also know come hard u elsewhere ran get error plenty opening issue last choice option could find relevant reference sequence length linked ticket try batch size please,issue,negative,positive,neutral,neutral,positive,positive
643917670,"thank you, I wasn't expecting such a quick response :)

I've updated to CuDNN 7.6 & just ran again with use_allow_growth - but I get the same error, I searched plenty before asking (opening an issue is my last choice option) but I couldn't find any relevant reference to sequence length issues.

I don't think there should be any OOM issue, they should all fit comfortably in the 8GB available

my dataset consists of:

dev: 1088 wav - total size: 80MB
test: 2177 wav - total size: 162MB
train: 7631 wav - total size: 558MB

they're all 16khz, mono files and as far as I can tell match the set up of the corpora used in training up to the checkpoint.
is there any other specs on the dataset that'd help?",thank quick response ran get error plenty opening issue last choice option could find relevant reference sequence length think issue fit comfortably available dev total size test total size train total size mono far tell match set corpus used training spec help,issue,positive,positive,positive,positive,positive,positive
643814487,"> **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10

Please note we don't support training on Windows.

> **CUDA/cuDNN version**: 10.0 & 7.4.2

I think you should be using CuDNN v7.6



> I've attached the full log. the recordings are all wav & the csv's have all been through character_check & I can't find any error any of them. I've tried various batch sizes

Have you searched a bit? A few seconds on google with your error message yields: https://github.com/tensorflow/models/issues/6305 which points to OOM of the GPU. Without more informations on your dataset, we can't conclude. Please try the growth option and report your dataset specs.",o platform distribution please note support training version think attached full log ca find error tried various batch size bit error message without ca conclude please try growth option report spec,issue,positive,positive,positive,positive,positive,positive
643718351,"It's a reasonable first cut, but if your ""production"" environment is low-noise and used in the US, it is a production model. So I don't think this really captures what needs to be said.",reasonable first cut production environment used u production model think really need said,issue,negative,positive,positive,positive,positive,positive
643670740,"@kdavis-mozilla How about something like this?

> Note that the pre-trained model is a work in progress and is not considered to be production-ready. The model currently performs best in low-noise environments with clear recordings and has a bias towards US male accents. It will likely need additional training to be ready for production use. ",something like note model work progress considered model currently best clear bias towards u male likely need additional training ready production use,issue,positive,positive,positive,positive,positive,positive
642939244,"Still having trouble making time but I thought you might want to know that, if I'm understanding things correctly, Intel's preparing to release a [brand new processor line without AVX](https://newsroom.intel.com/news/intel-hybrid-processors-uncompromised-pc-experiences-innovative-form-factors-foldables-dual-screens/?linkId=100000012863318#gs.8blsyn).

(Their Lakefield Hybrid processor (ie. big.LITTLE for x86) will be using Tremont and Sunny Cove cores and, from what I read, it seems they'll be turning off AVX and beyond on the Sunny Cove side, rather than adding them to the Tremont side, in order to ensure the OS can migrate processes safely between them.)",still trouble making time thought might want know understanding correctly release brand new processor line without hybrid processor ie sunny cove read turning beyond sunny cove side rather side order ensure o migrate safely,issue,positive,positive,positive,positive,positive,positive
642808422,"Hi, I would like to work on this. I am a new contributor, please let me know the files to get started.",hi would like work new contributor please let know get,issue,positive,positive,positive,positive,positive,positive
642599890,Yeah we should be checking errors more carefully in `save_dictionary`. Basically check errors when opening the fstream and writing to it before we get to ConstFst::Write in the first place.,yeah carefully basically check opening writing get first place,issue,negative,positive,neutral,neutral,positive,positive
642475716,"Other than ""not noise-robust, biased towards US male accents"" what would you suggest the text include?",towards u male would suggest text include,issue,negative,neutral,neutral,neutral,neutral,neutral
642360549,"> --package pack/

I was so simple, looks like at some point lost the full path, and was only taking the dir path.

Now it works with `--package pack/lm.scorer`  

@lissyx Thanks for the help.",package simple like point lost full path taking path work package thanks help,issue,positive,positive,positive,positive,positive,positive
642190197,@reuben I have lots of Mac/iOS experience with Objective-C. I’m a bit tied up with other projects right now but ping me if no-one else takes this.,lot experience bit tied right ping else,issue,negative,positive,positive,positive,positive,positive
642184919,This is unrelated. Please use discourse as advised for support. Please check your setup for tensorflow training requirements. ,unrelated please use discourse advised support please check setup training,issue,positive,neutral,neutral,neutral,neutral,neutral
642183331,"> > Am I interpreting this correct in that there is memory leak in 0.6.1 but seems that it's no longer an issue in 0.7.1?
> > Or is the ""possibly lost"" blocks a concern still?
> 
> So, @khu834 can you share your original 0.7+ valgrind report? We still are in the dark on that matter.

Here's the full report for python client, 0.7.1
https://gist.github.com/khu834/725e5ee108026b90cfdb0d77876dbd67",correct memory leak longer issue possibly lost concern still khu share original report still dark matter full report python client,issue,negative,positive,positive,positive,positive,positive
642038199,"With the latest changes to enable using TF 2.2 on the native client side, I was able to build the TFLite version of libdeepspeech.so for iOS. There's still some work to be done to integrate it with our CI before we can land it, and we would probably need to write a basic Objective-C/Swift wrapper for the API. I don't know anything about iOS development though, so if anyone is interested in helping out, it'd be greatly appreciated. I can help set up the development environment to build for iOS (or just send a copy of libdeepspeech.so) as well as help with CI changes needed for landing iOS support.",latest enable native client side able build version still work done integrate land would probably need write basic wrapper know anything development though anyone interested helping greatly help set development environment build send copy well help landing support,issue,positive,positive,positive,positive,positive,positive
641663928,"The stream state returns badbit
Docs: ""This flag is set by operations performed on the stream when an error occurs while read or writing data, generally causing the loss of integrity of the stream.""

",stream state flag set stream error read writing data generally causing loss integrity stream,issue,negative,positive,neutral,neutral,positive,positive
641648500,"> Is this native or Windows for Linux ?

I'm testing on a machine with Ubuntu 18.04.4 LTS as host SO, and a vm with Ubuntu 18.04.4 LTS running Windows 10 as host, both machines with the same error",native testing machine host running host error,issue,negative,neutral,neutral,neutral,neutral,neutral
641647630,"> Any specificity regarding the filesystem?

No.


> rights?

double-checked and folder and files got write read permissions.



> @carlfm01 Could you catch the actual error value returned by `tellp()` ?

Yes:
Finally re-compiled the decoder
tellp returns -1, reading the docs I should read the state, will try ",specificity regarding folder got write read could catch actual error value returned yes finally reading read state try,issue,negative,neutral,neutral,neutral,neutral,neutral
641121334,@carlfm01 Could you catch the actual error value returned by `tellp()` ?,could catch actual error value returned,issue,negative,neutral,neutral,neutral,neutral,neutral
641120817,">  8TB storage, host disk and project disk with more than 120GB free space each

Any specificity regarding the filesystem? rights? `tellp()` to fail on an output stream is weird ...",storage host disk project disk free space specificity regarding fail output stream weird,issue,negative,negative,negative,negative,negative,negative
641117733,"> I've been getting this warning in the console when training with DeepSpeech 0.7.3
> 
> ```
> swig/python detected a memory leak of type 'Alphabet *', no destructor found. 
> ```
> 
> It seems the valgrind check ran earlier reported an issue with TF but maybe this is also part of it?
> 
> If it's a separate issue I can open another ticket instead.

This was taken care of in #3049 ",getting warning console training memory leak type destructor found check ran issue maybe also part separate issue open another ticket instead taken care,issue,negative,neutral,neutral,neutral,neutral,neutral
641116943,"> Am I interpreting this correct in that there is memory leak in 0.6.1 but seems that it's no longer an issue in 0.7.1?
> Or is the ""possibly lost"" blocks a concern still?

So, @khu834  can you share your original 0.7+ valgrind report? We still are in the dark on that matter.",correct memory leak longer issue possibly lost concern still khu share original report still dark matter,issue,negative,positive,neutral,neutral,positive,positive
641033735,"That flag is precisely for when you don't have CUDNN training support, it loads CUDNN weights into a non-CUDNN graph. So it should not require any specific support in OpenVINO. You could also try exporting with the inference graph for TFLite (but without converting it to TFLite format) which is simpler.",flag precisely training support graph require specific support could also try inference graph without converting format simpler,issue,positive,positive,positive,positive,positive,positive
640997445,"Hi, 

> I don't know much about OpenVINO but this looks a bit like you forgot to specify `--load_cudnn`

This did not work, as it is not support by openvino IR conversion 
Openvino does not support the current architecture for now ",hi know much bit like forgot specify work support conversion support current architecture,issue,positive,positive,neutral,neutral,positive,positive
640990634,"> Can you verify if `out/lm.binary` was properly generated

An old client can load the lm.binary without issues",verify properly old client load without,issue,negative,positive,neutral,neutral,positive,positive
640973738,"> let me test if I can still generate the trie out of it.

```
./generate_trie alphabet.txt  lm.binary trie
terminate called after throwing an instance of 'lm::FormatLoadException'
  what():  native_client/kenlm/lm/model.cc:70 in lm::ngram::detail::GenericModel<Search, VocabularyT>::GenericModel(const char*, const lm::ngram::Config&) [with Search = lm::ngram::trie::TrieSearch<lm::ngram::SeparatelyQuantize, lm::ngram::trie::ArrayBhiksha>; VocabularyT = lm::ngram::SortedVocabulary] threw FormatLoadException because `new_config.enumerate_vocab && !parameters.fixed.has_vocabulary'.
The decoder requested all the vocabulary strings, but this binary file does not have them.  You may need to rebuild the binary file with an updated version of build_binary.
```
Throws an error but I think it is just my old generate_trie. Hmm no idea honestly



",let test still generate terminate throwing instance search char search threw vocabulary binary file may need rebuild binary file version error think old idea honestly,issue,negative,positive,positive,positive,positive,positive
640965193,"lm and trie

> Which old method?

lm.binary and trie as separate files



> Can you verify if `out/lm.binary` was properly generated? Maybe issue is here

Looks correct with 1.7GB, let me test if I can still generate the trie out of it.",old method separate verify properly maybe issue correct let test still generate,issue,negative,positive,neutral,neutral,positive,positive
640964274,Can you verify if `out/lm.binary` was properly generated? Maybe issue is here.,verify properly maybe issue,issue,negative,neutral,neutral,neutral,neutral,neutral
640963238,"> > Spanish from a private
> 
> Generating the lm and trie using the old method works fine with this text.

Which old method?",private generating old method work fine text old method,issue,negative,positive,positive,positive,positive,positive
640961987,"> Spanish from a private

Generating the lm and trie using the old method works fine with this text.",private generating old method work fine text,issue,negative,positive,positive,positive,positive,positive
640961452,"> can you verify with much less data?

Same with 500 words:
```
python3 generate_package.py --alphabet alphabet.txt --lm out/lm.binary --vocab out/vocab-500.txt --package pack/ --default_alpha 0.75 --default_beta 1.85
500 unique words read from vocabulary file.
Doesn't look like a character based model.
Using detected UTF-8 mode: False
ERROR: AlignOutput: Can't determine stream position
ERROR: Could not align file during write after header
Package created in pack/
swig/python detected a memory leak of type 'Alphabet *', no destructor found.
```
> What are your hardware specs here?

Ryzen 9 3900x
32 GB RAM
8TB storage, host disk and project disk with more than 120GB free space each

> Where are those data from ?

Spanish from a private source, English: http://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz

> Can you repro with documented LM steps and git-provided data sources for the LM?

Yes, with the English norm text from libri of the guide. ",verify much le data python alphabet package unique read vocabulary file look like character based model mode false error ca determine stream position error could align file write header package memory leak type destructor found hardware spec ram storage host disk project disk free space data private source data yes norm text guide,issue,negative,positive,positive,positive,positive,positive
640947035,"> ERROR: AlignOutput: Can't determine stream position
> ERROR: Could not align file during write after header

this error is not from kenlm, it's from openfst code


>  --top_k 9000000

can you verify with much less data?

What are your hardware specs here?


> Spanish and English text.

Where are those data from ? Can you repro with documented LM steps and git-provided data sources for the LM?",error ca determine stream position error could align file write header error code verify much le data hardware spec text data data,issue,negative,positive,positive,positive,positive,positive
640908616,"Follow the build documentation but with the paths adapted to use the submodule instead of a separate repo, see what breaks, try to fix it, report here if you get stuck.",follow build documentation use instead separate see try fix report get stuck,issue,negative,neutral,neutral,neutral,neutral,neutral
640855545,"@imskr there's nothing here to be tested. The goal of this issue is to change the build scripts, documentation, tests, etc to work with a submodule instead of separate repos. Creating the submodule is just the first step.",nothing tested goal issue change build documentation work instead separate first step,issue,negative,positive,positive,positive,positive,positive
640574427,(So building Java bindings on Windows is probably currently broken.),building probably currently broken,issue,negative,negative,negative,negative,negative,negative
640561452,I added a comment when merging to avoid spinning tests.,added comment avoid spinning,issue,negative,neutral,neutral,neutral,neutral,neutral
640556932,"Finally all green! I think eventually we should probably just remove the root ones, but an incremental step is better than nothing :)",finally green think eventually probably remove root incremental step better nothing,issue,negative,positive,positive,positive,positive,positive
640464870,"Ah, no, I guess you can't, it's still hardcoded to specific people and teams.",ah guess ca still specific people,issue,negative,neutral,neutral,neutral,neutral,neutral
640464107,"You should be able to do it if you login with GitHub, as you have contributor access to this repo. In any case, there's no point in rerunning these tasks, as this PR hasn't changed any code, so it also won't change any tests.",able login contributor access case point code also wo change,issue,negative,positive,positive,positive,positive,positive
639978971,"I've been getting this warning in the console when training with DeepSpeech 0.7.3

```
swig/python detected a memory leak of type 'Alphabet *', no destructor found. 
```

It seems the valgrind check ran earlier reported an issue with TF but maybe this is also part of it?

If it's a separate issue I can open another ticket instead.",getting warning console training memory leak type destructor found check ran issue maybe also part separate issue open another ticket instead,issue,negative,neutral,neutral,neutral,neutral,neutral
639690826,"For example https://github.com/tensorflow/tensorflow/issues/29217 mentions leaking thread pools, which I confirmed as of now. Years old issue, still there, unlikely we have time to fix it ourselves ...",example thread confirmed old issue still unlikely time fix,issue,negative,neutral,neutral,neutral,neutral,neutral
639510200,"Ah, OK. Yeah I think for now we keep our current understanding for documentation. We have previously defined the API boundary for compatibility, documentation, and support at the native client level rather than including the training code. Maybe it'd be good to explicitly mention this in the docs somewhere.",ah yeah think keep current understanding documentation previously defined boundary compatibility documentation support native client level rather training code maybe good explicitly mention somewhere,issue,positive,positive,positive,positive,positive,positive
639503840,"I guess I just meant ""public"", as in not only TC specific, but ""public"" in the ""real"" world, i.e. PyPi.

I'm fine with the move, I just want to have it publicly decided that we aren't going to pour lots on effort into documentation, beyond what we've already have.",guess meant public specific public real world fine move want publicly decided going pour lot effort documentation beyond already,issue,negative,positive,positive,positive,positive,positive
639490150,"It's already public, somewhat documented, and we already have to deal support. I don't see PyPI publishing as any more public than what we currently have, just a way with less hacks to install it.",already public somewhat already deal support see public currently way le install,issue,negative,neutral,neutral,neutral,neutral,neutral
639465438,"@khu834 It's really sad that you decided to cut the whole original valgrind informations, because I have no way to check whether your original report matches my observations on `libdeepspeech.so` or not and thus I'm having to re-do everything. Much more complicated, especially when your other valgrind crashed: I'm have no idea if I'm looking at the same thing than you.",khu really sad decided cut whole original way check whether original report thus everything much complicated especially idea looking thing,issue,negative,negative,neutral,neutral,negative,negative
639459792,"Are we planning to document the decoder package as it would be ""public""? (I'd guess not but I thought I'd ask.)",document package would public guess thought ask,issue,negative,neutral,neutral,neutral,neutral,neutral
639442648,"On a debug build, full TensorFlow, I see the same figures and nothing that seems to be from our code, but all from TensorFlow itself.",build full see nothing code,issue,negative,positive,positive,positive,positive,positive
639423783,"No, adding to this one is fine.

> Am 05.06.2020 um 13:25 schrieb ricky-cck <notifications@github.com>:
> 
> ﻿
> should I make another PR?
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",one fine um make another reply directly view,issue,negative,positive,positive,positive,positive,positive
639422568,"We have several other importers that also have this issue, could you also apply this fix to them?

```
$ rg -B 5 ""csv\.DictWriter""
bin/import_cv2.py
127-
128-    output_csv = os.path.join(os.path.abspath(audio_dir), dataset + "".csv"")
129-    print(""Saving new DeepSpeech-formatted CSV file to: "", output_csv)
130-    with open(output_csv, ""w"", encoding=""utf-8"") as output_csv_file:
131-        print(""Writing CSV file for DeepSpeech.py as: "", output_csv)
132:        writer = csv.DictWriter(output_csv_file, fieldnames=FIELDNAMES)

bin/import_slr57.py
160-    pool.join()
161-
162-    with open(target_csv_template.format(""train""), ""w"") as train_csv_file:  # 80%
163-        with open(target_csv_template.format(""dev""), ""w"") as dev_csv_file:  # 10%
164-            with open(target_csv_template.format(""test""), ""w"") as test_csv_file:  # 10%
165:                train_writer = csv.DictWriter(train_csv_file, fieldnames=FIELDNAMES)
166-                train_writer.writeheader()
167:                dev_writer = csv.DictWriter(dev_csv_file, fieldnames=FIELDNAMES)
168-                dev_writer.writeheader()
169:                test_writer = csv.DictWriter(test_csv_file, fieldnames=FIELDNAMES)

bin/import_ts.py
132-    pool.join()
133-
134-    with open(target_csv_template.format(""train""), ""w"") as train_csv_file:  # 80%
135-        with open(target_csv_template.format(""dev""), ""w"") as dev_csv_file:  # 10%
136-            with open(target_csv_template.format(""test""), ""w"") as test_csv_file:  # 10%
137:                train_writer = csv.DictWriter(train_csv_file, fieldnames=FIELDNAMES)
138-                train_writer.writeheader()
139:                dev_writer = csv.DictWriter(dev_csv_file, fieldnames=FIELDNAMES)
140-                dev_writer.writeheader()
141:                test_writer = csv.DictWriter(test_csv_file, fieldnames=FIELDNAMES)

bin/import_tuda.py
110-        csv_path = os.path.join(
111-            CLI_ARGS.base_dir, ""tuda-{}-{}.csv"".format(TUDA_VERSION, sub_set)
112-        )
113-        print('Writing ""{}""...'.format(csv_path))
114-        with open(csv_path, ""w"") as csv_file:
115:            writer = csv.DictWriter(csv_file, fieldnames=FIELDNAMES)

bin/import_cv.py
126-    pool.close()
127-    pool.join()
128-
129-    print('Writing ""%s""...' % target_csv)
130-    with open(target_csv, ""w"") as target_csv_file:
131:        writer = csv.DictWriter(target_csv_file, fieldnames=FIELDNAMES)

bin/import_swc.py
460-        set_samples = sorted(set_samples, key=lambda s: s.wav_path)
461-        base_dir = os.path.abspath(CLI_ARGS.base_dir)
462-        csv_path = os.path.join(base_dir, language + ""-"" + sub_set + "".csv"")
463-        print('Writing ""{}""...'.format(csv_path))
464-        with open(csv_path, ""w"") as csv_file:
465:            writer = csv.DictWriter(

bin/import_m-ailabs.py
138-    pool.join()
139-
140-    with open(target_csv_template.format(""train""), ""w"") as train_csv_file:  # 80%
141-        with open(target_csv_template.format(""dev""), ""w"") as dev_csv_file:  # 10%
142-            with open(target_csv_template.format(""test""), ""w"") as test_csv_file:  # 10%
143:                train_writer = csv.DictWriter(train_csv_file, fieldnames=FIELDNAMES)
144-                train_writer.writeheader()
145:                dev_writer = csv.DictWriter(dev_csv_file, fieldnames=FIELDNAMES)
146-                dev_writer.writeheader()
147:                test_writer = csv.DictWriter(test_csv_file, fieldnames=FIELDNAMES)

bin/import_lingua_libre.py
137-    pool.join()
138-
139-    with open(target_csv_template.format(""train""), ""w"") as train_csv_file:  # 80%
140-        with open(target_csv_template.format(""dev""), ""w"") as dev_csv_file:  # 10%
141-            with open(target_csv_template.format(""test""), ""w"") as test_csv_file:  # 10%
142:                train_writer = csv.DictWriter(train_csv_file, fieldnames=FIELDNAMES)
143-                train_writer.writeheader()
144:                dev_writer = csv.DictWriter(dev_csv_file, fieldnames=FIELDNAMES)
145-                dev_writer.writeheader()
146:                test_writer = csv.DictWriter(test_csv_file, fieldnames=FIELDNAMES)
```",several also issue could also apply fix print saving new file open print writing file writer open train open dev open test open train open dev open test print open writer print open writer sorted language print open writer open train open dev open test open train open dev open test,issue,negative,positive,neutral,neutral,positive,positive
639421634,"OK, I see it now, I had misread the documentation before. We do pass a file-like to csv.DictWriter, and the file-like, not the writer, must be opened with `newline=''`. What a bad trap.",see misread documentation pas writer must bad trap,issue,negative,negative,negative,negative,negative,negative
639419767,"csv format incorrect (extra CRLF) in windows environment, adding this parameter will fix",format incorrect extra environment parameter fix,issue,negative,neutral,neutral,neutral,neutral,neutral
639413659,"Hm, wait, `csvfile` is not a file object here. Have you actually observed incorrect behavior with the importer?",wait file object actually incorrect behavior importer,issue,negative,neutral,neutral,neutral,neutral,neutral
639413221,"Ugh, thanks for the PR. I don't even know why we're using `csv` here when we have `pandas` as a dependency already.",ugh thanks even know dependency already,issue,negative,positive,positive,positive,positive,positive
639362182,"I fear it might be on tensorflow side, not in our code ...",fear might side code,issue,negative,neutral,neutral,neutral,neutral,neutral
639361281,"> Seems that valgrind crashed?

Problem on your system, it works well here.

See, full TensorFlow:
```
[...]
==3876339== LEAK SUMMARY:
==3876339==    definitely lost: 24 bytes in 1 blocks
==3876339==    indirectly lost: 0 bytes in 0 blocks
==3876339==      possibly lost: 330,996 bytes in 1,472 blocks
==3876339==    still reachable: 1,631,169 bytes in 33,986 blocks
==3876339==                       of which reachable via heuristic:
==3876339==                         stdstring          : 396,275 bytes in 11,298 blocks
==3876339==                         newarray           : 4,672 bytes in 11 blocks
==3876339==         suppressed: 0 bytes in 0 blocks
```

And TFLite:
```
[...]
==3878526== LEAK SUMMARY:
==3878526==    definitely lost: 24 bytes in 1 blocks
==3878526==    indirectly lost: 0 bytes in 0 blocks
==3878526==      possibly lost: 0 bytes in 0 blocks
==3878526==    still reachable: 8,143 bytes in 134 blocks
==3878526==                       of which reachable via heuristic:
==3878526==                         stdstring          : 2,180 bytes in 58 blocks
==3878526==         suppressed: 0 bytes in 0 blocks
```",problem system work well see full leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed,issue,negative,positive,neutral,neutral,positive,positive
639149383,"Here's what I got with C++ client 0.7.1

```
valgrind --tool=memcheck ./deepspeech --model am/deepspeech-0.7.1-models.pbmm --scorer lm/deepspeech-0.7.1-models.scorer --audio ~/mem_tests/000de1bf-621c-4324-8f61-2736990b3467_8.wav
```

Seems that valgrind crashed?

```
==22593== Memcheck, a memory error detector
==22593== Copyright (C) 2002-2015, and GNU GPL'd, by Julian Seward et al.
==22593== Using Valgrind-3.12.0.SVN and LibVEX; rerun with -h for copyright info
==22593== Command: ./deepspeech --model am/deepspeech-0.7.1-models.pbmm --scorer lm/deepspeech-0.7.1-models.scorer --audio /home/khuang/mem_tests/000de1bf-621c-4324-8f61-2736990b3467_8.wav
==22593== 
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.1-0-g2e9c281
2020-06-04 22:17:36.176129: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
==22593== Warning: set address range perms: large range [0x395f8000, 0x71794000) (defined)

valgrind: m_translate.c:1767 (vgPlain_translate): Assertion 'tres.status == VexTransOK' failed.

host stacktrace:
==22593==    at 0x38083828: show_sched_status_wrk (m_libcassert.c:343)
==22593==    by 0x38083944: report_and_quit (m_libcassert.c:419)
==22593==    by 0x38083AD1: vgPlain_assert_fail (m_libcassert.c:485)
==22593==    by 0x380A2006: vgPlain_translate (m_translate.c:1767)
==22593==    by 0x380D547B: handle_chain_me (scheduler.c:1076)
==22593==    by 0x380D6FEF: vgPlain_scheduler (scheduler.c:1420)
==22593==    by 0x380E6416: thread_wrapper (syswrap-linux.c:103)
==22593==    by 0x380E6416: run_a_thread_NORETURN (syswrap-linux.c:156)
==22593==    by 0x380E68DA: vgModuleLocal_start_thread_NORETURN (syswrap-linux.c:325)
==22593==    by 0x3810F44D: ??? (in /usr/lib/valgrind/memcheck-amd64-linux)
==22593==    by 0xDEADBEEFDEADBEEE: ???
==22593==    by 0xDEADBEEFDEADBEEE: ???
==22593==    by 0xDEADBEEFDEADBEEE: ???

sched status:
  running_tid=4

Thread 1: status = VgTs_WaitSys (lwpid 22593)
==22593==    at 0x7ED6469: syscall (syscall.S:38)
==22593==    by 0x65A9323: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65A9120: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65A76C3: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65A7C20: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x536373A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x536378A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x536F598: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x537901C: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x53756B4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535E17A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5359BBA: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535A846: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535B366: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535B3DB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535B6DF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535BDBE: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x535BDD8: DS_SpeechToText (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x407D61: LocalDsSTT(ModelState*, short const*, unsigned long, bool, bool) (in /home/khuang/mem_tests/ds7/deepspeech)
==22593==    by 0x408311: ProcessFile(ModelState*, char const*, bool) (in /home/khuang/mem_tests/ds7/deepspeech)
==22593==    by 0x4085DF: main (in /home/khuang/mem_tests/ds7/deepspeech)

Thread 2: status = VgTs_WaitSys (lwpid 22594)
==22593==    at 0x7BE370F: futex_wait (futex-internal.h:61)
==22593==    by 0x7BE370F: futex_wait_simple (futex-internal.h:135)
==22593==    by 0x7BE370F: __pthread_once_slow (pthread_once.c:105)
==22593==    by 0x5ED56D5: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED58DF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED61D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB17F: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB5DB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA705: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA82B: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x54B87D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5510C86: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AEF61: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AF96E: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58B05D9: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFFA4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFEAE: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65940CB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 3: status = VgTs_WaitSys (lwpid 22595)
==22593==    at 0x7BE370F: futex_wait (futex-internal.h:61)
==22593==    by 0x7BE370F: futex_wait_simple (futex-internal.h:135)
==22593==    by 0x7BE370F: __pthread_once_slow (pthread_once.c:105)
==22593==    by 0x5ED56D5: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED58DF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED61D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB17F: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB5DB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA705: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA82B: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x54B87D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5510C86: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AEF61: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AF96E: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58B05D9: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFFA4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFEAE: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65940CB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 4: status = VgTs_Runnable (lwpid 22596)
==22593==    at 0x40B7AD1: ???
==22593==    by 0x5F: ???
==22593==    by 0xF: ???

Thread 5: status = VgTs_WaitSys (lwpid 22597)
==22593==    at 0x7BE217F: pthread_cond_wait@@GLIBC_2.3.2 (pthread_cond_wait.S:185)
==22593==    by 0x71BF50B: std::condition_variable::wait(std::unique_lock<std::mutex>&) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x6593C9A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65942CA: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 6: status = VgTs_WaitSys (lwpid 22598)
==22593==    at 0x7BE217F: pthread_cond_wait@@GLIBC_2.3.2 (pthread_cond_wait.S:185)
==22593==    by 0x71BF50B: std::condition_variable::wait(std::unique_lock<std::mutex>&) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x6593C9A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65942CA: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 7: status = VgTs_WaitSys (lwpid 22599)
==22593==    at 0x7BE3780: futex_wake (futex-internal.h:231)
==22593==    by 0x7BE3780: __pthread_once_slow (pthread_once.c:127)
==22593==    by 0x5ED56D5: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED58DF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5ED61D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB17F: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFB5DB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA705: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5EFA82B: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x54B87D8: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5510C86: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AEF61: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AF96E: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58B05D9: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFFA4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFEAE: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFD0A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58AFF99: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58B01AD: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58BC6AD: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58BDF4A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58E259D: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x58E2EB2: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x63B0FA4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x63A1EBF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65940CB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 8: status = VgTs_WaitSys (lwpid 22600)
==22593==    at 0x7BE217F: pthread_cond_wait@@GLIBC_2.3.2 (pthread_cond_wait.S:185)
==22593==    by 0x71BF50B: std::condition_variable::wait(std::unique_lock<std::mutex>&) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x54042CA: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5404392: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5B791D0: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x5BB0F86: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x63B0FA4: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x63A1EBF: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65940CB: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 9: status = VgTs_WaitSys (lwpid 22601)
==22593==    at 0x7BE217F: pthread_cond_wait@@GLIBC_2.3.2 (pthread_cond_wait.S:185)
==22593==    by 0x71BF50B: std::condition_variable::wait(std::unique_lock<std::mutex>&) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x6593C9A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x65942CA: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)

Thread 10: status = VgTs_WaitSys (lwpid 22602)
==22593==    at 0x7BE217F: pthread_cond_wait@@GLIBC_2.3.2 (pthread_cond_wait.S:185)
==22593==    by 0x71BF50B: std::condition_variable::wait(std::unique_lock<std::mutex>&) (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x6593C9A: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x659440B: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x6593193: ??? (in /home/khuang/mem_tests/ds7/libdeepspeech.so)
==22593==    by 0x71C51FF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.22)
==22593==    by 0x7BDC4A3: start_thread (pthread_create.c:456)
==22593==    by 0x7EDAD0E: clone (clone.S:97)


Note: see also the FAQ in the source distribution.
It contains workarounds to several common problems.
In particular, if Valgrind aborted or crashed after
identifying problems in your program, there's a good chance
that fixing those problems will prevent Valgrind aborting or
crashing, especially if it happened in m_mallocfree.c.

If that doesn't help, please report this bug to: www.valgrind.org

In the bug report, send all the above text, the valgrind
version, and what OS and version you are using.  Thanks.
```
",got client model scorer audio memory error detector copyright gnu al rerun copyright command model scorer audio binary use warning set address range large range defined assertion host status thread status short unsigned long bool bool char bool main thread status clone thread status clone thread status thread status clone thread status clone thread status clone thread status clone thread status clone thread status clone note see also source distribution several common particular aborted program good chance fixing prevent especially help please report bug bug report send text version o version thanks,issue,positive,positive,positive,positive,positive,positive
639084056,"Thanks for pointing me to discourse. I found many people mentioning this requirement since 2017 and building Indian accent (non-us accent) model. However, couldn't locate a link to someone who has uploaded a pretrained model for the same. ",thanks pointing discourse found many people requirement since building accent accent model however could locate link someone model,issue,negative,positive,positive,positive,positive,positive
638889555,"> Another similar ticket #1866 [Subpar performance with non-native English speakers](https://github.com/mozilla/DeepSpeech/issues/1866) has been closed.
> 
> I tried deepspeech with indian accent audios and US accent audios. The recognition of US accent is good but for non US accent the recognition is very bad. I have tested bit rate and background noise - all same for US and non US accent audios, so concluded that I may need a different model.
> 
> Current Model I a using is deepspeech-0.7.1-models.pbmm. Please let me know if there exists other model too? or same model should work ?

This is not a bug, please join Discourse where there are already efforts ongoing to provide indian-accented improved data.",another similar ticket performance closed tried accent u accent recognition u accent good non u accent recognition bad tested bit rate background noise u non u accent may need different model current model please let know model model work bug please join discourse already ongoing provide data,issue,positive,negative,neutral,neutral,negative,negative
638858730,"I see. It makes sense, in this case.

Thanks for all the efforts!",see sense case thanks,issue,negative,positive,positive,positive,positive,positive
638840453,"> Of course, even if useful, you might still leave it as ""help wanted"" enhancement.

I seriously doubt, given that I have shared patches as a PR against SWIG to bring support from 10+ to newer versions, and I still failed to get help from maintainers to run it on Travis.

V8 changes frequently enough that it's more trouble setting up the necessary bits for allowing people to build the wrapper than to just wait for us to ship an update.",course even useful might still leave help enhancement seriously doubt given swig bring support still get help run travis frequently enough trouble setting necessary people build wrapper wait u ship update,issue,positive,negative,neutral,neutral,negative,negative
638822977,"BTW: @lissyx : Thanks for having made these changes and having fixed #3027!
I confirm that deepspeech 0.7.3 npm package now loads with node 14.4.0. I'm still working on adapting to the new API.",thanks made fixed confirm package node still working new,issue,negative,positive,positive,positive,positive,positive
638821229,"Yeah, I took a brief look at the patch and got scared when I looked over the changes to 45 files, no less.

> In this case, we had to wait for node-pre-gyp to be updated first.

Do these situations appear most of the time, or only 1 out of 5 times? If the latter, a script might still be useful for the 4 cases.

Of course, even if useful, you might still leave it as ""help wanted"" enhancement.

> NodeJS is a mess

Extremely useful, but very patchy in its implementation, yes.",yeah took brief look patch got le case wait first appear time time latter script might still useful course even useful might still leave help enhancement mess extremely useful patchy implementation yes,issue,positive,positive,positive,positive,positive,positive
638815334,"If you look at what was changed in PR #3027, you'll see that it's not a matter of how complicated a build script is, sometimes it's not even possible to automate it (as was with this version). In this case, we had to wait for node-pre-gyp to be updated first. Sometimes, the build will start to fail due to some SWIG incompatibility, etc. NodeJS is a mess, it's not possible to simply hit a button and get support for a new platform.",look see matter complicated build script sometimes even possible version case wait first sometimes build start fail due swig incompatibility mess possible simply hit button get support new platform,issue,negative,negative,negative,negative,negative,negative
638806432,"I noticed :-)

I understand that it's non trivial to create such build scripts to automate the process. Should I file an another enhancement ticket for this? Because this will keep happening that node updates and somebody installs the update before you.",understand non trivial create build process file another enhancement ticket keep happening node somebody update,issue,negative,neutral,neutral,neutral,neutral,neutral
638798731,"> There is an easy, documented way (in INSTALL.md) to generate new binaries, or better yet, it happens automatically when the binary is missing.

Unfortunately, this is **not** easy, because you still need `libdeepspeech.so` for linkage, and because SWIG-based wrapper generation is complicated.",easy way generate new better yet automatically binary missing unfortunately easy still need linkage wrapper generation complicated,issue,positive,positive,positive,positive,positive,positive
638792377,"When you update the code, you need to reinstall the training code and update any dependencies, otherwise you end with mismatched versions. Just follow the normal installation step: https://deepspeech.readthedocs.io/en/v0.7.1/TRAINING.html#installing-deepspeech-training-code-and-its-dependencies",update code need reinstall training code update otherwise end follow normal installation step,issue,negative,positive,positive,positive,positive,positive
638780313,"DUP of #3027

The npm module was uploaded right **after** I filed this, so this should be FIXED now.",dup module right fixed,issue,negative,positive,positive,positive,positive,positive
638654456,"> @khu834 Do you see leak when running the C++ client ?

Will try that next. I have not ran the C++ client before, so I'll need to set that up first.",khu see leak running client try next ran client need set first,issue,negative,positive,positive,positive,positive,positive
638622114,@khu834 Do you see leak when running the C++ client ?,khu see leak running client,issue,negative,neutral,neutral,neutral,neutral,neutral
638621997,">  Or is the ""possibly lost"" blocks a concern still?

Without the details, it's hard to tell for sure, but it should be better to have 0. However, you tested the python bindings, and it could come from a lot of places there, even with the allocs things you tweaked.",possibly lost concern still without hard tell sure better however tested python could come lot even,issue,negative,positive,positive,positive,positive,positive
638610075,"Only took 10 minutes to get 0.7.1 set up! Love it.

python code (""mem_test.py"")
```
from deepspeech import Model
for i in range(5):
    ds = Model('am/deepspeech-0.7.1-models.pbmm')
    ds.enableExternalScorer('lm/deepspeech-0.7.1-models.scorer')
    ds.setScorerAlphaBeta(0.75, 1.85)
    ds.__del__()
```

valgrind command
```
valgrind --tool=memcheck --suppressions=valgrind-python.supp python -E -tt mem_test.py
```

Here's the summary:
```
==2441== HEAP SUMMARY:
==2441==     in use at exit: 3,520,936 bytes in 36,098 blocks
==2441==   total heap usage: 285,224 allocs, 249,126 frees, 57,586,141 bytes allocated
==2441==
==2441== LEAK SUMMARY:
==2441==    definitely lost: 70 bytes in 1 blocks
==2441==    indirectly lost: 0 bytes in 0 blocks
==2441==      possibly lost: 347,687 bytes in 1,561 blocks
==2441==    still reachable: 3,173,179 bytes in 34,536 blocks
==2441==                       of which reachable via heuristic:
==2441==                         stdstring          : 394,239 bytes in 11,236 blocks
==2441==                         newarray           : 3,792 bytes in 9 blocks
==2441==         suppressed: 0 bytes in 0 blocks
==2441== Rerun with --leak-check=full to see details of leaked memory
==2441==
==2441== For counts of detected and suppressed errors, rerun with: -v
==2441== Use --track-origins=yes to see where uninitialised values come from
==2441== ERROR SUMMARY: 6392 errors from 581 contexts (suppressed: 0 from 0)
```

Am I interpreting this correct in that there is memory leak in 0.6.1 but seems that it's no longer an issue in 0.7.1?
Or is the ""possibly lost"" blocks a concern still?


",took get set love python code import model range model command python summary heap summary use exit total heap usage leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed rerun see memory suppressed rerun use see come error summary suppressed correct memory leak longer issue possibly lost concern still,issue,negative,positive,neutral,neutral,positive,positive
638604797,"My apologies, just getting to this today.
Here's what I have so far running in 0.6.1 (will be doing 0.7.1 next as I have not set that up yet)

python code (""mem_test.py"")
```
from deepspeech import Model
for i in range(5):
    ds = Model('am/export/model.pbmm', 512)
    _ = ds.enableDecoderWithLM(
            'lm/lm.binary',
            'lm/trie',
            0.75,
            1.85
        )
    ds.__del__()
```

valgrind command
```
valgrind --tool=memcheck --suppressions=valgrind-python.supp python -E -tt mem_test.py
```

I downloaded the suppression file from http://svn.python.org/projects/python/trunk/Misc/valgrind-python.supp and uncommented the lines for PyObject_Free and PyObject_Realloc

Here's the summary:
```
==1838== HEAP SUMMARY:
==1838==     in use at exit: 5,676,567 bytes in 71,766 blocks
==1838==   total heap usage: 331,228 allocs, 259,462 frees, 44,720,754 bytes allocated
==1838==
==1838== LEAK SUMMARY:
==1838==    definitely lost: 14,382 bytes in 10 blocks
==1838==    indirectly lost: 1,179,029 bytes in 16,037 blocks
==1838==      possibly lost: 599,137 bytes in 4,979 blocks
==1838==    still reachable: 3,884,019 bytes in 50,740 blocks
==1838==                       of which reachable via heuristic:
==1838==                         stdstring          : 657,315 bytes in 16,518 blocks
==1838==                         newarray           : 15,328 bytes in 61 blocks
==1838==         suppressed: 0 bytes in 0 blocks
==1838== Rerun with --leak-check=full to see details of leaked memory
==1838==
==1838== For counts of detected and suppressed errors, rerun with: -v
==1838== Use --track-origins=yes to see where uninitialised values come from
==1838== ERROR SUMMARY: 4790 errors from 561 contexts (suppressed: 0 from 0)
```

Let me know if my methodologies is sound. I'll continue with 0.7.1 and report back.

",getting today far running next set yet python code import model range model command python suppression file uncommented summary heap summary use exit total heap usage leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed rerun see memory suppressed rerun use see come error summary suppressed let know sound continue report back,issue,negative,positive,neutral,neutral,positive,positive
638440028,"This could be handy for running experiments quickly. Till 0.8.0 will have to limit data manually. Anyways, Looking forward to it. ",could handy running quickly till limit data manually anyways looking forward,issue,negative,positive,positive,positive,positive,positive
638420347,"Augmentation changes the data in-place as it is being fed, but because it does random transformations every time it loads a file, it's like having more varied files. The number of steps does not change.",augmentation data fed random every time file like varied number change,issue,negative,negative,negative,negative,negative,negative
638401713,"> My question might be asked not in the right place, sorry for that.

No need to apologize. The issue template you deleted when posting this tells exactly where to post this, on Discourse: https://discourse.mozilla.org/c/deep-speech

In any case, the language model is created independently from the training of an acoustic model. We've recently added some more docs to ReadTheDocs with some instructions on how to create your own: https://deepspeech.readthedocs.io/en/master/Scorer.html and https://deepspeech.readthedocs.io/en/master/Decoder.html",question might right place sorry need apologize issue template posting exactly post discourse case language model independently training acoustic model recently added create,issue,negative,positive,neutral,neutral,positive,positive
638094925,"Ok, I'll check it out a different setup and let you know. Thanks for the
support

On Wed, Jun 3, 2020 at 11:58 AM lissyx <notifications@github.com> wrote:

> @generosocarbone <https://github.com/generosocarbone> Converting from
> different file format / audio format can raise very tricky issues, and it's
> a support burden that ends up as ""deepspeech provides poor results"" when
> it's just a matter of poor conversion. That's one of the reason we are not
> really keen to support that usecase, it's better you properly assert that
> your MP3 -> WAV conversion is correct before feeding.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/3017#issuecomment-638093129>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACGIO5CPLVI2I3NORSJSFLDRUYNDZANCNFSM4NKRJPGA>
> .
>
",check different setup let know thanks support wed wrote converting different file format audio format raise tricky support burden poor matter poor conversion one reason really keen support better properly assert conversion correct feeding reply directly view,issue,positive,positive,neutral,neutral,positive,positive
638093129,"@generosocarbone Converting from different file format / audio format can raise very tricky issues, and it's a support burden that ends up as ""deepspeech provides poor results"" when it's just a matter of poor conversion. That's one of the reason we are not really keen to support that usecase, it's better you properly assert that your MP3 -> WAV conversion is correct before feeding.",converting different file format audio format raise tricky support burden poor matter poor conversion one reason really keen support better properly assert conversion correct feeding,issue,negative,negative,neutral,neutral,negative,negative
638087638,"That is the Python client (installed with pip), not the binary we provide in the native_client.tar.xz package. It doesn't support MP3 (on any platform).",python client pip binary provide package support platform,issue,negative,neutral,neutral,neutral,neutral,neutral
638086844,"Sorry for the late reply.
This is my configuration, 
I'm using the [DeepSpeech Italian Model](https://github.com/MozillaItalia/DeepSpeech-Italian-Model)
OS: ubuntu 18.04

These are the commands I use for the execution
$ virtualenv test --python=python3
$ source test/bin/activate
$ pip install deepspeech==0.7.0a1
$ deepspeech --model output_graph.pbmm --audio test.mp3 --trie trie --lm lm.binary

And this is the error I get

`Loading model from file output_graph.pbmm`
`TensorFlow: v1.15.0-24-gceb46aa`
`DeepSpeech: v0.7.0-alpha.1-0-g60cbe3b`
`2020-06-03 11:39:41.454455: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA`
`Loaded model in 0.221s.`
`Loading language model from files lm.binary trie`
`Loaded language model in 0.131s.`
`Traceback (most recent call last):`
  `File ""/home/generoso/java/deepseech/test/bin/deepspeech"", line 8, in <module>`
 `   sys.exit(main())`
`  File ""/home/generoso/java/deepseech/test/lib/python3.6/site-packages/deepspeech/client.py"", line 126, in main`
`    fin = wave.open(args.audio, 'rb')`
`  File ""/home/generoso/anaconda3/lib/python3.6/wave.py"", line 499, in open`
`    return Wave_read(f)`
`  File ""/home/generoso/anaconda3/lib/python3.6/wave.py"", line 163, in __init__`
`    self.initfp(f)`
`  File ""/home/generoso/anaconda3/lib/python3.6/wave.py"", line 130, in initfp`
`    raise Error('file does not start with RIFF id')`
`wave.Error: file does not start with RIFF id`

At the moment I don't have the possibility to test it on macOs",sorry late reply configuration model o use execution test source pip install model audio error get loading model file binary use loaded model loading language model loaded language model recent call last file line module main file line main fin file line open return file line file line raise error start riff id file start riff id moment possibility test,issue,negative,negative,neutral,neutral,negative,negative
638085616,I had the same issue. I solved it changing to the stable branch 0.7.1 such is said [here](https://discourse.mozilla.org/t/failed-to-creating-scorer-model-ds-err-scorer-no-trie-solved/60897/6). Before that I was working on the master branch.,issue stable branch said working master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
638067185,"> with reference to #2851, I tried 0.8.0a2 but still not able to get these flags working. Will these be available with final release?
> 
> **INSTALL**
> `pip list`
> `deepspeech-training 0.8.0a2 /content/DeepSpeech/training`

This PR was not merged",reference tried still able get working available final release install pip list,issue,negative,positive,positive,positive,positive,positive
637819265,"I'll see what I can do. The main holdup in providing a PR of any kind has been that I've been having trouble making time for it on my end. Things just keep coming up and, when I do find time, it's been pushed to near the back of my priority-sorted TODO queue.",see main holdup providing kind trouble making time end keep coming find time near back queue,issue,negative,positive,positive,positive,positive,positive
637818314,"> Working from these phrasings and trying to retain its current concision...
> 
> > Linux x86 64 bit with a modern CPU (Needs at least AVX/FMA)
> > Linux x86 64 bit with a modern CPU + NVIDIA GPU (Compute Capability at least 3.0, see [NVIDIA docs](https://developer.nvidia.com/cuda-gpus))
> 
> ...maybe this.
> 
> > Linux x86 64 bit with an AVX/FMA-capable CPU
> > Linux x86 64 bit with an AVX/FMA-capable CPU + NVIDIA GPU ([Compute Capability](https://developer.nvidia.com/cuda-gpus) at least 3.0)
> 
>     1. It's shorter. (The existing one word-wraps in the comment preview while this doesn't.
> 
>     2. It avoids the ambiguity of saying ""a modern CPU"" in both but allowing the interpretation that the CUDA requirement replaces the AVX/FMA requirement.
> 
>     3. It takes advantage of how hyperlinks are used on sites like Wikipedia. (i.e. ""Click here to learn about Compute Capability"")
> 
>     4. It just generally avoids the duplication of saying ""a modern CPU, meaning a CPU with ..."" or ""Compute Capability, and here's a hyperlink"" when you can just say ""a CPU with ..."" or hyperlink the ""Computer Capability"" to begin with.

Happy to review a PR with those wording :)",working trying retain current concision bit modern need least bit modern compute capability least see maybe bit bit compute capability least shorter one comment preview ambiguity saying modern interpretation requirement requirement advantage used like click learn compute capability generally duplication saying modern meaning compute capability say computer capability begin happy review wording,issue,positive,positive,neutral,neutral,positive,positive
637805012,"Working from these phrasings and trying to retain its current concision...

> Linux x86 64 bit with a modern CPU (Needs at least AVX/FMA)
> Linux x86 64 bit with a modern CPU + NVIDIA GPU (Compute Capability at least 3.0, see [NVIDIA docs](https://developer.nvidia.com/cuda-gpus))

...maybe this.

> Linux x86 64 bit with an AVX/FMA-capable CPU
> Linux x86 64 bit with an AVX/FMA-capable CPU + NVIDIA GPU ([Compute Capability](https://developer.nvidia.com/cuda-gpus) at least 3.0)

1. It's shorter. (The existing one word-wraps in the comment preview while this doesn't.
2. It avoids the ambiguity of saying ""a modern CPU"" in both but allowing the interpretation that the CUDA requirement replaces the AVX/FMA requirement.
3. It takes advantage of how hyperlinks are used on sites like Wikipedia. (i.e. ""Click here to learn about Compute Capability"")
4. It just generally avoids the duplication of saying ""a modern CPU, meaning a CPU with ..."" or ""Compute Capability, and here's a hyperlink"" when you can just say ""a CPU with ..."" or hyperlink the ""Computer Capability"" to begin with.",working trying retain current concision bit modern need least bit modern compute capability least see maybe bit bit compute capability least shorter one comment preview ambiguity saying modern interpretation requirement requirement advantage used like click learn compute capability generally duplication saying modern meaning compute capability say computer capability begin,issue,positive,negative,neutral,neutral,negative,negative
637717003,"Yes. I thought the question was for you, because you reopened it again. And I already had a workaround.",yes thought question already,issue,negative,neutral,neutral,neutral,neutral,neutral
637665914,"I don't remember any specific choice of first vs last letter being decided on, or even coded. I think what you're seeing is just a coincidence. If you can figure out a better way to capture the timings, PRs are welcome. But the first task would be to collect a diverse set of audios as a test set to show that your changes don't regress timings too badly on files that aren't your own.",remember specific choice first last letter decided even think seeing coincidence figure better way capture welcome first task would collect diverse set test set show regress badly,issue,negative,positive,positive,positive,positive,positive
637662014,"cool, thanks @reuben I can't rerun it. I guess it can be done only by members",cool thanks ca rerun guess done,issue,positive,positive,positive,positive,positive,positive
637648352,"In this case the failures look like they're network related, some intermittent connection failure. You can rerun the task by clicking on it and then using the action button on the bottom right corner.",case look like network related intermittent connection failure rerun task action button bottom right corner,issue,negative,positive,neutral,neutral,positive,positive
637647765,"@imskr you can check the logs for yourself, just click on the failed task and then click ""View Live Logs"".",check click task click view live,issue,negative,positive,positive,positive,positive,positive
637607567,"@ssokolow Do you have a wording suggestion, so that we can make the documentation elss ambigous?",wording suggestion make documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
637606850,"@khu834 Gentle ping, can you shed more light on that?",khu gentle ping shed light,issue,negative,positive,positive,positive,positive,positive
637605772,"> > Not everyone can afford to upgrade to an RPi 4 confused
> 
> So, at the time of our previous exchanges, the situation was that the huge matrix/vector multiplications in our model would not be parallelized, because they depends on floats. And turning our model to int using TFLite's quantization tooling was broken from several places.
> 
> Things have moved, and I could verify that TensorFlow r2.2 relies on ruy library and that if you compile it properly, you can get TFLite runtime and RUY for those matrix/vector multiplications.
> I could verify we now leverage 4 threads on several ARM targets, including RPi3 running Raspbian.
> 
> There's still quite some plumbery work, but we should have something available sooner than later now.

This revealed a nasty bug in the ruy library used by tensorflow (only exposed on armv7 running nodejs v11 and above), but now it should work as expected: this is the PR leveraging this effort https://github.com/mozilla/DeepSpeech/pull/2952

With TensorFlow r2.2, we can get GPUs (not only) delegation so any feedback could be welcome on https://github.com/mozilla/DeepSpeech/issues/2270

If people are brave enough to test and give some feedback that would help asserting the need and improvements one can expect.",everyone afford upgrade confused time previous situation huge model would turning model quantization tooling broken several could verify library compile properly get could verify leverage several arm running still quite plumbery work something available sooner later revealed nasty bug library used exposed running work effort get delegation feedback could welcome people brave enough test give feedback would help need one expect,issue,negative,positive,neutral,neutral,positive,positive
637503198,"> In this example also, for the first word 'what' the start_time is 0.54 ms, that is the time step where the letter 'w' ends. Ideally the start time of the word 'what' is 0.47 ms, where the letter w starts.

I think I remember discussions around that specifically when the feature was landed and we had to find a middle ground that works for any language. @reuben might be able to shed more light, since he was reviewing that code :/",example also first word time step letter ideally start time word letter think remember around specifically feature landed find middle ground work language might able shed light since code,issue,negative,positive,positive,positive,positive,positive
637487571," ```
./deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --audio ../../test_data/en-US_testing/pcm_general_ckohls_american_accent/withagc/1583528025758_but_as_the_name_of_the_russian_president.wav --json --beam_width 512
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=96000
{
""metadata"":{""confidence"":-44.8398},""words"":[{""word"":""**what**"",""time"":**0.54**,""duration"":0.12},{""word"":""is"",""time"":0.68,""duration"":0.1},{""word"":""the"",""time"":0.8,""duration"":0.08},{""word"":""name"",""time"":0.92,""duration"":0.16},{""word"":""of"",""time"":1.1,""duration"":0.12},{""word"":""the"",""time"":1.24,""duration"":0.0999999},{""word"":""russian"",""time"":1.38,""duration"":0.32},{""word"":""president"",""time"":1.8,""duration"":0.4}],
""alternatives"":[
{""metadata"":{""confidence"":-37.1093},""words"":[{""word"":""what"",""time"":0.54,""duration"":0.12},{""word"":""is"",""time"":0.68,""duration"":0.1},{""word"":""the"",""time"":0.8,""duration"":0.08},{""word"":""name"",""time"":0.92,""duration"":0.16},{""word"":""of"",""time"":1.1,""duration"":0.12},{""word"":""the"",""time"":1.24,""duration"":0.0999999},{""word"":""russian"",""time"":1.38,""duration"":0.32},{""word"":""resident"",""time"":1.8,""duration"":0.4}]},
{""metadata"":{""confidence"":-38.2863},""words"":[{""word"":""what"",""time"":0.54,""duration"":0.12},{""word"":""is"",""time"":0.68,""duration"":0.1},{""word"":""the"",""time"":0.8,""duration"":0.08},{""word"":""name"",""time"":0.92,""duration"":0.16},{""word"":""of"",""time"":1.1,""duration"":0.12},{""word"":""the"",""time"":1.24,""duration"":0.0999999},{""word"":""russian"",""time"":1.38,""duration"":0.32},{""word"":""present"",""time"":1.8,""duration"":0.42}]}
]
}
```

In this example also, for the first word 'what' the start_time is 0.54 ms, that is the time step where the letter 'w' ends. Ideally the start time of the word 'what' is 0.47 ms, where the letter w starts.
 Please find the sample file at https://drive.google.com/drive/folders/1oYwmXVswgJUpfZDHu8r1GDJmSUjaMkfB?usp=sharing ",model scorer audio lite confidence word time duration word time duration word time duration word name time duration word time duration word time duration word time duration word president time duration confidence word time duration word time duration word time duration word name time duration word time duration word time duration word time duration word resident time duration confidence word time duration word time duration word time duration word name time duration word time duration word time duration word time duration word present time duration example also first word time step letter ideally start time word letter please find sample file,issue,positive,positive,positive,positive,positive,positive
637476978,"> For in the above example, in case of word alexa, the letter 'a' is recognised at the time step 38(0.76 ms), that is the end of letter 'a', ideally the word starts at time step 33(0.66 ms) where the letter 'a' starts.

Do you reproduce with other words that would not start / end with the same letter?",example case word letter time step end letter ideally word time step letter reproduce would start end letter,issue,negative,positive,positive,positive,positive,positive
637465396,"The problem with start_time for the first word is that, showing the time step at which it recognise the first letter, that means the  time step at the end of that letter. Ideally we should get the time step at which the start of the first letter. But with the current implementation, it is difficult to get the start time of the first letter of the starting word.

For in the above example, in case of word alexa, the letter 'a' is recognised at the time step 38(0.76 ms), that is the end of letter 'a', ideally the word starts at time step 33(0.66 ms) where the letter 'a' starts.",problem first word showing time step first letter time step end letter ideally get time step start first letter current implementation difficult get start time first letter starting word example case word letter time step end letter ideally word time step letter,issue,negative,positive,positive,positive,positive,positive
636430303,Cool. Which branch we have to make git submodule? @lissyx ,cool branch make git,issue,negative,positive,positive,positive,positive,positive
636391841,"> Can I help on this @lissyx

Well maybe not the TC things, but if you want to experiment smoother flow with tensorflow as a submodule, you're welcome",help well maybe want experiment smoother flow welcome,issue,positive,positive,positive,positive,positive,positive
636125880,"PR looks good, but there's a weird failure on Python 3.5...",good weird failure python,issue,negative,negative,neutral,neutral,negative,negative
635939936,"Oh, and you can also remove the Travis entry for running unittests.",oh also remove travis entry running,issue,negative,neutral,neutral,neutral,neutral,neutral
635543824,"Make sure Git LFS is properly installed before cloning the repository, otherwise you end up with missing files. https://deepspeech.readthedocs.io/en/v0.7.1/TRAINING.html",make sure git properly repository otherwise end missing,issue,negative,positive,neutral,neutral,positive,positive
635542887,"> ```
> version https://git-lfs.github.com/spec/v1
> oid sha256:d0cf926ab9cab54a8a7d70003b931b2d62ebd9105ed392d1ec9c840029867799
> size 953363776```
> ```

Broken git lfs setup then",version sha size broken git setup,issue,negative,negative,negative,negative,negative,negative
635304576,"> we can do the predictions using the pip module of `deepspeech`

you can use python binding or nodejs binding or directly the c++ client, we provide prebuilt versions for all ..",pip module use python binding binding directly client provide,issue,negative,positive,neutral,neutral,positive,positive
635295353,"@lissyx To be honest, I did not notice that we can do the predictions using the pip module of `deepspeech`. Now that I think back about it, it was kinda silly, considering it's the first example on the homepage. I probably did not see it at that time, and then never actually happened to see it again, until today.",honest notice pip module think back silly considering first example probably see time never actually see today,issue,positive,positive,neutral,neutral,positive,positive
635286882,"> Alright @lissyx . I am not good at building from source, my bad :(

May I ask why you went down the complicated road of building all the dependencies yourself? why not using your distro's and just build `deepspeech` as we document ?",alright good building source bad may ask went complicated road building build document,issue,negative,negative,negative,negative,negative,negative
635282539,"Alright @lissyx . I am not good at building from source, my bad :(",alright good building source bad,issue,negative,positive,neutral,neutral,positive,positive
635280298,"> @lissyx Thanks, but `pkg-config` is not mentioned anywhere on the build page, which I linked to in my post :(

We mention distros deps already. You chose to build from scratch, it's not unexpected you should be able to read the makefile and the cc command to check what it does. And pkgconfig is a very well known tooliin that kind of use.

How do you want to articulate that in the doc? Please send PR. ",thanks anywhere build page linked post mention already chose build scratch unexpected able read command check well known kind use want articulate doc please send,issue,positive,positive,positive,positive,positive,positive
635261892,"@lissyx Thanks, but `pkg-config` is not mentioned anywhere on the build page, which I linked to in my post :(",thanks anywhere build page linked post,issue,negative,positive,positive,positive,positive,positive
635257364,">  It is only on the third step for `make deepspeech` that I get the above output.

it looks like you build sox yourself, I'd suspect `pkg-config` is not properly returning its values ....",third step make get output like build suspect properly,issue,negative,neutral,neutral,neutral,neutral,neutral
635123745,"[This SO answer](https://stackoverflow.com/a/42339395) helped me get past this error. I'm on Ubuntu 18.04, and I simply did `sudo apt install libgsm-dev libmagic-dev` as referred to in the SO answer. It did help me get past this error (however, I got another unrelated error later :(",answer get past error simply apt install answer help get past error however got another unrelated error later,issue,negative,positive,neutral,neutral,positive,positive
635118800,"./deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --json --audio /data/local/test_data/3.wav **--beam_width 128**
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":-25.784},""words"":[{""word"":""alexa"",""time"":0.76,""**duration"":0.38**}],
""alternatives"":[
{""metadata"":{""confidence"":-11.6792},""words"":[{""word"":""alex"",""time"":0.76,""duration"":0.32}]},
{""metadata"":{""confidence"":-10.141},""words"":[{""word"":""alec"",""time"":0.76,""duration"":0.32}]}
]
}


./deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --json --audio /data/local/test_data/3.wav **--beam_width 64**
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":-25.784},""words"":[{""word"":""alexa"",""time"":0.76,**""duration"":0.68**}],
""alternatives"":[
{""metadata"":{""confidence"":-11.6792},""words"":[{""word"":""alex"",""time"":0.76,""duration"":0.34}]},
{""metadata"":{""confidence"":-10.141},""words"":[{""word"":""alec"",""time"":0.76,""duration"":0.34}]}
]
}

In the above two examples, one with beam_width 128 is giving duration 0.38 and the  beam_width 64 is giving duration 0.68, which seems to be more closer to the actual scenario. But the start time is still not accurate. 
Why beam_width is making a big difference in the duration calculation here?",model scorer audio lite confidence word time duration confidence word time duration confidence word alec time duration model scorer audio lite confidence word time duration confidence word time duration confidence word alec time duration two one giving duration giving duration closer actual scenario start time still accurate making big difference duration calculation,issue,positive,positive,positive,positive,positive,positive
634834071,no problem! will test again and close if there is no issue. ^^ ,problem test close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
634811858,Sorry for delay @reuben I will fix this by tomorrow. And I will update you on mozilla matrix. ,sorry delay fix tomorrow update matrix,issue,negative,negative,negative,negative,negative,negative
634805989,"Ah, looks like a leftover from argument reordering. I [pushed a fix](https://github.com/mozilla/DeepSpeech/commit/3d0ec01853fe9f5b73a6e35b0226e4c97c237655). The train, dev and test subsets should have completed in that run, if you're looking for validated, other, or train-all, you should be able to re-run with the fixed code and it'll skip the already done conversion work, so should be faster to continue from where it stopped. Thanks for testing!",ah like leftover argument fix train dev test run looking able fixed code skip already done conversion work faster continue stopped thanks testing,issue,negative,positive,positive,positive,positive,positive
634802600,"```
Skipped 370976 samples that failed upon conversion.
Final amount of imported audio: 0:00:00.
Saving new DeepSpeech-formatted CSV file to:  C:\Users\kin\Downloads\de.tar\de\clips\validated.csv
Writing CSV file for DeepSpeech.py as:  C:\Users\kin\Downloads\de.tar\de\clips\validated.csv
Progress |#                                                                                            | 100% completed
Traceback (most recent call last):
  File ""DeepSpeech-0.6.0/bin/import_cv2.py"", line 222, in <module>
    main()
  File ""DeepSpeech-0.6.0/bin/import_cv2.py"", line 219, in main
    params.space_after_every_character)
  File ""DeepSpeech-0.6.0/bin/import_cv2.py"", line 42, in _preprocess_data
    filter_obj, rows=set_samples, exclude=exclude)
TypeError: _maybe_convert_set() got multiple values for argument 'rows'

```

",upon conversion final amount audio saving new file writing file progress recent call last file line module main file line main file line got multiple argument,issue,negative,positive,neutral,neutral,positive,positive
634790173,"Should be simpler to reason about the values after #3021, confidence values are simply log probs.",simpler reason confidence simply log,issue,positive,neutral,neutral,neutral,neutral,neutral
634586680,So why are we getting high negative confidence value  for correct recognition ?,getting high negative confidence value correct recognition,issue,negative,negative,neutral,neutral,negative,negative
634585131,What PR? #2911 was (mistakenly) linked and unlinked from this issue.,mistakenly linked unlinked issue,issue,negative,neutral,neutral,neutral,neutral,neutral
634562378,will this pull request solve this issue?,pull request solve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
634513398,"Thanks for the quick response @reuben ! I just created a new virtual environment, and added a `-U` while doing the pip install and it worked!",thanks quick response new virtual environment added pip install worked,issue,negative,positive,positive,positive,positive,positive
634478299,"Huh, TensorFlow really messed up the documentation around 1.15. It's 0.24.1. I'll include that inline in the README.",huh really documentation around include,issue,negative,positive,positive,positive,positive,positive
634477324,"> $ pip install dist/*.whl

Did this actually install the package? You didn't share logs. Try with `-U` to force the upgrade.",pip install actually install package share try force upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
634311053,The issue template you ignored and deleted in order to post this issue clearly states GitHub issues are not meant for support. Use Discourse.,issue template order post issue clearly meant support use discourse,issue,positive,positive,positive,positive,positive,positive
634125748,"The client in the native_client package relies on SoX to handle the input. On macOS it does support MP3, but I'm not sure if our release Linux binaries are linked against libmp3lame. You should be able to test quite easily, though.",client package handle input support sure release linked able test quite easily though,issue,positive,positive,positive,positive,positive,positive
634099539,"RTD is ReadTheDocs. Those docs are now here: https://deepspeech.readthedocs.io/en/master/Scorer.html

Thanks for noticing the dangling reference in data/README.rst, I'll update it.",thanks dangling reference update,issue,negative,positive,positive,positive,positive,positive
634062410,"Oh, it seems the README was deleted two days ago (https://github.com/mozilla/DeepSpeech/commit/4356a2764ba086dc7f4049d4c90a4d07d482b3f0). I am not sure what ""RTD"" is (in the commit message)? And should I refer to the old README, or has there been some content changes as well to the README?",oh two day ago sure commit message refer old content well,issue,positive,positive,positive,positive,positive,positive
633718416,"tried. Seems to work. I will let it continue running in the meantime. will get back to you after it's finished to make sure. 
nvm i don't have the time to let it run through the entire process. Will let it run through the entire process tomorrow.",tried work let continue running get back finished make sure time let run entire process let run entire process tomorrow,issue,negative,positive,positive,positive,positive,positive
633669674,I don't know much about OpenVINO but this looks a bit like you forgot to specify `--load_cudnn`,know much bit like forgot specify,issue,negative,positive,positive,positive,positive,positive
633618129,"We currently don't support conversion using OpenVINO. Maybe the OpenVINO team could help?

That said, if you succeed in conversion using OpenVINO we'd be interested in hearing about tha result.",currently support conversion maybe team could help said succeed conversion interested hearing tha result,issue,positive,positive,positive,positive,positive,positive
633592632,"The way that code is written is broken, it's incompatible with some `multiprocessing` spawn methods, we should fix it. There are different default spawn methods on different platforms, which is probably why it's breaking on Windows.",way code written broken incompatible spawn fix different default spawn different probably breaking,issue,negative,negative,negative,negative,negative,negative
633591466,"> It should be defined within bin/import_cv2.py.

Well yeah it's in the code. But as soon as it tries to calls it it somehow undefined. I have no idea why. Seems like a weird issue since it works on Ubuntu. But since training on Windows isn't support i guess i'll have to install linux then. Anyways thanks for your help. ",defined within well yeah code soon somehow undefined idea like weird issue since work since training support guess install anyways thanks help,issue,positive,negative,negative,negative,negative,negative
633588866,"> NameError: name 'label_filter_fun' is not defined

It should be defined within `bin/import_cv2.py`. Please note we don't support training on Windows, so it's not surprising it is breaking.",name defined defined within please note support training surprising breaking,issue,positive,positive,positive,positive,positive,positive
633434607,"Thanks for the fix! I'll start a new PR with your commit and add some tests, as CI tests only run for PRs opened by people with write access.",thanks fix start new commit add run people write access,issue,positive,positive,positive,positive,positive,positive
633070499,"I was running a 32-bit version of 3.6, but I have since made a 3.8-64 bit install and pip worked to download deepspeech on that. Thank you!

As a note: on the ""Supported Platforms"" page of 0.7.1 ""Windows 8.1, 10, and Server 2012 R2 64-bits"" was ambiguous to me--I thought only the Server 2012 required the 64-bit from this, but I suppose the ""bitS"" should have hinted otherwise. ",running version since made bit install pip worked thank note page server ambiguous thought server suppose otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
632933473,"> I see. Given that you've already seen from experience this isn't a good idea, we can probably just close this.
> 
> I'd like to know from your experience though if the simplest solution (local storage) is the best solution or if there is a better solution for storing large amounts of training data?

it's really @tilmankamp who can give useful feedback here.",see given already seen experience good idea probably close like know experience though solution local storage best solution better solution large training data really give useful feedback,issue,positive,positive,positive,positive,positive,positive
632932073,"I see. Given that you've already seen from experience this isn't a good idea, we can probably just close this.

I'd like to know from your experience though if the simplest solution (local storage) is the best solution or if there is a better solution for storing large amounts of training data?",see given already seen experience good idea probably close like know experience though solution local storage best solution better solution large training data,issue,positive,positive,positive,positive,positive,positive
632931058,"> Training. But it can be extended to inference as well.

For training, I'm already doubtful of the performances, but for inference it's unilkely to be a good idea


> 
> Performance will depend on the network since audio is stored in the cloud.
> I don't have metrics but assuming you've optimized the audio in a cache or similar it should be 'fast'. If necessary, I might be able to do some measurements.

Training experience says otherwise, and also forces me to believe only properly validated numbers.
I mean, let's be realistic two seconds: the cloud is not magic, there will be data tranfer at some point.
And if you do it live during the training, you need to have sustained network performances from the cloud to feed your GPUs.",training extended inference well training already doubtful inference good idea performance depend network since audio cloud metric assuming audio cache similar necessary might able training experience otherwise also believe properly mean let realistic two cloud magic data point live training need sustained network cloud feed,issue,negative,positive,neutral,neutral,positive,positive
632929311,"> I’m now using EBS volumes mounted directly on the instance.

I also tried to use EFS and between the setup and speed, I found it to be too cumbersome and just went with an expanded EBS like you did.",mounted directly instance also tried use setup speed found cumbersome went expanded like,issue,negative,positive,neutral,neutral,positive,positive
632929072,"> Are we talking about training? Inference?

Training. But it can be extended to inference as well.

> Have you got nice perfs out of this?

Performance will depend on the network since audio is stored in the cloud.
I don't have metrics but assuming you've optimized the audio in a cache or similar it should be 'fast'. If necessary, I might be able to do some measurements.
",talking training inference training extended inference well got nice performance depend network since audio cloud metric assuming audio cache similar necessary might able,issue,positive,positive,positive,positive,positive,positive
632900592,"I’ve being doing training on AWS and tried various methods of accessing the data in the cloud, including S3 (via FUSE) and Elastic File System. In my testing, network volumes are far too slow for training. I’m now using EBS volumes mounted directly on the instance.",training tried various data cloud via fuse elastic file system testing network far slow training mounted directly instance,issue,negative,negative,neutral,neutral,negative,negative
632895500,Also you need to know that @tilmankamp worked hard of the topic of efficiency regarding training on our cluster and I fear this might be complicated. Have you got nice perfs out of this? ,also need know worked hard topic efficiency regarding training cluster fear might complicated got nice,issue,negative,negative,neutral,neutral,negative,negative
632887978,"Ex. I have 5 million audio recordings in an S3 bucket that are over 1TB in size.
Instead of loading the audio locally and pointing the filename to the local directory, I can instead specify an S3 URL and DS would download and process the audio from there instead.

What the CSV/TSV file would look like:

```
filename, filesize, transcript
s3:my-bucket/file_1, 100, foo 
s3:my-bucket/file_2, 100, bar 
s3:my-bucket/file_3, 100, baz
... 
```",ex million audio bucket size instead loading audio locally pointing local directory instead specify would process audio instead file would look like transcript foo bar,issue,negative,neutral,neutral,neutral,neutral,neutral
632866725,"Could you describre the usecase here? Even as optional, that's a non trivial amount of work and maintenance to consider.",could even optional non trivial amount work maintenance consider,issue,negative,neutral,neutral,neutral,neutral,neutral
632590680,0.7.0 and 0.7.1 no longer use lm.binary. See for example [client.py](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/client.py) for usage of the new API.,longer use see example usage new,issue,negative,positive,positive,positive,positive,positive
632191391,"Conda causes all kinds of weird things for native code (and Python code too lots of the time), which breaks our packages. We document and support only virtualenv and venv.",weird native code python code lot time document support,issue,negative,negative,negative,negative,negative,negative
631321172,"
1. deepspeech --model deepspeech-0.7.0-models.tflite --audio /data/local/test_data/3.wav
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
alexa

2. both 2.wav and 3.wav at below location
https://drive.google.com/drive/folders/1oYwmXVswgJUpfZDHu8r1GDJmSUjaMkfB?usp=sharing",model audio lite location,issue,negative,neutral,neutral,neutral,neutral,neutral
631319804,"Questions...

1. What is the output of 
> `deepspeech --model deepspeech-0.7.0-models.tflite --audio /data/local/test_data/3.wav`
2. Can you share 3.wav",output model audio share,issue,negative,neutral,neutral,neutral,neutral,neutral
631308363,"Please find the results without scorer 

deepspeech --model deepspeech-0.7.0-models.tflite  --json --audio /data/local/test_data/3.wav                                                                                                                      <
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":**1.24544**},""words"":[{""word"":""**alexa**"",""time"":0.76,""duration"":0.38}],
""alternatives"":[
{""metadata"":{""confidence"":**1.51901**},""words"":[{""word"":""**alaxa**"",""time"":0.76,""duration"":0.38}]},
{""metadata"":{""confidence"":**2.47905**},""words"":[{""word"":""**alexsa**"",""time"":0.76,""duration"":0.68}]}
]
}

Here also the alternate words (alexsa) having a better confidence than actual output alexa.",please find without scorer model audio lite confidence word time duration confidence word time duration confidence word time duration also alternate better confidence actual output,issue,positive,positive,positive,positive,positive,positive
631306798,"The crucial fact is that the confidence is computed from the acoustic model alone. In this case, it looks like the LM scoring is causing the seemingly lower confidence result to be returned first. You can remove the post-processing step in `DecoderState::decode` if you want to take a look at the raw scores that were used to sort the list.",crucial fact confidence acoustic model alone case like scoring causing seemingly lower confidence result returned first remove step want take look raw used sort list,issue,positive,positive,neutral,neutral,positive,positive
631303962,"No, its with 3.wav only

deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --json --audio /data/local/test_data/3.wav <
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":-25.784},""words"":[{""word"":""alexa"",""time"":0.76,""duration"":0.36}],
""alternatives"":[
{""metadata"":{""confidence"":-11.6792},""words"":[{""word"":""alex"",""time"":0.76,""duration"":0.32}]},
{""metadata"":{""confidence"":-10.141},""words"":[{""word"":""alec"",""time"":0.76,""duration"":0.3}]}
]
}

Here the actual output which is 'alexa' is having confidence value of -25.784, but the words which are in the alternatives like 'alex' having confidence -11.6792, in-fact which is better then the actual output(alexa) confidence(-25.784) value. ",model scorer audio lite confidence word time duration confidence word time duration confidence word alec time duration actual output confidence value like confidence better actual output confidence value,issue,positive,positive,positive,positive,positive,positive
631298833,"But only one confusion here is that, if I run the above command without --json option. 
deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer  --audio /data/local/test_data/3.wav                                                                                     <
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
alexa

I get the output 'alexa' and it is correct also, but 'alex' is having a better confidence ('-10.7203') value than alexa.  ",one confusion run command without option model scorer audio lite get output correct also better confidence value,issue,positive,positive,positive,positive,positive,positive
631289058,"In that case, in the above example,   
{
""metadata"":{""confidence"":-25.3747},""words"":[{""word"":""alexa"",""time"":0.78,""duration"":0.28}],
""alternatives"":[
{""metadata"":{""confidence"":-10.7203},""words"":[{""word"":""alex"",""time"":0.78,""duration"":0.24}]},
{""metadata"":{""confidence"":-24.7374},""words"":[{""word"":""alaka"",""time"":0.78,""duration"":0.3}]}
]
}
word 'alexa' is having confidence of -25.3747, but for the alternative options like 'alex' which is having confidence value of '-10.7203'. Since both are negative values, alex is having a better confidence right ?",case example confidence word time duration confidence word time duration confidence word time duration word confidence alternative like confidence value since negative better confidence right,issue,positive,positive,positive,positive,positive,positive
631285681,"This is expected. Confidence for a word corresponds to ""roughly the sum of the acoustic model logit values for each timestep/character that contributed to the creation of"" the word.

See, for example, the [confidence documentation](https://github.com/mozilla/DeepSpeech/blob/430132c5a50f79c8cb28851e94963f8e10926d17/native_client/deepspeech.h#L45) in deepspeech.h",confidence word roughly sum acoustic model creation word see example confidence documentation,issue,positive,negative,neutral,neutral,negative,negative
631147477,"> The whole reason this came up is that I had a customer upload a 3 hour file and submit it for inference. (I think the previous longest file was around 2 hours, which worked fine.) Normally I get around 3x realtime performance but in this case it's been more than 3 hours and it's still running inference. So I'm getting sub-realtime performance on longer files, and when I looked in `top -H` it wasn't doing a great deal (after I posted this two other cores got to around 20% but still nowhere near what my system is capable of).

Even more reason to carefully analyze: if you had 3x realtime performance and this one is much slower, there might be something else that explains and your problem might become much more non trivial than ""divide and conquer"".",whole reason came customer hour file submit inference think previous file around worked fine normally get around performance case still running inference getting performance longer top great deal posted two got around still nowhere near system capable even reason carefully analyze performance one much might something else problem might become much non trivial divide conquer,issue,negative,positive,positive,positive,positive,positive
631100585,"This is what transcribe.py does. We don't have any immediate plans of doing that in the native client, as it is focused on low latency (live) streaming recognition, and you're asking for high throughput batch recognition.

In terms of technical feasibility I guess there could be a check when a long enough audio buffer is provided, which enables a separate throughput optimized path.",immediate native client low latency live streaming recognition high throughput batch recognition technical feasibility guess could check long enough audio buffer provided separate throughput path,issue,negative,positive,neutral,neutral,positive,positive
631092431,"> Threading is already handled by tensorflow.

That's different though. Tensorflow is trying to thread processing of the model (as much as that can be parallelized) but is still processing the audio sequentially. What I'm talking about is splitting up the audio into segments (say 30 secs each in length) prior to processing and then running inference on each segment independently in parallel. This would likely not be worth the setup performance hit on short files but could have a big impact on files of a longer duration.

The whole reason this came up is that I had a customer upload a 3 hour file and submit it for inference. (I think the previous longest file was around 2 hours, which worked fine.) Normally I get around 3x realtime performance but in this case it's been more than 3 hours and it's still running inference. So I'm getting sub-realtime performance on longer files, and when I looked in `top -H` it wasn't doing a great deal (after I posted this two other cores got to around 20% but still nowhere near what my system is capable of).

But I understand that not every use case is the same and not everyone needs to transcribe massive files. I've just been calling the command-line version of DeepSpeech from my app for simplicity of installation, but maybe I've outgrown it now and need to use the API directly.",already handled different though trying thread model much still audio sequentially talking splitting audio say length prior running inference segment independently parallel would likely worth setup performance hit short could big impact longer duration whole reason came customer hour file submit inference think previous file around worked fine normally get around performance case still running inference getting performance longer top great deal posted two got around still nowhere near system capable understand every use case everyone need transcribe massive calling version simplicity installation maybe need use directly,issue,positive,positive,positive,positive,positive,positive
631064991,"> It looks like the majority of the work gets done in a single thread and most of the other threads are idle.

Please profile with perf and time : each time we verified there was a linear speedup in the number of threads until reaching the number of cores available, i.e., tensorflow threading was already doing its best usage of the ressources, and spawning more parallel threads would not help in the long run but put more pressure on the system. ",like majority work done single thread idle please profile time time linear number reaching number available already best usage spawning parallel would help long run put pressure system,issue,positive,positive,positive,positive,positive,positive
631063204,"> splitting up the audio file into sections and transcribing them in parallel (obviously this would only work with pre-recorded clips and not live streaming).

Doing that at timestep level might work but I fear the setup costs would kill the win",splitting audio file parallel obviously would work clip live streaming level might work fear setup would kill win,issue,negative,positive,positive,positive,positive,positive
631061871,"Threading is already handled by tensorflow. Adding our own layer will likely add issues : this is already the case with tflite threading on r2.2. I'm unsure about the use case you describe: if you have pre-recorded data you need to run in volume, the API is maybe not the best way and relying on evaluate.py will yield much better results. ",already handled layer likely add already case unsure use case describe data need run volume maybe best way yield much better,issue,positive,positive,positive,positive,positive,positive
630966004,"> @DanBmh Unfortunately yes. Due to the massive amount of data that we plan to use for overlaying, things had to be tighter integrated with sample reading facilities in `util/sample_collections.py`. Also some of the augmentations would've been hard to realize on the TensorFlow side of things. Sorry for this decision!

Maybe you could have informed us earlier, but I'm glad this feature is now in the master branch:) And you also did add some other interesting augmentations.

Do you plan to use the noise augmentation for the next checkpoint release already?",unfortunately yes due massive amount data plan use sample reading also would hard realize side sorry decision maybe could informed u glad feature master branch also add interesting plan use noise augmentation next release already,issue,positive,negative,neutral,neutral,negative,negative
630775925,"@imskr sorry, I completely forgot about this issue and just did the uplift myself during the 0.7.0 release :(",sorry completely forgot issue uplift release,issue,negative,negative,negative,negative,negative,negative
630773144,"I somehow added a dupe of this in #2961, and there's been some movement there so closing this one.",somehow added dupe movement one,issue,negative,neutral,neutral,neutral,neutral,neutral
630771905,"DeepSpeech side task added in #2999.
Initial changes added to scriptworker here: https://github.com/mozilla/deepspeech-pkguploadworker/compare/1e4ef28e463cd17f5298278d445020a78f2864af...ad10a9019f2e45751da419290c9dd16546c9f7a1

Need to make some changes to avoid publishing prerelease versions, and double check what happens with the ""latest"" version and whether we really need to trigger builds manually.",side task added initial added need make avoid prerelease double check latest version whether really need trigger manually,issue,negative,positive,positive,positive,positive,positive
630713578,"@DanBmh Unfortunately yes. Due to the massive amount of data that we plan to use for overlaying, things had to be tighter integrated with sample reading facilities in `util/sample_collections.py`. Also some of the augmentations would've been hard to realize on the TensorFlow side of things. Sorry for this decision!",unfortunately yes due massive amount data plan use sample reading also would hard realize side sorry decision,issue,negative,negative,negative,negative,negative,negative
630683968,"Am I right that this is now outdated with @tilmankamp's merged pull request https://github.com/mozilla/DeepSpeech/pull/2897?

The [overlay augmentation docs](https://github.com/mozilla/DeepSpeech/blob/master/doc/TRAINING.rst#audio-augmentation) describe the same mixing features of noise and speech files.",right outdated pull request overlay augmentation describe noise speech,issue,negative,negative,neutral,neutral,negative,negative
630436812,"> Running Deepspeech on a raspberry Pi3b yields following results:
> pi@raspberrypi:./deepspeech --model deepspeech-0.7.1-models.tflite --scorer deepspeech-0.7.1-models.scorer --audio testlastb.wav
> Loading model from file deepspeech-0.7.1-models.tflite
> TensorFlow: v1.15.0-24-gceb46aa
> DeepSpeech: v0.7.1-0-g2e9c281
> Loaded model in 0.0037s.
> Loading scorer from files deepspeech-0.7.1-models.scorer
> Loaded scorer in 0.000744s.
> Running inference.
> back
> Inference took 10.495s for 4.195s audio file.
> 
> Any suggestions on how to reduce inference time?

As documented, we cannot achieve realtime on RPi3 models. Except training your own model with smaller `n_hidden`, there is no solution so far.",running raspberry following pi model scorer audio loading model file loaded model loading scorer loaded scorer running inference back inference took audio file reduce inference time achieve except training model smaller solution far,issue,negative,positive,neutral,neutral,positive,positive
630348360,"I also had to trigger a ""latest"" build to get it to pick up v0.7.1, as it was still showing v0.6.1.",also trigger latest build get pick still showing,issue,negative,positive,positive,positive,positive,positive
630347099,For v0.7.1 I had to manually trigger. Does it take a long time to be picked up?,manually trigger take long time picked,issue,negative,negative,neutral,neutral,negative,negative
630091563,"Please find below the results with 0.7.1 released model and scorer.

/deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --json --audio /data/local/test_data/2.wav                                                                               <
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":-25.3747},""words"":[{""word"":""alexa"",""time"":0.78,""duration"":0.28}],
""alternatives"":[
{""metadata"":{""confidence"":-10.7203},""words"":[{""word"":""alex"",""time"":0.78,""duration"":0.24}]},
{""metadata"":{""confidence"":-24.7374},""words"":[{""word"":""alaka"",""time"":0.78,""duration"":0.3}]}
]
}

/deepspeech --model deepspeech-0.7.0-models.tflite --scorer deepspeech-0.7.0-models.scorer --json --audio /data/local/test_data/3.wav                                                                               <
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=58880
{
""metadata"":{""confidence"":-25.784},""words"":[{""word"":""alexa"",""time"":0.76,""duration"":0.36}],
""alternatives"":[
{""metadata"":{""confidence"":-11.6792},""words"":[{""word"":""alex"",""time"":0.76,""duration"":0.32}]},
{""metadata"":{""confidence"":-10.141},""words"":[{""word"":""alec"",""time"":0.76,""duration"":0.3}]}
]
}

https://drive.google.com/drive/folders/1oYwmXVswgJUpfZDHu8r1GDJmSUjaMkfB?usp=sharing

It seems both the start time and duration is not accurate for both the samples.

",please find model scorer model scorer audio lite confidence word time duration confidence word time duration confidence word time duration model scorer audio lite confidence word time duration confidence word time duration confidence word alec time duration start time duration accurate,issue,positive,positive,positive,positive,positive,positive
630041126,"> **Python version**: Python 3.6.3

Can you verify it is 64-bits version of Python?",python version python verify version python,issue,negative,neutral,neutral,neutral,neutral,neutral
630026310,"I think we won't necessarily need it for the 0.8 cycle, but it's good to exercise this before 1.0 to give time to correct anything.",think wo necessarily need cycle good exercise give time correct anything,issue,negative,positive,positive,positive,positive,positive
630024463,"Got it.

Would this be something we should do for 0.8.0, where we will not offer long term support, or something we should do for 1.0.0, where we would offer long term support.",got would something offer long term support something would offer long term support,issue,positive,negative,neutral,neutral,negative,negative
630023093,"It's now disconnected from the docs issue and would not involve changing the GitHub default branch. The goal would be to get better release management capabilities out of it, like being able to do a 0.8.x release after the first 0.9 alpha.",disconnected issue would involve default branch goal would get better release management like able release first alpha,issue,positive,positive,positive,positive,positive,positive
629387186,"Hmm.

Looks like the only other calls are train.py:643, evaluate.py:143, and lm_optimizer.py:36. All of those look like they don't rely on the overwriting and the only one which breaks as a result of the overwriting is lm_optimizer.py:36.

So you're change looks good.",like look like rely one result change good,issue,positive,positive,positive,positive,positive,positive
629386519,"Yes, I've checked it. Everywhere else as argument `FLAGS.test_files.split(',')` was given, so the bug was hidden. Other case is only in lm_optimizer.py, where this fix corrects the pruner behaviour.",yes checked everywhere else argument given bug hidden case fix pruner behaviour,issue,negative,negative,negative,negative,negative,negative
629384491,Have you checked all other calls to evaluate() to make sure they don't rely on this overwriting?,checked evaluate make sure rely,issue,negative,positive,positive,positive,positive,positive
629377793,"The variable is used on the next line, that's fine.

But the function argument has the same variable name and is overwritten.
This leads to problems in lm_optimizer.py where each time all test_csvs are used, because given argument is ignored.",variable used next line fine function argument variable name time used given argument,issue,negative,positive,positive,positive,positive,positive
629353380,"Sure, sorry for the delay, been occupied with chasing other leads.
Will do this in the next week.

On Fri, May 15, 2020 at 3:40 AM lissyx <notifications@github.com> wrote:

> Please @khu834 <https://github.com/khu834> ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2967#issuecomment-629164604>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ACJEOTMTSHMITA7ZW73LUKTRRUL2RANCNFSM4MWZUONQ>
> .
>
",sure sorry delay chasing next week may wrote please khu reply directly view,issue,negative,positive,neutral,neutral,positive,positive
628217282,So does this now work with the new scorer? I am looking for the same feature too.,work new scorer looking feature,issue,negative,positive,positive,positive,positive,positive
627989199,"Please provide the correct document link.
I am using 0.7.0 version.",please provide correct document link version,issue,negative,neutral,neutral,neutral,neutral,neutral
627946584,"You're reading the wrong docs for the version of the code you're using. If you're using v0.7.1, read the v0.7.1 docs.",reading wrong version code read,issue,negative,negative,negative,negative,negative,negative
627915152,I think the issue can be closed now that the AUR package has been updated,think issue closed package,issue,negative,negative,neutral,neutral,negative,negative
627898600,"You were right! I deleted my .gitconfig file and re-cloned both mozilla/DeepSpeech and mozilla/tensorflow; after that the ./configure command worked and the bazel build command succeeded without error.
Thank you so much!",right file command worked build command without error thank much,issue,negative,positive,positive,positive,positive,positive
627336327,"> I get `env: bash\r: No such file or directory`

Hm. The `\r` in this message, plus the `?` symbols in the patch apply error message, plus the fact that the error is a patch failing to apply, seems to indicate there's something wrong with your Git config where it's writing bad newlines in the files it checks out. You should check if your git config doesn't include any bad newline settings.",get file directory message plus patch apply error message plus fact error patch failing apply indicate something wrong git writing bad check git include bad,issue,negative,negative,negative,negative,negative,negative
627300048,"1. Yes I am sure, after the ""uninstall"" step (first line) bazel is not installed anymore, so runnning a bazel command returns `zsh: command not found: bazel`. After the installation, `bazel version` returns: 
```
Build label: 0.24.1
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Apr 2 16:32:47 2019 (1554222767)
Build timestamp: 1554222767
Build timestamp as int: 1554222767
```

As for the configure script, I get another weird bug. When running `./configure`, I get `env: bash\r: No such file or directory`, even though the file is in the directory (shows up in ls). As a workaround, I just ran `python configure.py`, which works just fine and the configure script doesn't seem to be doing anything else either. But the error when running the bazel command still does not change. 

I don't know how to clean the cache bazel uses.. Apparently removing the ~/.cache/bazel directory did not do the trick, neither does specifying `--repository_cache=""""` when running the command, though I don't know what exactly that option does. It just says in the documentary ""An empty string as argument requests the cache to be disabled."" However, the info message about the protobuf cache hit still appears.",yes sure step first line command command found installation version build label build target build time tue build build configure script get another weird bug running get file directory even though file directory ran python work fine configure script seem anything else either error running command still change know clean cache apparently removing directory trick neither running command though know exactly option documentary empty string argument cache disabled however message cache hit still,issue,negative,positive,positive,positive,positive,positive
627220892,"Also you forgot the configure step. For libdeepspeech alone I don't think it makes any difference but to be safe, do that.",also forgot configure step alone think difference safe,issue,negative,positive,positive,positive,positive,positive
627220631,"1. Are you sure you're running the bazel you installed and not a different copy of it that's on the system?
2. I run that same command, also on macOS 10.15, and it works fine, so whatever it is, it's on your side.

Note the message about there being a cache hit for the protobuf package, indicating you're not properly cleaning the (correct) cache.",sure running different copy system run command also work fine whatever side note message cache hit package properly cleaning correct cache,issue,negative,positive,positive,positive,positive,positive
627197499,"I don't really know what else to try.. 
I ran the following script:

```
rm -fr ~/.bazel ~/.bazelrc ~/.cache/bazel    # Uninstall bazel

# Install bazel
curl -LO https://github.com/bazelbuild/bazel/releases/download/0.24.1/bazel-0.24.1-installer-darwin-x86_64.sh
chmod +x bazel-0.24.1-installer-darwin-x86_64.sh
./bazel-0.24.1-installer-darwin-x86_64.sh --user
rm bazel-0.24.1-installer-darwin-x86_64.sh

# Clone tensorflow
git clone https://github.com/mozilla/tensorflow.git
cd tensorflow
git checkout origin/r1.15

bazel clean --expunge    # Whether or not I run this command, nothing changes

# Build libdeepspeech
ln -s ../DeepSpeech/native_client ./
bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so
```

And I get the error message above.. ",really know else try ran following script install curl user clone git clone git clean expunge whether run command nothing build build bash opt get error message,issue,negative,positive,positive,positive,positive,positive
627090959,"> I was not using a server. `http-server` resolved the issue

I'm having the same issue. Could you elaborate on how that fixed it?",server resolved issue issue could elaborate fixed,issue,negative,positive,positive,positive,positive,positive
626686899,"Also, this would be a good opportunity to refactor the training code a bit and make it more reusable so that logic like this can be implemented as an orchestration of existing functions rather than hardcoded into the training loop. For example if individual training steps and epochs are simple enough to set up and call from an external, simpler training script, the script can contain all of the schedule parsing logic, instead of it being spread throughout the code.",also would good opportunity training code bit make logic like orchestration rather training loop example individual training simple enough set call external simpler training script script contain schedule logic instead spread throughout code,issue,positive,positive,positive,positive,positive,positive
626685390,"Someone said they were interested in contributing a LR scheduler a while ago, I don't remember who it was though :/",someone said interested ago remember though,issue,negative,positive,positive,positive,positive,positive
626445213,"> This tutorial is old. Please read the documentation, everything is explained. Please search on discourse, à lot of other people trained for mandarin and other languages.

hi Lissyx:
Could you please point out what introduction do you suggest me to look at? I checked your doc:
https://deepspeech.readthedocs.io/en/v0.7.0/TRAINING.html, but I do not know how to generate alphabet.txt and how to train language model, so maybe could you please give one introduction step by step?

Thanks",tutorial old please read documentation everything please search discourse lot people trained mandarin hi could please point introduction suggest look checked doc know generate train language model maybe could please give one introduction step step thanks,issue,positive,positive,positive,positive,positive,positive
626397055,@reuben nevermind then. I though you were still fighting with the conversion. Your approach sounds correct.,though still fighting conversion approach correct,issue,negative,neutral,neutral,neutral,neutral,neutral
626319628,"This tutorial is old. Please read the documentation, everything is explained. Please search on discourse, à lot of other people trained for mandarin and other languages. ",tutorial old please read documentation everything please search discourse lot people trained mandarin,issue,positive,positive,neutral,neutral,positive,positive
626245217,"> Hi, @lissyx
> Sorry to disturb you. Will remove my comment after you see it to keep comment section clean.
> 
>     1. Will this be out soon(maybe 0.7.x)?
I hope it will be out soon, but it triggers weird behavior on CI under ARMv7 / NodeJS > 10 that are not yet understood, and I'm very busy with that and other things.

Will not be 0.7 for sure, this is a too big change for this.

> 
>     2. I see that you add `//tensorflow/core:rnn_ops_op_lib"",  # BlockLSTM`. Could you add `//tensorflow/core:cudnn_rnn_ops_op_lib"",  # cudnnLSTM` as well? Since it will allow user to train with cudnn and cudnnLSTM has more functions than BlockLSTM like dropout and num_proj.
> 

CuDNN training is already possible, and we already use BlockLSTM for a long time if you had a look at the code and the documentation.
Anyway, the code here is only to run inference, not for training.

> 
> Thanks!

You're welcome. Please be patient, though.",hi sorry disturb remove comment see keep comment section clean soon maybe hope soon weird behavior yet understood busy sure big change see add could add well since allow user train like dropout training already possible already use long time look code documentation anyway code run inference training thanks welcome please patient though,issue,positive,positive,neutral,neutral,positive,positive
626118604,I think you're misunderstanding how the KWS/VAD functionality would work here. There is no multi-threading. The threading implications are the same as with current DeepSpeech: users must make sure the inference calls don't block any other critical threads like a UI thread or the microphone recording thread.,think misunderstanding functionality would work current must make sure inference block critical like thread microphone recording thread,issue,negative,positive,positive,positive,positive,positive
626117769,"All the audio files we commonly work with have a header that I think Riff is a common container as compression is just on top of that.
I was just thinking like some proprietory camera/av stuff they use a cue naming scheme and the cue chunk of the header.
That there is no connection or requirement to VAD or KWS just that VAD KWS leaves a cue of activity.

As said when it comes to PCM streams it sort of doesn't work as there isn't a chunk or header as there is no file.

I dunno to be honest as trying to image how it will work purely from reading but for many instances Deepspeech is single thread because of the GPU or accelerator they use.

So you have a multithread KWS VAD queue feeding a single thread instance and what you wrote sounded like it could be very complex.

Linux is just files so to keep it simple have a cue file for each input as often these are going to be queued?
I was just thinking VAD and KWS prob will be working with realtime streams but deepspeech will be a naive single thread due to the hardware used with it?

I have no idea and bow to you wonderful work and knowledge but just thought an accompanying cue file might be needed as KWS/VAD are likely not to be in sync with what is being processed?
My complete lack of knowledge and fear of a asynchronous callback based API's ducked under the cover of a simple file base.",audio commonly work header think riff common container compression top thinking like proprietory stuff use cue naming scheme cue chunk header connection requirement leaf cue activity said come sort work chunk header file honest trying image work purely reading many single thread accelerator use queue feeding single thread instance wrote like could complex keep simple cue file input often going thinking prob working naive single thread due hardware used idea bow wonderful work knowledge thought cue file might likely sync complete lack knowledge fear asynchronous based cover simple file base,issue,positive,positive,neutral,neutral,positive,positive
625957087,"It can be tricky to understand all the ways bazel does cashing, so instead of deleting folders by hand try running bazel clean --expunge.


> Am 08.05.2020 um 19:36 schrieb Onno Eberhard <notifications@github.com>:
> 
> ﻿
> Yes I am on the r1.15 branch. I tried removing bazel using rm -fr ~/.bazel ~/.bazelrc ~/.cache/bazel and reinstalling it but the error remains the same..
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",tricky understand way instead hand try running clean expunge um yes branch tried removing error remains thread reply directly view,issue,positive,positive,positive,positive,positive,positive
625943357,@StuartIanNaylor I don't understand. What even is a chunk in this context?,understand even chunk context,issue,negative,neutral,neutral,neutral,neutral,neutral
625931471,Yes I am on the r1.15 branch. I tried removing bazel using `rm -fr ~/.bazel ~/.bazelrc ~/.cache/bazel` and reinstalling it but the error remains the same..,yes branch tried removing error remains,issue,negative,neutral,neutral,neutral,neutral,neutral
625785229,"It seems it fails to apply a patch. I have no idea why and it looks more tensorflow level than DeepSpeech. Make sure you are on our r1.15 branch and not upstream one, but 0.24.1 should work. Try purging bazel cache as well? ",apply patch idea level make sure branch upstream one work try purging cache well,issue,positive,positive,positive,positive,positive,positive
625754025,"@fotiDim I have no idea what you're talking about. If you're replying to my latest message, I understand even less. The model is already converted, see above. I'm talking about the surrounding code that needs to use the CoreML API to perform inference, as well as computing features, managing inputs, outputs, LSTM hidden state, etc. Using the TFLite CoreML delegate would be a way to circumvent all of this work, by reusing our TFLite code.",idea talking latest message understand even le model already converted see talking surrounding code need use perform inference well hidden state delegate would way circumvent work code,issue,negative,positive,positive,positive,positive,positive
625728266,"@reuben I don't believe that there is a way to write a CoreML implementation from scratch. A CoreML model is meant to be the product of conversion of a model from another framework.

Also Core ML Tools which is the conversion tool from Apple expects a TensorFlow model and not TFLite as input. Then you can convert a TensorFlow to CoreML directly.

The above is at least one path. The other path would be to convert the TensorFlow model to TFLite and then use the Firebase library (I believe MLKit is what is needed) to deploy it on device to do the inference.",believe way write implementation scratch model meant product conversion model another framework also core conversion tool apple model input convert directly least one path path would convert model use library believe deploy device inference,issue,negative,negative,negative,negative,negative,negative
625699682,"@reuben prob a very dumb coment but can you not expect dynamic Cue-Points Chunk that VAD & KWS should create?
You can to a file but don't know if you can dynamically to a open stream.


",prob dumb expect dynamic chunk create file know dynamically open stream,issue,negative,negative,negative,negative,negative,negative
625551566,"@reuben Once we can get r2.2 this will get even more interesting since we could enable CoreML and Hexagon delegation. No idea of a potential speedup obviously, but I'm wondering how much of that should be exposed to the API ?",get get even interesting since could enable hexagon delegation idea potential obviously wondering much exposed,issue,negative,positive,positive,positive,positive,positive
625197004,"@imskr cool! We have some unit tests in the `tests` folder, runnable with `python -m unittest` with the training package properly installed. Currently, they are being run in Travis: https://github.com/mozilla/DeepSpeech/blob/9a7ec1ae0d55db4de1ac6ac4d43c4e11478b9610/.travis.yml#L20-L27

The problem is that when installing the training package, it depends on downloading a pre-built decoder package from TaskCluster, matching the current version in the `VERSION` file. When we bump the version, `setup.py` tries to install the pre-built package, but it doesn't exist yet, because it's a new version that hasn't been built.

The fix for this is to move the unit tests execution into a TaskCluster task, which depends on the task that builds the decoder package, and so will only run after it's available. This can be done by adapting the existing training tests. See for example [taskcluster/test-training_16k-linux-amd64-py37m-opt.yml](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/test-training_16k-linux-amd64-py37m-opt.yml).

You should be able to copy the `test-training*` tasks into similar `test-training-unittests*` tasks, that instead of running `tc-train-tests.sh`, run `tc-train-unittests.sh`. You can then adapt the logic from the existing `tc-train-tests.sh` into `tc-train-unittests.sh` by copying its [initial setup part](https://github.com/mozilla/DeepSpeech/blob/9a7ec1ae0d55db4de1ac6ac4d43c4e11478b9610/taskcluster/tc-train-tests.sh#L1-L22) and then calling `python -m unittest`.

I'll give you write access so you can trigger TaskCluster tasks to test this when you make a PR.",cool unit folder runnable python training package properly currently run travis problem training package package matching current version version file bump version install package exist yet new version built fix move unit execution task task package run available done training see example able copy similar instead running run adapt logic initial setup part calling python give write access trigger test make,issue,negative,positive,positive,positive,positive,positive
624772865,"> I cherry picked your commit and added tests, pushed as #2981 (tests only run in PRs created by people with write access).

Awesome, thanks for resolving; 0.7 is looking good.",cherry picked commit added run people write access awesome thanks looking good,issue,positive,positive,positive,positive,positive,positive
624557409,"I cherry picked your commit and added tests, pushed as #2981 (tests only run in PRs created by people with write access).",cherry picked commit added run people write access,issue,negative,neutral,neutral,neutral,neutral,neutral
624348719,Thanks! I'll add a test case that exercises this code path and merge this PR tomorrow.,thanks add test case code path merge tomorrow,issue,negative,positive,positive,positive,positive,positive
624146234,We've moved more things into ReadTheDocs which has the latest stable release as default homepage: #2949,latest stable release default,issue,negative,positive,positive,positive,positive,positive
624127372,"> Maybe I'm interpreting this message incorrectly.
> [#2403 (comment)](https://github.com/mozilla/DeepSpeech/issues/2403#issuecomment-544085038)
> 
> It says fixed for .Net client, but ""looks like the C++ client is not releasing completely"".
> Can you confirm that it is fixed for the python client? As far as that thread was concerned?
> 
> What I'm seeing may just be a side-effect of python garbage collector still keeping some allocation.
> If the other thread is fixed for python client, then we can close this one. I don't have strong evidence that it is from deepspeech and not just the behavior from python.

I've linked you the valgrind proof. Please, try to reproduce on current 0.7.1 alpha.",maybe message incorrectly comment fixed client like client completely confirm fixed python client far thread concerned seeing may python garbage collector still keeping allocation thread fixed python client close one strong evidence behavior python linked proof please try reproduce current alpha,issue,positive,positive,positive,positive,positive,positive
624090706,"Just exporting is fine. Have you tried it?

Also please use Discourse for discussion.

> Am 05.05.2020 um 12:40 schrieb Rohith Krishnan <notifications@github.com>:
> 
> ﻿
> @reuben I have one more doubt could you please help.
> I have continued training of en_US model file using some of my voice files and i wanted to use the newly trained model in my android application . Whether i need to only export the tflite file and use it in the android application or is there is any additional files or steps i need to execute for the same.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",fine tried also please use discourse discussion um one doubt could please help continued training model file voice use newly trained model android application whether need export file use android application additional need execute reply directly view,issue,positive,positive,positive,positive,positive,positive
623988993,">     * **OS Platform and Distribution (e.g., Linux Ubuntu 18.04)**:
> 
> 
> This URL says no resource found:
> https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.7.0.cpu-ctc/artifacts/public/ds_ctcdecoder-0.7.0-cp37-cp37m-manylinux1_x86_64.whl'

This URL works fine.

> 
> where do I get the package?
> running python setup.py install gives me this error
> I want to make my custom scorer using generate_package.py

This is not a bug, for the third time, use Discourse to reach support.",o platform distribution resource found work fine get package running python install error want make custom scorer bug third time use discourse reach support,issue,negative,positive,positive,positive,positive,positive
623987331,"> This URL says no resource found:
> https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.7.0.cpu-ctc/artifacts/public/ds_ctcdecoder-0.7.0-cp37-cp37m-manylinux1_x86_64.whl'
> 
> where do I get the package?

This URL works fine for me.

> running python setup.py install gives me this error
> I want to make my custom scorer using generate_package.py

This is not a bug, use Discourse.",resource found get package work fine running python install error want make custom scorer bug use discourse,issue,negative,positive,positive,positive,positive,positive
623986530,"This URL says no resource found:
https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.7.0.cpu-ctc/artifacts/public/ds_ctcdecoder-0.7.0-cp37-cp37m-manylinux1_x86_64.whl'

where do I get the package?
running python setup.py install gives me this error
I want to make my custom scorer using generate_package.py",resource found get package running python install error want make custom scorer,issue,negative,neutral,neutral,neutral,neutral,neutral
623986190,"@krutika23 Use Discourse for support, and please share more details.",use discourse support please share,issue,positive,neutral,neutral,neutral,neutral,neutral
623980328,"@kdavis-mozilla @reuben I have one more doubt could you please help.
I have continued training of en_US model file using some of my voice files and i wanted to use the newly trained model in my android application . Whether i need to only export the tflite file and use it in the android application or is there is any additional files or steps i need to execute for the same.

And whether https://github.com/mozilla/DeepSpeech-examples/tree/r0.7/android_mic_streaming this example support offline processing of voice . Because i have using a sample https://github.com/mozilla/androidspeech which support offline processing.

",one doubt could please help continued training model file voice use newly trained model android application whether need export file use android application additional need execute whether example support voice sample support,issue,positive,positive,positive,positive,positive,positive
623973459,"> And i have one doubt whether we need to do the above steps

Only if you made changes to the code. We have a pre-built AAR that you can simply add as a dependency to your Android app, for example: https://github.com/mozilla/DeepSpeech-examples/blob/695f69bf6e5362428954c0706d32fe517153095d/android_mic_streaming/app/build.gradle#L37

See also the rest of that example: https://github.com/mozilla/DeepSpeech-examples/tree/r0.7/android_mic_streaming

The error you got is due to missing libraries. They should be installed as dependencies of libsox-dev.",one doubt whether need made code simply add dependency android example see also rest example error got due missing,issue,negative,negative,negative,negative,negative,negative
623972116,"> Did the TensorFlow ./configure step complete without error?

@kdavis-mozilla Yes it is done properly and also the **bazel build** is also completed properly.
Error is when executing the **make deepspeech**.

And i have one doubt whether we need to do the above steps ( Compiling DeepSpeech) if i want to build the DeepSpeech for Android Devices (https://github.com/mozilla/DeepSpeech/blob/v0.7.0/native_client/README.rst#android-devices)",step complete without error yes done properly also build also properly error make one doubt whether need want build android,issue,negative,positive,neutral,neutral,positive,positive
623919178,Did the TensorFlow ./configure step complete without error?,step complete without error,issue,negative,positive,neutral,neutral,positive,positive
622982843,"Maybe I'm interpreting this message incorrectly.
https://github.com/mozilla/DeepSpeech/issues/2403#issuecomment-544085038

It says fixed for .Net client, but ""looks like the C++ client is not releasing completely"".
Can you confirm that it is fixed for the python client? As far as that thread was concerned?

What I'm seeing may just be a side-effect of python garbage collector still keeping some allocation.
If the other thread is fixed for python client, then we can close this one. I don't have strong evidence that it is from deepspeech and not just the behavior from python.
",maybe message incorrectly fixed client like client completely confirm fixed python client far thread concerned seeing may python garbage collector still keeping allocation thread fixed python client close one strong evidence behavior python,issue,positive,positive,positive,positive,positive,positive
622929590,"The linked thread was fixed, I don't think it's related to what you're seeing.",linked thread fixed think related seeing,issue,negative,positive,neutral,neutral,positive,positive
622667161,"I'll spend some time to get 0.7.0 running.
Any reference as to how this issue is fixed between 0.6.0 and 0.7.0?
The thread above indicates that this was an issue at least as of early 0.6.0-alpha",spend time get running reference issue fixed thread issue least early,issue,negative,negative,neutral,neutral,negative,negative
622557597,"Yes I did try calling `__del__()` directly, the result is the same.",yes try calling directly result,issue,negative,positive,neutral,neutral,positive,positive
622315795,"ok `client.cc` calls `DS_createModel`, that initialises a model with `TFModelState` input. So, while running the model in `tfjs`, the input (say, `X`) to `model.predict` should be of the form defined in `TFModelState`. Is that correct? 

If yes, I have anther question: 
I was passing an audio file through `mode.predict` which obviously is not of the form `X`. Why did it mean that I need to convert the `TFModelState` to `tfjs` (as you stated earlier in the thread)? Shouldn't it just mean that the audio file that I am passing should be converted to the form `X` 


The [train.py](https://github.com/mozilla/DeepSpeech/blob/master/training/deepspeech_training/train.py#L661) (create_inference_graph) has already defined what the `X` format mean. Why was my input not directly converted into that format? The `create_inference_graph` is not converted to tfjs through `tfjs_coverter`, is it? So basically i need to write code in tfjs to convert this input to form `X`?

And how would i convey in the tfjs code that model.predict would mean Session::Run() equivalent-of-tfjs.
PS: I can take this to the discourse forum, if this is not the right place to discuss this here.  ",model input running model input say form defined correct yes anther question passing audio file obviously form mean need convert stated thread mean audio file passing converted form already defined format mean input directly converted format converted basically need write code convert input form would convey code would mean session take discourse forum right place discus,issue,negative,negative,negative,negative,negative,negative
622307197,"There's nothing set anywhere, they're not connected in any way other than semantically, because they perform equivalent actions (running a TensorFlow graph).",nothing set anywhere connected way semantically perform equivalent running graph,issue,negative,neutral,neutral,neutral,neutral,neutral
622306752,where did we set this in the code that calling `model.predict` should be equivalent to calling `Session::Run()`?,set code calling equivalent calling session,issue,negative,neutral,neutral,neutral,neutral,neutral
622304972,"`model.predict` is not literally calling that code, it's equivalent to it. Calling `model.predict` is equivalent to calling `Session::Run()` with the C++ TensorFlow API.",literally calling code equivalent calling equivalent calling session,issue,negative,neutral,neutral,neutral,neutral,neutral
622296603,Does the problem go away if you call `model.__del__()` directly? Maybe we should expose the destructor explicitly instead of only relying on Python GC.,problem go away call directly maybe expose destructor explicitly instead python,issue,negative,positive,neutral,neutral,positive,positive
622243542,"hi @alexcannan I was looking at the tfjs `model.predict` code 
I couldn't understand where does `model.predict` get that it has to look into `tfModelState` file? 

deepspeech.cc calls the [tfModelState](https://github.com/mozilla/DeepSpeech/blob/master/native_client/deepspeech.cc#L287); and BUILD file has [deepspeech.cc](https://github.com/mozilla/DeepSpeech/blob/master/native_client/BUILD#L94) and [tfModelState](https://github.com/mozilla/DeepSpeech/blob/master/native_client/BUILD#L108) as well.
So, which part of the code above tells the model.predict to point to session_->run in tfModelState.

Could you point me to some resource that will help me understand the inference code flow - sequence of code blocks that are called start to end during inference. Thanks",hi looking code could understand get look file build file well part code point run could point resource help understand inference code flow sequence code start end inference thanks,issue,positive,positive,positive,positive,positive,positive
621825954,"According to NVIDIA, checkpoints with automatic mixed precision enabled are not compatible with checkpoints without it. Same for the other way around. Because we don't use automatic mixed precision training for our runs, you can't load our checkpoint and enable it, you'll have to use it only for training from scratch, or with a checkpoint that already had it.",according automatic mixed precision compatible without way around use automatic mixed precision training ca load enable use training scratch already,issue,negative,neutral,neutral,neutral,neutral,neutral
621679644,"As this doesn't appear to be a bug or feature request, what we reserve issues for, could you move this discussion to [discourse](https://discourse.mozilla.org/c/deep-speech/247).

As to your problem, there are many unknowns about the audio, e.g. what processing adjust_for_ambient_noise() applies, that will effect the result and need to be dealt with. So [discourse](https://discourse.mozilla.org/c/deep-speech/247) is the better form to discuss these.",appear bug feature request reserve could move discussion discourse problem many audio effect result need dealt discourse better form discus,issue,negative,positive,positive,positive,positive,positive
621669612,"@salman03444 This would be best addressed on [discourse](https://discourse.mozilla.org/c/deep-speech/247), but the core thing you might want to explore is the new [transfer learning support](https://deepspeech.readthedocs.io/en/v0.7.0/TRAINING.html#transfer-learning-new-alphabet) added in 0.7.0.",would best discourse core thing might want explore new transfer learning support added,issue,positive,positive,positive,positive,positive,positive
621197106,"@MittalShruti TensorFlow.JS is an alternative backend, similar to TFModelState and TFLiteModelState in the native client code. This means one has to reimplement the entire inference logic to be able to use the TF.JS converted model. You're not going to magically get the the DeepSpeech API from just converting the model, it needs to be implemented in JS (or compiled/transpiled, I guess).",alternative similar native client code one entire inference logic able use converted model going magically get converting model need guess,issue,negative,positive,positive,positive,positive,positive
621136172,"@alexcannan 
I am a bit confused as to why are you using `model.predict` to get the transcription. I looked at `evaluate tflite.py` code, it has `ds.stt(audio)` to transcribe an audio. Similarly, the `client.js` file
How did you figure out that you need to call `model.predict` and what should be its parameters?

`console.log(model.executor.inputs)` outputs 4 parameters that can be found in the `tfmodelstate.cc` file. But I am unable to figure out a connection between tfmodelstate and model.predict



",bit confused get transcription evaluate code audio transcribe audio similarly file figure need call found file unable figure connection,issue,negative,negative,negative,negative,negative,negative
620866291,@MittalShruti I would try and just use the tf.loadGraphModel() method from the main tfjs package instead of whatever that tfjs-converter import is. I'm able to import the model using TFJS 1.7.3.,would try use method main package instead whatever import able import model,issue,negative,positive,positive,positive,positive,positive
620847175,Huge thanks @reuben! I'll go ahead and close this.,huge thanks go ahead close,issue,positive,positive,positive,positive,positive,positive
620815592,"A function in the core API needs to be designed for all possible inputs. Then it has to be exposed to Python, Node.JS, Electron, .NET, Java, etc… Then we have to provide support and maintenance.

Personally I'd be fine with contributions to the higher level language bindings to add such a helper, though I'm not sure what the rest of the team thinks. For example adding such a convenience function directly to the Python or Node.JS binding. Or even a snippet to the relevant documentation page.

For all functionality in the core C API, we aim to make it consistently supported on all language bindings and for any valid model, so adding language-specific helper functions makes for an awkward design that we'll have to support for a long time and/or break compatibility if we need to change it.",function core need designed possible exposed python electron provide support maintenance personally fine higher level language add helper though sure rest team example convenience function directly python binding even snippet relevant documentation page functionality core aim make consistently language valid model helper awkward design support long time break compatibility need change,issue,positive,positive,positive,positive,positive,positive
620803508,"@dabinat @kdavis-mozilla my thoughts exactly.
We already use models trained for a specific language and get a transcription, can't we simple match  the characters to the transcribed word and get a time interval?
starting with english will be great.
google has it already and many request it.",exactly already use trained specific language get transcription ca simple match word get time interval starting great already many request,issue,positive,positive,positive,positive,positive,positive
620799922,"@kdavis-mozilla Is there merit in having some kind of helper function in the API to group the timed character output into words? I know it won't work for Chinese, but there are still a lot of languages it would be useful for. Currently everyone needs to roll their own solution, which is a lot of duplicated effort.",merit kind helper function group timed character output know wo work still lot would useful currently everyone need roll solution lot effort,issue,positive,positive,positive,positive,positive,positive
620728081,"It has character level timestamps, see for example [sttWithMetadata()](https://deepspeech.readthedocs.io/en/v0.7.0/Python-API.html#native_client.python.Model.sttWithMetadata) and the  [Metadata](https://deepspeech.readthedocs.io/en/v0.7.0/Python-API.html#native_client.python.Metadata) it returns.

Words are language dependent, e.g. English vs Simplified Chinese, thus we do not ""bake"" word timestamps into the API.",character level see example language dependent simplified thus bake word,issue,negative,neutral,neutral,neutral,neutral,neutral
620644841,"> Not everyone can afford to upgrade to an RPi 4 confused

So, at the time of our previous exchanges, the situation was that the huge matrix/vector multiplications in our model would not be parallelized, because they depends on floats. And turning our model to int using TFLite's quantization tooling was broken from several places.

Things have moved, and I could verify that TensorFlow r2.2 relies on ruy library and that if you compile it properly, you can get TFLite runtime and RUY for those matrix/vector multiplications.
I could verify we now leverage 4 threads on several ARM targets, including RPi3 running Raspbian.

There's still quite some plumbery work, but we should have something available sooner than later now.",everyone afford upgrade confused time previous situation huge model would turning model quantization tooling broken several could verify library compile properly get could verify leverage several arm running still quite plumbery work something available sooner later,issue,negative,negative,neutral,neutral,negative,negative
620633118,"@acabunoc I just landed a pull request slimming down the GitHub README to point people to readthedocs.io, which contains versioned documentation and by default shows docs for the latest stable release. I've also moved the demo section from the README into the readthedocs index page: https://deepspeech.readthedocs.io/en/master/",landed pull request point people documentation default latest stable release also section index page,issue,negative,positive,positive,positive,positive,positive
620631653,"FWIW I figured out a way to do static linking of libsox on macOS, so it should no longer require `brew install sox`, bringing it in line with the other platforms. It's in PR #2951.",figured way static linking longer require brew install line,issue,negative,positive,positive,positive,positive,positive
620629636,"Addressed immediate comments, will work on Java and .NET stuff in follow up PRs.",immediate work stuff follow,issue,negative,neutral,neutral,neutral,neutral,neutral
620601414,"All green. Dependencies from the macOS client now:

```
$ otool -L deepspeech
deepspeech:
	@rpath/libdeepspeech.so (compatibility version 0.0.0, current version 0.0.0)
	/System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio (compatibility version 1.0.0, current version 1.0.0)
	/usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.11)
	/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 400.9.4)
	/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.200.5)
```",green client compatibility version current version compatibility version current version compatibility version current version compatibility version current version compatibility version current version,issue,negative,negative,neutral,neutral,negative,negative
620537579,"Also, the fact that previously it recognized ""visteon,"" and now it is ""mister yarn"" could in itself explain the correct duration value",also fact previously mister yarn could explain correct duration value,issue,negative,negative,negative,negative,negative,negative
620515071,"Exactly, I already have lm and trie for which I am using with 0.6.1 model, will generate scorer for 0.7 and will confirm that, the duration is fine when there is an accurate recognition.",exactly already model generate scorer confirm duration fine accurate recognition,issue,negative,positive,positive,positive,positive,positive
620513499,"As ""visteon"" is such an uncommon word, I doubt if it's in its trie. So it's not a surprise.

If you need uncommon words such as ""visteon"", I suggest training your own scorer.",uncommon word doubt surprise need uncommon suggest training scorer,issue,negative,positive,positive,positive,positive,positive
620507962,"With 0.7 pre-trained model and scorer, the duration parameter seems to be correct, but the recognition is not accurate. 

0.7 pre-trained model test results for the same wav file.   

TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-0-g3fbbca2
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{
""metadata"":{""confidence"":2.86337},""words"":[{""word"":""mister"",""time"":0.38,""duration"":0.24},{""word"":""yarn"",""time"":0.7,""duration"":0.16}],
""alternatives"":[
{""metadata"":{""confidence"":3.02035},""words"":[{""word"":""mistor"",""time"":0.38,""duration"":0.24},{""word"":""yarn"",""time"":0.7,""duration"":0.16}]},
{""metadata"":{""confidence"":3.81517},""words"":[{""word"":""mester"",""time"":0.38,""duration"":0.24},{""word"":""yarn"",""time"":0.7,""duration"":0.16}]}
]
}
here it recognise as ""**mister yarn**""  instead of ""**visteon**"".   

I will export my model to 0.7 and will confirm the results.   
",model scorer duration parameter correct recognition accurate model test file lite confidence word mister time duration word yarn time duration confidence word time duration word yarn time duration confidence word mester time duration word yarn time duration mister yarn instead export model confirm,issue,positive,positive,neutral,neutral,positive,positive
620504849,"Yeah, just busy a bit this week.",yeah busy bit week,issue,negative,positive,neutral,neutral,positive,positive
620468888,Yes the language model + trie are now packaged in the scorer. See for example[[1](https://github.com/mozilla/DeepSpeech/blob/master/doc/USING.rst#using-a-pre-trained-model)],yes language model scorer see example,issue,negative,neutral,neutral,neutral,neutral,neutral
620466940,"I am trying to reproduce the same in 0.7 release model, But the 0.7 native client does not support the lm. Is it an expected behaviour?",trying reproduce release model native client support behaviour,issue,negative,neutral,neutral,neutral,neutral,neutral
620426658,"hi @alexcannan 
how did you load the `model.json` in the browser. I am new to js. I have kept the `model.json` file that you get after `tensorflowjs_converter` in the `src` folder. I am building a react app 

This is the [model.json](https://colab.research.google.com/gist/MittalShruti/f412a91fb81e8aed21a560c8529b6f9e/model-json.ipynb) in case it helps 



```
import * as tf from '@tensorflow/tfjs';
import {loadGraphModel} from '@tensorflow/tfjs-converter';

const MODEL_URL = ""./model.json"";

class App extends React.Component {
  componentDidMount(){
    (async () => {
      const model = await loadGraphModel(MODEL_URL);
      console.log('tns', model)
    })()
```

Error

```
tf-core.esm.js:17 Uncaught (in promise) Error: Failed to parse model JSON of response from model.json. Please make sure the server is serving valid JSON for this request.
    at t.<anonymous> (tf-core.esm.js:17)
    at tf-core.esm.js:17
    at Object.throw (tf-core.esm.js:17)
    at s (tf-core.esm.js:17)
```",hi load browser new kept file get folder building react case import import class model await model error uncaught promise error parse model response please make sure server serving valid request anonymous,issue,negative,positive,positive,positive,positive,positive
620377195,"Sounds great, will have a look on it later
Thank you",great look later thank,issue,positive,positive,positive,positive,positive,positive
620369882,"Hello @erksch, thanks for the update.

The CLI project type works as usual on my side, can't test UWP due to an external issue that suggests reinstalling vs, I can't do that right now.

This looks like VS cache/config/version issue, now please verify under Tools/Options/Nuget package manager this config:
![Captura de pantalla (1041)](https://user-images.githubusercontent.com/32177100/80446375-ed5d1980-88d3-11ea-9545-e1717f607449.png)

Also, clear the NuGet cache and try again. If this doesn't work please update visual studio.",hello thanks update project type work usual side ca test due external issue ca right like issue please verify package manager de also clear cache try work please update visual studio,issue,positive,positive,neutral,neutral,positive,positive
620256767,"We moved away from notebook a long time ago. However, you can find similar process in https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train that I'm trying to make address the exact usecase you describe. It's still on 0.6, but you might be able to help https://github.com/Common-Voice/commonvoice-fr/projects/5",away notebook long time ago however find similar process trying make address exact describe still might able help,issue,negative,positive,positive,positive,positive,positive
620177362,"You're right, you'd need to reimplement the whole client logic. Some starting options to get some starting results faster:

- Export a model with n_steps=None, taking in an entire audio file at once instead of doing streaming. See here for an example: https://github.com/mozilla/DeepSpeech/blob/6e9b251da27cac697783b4076f9128d6c2d5467f/training/deepspeech_training/train.py#L847-L884
- You can implement a simple greedy CTC decoder as a start. Accuracy won't be as good as with full blown beam search decoding, but it'll give you a baseline. See here for some info: https://distill.pub/2017/ctc/ (Basically take the most likely label at each time step, collapse duplicates, remove blanks.)",right need whole client logic starting get starting faster export model taking entire audio file instead streaming see example implement simple greedy start accuracy wo good full blown beam search give see basically take likely label time step collapse remove,issue,negative,positive,positive,positive,positive,positive
620169797,"So, I naïvely put together a small app to transcribe audio thinking that model.predict(inputBuffer) would give me transcribed audio, but it looks like model.predict() calls the `session_->Run()` function found in [the tfmodelstate.cc file](https://github.com/mozilla/DeepSpeech/blob/6e9b251da27cac697783b4076f9128d6c2d5467f/native_client/tfmodelstate.cc#L202) under infer(), since running `console.log(model.executor.inputs)` outputs:

```
[{
    ""name"": ""input_node"",
    ""shape"": [ 1, 16, 19, 26 ],
    ""dtype"": ""float32""
  },
  {
    ""name"": ""input_lengths"",
    ""shape"": [ 1 ],
    ""dtype"": ""int32""
  },
  {
    ""name"": ""previous_state_c"",
    ""shape"": [ 1, 2048 ],
    ""dtype"": ""float32""
  },
  {
    ""name"": ""previous_state_h"",
    ""shape"": [ 1, 2048 ],
    ""dtype"": ""float32""
  }]
```

Getting this to work looks like it'll require porting a lot of the native_client C level API to typescript or maybe a WASM module that links up with the model.predict call. I'll continue fudging around with this but if anyone has any quick and dirty ideas I'd love to hear them.",put together small transcribe audio thinking would give audio like run function found file infer since running name shape float name shape name shape float name shape float getting work like require lot level typescript maybe module link call continue around anyone quick dirty love hear,issue,positive,negative,neutral,neutral,negative,negative
620161455,"This basically makes ReadTheDocs the source of truth and slims down the main README to avoid linking into GitHub where possible. We need to write usage docs for the .NET bindings, and then after that things should be mostly self contained on RTD. There's one or two links to the native client README for building from source but that should be it. Hopefully this solves #2824 by redirecting people to instructions that work reliably with the latest released model by default.

We may still want to have release branches as we go into maintenance of 1.x, but we don't have to keep changing the default branch on GitHub.

Built docs are here: https://community-tc.services.mozilla.com/api/queue/v1/task/Kh_P4l6jRZ6AP0o4skMJPA/runs/0/artifacts/public/doc-html.zip",basically source truth main avoid linking possible need write usage mostly self one two link native client building source hopefully people work reliably latest model default may still want release go maintenance keep default branch built,issue,negative,positive,positive,positive,positive,positive
619898641,"> AVX has been on AMD CPUs for years: when we verified the requirements, it was introduced in 2011 for Intel (SandyBridge I think) and AMD (Bulldozer as much as I can tell).

There's a reason I said ""still thinking of"". When you're on the last pre-AVX AMD generation and the rest of the family has slower CPUs, regardless of generation, it skews your perception.

> README, not the release notes.

Thanks. I'm not sure when I'll get to it, but I'll try not to make it too long.",think bulldozer much tell reason said still thinking last generation rest family regardless generation perception release thanks sure get try make long,issue,positive,positive,positive,positive,positive,positive
619896565,"> (To be honest, I was still thinking of AVX as ""that Intel thing that arrived on AMD products recently enough that requiring it would be like selling a game that only runs on nVidia GPUs."")

AVX has been on AMD CPUs for years: when we verified the requirements, it was introduced in 2011 for Intel (SandyBridge I think) and AMD (Bulldozer as much as I can tell).


> As for the PR, are you asking me to modify the README to add the requirements or is there a way to modify Releases metadata through PRs that I'm unaware of?

README, not the release notes.",honest still thinking thing recently enough would like selling game think bulldozer much tell modify add way modify unaware release,issue,positive,positive,neutral,neutral,positive,positive
619708978,"> It would be great if we have this feature for deep speech pre-build binary as well as, Inferencing more than one audio file at the same time. Currently, I've written a python script and passing audio file name one by one.

@nullbyte91 I'm trying to run audio fie one by one through PythonScript in deepspeech 0.6.1 model.
Could you please help me out.",would great feature deep speech binary well one audio file time currently written python script passing audio file name one one trying run audio fie one one model could please help,issue,positive,positive,positive,positive,positive,positive
619646008,"It's a matter of perspective. Ever since the race to keep a PC sufficiently performant for non-game tasks relaxed, ""modern CPU"" has stopped being obvious... especially for Linux users. I think we only have one machine in the whole house with AVX but, from how the machines perform the desired tasks, they certainly still feel modern.

(To be honest, I was still thinking of AVX as ""that Intel thing that arrived on AMD products recently enough that requiring it would be like selling a game that only runs on nVidia GPUs."")

As for the PR, are you asking me to modify the README to add the requirements or is there a way to modify Releases metadata through PRs that I'm unaware of?",matter perspective ever since race keep sufficiently performant relaxed modern stopped obvious especially think one machine whole house perform desired certainly still feel modern honest still thinking thing recently enough would like selling game modify add way modify unaware,issue,positive,positive,positive,positive,positive,positive
619572971,"> I apologize, I totally read over that part multiple times...
> When adding TF_FORCE_GPU_ALLOW_GROWTH to the script it works.
> So it's possible to just build the docker container and run it.

Don't hesitate to send PR to improve the docs, if you think there's a need to: if you missed it maybe it is because it's not as readable as we thought? ",apologize totally read part multiple time script work possible build docker container run hesitate send improve think need maybe readable thought,issue,negative,neutral,neutral,neutral,neutral,neutral
619572307,"I apologize, I totally read over that part multiple times...
When adding TF_FORCE_GPU_ALLOW_GROWTH to the script it works.
So it's possible to just build the docker container and run it.",apologize totally read part multiple time script work possible build docker container run,issue,negative,neutral,neutral,neutral,neutral,neutral
619566667,">     1. I _am_ wondering that.
> 
>     2. I'm suggesting that the system requirements should be made more clear, because it's unclear whether the AVX/FMA requirement is in addition to ""a modern CPU"" (not needed for GPU builds) or the definition of ""a modern CPU"" (needed for GPU builds).

Well, I guess a PR from you rewording that is useful because for us it is trivial that ""modern CPU"" is the AVX/FMA contraint, and this you need it also for GPU builds.",wondering suggesting system made clear unclear whether requirement addition modern definition modern well guess useful u trivial modern need also,issue,positive,positive,positive,positive,positive,positive
619558350,"1. I *am* wondering that.
2. I'm suggesting that the system requirements should be made more clear, because it's unclear whether the AVX/FMA requirement is in addition to ""a modern CPU"" (not needed for GPU builds) or the definition of ""a modern CPU"" (needed for GPU builds).",wondering suggesting system made clear unclear whether requirement addition modern definition modern,issue,negative,positive,positive,positive,positive,positive
619553584,"> I _think_ this means I can use it on my Athlon II X2 270 (predates AVX/FMA) as long as I pick the version which will hand off to my GeForce GTX750 (compute capability 5.0), but I shouldn't feel so un-confident in that assessment. (For all I know the ""with a modern CPU"" refers to the AVX/FMA requirement in both cases and you just didn't repeat it. I've seen people do that before.)

I don't understand your question. Are you asking if the GPU builds are also dependant on AVX/FMA ?",use long pick version hand compute capability feel assessment know modern requirement repeat seen people understand question also,issue,negative,positive,neutral,neutral,positive,positive
619553248,">  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.

Have you tried searching this on our docs? https://deepspeech.readthedocs.io/en/v0.7.0/TRAINING.html#recommendations",unknown get convolution algorithm probably initialize try looking see warning log message printed tried searching,issue,negative,negative,neutral,neutral,negative,negative
619552690,">  Which details can I provide to find a solution?

I already gave you two: batch size, GPU memory. You need to share more context on what you are doing exactly ... Hardware ? Software ? Other process using GPUs outside of Docker ? etc.",provide find solution already gave two batch size memory need share context exactly hardware process outside docker,issue,positive,positive,positive,positive,positive,positive
619551737,"Hi Lissyx, the fact that the -gpus switch works means that nvidia-docker is correctly working
I first installed it locally according to the documentation and this works with the exact same GPU's and commands, that's why I'm unsure where the error comes from... 
Which details can I provide to find a solution?",hi fact switch work correctly working first locally according documentation work exact unsure error come provide find solution,issue,negative,positive,positive,positive,positive,positive
619551100,"> Nvidia docker is installed, and nvidia-smi for example works in the deepspeech container, so afaik that should be okay?

It was not in your command.

This Dockerfile was contributed by @GeorgeFedoseev but we are only building it, we have no way to test it. You can see we never refer to it in any documentation.

This error can also sometimes be related to batch size / insufficient amount of GPU memory. We need much more details to be able to help.",docker example work container command building way test see never refer documentation error also sometimes related batch size insufficient amount memory need much able help,issue,positive,positive,positive,positive,positive,positive
619548138,"Nvidia docker is installed, and nvidia-smi for example works in the deepspeech container, so afaik that should be okay?",docker example work container,issue,negative,neutral,neutral,neutral,neutral,neutral
619546977,">  docker run --gpus 2 -it [image]

Don't you lack `--runtime=nvidia` ? This needs `NVIDIA-Docker` to work",docker run image lack need work,issue,negative,neutral,neutral,neutral,neutral,neutral
619444666,"I used the same name `--discount_fallback`:
```
usage: generate_lm.py [-h] --input_txt INPUT_TXT --output_dir OUTPUT_DIR
                      --top_k TOP_K --kenlm_bins KENLM_BINS --arpa_order
                      ARPA_ORDER --max_arpa_memory MAX_ARPA_MEMORY
                      --arpa_prune ARPA_PRUNE --binary_a_bits BINARY_A_BITS
                      --binary_q_bits BINARY_Q_BITS --binary_type BINARY_TYPE
                      [--discount_fallback]

Generate lm.binary and top-k vocab for DeepSpeech.

optional arguments:
  -h, --help            show this help message and exit
  --input_txt INPUT_TXT
                        Path to a file.txt or file.txt.gz with sample
                        sentences
  --output_dir OUTPUT_DIR
                        Directory path for the output
  --top_k TOP_K         Use top_k most frequent words for the vocab.txt file.
                        These will be used to filter the ARPA file.
  --kenlm_bins KENLM_BINS
                        File path to the KENLM binaries lmplz, filter and
                        build_binary
  --arpa_order ARPA_ORDER
                        Order of k-grams in ARPA-file generation
  --max_arpa_memory MAX_ARPA_MEMORY
                        Maximum allowed memory usage for ARPA-file generation
  --arpa_prune ARPA_PRUNE
                        ARPA pruning parameters. Separate values with '|'
  --binary_a_bits BINARY_A_BITS
                        Build binary quantization value a in bits
  --binary_q_bits BINARY_Q_BITS
                        Build binary quantization value q in bits
  --binary_type BINARY_TYPE
                        Build binary data structure type
  --discount_fallback   To try when such message is returned by kenlm: 'Could
                        not calculate Kneser-Ney discounts [...] rerun with
                        --discount_fallback'
```
",used name usage generate optional help show help message exit path sample directory path output use frequent file used filter file file path filter order generation maximum memory usage generation pruning separate build binary quantization value build binary quantization value build binary data structure type try message returned calculate rerun,issue,positive,positive,neutral,neutral,positive,positive
619424785,"This should not be always enabled. Can you make this into a command line flag like the other options, disabled by default? Then you can document the flag with the KenLM error message for example.",always make command line flag like disabled default document flag error message example,issue,negative,negative,negative,negative,negative,negative
619369482,"> thanks, it really was the bazel version (0.24.1)

Then maybe you can send a PR for doc? Thanks for checking and giving feedback. ",thanks really version maybe send doc thanks giving feedback,issue,positive,positive,positive,positive,positive,positive
619345558,">  So I downloaded deepspeech 0.7.0 tarball

please use git clone, not tarball

> ERROR: /home/user1/projects/aur-scripts/deepspeech/src/tensorflow/native_client/BUILD:3:1: file '@org_tensorflow//tensorflow:tensorflow.bzl' does not contain symbol 'if_cuda'
> ERROR: /home/user1/projects/aur-scripts/deepspeech/src/tensorflow/native_client/BUILD:91:1: name 'tf_cc_shared_object' is not defined
> ERROR: error loading package 'native_client': Package 'native_client' contains errors

please try with bazel 0.24.1 and cross-check you are on `r1.15`",please use git clone error file contain symbol error name defined error error loading package package please try,issue,negative,neutral,neutral,neutral,neutral,neutral
619328372,"I agree. I was actively looking for system requirements and I didn't find them until you told me where to look because it never occurred to me to check the release notes.

Also, it could be a little more clear.

I *think* this means I can use it on my Athlon II X2 270 (predates AVX/FMA) as long as I pick the version which will hand off to my GeForce GTX750 (compute capability 5.0), but I shouldn't feel so un-confident in that assessment. (For all I know the ""with a modern CPU"" refers to the AVX/FMA requirement in both cases and you just didn't repeat it. I've seen people do that before.)

> * Linux x86 64 bit with a modern CPU (Needs at least AVX/FMA)
> * Linux x86 64 bit with a modern CPU + NVIDIA GPU (Compute Capability at least 3.0, see NVIDIA docs)",agree actively looking system find told look never check release also could little clear think use long pick version hand compute capability feel assessment know modern requirement repeat seen people bit modern need least bit modern compute capability least see,issue,positive,negative,neutral,neutral,negative,negative
619328061,"From what I remember, the original reCAPTCHA would:

1. Present you with a known and an unknown word to determine whether you got it right
2. Farm the same word out to a bunch of people to up the confidence that the result was correct

The current reCAPTCHA would do something similar to get sufficient confidence in the correctness of the input.",remember original would present known unknown word determine whether got right farm word bunch people confidence result correct current would something similar get sufficient confidence correctness input,issue,positive,positive,neutral,neutral,positive,positive
619190765,Upgrading to the most recent version seemed to work! I'll put together a client to test performance.,recent version work put together client test performance,issue,negative,neutral,neutral,neutral,neutral,neutral
619180466,"Update:
When creating a fresh WPF App, adding the package and using it works as expected.
However when making a CLI or UWP project it does not.

",update fresh package work however making project,issue,negative,positive,positive,positive,positive,positive
619103687,"Here's the info:

```
Microsoft Visual Studio Community 2019 (2)
Version 16.3.10
VisualStudio.16.Release/16.3.10+29519.87
Microsoft .NET Framework
Version 4.8.03752

Installed Version: Community

Visual C++ 2019   00435-60000-00000-AA461
Microsoft Visual C++ 2019

Application Insights Tools for Visual Studio Package   9.1.00913.1
Application Insights Tools for Visual Studio

ASP.NET and Web Tools 2019   16.3.286.43615
ASP.NET and Web Tools 2019

Azure App Service Tools v3.0.0   16.3.286.43615
Azure App Service Tools v3.0.0

C# Tools   3.3.1-beta3-19461-02+2fd12c210e22f7d6245805c60340f6a34af6875b
C# components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Common Azure Tools   1.10
Provides common services for use by Azure Mobile Services and Microsoft Azure Tools.

IntelliCode Extension   1.0
IntelliCode Visual Studio Extension Detailed Info

Microsoft JVM Debugger   1.0
Provides support for connecting the Visual Studio debugger to JDWP compatible Java Virtual Machines

Microsoft MI-Based Debugger   1.0
Provides support for connecting Visual Studio to MI compatible debuggers

Microsoft Visual C++ Wizards   1.0
Microsoft Visual C++ Wizards

Microsoft Visual Studio VC Package   1.0
Microsoft Visual Studio VC Package

NuGet Package Manager   5.3.1
NuGet Package Manager in Visual Studio. For more information about NuGet, visit https://docs.nuget.org/

ProjectServicesPackage Extension   1.0
ProjectServicesPackage Visual Studio Extension Detailed Info

Test Adapter for Boost.Test   1.0
Enables Visual Studio's testing tools with unit tests written for Boost.Test.  The use terms and Third Party Notices are available in the extension installation directory.

Test Adapter for Google Test   1.0
Enables Visual Studio's testing tools with unit tests written for Google Test.  The use terms and Third Party Notices are available in the extension installation directory.

TypeScript Tools   16.0.10821.2002
TypeScript Tools for Microsoft Visual Studio

Visual Basic Tools   3.3.1-beta3-19461-02+2fd12c210e22f7d6245805c60340f6a34af6875b
Visual Basic components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Visual Studio Code Debug Adapter Host Package   1.0
Interop layer for hosting Visual Studio Code debug adapters in Visual Studio

Visual Studio Tools for CMake   1.0
Visual Studio Tools for CMake

Visual Studio Tools for CMake   1.0
Visual Studio Tools for CMake
```",visual studio community version framework version version community visual visual application visual studio package application visual studio web web azure service azure service used ide depending project type different version compiler may used common azure common use azure mobile azure extension visual studio extension detailed support visual studio compatible virtual support visual studio mi compatible visual visual visual studio package visual studio package package manager package manager visual studio information visit extension visual studio extension detailed test adapter visual studio testing unit written use third party available extension installation directory test adapter test visual studio testing unit written test use third party available extension installation directory typescript typescript visual studio visual basic visual basic used ide depending project type different version compiler may used visual studio code adapter host package layer hosting visual studio code visual studio visual studio visual studio visual studio visual studio,issue,positive,positive,neutral,neutral,positive,positive
619102639,"> Does it work for you when creating a new project?

Yes, I just created a new project and imported it without a problem.

Go to Help/About Visual Studio and click the copy button


> Microsoft Visual Studio Community 2019
> Version 16.5.4
> VisualStudio.16.Release/16.5.4+30011.22
> Microsoft .NET Framework
> Version 4.8.03761
> 
> Installed Version: Community
> 
> Visual C++ 2019   00435-60000-00000-AA985
> Microsoft Visual C++ 2019
> 
> ASP.NET and Web Tools 2019   16.5.236.49856
> ASP.NET and Web Tools 2019
> 
> ASP.NET Web Frameworks and Tools 2019   16.5.236.49856
> For additional information, visit https://www.asp.net/
> 
> Azure App Service Tools v3.0.0   16.5.236.49856
> Azure App Service Tools v3.0.0
> 
> Azure Functions and Web Jobs Tools   16.5.236.49856
> Azure Functions and Web Jobs Tools
> 
> C# Tools   3.5.0-beta4-20153-05+20b9af913f1b8ce0a62f72bea9e75e4aa3cf6b0e
> C# components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.
> 
> Common Azure Tools   1.10
> Provides common services for use by Azure Mobile Services and Microsoft Azure Tools.
> 
> IntelliCode Extension   1.0
> IntelliCode Visual Studio Extension Detailed Info
> 
> Microsoft Azure Tools   2.9
> Microsoft Azure Tools for Microsoft Visual Studio 2019 - v2.9.30207.1
> 
> Microsoft Continuous Delivery Tools for Visual Studio   0.4
> Simplifying the configuration of Azure DevOps pipelines from within the Visual Studio IDE.
> 
> Microsoft JVM Debugger   1.0
> Provides support for connecting the Visual Studio debugger to JDWP compatible Java Virtual Machines
> 
> Microsoft Library Manager   2.1.25+gdacdb9b7a1
> Install client-side libraries easily to any web project
> 
> Microsoft MI-Based Debugger   1.0
> Provides support for connecting Visual Studio to MI compatible debuggers
> 
> Microsoft Visual C++ Wizards   1.0
> Microsoft Visual C++ Wizards
> 
> Microsoft Visual Studio Tools for Containers   1.1
> Develop, run, validate your ASP.NET Core applications in the target environment. F5 your application directly into a container with debugging, or CTRL + F5 to edit & refresh your app without having to rebuild the container.
> 
> Microsoft Visual Studio VC Package   1.0
> Microsoft Visual Studio VC Package
> 
> NuGet Package Manager   5.5.0
> NuGet Package Manager in Visual Studio. For more information about NuGet, visit https://docs.nuget.org/
> 
> NVIDIA CUDA 10.2 Wizards   10.2
> Wizards to create new NVIDIA CUDA projects and source files.
> 
> ProjectServicesPackage Extension   1.0
> ProjectServicesPackage Visual Studio Extension Detailed Info
> 
> SQL Server Data Tools   16.0.62003.05170
> Microsoft SQL Server Data Tools
> 
> StylerPackage Extension   1.0
> StylerPackage Visual Stuido Extension Detailed Info
> 
> SyncfusionMenu Extension   1.0
> SyncfusionMenu Visual Studio Extension Detailed Info
> 
> Test Adapter for Boost.Test   1.0
> Enables Visual Studio's testing tools with unit tests written for Boost.Test.  The use terms and Third Party Notices are available in the extension installation directory.
> 
> Test Adapter for Google Test   1.0
> Enables Visual Studio's testing tools with unit tests written for Google Test.  The use terms and Third Party Notices are available in the extension installation directory.
> 
> TypeScript Tools   16.0.20225.2001
> TypeScript Tools for Microsoft Visual Studio
> 
> Visual Basic Tools   3.5.0-beta4-20153-05+20b9af913f1b8ce0a62f72bea9e75e4aa3cf6b0e
> Visual Basic components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.
> 
> Visual C++ for Linux Development   1.0.9.29814
> Visual C++ for Linux Development
> 
> Visual F# Tools 10.8.0.0 for F# 4.7   16.5.0-beta.20181.6+85af456066acd4e76d2bc7821b44a325e46f2fca
> Microsoft Visual F# Tools 10.8.0.0 for F# 4.7
> 
> Visual Studio Code Debug Adapter Host Package   1.0
> Interop layer for hosting Visual Studio Code debug adapters in Visual Studio
> 
> Visual Studio Container Tools Extensions (Preview)   1.0
> View, manage, and diagnose containers within Visual Studio.
> 
> Visual Studio Tools for CMake   1.0
> Visual Studio Tools for CMake
> 
> Visual Studio Tools for Containers   1.0
> Visual Studio Tools for Containers",work new project yes new project without problem go visual studio click copy button visual studio community version framework version version community visual visual web web web additional information visit azure service azure service azure web azure web used ide depending project type different version compiler may used common azure common use azure mobile azure extension visual studio extension detailed azure azure visual studio continuous delivery visual studio configuration azure within visual studio ide support visual studio compatible virtual library manager install easily web project support visual studio mi compatible visual visual visual studio develop run validate core target environment application directly container edit refresh without rebuild container visual studio package visual studio package package manager package manager visual studio information visit create new source extension visual studio extension detailed server data server data extension visual extension detailed extension visual studio extension detailed test adapter visual studio testing unit written use third party available extension installation directory test adapter test visual studio testing unit written test use third party available extension installation directory typescript typescript visual studio visual basic visual basic used ide depending project type different version compiler may used visual development visual development visual visual visual studio code adapter host package layer hosting visual studio code visual studio visual studio container preview view manage diagnose within visual studio visual studio visual studio visual studio visual studio,issue,positive,positive,neutral,neutral,positive,positive
619098740,"Hello @erksch 

> I was looking into this [commit of the example project](https://github.com/mozilla/DeepSpeech-examples/commit/2dd02d0417ca80a74aae54c18af058256e27a0f2) and saw these lines were added in the `.csproj` file:

This should be automatically added by Visual Studio, which Visual studio version are you using?




> I'm pretty sure you should be able to use it with just the NuGet reference...

You are right.",hello looking commit example project saw added file automatically added visual studio visual studio version pretty sure able use reference right,issue,positive,positive,positive,positive,positive,positive
619097327,I'm pretty sure you should be able to use it with just the NuGet reference...,pretty sure able use reference,issue,positive,positive,positive,positive,positive,positive
618984281,Tested the Docker fix separately to avoid waiting for an entire group: https://community-tc.services.mozilla.com/tasks/EH57gYcBQ5qZhikrVyCSNA,tested docker fix separately avoid waiting entire group,issue,negative,neutral,neutral,neutral,neutral,neutral
618947588,"> Does that installs you 0.6.1 ?

Yes it does.

Sorry @lissyx :D Although it's not perfect, I found my workaround. So thank you for checking in! Maybe later @carlfm01 will clarify some things.

",yes sorry although perfect found thank maybe later clarify,issue,positive,positive,positive,positive,positive,positive
618946418,"> nuget install DeepSpeech

Does that installs you 0.6.1 ?


> But this seems a bit odd, shouldn't the NuGet package when referred with `PackageReference` work, too?

Again, 0 knowledge in .Net, I don't even understand what you are talking abotu.",install bit odd package work knowledge even understand talking,issue,negative,negative,negative,negative,negative,negative
618944851,"But this seems a bit odd, shouldn't the NuGet package when referred with `PackageReference` work, too?",bit odd package work,issue,negative,negative,negative,negative,negative,negative
618944145,"I fixed it!
I was looking into this [commit of the example project](https://github.com/mozilla/DeepSpeech-examples/commit/2dd02d0417ca80a74aae54c18af058256e27a0f2) and saw these lines were added in the `.csproj` file:

```
<Reference Include=""DeepSpeechClient, Version=1.0.0.0, Culture=neutral, processorArchitecture=AMD64"">
  <HintPath>packages\DeepSpeech.0.6.0\lib\net46\DeepSpeechClient.dll</HintPath>
</Reference> 
```

I looked up the lines in my file and it is:
```
<PackageReference Include=""DeepSpeech"">
  <Version>0.6.1</Version>
</PackageReference>
```

So my uneducated guess would be to run `nuget install DeepSpeech` and just reference the resulting folder via `Reference` and `HintPath` instead of using `PackageReference`.  ",fixed looking commit example project saw added file reference file version uneducated guess would run install reference resulting folder via reference instead,issue,negative,positive,neutral,neutral,positive,positive
618943294,"> I am using the latest v0.6.1. The code in `native_client/dotnet` README only states how to build the native client for windows, but I guess I don't have to do that because the NuGet package with a prebuild library exists.

Unfortunately, according to the docs, 0.6..1 uses the same interface, and it's working well on CI.

Have you verified against ? https://github.com/mozilla/DeepSpeech-examples/tree/r0.6/net_framework/DeepSpeechWPF

I know nothing about .Net in itself, so you'd need to wait for @carlfm01 :/",latest code build native client guess package library unfortunately according interface working well know nothing need wait,issue,negative,neutral,neutral,neutral,neutral,neutral
618940998,"I am using the latest v0.6.1. The code in  `native_client/dotnet` README only states how to build the native client for windows, but I guess I don't have to do that because the NuGet package with a prebuild library exists. ",latest code build native client guess package library,issue,negative,positive,positive,positive,positive,positive
618251541,"If that works, it sounds like the easiest solution to me. ",work like easiest solution,issue,positive,neutral,neutral,neutral,neutral,neutral
618248794,"What if we remove the version specifier in setup.py and let pip find a version that matches all constraints? That way we don't have to reimplement the build logic in setup.py, since it's already propagated by the fact that we depend on ds_ctcdecoder from there.",remove version specifier let pip find version way build logic since already fact depend,issue,negative,neutral,neutral,neutral,neutral,neutral
618245578,"I ran into this in creating a scorer, not really training in the normal sense of the word.

But ignoring 3.8 we still have the problem as the maximal minimum version is 1.14.5 for

- Linux and Python 3.6
- Darwin and Python 3.7
- Windows and Python 3.7

while the minimal maximal version is 1.12.0 for

- Windows and Python 3.5 

So it doesn't look like we can have a numpy version that works for all cases if we ignore the platform and Python version.",ran scorer really training normal sense word still problem maximal minimum version python python python minimal maximal version python look like version work ignore platform python version,issue,negative,positive,neutral,neutral,positive,positive
618229582,"We can't support Python 3.8 for training anyway, because TensorFlow 1.15.2 does not have Python 3.8 wheels. Does eliminating that version fix the problem of the empty interval?",ca support python training anyway python version fix problem empty interval,issue,negative,negative,neutral,neutral,negative,negative
618228171,"@alexcannan I just did `pip install tensorflowjs` in a separate virtual environment, so the latest version. We're releasing 0.7.0 in the next few days so you should be able to more easily reproduce this.",pip install separate virtual environment latest version next day able easily reproduce,issue,negative,positive,positive,positive,positive,positive
618198447,"Seems like we might have to mirror the logic of tc-py-utils.sh in setup.py using[[1](https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies)]

However, repeating such delicate code seems like a recipe for a maintenance headache. ",like might mirror logic however delicate code like recipe maintenance headache,issue,positive,negative,negative,negative,negative,negative
618192956,"I don't know if this is solvable.

setup.py sets numpy version independent of python version used[[1](https://github.com/mozilla/DeepSpeech/blob/master/setup.py#L67)]

However, the ds-ctcdecoder decoder numpy versions are dependent upon the python version used[[2](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L235)]

This situation might be OK is we could, considering all python versions and platforms, look for the maximal minimum version required here[[2](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L235)] and also, considering all python versions and platforms, find the minimal maximal version required here[[2](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L235)] and then bound the setup.py numpy version by the interval so found.

This migh work, but this interval is empty.

For example the maximal minimum version required on Darwin for python 3.8 is 1.17.3[[3](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L272)] and the minimal maximal version required by python 3.7 is 1.17.0[[4](https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-py-utils.sh#L268)] so there is no version of numpy that works for all platforms and python versions.",know solvable version independent python version used however dependent upon python version used situation might could considering python look maximal minimum version also considering python find minimal maximal version bound version interval found work interval empty example maximal minimum version python minimal maximal version python version work python,issue,negative,negative,neutral,neutral,negative,negative
618186669,I'm going to solve this a different way,going solve different way,issue,negative,neutral,neutral,neutral,neutral,neutral
618076210,"@reuben What version of tensorflowjs are you using? It doesn't look like the recommended 0.8.6 version, otherwise it wouldn't let you use `--output_format=tfjs_graph_model`. 


I was able to build a basic output_graph.pb using reuben's diff applied to the current master, but upon running the conversion via the following command:

```
tensorflowjs_converter --input_format=tf_frozen_model --output_format=tensorflowjs --output_node_names=""logits,new_state_c,new_state_h,metadata_version,metadata_sample_rate,metadata_feature_win_len,metadata_feature_win_step,metadata_alphabet"" ./exports/output_graph.pb ./exports/output_graph.tfjs
```

I got the following error:

```
Using TensorFlow backend.
Traceback (most recent call last):
  File ""/home/alex/miniconda3/envs/tfjs-conv/bin/tensorflowjs_converter"", line 8, in <module>
    sys.exit(main())
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/converter.py"", line 352, in main
    strip_debug_ops=FLAGS.strip_debug_ops)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_pb.py"", line 331, in convert_tf_frozen_model
    skip_op_check=skip_op_check, strip_debug_ops=strip_debug_ops)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_pb.py"", line 117, in optimize_graph
    ', '.join(unsupported))
ValueError: Unsupported Ops in the model before optimization
AddV2
```

I added a `--skip_op_check=SKIP_OP_CHECK` flag to proceed past that ValueError and I was able to get to:

```
tensorflowjs_converter --input_format=tf_frozen_model --output_format=tensorflowjs --output_node_names=""logits,new_state_c,new_state_h,metadata_version,metadata_sample_rate,metadata_feature_win_len,metadata_feature_win_step,metadata_alphabet"" ./exports/output_graph.pb ./exports/output_graph.tfjs --skip_op_check=SKIP_OP_CHECK
Using TensorFlow backend.
2020-04-22 18:03:42.796417: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] Optimization results for grappler item: graph_to_optimize
2020-04-22 18:03:42.796448: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   debug_stripper: Graph size after: 1026 nodes (0), 1715 edges (0), time = 1.045ms.
2020-04-22 18:03:42.796453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 980 nodes (-46), 1671 edges (-44), time = 5.506ms.
2020-04-22 18:03:42.796458: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 975 nodes (-5), 1666 edges (-5), time = 1793.35901ms.
2020-04-22 18:03:42.796463: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 825 nodes (-150), 1489 edges (-177), time = 1143.177ms.
2020-04-22 18:03:42.796468: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 793 nodes (-32), 1441 edges (-48), time = 8.19ms.
2020-04-22 18:03:42.796473: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 2.886ms.
2020-04-22 18:03:42.796494: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   remapper: Graph size after: 793 nodes (0), 1441 edges (0), time = 2.436ms.
2020-04-22 18:03:42.796498: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 887.803ms.
2020-04-22 18:03:42.796512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 1011.50897ms.
2020-04-22 18:03:42.796516: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 7.577ms.
2020-04-22 18:03:42.796521: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   debug_stripper: Graph size after: 793 nodes (0), 1441 edges (0), time = 1.091ms.
2020-04-22 18:03:42.796525: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 2.682ms.
2020-04-22 18:03:42.796529: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 889.931ms.
2020-04-22 18:03:42.796534: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 1015.008ms.
2020-04-22 18:03:42.796538: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 7.938ms.
2020-04-22 18:03:42.796542: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 2.935ms.
2020-04-22 18:03:42.796546: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   remapper: Graph size after: 793 nodes (0), 1441 edges (0), time = 2.492ms.
2020-04-22 18:03:42.796561: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 904.186ms.
2020-04-22 18:03:42.796565: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 1013.05298ms.
2020-04-22 18:03:42.796570: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 7.999ms.
Writing weight file ./exports/output_graph.tfjs/tensorflowjs_model.pb...
2020-04-22 18:03:43.029490: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-22 18:03:43.051779: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3497900000 Hz
2020-04-22 18:03:43.052009: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5580c09fc300 executing computations on platform Host. Devices:
2020-04-22 18:03:43.052033: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""/home/alex/miniconda3/envs/tfjs-conv/bin/tensorflowjs_converter"", line 8, in <module>
    sys.exit(main())
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/converter.py"", line 352, in main
    strip_debug_ops=FLAGS.strip_debug_ops)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_pb.py"", line 331, in convert_tf_frozen_model
    skip_op_check=skip_op_check, strip_debug_ops=strip_debug_ops)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_pb.py"", line 139, in optimize_graph
    extract_weights(optimized_graph, output_graph, quantization_dtype)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/converters/tf_saved_model_conversion_pb.py"", line 183, in extract_weights
    [const_manifest], path, quantization_dtype=quantization_dtype)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/write_weights.py"", line 119, in write_weights
    group_bytes, total_bytes, _ = _stack_group_bytes(group)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/write_weights.py"", line 196, in _stack_group_bytes
    _assert_valid_weight_entry(entry)
  File ""/home/alex/miniconda3/envs/tfjs-conv/lib/python3.6/site-packages/tensorflowjs/write_weights.py"", line 305, in _assert_valid_weight_entry
    data.dtype.name + ' not supported.')
ValueError: Error dumping weight metadata_alphabet, dtype object not supported.
```

Anyone know why my model has AddV2 ops? I tried to use the latest release (v0.7.0a3) but only the current master had the files applicable for the diff. Perhaps I can try to restructure the v0.6.1 release according to reuben's diff and go from there.",version look like version otherwise would let use able build basic applied current master upon running conversion via following command got following error recent call last file line module main file line main file line file line unsupported unsupported model optimization added flag proceed past able get optimization grappler item graph size time graph size time constant folding graph size time graph size time graph size time graph size time graph size time constant folding graph size time graph size time graph size time graph size time graph size time constant folding graph size time graph size time graph size time graph size time graph size time constant folding graph size time graph size time graph size time writing weight file binary use frequency service platform host device undefined undefined recent call last file line module main file line main file line file line file line path file line group file line entry file line error dumping weight object anyone know model tried use latest release current master applicable perhaps try release according go,issue,negative,positive,neutral,neutral,positive,positive
617972281,FWIW TensorFlow Lite has an experimental CoreML delegate which would be way easier to integrate into our existing TFLite native client than writing a new CoreML implementation from scratch. Could be worth exploring if anyone is interested: https://www.tensorflow.org/lite/performance/coreml_delegate,lite experimental delegate would way easier integrate native client writing new implementation scratch could worth exploring anyone interested,issue,positive,positive,positive,positive,positive,positive
617184068,"> so I think the problem is solved :)

Thanks!



> It would be good to add some logic to check the scorer path. Is there any function which would check the scorer itself which I could use? Or should I just check if file exists?

I think in other places we just try and load the scorer and let it fail this way. Fixing it properly is likely to be done in the `native_client/ctcdecoder` part, if you want to have a look.",think problem thanks would good add logic check scorer path function would check scorer could use check file think try load scorer let fail way fixing properly likely done part want look,issue,negative,positive,neutral,neutral,positive,positive
617182280,"Sorry for the slow answer.

WER is very similar right now:
evaluate.py - 0.192821
evaluate_tflite.py - 0.191987

so I think the problem is solved :)
The only issue which I found is that if I specify the scorer to non-existing path I get very cryptic error:
```
python evaluate_tflite.py --model ""/data/DeepSpeech/deepspeech-cleaner/languages/de/training/datamodel_export/output_graph.pb"" --scorer /data/DeepSpeech/DS_worker_path/model/kenlm_ds.scorer --csv /home/ben/test.csv --proc 1
['tflite_process_0']
Totally 99 wav entries found in csv

TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-alpha.3-0-g58bc2f2
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2020-04-21 11:55:52.642798: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Fatal Python error: Segmentation fault

Current thread 0x00007fa1a1af7740 (most recent call first):
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/deepspeech/impl.py"", line 158 in SpeechToText
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/deepspeech/__init__.py"", line 122 in stt
  File ""evaluate_tflite.py"", line 46 in tflite_worker
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93 in run
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258 in _bootstrap
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 73 in _launch
  File ""/usr/lib/python3.6/multiprocessing/popen_fork.py"", line 19 in __init__
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 277 in _Popen
  File ""/usr/lib/python3.6/multiprocessing/context.py"", line 223 in _Popen
  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 105 in start
  File ""evaluate_tflite.py"", line 63 in main
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""evaluate_tflite.py"", line 126 in <module>
^CTraceback (most recent call last):
  File ""evaluate_tflite.py"", line 126, in <module>
    absl.app.run(partial(main, parse_args()))
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ben/DeepSpeech/venv/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""evaluate_tflite.py"", line 86, in main
    work_todo.join()
  File ""/usr/lib/python3.6/multiprocessing/queues.py"", line 305, in join
    self._cond.wait()
  File ""/usr/lib/python3.6/multiprocessing/synchronize.py"", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
```
It would be good to add some logic to check the scorer path. Is there any function which would check the scorer itself which I could use? Or should I just check if file exists?",sorry slow answer wer similar right think problem issue found specify scorer path get cryptic error python model scorer totally found warning reading entire model file memory transform model file graph reduce heap usage binary use fatal python error segmentation fault current thread recent call first file line file line file line file line run file line file line file line file line file line file line start file line main file line file line run file line module recent call last file line module partial main file line run main file line main file line main file line join file line wait return true would good add logic check scorer path function would check scorer could use check file,issue,negative,positive,neutral,neutral,positive,positive
617023049,"> Right, I'll come back in a couple of hours/tomorrow.

So I'm sure it fixed the lack of scorer, but @Jendker is it working correctly ? Is it enough for fixing your WER issues ?",right come back couple sure fixed lack scorer working correctly enough fixing wer,issue,negative,positive,positive,positive,positive,positive
616815988,"That seems to work, using the static_rnn RNN impl (like we do for TFLite exports), but without converting to TFLite. https://gist.github.com/reuben/4330b69db52112982c63aa8f98912c9f

Then:

```
tensorflowjs_converter --input_format=tf_frozen_model --output_format=tfjs_graph_model --output_node_names=""logits,new_state_c,new_state_h,metadata_version,metadata_sample_rate,metadata_feature_win_len,metadata_feature_win_step,metadata_alphabet"" ../tfjs_test/output_graph.pb output_graph.tfjs
2020-04-20 23:17:51.520207: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-20 23:17:51.520231: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   debug_stripper: debug_stripper did nothing. time = 0.09ms.
2020-04-20 23:17:51.520236: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   model_pruner: Graph size after: 980 nodes (-46), 1671 edges (-44), time = 235.555ms.
2020-04-20 23:17:51.520240: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 980 nodes (0), 1671 edges (0), time = 1595.54199ms.
2020-04-20 23:17:51.520244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 828 nodes (-152), 1494 edges (-177), time = 686.765ms.
2020-04-20 23:17:51.520248: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 793 nodes (-35), 1441 edges (-53), time = 54.915ms.
2020-04-20 23:17:51.520337: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 49.553ms.
2020-04-20 23:17:51.520349: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 755.521ms.
2020-04-20 23:17:51.520354: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 661.083ms.
2020-04-20 23:17:51.520359: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 54.496ms.
2020-04-20 23:17:51.520362: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   debug_stripper: debug_stripper did nothing. time = 13.755ms.
2020-04-20 23:17:51.520366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 36.591ms.
2020-04-20 23:17:51.520528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 762.896ms.
2020-04-20 23:17:51.520540: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 662.148ms.
2020-04-20 23:17:51.520544: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 55.646ms.
2020-04-20 23:17:51.520548: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   model_pruner: Graph size after: 793 nodes (0), 1441 edges (0), time = 50.742ms.
2020-04-20 23:17:51.520552: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 793 nodes (0), 1441 edges (0), time = 754.065ms.
2020-04-20 23:17:51.520556: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 671.946ms.
2020-04-20 23:17:51.520559: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 793 nodes (0), 1441 edges (0), time = 54.968ms.
2020-04-20 23:17:55.483821: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-20 23:17:55.483844: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   remapper: Graph size after: 768 nodes (-25), 1416 edges (-25), time = 82.316ms.
2020-04-20 23:17:55.483849: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 768 nodes (0), 1416 edges (0), time = 791.112ms.
2020-04-20 23:17:55.483853: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 768 nodes (0), 1416 edges (0), time = 715.423ms.
2020-04-20 23:17:55.483857: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 768 nodes (0), 1416 edges (0), time = 56.041ms.
2020-04-20 23:17:55.483861: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   remapper: Graph size after: 768 nodes (0), 1416 edges (0), time = 96.295ms.
2020-04-20 23:17:55.483951: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 768 nodes (0), 1416 edges (0), time = 771.628ms.
2020-04-20 23:17:55.483964: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   arithmetic_optimizer: Graph size after: 768 nodes (0), 1416 edges (0), time = 712.75ms.
2020-04-20 23:17:55.483968: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   dependency_optimizer: Graph size after: 768 nodes (0), 1416 edges (0), time = 55.314ms.
Writing weight file output_graph.tfjs/model.json...
```",work like without converting optimization grappler item nothing time graph size time graph size time graph size time graph size time graph size time graph size time graph size time graph size time nothing time graph size time graph size time graph size time graph size time graph size time graph size time graph size time graph size time optimization grappler item graph size time graph size time graph size time graph size time graph size time graph size time graph size time graph size time writing weight file,issue,negative,neutral,neutral,neutral,neutral,neutral
616804362,"You could try exporting the TFLite model instead. It does not use BlockLSTM. You'll have to comment out the feature computation sub-graph (and figure out an alternative for computing MFCCs in JS), but maybe it's enough to make some progress.",could try model instead use comment feature computation figure alternative maybe enough make progress,issue,negative,neutral,neutral,neutral,neutral,neutral
616772273,"> Unforunately, tfjs does not support certain operations to properly convert the existing model.

Thanks, sadly this is aligned with our experience on several other tools, EdgeTPU included :/",support certain properly convert model thanks sadly experience several included,issue,positive,negative,neutral,neutral,negative,negative
616752657,"For sake of documentation, I was able to set up the tfjs-converter package to attempt to process the output_graph.pb model, using the following command:

`tensorflowjs_converter --input_format=tf_frozen_model --output_format=tensorflowjs --output_node_names=""logits,new_state_c,new_state_h,mfccs,metadata_version,metadata_sample_rate,metadata_feature_win_len,metadata_feature_win_step,metadata_alphabet"" output_graph.pb output_graph.tfjs`

The output_node_names I was able to access during the export() function in DeepSpeech.py.

Unforunately, tfjs does not support certain operations to properly convert the existing model.

`ValueError: Unsupported Ops in the model before optimization 
BlockLSTM, AudioSpectrogram, Mfcc`

So until tfjs implements these ops, it looks like a simple tfjs conversion won't be possible. There has been movement recently to set up audio-related ops like [stft](https://github.com/tensorflow/tfjs/issues/1362), but it will take some development to get this working. If anyone is interested in contributing, check out [this ticket](https://github.com/tensorflow/tfjs/issues/624) to get an idea of the op development process. ",sake documentation able set package attempt process model following command able access export function support certain properly convert model unsupported model optimization like simple conversion wo possible movement recently set like take development get working anyone interested check ticket get idea development process,issue,positive,positive,positive,positive,positive,positive
616579301,"Right, I'll come back in a couple of hours/tomorrow.",right come back couple,issue,negative,positive,positive,positive,positive,positive
616578848,@Jendker I'd like to wait for your go one you have been able to confirm it works :),like wait go one able confirm work,issue,negative,positive,positive,positive,positive,positive
616572807,"Also, squash into one commit :)",also squash one commit,issue,negative,neutral,neutral,neutral,neutral,neutral
616552293,"> how to export it ?

Seriously? you spam, you don't read the issue template, you reach for support on Github instead of Discourse, **and** you don't read your own output?

There's **nothing** actionable in your few console output. We don't know what you did, we can't help you.",export seriously read issue template reach support instead discourse read output nothing actionable console output know ca help,issue,positive,negative,negative,negative,negative,negative
616548893,"This is not a bug, please reach for support on Discourse as explaine in the issue template you removed.",bug please reach support discourse issue template removed,issue,positive,neutral,neutral,neutral,neutral,neutral
616519144,"> Hi, this is not a bug.
> 
> I have been unable to load discourse forum for the last 24 hours. Is the site under maintenance? If yes, when will it be back up and running?

Can you be more specific ? We have no knowledge of planned outage, it works for us, and we are not in charge of the forum itself.",hi bug unable load discourse forum last site maintenance yes back running specific knowledge outage work u charge forum,issue,negative,negative,negative,negative,negative,negative
615931706,"The ReadTheDocs contents are generated from the source on GitHub. The code to build it is here: https://github.com/mozilla/DeepSpeech/tree/master/doc

See the Makefile and conf.py. In particular, here is where the `github` scheme is set up: https://github.com/mozilla/DeepSpeech/blob/master/doc/conf.py#L199-L200

If you can find a way to make that work on both GitHub and ReadTheDocs, please send a PR. Otherwise, my plan is to remove references to the GitHub versions and link to ReadTheDocs instead.",content source code build see particular scheme set find way make work please send otherwise plan remove link instead,issue,negative,positive,positive,positive,positive,positive
615931341,"> These files are meant to be rendered on deepspeech.readthedocs.io, where the links work fine. Here's an example:
> 
> https://deepspeech.readthedocs.io/en/v0.6.1/TRAINING.html#installing-python-dependencies
> 
> And the corresponding source:
> 
> https://github.com/mozilla/DeepSpeech/blob/v0.6.1/doc/TRAINING.rst#installing-python-dependencies
> 
> They don't render correctly on GitHub, but we couldn't find a way to make it work on both platforms. We should probably remove the links to the sub-files from the main README and just link to readthedocs to avoid this confusion.

I see a problem. This pull request was for document on GitHub",meant link work fine example corresponding source render correctly could find way make work probably remove link main link avoid confusion see problem pull request document,issue,negative,positive,positive,positive,positive,positive
615928302,"These files are meant to be rendered on deepspeech.readthedocs.io, where the links work fine. Here's an example:

https://deepspeech.readthedocs.io/en/v0.6.1/TRAINING.html#installing-python-dependencies

And the corresponding source:

https://github.com/mozilla/DeepSpeech/blob/v0.6.1/doc/TRAINING.rst#installing-python-dependencies

They don't render correctly on GitHub, but we couldn't find a way to make it work on both platforms. We should probably remove the links to the sub-files from the main README and just link to readthedocs to avoid this confusion.",meant link work fine example corresponding source render correctly could find way make work probably remove link main link avoid confusion,issue,negative,positive,positive,positive,positive,positive
615927583,"> You can't force links to github like that this will break branches. `:github:` is here to take care of this. Can you explain why you do this?

':github:' didn't work for links.
And now it is working.",ca force link like break take care explain work link working,issue,positive,neutral,neutral,neutral,neutral,neutral
615418506,"Maybe it's a good idea if you squash this pull request before you merge it, to remove all the readme tries I made.",maybe good idea squash pull request merge remove made,issue,negative,positive,positive,positive,positive,positive
615414363,"> Whats the reason for the last commit (no-sort merge)?

I think @carlfm01 just did an incorrect push at some point. @mychiux413 should be able to just force-push over it.",whats reason last commit merge think incorrect push point able,issue,negative,positive,positive,positive,positive,positive
615413335,"> @tilmankamp Maybe I should wait for it, the latest master did so much refactoring, the `./bin/run-ldc93s1.sh` even does not work, furthermore, I haven't fully understood the new project structure.

@mychiux413 Sent you a pull request.",maybe wait latest master much even work furthermore fully understood new project structure sent pull request,issue,negative,positive,positive,positive,positive,positive
615273856,">  DeepSpeech: v0.6.1-52-g8431251

This is still not pure DeepSpeech v0.6.1. Could you please ensure using the same tree?",still pure could please ensure tree,issue,positive,positive,positive,positive,positive,positive
615259486,Could you please repro on current master without local patches? Or can you repro only with this file or any other that is built the same way? ,could please current master without local file built way,issue,negative,neutral,neutral,neutral,neutral,neutral
615154257,"> These results are with lm. If I try the deepspeech native-client without lm option, I amgetting following error
> 
> ./deepspeech --model /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/ww/output_graph.tflite --audio /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav
> TensorFlow: v1.14.0-21-ge77504ac6b
> DeepSpeech: v0.6.1-51-g18403f0
> INFO: Initialized TensorFlow Lite runtime.
> Error on stat: 2
> Unexpected type for /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav: 0

Please run on desktop, the c++ native client on Android is very very limited as documented. ",try without option following error model audio lite error unexpected type please run native client android limited,issue,positive,positive,neutral,neutral,positive,positive
615139137,"Yes, got it,. Should we file a new issue for this.
",yes got file new issue,issue,negative,positive,positive,positive,positive,positive
615138652,"Because the start time changed, which is the goal of the patch.",start time goal patch,issue,negative,neutral,neutral,neutral,neutral,neutral
615138326,"But for the same audio file, the duration value is different before and after the patch.",audio file duration value different patch,issue,negative,neutral,neutral,neutral,neutral,neutral
615137613,"This is a separate issue, the end time did not change with the patch.",separate issue end time change patch,issue,negative,neutral,neutral,neutral,neutral,neutral
615136342,"These results are with lm. If I try the deepspeech native-client without lm option, I amgetting following error

./deepspeech --model /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/ww/output_graph.tflite --audio /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
Error on stat: 2
Unexpected type for /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav: 0
",try without option following error model audio lite error unexpected type,issue,positive,positive,neutral,neutral,positive,positive
615134375,"> Please find the result of the same file before applying the patch.
> 
> TensorFlow: v1.14.0-21-ge77504ac6b
> DeepSpeech: v0.6.1-51-g18403f0
> INFO: Initialized TensorFlow Lite runtime.
> audio_format=1
> num_channels=1
> sample_rate=16000 (desired=16000)
> bits_per_sample=16
> res.buffer_size=38400
> {""metadata"":{""confidence"":-4.83948},""words"":[{""word"":""**visteon**"",""time"":0,""**duration"":0.6**}]}
> 
> This (0.60) seems to be the correct value.

Is this with or without using a LM ?",please find result file patch lite confidence word time duration correct value without,issue,positive,neutral,neutral,neutral,neutral,neutral
615133764,"Please find the result of the same file before applying the patch.

TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{""metadata"":{""confidence"":-4.83948},""words"":[{""word"":""**visteon**"",""time"":0,""**duration"":0.6**}]}

This (0.60) seems to be the correct value.
",please find result file patch lite confidence word time duration correct value,issue,positive,neutral,neutral,neutral,neutral,neutral
615130220,Are you saying the word end time was correct before this patch but is now incorrect?,saying word end time correct patch incorrect,issue,negative,neutral,neutral,neutral,neutral,neutral
615129142,"we are using this model for wakeword detection, where the audio sample is samll(one or two words only)",model detection audio sample one two,issue,negative,neutral,neutral,neutral,neutral,neutral
615126020,"The recognition is of word ""visteon"" is correct. I noticed this issue mainly when the audio is small(single word).",recognition word correct issue mainly audio small single word,issue,negative,negative,neutral,neutral,negative,negative
615125335,"I don't even have a `8431251`. And I can't really process your WAV file because it's very short, and given we don't yet have a 0.7 model, the 0.6.1 re-exported one cannot get me accuraet result at all:
```
{
  ""metadata"": {
    ""confidence"": -11.5804
  },
  ""words"": [
    {
      ""word"": ""which"",
      ""time"": 0.3,
      ""duration"": 0.16
    },
    {
      ""word"": ""to"",
      ""time"": 0.5,
      ""duration"": 0.12
    },
    {
      ""word"": ""do"",
      ""time"": 0.66,
      ""duration"": 0.02
    }
  ],
  ""alternatives"": [
    {
      ""metadata"": {
        ""confidence"": -9.68734
      },
      ""words"": [
        {
          ""word"": ""wish"",
          ""time"": 0.3,
          ""duration"": 0.16
        },
        {
          ""word"": ""to"",
          ""time"": 0.52,
          ""duration"": 0.12
        },
        {
          ""word"": ""do"",
          ""time"": 0.66,
          ""duration"": 0.04
        }
      ]
    },
    {
      ""metadata"": {
        ""confidence"": -20.0236
      },
      ""words"": [
        {
          ""word"": ""which"",
          ""time"": 0.3,
          ""duration"": 0.16
        },
        {
          ""word"": ""to"",
          ""time"": 0.5,
          ""duration"": 0.12
        },
        {
          ""word"": ""don"",
          ""time"": 0.66,
          ""duration"": 0.16
        }
      ]
    }
  ]
}
```",even ca really process file short given yet model one get result confidence word time duration word time duration word time duration confidence word wish time duration word time duration word time duration confidence word time duration word time duration word time duration,issue,positive,positive,neutral,neutral,positive,positive
615124241,">  **DeepSpeech: v0.6.1-52-g8431251**

This is not 0.6.1



> ""word"":""visteon"",

How close is this from the reality? At this point, this is really important, because it will change those values.",word close reality point really important change,issue,negative,positive,positive,positive,positive,positive
615121335,"Yes, duration is computed from start_value. In this case it should be around **0.48** instead of 0.36. The word visteon ends approximately at 0.72 (0.24 + 0.48).",yes duration case around instead word approximately,issue,negative,negative,negative,negative,negative,negative
615119072,"> In this example, it shows incorrect duration value

What should be the correct value ?
Duration is computed from start_time value.",example incorrect duration value correct value duration value,issue,positive,neutral,neutral,neutral,neutral,neutral
615109183,"I tried the above patch , and it looks like it solved the start_time issue, but now the duration is not correct always.  Please find below example 

TensorFlow: v1.14.0-21-ge77504ac6b
**DeepSpeech: v0.6.1-52-g8431251**
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{""metadata"":{""confidence"":-4.8416},""words"":[{""word"":""visteon"",""time"":0.24,""**duration"":0.36**}]}

Please find attached test wav file 
https://drive.google.com/file/d/1_vlqyDldadvWZkLEN23b51cF0Z68Jh4m/view?usp=sharing

In this example, it shows incorrect duration value",tried patch like issue duration correct always please find example lite confidence word time duration please find attached test file example incorrect duration value,issue,positive,neutral,neutral,neutral,neutral,neutral
614797787,It's so obvious we never thought about that. Any opinion @reuben? ,obvious never thought opinion,issue,negative,neutral,neutral,neutral,neutral,neutral
614441070,The master branch of deepspeech does take a scorer argument[[1](https://github.com/mozilla/DeepSpeech/blob/master/training/deepspeech_training/util/flags.py#L175)]. I assume you're using an older version of the code.,master branch take scorer argument assume older version code,issue,negative,positive,positive,positive,positive,positive
614233968,"Thanks for the PR. We want our code to install and run without hiccups on machines without a CUDA install. For example, this includes any macOS computer (for which TensorFlow has no GPU wheels published). Anyone who is serious enough to be training models but hasn't read the relevant documentation only has themselves to blame for not leveraging GPUs.",thanks want code install run without without install example computer anyone serious enough training read relevant documentation blame,issue,negative,positive,neutral,neutral,positive,positive
613895629,"1. There's no hyperparameter for the number of hidden layers, you'll have to change the code that defines the model in the function `create_model` in `train.py`.
2. In current master there's code to initialize some layers from scratch when loading a checkpoint, with the `--drop_source_layers` flag. If you want to continue a pre-trained checkpoint with more layers, it could be useful. It hasn't been tested for that, though, so you'll have to figure it out. It also wasn't available in 0.6.1 so you'll have to wait for the 0.7.0 release (which should go out in the next couple of weeks).
3. This is not a bug, please use [Discourse](https://discourse.mozilla.org/c/deep-speech) as documented in the issue template you deleted to post this issue.",number hidden change code model function current master code initialize scratch loading flag want continue could useful tested though figure also available wait release go next couple bug please use discourse issue template post issue,issue,positive,positive,positive,positive,positive,positive
613830796,"> This video seems to simply describe the phenomenon of deep double descent and over fitting due to many parameters. There is already a training variable --n_hidden when training. See https://github.com/mozilla/DeepSpeech/blob/master/training/deepspeech_training/util/flags.py

yeah, but it's error when you applied it, in purpose to continue trainning....
",video simply describe phenomenon deep double descent fitting due many already training variable training see yeah error applied purpose continue,issue,negative,positive,positive,positive,positive,positive
613786227,This video seems to simply describe the phenomenon of deep double descent and over fitting due to many parameters. There is already a training variable --n_hidden when training. See https://github.com/mozilla/DeepSpeech/blob/master/training/deepspeech_training/util/flags.py,video simply describe phenomenon deep double descent fitting due many already training variable training see,issue,negative,positive,positive,positive,positive,positive
613629356,"> See ? We don't have the same workflow. It's hard to have a one-for-all solution ...

Thats why i suggested the splitting. It would create a minimal solution where everyone can build upon.

> This thread is now going in very different direction and we still don't know whether this is `docker` vs `podman` or if there is something else.

It builds fine in your CI, so think this is podman related.

> I don't know podman, and I really have no time to play.

Important difference to docker is that it can run without root privileges


Currently I can't play with it, and this also don't has a high priority to me right now, because I solved the problem with the dockerfile above. And solving the input problem alone, wouldn't solve my gpu detection problem.",see hard solution thats splitting would create minimal solution everyone build upon thread going different direction still know whether docker something else fine think related know really time play important difference docker run without root currently ca play also high priority right problem input problem alone would solve detection problem,issue,positive,positive,positive,positive,positive,positive
613619499,"> Not quite, i think my workflow is a bit different. I'm using the container only to install everything i need and then connect to it and run my commands inside. For input and output data, i mount those directories into the container, also files i changed. Therefore i only have to rebuild it if something in the setup did change.

See ? We don't have the same workflow. It's hard to have a one-for-all solution ...

This thread is now going in very different direction and we still don't know whether this is `docker` vs `podman` or if there is something else.

I don't know podman, and I really have no time to play.",quite think bit different container install everything need connect run inside input output data mount container also therefore rebuild something setup change see hard solution thread going different direction still know whether docker something else know really time play,issue,positive,negative,neutral,neutral,negative,negative
613612491,"> Like https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train ?

Not quite, i think my workflow is a bit different. I'm using the container only to install everything i need and then connect to it and run my commands inside. For input and output data, i mount those directories into the container, also files i changed. Therefore i only have to rebuild it if something in the setup did change.

I did mean like the short file I inserted above, and then in the second file uninstall tensorflow and rebuild it from source. If your lucky the dependencies for building tensorflow were already installed by nvidia. Only those who want to build the native_client codebase have to build the second container. 
I think this will reduce complexity instead of adding, because you can simplify the contents and remove things nvidia did already.",like quite think bit different container install everything need connect run inside input output data mount container also therefore rebuild something setup change mean like short file inserted second file rebuild source lucky building already want build build second container think reduce complexity instead simplify content remove already,issue,positive,positive,neutral,neutral,positive,positive
613601871,"> The first part to build a container with prebuilt tensorflow and gpu-setup for training.

As @reuben said earlier, there is no need for this for training, you can just use `tensorflow-gpu` produced by upstream. The requirement for our forked tensorflow is **only** to build the `native_client` codebase.",first part build container training said need training use produced upstream requirement forked build,issue,negative,positive,positive,positive,positive,positive
613600505,">  Maybe you can then cache the images and only rebuild the ones where something did change, to reduce runtime for automatic tests.

Except we have no tests at all on that docker.",maybe cache rebuild something change reduce automatic except docker,issue,negative,neutral,neutral,neutral,neutral,neutral
613599371,"> But maybe another idea, what do you think about splitting your Dockerfile into two parts?

Again, this Dockerfile was submitted by @GeorgeFedoseev and looked like a good idea. It addresses some specific use cases.

Having multiples Dockerfile will complexify things, when we need to simplify them.",maybe another idea think splitting two like good idea specific use complexify need simplify,issue,positive,positive,positive,positive,positive,positive
613598319,">  This will greatly reduce the build time for the users who only want to do a training and should also reduce the overall build time a bit. And it will fix my gpu not detected error:)

Like https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train ?",greatly reduce build time want training also reduce overall build time bit fix error like,issue,negative,positive,positive,positive,positive,positive
613596289,"Sorry, i can't help you very much with this now. 
If I insert the values (possible with podman), the build continues but my laptop stops responding after some minutes. And I won't have a more powerful computer at my hands for the next time, as my university is closed ...


But maybe another idea, what do you think about splitting your Dockerfile into two parts? The first part to build a container with prebuilt tensorflow and gpu-setup for training. And in the second part you build upon that image and add/replace the dependencies for native client generation.
This will greatly reduce the build time for the users who only want to do a training and should also reduce the overall build time a bit. And it will fix my gpu not detected error:)
Maybe you can then cache the images and only rebuild the ones where something did change, to reduce runtime for automatic tests.
",sorry ca help much insert possible build wo powerful computer next time university closed maybe another idea think splitting two first part build container training second part build upon image native client generation greatly reduce build time want training also reduce overall build time bit fix error maybe cache rebuild something change reduce automatic,issue,negative,positive,neutral,neutral,positive,positive
613571006,">  I'm using podman instead of docker but the issue should be the same.

So, since we don't reproduce on CI, can you investigate around that ?",instead docker issue since reproduce investigate around,issue,negative,neutral,neutral,neutral,neutral,neutral
613480510,"https://travis-ci.community/t/github-status-not-posted-on-commits-on-repositories-using-legacy-service-integration/7798

We can't do the switch to the Github App ourselves because it needs to be approved by a mozilla org owner.",ca switch need owner,issue,negative,neutral,neutral,neutral,neutral,neutral
613409547,"I won't have time to look at this super soon. If someone is still running into this, please comment with a stack trace, it'd help a lot.",wo time look super soon someone still running please comment stack trace help lot,issue,positive,positive,positive,positive,positive,positive
613408389,Link to utf8 docs in the `--force_utf8` parameter description got merged.,link parameter description got,issue,negative,neutral,neutral,neutral,neutral,neutral
613339993,"> > > Maybe an easier solution is to apply a type of ""early pruning"", or ""late expansion start"" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.
> > 
> > 
> > This is what I mean: https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f
> 
> It looks like this is working. We should really have better regressions coverage on that :/

As much as I can re-test, this change does fix the present issue and does not regress issue #2489 @reuben Do you want to finalize landing this ?",maybe easier solution apply type early pruning late expansion start heuristic start expanding blank probability lower threshold point expand could good compromise transcription accuracy high quality complicated mean like working really better coverage much change fix present issue regress issue want finalize landing,issue,positive,positive,neutral,neutral,positive,positive
613334958,"> > Maybe an easier solution is to apply a type of ""early pruning"", or ""late expansion start"" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.
> 
> This is what I mean: https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f

It looks like this is working. We should really have better regressions coverage on that :/",maybe easier solution apply type early pruning late expansion start heuristic start expanding blank probability lower threshold point expand could good compromise transcription accuracy high quality complicated mean like working really better coverage,issue,positive,positive,neutral,neutral,positive,positive
613332349,"> Can anyone please assist me in resolving this error ?

As reuben said, mixing incompatible versions. Since you did not cared to properly share informations, and this is not a bug, I'm closing. Please use Discourse as documented to seek for support.",anyone please assist error said incompatible since properly share bug please use discourse seek support,issue,positive,neutral,neutral,neutral,neutral,neutral
613082614,We're in the process of changing our release process so that the default branch shown on GitHub is the most recent stable release (instead of master) to avoid this confusion.,process release process default branch shown recent stable release instead master avoid confusion,issue,negative,neutral,neutral,neutral,neutral,neutral
613082145,"master is the development branch, it has no stability guarantees, no pre-built binaries, and no pre-trained models. If you want to try our pre-built binaries, or use our pre-trained model or checkpoint, use a stable release: https://github.com/mozilla/DeepSpeech/releases/latest",master development branch stability want try use model use stable release,issue,negative,neutral,neutral,neutral,neutral,neutral
613011721,"But the README states ""it is for the master branch"" **and** at the same time suggests to install via pip, which just does **not** install the master branch. So can you please update the README for the master branch to state how to install the master branch? Kind thanks.",master branch time install via pip install master branch please update master branch state install master branch kind thanks,issue,positive,positive,positive,positive,positive,positive
612597792,"> Maybe an easier solution is to apply a type of ""early pruning"", or ""late expansion start"" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.

This is what I mean: https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f",maybe easier solution apply type early pruning late expansion start heuristic start expanding blank probability lower threshold point expand could good compromise transcription accuracy high quality complicated mean,issue,positive,negative,neutral,neutral,negative,negative
612595999,"As far as I can tell this problem happens because we start expanding the trie with all characters in the alphabet on timestep=0 (without logit pruning), and the prefixes created in the first steps are maintained until the later timesteps when characters with high probability from the acoustic model are seen.

The [heuristic to ""push timesteps forward""](https://github.com/mozilla/DeepSpeech/blob/0f71bd2493843168f3ba5d6f4f0206651380f50c/native_client/ctcdecode/path_trie.cpp#L42-L50) is meant to fix this problem, but the way it's currently implemented, it only pushes forward leaf nodes, which doesn't cover every case. If we relax the condition to:

```c++
      if (child->second->log_prob_c < cur_log_prob_c &&
          child->second->timestep < new_timestep) {
```

It does fix the early character problem in my tests, but it introduces a new problem: in words with repeated letters (as in ""soot"", ""all"") where the second repeated letter has a higher probability than the first one, both repeated letters get assigned the same timestep, breaking monotonicity. This is because in e.g. the ""soot"" case, when the second ""o"" is expanded, both the ""s"" and ""so"" prefixes still exist. When the ""s"" prefix is seen, the heuristic gets applied to the child representing the *first* ""o"", setting its timestep to be equal to the second ""o"", which is then also added as a child to the ""so"" prefix. I don't know how to fix this without even hackier heuristics.

Using [cutoff probability pruning](https://github.com/mozilla/DeepSpeech/blob/0f71bd2493843168f3ba5d6f4f0206651380f50c/native_client/deepspeech.cc#L386) also fixes this (without breaking monotonicity) in cases I tested for because on the early (silent) timesteps, the blank label will contain most of the probability mass, and so the ""r"" and ""re"" beams will not be created until later, when they're seen with higher probability by the acoustic model. The downside is that it degrades accuracy (although it gives a huge performance boost) and it becomes a new hyperparameter to tune.

Maybe an easier solution is to apply a type of ""early pruning"", or ""late expansion start"" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.",far tell problem start expanding alphabet without pruning first later high probability acoustic model seen heuristic push forward meant fix problem way currently forward leaf cover every case relax condition fix early character problem new problem repeated soot second repeated letter higher probability first one repeated get assigned breaking soot case second expanded still exist prefix seen heuristic applied child first setting equal second also added child prefix know fix without even cutoff probability pruning also without breaking tested early silent blank label contain probability mass later seen higher probability acoustic model downside accuracy although huge performance boost becomes new tune maybe easier solution apply type early pruning late expansion start heuristic start expanding blank probability lower threshold point expand could good compromise transcription accuracy high quality complicated,issue,negative,positive,neutral,neutral,positive,positive
612484030,"> I think it's Google Colab somehow. That string is what's shown in git commits for the symlink, but on clone it should turn into a real symlink.

Yes its colab problem, they use spaces in their drive repo which mess with the path in files, thank you. ",think somehow string shown git clone turn real yes problem use drive mess path thank,issue,negative,positive,neutral,neutral,positive,positive
612483816,"> can you check using path without spaces just in case?
I re-cloned the repo in the /content directory to avoid spaces in path and it solved the error, thank you. 

",check path without case directory avoid path error thank,issue,negative,neutral,neutral,neutral,neutral,neutral
612478328,"I think it's Google Colab somehow. That string is what's shown in git commits for the symlink, but on clone it should turn into a real symlink.",think somehow string shown git clone turn real,issue,negative,positive,positive,positive,positive,positive
612474487,"Are you sure you properly git clone? Can you hand verify that the root `VERSION` file is indeed here? 
can you check using path without spaces just in case? ",sure properly git clone hand verify root version file indeed check path without case,issue,positive,positive,positive,positive,positive,positive
612006511,"Weird behavior:
```
text: r
start_time: 0 => out[i].timesteps[j]=0 * 0.02
text: e
start_time: 0.02 => out[i].timesteps[j]=1 * 0.02
text: s
start_time: 1.12 => out[i].timesteps[j]=56 * 0.02
```

indeed the first two characters have inconsistent timestep with the rest of the word",weird behavior text text text indeed first two inconsistent rest word,issue,negative,negative,negative,negative,negative,negative
611895995,You ignored the issue template that is meant for exactly this type of problem. Edit the first comment with the information that's asked there so we can have an idea of what's happening. But I can already say you're probably mixing incompatible versions.,issue template meant exactly type problem edit first comment information idea happening already say probably incompatible,issue,negative,positive,positive,positive,positive,positive
611889153,"TypeError                                 Traceback (most recent call last)
<ipython-input-11-55eaea5c2806> in <module>()
      3 args = (model, alphabet)
      4 kwargs = {'N_FEATURES' : N_FEATURES, 'N_CONTEXT' : N_CONTEXT, 'BEAM_WIDTH' : BEAM_WIDTH}
----> 5 ds = Model(*args, **kwargs)
      6 model_load_end = timer() - model_load_start
      7 print('Loaded model in {:.3}s.'.format(model_load_end), file=sys.stderr)

/usr/local/lib/python3.6/dist-packages/deepspeech/__init__.py in __init__(self, *args, **kwargs)
     38         self._impl = None
     39 
---> 40         status, impl = deepspeech.impl.CreateModel(*args, **kwargs)
     41         if status != 0:
     42             raise RuntimeError(""CreateModel failed with error code {}"".format(status))


Can anyone please assist me in resolving this error ?",recent call last module model alphabet model timer print model self none status status raise error code status anyone please assist error,issue,negative,neutral,neutral,neutral,neutral,neutral
611595982,"If they weren't important we wouldn't go through the trouble of using a fork...

The changes only affect our native client, which is why for training you can simply install upstream TensorFlow with pip.",important would go trouble fork affect native client training simply install upstream pip,issue,negative,positive,neutral,neutral,positive,positive
611582952,"Are there changes which are important for this project?
I'm asking because i had some problems on one computer that tensorflow did not find my gpus with this container. I switched to one of nvidias prebuilt containers and there the gpus were found.

My file is much shorter and faster to build and currently i don't miss anything for training:
```
FROM nvcr.io/nvidia/tensorflow:20.03-tf1-py3

# Install basic packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    sox libsox-dev

# Build kenlm
RUN mkdir /DeepSpeech/ /DeepSpeech/native_client/ \
    && cd /DeepSpeech/native_client/ \
    && git clone --depth 1 https://github.com/kpu/kenlm \
    && cd kenlm \
    && mkdir -p build \
    && cd build \
    && cmake .. \
    && make -j 4

# Install required python packages
COPY . /DeepSpeech/
RUN pip3 install --no-cache-dir /DeepSpeech/

# Tool to convert output graph for inference
RUN python3 /DeepSpeech/util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .

WORKDIR /DeepSpeech/
CMD [""/bin/bash""]
```",important project one computer find container switched one found file much shorter faster build currently miss anything training install basic run update install build run git clone depth build build make install python copy run pip install tool convert output graph inference run python source artifact branch target,issue,negative,positive,positive,positive,positive,positive
611505760,"> What is the reason for building tensorflow ourself instead of using a prebuilt container?

This Dockerfile was contributed by someone that had the need to rebuild from scratch.",reason building ourself instead container someone need rebuild scratch,issue,negative,neutral,neutral,neutral,neutral,neutral
611503723,What is the reason for building tensorflow ourself instead of using a prebuilt container?,reason building ourself instead container,issue,negative,neutral,neutral,neutral,neutral,neutral
611502140,Whats the reason for the last commit (no-sort merge)?,whats reason last commit merge,issue,negative,neutral,neutral,neutral,neutral,neutral
611279014,"@tilmankamp Maybe I should wait for it, the latest master did so much refactoring, the `./bin/run-ldc93s1.sh` even does not work, furthermore, I haven't fully understood the new project structure.",maybe wait latest master much even work furthermore fully understood new project structure,issue,negative,positive,positive,positive,positive,positive
611175300,"> Interesting.
> 
> The behavior is the same in root and rootless build mode.
> 
> But we can close the issue, as the docker building seems to work correctly.

Well you could force env var to avoid that, and it might make sense as a PR",interesting behavior root rootless build mode close issue docker building work correctly well could force avoid might make sense,issue,negative,positive,positive,positive,positive,positive
611153757,"Interesting.

The behavior is the same in root and rootless build mode.

But we can close the issue, as the docker building seems to work correctly.",interesting behavior root rootless build mode close issue docker building work correctly,issue,negative,positive,positive,positive,positive,positive
611136084,"> Building the docker container awaits an input
> 
> ```
> STEP 50: RUN ln -s /DeepSpeech/native_client /tensorflow
> --> 9fa0ff23376
> STEP 51: WORKDIR /tensorflow
> --> 0fd7a5747d8
> 
> STEP 52: RUN ./configure
> Extracting Bazel installation...
> WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
> You have bazel 0.24.1 installed.
> Do you wish to build TensorFlow with ROCm support? [y/N]:
> ```
> 
> Tested with current master branch.
> I'm using podman instead of docker but the issue should be the same.

Obviously not because docker builds fine in our CI",building docker container input step run faff step step run installation warning batch mode please instead explicitly shut server command shutdown wish build support tested current master branch instead docker issue obviously docker fine,issue,positive,positive,positive,positive,positive,positive
611128554,Could you please test the recent changes for me? I currently can't build a new deepspeech container.,could please test recent currently ca build new container,issue,negative,positive,neutral,neutral,positive,positive
610837391,"> @lissyx But no matter what dataset I use, the loss is getting bigger，

So what? You expect help without sharing any details on how you train and not following basic instructions such as using discourse for support?",matter use loss getting expect help without train following basic discourse support,issue,negative,neutral,neutral,neutral,neutral,neutral
610835912,"@lissyx But no matter what dataset I use, the loss is getting bigger，",matter use loss getting,issue,negative,neutral,neutral,neutral,neutral,neutral
610794186,"This is not a bug, please use Discourse.",bug please use discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
610530677,This would avoid confusion like https://discourse.mozilla.org/t/not-able-to-install-ds-ctcdecoder-required-for-training-my-own-dataset/57172/4 by ensuring it is more easily discoverable.,would avoid confusion like easily discoverable,issue,negative,positive,positive,positive,positive,positive
610355948,@tilmankamp main change is splitting `--load` into `--load_train` and `--load_evaluate`. I also added a warning for catching people running with different load and save checkpoint dirs.,main change splitting load also added warning catching people running different load save,issue,negative,positive,positive,positive,positive,positive
610135940,"Not me! I was just trying to warn you so you didn't spend time on it, never mind :)",trying warn spend time never mind,issue,negative,neutral,neutral,neutral,neutral,neutral
610135550,"@reuben, you beat me to it:) #2887

the way you implemented it was the other way I thought about doing it, but I thought you would prefer a more complex function instead of two simpler ones. I like your PR more than mine, but I will let you decide before I close my PR",beat way way thought thought would prefer complex function instead two simpler like mine let decide close,issue,negative,negative,negative,negative,negative,negative
610118259,"if this is happening, it's a problem... I'll take a look",happening problem take look,issue,negative,neutral,neutral,neutral,neutral,neutral
610084461,"This can be closed, works well. Thanks",closed work well thanks,issue,positive,positive,neutral,neutral,positive,positive
609554488,Have y'all considered making a discord server?,considered making discord server,issue,negative,neutral,neutral,neutral,neutral,neutral
609043656,This is also breaking model export at the end of a transfer run.,also breaking model export end transfer run,issue,negative,neutral,neutral,neutral,neutral,neutral
609043187,"It can't possibly be expected, evaluation should be a read only operation.",ca possibly evaluation read operation,issue,negative,neutral,neutral,neutral,neutral,neutral
608524579,I did add a link to your utf8 docs in the `--force_utf8` parameter description in my above pull request. ,add link parameter description pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
607936109,"I had to install `@types/node` so that this could run and compile with `npx tsc`.
My `tsc` version is `3.6.2` as well.",install could run compile version well,issue,negative,neutral,neutral,neutral,neutral,neutral
607919509,"@piraka9011 Namely, there were some obscure-to-me errors from `tsc` on `client.ts` (yet it did generate the JS and it seemed to be running ...) that you can likely help about.",namely yet generate running likely help,issue,negative,neutral,neutral,neutral,neutral,neutral
607918982,"> @lissyx I should be apologizing for being AFK and not providing enough context :)
> I'll take a look at your PR and provide feedback there.

Right. I'll let current PR run and see if it at least works a bit, and then see if your suggestions works. I tried do to that locally but it was failing, and I have no idea why ...",providing enough context take look provide feedback right let current run see least work bit see work tried locally failing idea,issue,negative,negative,neutral,neutral,negative,negative
607912927,"@lissyx I should be apologizing for being AFK and not providing enough context :)
I'll take a look at your PR and provide feedback there.
I'm not too familiar with how you package the node module so I wasn't sure how much info I needed to add.
I can confirm that I was able to build the DeepSpeech libraries and NodeJS bindings locally (with the `index.d.ts` bundled as part of the package).",providing enough context take look provide feedback familiar package node module sure much add confirm able build locally part package,issue,negative,positive,positive,positive,positive,positive
607879702,I might have been able to implement something in https://github.com/mozilla/DeepSpeech/pull/2882 based on your PR.,might able implement something based,issue,negative,positive,positive,positive,positive,positive
607812336,"@piraka9011 Ok, thanks to some office colleagues, I think my understanding moved a bit:
 - we can just package and ship `index.d.ts` that provides the types for our interface
 - for our CI, though, I think we will need a `client.ts` (maybe a stripped-down version as you suggested as an example)",thanks office think understanding bit package ship interface though think need maybe version example,issue,negative,positive,positive,positive,positive,positive
607803548,"So far, the best point I came to was:
 - we need to package `index.d.ts`
 - we can run you example-provided `index.ts` using `ts-node`, but it should be `client.ts`

What I am still failing to understand is:
 - is `ts-node` the way to go ?
 - do we need to rewrite `client.js` as `client.ts` ?
 - does it even make sense to be able to run an equivalent of `client.js` as typescript ?
 - how are people going to use this ?
 - should typescript be packaged with current js and shipped together, like for ElectronJS ?",far best point came need package run still failing understand way go need rewrite even make sense able run equivalent typescript people going use typescript current shipped together like,issue,positive,positive,positive,positive,positive,positive
607796864,"@piraka9011 I'm really sorry, but could you please share complete running example + instructions ? We know nothing about TypeScript, and I've already tried for several hours to get something running but I failed to find any useful and clear documentation. I'm not sure we have all the pieces already for DeepSpeech, so it's hard to know if we are missing things that are obvious to people used to TypeScript, if I'm misunderstanding the docs, or if we just need to complete some missing packaging steps.",really sorry could please share complete running example know nothing typescript already tried several get something running find useful clear documentation sure already hard know missing obvious people used typescript misunderstanding need complete missing,issue,positive,negative,neutral,neutral,negative,negative
607699585,"> I did use the the `--force_utf8` flag when creating the scorer model. But my data is word based and i should not have used the flag.

Unfortunately, this is a very sharp edge case, and from the code itself it's hard to detect with 100% accurraccy. I'm not sure that besides improving the documentation we can fix that soonish.

Could you please give feedback or even better PR for the doc so that we can improve it ? It seems you got tricked and you learnt from that, so you know better than us what is misleading.",use flag scorer model data word based used flag unfortunately sharp edge case code hard detect sure besides improving documentation fix soonish could please give feedback even better doc improve got learnt know better u misleading,issue,positive,positive,positive,positive,positive,positive
607592988,"this got messy, making new PR",got messy making new,issue,negative,negative,neutral,neutral,negative,negative
607413514,@alexcannan unfortunately I moved on. My project went in a different direction and I was a bit over my head to begin with. Would love to follow along with your progress!,unfortunately project went different direction bit head begin would love follow along progress,issue,positive,neutral,neutral,neutral,neutral,neutral
607398737,"@beriberikix Have you made any progress? I'm interested in this feature, wanted to check before I get started.",made progress interested feature check get,issue,positive,positive,positive,positive,positive,positive
607343453,"> Types are automatically generated and tests are usually run (at least for the `DefintelyTyped` repo) by running `ts-lint` (or a and verifying that the types are valid.
> 
> An example of a simple file to run for typechecking is [here](https://github.com/piraka9011/DefinitelyTyped/blob/217f243dcc8169e1abad43713800b4952c995f84/types/deepspeech/deepspeech-tests.ts).

Ok so `ts-lint` is another NPM package to install but the binary is `tslint`. And then even running that fails:
```
$ PATH=$HOME/node_modules/.bin/:$PATH tslint deepspeech-tests.ts 
No valid rules have been specified
```",automatically usually run least running valid example simple file run another package install binary even running path valid,issue,negative,negative,negative,negative,negative,negative
607280844,"> An example of a simple file to run for typechecking is [here](https://github.com/piraka9011/DefinitelyTyped/blob/217f243dcc8169e1abad43713800b4952c995f84/types/deepspeech/deepspeech-tests.ts).

Shouldn't that be part of your PR ? And is it the file I should use to run `ts-lint` ?",example simple file run part file use run,issue,negative,neutral,neutral,neutral,neutral,neutral
607278955,"> Types are automatically generated and tests are usually run (at least for the `DefintelyTyped` repo) by running `ts-lint` (or a and verifying that the types are valid.

Sorry @piraka9011, I still have several questions

This is only going to check types validity. Shouldn't we also **run** actual code making use of the typescript'd module ?

How should we package things ? I don't see anything specific about that in your PR, is bundling those files together enough ?

How is it being used ?",automatically usually run least running valid sorry still several going check validity also run actual code making use typescript module package see anything specific together enough used,issue,negative,negative,negative,negative,negative,negative
607265834,"No, the error occurred at training time, after the training was finished at the beginning of the checkpoint evaluation.

I did use the the `--force_utf8` flag when creating the scorer model. But my data is word based and i should not have used the flag. I have seen you added more documentation around this flag recently.

",error training time training finished beginning evaluation use flag scorer model data word based used flag seen added documentation around flag recently,issue,negative,neutral,neutral,neutral,neutral,neutral
607261654,"> Building an utf8 scorer out of non utf8 data and running a training + evaluation with it resulted in a `Segmentation fault` error at the model evaluation.

What do you mean ""utf8 scorer"" and ""non utf8"" data ? Can you be more explicit ?",building scorer non data running training evaluation segmentation fault error model evaluation mean scorer non data explicit,issue,negative,negative,negative,negative,negative,negative
607232419,"> > > This [README](https://github.com/mozilla/DeepSpeech) you refer to is for master and is correct.
> > > The 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1) which you _do not_ refer to is also correct and does not mention a kenlm.scorer.
> > > When using Deep Speech 0.6.1 please refer to the 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1)
> > 
> > 
> > The master readme is not correct because the deepspeech-0.6.1-models that it states to download simply does not contain kenlm.scorer
> 
> If you are using deepspeech 0.6.1 you need to refer to README of 0.6.1.
> 
> We welcome any suggestions to solve this chicken / egg problem for master, but so far we have not been able to find a valid solution.

@cheahheng Please see the discussion in PR #2824",refer master correct refer also correct mention deep speech please refer master correct simply contain need refer welcome solve chicken egg problem master far able find valid solution please see discussion,issue,positive,positive,positive,positive,positive,positive
607230090,"> The reason I suggested it be automated with CI is that if there are any changes to the DeepSpeech public API, then `dts-gen` would automatically update the type declarations.

My understanding is that `dts-gen` generates template information, such as what SWIG uses in its `.i` wrapper. This is indeed not built on CI, but checked in.



> Regenerating the bindings are done with `dts-gen`.

Except this requires the module to be installed. There's some chicken/egg problem here, so it needs to be clearly outlined in the doc.



> or update the `native_client/javascript` README on how to regenerate the type definitions.

This, please.",reason public would automatically update type understanding template information swig wrapper indeed built checked done except module problem need clearly outlined doc update regenerate type please,issue,negative,positive,neutral,neutral,positive,positive
607221334,"Regenerating the bindings are done with `dts-gen`. 

```sh
dts-gen -module deepspeech -f index.d.ts
```

The reason I suggested it be automated with CI is that if there are any changes to the DeepSpeech public API, then `dts-gen` would automatically update the type declarations.

I can however just submit the `index.d.ts` type file in `native_client/javascript` if that's  what you prefer. The `README.md` in `native_client` points to the toplevel `README`. Would you prefer I add inline comments, or update the `native_client/javascript` README on how to regenerate the type definitions.
",done sh reason public would automatically update type however submit type file prefer would prefer add update regenerate type,issue,negative,neutral,neutral,neutral,neutral,neutral
607198784,@mychiux413 Master changed quite a bit since you opened this in December. Could you rebase (and squash) it?,master quite bit since could rebase squash,issue,negative,neutral,neutral,neutral,neutral,neutral
607182865,"> > This [README](https://github.com/mozilla/DeepSpeech) you refer to is for master and is correct.
> > The 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1) which you _do not_ refer to is also correct and does not mention a kenlm.scorer.
> > When using Deep Speech 0.6.1 please refer to the 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1)
> 
> The master readme is not correct because the deepspeech-0.6.1-models that it states to download simply does not contain kenlm.scorer

If you are using deepspeech 0.6.1 you need to refer to README of 0.6.1.

We welcome any suggestions to solve this chicken / egg problem for master, but so far we have not been able to find a valid solution. ",refer master correct refer also correct mention deep speech please refer master correct simply contain need refer welcome solve chicken egg problem master far able find valid solution,issue,positive,positive,positive,positive,positive,positive
607166492,"> This [README](https://github.com/mozilla/DeepSpeech) you refer to is for master and is correct.
> 
> The 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1) which you _do not_ refer to is also correct and does not mention a kenlm.scorer.
> 
> When using Deep Speech 0.6.1 please refer to the 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1)

The master readme is not correct because the deepspeech-0.6.1-models that it states to download simply does not contain kenlm.scorer",refer master correct refer also correct mention deep speech please refer master correct simply contain,issue,negative,neutral,neutral,neutral,neutral,neutral
607165530,"Please, then please tell me which version of deepspeech that will be able to run the following

deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --scorer deepspeech-0.6.1-models/kenlm.scorer --audio audio/2830-3980-0043.wav",please please tell version able run following model scorer audio,issue,positive,positive,positive,positive,positive,positive
607160009,"This [README](https://github.com/mozilla/DeepSpeech) you refer to is for master and is correct. 

The 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1) which you _do not_ refer to is also correct and does not mention a kenlm.scorer.

When using Deep Speech 0.6.1 please refer to the 0.6.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.6.1)",refer master correct refer also correct mention deep speech please refer,issue,negative,neutral,neutral,neutral,neutral,neutral
606810236,"I can confirm the learning rate is loaded correctly, as I submitted another patch to override learning rates that where set and stored by the reduce_lr_on_plateau",confirm learning rate loaded correctly another patch override learning set,issue,negative,neutral,neutral,neutral,neutral,neutral
606758636,"@piraka9011 Sorry for the multiple back/forth, but the more I read this, the more I think it's actually just the PR you were submitting to `DefinitelyTyped` that we need here, with proprer doc on how to re-generate the bindings ?",sorry multiple read think actually need doc,issue,negative,negative,negative,negative,negative,negative
606746860,"> This is the [commit](https://github.com/piraka9011/DefinitelyTyped/commit/217f243dcc8169e1abad43713800b4952c995f84) I was going to submit to `DefintelyTyped` with all the changes.

Shouldn't it just be the PR we need in DeepSpeech repo, in fact ? As @reuben mentionned on Matrix, it seems un-natural to run `dts-gen` during CI itself.",commit going submit need fact matrix run,issue,negative,neutral,neutral,neutral,neutral,neutral
606744116,"> I see you opened that as a WIP, is it because you are unsure or there are missing steps you are working on ?

Unsure if there's anything else related to the build I need to update.

> Also, how can we test the typescript generated bits ? Do you have code to share for that?

Types are automatically generated and tests are usually run (at least for the `DefintelyTyped` repo) by running `ts-lint` (or a and verifying that the types are valid.

An example of a simple file to run for typechecking is [here](https://github.com/piraka9011/DefinitelyTyped/blob/217f243dcc8169e1abad43713800b4952c995f84/types/deepspeech/deepspeech-tests.ts).

This is the [commit](https://github.com/piraka9011/DefinitelyTyped/commit/217f243dcc8169e1abad43713800b4952c995f84) I was going to submit to `DefintelyTyped` with all the changes.


",see unsure missing working unsure anything else related build need update also test typescript code share automatically usually run least running valid example simple file run commit going submit,issue,negative,negative,negative,negative,negative,negative
606716433,"@piraka9011 Also, how can we test the typescript generated bits ? Do you have code to share for that ?",also test typescript code share,issue,negative,neutral,neutral,neutral,neutral,neutral
606713840,"> @lissyx I added `dts-gen` to `npm pack` in the `Makefile`. See #2870.
> 
> Let me know what other changes are necessary or feel free to cherrypick.

I see you opened that as a WIP, is it because you are unsure or there are missing steps you are working on ?",added pack see let know necessary feel free see unsure missing working,issue,negative,positive,neutral,neutral,positive,positive
606666553,"@lissyx I added `dts-gen` to `npm pack` in the `Makefile`. See #2870.

Let me know what other changes are necessary or feel free to cherrypick.",added pack see let know necessary feel free,issue,positive,positive,positive,positive,positive,positive
606644457,Closing for lack of information and nothing actionable here.,lack information nothing actionable,issue,negative,neutral,neutral,neutral,neutral,neutral
606606067,"@piraka9011 Gentle ping ? If you want, just share us basics of your patch and I'll finish the integration and you can review it ?",gentle ping want share u patch finish integration review,issue,positive,positive,positive,positive,positive,positive
606590404,"@HandsLing Does #2868 answers your question, or do you think this doc needs to be improved ? If so, what is missing ?",question think doc need missing,issue,negative,negative,negative,negative,negative,negative
606502049,"> Any tentative time frame for a fix ?

This requires to be able to investigate the issue, and we don't have enough bandwidth to do so.",tentative time frame fix able investigate issue enough,issue,negative,positive,positive,positive,positive,positive
606499621,Any  tentative time frame for a fix ?,tentative time frame fix,issue,negative,neutral,neutral,neutral,neutral,neutral
606496584,"Turns out, it's not a new issue see #2294 which seems to have introduced that.",turn new issue see,issue,negative,positive,positive,positive,positive,positive
606493254,"> Currently I don't have a checkpoint for 0.7.0a3, so I could not validate it.

Re-exporting 0.6.1 checkpoint works. I can reproduce the issue :'(.",currently could validate work reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
606482859,@HandsLing This is really aimed at people training their own model. I have not been able to articulate documentation around that.,really people training model able articulate documentation around,issue,negative,positive,positive,positive,positive,positive
606461202,"> i use the dataset U provided:zh-CN.tar.gz, when i transfrom it to .csv format, it comes out that message, so can U give some advices what the validate_label_locale parms mean? thx

Here: #2816 ",use provided format come message give mean,issue,negative,negative,negative,negative,negative,negative
606437682,"@reuben when i use deepspeech with trained model, it turns out the error:ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory
and i install deepspeech with : pip3 install deepspeech-gpu
so can i change somewhere to make deepspeech surpport cuda10.1",use trained model turn error open object file file directory install pip install change somewhere make,issue,negative,neutral,neutral,neutral,neutral,neutral
606426354,"As this is a particular problem for a particular audio clip (one can always find an audio clip that results in an incorrect transcription) and not a bug with the code or a request for a new feature, could you move this to [discourse](https://discourse.mozilla.org/c/deep-speech/247). Thank you. 

PS: We generally reserve issues for bugs and/or feature requests. ",particular problem particular audio clip one always find audio clip incorrect transcription bug code request new feature could move discourse thank generally reserve feature,issue,negative,positive,positive,positive,positive,positive
606412273,"@alokprasad mixed clean speech with noise, using the new feature `--test_augmentation_files`, the every test dataset is always `librivox-test-clean.csv`",mixed clean speech noise new feature every test always,issue,negative,positive,positive,positive,positive,positive
606402016,"@mychiux413 How you are generating test samples ,is it natural voice with noisy background or you have mixed clean speech with noise and then using it as test wave?",generating test natural voice noisy background mixed clean speech noise test wave,issue,positive,positive,positive,positive,positive,positive
606398427,"> Here’s a question: is it necessary to run augmentation on every epoch? It seems like augmentation is probably more valuable as the model nears convergence. I wonder if you could balance out the performance hit by not augmenting the first x epochs, when the model still has a high WER.


Here is my recent experiment result below (continuing...), I trained 20 epochs for every model with different parameters
* noise file: `rnnoise`, `pointsources noise`
* train dataset: librivox `clean-100.csv` `clean-300.csv` `other-500.csv`
* test dataset: `test-clean.csv`
* the loss records are final step (epoch = 19)
* in addition to this, I also mixed the `zh-tw speech` into librivox, and test the WER.

|Name|min_audio_dbfs               |max_audio_dbfs|min_snr_db                                   |max_snr_db|limit_audio_peak_dbfs|limit_noise_peak_dbfs|train loss|dev loss |test loss|test wer|test loss (mix TW speech)|test wer (mix TW speech)|
|----|-----------------------------|--------------|---------------------------------------------|----------|---------------------|---------------------|----------|---------|---------|--------|-------------------------|------------------------|
|Baseline (No Augmentation)|                             |              |                                             |          |                     |                     |27.685342 |24.046401|23.756416|0.137232|121.442734               |0.454246                |
|Default mix noise|0                            |-35           |3                                            |30        |7                    |3                    |69.323678 |21.669104|21.383959|0.112958|60.703743                |0.270337                |
|speech non over boosted|0                            |-35           |3                                            |30        |0                    |3                    |64.432057 |21.491052|21.344168|0.11471 |60.352631                |0.261519                |
|noise non over boosted|0                            |-35           |3                                            |30        |7                    |0                    |66.458655 |21.09868 |21.09868 |0.111596|62.270283                |0.269928                |
|Wide speech volume|0                            |-45           |3                                            |30        |7                    |3                    |67.366901 |21.060449|20.68895 |0.116559|59.696766                |0.2673                  |

The result shows:
1. whatever the noise parameters are, the tests WER are always better than the test of ""No Aug model""
2. The performance of defending noise (column `test wer (mix TW speech)`) is very effective with mix noise training
3. Don't be misled by training loss when mix with noise, because the space of data coverage is large than no-aug.
4. To inspect the noise mix training, the parameters might lead some trade off here, if we want to enhance cocktail party speech, you might lose some accuracy in clean test, in my opinion, if we `skip first x epochs` to emphasize the clean environment, which should be equivalent to `increase max SNR`, so the noise test should be worse then.

So my conclusion is:
* Tuning the noise parameters according to your target application environment, which should be equivalent as tuning `skip first x epochs`.
* Of course I will also try your idea if I have free resources later.",question necessary run augmentation every epoch like augmentation probably valuable model convergence wonder could balance performance hit first model still high wer recent experiment result trained every model different noise file noise train test loss final step epoch addition also mixed speech test wer loss loss mix speech wer mix speech augmentation mix non non speech result whatever noise wer always better test model performance noise column test wer mix speech effective mix noise training misled training loss mix noise space data coverage large inspect noise mix training might lead trade want enhance cocktail party speech might lose accuracy clean test opinion skip first emphasize clean environment equivalent increase noise test worse conclusion tuning noise according target application environment equivalent tuning skip first course also try idea free later,issue,positive,positive,positive,positive,positive,positive
606234809,Let's verify you are not breaking anything.,let verify breaking anything,issue,negative,neutral,neutral,neutral,neutral,neutral
605909648,OH heck sorry wrong repo! Don't know how i ended up here. please ignore!,oh heck sorry wrong know ended please ignore,issue,negative,negative,negative,negative,negative,negative
605864492,"The official TensorFlow documentation seems to indicate that 10.1 is fine, but the docs have not been very well kept during the 1.x -> 2.x transition period, so you'll have to test for yourself. We've been using 10.0 for a long time now.",official documentation indicate fine well kept transition period test long time,issue,negative,positive,positive,positive,positive,positive
605531488,"> Alpha versions have no guarantee of stability between them. I don't know what happened between those alphas but in general if your acoustic model was trained on a specific version you should stick to that version on all components, not mix and match versions of the model and the client or the decoder. Basically, until 1.0 is out, stick to the same version of every component: version of training/export code, decoder package, version of native client, version of acoustic model/checkpoint if using our releases, version of any tooling like `generate_trie`, etc.

Thanks for your quick reply. Yes, I am sure that when I used the stable version v0.6.0, I have cloned the original code, and used the Dokerfile in masker generated the docker image and docker container. Native client, ctcdecoder, and generated_trie are all based on the source code. The result has encountered the problem which I showed in the first picture(only one character in each sentence). As you mentioned, it may because of the UTF-8 targeting. I also noticed the `_swigwrapper.cpython-36m-x86_64-linux-gnu.so` file is larger than the old version,  after alpha13, a new Alphabet class is introduced as well. ",alpha guarantee stability know general acoustic model trained specific version stick version mix match model client basically stick version every component version code package version native client version acoustic version tooling like thanks quick reply yes sure used stable version original code used masker docker image docker container native client based source code result problem first picture one character sentence may also file old version alpha new alphabet class well,issue,positive,positive,positive,positive,positive,positive
605523859,"FYI, there is one big change that affects character based models, but it only landed in v0.6.0-alpha.15: UTF-8 targeting, which supersedes the old character based decoding paths.",one big change character based landed old character based,issue,negative,positive,neutral,neutral,positive,positive
605523659,"Alpha versions have no guarantee of stability between them. I don't know what happened between those alphas but in general if your acoustic model was trained on a specific version you should stick to that version on all components, not mix and match versions of the model and the client or the decoder. Basically, until 1.0 is out, stick to the same version of every component: version of training/export code, decoder package, version of native client, version of acoustic model/checkpoint if using our releases, version of any tooling like `generate_trie`, etc.",alpha guarantee stability know general acoustic model trained specific version stick version mix match model client basically stick version every component version code package version native client version acoustic version tooling like,issue,positive,positive,neutral,neutral,positive,positive
605404347,"Here’s a question: is it necessary to run augmentation on every epoch? It seems like augmentation is probably more valuable as the model nears convergence. I wonder if you could balance out the performance hit by not augmenting the first x epochs, when the model still has a high WER.",question necessary run augmentation every epoch like augmentation probably valuable model convergence wonder could balance performance hit first model still high wer,issue,positive,positive,positive,positive,positive,positive
604970398,@reuben Could we imagine a way to be able to detect if the code has not been installed using `pip` when people try to run it ? So we can avoid all the long tail of those not reading the documentation and then complaining ?,could imagine way able detect code pip people try run avoid long tail reading documentation,issue,negative,positive,positive,positive,positive,positive
604483384,@lissyx I added a section linking to the existing documentation in the native client README,added section linking documentation native client,issue,negative,neutral,neutral,neutral,neutral,neutral
604454973,"> Can you please help me to resolve this issue, thank you in advance.

No. Next time, read carefully the issue template that you removed. Please use Discourse for support.



>  My tensorflow version : 2.0.0

You obviously have not read the documentation, since we require TensorFlow r1.15.",please help resolve issue thank advance next time read carefully issue template removed please use discourse support version obviously read documentation since require,issue,positive,negative,neutral,neutral,negative,negative
604350039,">  There are few things that needs to be done apart from following the documentations and readme files.

Could you please file bugs / explains what is tricky to you ? We can't improve the project with that kind of feedback @cheahheng.",need done apart following could please file tricky ca improve project kind feedback,issue,positive,positive,positive,positive,positive,positive
604348990,"> DeepSpeech 0.6.1
> ds_ctcdecoder 0.7.0a2

Please read the documentation and use matching versions. There is no bug, you are mixing incompatible versions. Please avoid using Github for support and go to Discourse.",please read documentation use matching bug incompatible please avoid support go discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
604226582,"a possible implementation:

""Unrestricted Vocabulary Keyword Spotting using LSTM-CTC""

https://www.isca-speech.org/archive/Interspeech_2016/pdfs/0753.PDF",possible implementation unrestricted vocabulary spotting,issue,negative,neutral,neutral,neutral,neutral,neutral
604209007,Hi I manage to resolve this and have successfully build my own kenlm.scorer from scratch. There are few things that needs to be done apart from following the documentations and readme files. It's tricky but I have done it.,hi manage resolve successfully build scratch need done apart following tricky done,issue,positive,positive,positive,positive,positive,positive
604073657,"I'm asking for review from y'all three mostly so you're aware of this big change. The vast majority of it is just shuffling code from one place to the other and adapting imports, so don't feel like you have to review line by line.",review three mostly aware big change vast majority shuffling code one place feel like review line line,issue,negative,positive,neutral,neutral,positive,positive
603970145,"First avoid screenshot.
Second,this is not a bug, use discourse for support.
Third, please grant execution rights to the binary, and avoid sudo.",first avoid second bug use discourse support third please grant execution binary avoid,issue,negative,positive,neutral,neutral,positive,positive
603805274,@reuben Should that doc cover building the `ds_ctcdecoder` module ? Either in this PR or in a subsequent one ?,doc cover building module either subsequent one,issue,negative,neutral,neutral,neutral,neutral,neutral
603769040,"> Yes, it make sense, I will try it, but the arguments would be twice than previous version, and how about specifying the number of sub-speakers for each speech? is this helpful for your experiments?

Do you mean augmenting with not only one but multiple background speech or noise files at once? If you dont think its to complicated this is an interesting idea. It would make the backgound noises even more realistic. In this case I would suggest to make the number not fixed, but random with an upper boundary to simulate different environments.",yes make sense try would twice previous version number speech helpful mean one multiple background speech noise dont think complicated interesting idea would make even realistic case would suggest make number fixed random upper boundary simulate different,issue,positive,negative,neutral,neutral,negative,negative
603748656,"If there's no way to specify per-file limits, then the limit should be global. Having a single `--limit_train` flag that applies separately for each CSV is very counter intuitive.",way specify limit global single flag separately counter intuitive,issue,negative,negative,neutral,neutral,negative,negative
603710439,"Pending PR shows the build is green, I'm merging! Thanks!",pending build green thanks,issue,negative,neutral,neutral,neutral,neutral,neutral
603692409,">     * 
> 
> 
> I build the ctcdecoder in directory: DeepSpeech-master/native_client/ctcdecode/,
> use command: python setup.py install

This is not how you are supposed to do. Please install `ds_ctcdecoder` wheel, why do you want to rebuild it ?",build directory use command python install supposed please install wheel want rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
603674503,"> What do you think about two noise pipelines? One for the noise and one for cocktailparty speech.
> I thougth about mixing my files together into one pipeline, but i think it would be better to have seperate mixing parameters for noise and speech. Mostly because you can mix the noise much louder than than the speech while keeping the text understandable.

Yes, it make sense, I will try it, but the arguments would be twice than previous version, and how about specifying the number of  sub-speakers for each speech? is this helpful for your experiments?",think two noise one noise one speech together one pipeline think would better noise speech mostly mix noise much speech keeping text understandable yes make sense try would twice previous version number speech helpful,issue,positive,positive,positive,positive,positive,positive
603659077,"@lissyx  I don't actually have more resources to benchmark the performance between them, but we can close the PR, I think the two should not be too different, and depending on `optuna` should be more stable.",actually performance close think two different depending stable,issue,negative,neutral,neutral,neutral,neutral,neutral
603595321,"@lissyx I addressed review comments.
Please check it.

I appreciate for your kind suggestions :)",review please check appreciate kind,issue,positive,positive,positive,positive,positive,positive
603394533,"> How about something like
> `--train_files some/data/set.csv[10:-100],some/other/data.sdb[:100]` ?
> Should be straight-forward to implement through extended generator functions in `util.sample_collections.SDB` and `util.sample_collections.CSV`.

I was looking into `create_dataset` and re-vive the `--limit` flags. I worry that the proposed syntax might be unobvious to people and error prone from shell point of view",something like implement extended generator looking limit worry syntax might unobvious people error prone shell point view,issue,negative,neutral,neutral,neutral,neutral,neutral
603392850,"How about something like
`--train_files some/data/set.csv[10:-100],some/other/data.sdb[:100]` ?
Should be straight-forward to implement through extended generator functions in `util.sample_collections.SDB` and `util.sample_collections.CSV`.",something like implement extended generator,issue,negative,neutral,neutral,neutral,neutral,neutral
603386907,"I'm wondering since when this is broken. Checking `v0.4.1`, there's `limit` as an argument to `DataSet`, but it's never used anywhere.",wondering since broken limit argument never used anywhere,issue,negative,negative,negative,negative,negative,negative
603360351,">  so, maybe we can close this PR.

Since there has been no more activity from you on that @mychiux413, I'm closing. Feel free to open a new PR if you think there's value :)",maybe close since activity feel free open new think value,issue,positive,positive,positive,positive,positive,positive
603359265,"@dabinat From @reuben's reply above, I don't think we can fix that. I'm closing, but feel free to re-open if you think we should really do the extra work described.",reply think fix feel free think really extra work,issue,positive,positive,positive,positive,positive,positive
603357057,Closing for triviality and lack of feedback over the proposed solution.,triviality lack feedback solution,issue,negative,neutral,neutral,neutral,neutral,neutral
603350746,"To summarize, if you can prepare CI integration it'd be awesome, but don't block yourself on that. For several reasons, we can't easily open TaskCluster CI to anybody, so it's still not super trivial to hack around.",summarize prepare integration awesome block several ca easily open anybody still super trivial hack around,issue,positive,positive,positive,positive,positive,positive
603289535,"@ryojiysd I have a PR that produced ctc decoder python wheels on Windows: https://community-tc.services.mozilla.com/tasks/elQXQ6CaS7en6upzrcpWbA#artifacts

So once you fix the nits, this is good to go for me :)",produced python fix good go,issue,negative,positive,positive,positive,positive,positive
603288095,@mychiux413 Does that PR still make sense now that we have the LM optimizer code ? ,still make sense code,issue,negative,neutral,neutral,neutral,neutral,neutral
603207136,"> It sounds like this is adding a step to `npm-pack` in the `Makefile` where `dts-gen` is run to add the types automatically. The build docs are clear and I've compiled DS before. Any nuances I should be aware of though?

Do you have some patch ? That might be the easiest way to know for sure. But from your description, it might be just that (and maybe the nodejs deps ?)



> I have written some type tests so that should also help.
> Is there anything else needed for CI?

It might be a bit convoluted to add CI, but you can try by looking at the existing NodeJS / ElectronJS tests files: `.yml` under `taskcluster/` as well as `tc-node-tests.sh` there.

Worst case, if you have basics of tests we can build on top of them.",like step run add automatically build clear aware though patch might easiest way know sure description might maybe written type also help anything else might bit convoluted add try looking well worst case build top,issue,positive,positive,neutral,neutral,positive,positive
603201390,"> Right, but that means we also advertise support for TypeScript, so we need proper CI to cover that. Would you be willing to help there?

It sounds like this is adding a step to `npm-pack` in the `Makefile` where `dts-gen` is run to add the types automatically. The build docs are clear and I've compiled DS before. Any nuances I should be aware of though?

I have written some type tests so that should also help.
Is there anything else needed for CI?

> What's the different between hand-written and `dts-gen` ?

Automation :) That and probably documentation (but the documentation in the Node package should suffice).",right also advertise support typescript need proper cover would willing help like step run add automatically build clear aware though written type also help anything else different probably documentation documentation node package suffice,issue,positive,positive,positive,positive,positive,positive
603198345,"> > 
> 
> Sure, the DeepSpeech node package currently does not have any type definitions for TypeScript.
> Having a [type decleration file](https://www.typescriptlang.org/docs/handbook/declaration-files/introduction.html) enables developers to use typescript instead of pure JS modules.

Right, but that means we also advertise support for TypeScript, so we need proper CI to cover that. Would you be willing to help there?



> I wrote the type definitions and submitted to them to the `DefinetelyTyped` repo so that they could be installed using `npm install @types/deepspeech`.
> 
> The types could also be generated using the [`dts-gen`](https://github.com/Microsoft/dts-gen) package.

What's the different between hand-written and `dts-gen` ?



> I'm not sure how you bundle your JS client to npm but if you give me some context there, I can probably just contribute the type definitions back here (and maybe add a step to the packaging process to produce the types if you have such a process).

Everything to produce the NPM package is documented, have you had a look at that ? The `native_client/javascript/Makefile` should be mostly enough to grasp it, but if you have more precise questions, please feel free to ask.",sure node package currently type typescript type file use typescript instead pure right also advertise support typescript need proper cover would willing help wrote type could install could also package different sure bundle client give context probably contribute type back maybe add step process produce process everything produce package look mostly enough grasp precise please feel free ask,issue,positive,positive,positive,positive,positive,positive
603196870,"> Could you please give some context ?

Sure, the DeepSpeech node package currently does not have any type definitions for TypeScript. 
Having a [type decleration file](https://www.typescriptlang.org/docs/handbook/declaration-files/introduction.html) enables developers to use typescript instead of pure JS modules.

I wrote the type definitions and submitted to them to the `DefinetelyTyped` repo so that they could be installed using `npm install @types/deepspeech`.

The types could also be generated using the [`dts-gen`](https://github.com/Microsoft/dts-gen) package.

I'm not sure how you bundle your JS client to npm but if you give me some context there, I can probably just contribute the type definitions back here (and maybe add a step to the packaging process to produce the types if you have such a process).",could please give context sure node package currently type typescript type file use typescript instead pure wrote type could install could also package sure bundle client give context probably contribute type back maybe add step process produce process,issue,positive,positive,positive,positive,positive,positive
603196465,"> > @lissyx Thanks for reviewing my PR! I will fix these points. Please wait for a while.
> 
> Cool! If you feel like you want to try, you can add some TaskCluster build task. Otherwise, I can take care of that after.

@ryojiysd Nevermind, I'm starting the work on top of your PR. Just fix what I mentionned :)",thanks fix please wait cool feel like want try add build task otherwise take care starting work top fix,issue,positive,positive,positive,positive,positive,positive
603191774,"> @lissyx Thanks for reviewing my PR! I will fix these points. Please wait for a while.

Cool! If you feel like you want to try, you can add some TaskCluster build task. Otherwise, I can take care of that after.",thanks fix please wait cool feel like want try add build task otherwise take care,issue,positive,positive,positive,positive,positive,positive
603135068,@lissyx Thanks for reviewing my PR! I will fix these points. Please wait for a while.,thanks fix please wait,issue,positive,positive,positive,positive,positive,positive
603129896,@ryojiysd Could you fix the `pylint` error reported on Travis ?,could fix error travis,issue,negative,neutral,neutral,neutral,neutral,neutral
603096070,"Please use discourse for support. You dont need to build generate_trie, we already publish it in native_client.tar.xz. If you want to build it, please read correctly the doc and install the dependencies. ",please use discourse support dont need build already publish want build please read correctly doc install,issue,positive,neutral,neutral,neutral,neutral,neutral
603093082,That's the kind of nice gift I like to have when waking up. ,kind nice gift like waking,issue,positive,positive,positive,positive,positive,positive
602624045,"What do you think about two noise pipelines? One for the noise and one for cocktailparty speech. \
I thougth about mixing my files together into one pipeline, but i think it would be better to have seperate mixing parameters for noise and speech.  Mostly because you can mix the noise much louder than than the speech while keeping the text understandable.",think two noise one noise one speech together one pipeline think would better noise speech mostly mix noise much speech keeping text understandable,issue,negative,positive,positive,positive,positive,positive
602593576,"The repository from @tilmankamp (i think you ment [this](https://github.com/mozilla/oscarlm)) seems to be specifically for the OSCAR corpora. 

What about splitting the file into two scripts? One to download the english text corpus and the other to generate a language model out of a text file with sentences. This would be language/dataset independent then.",repository think specifically corpus splitting file two one text corpus generate language model text file would independent,issue,negative,neutral,neutral,neutral,neutral,neutral
602591307,">  If the maintainers prefer a PR against this repo with the types, that is also something I am open to doing.

Could you also explain more what are the requirements ?
Having some DeepSpeech-stuff in some third-party repo is not a good idea: we loose track of it, it will be outdated very quickly, etc.",prefer also something open could also explain good idea loose track outdated quickly,issue,negative,positive,positive,positive,positive,positive
602590334,"> I have added types for the DeepSpeech module v0.6.0 to [`DefinitelyTyped`](https://github.com/DefinitelyTyped/DefinitelyTyped).

Could you please give some context ?",added module could please give context,issue,negative,neutral,neutral,neutral,neutral,neutral
602580898,"@mathematiguy Hey I think this is fine, but it seems like there is now a bug in master related to the LM optimization. The return values from evaluate() in evaluate.py changed which breaks all the optimizer. So, I'm going to try and figure that out before landing this PR.",hey think fine like bug master related optimization return evaluate going try figure landing,issue,positive,positive,positive,positive,positive,positive
601848072,Looks like we can't expect ARM64 / ARMv7 images: https://issuetracker.google.com/issues/130023365,like ca expect arm,issue,negative,neutral,neutral,neutral,neutral,neutral
601458731,"> > @lissyx Should I delete line causing warning ` DeepSpeech.cs(114,20): warning CS0219: The variable 'exceptionMessage' is assigned but its value is never used [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]` ?
> > I think we can ignore this warning
> 
> That'd be my guess, but @carlfm01 is the real source of truth here.

Yes, this is no longer required.


And to convert Enums into ints please use `(int)errorCodes`. https://stackoverflow.com/questions/943398/get-int-value-from-enum-in-c-sharp

Please debug and make sure that the parsed errorCode is still the desired.",delete line causing warning warning variable assigned value never used think ignore warning guess real source truth yes longer convert please use please make sure still desired,issue,positive,positive,positive,positive,positive,positive
601187231,"> Ah, I missed that section, because I was looking for a way to build just the bindings, so I ignored the ""demo app"" section. Ignore me then.

I'm 100% open to improve the docs if I know the pain points :)",ah section looking way build section ignore open improve know pain,issue,negative,neutral,neutral,neutral,neutral,neutral
601184388,"Ah, I missed that section, because I was looking for a way to build just the bindings, so I ignored the ""demo app"" section. Ignore me then.",ah section looking way build section ignore,issue,negative,neutral,neutral,neutral,neutral,neutral
601181541,"> Oh, sorry, I missed your edit. Maybe add some documentation on how to build the Java bindings? Probably checked into the tree rather than just here on this issue. AFAIK currently you have to find out how to do it from the TaskCluster scripts.

Current doc already cover the `make apk`, what do you think is missing and requires looking into TC scripts ?",oh sorry edit maybe add documentation build probably checked tree rather issue currently find current doc already cover make think missing looking,issue,negative,negative,negative,negative,negative,negative
601172667,"Oh, sorry, I missed your edit. Maybe add some documentation on how to build the Java bindings? Probably checked into the tree rather than just here on this issue. AFAIK currently you have to find out how to do it from the TaskCluster scripts.",oh sorry edit maybe add documentation build probably checked tree rather issue currently find,issue,negative,negative,negative,negative,negative,negative
601170902,"> @lissyx ping re documentation for this. This will require significant changes to the bindings, so it'd be best if we landed it before 0.7.0.

Isn't my edit enough yet? Part of the issue is that's I'm very far from the Java world, I lack a good overview of everything that should be done differently :)",ping documentation require significant best landed edit enough yet part issue far world lack good overview everything done differently,issue,positive,positive,positive,positive,positive,positive
601160109,"@lissyx ping re documentation for this. This will require significant changes to the bindings, so it'd be best if we landed it before 0.7.0.",ping documentation require significant best landed,issue,positive,positive,positive,positive,positive,positive
601092310,"> Thank you to reply.
> That's right , but i'm not totally newbie. I understand almost.

Then why do you keep insisting reaching for support here instead of Discourse?",thank reply right totally understand almost keep reaching support instead discourse,issue,positive,positive,positive,positive,positive,positive
601091790,"Thank you to reply.
That's right , but i'm not totally newbie. I understand almost.
I collect character set in transcripts for making char2id and id2char.
When i use ""\s"" for different index almost the foremost index 2 and the last index. It seems to differ loss. So i asked.",thank reply right totally understand almost collect character set making use different index almost foremost index last index differ loss,issue,negative,positive,neutral,neutral,positive,positive
601071138,"> > > Hi, attached is my log. I'm using Ubuntu 18 and running deepspeech to train a zh-HK model. All my audio files and tsv files downloaded from cv is processed by import_cv2.py and i used the util/check_characters.py and added all characters to alpabet.txt, however, I still face the error as shown in my logs.txt
> > > [logs.txt](https://github.com/mozilla/DeepSpeech/files/4348652/logs.txt)
> > 
> > 
> > I don't see your command line pointing to a new alphabet file.
> 
> I've ran this again with --alphabet_config_path with logs as attached. Same problem...Attached also is the alphabet.txt that I used
> 
> [logs2.txt](https://github.com/mozilla/DeepSpeech/files/4348823/logs2.txt)
> 
> [alphabet.txt](https://github.com/mozilla/DeepSpeech/files/4348782/alphabet.txt)

```
I Loading most recent checkpoint from /home/chlinux/.local/share/deepspeech/checkpoints/train-0
```
Can you cleanup broken checkpoints please ?",hi attached log running train model audio used added however still face error shown see command line pointing new alphabet file ran attached problem attached also used loading recent cleanup broken please,issue,negative,negative,neutral,neutral,negative,negative
601070011,"> Hello. I'm newbie.
> I have question.

Being a newbie does not makes you unable to read and understand. Questions goes to Discourse.",hello question unable read understand go discourse,issue,negative,negative,negative,negative,negative,negative
600584836,"> > Hi, attached is my log. I'm using Ubuntu 18 and running deepspeech to train a zh-HK model. All my audio files and tsv files downloaded from cv is processed by import_cv2.py and i used the util/check_characters.py and added all characters to alpabet.txt, however, I still face the error as shown in my logs.txt
> > [logs.txt](https://github.com/mozilla/DeepSpeech/files/4348652/logs.txt)
> 
> I don't see your command line pointing to a new alphabet file.

I've ran this again with --alphabet_config_path with logs as attached. Same problem...Attached also is the alphabet.txt that I used

[logs2.txt](https://github.com/mozilla/DeepSpeech/files/4348823/logs2.txt)

[alphabet.txt](https://github.com/mozilla/DeepSpeech/files/4348782/alphabet.txt)

",hi attached log running train model audio used added however still face error shown see command line pointing new alphabet file ran attached problem attached also used,issue,negative,positive,positive,positive,positive,positive
600575185,"> Hi, attached is my log. I'm using Ubuntu 18 and running deepspeech to train a zh-HK model. All my audio files and tsv files downloaded from cv is processed by import_cv2.py and i used the util/check_characters.py and added all characters to alpabet.txt, however, I still face the error as shown in my logs.txt
> [logs.txt](https://github.com/mozilla/DeepSpeech/files/4348652/logs.txt)

I don't see your command line pointing to a new alphabet file. ",hi attached log running train model audio used added however still face error shown see command line pointing new alphabet file,issue,negative,positive,positive,positive,positive,positive
600537046,"> I just tried without filter alphabet and it works, the first time it doesn't, but it works now....thanks and sorry for the trouble...

Thanks, so there is no issue here? Let's close.",tried without filter alphabet work first time work thanks sorry trouble thanks issue let close,issue,negative,negative,neutral,neutral,negative,negative
600525610,"I just tried without filter alphabet and it works, the first time it doesn't, but it works now....thanks and sorry for the trouble...",tried without filter alphabet work first time work thanks sorry trouble,issue,negative,negative,neutral,neutral,negative,negative
600522135,"> sorry, the logs.txt is the one with the issue, tsv when converted to csv, there's no data in the csv file..

Have you tried without filter alphabet ? What alphabet did you use ?",sorry one issue converted data file tried without filter alphabet alphabet use,issue,negative,negative,negative,negative,negative,negative
600521561,"sorry, the logs.txt is the one with the issue, tsv when converted to csv, there's no data in the csv file..",sorry one issue converted data file,issue,negative,negative,negative,negative,negative,negative
600517672,"> @lissyx
> [logs.txt](https://github.com/mozilla/DeepSpeech/files/4347884/logs.txt)

So this is not the same execution as what you reported at first. Here there's an extra `--filter-alphabet`. Please be consistent. Can you extract a small subset that reproduces ?",execution first extra please consistent extract small subset,issue,negative,positive,neutral,neutral,positive,positive
600314365,"I thought I already tried that, but I checked it properly and you're right. Fixed!",thought already tried checked properly right fixed,issue,negative,positive,positive,positive,positive,positive
600309743,Thanks for the PR! If you reset the default graph with `tfv1.reset_default_graph()` before calling `evaluate` it should avoid the need for the reuse flags. Otherwise this is adding new ops to the graph on every call.,thanks reset default graph calling evaluate avoid need reuse otherwise new graph every call,issue,negative,positive,positive,positive,positive,positive
599951738,"Clone the repository instead of downloading a tarball, if that's what you've done.",clone repository instead done,issue,negative,neutral,neutral,neutral,neutral,neutral
599761872,@kdavis-mozilla any idea when will that be? or if there is any way to make a pretrained 0.6 model compatible with 0.7,idea way make model compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
599553712,"> > > RPi4 is faster than RPI3.
> > 
> > 
> > ok, but my device is nanopi-neo2 that is arm64 and core is arm a53. RPI4 core is arm a72. Maybe that's why it didnot run faster than real time on a single core.
> 
> Again, we documented on Github performances comparisions on several boards. ARMv7 vs ARM64 was not showing any impactful difference.
> 
> RPi4 is much faster than RPi3 as said, and that's why it is able to cope with realtime on our default model.

Got it. Thank you very much. ",faster device arm core arm core arm maybe run faster real time single core several arm showing difference much faster said able cope default model got thank much,issue,negative,positive,positive,positive,positive,positive
599543965,"> > RPi4 is faster than RPI3.
> 
> ok, but my device is nanopi-neo2 that is arm64 and core is arm a53. RPI4 core is arm a72. Maybe that's why it didnot run faster than real time on a single core.

Again, we documented on Github performances comparisions on several boards. ARMv7 vs ARM64 was not showing any impactful difference.

RPi4 is much faster than RPi3 as said, and that's why it is able to cope with realtime on our default model.",faster device arm core arm core arm maybe run faster real time single core several arm showing difference much faster said able cope default model,issue,negative,positive,positive,positive,positive,positive
599543179,"> RPi4 is faster than RPI3.

ok, but my device is nanopi-neo2 that is arm64 and core is arm a53. RPI4 core is arm a72.  Maybe that's why  it didnot run faster than real time on a single core.",faster device arm core arm core arm maybe run faster real time single core,issue,negative,positive,neutral,neutral,positive,positive
599538429,"> > @reuben i read your report [https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/](url) about ""DeepSpeech v0.6 with TensorFlow Lite runs faster than real time on a single core of a Raspberry Pi 4"", which confuses me a lot. Raspberry Pi 4 is arm64 and for 0.6.1, default runtime on ARM64 was NOT TFLite, but ARMv7 one was already TFLite. Can you tell me some details about your test? I will appreciate it for any help.
> 
> RPi4 is ARM64 but the binaries we produce, as documented, are made to be compatible with RPi3 and RPi4 **and** to run on Raspbian, which is NOT **ARM64**. Hence why we changed the default runtime to TFLite on ARMv7 much before changing it on ARM64.

Thank you, I see. I run RPI3 native client on arm64 successfully, but it didnot run faster than real time on a single core of arm64 board. It costs 11 seconds when processing 2.48 second audio. Why did this happen? ",read report lite faster real time single core raspberry pi lot raspberry pi arm default arm one already tell test appreciate help arm produce made compatible run arm hence default much arm thank see run native client arm successfully run faster real time single core arm board second audio happen,issue,positive,positive,positive,positive,positive,positive
599526393,"> @reuben i read your report [https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/](url) about ""DeepSpeech v0.6 with TensorFlow Lite runs faster than real time on a single core of a Raspberry Pi 4"", which confuses me a lot. Raspberry Pi 4 is arm64 and for 0.6.1, default runtime on ARM64 was NOT TFLite, but ARMv7 one was already TFLite. Can you tell me some details about your test? I will appreciate it for any help.

RPi4 is ARM64 but the binaries we produce, as documented, are made to be compatible with RPi3 and RPi4 **and** to run on Raspbian, which is NOT **ARM64**. Hence why we changed the default runtime to TFLite on ARMv7 much before changing it on ARM64.",read report lite faster real time single core raspberry pi lot raspberry pi arm default arm one already tell test appreciate help arm produce made compatible run arm hence default much arm,issue,positive,positive,positive,positive,positive,positive
599521126,"@reuben i read your report [https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/](url) about ""DeepSpeech v0.6 with TensorFlow Lite runs faster than real time on a single core of a Raspberry Pi 4"", which confuses me a lot. Raspberry Pi 4 is arm64 and for 0.6.1, default runtime on ARM64 was NOT TFLite, but ARMv7 one was already TFLite. Can you tell me some details about your test? I will appreciate it for any help. ",read report lite faster real time single core raspberry pi lot raspberry pi arm default arm one already tell test appreciate help,issue,positive,positive,neutral,neutral,positive,positive
599425835,"Update, specify the dbfs and S/R to determine the balance of audio/noise, and support csv files for cocktail party purpose.

* Now, we can select noise files by directory or csv files with `--audio_aug_mix_noise_train_dirs_or_files`, `--audio_aug_mix_noise_dev_dirs_or_files`, `--audio_aug_mix_noise_test_dirs_or_files` to validate how tough is the model defending noise.
* The final audio volume is random choosed between `--audio_aug_mix_noise_min_audio_dbfs` and `--audio_aug_mix_noise_max_audio_dbfs`
* The final noise volume is relatively determined by `--audio_aug_mix_noise_min_snr_db` and `--audio_aug_mix_noise_max_snr_db` and `target audio volume`.
* Use `--audio_aug_mix_noise_limit_audio_peak_dbfs` and `--audio_aug_mix_noise_limit_noise_peak_dbfs` to protect drastic volume variation, if we gain the volume only depends on `average` dbfs of the audio, the peak part of signal might be drastically over boosted.
* Use `--augmentation_review_audio_steps` to listen the augmented audio in `tensorboard`, but the tensorboard can only exhibit 10 audios in one panel, I don't know how to set it, and tensorboard always normalize the volume of dumped audio, no matter how low is the volume you dumped it, if `--summary_dir` is not specified, we can review the augmented audio in default directory:
```
tensorboard --logdir ~/.share/local/deepspeech/summaries/
```
* Do NOT use `--augmentation_review_audio_steps` with `spectrogram augmentation` in this commit, because this branch was based on a wrong spectrogram augmentation code, the process will not run correctly.

* An extreme Example to make sure your audio is mixed:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --dev_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --n_hidden 100 \
  --audio_aug_mix_noise_train_dirs_or_files <directory-path1>,<csv-path1>,<directory-path2> \
  --audio_aug_mix_noise_dev_dirs_or_files <directory-path1>,<csv-path1>,<directory-path2> \
  --audio_aug_mix_noise_test_dirs_or_files <directory-path1>,<csv-path1>,<directory-path2> \
  --audio_aug_mix_noise_min_snr_db 0.1 \
  --audio_aug_mix_noise_max_snr_db 0.2 \
  --audio_aug_mix_noise_min_audio_dbfs -0.2 \
  --audio_aug_mix_noise_max_audio_dbfs -0.1 \
  --audio_aug_mix_noise_limit_audio_peak_dbfs 100 \
  --audio_aug_mix_noise_limit_noise_peak_dbfs 100 \
  --augmentation_review_audio_steps 10 \
  ""$@""
```
* I set the default parameters for `non speech noise` environment, if we want to train the cocktail party environment, try decreasing the `--audio_aug_mix_noise_min_snr_db` and `--audio_aug_mix_noise_max_snr_db`.",update specify determine balance support cocktail party purpose select noise directory validate tough model noise final audio volume random final noise volume relatively determined target audio volume use protect drastic volume variation gain volume average audio peak part signal might drastically use listen augmented audio exhibit one panel know set always normalize volume audio matter low volume review augmented audio default directory use spectrogram augmentation commit branch based wrong spectrogram augmentation code process run correctly extreme example make sure audio mixed python set default non speech noise environment want train cocktail party environment try decreasing,issue,positive,negative,negative,negative,negative,negative
599420848,@liziru It will be made public when the 0.7.0 release is made public.,made public release made public,issue,negative,neutral,neutral,neutral,neutral,neutral
599160412,"This is awesome, thanks! I was just going to go about implementing my own :)
I'd like to give this a shot on my own model. It doesn't look like I need to recompile DS for this, correct?",awesome thanks going go like give shot model look like need recompile correct,issue,positive,positive,positive,positive,positive,positive
599160000,"> Like the PR I linked earlier was merged on january 17h so 0.7.0a0 includes it and it's still compatible with 0.6.1 model: https://github.com/mozilla/DeepSpeech/releases/tag/v0.7.0-alpha.0
> 
> > I plan to cross-compile c++ binary for v0.6.1 to support tflite runtime on arm64. Will it work?
> 
> Again, cross-compiling is documented but you would need to adapt the setup to target TFLite runtime. Please try and rely on 0.7.0a0 instead.

I tried 0.7.0a0 with v0.6.1 pbmm model and v0.6.1 tflite model. The test shows v0.7.0a0 doesnot support v0.6.1 tflite model. However, i remember that you told me on arm64 TFLite is the default engine besides v0.6.1 of arm64.",like linked still compatible model plan binary support arm work would need adapt setup target please try rely instead tried model model test support model however remember told arm default engine besides arm,issue,positive,neutral,neutral,neutral,neutral,neutral
599103139,"> Like the PR I linked earlier was merged on january 17h so 0.7.0a0 includes it and it's still compatible with 0.6.1 model: https://github.com/mozilla/DeepSpeech/releases/tag/v0.7.0-alpha.0
> 
> > I plan to cross-compile c++ binary for v0.6.1 to support tflite runtime on arm64. Will it work?
> 
> Again, cross-compiling is documented but you would need to adapt the setup to target TFLite runtime. Please try and rely on 0.7.0a0 instead.

well, I see. Thanks for your help.",like linked still compatible model plan binary support arm work would need adapt setup target please try rely instead well see thanks help,issue,positive,positive,positive,positive,positive,positive
599102966,"> > I see. I am sorry for my poor english. Thank you very much.
> 
> If my Chinese was as good as your English, I'd be proud.

haha, I can teach you chinese if you are interested.",see sorry poor thank much good teach interested,issue,positive,positive,neutral,neutral,positive,positive
599101933,"> I see. I am sorry for my poor english. Thank you very much.

If my Chinese was as good as your English, I'd be proud.",see sorry poor thank much good,issue,negative,negative,neutral,neutral,negative,negative
599101811,"Like the PR I linked earlier was merged on january 17h so 0.7.0a0 includes it and it's still compatible with 0.6.1 model: https://github.com/mozilla/DeepSpeech/releases/tag/v0.7.0-alpha.0



> I plan to cross-compile c++ binary for v0.6.1 to support tflite runtime on arm64. Will it work?

Again, cross-compiling is documented but you would need to adapt the setup to target TFLite runtime. Please try and rely on 0.7.0a0 instead.",like linked still compatible model plan binary support arm work would need adapt setup target please try rely instead,issue,positive,neutral,neutral,neutral,neutral,neutral
599101382,"> > @liziru Now if you look at the releases pages on Github, you can see we also have them: https://github.com/mozilla/DeepSpeech/releases
> 
> Thank you very much. It is very embarrassing that i cannot use tflite with v0.6.1 and cannot use v0.7.0 with no pre-trained model on arm64. I plan to cross-compile c++ binary for v0.6.1 to support tflite runtime on arm64. Will it work?

Or just pick one of the 0.7 alpha that was produced **after** I merged the switch to ARM64 to default to TFLite and before we changed the model ?",look see also thank much embarrassing use use model arm plan binary support arm work pick one alpha produced switch arm default model,issue,negative,positive,positive,positive,positive,positive
599099110,"> @liziru Now if you look at the releases pages on Github, you can see we also have them: https://github.com/mozilla/DeepSpeech/releases

Thank you very much. It is very embarrassing that i cannot use tflite with v0.6.1 and cannot use v0.7.0 with no pre-trained model on arm64. I plan to cross-compile c++ binary for v0.6.1 to support tflite runtime on arm64. Will it work?",look see also thank much embarrassing use use model arm plan binary support arm work,issue,negative,positive,positive,positive,positive,positive
599097836,I see. I am sorry for my poor english. Thank you very much.,see sorry poor thank much,issue,negative,negative,negative,negative,negative,negative
599096768,"> i have checked many issues but i didnot get answer. For example,
> 
> > @isjosan We have started experimenting with TFLite lib on other platforms, but it's still experimental. For example, you can find them on this link for your platform: https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.6.0-alpha.4/tflite
> 
> i cannot find anything through [https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.6.0-alpha.4/tflite](url).

This link is broken because TaskCluster infrastructure has been migrated.",checked many get answer example still experimental example find link platform find anything link broken infrastructure,issue,negative,positive,neutral,neutral,positive,positive
599095416,"> > Alpha versions don't have models. The 0.7.0 model with be released with the 0.7.0 release.
> 
> but i cannot find 0.7.0 model on [https://github.com/mozilla/DeepSpeech/releases](url) with 0.7.0 release. I can only find 0.6.1 model.

As @reuben said we don't yet have 0.7 compatible models.",alpha model release find model release find model said yet compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
599095263,"> ![image](https://user-images.githubusercontent.com/34911790/76686338-9cf86800-6655-11ea-9e5f-0d296efcdef5.png)

Could you please read the replies we are prividing ?",image could please read,issue,negative,neutral,neutral,neutral,neutral,neutral
599094693,"For 0.6.1, default runtime on ARM64 was NOT TFLite, but ARMv7 one was already TFLite.",default arm one already,issue,negative,neutral,neutral,neutral,neutral,neutral
599094425,"> Question: How can i use tflite on arm64? I will appreciate it if anyone can help me.

On ARM64, TFLite is the default engine.",question use arm appreciate anyone help arm default engine,issue,positive,neutral,neutral,neutral,neutral,neutral
599094102,"i have checked many issues but i didnot get answer.  For example, 

> @isjosan We have started experimenting with TFLite lib on other platforms, but it's still experimental. For example, you can find them on this link for your platform: https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.6.0-alpha.4/tflite

i cannot find anything through [https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.6.0-alpha.4/tflite](url).",checked many get answer example still experimental example find link platform find anything,issue,negative,positive,positive,positive,positive,positive
599089153,"> Alpha versions don't have models. The 0.7.0 model with be released with the 0.7.0 release.

but i cannot find 0.7.0 model on [https://github.com/mozilla/DeepSpeech/releases](url) with 0.7.0 release. I can only find 0.6.1 model. ",alpha model release find model release find model,issue,negative,neutral,neutral,neutral,neutral,neutral
599077124,@reuben where can i find 0.7.0 pre-trained model? I have searched for 0.7.0 pre-trained model for a long time. I will appreciate it for any help. ,find model model long time appreciate help,issue,positive,negative,neutral,neutral,negative,negative
599035458,"Ok, so it progressed since the last time: instance is able to pick up work. Now, runtime fails to find `nvcuda.dll`, so we will have to adapt `bootstrap.ps1`.",since last time instance able pick work find adapt,issue,negative,positive,positive,positive,positive,positive
598304646,"@lissyx For warning `DeepSpeech.cs(94,82): error CS1503: Argument 1: cannot convert from 'DeepSpeechClient.Enums.ErrorCodes' to 'int' [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]`

I think we are converting it to `NativeImp.DS_ErrorCodeToErrorMessage(resultCode).IntPtrToString()` 
",warning error argument convert think converting,issue,negative,neutral,neutral,neutral,neutral,neutral
598300593,"> @lissyx Should I delete line causing warning ` DeepSpeech.cs(114,20): warning CS0219: The variable 'exceptionMessage' is assigned but its value is never used [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]` ?
> 
> I think we can ignore this warning

That'd be my guess, but @carlfm01 is the real source of truth here.",delete line causing warning warning variable assigned value never used think ignore warning guess real source truth,issue,negative,positive,positive,positive,positive,positive
598299447,"@lissyx Should I delete line causing warning ` DeepSpeech.cs(114,20): warning CS0219: The variable 'exceptionMessage' is assigned but its value is never used [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]` ?

I think we can ignore this warning",delete line causing warning warning variable assigned value never used think ignore warning,issue,negative,neutral,neutral,neutral,neutral,neutral
598163636,"> Broken importers:
> 
> ```
> $ git grep multiprocessing.dummy bin/import_*
> bin/import_cv.py:from multiprocessing.dummy import Pool
> bin/import_cv2.py:from multiprocessing.dummy import Pool
> bin/import_lingua_libre.py:from multiprocessing.dummy import Pool
> bin/import_m-ailabs.py:from multiprocessing.dummy import Pool
> bin/import_slr57.py:from multiprocessing.dummy import Pool
> bin/import_vctk.py:from multiprocessing.dummy import Pool
> ```

All those importers are converted.",broken git import pool import pool import pool import pool import pool import pool converted,issue,negative,negative,negative,negative,negative,negative
598134979,I have manually ran all importers and verified the CSV files were populated with the same amount of data.,manually ran amount data,issue,negative,neutral,neutral,neutral,neutral,neutral
598134812,"This is based on #2816 

@rhamnett Can you give a look at the `VCTK` dataset part?",based give look part,issue,negative,neutral,neutral,neutral,neutral,neutral
597551299,"Broken importers:
```
$ git grep multiprocessing.dummy bin/import_*
bin/import_cv.py:from multiprocessing.dummy import Pool
bin/import_cv2.py:from multiprocessing.dummy import Pool
bin/import_lingua_libre.py:from multiprocessing.dummy import Pool
bin/import_m-ailabs.py:from multiprocessing.dummy import Pool
bin/import_slr57.py:from multiprocessing.dummy import Pool
bin/import_vctk.py:from multiprocessing.dummy import Pool
```",broken git import pool import pool import pool import pool import pool import pool,issue,negative,negative,negative,negative,negative,negative
597530139,"Quick test for importing ~10k WAV files:

Using `multiprocessing`:
```
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ time python bin/import_ts.py --validate_label_locale ~/tmp/ts2/fra.py ~/tmp/ts2/
Found archive ""/home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR.zip"" - not downloading.
Found directory ""/home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR.zip"" - not extracting it from archive.
Importing 10000 wav files...
Progress |###############################################################################################################################################################################################################################################################################################################################################################################| 100% completedImported 10000 samples.
Final amount of imported audio: 14:45:26.
Progress |###############################################################################################################################################################################################################################################################################################################################################################################| 100% completed

real    0m3,331s
user    1m11,980s
sys     3m26,484s
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ wc -l ~/tmp/ts2/ts_2019-04-11_fr_FR_{train,dev,test}.csv 
   8001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_train.csv
   1001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_dev.csv
   1001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_test.csv
  10003 total
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ find ~/tmp/ts2/ts_2019-04-11_fr_FR/ -type f -name ""*.converted.wav"" | wc -l
10000
```

Using `multiprocessing.dummy`:
```
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ time python bin/import_ts.py --validate_label_locale ~/tmp/ts2/fra.py ~/tmp/ts2/
Found archive ""/home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR.zip"" - not downloading.
Found directory ""/home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR.zip"" - not extracting it from archive.
Importing wav files...
Progress |############################################################################################################################################################################################################################################################################################################################################################################   |  99% completedImported 10000 samples.
Final amount of imported audio: 14:45:26.
Progress |###############################################################################################################################################################################################################################################################################################################################################################################| 100% completed

real    1m53,198s
user    1m28,254s
sys     18m18,999s
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ wc -l ~/tmp/ts2/ts_2019-04-11_fr_FR_{train,dev,test}.csv 
   8001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_train.csv
   1001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_dev.csv
   1001 /home/alexandre/tmp/ts2/ts_2019-04-11_fr_FR_test.csv
  10003 total
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ find ~/tmp/ts2/ts_2019-04-11_fr_FR/ -type f -name ""*.converted.wav"" | wc -l
10000
```",quick test time python found archive found directory archive progress final amount audio progress real user train dev test total find time python found archive found directory archive progress final amount audio progress real user train dev test total find,issue,positive,positive,positive,positive,positive,positive
597482072,"@alokprasad I'm still developing, there are still some issues now, please do not use the commit.

@DanBmh I will make the arguments also accept csv files for cocktail party purpose.

And about the augmentation pipelines, here is the data pipeline below
** `Current Pipeline` **
[noise] filename -> wav ↴
[ train ] filename -> wav -> `mixed audio`↴ -> spectrogram(aug) ↴-> mfcc(aug) -> input
[tensorboard] ___________________`audio review` _______ `approximate audio review`

** `Noise Aug Pipeline` **
[noise] filename -> wav -> spectrogram(aug) -> mfcc(aug)↴
[ train ]  filename -> wav -> spectrogram(aug) -> mfcc(aug) -> `mixed mfcc` -> input
[tensorboard]

This will cause several problems:
* With `Noise Aug Pipeline`, we have to prove the superposition between `audio` or `mfcc` are equivalent in math, or anyone knows the answer, please reply us.
* After spectrogram process, the signal phase term has been lost, if we want to reconstruct the audio back for reviewing purpose, the audio must sound awful (heavy distortion), which is also a major topic in TTS like tacotron, anyway, if we want to dump a clear audio out, `Current Pipeline` should be the best option.
* Continuing the last issue above, We can also augment `pitch`, `tempo` just in `wav process`, but `pitch code` would be quite different from `spectrogram_augmentations.py` and might cost large cpu computation during `prefetch phase` due to fft conversion.",still still please use commit make also accept cocktail party purpose augmentation data pipeline current pipeline noise train mixed audio spectrogram input audio review approximate audio review noise pipeline noise spectrogram train spectrogram mixed input cause several noise pipeline prove superposition audio equivalent math anyone answer please reply u spectrogram process signal phase term lost want reconstruct audio back purpose audio must sound awful heavy distortion also major topic like anyway want dump clear audio current pipeline best option last issue also augment pitch tempo process pitch code would quite different might cost large computation phase due conversion,issue,positive,positive,neutral,neutral,positive,positive
597024905,"What do you think about using a csv file (formatted like the training csv files) as input instead of a directory. I think in this way you could:
- Use the augmentation features from the training pipeline also with your noise pipeline
- Use the speech data instead of the noise data (cocktail party background noise)
- Maybe use both of the above pipelines for augmentation",think file like training input instead directory think way could use augmentation training pipeline also noise pipeline use speech data instead noise data cocktail party background noise maybe use augmentation,issue,positive,neutral,neutral,neutral,neutral,neutral
597014399,"There's also a warning:
```
  DeepSpeech.cs(114,20): warning CS0219: The variable 'exceptionMessage' is assigned but its value is never used [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]
```",also warning warning variable assigned value never used,issue,negative,neutral,neutral,neutral,neutral,neutral
597011519,"@imskr Please have a look at the `Community-TC` task group, there are Windows builds failures such as: https://community-tc.services.mozilla.com/tasks/RHRIhwl4R4aL6w_hnG_LAw/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FRHRIhwl4R4aL6w_hnG_LAw%2Fruns%2F0%2Fartifacts%2Fpublic%2Flogs%2Flive.log#L7776",please look task group,issue,negative,neutral,neutral,neutral,neutral,neutral
596993872,"@mychiux413 is this the change that calculates SNR and adjust gain? 
https://github.com/mozilla/DeepSpeech/pull/2622/commits/2269514a9ef676100b46f0c99c0e6a7150feb4dd 
How is the audio generated , did u got chance to see using tf.print outputstream option.",change adjust gain audio got chance see option,issue,positive,neutral,neutral,neutral,neutral,neutral
596984334,"> @lissyx docs where I will make changes are in doc directory right?

Yeah, but you might want to verify everywhere, just in case.",make doc directory right yeah might want verify everywhere case,issue,negative,positive,positive,positive,positive,positive
596983833,Closing for lack of actionability and reporter not giving feedback.,lack reporter giving feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
596983508,"> It’s especially bad if you’re training on the cloud and paying by the hour.

Hm, that's not a use-case we experiment a lot, but maybe people are more affected than us for this specific need.

@dabinat do you want / have the time to send a patch ?",especially bad training cloud paying hour experiment lot maybe people affected u specific need want time send patch,issue,negative,negative,negative,negative,negative,negative
596955479,"> Sorry for being dense, but I am running into the same confusion with the README. Steps to recreate:
> 
>     1. clone master
> 
>     2. follow instructions in readme in master
> 
>     3. receive above error message
> 
> 
> It seems that the master documentation says to install with pip, which then installs something other than the master branch? Launching python in my venv I see:
> 
> ```python
> [GCC 5.4.0 20160609] on linux
> Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
> >>> import deepspeech
> >>> deepspeech.printVersions()
> TensorFlow: v1.14.0-21-ge77504a
> DeepSpeech: v0.6.1-0-g3df20fe```
> ```

Well this is default pip behavior, it installs stable builds by default. ",sorry dense running confusion recreate clone master follow master receive error message master documentation install pip something master branch python see python type help copyright license information import well default pip behavior stable default,issue,negative,negative,negative,negative,negative,negative
596941008,"> Also, since there are checkpoints, is this really a big deal ? It would restart from it, wouldn't it ?

Yeah, it’s not a huge problem, but it can be frustrating if you start it training, go away for a while, come back and discover that a bunch of time was wasted because it stopped due to an error. It’s especially bad if you’re training on the cloud and paying by the hour.",also since really big deal would restart would yeah huge problem start training go away come back discover bunch time wasted stopped due error especially bad training cloud paying hour,issue,negative,negative,negative,negative,negative,negative
596846950,"Sorry for being dense, but I am running into the same confusion with the README. Steps to recreate:
1) clone master
2) follow instructions in readme in master
3) receive above error message

It seems that the master documentation says to install with pip, which then installs something other than the master branch? Launching python in my venv I see:

```Python 3.5.2 (default, Oct  8 2019, 13:06:37)
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import deepspeech
>>> deepspeech.printVersions()
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.1-0-g3df20fe```",sorry dense running confusion recreate clone master follow master receive error message master documentation install pip something master branch python see python default type help copyright license information import,issue,negative,negative,negative,negative,negative,negative
596830250,@lissyx docs where I will make changes are in doc directory right? ,make doc directory right,issue,negative,positive,positive,positive,positive,positive
596680788,"> @lissyx sorry for the confusion. You mentioned earlier to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure. So this PR is good according to the issue. I was asking should I create new PR for docs reference?

Yes, please.",sorry confusion update return zero success failure refer error code structure good according issue create new reference yes please,issue,positive,positive,neutral,neutral,positive,positive
596672961,"@lissyx sorry for the confusion. You mentioned earlier to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure. So this PR is good according to the issue. I was asking should I create new PR for docs reference?",sorry confusion update return zero success failure refer error code structure good according issue create new reference,issue,negative,positive,neutral,neutral,positive,positive
596648822,"> > > > @lissyx Where should I make changes for the doc? And should I open new PR for the doc?
> > > 
> > > 
> > > Which doc changes ?
> > > Those ?:
> > > > @imskr I'm not sure we should do that in this bug or file a followup to address, but once this is live, we might want to take the opportunity to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure.
> > 
> > 
> > Yes
> 
> @lissyx Doc updation?

Sorry but I still dont know what you are referring to. Please be precise, there are many context-dependant discussions around doc her.",make doc open new doc doc sure bug file address live might want take opportunity update return zero success failure refer error code structure yes doc sorry still dont know please precise many around doc,issue,positive,positive,positive,positive,positive,positive
596213353,"> > > @lissyx Where should I make changes for the doc? And should I open new PR for the doc?
> > 
> > 
> > Which doc changes ?
> > Those ?:
> > > @imskr I'm not sure we should do that in this bug or file a followup to address, but once this is live, we might want to take the opportunity to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure.
> 
> Yes

@lissyx Doc updation? ",make doc open new doc doc sure bug file address live might want take opportunity update return zero success failure refer error code structure yes doc,issue,positive,positive,positive,positive,positive,positive
595951287,"If your goal is to optimize, removing apt cache and others as well as bazel cache and build artifacts will improve a lot. ",goal optimize removing apt cache well cache build improve lot,issue,positive,positive,positive,positive,positive,positive
595950036,"I understand the goal, I also want to make sure this is not going to break users. ",understand goal also want make sure going break,issue,negative,positive,positive,positive,positive,positive
595946504,"overall aim is to reduce the package number , download time and size in both the Docker image and reduce the size and fetch time of the image",overall aim reduce package number time size docker image reduce size fetch time image,issue,negative,neutral,neutral,neutral,neutral,neutral
595945783,"i added ""ca-certificates"" , as wget , curl or even git throws certificate error without this .",added curl even git certificate error without,issue,negative,neutral,neutral,neutral,neutral,neutral
595943298,"> > > debconf: delaying package configuration, since apt-utils is not installed
> > 
> > 
> > This ? I'm not sure it's really slowing us.
> 
> yes , it takes time while configuring pakages if ""apt-utils"" is not installed .

I'm far from being convinced it's really a huge impact, most of the build time is spent on TensorFlow side anyway.",delaying package configuration since sure really u yes time far convinced really huge impact build time spent side anyway,issue,positive,positive,positive,positive,positive,positive
595942493,"> > debconf: delaying package configuration, since apt-utils is not installed
> 
> This ? I'm not sure it's really slowing us.

yes , it takes time while configuring pakages if ""apt-utils"" is  not installed .",delaying package configuration since sure really u yes time,issue,positive,positive,positive,positive,positive,positive
595942021,"> debconf: delaying package configuration, since apt-utils is not installed

This ? I'm not sure it's really slowing us.",delaying package configuration since sure really u,issue,negative,positive,positive,positive,positive,positive
595940617,"> Because build is
> 
>     1. Slow and in log it is showing because ""apt-utils"" not installed
> 
>     2. to avoid build to exits with error without having certificate

Can you elaborate?",build slow log showing avoid build error without certificate elaborate,issue,negative,positive,neutral,neutral,positive,positive
595926312,"> > @lissyx Where should I make changes for the doc? And should I open new PR for the doc?
> 
> Which doc changes ?
> 
> Those ?:
> 
> > @imskr I'm not sure we should do that in this bug or file a followup to address, but once this is live, we might want to take the opportunity to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure.

Yes",make doc open new doc doc sure bug file address live might want take opportunity update return zero success failure refer error code structure yes,issue,positive,positive,positive,positive,positive,positive
595903945,"> Done with current language model it lm_alpha=0.931289039105002, lm_beta=1.1834137581510284

Was produced with your pending optimizer PR? ",done current language model produced pending,issue,negative,neutral,neutral,neutral,neutral,neutral
595896028,"Done with current language model it lm_alpha=0.931289039105002, lm_beta=1.1834137581510284",done current language model,issue,negative,neutral,neutral,neutral,neutral,neutral
595894887,"> @lissyx Where should I make changes for the doc? And should I open new PR for the doc?

Which doc changes ? 


Those ?:
> @imskr I'm not sure we should do that in this bug or file a followup to address, but once this is live, we might want to take the opportunity to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure.",make doc open new doc doc sure bug file address live might want take opportunity update return zero success failure refer error code structure,issue,negative,positive,positive,positive,positive,positive
595890674,@lissyx Where should I make changes for the doc? And should I open new PR for the doc?,make doc open new doc,issue,negative,positive,neutral,neutral,positive,positive
595876102,"Code finished, waiting on review of PR 2783",code finished waiting review,issue,negative,neutral,neutral,neutral,neutral,neutral
595839027,This could be a good first bug: I guess a way to do that would be to just early-initialize a `Scorer` and leave it to exception system if it's not being provided proper arguments.,could good first bug guess way would scorer leave exception system provided proper,issue,negative,positive,positive,positive,positive,positive
595764423,"> I guess I should wait on the review until you've added in Reuben's suggestions

You can go ahead, I've implemented those :)",guess wait review added go ahead,issue,negative,neutral,neutral,neutral,neutral,neutral
595754997,I guess I should wait on the review until you've added in Reuben's suggestions,guess wait review added,issue,negative,neutral,neutral,neutral,neutral,neutral
595752000,"> > 
> 
> As long as we check in the files they should still have the correct line endings on all platforms, no?

Ok, I better understand what you mean here. Why not, then.",long check still correct line better understand mean,issue,negative,positive,neutral,neutral,positive,positive
595749697,"> I was unsure about that, the combination of codecs.open + manual [:-1] I thought you had somethign specific in mind :)

Just an oversight. And maybe also related to Python 2 + 3 support. I don't remember.

> I actually think that for unit tests, it's better not to. This way, people can run them locally and be assured it won't shit in their desktop :)

As long as we check in the files they should still have the correct line endings on all platforms, no? And by overriding the behavior we risk testing something that's not actually what Python is doing. I don't know, I'm just deeply suspicious of mocking after seeing how badly it can fail in Gaia.",unsure combination manual thought specific mind oversight maybe also related python support remember actually think unit better way people run locally assured wo long check still correct line behavior risk testing something actually python know deeply suspicious seeing badly fail,issue,negative,negative,neutral,neutral,negative,negative
595748285,"But Eren has told me that TensorBoard logging causes significant file system issues in the cluster, so I'm a bit cautious of increasing our logging there.",told logging significant file system cluster bit cautious increasing logging,issue,negative,positive,positive,positive,positive,positive
595748191,"> Finally, maybe a cleaner fix instead of removing the endings with str.replace would be using `open(..., encoding='utf8')` instead of `codecs.open`, which does newline normalization.

I was unsure about that, the combination of `codecs.open` + manual `[:-1]` I thought you had somethign specific in mind :)



> Can't you use the public encode/decode API to test this? To avoid touching private methods.

On the Alphabet object? Yeah, it should work.



> Also, can't we check in actual test files into the tree to avoid the mocking magic?

I actually think that for unit tests, it's better not to. This way, people can run them locally and be assured it won't shit in their desktop :)",finally maybe cleaner fix instead removing would open instead normalization unsure combination manual thought specific mind ca use public test avoid touching private alphabet object yeah work also ca check actual test tree avoid magic actually think unit better way people run locally assured wo,issue,negative,positive,positive,positive,positive,positive
595748018,"It's still disabled by default, the only thing that changed is we have a finer trained loss progression graph (per step). We can share that, provided it was saved in the recent training runs, but ideally we need to add more useful information to diagnose training runs.",still disabled default thing finer trained loss progression graph per step share provided saved recent training ideally need add useful information diagnose training,issue,positive,positive,positive,positive,positive,positive
595743240,"Closing this since this is not a bug. Please next time, go to Discourse for support.",since bug please next time go discourse support,issue,positive,neutral,neutral,neutral,neutral,neutral
595742673,"@reuben I think this was improved, maybe we could ship them now ?",think maybe could ship,issue,negative,neutral,neutral,neutral,neutral,neutral
595742349,@JinZhuXing #2813 will make sure people producing alphabet on one system and using it on another won't get into troubles.,make sure people alphabet one system another wo get,issue,negative,positive,positive,positive,positive,positive
595677466,"@JinZhuXing Just removing `CRLF` line ending was enough. Training is only tested / supported on Linux so far, as documented. Looks like this was prepared on a Windows system to be with `CRLF` line endings.",removing line ending enough training tested far like prepared system line,issue,positive,positive,neutral,neutral,positive,positive
595652320,"> > > > > > @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
> > > > > 
> > > > > 
> > > > > Uploaded.
> > > > > [alphabet_20200214.zip](https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip)
> > > > 
> > > > 
> > > > This does not include the transcript. Please, share debuggable data.
> > > 
> > > 
> > > Uploaded transcript.
> > > [zh-cn_trans.zip](https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip)
> > 
> > 
> > Ok, looking at your alphabet file there are **three** occurrences of `母`. Now I have no knowledge of `zh-cn` locale, but I suspect this is not expected.
> 
> I just removed two '母‘ characters at alphabet file. But the same error occur.

Could you please work on a reduced test case that reproduces the issue ?
99.999% of the time, those bugs are dataset-side.",could post transcript include transcript please share data transcript looking alphabet file three knowledge locale suspect removed two alphabet file error occur could please work reduced test case issue time,issue,negative,neutral,neutral,neutral,neutral,neutral
595544028,"> > > > > @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
> > > > 
> > > > 
> > > > Uploaded.
> > > > [alphabet_20200214.zip](https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip)
> > > 
> > > 
> > > This does not include the transcript. Please, share debuggable data.
> > 
> > 
> > Uploaded transcript.
> > [zh-cn_trans.zip](https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip)
> 
> Ok, looking at your alphabet file there are **three** occurrences of `母`. Now I have no knowledge of `zh-cn` locale, but I suspect this is not expected.

I just removed two '母‘ characters at alphabet file. But the same error occur.",could post transcript include transcript please share data transcript looking alphabet file three knowledge locale suspect removed two alphabet file error occur,issue,negative,neutral,neutral,neutral,neutral,neutral
595462052,"Checkpoints don't have a fixed batch size. You should be able to continue training with a different batch size. You can also just re-export with the same checkpoint you used but using --export_batch_size 1 to get a model that works with your clients.

",fixed batch size able continue training different batch size also used get model work,issue,negative,positive,positive,positive,positive,positive
595461133,"> Thanks for the help! Looks like I need to completely retrain since my checkpoints are of a different shape now. Anyways to still use my old checkpoints?

I have not checked but it should be okay to just re-export without this argument. Pass checkpoint dur, no train, dev nor test csv arguments and `--load best ` that should suffice ",thanks help like need completely retrain since different shape anyways still use old checked without argument pas train dev test load best suffice,issue,positive,positive,positive,positive,positive,positive
595457547,Thanks for the help! Looks like I need to completely retrain since my checkpoints are of a different shape now. Anyways to still use my old checkpoints?,thanks help like need completely retrain since different shape anyways still use old,issue,positive,positive,neutral,neutral,positive,positive
595348797,"> > > > @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
> > > 
> > > 
> > > Uploaded.
> > > [alphabet_20200214.zip](https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip)
> > 
> > 
> > This does not include the transcript. Please, share debuggable data.
> 
> Uploaded transcript.
> 
> [zh-cn_trans.zip](https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip)

Ok, looking at your alphabet file there are **three** occurrences of `母`. Now I have no knowledge of `zh-cn` locale, but I suspect this is not expected.",could post transcript include transcript please share data transcript looking alphabet file three knowledge locale suspect,issue,negative,neutral,neutral,neutral,neutral,neutral
595343793,I will sort it yeah but I'll take @tilmankamp's advice,sort yeah take advice,issue,negative,neutral,neutral,neutral,neutral,neutral
595340841,"I'd put it on hold till #2723 lands, as it'd have to be re-implemented completely. ",put hold till completely,issue,negative,positive,neutral,neutral,positive,positive
595339338,"@rhamnett Should be a fairly easy PR, do you want to try ?",fairly easy want try,issue,negative,positive,positive,positive,positive,positive
595068333,"BTW this is not a bug, please reach for support on Discourse. You can also find inspiration in https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train and https://github.com/MozillaItalia/DeepSpeech-Italian-Model",bug please reach support discourse also find inspiration,issue,positive,neutral,neutral,neutral,neutral,neutral
595068052,"> Hi, I have a pretty decent sized dataset for Spanish, about 350,000 clips (5-10 seconds each). I want to go ahead and train the DeepSpeech Repo. I have been sifting through Issues for ours but I have not been able to find any concrete step-by-step procedure on how to proceed with the training for a language other than English. Could anyone please outline the steps I would need to follow to train DeepSpeech for Spanish. Thanks!

What is unclear with ? https://github.com/mozilla/DeepSpeech/blob/master/doc/TRAINING.rst",hi pretty decent sized clip want go ahead train sifting able find concrete procedure proceed training language could anyone please outline would need follow train thanks unclear,issue,positive,positive,positive,positive,positive,positive
594916082,"> Can we uninstall this version and install the 0.6.1 version of it independently

`pip uninstall ds_ctcdecoder` then follow the docs: `pip install $(python util/taskcluster.py --decoder)`",version install version independently pip follow pip install python,issue,negative,neutral,neutral,neutral,neutral,neutral
594861401,"its 
pip list | grep ds-ctcdecoder
ds-ctcdecoder        0.7.0a2

//Number of argument does match your error: it's likely you are calling a post-0.6.1 ds_ctcdecoder using v0.6.1 signature.
seems correct .

Can we uninstall this version and install the 0.6.1 version of it independently ",pip list argument match error likely calling signature correct version install version independently,issue,negative,neutral,neutral,neutral,neutral,neutral
594859301,"> ```
> 
> ```
> 
> 
> So it seems to me like it's saying that a network trained on a batch size greater than 1 cannot infer for a single audio file.

Current `libdeepspeech` can only perform one batch inference.


> --export_batch_size $batch_size \

Just remove that.",like saying network trained batch size greater infer single audio file current perform one batch inference remove,issue,positive,positive,positive,positive,positive,positive
594858162,"> Perhaps if the user has specified the test pass it should check the scorer is correct at startup?

Might be a good idea.


> This also only occurs at the end of training, so you have to wait for training to complete before realizing you haven't installed the scorer.

Also, since there are checkpoints, is this really a big deal ? It would restart from it, wouldn't it ?",perhaps user test pas check scorer correct might good idea also end training wait training complete realizing scorer also since really big deal would restart would,issue,negative,positive,positive,positive,positive,positive
594849161,"> --utf8? --because by default its false ,we want to use this mode ..is there something wrong ?

Have you read what that flag does ?

> Could you share what commit is your HEAD and what version of ds_ctcdecoder is installed ?
> git branch
> master
> 
>     * r0.6.1
> 
> 
> git rev-parse --short HEAD
> [3df20fe](https://github.com/mozilla/DeepSpeech/commit/3df20fee52fda47d08e3726fd0da86dbb414e9d8)

You have not documented `ds_ctcdecoder` version.",default false want use mode something wrong read flag could share commit head version git branch master git short head version,issue,negative,negative,negative,negative,negative,negative
594848484,"> Please, update the main README then: https://github.com/mozilla/DeepSpeech

The master README refers to master branch, and it is accurate.",please update main master master branch accurate,issue,negative,positive,positive,positive,positive,positive
594843737,"> > version: r0.6.1
> 
> Are you sure about that ?

We just checkout this branch from v0.6.1 tag",version sure branch tag,issue,negative,positive,positive,positive,positive,positive
594835103,"--utf8? --because  by default its false  ,we want to use this mode ..is there something wrong ?
Could you share what commit is your HEAD and what version of ds_ctcdecoder is installed ?
git branch
  master
* r0.6.1

git rev-parse --short HEAD
3df20fee",default false want use mode something wrong could share commit head version git branch master git short head,issue,negative,negative,negative,negative,negative,negative
594829959,"There is no bug here, just read the appropriate documentation.",bug read appropriate documentation,issue,negative,positive,positive,positive,positive,positive
594825844,"`v0.6.1` `Scorer.__init__()`: https://github.com/mozilla/DeepSpeech/blob/v0.6.1/native_client/ctcdecode/__init__.py#L19
`master` `Scorer.__init__()`: https://github.com/mozilla/DeepSpeech/blob/master/native_client/ctcdecode/__init__.py#L19

Number of argument does match your error: it's likely you are calling a post-0.6.1 `ds_ctcdecoder` using `v0.6.1` signature.",master number argument match error likely calling signature,issue,negative,neutral,neutral,neutral,neutral,neutral
594823775,">   File ""/mnt/e/IBEX/SpecialProjects/deepspeech/DeepSpeech/evaluate.py"", line 48, in evaluate
>     Config.alphabet)

@humayunzaee Could you share what commit is your `HEAD` and what version of `ds_ctcdecoder` is installed ?",file line evaluate could share commit head version,issue,positive,neutral,neutral,neutral,neutral,neutral
594762633,Yes. I think we can make the necessary changes and for docs make another PR maybe. ,yes think make necessary make another maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
594761193,"@imskr I'm not sure we should do that in this bug or file a followup to address, but once this is live, we might want to take the opportunity to update all docs references of ""return zero on success non-zero on failure"" to refer to error code structure.",sure bug file address live might want take opportunity update return zero success failure refer error code structure,issue,negative,positive,positive,positive,positive,positive
594359155,"@alokprasad 
* For current version, The parameters `--audio_aug_mix_noise_max_noise_db -5`, `--audio_aug_mix_noise_min_noise_db -35`, `--audio_aug_mix_noise_max_audio_db 5`, `
--audio_aug_mix_noise_min_audio_db -10` could get a good result for me.
* Yes, use SNR should be more stable, but considering the performance, I would try to cache every single speech/noise file's DBFS at the beginning, thus we don't have to recalculate every DBFS for each training step to estimate SNR.
* Furthermore, I want to add options to mix `dev/test noises` into `dev/test files`, I think it could indicate how strong is the model defending noise instead of just testing clean speech data, also to make sure the model doesn't overfit the specific noise environment. (note: `dev/test noise dir` should be different to `train noise dir`).",current version could get good result yes use stable considering performance would try cache every single file beginning thus recalculate every training step estimate furthermore want add mix think could indicate strong model noise instead testing clean speech data also make sure model overfit specific noise environment note noise different train noise,issue,positive,positive,positive,positive,positive,positive
594244717,"Thanks! It works if specify
```
$ pip3 install deepspeech==0.7.0a2
```
... or rather I'm onto some other bug. Thanks for your help!",thanks work specify pip install rather onto bug thanks help,issue,positive,positive,positive,positive,positive,positive
594242623,"Yep, try `pip3 install deepspeech==0.7`",yep try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
594239561,"Oh I see. Is there a way to install the newest version of deepspeech then? ""pip3 install deepspeech"" seems to install 0.6.1
",oh see way install version pip install install,issue,negative,neutral,neutral,neutral,neutral,neutral
594238244,"I am having this same issue. I have trained a model. I now what to test it on such an audio file, but get this error. The DeepSpeech I installed is up to date:
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.1-0-g3df20fe
So is the github documentation under ""transcribe an audio file"" out of date?
https://github.com/mozilla/DeepSpeech",issue trained model test audio file get error date documentation transcribe audio file date,issue,negative,neutral,neutral,neutral,neutral,neutral
594057403,"Recent changes:

- `read_buffer` flag
- tower and batch-size dependent ahead-processing of samples (high performance impact)
- re-basing fix: refactored `wav_filename` to `sample_id` in `feeding.py`",recent flag tower dependent high performance impact fix,issue,negative,positive,neutral,neutral,positive,positive
594023111,"My new commits should solve your requested changes.

I also added some statistics about the input file:

```
Calculating word statistics ...
  Your text file has 803288729 words in total
  It has 973673 unique words
  Your top-500000 words are 99.9354 percent of all words
  Your most common word ""the"" occurred 49059384 times
  The least common word in your top-k is ""corders"" with 2 times
  The first word with 3 occurrences is ""zungwan"" at place 420186

```",new solve also added statistic input file calculating word statistic text file total unique percent common word time least common word time first word place,issue,negative,negative,neutral,neutral,negative,negative
593741159,"> > > @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
> > 
> > 
> > Uploaded.
> > [alphabet_20200214.zip](https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip)
> 
> This does not include the transcript. Please, share debuggable data.

Uploaded transcript.

[zh-cn_trans.zip](https://github.com/mozilla/DeepSpeech/files/4279001/zh-cn_trans.zip)
",could post transcript include transcript please share data transcript,issue,positive,neutral,neutral,neutral,neutral,neutral
593698456,"@imskr 
Should be something like :

```

[DllImport(""libdeepspeech.so"", CallingConvention = CallingConvention.Cdecl)]
        internal unsafe static extern IntPtr DS_ErrorCodeToErrorMessage(int aErrorCode);
```

then when you call DS_ErrorCodeToErrorMessage : 



` return DS_ErrorCodeToErrorMessage(erroCode).IntPtrToString();`



",something like internal unsafe static extern call return,issue,negative,positive,positive,positive,positive,positive
593478424,"For .NET in nativeimp.cs do i add this for DS_ErrorCodeToErrorMessage?

```
[DllImport(""libdeepspeech.so"", CallingConvention = CallingConvention.Cdecl)]
        internal unsafe static extern ErrorCodes DS_ErrorCodeToErrorMessage(int aErrorCode,
                   ref IntPtr** pint);
```
",add internal unsafe static extern ref pint,issue,negative,positive,positive,positive,positive,positive
593454036,"> > @JinZhuXing Could you post the transcript of common_voice_zh-CN_18782225.wav and your data/alphabet.txt?
> 
> Uploaded.
> 
> [alphabet_20200214.zip](https://github.com/mozilla/DeepSpeech/files/4204035/alphabet_20200214.zip)

This does not include the transcript. Please, share debuggable data.",could post transcript include transcript please share data,issue,positive,neutral,neutral,neutral,neutral,neutral
593448817,"> > OK, I will test with vanilla Python.
> > Thanks, all of you.
> 
> @JinZhuXing Any update ?

It's the same. I can't do it.
So I will try with english dataset.
Thanks.",test vanilla python thanks update ca try thanks,issue,positive,positive,positive,positive,positive,positive
593437459,"> Make use you have run `export LC_ALL=""en_US.UTF-8""` in your runtime for Python to handle unicode.

Same error.",make use run export python handle error,issue,negative,neutral,neutral,neutral,neutral,neutral
593359317,"> Ah, OK. The first comment talked about importers so I thought that's what this was about. Ignore my comment!

My goal is to ensure people try and stay as close as possible of our upstream. Having to fork for some kind of feature like that makes it easier for people to think ""we already have a fork, we can hack this and that"" and we end up with bugs from unknown states.",ah first comment thought ignore comment goal ensure people try stay close possible upstream fork kind feature like easier people think already fork hack end unknown,issue,positive,positive,positive,positive,positive,positive
593316543,@zhangpengk You already received help on Discourse for that. Please act and void opening issues when there is no bug.,already received help discourse please act void opening bug,issue,positive,neutral,neutral,neutral,neutral,neutral
593302271,"Ah, OK. The first comment talked about importers so I thought that's what this was about. Ignore my comment!",ah first comment thought ignore comment,issue,negative,positive,positive,positive,positive,positive
593300688,"> I think if we do this we should have a more flexible API than just `validate_label`, so new importers are able to use building blocks from previous importers, even if their requirements aren't the same. For example the ""text cleaners"" stuff in TTS where you can pass a list of cleaners, which are small passes over data that do a single transform, and they're applied in order.

I think importers should stay dumb as they are, and that the consistency problem should be addressed at locale-level, without forking DeepSpeech repo: a new-locale specific `validate_label` that would be defined and living in locale's repo.",think flexible new able use building previous even example text stuff pas list small data single transform applied order think stay dumb consistency problem without specific would defined living locale,issue,negative,negative,neutral,neutral,negative,negative
593298494,"@imskr You could, instead of throwing an exception with only the error code
```python
        status, impl = deepspeech.impl.CreateModel(model_path)
        if status != 0:
            raise RuntimeError(""CreateModel failed with error code 0x{:X}"".format(status))
```
throw an exception with the error code and textual description. Something like
```python
        status, impl = deepspeech.impl.CreateModel(model_path)
        if status != 0:
            status_message = deepspeech.impl.ErrorCodeToErrorMessage(status)
            raise RuntimeError(""CreateModel failed with error message {} with error code 0x{:X}"".format(status_message, status))
```",could instead throwing exception error code python status status raise error code status throw exception error code textual description something like python status status status raise error message error code status,issue,negative,neutral,neutral,neutral,neutral,neutral
593295270,"I think if we do this we should have a more flexible API than just `validate_label`, so new importers are able to use building blocks from previous importers, even if their requirements aren't the same. For example the ""text cleaners"" stuff in TTS where you can pass a list of cleaners, which are small passes over data that do a single transform, and they're applied in order.",think flexible new able use building previous even example text stuff pas list small data single transform applied order,issue,negative,positive,neutral,neutral,positive,positive
593291299,"For the [CorporaCreator](https://github.com/mozilla/CorporaCreator) I did something like this
```python
    def _preprocessor_wrapper(self, client_id, sentence, up_votes, down_votes):
        preprocessor = getattr(
            preprocessors, self.locale.replace(""-"", """")
        )  # Get locale specific preprocessor
        sentence = preprocessor(client_id, sentence)
        if None == sentence or not sentence.strip():
            up_votes = 0
            down_votes = 2
        return pd.Series([sentence, up_votes, down_votes])
```
where the ```preprocessors``` module has a preprocessor for each locale.",something like python self sentence get locale specific sentence sentence none sentence return sentence module locale,issue,positive,neutral,neutral,neutral,neutral,neutral
593227375,"@mychiux413 one suggestion , i think it would be better to check SNR during training if its too bad 
dynamic adjust the DBFS so that gain of noise is not too much that it hides speech signal.",one suggestion think would better check training bad dynamic adjust gain noise much speech signal,issue,positive,positive,neutral,neutral,positive,positive
592929576,"Make use you have run `export LC_ALL=""en_US.UTF-8""` in your runtime for Python to handle unicode.",make use run export python handle,issue,negative,neutral,neutral,neutral,neutral,neutral
592648197,"Should I remove the `raise` statement and add the `DS_ErrorCodeToErrorMessage` function [here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/__init__.py#L37-L39) ?
Having little confusion how do i use the `DS_ErrorCodeToErrorMessage` in `__init__.py` although i have added it in `impli.i` @reuben ",remove raise statement add function little confusion use although added,issue,negative,negative,negative,negative,negative,negative
592509131,@stuclearmob Could you please answer our questions regarding batch size ?,could please answer regarding batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
592432061,@ykhemanth @Juanvulcano @YagoRegis Can you give a try to #2802 ? Especially check on your side if it does not slow down training.,give try especially check side slow training,issue,negative,negative,negative,negative,negative,negative
592427686,"@imskr you don't need to duplicate the list of errors anywhere. Just make sure whenever we report errors, instead of just showing the error number we also include a textual description by calling the new function you added in #2794.",need duplicate list anywhere make sure whenever report instead showing error number also include textual description calling new function added,issue,negative,positive,positive,positive,positive,positive
592101093,@reuben In python: Do I have to add all types of errors mentioned in API  in `__init__` function of both `Model` and `Stream` class [here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/__init__.py) ?,python add function model stream class,issue,negative,neutral,neutral,neutral,neutral,neutral
592064350,"> > Thanks, this is a discussion we already had and the outcome was that this would add too much complexity.
> 
> I don't think i added much complexity. Only the possibility to use your own txt.file with sentences. And i added some command line arguments for customization.

I'm not judging, I'm reporting status of discussions on the exact same feature since I did it for french.",thanks discussion already outcome would add much complexity think added much complexity possibility use added command line status exact feature since,issue,negative,positive,positive,positive,positive,positive
592062018,"> Thanks, this is a discussion we already had and the outcome was that this would add too much complexity.

I don't think i added much complexity. Only the possibility to use your own txt.file with sentences. And i added some command line arguments for customization.",thanks discussion already outcome would add much complexity think added much complexity possibility use added command line,issue,negative,positive,positive,positive,positive,positive
592052353,"Thanks, this is a discussion we already had and the outcome was that this would add too much complexity. ",thanks discussion already outcome would add much complexity,issue,negative,positive,positive,positive,positive,positive
592030842,"> > > This in an update from #2799.
> > > I setup CUDA correctly but it is still failing with the same error code.
> > > How can I see the WER of my model?
> > 
> > 
> > Insisting is not going to get your more support, just make people loose time and don't want to help you.
> 
> How is it insisting if the issue was closed?

It was closed because it was not a bug. You obviously did not read the documentation nor the issue template for opening an issue without properly setting up CUDA as documented. As @dabinat mentionned, `git-lfs` is also covered.

> I can understand that insisting is annoying if the issue is open but I followed what you said and the issue was not solved. Not too sure if people check the closed issues.

Until proven otherwise, this is not a bug. Please discuss on Discourse.

> 
> Thanks for assisting guys.

",update setup correctly still failing error code see wer model going get support make people loose time want help issue closed closed bug obviously read documentation issue template opening issue without properly setting also covered understand annoying issue open said issue sure people check closed proven otherwise bug please discus discourse thanks,issue,negative,negative,neutral,neutral,negative,negative
592026871,"> > This in an update from #2799.
> > I setup CUDA correctly but it is still failing with the same error code.
> > How can I see the WER of my model?
> 
> Insisting is not going to get your more support, just make people loose time and don't want to help you.

How is it insisting if the issue was closed?
I can understand that insisting is annoying if the issue is open but I followed what you said and the issue was not solved. Not too sure if people check the closed issues. 

Thanks for assisting guys.",update setup correctly still failing error code see wer model going get support make people loose time want help issue closed understand annoying issue open said issue sure people check closed thanks,issue,negative,negative,neutral,neutral,negative,negative
592022006,The reason for this error is that you haven’t downloaded the scorer. You need to install git-lfs and do git-lfs pull to download it.,reason error scorer need install pull,issue,negative,neutral,neutral,neutral,neutral,neutral
592021634,"> Looks like is might be related to the new code [feeding.py#L34](https://github.com/mozilla/DeepSpeech/blob/46e7993075f5ad64fde193465c05dab3b405a776/util/feeding.py#L34) comparing a zero dimensional Tensor of type int32 with an int.

Indeed, and even in CI we see it. I'm wondering if @reuben and myself did not got tricked when we made / reviewed this pathc.",like might related new code zero dimensional tensor type indeed even see wondering got made,issue,negative,positive,neutral,neutral,positive,positive
592019441,"@Juanvulcano Please join efforts and rely on https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/Dockerfile.train as other communities does (https://github.com/MozillaItalia/DeepSpeech-Italian-Model), this will avoid you loosing time on that. ",please join rely avoid loosing time,issue,negative,neutral,neutral,neutral,neutral,neutral
592018289,"> This in an update from #2799.
> I setup CUDA correctly but it is still failing with the same error code.
> How can I see the WER of my model?

Insisting is not going to get your more support, just make people loose time and don't want to help you.",update setup correctly still failing error code see wer model going get support make people loose time want help,issue,negative,negative,neutral,neutral,negative,negative
592004580,">  Could not load dynamic library

Please properly setup CUDA.",could load dynamic library please properly setup,issue,positive,neutral,neutral,neutral,neutral,neutral
591996905,Looks like is might be related to the new code [feeding.py#L34](https://github.com/mozilla/DeepSpeech/blob/46e7993075f5ad64fde193465c05dab3b405a776/util/feeding.py#L34) comparing a zero dimensional Tensor of type int32 with an int.,like might related new code zero dimensional tensor type,issue,negative,positive,neutral,neutral,positive,positive
591951121,"> **GPU model and memory**: T4 NVIDIA

This is not hardware we tested. https://www.nvidia.com/en-us/data-center/tesla-t4/
Can you please share more logs to make sure that TensorFlow GPU CUDA does support this ?

Also, please refrain from using `sudo`.",model memory hardware tested please share make sure support also please refrain,issue,positive,positive,positive,positive,positive,positive
591886305,"> @lissyx and @kdavis-mozilla if you could review the docs in particular, see if there's anything missing. Not just in the context of this PR but also in making this clear and correct for 0.7. The built docs should be ready shortly from TaskCluster.

I've setup it online for easing reviews: https://ds-test-reuben.readthedocs.io/en/multiple_transcriptions/",could review particular see anything missing context also making clear correct built ready shortly setup easing,issue,positive,positive,neutral,neutral,positive,positive
591853132,"The default train, dev, and test batch sizes are all 1, see [flags.py#L73](https://github.com/mozilla/DeepSpeech/blob/master/util/flags.py#L73). As you don't explicitly set the train, dev, or test batch sizes, they are all 1.

To better utilize your GPU your batch size should be made larger than 1. How much larger is dependent on your data and your GPU's memory.",default train dev test batch size see explicitly set train dev test batch size better utilize batch size made much dependent data memory,issue,negative,positive,positive,positive,positive,positive
591581637,"> there are people like you that have no problems with 7.5,

I thought I was on 7.5, but it looks like I got tricked.",people like thought like got,issue,positive,neutral,neutral,neutral,neutral,neutral
591575326,"@lissyx It's hard to conclude anything. While the Tensorflow docs says almost nothing about TF 1.15 compatibility with CUDA and cudNN, there are people like you that have no problems with 7.5, and other people like me and @dabinat  who had to upgrade cudnn to use it. ",hard conclude anything almost nothing compatibility people like people like upgrade use,issue,negative,negative,negative,negative,negative,negative
591522455,"@lissyx and @kdavis-mozilla if you could review the docs in particular, see if there's anything missing. Not just in the context of this PR but also in making this clear and correct for 0.7. The built docs should be ready shortly from TaskCluster.",could review particular see anything missing context also making clear correct built ready shortly,issue,negative,positive,neutral,neutral,positive,positive
591499151,"Yes I would like to take this, thanks. ",yes would like take thanks,issue,positive,positive,positive,positive,positive,positive
591484365,"@imskr thanks for the interest! I guess in order to avoid duplicated work, it's better to wait until 0.7 is out before working on this. Then we'll make a new branch on the examples repository for 0.7 and this work can happen there. I'll ping you here once that happens :)",thanks interest guess order avoid work better wait working make new branch repository work happen ping,issue,positive,positive,positive,positive,positive,positive
591472517,"The second part of this issue is making sure our bindings in the tree use the new API. There are four bindings in the three:

  - Python: [native_client/python](../tree/master/native_client/python)
  - JavaScript: [native_client/javascript](../tree/master/native_client/javascript)
  - .NET: [native_client/dotnet](../tree/master/native_client/dotnet)
  - Java: [native_client/java](../tree/master/native_client/java)

Here's a rough idea for how to do this for each one of them:

  - Python: in the object oriented wrapper classes ([code here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/__init__.py)), add checks around every fallible API call as well as using the message strings when raising an exception instead of using the numeric code. You'll also have to add the new function to the list [here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/impl.i#L77-L82) to make sure the strings are deallocated.
  - JavaScript: same as above. Wrapper classes are [here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/index.js), list of functions that return newly allocated strings is [here](https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/deepspeech.i#L34-L39).
  - .NET: already has its own handling, which was used as the source for the textual descriptions. Needs to be updated to use the new API. The new function needs to be added in [NativeImp.cs](https://github.com/mozilla/DeepSpeech/blob/master/native_client/dotnet/DeepSpeechClient/NativeImp.cs), and then it can be used from [DeepSpeech.EvaluateResultCode](https://github.com/mozilla/DeepSpeech/blob/a9e72eb1520a19457be967f38aec56480756185e/native_client/dotnet/DeepSpeechClient/DeepSpeech.cs#L86-L125).
  - Java: function has to be added to the list [here](https://github.com/mozilla/DeepSpeech/blob/a9e72eb1520a19457be967f38aec56480756185e/native_client/java/jni/deepspeech.i#L45-L47). Actually using it is part of a separate issue, #2701.

@imskr are you interested in also taking on this part?",second part issue making sure tree use new four three python rough idea one python object wrapper class code add around every fallible call well message raising exception instead code also add new function list make sure wrapper class list return newly already handling used source textual need use new new function need added used function added list actually part separate issue interested also taking part,issue,positive,positive,positive,positive,positive,positive
591394265,@imskr please return a copy of the string using `strdup` and change the documentation accordingly to mention that people should use `DS_FreeString` on the returned pointer.,please return copy string change documentation accordingly mention people use returned pointer,issue,negative,neutral,neutral,neutral,neutral,neutral
591320416,"Yeah it's not ideal.

But having this mixed API where some strings need to be freed with
```c++
DS_FreeString()
```
and some strings do not need to be freed with
```c++
DS_FreeString()
```
is also not ideal as it's confusing.

As for Case1, your example is true of _very_ simply programs and applications, but for production integrations, think a GUI based application, you would never just exit if someone encountered a `DS_ERR_INVALID_ALPHABET` error. You'd ""catch"" the error and present them with a dialog to specify a correct alphabet file.",yeah ideal mixed need freed need freed also ideal case example true simply production think based application would never exit someone error catch error present specify correct alphabet file,issue,positive,positive,positive,positive,positive,positive
591310849,"Ah, OK. Sorry, I misunderstood your other comment.",ah sorry misunderstood comment,issue,negative,negative,negative,negative,negative,negative
591310453,"Nope, just let me some time and I'll document thoroughly ",nope let time document thoroughly,issue,negative,neutral,neutral,neutral,neutral,neutral
591309400,"> I think I got lurred and mixed with another good first bug where you did it :/

So should the tags be removed from this issue?",think got mixed another good first bug removed issue,issue,negative,positive,positive,positive,positive,positive
591308351,"Granted, this is also true for `DS_Version` where we went with that approach. Maybe consistency is worth the awkwardness cost, specially since most of our language bindings abstract this away.",also true went approach maybe consistency worth awkwardness cost specially since language abstract away,issue,negative,positive,positive,positive,positive,positive
591307386,"Returning an allocated copy is unfortunate in this case because for getting the error string there are basically two main cases:

Case 1, abort entire program:
```c++
int err = DS_SomeAPI();
if (err != 0) {
    fprintf(stderr, ""DeepSpeech error: %s\n"", DS_ErrorCodeToErrorString(err));
    exit(1);
}
```

In this case freeing the string is pointless since you're `exit`-ing anyway.

Case 2, error propagation:
```c++
int err = DS_SomeAPI();
if (err != 0) {
    char* ds_copy = DS_ErrorCodeToErrorMessage(err);
    char* our_copy = strdup(ds_copy); // caller shouldn't have to know about DS API
    DS_FreeString(ds_copy);
    return MyErrorAbstraction(STT_ERROR, our_copy);
}
```

In this case, if we allocate the error string, we force applications to immediately copy it again with their own allocator, or we force them to include custom allocator/deleter support in their error abstraction, because otherwise some caller far away is going to have to know about `DS_FreeString`. Whereas a const C string can be propagated without this problem:

```c++
int err = DS_SomeAPI();
if (err != 0) {
    return MyErrorAbstraction(STT_ERROR, DS_ErrorCodeToErrorMessage(err));
}
```",copy unfortunate case getting error string basically two main case abort entire program err err error err exit case freeing string pointless since exit anyway case error propagation err err char err char caller know return case allocate error string force immediately copy allocator force include custom support error abstraction otherwise caller far away going know whereas string without problem err err return err,issue,negative,negative,neutral,neutral,negative,negative
591304827,We need to ping @est31 and @asticode who will have some work on that as well.,need ping work well,issue,negative,neutral,neutral,neutral,neutral,neutral
591297001,"@reuben @imskr Note that the way these strings are created, in static memory and _not_ the heap, contradicts with the documentation of [`DS_FreeString()`](https://github.com/mozilla/DeepSpeech/blob/master/native_client/deepspeech.h#L285) which says that it is used to ""Free a `char*` string returned by the DeepSpeech API"".

People will likely not catch this subtle difference and try to call [`DS_FreeString()`](https://github.com/mozilla/DeepSpeech/blob/master/native_client/deepspeech.h#L285) on strings returned from this function.",note way static memory heap documentation used free char string returned people likely catch subtle difference try call returned function,issue,positive,positive,positive,positive,positive,positive
591216375,"@mychiux413 , i figured that out, btw what DBFS you think might be good for running training on rnnoise after normalizing.",figured think might good running training,issue,negative,positive,positive,positive,positive,positive
590998290,"> For some reason there's no mention of recommended versions for 1.15 [here](https://www.tensorflow.org/install/source#linux). But if you assume nothing changed between 1.14 and 2.0, it should be cuDNN 7.4, not 7.5. So the dependencies for 0.6 were already contrary to what was recommended on the Tensorflow site.

And yet, NVIDIA's docker is on 7.6 as well: https://gitlab.com/nvidia/container-images/cuda/-/blob/ubuntu18.04/10.0/runtime/cudnn7/Dockerfile

@dabinat I guess it's such a mess we might as well update the docs to 7.5 ?",reason mention assume nothing already contrary site yet docker well guess mess might well update,issue,negative,negative,negative,negative,negative,negative
590994631,"The C language standard does not guarantee the underlying size of an enum, so we could end up with nasty ABI compatibility issues due to compiler mismatches. `int` is safer in that regard.",language standard guarantee underlying size could end nasty compatibility due compiler regard,issue,negative,negative,negative,negative,negative,negative
590966677,"@reuben @lissyx Shouldn't be the argument of function
 ```cpp
char* DS_ErrorCodeToErrorMessage(int aErrorCode); 
```
be 
 ```cpp
char* DS_ErrorCodeToErrorMessage(DeepSpeech_Error_Codes aErrorCode); 
```
As in `deepspeech.h`  error codes are in  `enum DeepSpeech_Error_Codes`",argument function char char error,issue,negative,neutral,neutral,neutral,neutral,neutral
590865099,"> @lissyx if this is a good first bug it should probably include an explanation here of what's missing and how to go at fixing it.

I think I got lurred and mixed with another good first bug where you did it :/",good first bug probably include explanation missing go fixing think got mixed another good first bug,issue,positive,positive,positive,positive,positive,positive
590862450,@lissyx if this is a good first bug it should probably include an explanation here of what's missing and how to go at fixing it.,good first bug probably include explanation missing go fixing,issue,negative,positive,positive,positive,positive,positive
590832053,"I'm building on this branch to get it to a landable state (docs, bindings, etc), and using the opportunity to polish the metadata API naming a bit. I'll make a PR once everything is set up. Thanks a lot for the PR @dabinat!",building branch get state opportunity polish naming bit make everything set thanks lot,issue,positive,positive,positive,positive,positive,positive
590807548,"All of the validations we're talking about will be done on the ""model repository"" side. The discussion here is about the guidelines in the help text and default file that's generated.",talking done model repository side discussion help text default file,issue,negative,neutral,neutral,neutral,neutral,neutral
590752408,"> Perhaps it’s better to let users put whatever they want...

Are you referring to a specific field or are you making the suggestion that the meta data should be completely unstructured text or are you making the suggestion that each existing field should not be validated?",perhaps better let put whatever want specific field making suggestion meta data completely text making suggestion field,issue,negative,positive,positive,positive,positive,positive
590723642,"@alokprasad To prevent this, I just repeat the noise file to make the duration over than speech file,
this might make some `continuous environment noise`(like street) audio have `discontinuous points`, but most of the time, it wont happen, because `bin/normalize_noise_audio.py` can split noise files into 30s around or even longer.

And an another repeat reason is, some of `point source noise`(like bell) files are short, but they are OK to be repeated.",prevent repeat noise file make duration speech file might make continuous environment noise like street audio discontinuous time wont happen split noise around even longer another repeat reason point source noise like bell short repeated,issue,positive,neutral,neutral,neutral,neutral,neutral
590697062,"@mychiux413 How are you handling case , if Noise file len is less than speech file len.?
",handling case noise file le speech file,issue,negative,neutral,neutral,neutral,neutral,neutral
590642659,"Perhaps it’s better to let users put whatever they want and do the validation on the server end when submitting a model to the store? This feature may be useful for adding metadata even for people not using the model store, so it would be great to not impose too many strict store-specific restrictions. 

So maybe it’s better to have the help text suggest sensible data formats but not aggressively validate them.",perhaps better let put whatever want validation server end model store feature may useful even people model store would great impose many strict maybe better help text suggest sensible data aggressively validate,issue,positive,positive,positive,positive,positive,positive
590583617,"Sorry, it's late, that's not what I meant to send. I've been following the Ubuntu instructions here[0] which also say 7.6. Maybe it changed at some point between 1.15.0 and today? TensorFlow 1.15 was released full of documentation issues so it's hard to tell.

https://web.archive.org/web/20191223214017/https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_10
[0] https://web.archive.org/web/20191223214017/https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_10


> On 24 Feb 2020, at 23:10, Reuben Morais <notifications@github.com> wrote:
> 
> ﻿https://github.com/mozilla/tensorflow/blob/r1.15/configure.py#L36-L39
> 
> 
> > On 24 Feb 2020, at 19:45, lissyx <notifications@github.com> wrote:
> > 
> > ﻿
> > So the dependencies for 0.6 were already contrary to what was recommended on the Tensorflow site.
> > 
> > Exactly for that reason that we wanted to avoid replicating TensorFlow website. I still think 0.6 dep change was a result of the same feedback as yours.
> > 
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub, or unsubscribe.
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",sorry late meant send following also say maybe point today full documentation hard tell wrote wrote already contrary site exactly reason avoid still think change result feedback thread reply directly view thread reply directly view,issue,negative,negative,neutral,neutral,negative,negative
590574599,"https://github.com/mozilla/tensorflow/blob/r1.15/configure.py#L36-L39


> On 24 Feb 2020, at 19:45, lissyx <notifications@github.com> wrote:
> 
> ﻿
> So the dependencies for 0.6 were already contrary to what was recommended on the Tensorflow site.
> 
> Exactly for that reason that we wanted to avoid replicating TensorFlow website. I still think 0.6 dep change was a result of the same feedback as yours.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",wrote already contrary site exactly reason avoid still think change result feedback thread reply directly view,issue,negative,positive,positive,positive,positive,positive
590487438,"> So the dependencies for 0.6 were already contrary to what was recommended on the Tensorflow site.

Exactly for that reason that we wanted to avoid replicating TensorFlow website. I still think 0.6 dep change was a result of the same feedback as yours.",already contrary site exactly reason avoid still think change result feedback,issue,negative,positive,positive,positive,positive,positive
590479122,"For some reason there's no mention of recommended versions for 1.15 [here](https://www.tensorflow.org/install/source#linux). But if you assume nothing changed between 1.14 and 2.0, it should be cuDNN 7.4, not 7.5. So the dependencies for 0.6 were already contrary to what was recommended on the Tensorflow site.",reason mention assume nothing already contrary site,issue,negative,neutral,neutral,neutral,neutral,neutral
590457767,I'm using 7.5 successfully. The source of truth we are referring to should be tensorflow website anyway.,successfully source truth anyway,issue,positive,positive,positive,positive,positive,positive
590437229,"Adding `const` to the parameter is a relaxation of the constraints from the user's perspective. It would help catch *our* broken code, but not broken user code. User code is already prevented from writing into our data anyway because it's an opaque pointer so there's nothing to write to. I'll add it since it doesn't hurt anyway.",parameter relaxation user perspective would help catch broken code broken user code user code already writing data anyway opaque pointer nothing write add since hurt anyway,issue,negative,negative,negative,negative,negative,negative
590433903,"> There's no added type safety, taking a const pointer there would literally be just documentation for humans.

Which is still good :)



> Applications can't see the contents of a ModelState, so even if we changed the contents, they wouldn't be able to see it.

Enforcing `const` could always help catching broken code trying to write into our data?",added type safety taking pointer would literally documentation still good ca see content even content would able see could always help catching broken code trying write data,issue,positive,positive,positive,positive,positive,positive
590333308,"> I would like to work on this issue!

You should have all the informations requires already here. Please feel free to ask for clarification if required.",would like work issue already please feel free ask clarification,issue,positive,positive,positive,positive,positive,positive
590286385,I would like to work on this issue! ,would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
590281552,"We're going to have a Mozilla ML website, a Jekyll GitHub page, and as part of that we will have a model repository where internal and external models can be advertised. Adding a model will essentially be submitting a PR with the .md generated by this code.",going page part model repository internal external model essentially code,issue,negative,neutral,neutral,neutral,neutral,neutral
590278773,"> @lissyx The idea is to use Jekyll [collections](https://jekyllrb.com/docs/collections/). (The file generated by the PR's code would be the analog of the `jane.md` file in the example on the linked page.)

What would be the use-case here ?",idea use file code would file example linked page would,issue,negative,neutral,neutral,neutral,neutral,neutral
590278193,@lissyx The idea is to use Jekyll [collections](https://jekyllrb.com/docs/collections/). (The file generated by the PR's code would be the analog of the `jane.md` file in the example on the linked page.),idea use file code would file example linked page,issue,negative,neutral,neutral,neutral,neutral,neutral
590270777,Wouldn't we want that kind of metadata to be easily parsable by a machine? And thus use a higher-level description than just `markdown` ?,would want kind easily parsable machine thus use description markdown,issue,positive,positive,positive,positive,positive,positive
590265586,"Example output:

```
---
author: author
model_name: model
model_version: 1
contact_info: <public contact information of the author. Free form, could be an email address, a repository URL, a company website, etc.>
license: <license of the exported model>
language: <language the model was trained on - IETF BCP 47 language tag, e.g. ""de-DE"" or ""zh-cmn-Hans-CN"">
runtime: tensorflow
min_ds_version: <minimum DeepSpeech version (inclusive) the exported model is compatible with>
max_ds_version: <maximum DeepSpeech version (inclusive) the exported model is compatible with>
acoustic_model_url: <replace this with a publicly available URL of the acoustic model>
scorer_url: <replace this with a publicly available URL of the scorer, if present>
---
<Freeform description of the model being exported. Markdown accepted. You can also leave this flag unchanged and edit the generated .md file directly. Useful things to describe are demographic and acoustic characteristics of the data used to train the model, any architectural changes, names of public datasets that were used when applicable, hyperparameters used for training, evaluation results on standard benchmark datasets, etc.>
```",example output author author model public contact information author free form could address repository company license license model language language model trained language tag minimum version inclusive model compatible maximum version inclusive model compatible replace publicly available acoustic model replace publicly available scorer present description model markdown accepted also leave flag unchanged edit file directly useful describe demographic acoustic data used train model architectural public used applicable used training evaluation standard,issue,positive,positive,positive,positive,positive,positive
590249351,"@kdavis-mozilla @lissyx Just to be clear, my point about ModelState being an opaque pointer is that it is not possible to ""surprise"" API users. Applications can't see the contents of a ModelState, so even if we changed the contents, they wouldn't be able to see it. There's no added type safety, taking a const pointer there would literally be just documentation for humans.",clear point opaque pointer possible surprise ca see content even content would able see added type safety taking pointer would literally documentation,issue,positive,positive,positive,positive,positive,positive
590241894,"> Sorry for the delay @lissyx I will be making a PR. What I have done now is added `darwin-amd64-ctc-opt` and `linux-amd64-ctc-opt` in `python` list of `scriptworker-task-github`. Am I doing right?

You forgot to add the dependencies as I stated :/",sorry delay making done added python list right forgot add stated,issue,negative,negative,negative,negative,negative,negative
590220242,"> ModelState is an opaque pointer so I don't understand what difference that makes in practice. Communicating to the API consumer that the function is read only?

I'd guess this is the major win, communicating to the API consumer that this function does not modify ModelState. People tend to ignore documentation, but they can't ignore the compiler.

> It would be preferable if the DS_Version function did not allocate. There is no need for it, if it's documented that the result doesn't have to and must not be freed.

I agree with this. It seems like you could just return a const pointer to a string literal. 

However, this brings up another problem in that all the other returned strings are allocated and this ""version string"" would be the only one that is _not_ allocated, which will likely cause people (who generally do not read the documentation) to try and deallocate it and cause a crash.

So maybe it's better just to keep DS_Version as it is.",opaque pointer understand difference practice communicating consumer function read guess major win communicating consumer function modify people tend ignore documentation ca ignore compiler would preferable function allocate need result must freed agree like could return pointer string literal however another problem returned version string would one likely cause people generally read documentation try cause crash maybe better keep,issue,positive,positive,positive,positive,positive,positive
590218732,"> > The DS_GetModelBeamWidth function could take a const pointer instead of a mutable one ( DS_GetModelSampleRate has this issue too btw)
> 
> ModelState is an opaque pointer so I don't understand what difference that makes in practice. Communicating to the API consumer that the function is read only? Isn't it enough to document it?

We all know people don't read the documentation. Passing that information to the compiler could be useful, indeed.



> I was concerned about wrong `free()` usage but also users trying to modify read only memory and causing weird crashes. I guess we can try no allocation in 0.7.0 and see if any reports pop up. @lissyx thoughts?

:+1: ",function could take pointer instead mutable one issue opaque pointer understand difference practice communicating consumer function read enough document know people read documentation passing information compiler could useful indeed concerned wrong free usage also trying modify read memory causing weird guess try allocation see pop,issue,negative,negative,neutral,neutral,negative,negative
590204808,"> ModelState is an opaque pointer so I don't understand what difference that makes in practice. Communicating to the API consumer that the function is read only? Isn't it enough to document it?

Hmm it seems I can make non-mutable wrapper functions so it seems there is no immediate need for me to have const wrappers.

> I was concerned about wrong free() usage but also users trying to modify read only memory and causing weird crashes.

You have a point, the new API is probably more obvious. It's not really important, both choices are okay.",opaque pointer understand difference practice communicating consumer function read enough document make wrapper immediate need concerned wrong free usage also trying modify read memory causing weird point new probably obvious really important,issue,negative,negative,neutral,neutral,negative,negative
590195623,"> The DS_GetModelBeamWidth function could take a const pointer instead of a mutable one ( DS_GetModelSampleRate has this issue too btw)

ModelState is an opaque pointer so I don't understand what difference that makes in practice. Communicating to the API consumer that the function is read only? Isn't it enough to document it?

> It would be prefferable if the DS_Version function did not allocate. There is no need for it, if it's documented that the result doesn't have to and must not be freed.

I was concerned about wrong `free()` usage but also users trying to modify read only memory and causing weird crashes. I guess we can try no allocation in 0.7.0 and see if any reports pop up. @lissyx thoughts?

> Overall, the changes were really good, especially that the beam width is now stored with the model. This makes usage much easier. Thanks for doing this!

Thanks for updating the Rust bindings \o/",function could take pointer instead mutable one issue opaque pointer understand difference practice communicating consumer function read enough document would function allocate need result must freed concerned wrong free usage also trying modify read memory causing weird guess try allocation see pop overall really good especially beam width model usage much easier thanks thanks rust,issue,positive,positive,neutral,neutral,positive,positive
590118425,"The 0.7.0 checkpoint will NOT work with the DeepSpeech 0.6.1 training graph, and the 0.7.0 model will NOT work with the DeepSpeech 0.6.1 clients.",work training graph model work,issue,negative,neutral,neutral,neutral,neutral,neutral
590113658,Is it already known if the 0.7.0 model will work with deepspeech 0.6.1 and other way around?,already known model work way around,issue,negative,neutral,neutral,neutral,neutral,neutral
590037459,"Thanks and apologies again. 

Sent from Yahoo Mail on Android 
 
  On Sun, 23 Feb 2020 at 2:26, Francis Tyers<notifications@github.com> wrote:   
Dear @doclr, this is indeed the wrong place. But thank you for getting in contact. The right place to take this up is probably on Disource. I've taken the liberty of creating a new topic there for the discussion. @kdavis-mozilla please feel free to delete these two comments.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.
  
",thanks sent yahoo mail android sun wrote dear indeed wrong place thank getting contact right place take probably taken liberty new topic discussion please feel free delete two reply directly view,issue,positive,positive,positive,positive,positive,positive
590034783,"The problem is that tf.data.Dataset is built with streaming to be able to handle very large datasets so it has no `__len__`. We could compute a number ourselves but it requires reimplementing (and keeping in sync) any tf.data logic that changes the length, like `filter` or the `drop_remainder` argument of some batching/windowing APIs.",problem built streaming able handle large could compute number keeping sync logic length like filter argument,issue,negative,positive,positive,positive,positive,positive
590019313,"Dear @doclr, this is indeed the wrong place. But thank you for getting in contact. The right place to take this up is probably on [Disource](https://discourse.mozilla.org/c/deep-speech/247). I've taken the liberty of creating a [new topic](https://discourse.mozilla.org/t/healthcare-application-for-deepspeech/54556) there for the discussion. @kdavis-mozilla please feel free to delete these two comments.",dear indeed wrong place thank getting contact right place take probably taken liberty new topic discussion please feel free delete two,issue,positive,positive,neutral,neutral,positive,positive
590008685,"Hi. Please excuse my complete lack of experience as I am a doctor not a coder. I would like to know whether this language model could be used for healthcare application in speech recognition? All the healthcare related software is closed source and very expensive eg. Dragon. I wonder if deepspeech will be a way forward for open source software for this.

Do you think there is anyone at Mozilla interested in something like this. 

I apologise if this is the wrong place to ask this question. 

Sorry",hi please excuse complete lack experience doctor coder would like know whether language model could used application speech recognition related closed source expensive dragon wonder way forward open source think anyone interested something like wrong place ask question sorry,issue,positive,negative,negative,negative,negative,negative
589971438,Sorry for the delay @lissyx I will be making a PR. What I have done now is added `darwin-amd64-ctc-opt` and `linux-amd64-ctc-opt`  in `python` list of `scriptworker-task-github`. Am I doing right?,sorry delay making done added python list right,issue,negative,negative,negative,negative,negative,negative
589961593,"I could not check it with updated version... Will update it by a day

On Sat, 22 Feb, 2020, 7:51 PM lissyx, <notifications@github.com> wrote:

> @raikarsagar <https://github.com/raikarsagar> Please, can you update us ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2758?email_source=notifications&email_token=AFLTJI2JG4EVUBKJXMSFNMLREEYILA5CNFSM4KVWCVA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMVBL3Q#issuecomment-589960686>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFLTJI2YVCG5C3DAIKUYVBTREEYILANCNFSM4KVWCVAQ>
> .
>
",could check version update day sat wrote please update u reply directly view,issue,negative,positive,neutral,neutral,positive,positive
589960730,"> > @lissyx yes I want to work on this. I will ask for help if needed.
> 
> @imskr Gentle ping?

@imskr Are you still expecting to send a patch for that or not?",yes want work ask help gentle ping still send patch,issue,positive,positive,positive,positive,positive,positive
589799045,"Just to clarify, is the Result struct ok or should it be changed? IMO it's better to add a little extra complexity on the backend if it makes the public API simpler.",clarify result better add little extra complexity public simpler,issue,negative,positive,neutral,neutral,positive,positive
589741007,"> Some more:
> 
> https://arxiv.org/abs/2002.03520
> 
> https://krex.k-state.edu/dspace/handle/2097/39830
> 
> https://ieeexplore.ieee.org/abstract/document/8638637
> 
> http://repositori.usu.ac.id/handle/123456789/15447

I've added these. One of them is in Indonesian and I can't work out what kind of thesis it is so I've just put masters. 

The ones that are ""submitted"" but not ""published"" I've put in ""to appear"".",added one ca work kind thesis put put appear,issue,positive,positive,positive,positive,positive,positive
589717607,@JRMeyer I have fixed transcribe.py in #2780 would you care to merge so we can get both scan dir and catalog usable? Thank you.,fixed would care merge get scan usable thank,issue,positive,positive,neutral,neutral,positive,positive
589641936,Sorry I don't know how I messed up making a comment. Added four more references that I know of. Thanks for starting this PR!,sorry know making comment added four know thanks starting,issue,negative,negative,neutral,neutral,negative,negative
589603810,"@alokprasad But while the `uniform()` pick a lower noise_ratio like -35 db, I will consider the noise approximately as none, so why should we have to keep ""clean audio"" for each epoch?
And I checked the Baidu's DeepSpeech [add_noise()](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/data_utils/audio.py), they mixed complete file like you said, so I will modify it.",uniform pick lower like consider noise approximately none keep clean audio epoch checked mixed complete file like said modify,issue,negative,positive,neutral,neutral,positive,positive
589519536,"@mychiux413  ""process will not augment every single audio time step, but just randomly augment an interval for each audio"" I think this might not produce good result , i think each interval should be mixed with noise.( i.e complete file should be mixed with noise)

Infact it would be good that same audio is fed twice to the network 

1. mixed with noise 
2. without noise.

i have added a flag in transcript.csv file  with extra flag ""noise_flag"" whose value is 0 or 1 .
eg.csv file will have follwing
```
wav_filename,wav_filesize,transcript,noise_flag
test1.wav,3423,""where are you?"",1
test1.wav,3423,""where are you?"",0
```
1 is to mix noise and 0 donto mix noise.

relevant code changes 

```
if train_phase and noise_iterator :
        audio = tf.cond(noise_flag > 0 ,
            lambda:augment_noise(
            audio,
            noise_iterator.get_next(),
            change_audio_db_max=FLAGS.audio_aug_mix_noise_max_audio_db,
            change_audio_db_min=FLAGS.audio_aug_mix_noise_min_audio_db,
            change_noise_db_max=FLAGS.audio_aug_mix_noise_max_noise_db,
            change_noise_db_min=FLAGS.audio_aug_mix_noise_min_noise_db,
        )

            ),
            lambda:audio)    

```

",process augment every single audio time step randomly augment interval audio think might produce good result think interval mixed noise complete file mixed noise would good audio fed twice network mixed noise without noise added flag file extra flag whose value file transcript mix noise mix noise relevant code audio lambda audio lambda audio,issue,positive,positive,positive,positive,positive,positive
589469167,"@alokprasad I tried tf.print and listened the audio, it's really augmented, maybe my default parameters are too conservative (because some noise data are ""speech noise"", I don't know what would them cause if too loud), and the process will not augment every single audio time step, but just randomly augment an interval for each audio, and many intervals in noise file are actually silence.
Don't forget to delete `test.wav` before each execution, or you will always hear the same output.
Try an extreme example: ` --audio_aug_mix_noise_max_noise_db=5`, `--audio_aug_mix_noise_min_noise_db=10`, to make sure the noise does exist.

Here is another tip, you can also try `--audio_aug_mix_noise_max_audio_db=10`, this could simulate `microphone over boosted` sound effect.",tried audio really augmented maybe default conservative noise data speech noise know would cause loud process augment every single audio time step randomly augment interval audio many noise file actually silence forget delete execution always hear output try extreme example make sure noise exist another tip also try could simulate microphone sound effect,issue,negative,positive,positive,positive,positive,positive
589282210,"It was an oversight on my part when porting the feeding code to tf.data and then I never got around to fixing it. Should be simple enough to add back the limits.

> On 20 Feb 2020, at 20:28, Richard Hamnett <notifications@github.com> wrote:
> 
> ﻿
> It's literally not in the code base. It's up to you. It's easy to create a new, limited CSV file but it seems better just have a flag so I was prepared to re-implement it.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",oversight part feeding code never got around fixing simple enough add back wrote literally code base easy create new limited file better flag prepared reply directly view,issue,positive,positive,neutral,neutral,positive,positive
589266622,"It's literally not in the code base. It's up to you. It's easy to create a new, limited CSV file but it seems better just have a flag so I was prepared to re-implement it.",literally code base easy create new limited file better flag prepared,issue,positive,positive,neutral,neutral,positive,positive
589264532,"Hm this was removed as part of 1cea2b0fe88b888ae8bbbb4cbe2743c1a6087552 last year, was it a mistake or on purpose? I don't remember cc @reuben ",removed part last year mistake purpose remember,issue,negative,neutral,neutral,neutral,neutral,neutral
588994320,"@mychiux413 
I also tried to save the audio using tf.print 's  output_stream option in following function 

```
""def augment_noise""
    noise_ratio = tf.math.pow(10.0, choosen_noise_db / 10)
    mixed_audio = tf.multiply(audio, audio_ratio) + tf.multiply(mixed_noise, noise_ratio)
    #save to wav file              
    final_pcm = contrib_audio.encode_wav(mixed_audio,16000)
    tf.print(final_pcm,output_stream=""file:///tmp/test.wav"",summarize=-1)
    return mixed_audio
    #return tf.multiply(audio, audio_ratio) + tf.multiply(mixed_noise, noise_ratio)

```
but two problems i am facing
1. i am not able to change parameter of output_stream dynamically so that multiple wave file is saved.
2.Files size keeps growing so we have to stop training ctrl+c after few steps. 

anyway if i listen the audio , i dont think noise is getting augmented to the speech at all.
",also tried save audio option following function audio save file file return return audio two facing able change parameter dynamically multiple wave file saved size growing stop training anyway listen audio dont think noise getting augmented speech,issue,positive,positive,positive,positive,positive,positive
588839057,"@alokprasad You're right, in fact, all the augmented audio should be able to be reviewed in pipeline, even augment on spectrogram like pitch/tempo/mask..., or we would not have a concept to tune the proper parameters.
But in tensorflow's pipeline, it's not as simple as offline augmentation does, we should dump audio data into tensorboard by `tf.summary.audio`, and I'm still study this method, also trying to figure out how much refactoring this will affect.",right fact augmented audio able pipeline even augment spectrogram like would concept tune proper pipeline simple augmentation dump audio data still study method also trying figure much affect,issue,negative,positive,positive,positive,positive,positive
588819519,"> But when I run this command, it doesn't shows the generate_trie.
> 
> ubuntu@ip-172-31-36-41:~/DeepSpeech$ python3 util/taskcluster.py --target native_client
> Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.7.0-alpha.2.cpu/artifacts/public/native_client.tar.xz ...
> Downloading: 100%
> 
> libdeepspeech.so
> LICENSE
> deepspeech
> deepspeech.h
> README.mozilla
> 
> > `generate_trie` is still bundled in the `native_client.tar.xz`, so please have a look or give more context.

Because if you look carefully to the result as well as the doc you will learn it defaults to downloading matching version with your DeepSpeech clone. I gave you the link to 0.4.1 as you asked, so I don't understand what's blocking now. ",run command python target license still please look give context look carefully result well doc learn matching version clone gave link understand blocking,issue,negative,negative,neutral,neutral,negative,negative
588810333,"But when I run this command, it doesn't shows the generate_trie.

ubuntu@ip-172-31-36-41:~/DeepSpeech$ python3 util/taskcluster.py --target native_client
Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.7.0-alpha.2.cpu/artifacts/public/native_client.tar.xz ...
Downloading: 100%

libdeepspeech.so
LICENSE
deepspeech
deepspeech.h
README.mozilla


> `generate_trie` is still bundled in the `native_client.tar.xz`, so please have a look or give more context.

",run command python target license still please look give context,issue,negative,neutral,neutral,neutral,neutral,neutral
588788184,"> > @yinshengabc Please avoid posting screenshot. `v0.4.1` release is not supported anymore and the artifact has expired, so you have to download from Github releases: https://github.com/mozilla/DeepSpeech/releases/v0.4.1
> 
> Thank you for your reply, also I noticed that the generate_trie file was removed, how can I do now to generate trie file and do the training?

`generate_trie` is still bundled in the `native_client.tar.xz`, so please have a look or give more context.",please avoid posting release artifact thank reply also file removed generate file training still please look give context,issue,positive,neutral,neutral,neutral,neutral,neutral
588768659,"> @yinshengabc Please avoid posting screenshot. `v0.4.1` release is not supported anymore and the artifact has expired, so you have to download from Github releases: https://github.com/mozilla/DeepSpeech/releases/v0.4.1

Thank you for your reply, also I noticed that the generate_trie file was removed, how can I do now to generate trie file and do the training?",please avoid posting release artifact thank reply also file removed generate file training,issue,negative,neutral,neutral,neutral,neutral,neutral
588732793,"@yinshengabc Please avoid posting screenshot. `v0.4.1` release is not supported anymore and the artifact has expired, so you have to download from Github releases: https://github.com/mozilla/DeepSpeech/releases/v0.4.1",please avoid posting release artifact,issue,negative,neutral,neutral,neutral,neutral,neutral
588714539,@mychiux413 anyway we can dump the mixed files and see how effective is the mixing of noise to speech file.just to make sure mixing is proper,anyway dump mixed see effective noise speech make sure proper,issue,negative,positive,positive,positive,positive,positive
588595372,Please can we get this added back in? It's really handy. Thanks,please get added back really handy thanks,issue,positive,positive,positive,positive,positive,positive
588336328,"> If that is the case (The flag --scorer is not part of the 0.6.1 release) it should probably be removed from each of the example blocks here - https://github.com/mozilla/DeepSpeech under
> `# Transcribe an audio file`

That documentation is for master. The v0.6.1 is okay: https://github.com/mozilla/DeepSpeech/tree/v0.6.1",case flag scorer part release probably removed example transcribe audio file documentation master,issue,negative,neutral,neutral,neutral,neutral,neutral
588328374,"If that is the case (The flag --scorer is not part of the 0.6.1 release) it should probably be removed from each of the example blocks here - https://github.com/mozilla/DeepSpeech under 
`# Transcribe an audio file`

",case flag scorer part release probably removed example transcribe audio file,issue,negative,neutral,neutral,neutral,neutral,neutral
588226813,"Next steps would then be to expose this API to our language bindings, as well as make use of it in the .NET binding instead of having its own list there.",next would expose language well make use binding instead list,issue,negative,neutral,neutral,neutral,neutral,neutral
588223015,"> We should probably add a [strerror](https://linux.die.net/man/3/strerror)-like API as well.

Maybe file as a easy bug / help wanted ?",probably add well maybe file easy bug help,issue,positive,positive,positive,positive,positive,positive
588004650,"I added `bin/normalize_noise_audio.py`, and did some modifications:
1. Removed `typing` for environment compatibility
2. Fixed pylint error, added warning message for ImportError of `tqdm` & `pydub`, because they are not standard packages in `requirement.txt`
3. Replaced `seconds_to_hours()` with `util/feeding.py::secs_to_hours()`

Usage:
```
python bin/normalize_noise_audio.py --from_dir <directory include noise data> --to_dir <directory to output normalized data>
```",added removed environment compatibility fixed error added warning message standard usage python directory include noise data directory output data,issue,negative,positive,neutral,neutral,positive,positive
587599270,Oh yes - but that is simple. Thanks for the heads-up.,oh yes simple thanks,issue,positive,positive,neutral,neutral,positive,positive
587598062,@tilmankamp this will require some adjustment on the SDB due to the different sample IDs vs filenames there.,require adjustment due different sample,issue,negative,negative,neutral,neutral,negative,negative
587533438,"@lissyx no problem! Glad I could help identify an issue.
Keep up the amazing work!",problem glad could help identify issue keep amazing work,issue,positive,positive,positive,positive,positive,positive
587514269,Disabled by default until we figure out good defaults from our current training runs.,disabled default figure good current training,issue,negative,positive,positive,positive,positive,positive
587513721,I'm going to make sure this passes tests and deal with the missing variable stuff in a separate PR.,going make sure deal missing variable stuff separate,issue,negative,positive,positive,positive,positive,positive
587458275,"@piraka9011 Thanks for the PR, but we're going to fix it properly in #2768 ",thanks going fix properly,issue,negative,positive,neutral,neutral,positive,positive
587420567,"> I just don't understand how it's even working on Linux...

it does not need to work, `docker-worker` does not break the encoding by magically gzipping without changing the content type, like `generic-worker` does",understand even working need work break magically without content type like,issue,negative,positive,positive,positive,positive,positive
587419882,"> It doesn't: https://github.com/python/cpython/blob/master/Lib/urllib/request.py

we don't care, in all cases we have to do the decompression ourselves for that use case",care decompression use case,issue,negative,neutral,neutral,neutral,neutral,neutral
587418980,"> Also we don't use `requests` at all in taskcluster.py? We use `urllib.request.urlretrieve`...

It uses requests in the background",also use use background,issue,negative,neutral,neutral,neutral,neutral,neutral
587416731,"> I can reproduce this on master.

Yeah, I just understood, it's `generic-worker` messing with us.",reproduce master yeah understood messing u,issue,negative,neutral,neutral,neutral,neutral,neutral
587416648,Downloading the file with Firefox properly decompresses it though. Probably some bug in requests or some weird header edge case being sent by TaskCluster or Amazon.,file properly though probably bug weird header edge case sent,issue,negative,negative,negative,negative,negative,negative
587415394,"> > @piraka9011 Can you share more details on your system ? This is running fine for me under linux (ubuntu 19.10)
> 
> MacOS 10.15
> Python 3.7.6 (virtual environment)
> requests 2.22.0
> Output of `pip freeze`:

Even `requests` docs agrees: https://requests.readthedocs.io/en/master/community/faq/#encoded-data",share system running fine python virtual environment output pip freeze even,issue,negative,positive,positive,positive,positive,positive
587276675,"> @piraka9011 Can you share more details on your system ? This is running fine for me under linux (ubuntu 19.10)

MacOS 10.15
Python 3.7.6 (virtual environment)
requests 2.22.0

<details>
<summary>Output of `pip freeze`:</summary>

```sh
absl-py==0.9.0
astor==0.8.1
attrdict==2.0.1
audioread==2.1.8
bcrypt==3.1.7
beautifulsoup4==4.8.2
boto3==1.12.0
botocore==1.15.0
bs4==0.0.1
certifi==2019.11.28
cffi==1.14.0
chardet==3.0.4
colorama==0.4.3
cryptography==2.8
cursor==1.3.4
cycler==0.10.0
decorator==4.4.1
deepspeech==0.6.0
docutils==0.15.2
ds-ctcdecoder==0.6.0
gast==0.3.3
google-pasta==0.1.8
grpcio==1.27.1
h5py==2.10.0
halo==0.0.28
idna==2.8
jmespath==0.9.4
joblib==0.14.1
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.0
kiwisolver==1.1.0
librosa==0.7.2
llvmlite==0.31.0
log-symbols==0.0.14
Markdown==3.2
matplotlib==3.1.3
numba==0.48.0
numpy==1.15.4
pandas==1.0.1
paramiko==2.7.1
progressbar2==3.47.0
protobuf==3.11.3
PyAudio==0.2.11
pycparser==2.19
PyNaCl==1.3.0
pyparsing==2.4.6
python-dateutil==2.8.1
python-utils==2.3.0
pytz==2019.3
pyxdg==0.26
requests==2.22.0
resampy==0.2.2
s3transfer==0.3.3
scikit-learn==0.22.1
scipy==1.4.1
six==1.14.0
SoundFile==0.10.3.post1
soupsieve==1.9.5
sox==1.3.7
spinners==0.0.23
tensorboard==1.14.0
tensorflow==1.14.0
tensorflow-estimator==1.14.0
termcolor==1.1.0
urllib3==1.25.8
webrtcvad==2.0.10
Werkzeug==1.0.0
wrapt==1.11.2
```

</details>

",share system running fine python virtual environment summary output pip freeze sh post,issue,negative,positive,positive,positive,positive,positive
587122985,"Side note: check if your kenlm is latest master from github and that build_binary on command line has a ""-v"" option. This caught me out as my version did not have ""-v""",side note check latest master command line option caught version,issue,negative,positive,positive,positive,positive,positive
587064207,"@raikarsagar Newer 0.7.0a2 is out, please ensure you have everything in sync.",please ensure everything sync,issue,positive,neutral,neutral,neutral,neutral,neutral
587019782,"> there is no standard way to normalize volume, I can only offer an example for you, you can optimize the script by yourself, and don't forget to listen the output audio to make sure everything sounds well.

Could you add this script to your pull request?

I added a progressbar and a summary to it, feel free to copy it back. The updated code is here: https://github.com/DanBmh/deepspeech-german/blob/master/data/normalize_noise_audio.py
",standard way normalize volume offer example optimize script forget listen output audio make sure everything well could add script pull request added summary feel free copy back code,issue,positive,positive,positive,positive,positive,positive
586984666,"I've triggered a new alpha, so you should be able to use it. This is not compatible with 0.6.1 model but re-exporting should be fine.",triggered new alpha able use compatible model fine,issue,negative,positive,positive,positive,positive,positive
586968944,"Great, thank-you @lissyx.  I'll probably end up waiting until the release is made to try it out.",great probably end waiting release made try,issue,positive,positive,positive,positive,positive,positive
586961430,We've since verified this and added API support for querying the model desired sample rate.,since added support querying model desired sample rate,issue,positive,neutral,neutral,neutral,neutral,neutral
586944876,"@dsteinman Support for next versions is here, do not hesitate to ask / give feedback or improvements on the docs if you still have troubles getting that with 0.6.1, because it should be transparent once you have `swig` setup and you pass the proper arguments. Again, the doc is quite new so it might need refinments, don't hesitate to ping us.",support next hesitate ask give feedback still getting transparent swig setup pas proper doc quite new might need hesitate ping u,issue,negative,positive,neutral,neutral,positive,positive
586941986,"> @lissyx yes I want to work on this. I will ask for help if needed.

@imskr Gentle ping?",yes want work ask help gentle ping,issue,positive,positive,positive,positive,positive,positive
586861935,"> I'm not sure if I'll be able to figure this out on my own. I don't think I even have swig installed correctly, I downloaded the binary from that taskcluster link, but I get these make errors.
> 
> ```
> swig -c++ -javascript -node deepspeech.i
> :1: Error: Unable to find 'swig.swg'
> :3: Error: Unable to find 'javascript.swg'
> deepspeech.i:2: Error: Unable to find 'typemaps.i'
> make: *** [deepspeech_wrap.cxx] Error 1
> ```

There should be enough doc in https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.rst#install-nodejs--electronjs-bindings but it's very fresh, so please advise if it needs improvements.

FTR, I just tested and it looks like it should build / run easily, so I can make a PR for that later today, but that won't cover 0.6.1, you will have anyway to do it on your side. We are trying to make that as easy as we can, please mind the gap between the code and the binary.",sure able figure think even swig correctly binary link get make swig error unable find error unable find error unable find make error enough doc fresh please advise need tested like build run easily make later today wo cover anyway side trying make easy please mind gap code binary,issue,positive,positive,neutral,neutral,positive,positive
586860403,"> I'm not sure if I'll be able to figure this out on my own. I don't think I even have swig installed correctly, I downloaded the binary from that taskcluster link, but I get these make errors.
> 
> ```
> swig -c++ -javascript -node deepspeech.i
> :1: Error: Unable to find 'swig.swg'
> :3: Error: Unable to find 'javascript.swg'
> deepspeech.i:2: Error: Unable to find 'typemaps.i'
> make: *** [deepspeech_wrap.cxx] Error 1
> ```

Good news, it seems you can get that to work easily:
```
$ SWIG_LIB=/home/alex/tmp/deepspeech/SWIG/install/share/swig/4.0.2 PATH=$HOME/tmp/deepspeech/SWIG/install/bin/:$HOME/node_modules/.bin/:$PATH make -C native_client/javascript/ NODE_ABI_TARGET=--target=8.0.1 NODE_DIST_URL=--disturl=https://electronjs.org/headers NODE_RUNTIME=--runtime=electron clean node-wrapper npm-pack 
```",sure able figure think even swig correctly binary link get make swig error unable find error unable find error unable find make error good news get work easily path make clean,issue,negative,positive,positive,positive,positive,positive
586859326,@piraka9011 Can you share more details on your system ? This is running fine for me under linux (ubuntu 19.10),share system running fine,issue,negative,positive,positive,positive,positive,positive
586855156,"> > How did you perform the download? Using `utils/taskcluster.py` should already do that, and if not it's a bug.
> 
> Exactly as specified [here](https://github.com/mozilla/DeepSpeech/blob/master/doc/TRAINING.rst#making-a-mmap-able-model-for-inference):
> 
> ```shell
> python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .
> ```

Well, it works for us:
```
$ python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target . ; file convert_graphdef_memmapped_format 
Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.tensorflow.pip.r1.15.cpu/artifacts/public/convert_graphdef_memmapped_format ...
Downloading: 100%

convert_graphdef_memmapped_format: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=1b35f6b2db6854a525cf3c1843afed4bb6550050, not stripped
$ ./convert_graphdef_memmapped_format 
2020-02-17 08:35:45.671153: E tensorflow/contrib/util/convert_graphdef_memmapped_format.cc:65] in_graph graph can't be empty
```",perform already bug exactly shell python source artifact branch target well work u python source artifact branch target file elf executable version dynamically linked interpreter sha stripped graph ca empty,issue,negative,positive,neutral,neutral,positive,positive
586853261,"> Yes. I have installed the latest version as per documentation.
> […](#)
> On Sat, 15 Feb, 2020, 1:15 PM Kelly Davis, ***@***.***> wrote: Have you installed the ds_ctcdecoder package? — You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub <#2758?email_source=notifications&email_token=AFLTJIYHJCB3E5CVRJ2NWEDRC6MQTA5CNFSM4KVWCVA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEL3EJWY#issuecomment-586564827>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AFLTJI7O4DPQSBSB27LNUETRC6MQTANCNFSM4KVWCVAQ> .

Latest is 0.7.0a1 ? Please try one of the wheels from https://community-tc.services.mozilla.com/tasks/ZSWB9IAuS4OULjCuMXwg9g#artifacts",yes latest version per documentation sat kelly wrote package thread reply directly view latest please try one,issue,positive,positive,positive,positive,positive,positive
586853243,"> @mychiux413 any idea how can be this done ? it should be online process ?

you should prepare normalized noise files by yourself before training start.

there is no standard way to normalize volume, I can only offer an example for you, you can optimize the script by yourself, and don't forget to listen the output audio to make sure everything sounds well.

notice:
1. I use pydub in the example, before `pip install pydub`, you should install ffmpeg by `sudo apt-get install ffmpeg`
2. the raw data I've downloaded from rnnoise is `.raw`, which should be manually specified `frame rate`, `sample size`, `channel`
3. some rnnoise data duration are almost 5 minutes, which is unnecessary in online mixing, so the example split them into 30 secs around.
4. the script is under python environment 3.7 (typing supported)

usage:
```
python <python_file.py> --from_dir <directory include rnnoise data> --to_dir <directory to output normalized data>
```

```
from __future__ import absolute_import, division, print_function
from pydub import AudioSegment
from multiprocessing import Pool
from functools import partial
import math
import argparse
import sys
import os


def detect_silence(sound: AudioSegment, silence_threshold=-50.0,
                   chunk_size=10) -> (int, int):
    start_trim = 0  # ms
    sound_size = len(sound)
    assert chunk_size > 0  # to avoid infinite loop
    while sound[start_trim:(
            start_trim +
            chunk_size)].dBFS < silence_threshold and start_trim < sound_size:
        start_trim += chunk_size

    end_trim = sound_size
    while sound[(end_trim - chunk_size):end_trim].dBFS < silence_threshold \
            and end_trim > 0:
        end_trim -= chunk_size

    start_trim = min(sound_size, start_trim)
    end_trim = max(0, end_trim)

    return min([start_trim, end_trim]), max([start_trim, end_trim])


def trim_silence_audio(sound: AudioSegment,
                       silence_threshold=-50.0,
                       chunk_size=10) -> AudioSegment:
    start_trim, end_trim = detect_silence(sound, silence_threshold, chunk_size)
    return sound[start_trim:end_trim]


def convert(filename: str, src_dir: str, dst_dirpath: str, dirpath: str,
            normalize: bool, trim_silence: bool, min_duration_seconds: float,
            max_duration_seconds: float):
    if not filename.endswith(('.wav', '.raw')):
        return
    filepath = os.path.join(dirpath, filename)
    if filename.endswith('.wav'):
        sound: AudioSegment = AudioSegment.from_file(filepath)
    else:
        try:
            sound: AudioSegment = AudioSegment.from_raw(filepath,
                                                        sample_width=2,
                                                        frame_rate=44100,
                                                        channels=1)
        except Exception as err:
            print('[retry] {}'.format(err))
            try:
                sound: AudioSegment = AudioSegment.from_raw(filepath,
                                                            sample_width=2,
                                                            frame_rate=48000,
                                                            channels=1)
            except Exception as err:
                print('bypass audio {}, got error: {}'.format(filepath, err))
                return
        try:
            sound = sound.set_frame_rate(16000)
        except Exception as err:
            print('[bypass] {}'.format(err))
            return

    n_splits: int = max(
        1, math.floor(sound.duration_seconds / max_duration_seconds))
    chunk_duration_ms = math.ceil(len(sound) / n_splits)
    chunks = []
    for i in range(n_splits):
        end_ms = min((i + 1) * chunk_duration_ms, len(sound))
        chunk = sound[(i * chunk_duration_ms):end_ms]
        chunks.append(chunk)
    for i, chunk in enumerate(chunks):
        dst_path = os.path.join(dst_dirpath, str(i) + '_' + filename)
        if dst_path.endswith('.raw'):
            dst_path = dst_path[:-4] + '.wav'
        if os.path.exists(dst_path):
            print('audio exists: {}'.format(dst_path))
            return
        if normalize:
            chunk = chunk.normalize()
            if chunk.dBFS < -30.0:
                chunk = chunk.compress_dynamic_range().normalize()
            if chunk.dBFS < -30.0:
                chunk = chunk.compress_dynamic_range().normalize()
        if trim_silence:
            chunk = trim_silence_audio(chunk)

        if chunk.duration_seconds < min_duration_seconds:
            return
        chunk.export(dst_path, format='wav')


def main(src_dir: str,
         dst_dir: str,
         min_duration_seconds: float,
         max_duration_seconds: float,
         normalize=True,
         trim_silence=True):
    assert os.path.exists(src_dir)
    if not os.path.exists(dst_dir):
        os.makedirs(dst_dir, exist_ok=False)
    src_dir = os.path.abspath(src_dir)
    dst_dir = os.path.abspath(dst_dir)

    # n_data = 0
    for dirpath, _, filenames in os.walk(src_dir):
        dirpath = os.path.abspath(dirpath)
        dst_dirpath = os.path.join(dst_dir,
                                   dirpath.replace(src_dir, '').lstrip('/'))
        print('converting dirpath: {} -> {}'.format(dirpath, dst_dirpath))
        if not os.path.exists(dst_dirpath):
            os.makedirs(dst_dirpath, exist_ok=False)

        convert_func = partial(convert,
                               src_dir=src_dir,
                               dst_dirpath=dst_dirpath,
                               dirpath=dirpath,
                               normalize=normalize,
                               trim_silence=trim_silence,
                               min_duration_seconds=min_duration_seconds,
                               max_duration_seconds=max_duration_seconds)
        p = Pool()
        p.map(convert_func, filenames)


if __name__ == ""__main__"":
    PARSER = argparse.ArgumentParser(description='Optimize noise files')
    PARSER.add_argument('--from_dir',
                        help='Convert wav from directory',
                        type=str)
    PARSER.add_argument('--to_dir', help='save wav to directory', type=str)
    PARSER.add_argument('--min_sec',
                        help='min duration seconds of saved file',
                        type=float,
                        default=1.0)
    PARSER.add_argument('--max_sec',
                        help='max duration seconds of saved file',
                        type=float,
                        default=30.0)
    PARSER.add_argument('--normalize',
                        action='store_true',
                        help='Trim silence, default is true',
                        default=True)
    PARSER.add_argument('--trim',
                        action='store_true',
                        help='Trim silence, default is true',
                        default=True)
    PARAMS = PARSER.parse_args()

    main(PARAMS.from_dir, PARAMS.to_dir, PARAMS.min_sec, PARAMS.max_sec,
         PARAMS.normalize, PARAMS.trim)
```",idea done process prepare noise training start standard way normalize volume offer example optimize script forget listen output audio make sure everything well notice use example pip install install install raw data manually frame rate sample size channel data duration almost unnecessary example split around script python environment usage python directory include data directory output data import division import import pool import partial import math import import import o sound sound assert avoid infinite loop sound sound min return min sound sound return sound convert normalize bool bool float float return sound else try sound except exception err print retry err try sound except exception err print audio got error err return try sound except exception err print bypass err return sound range min sound chunk sound chunk chunk enumerate print return normalize chunk chunk chunk chunk chunk return main float float assert print partial convert pool parser noise directory directory duration saved file duration saved file normalize silence default true trim silence default true main,issue,positive,positive,positive,positive,positive,positive
586787712,"> 
> 
> How did you perform the download? Using `utils/taskcluster.py` should already do that, and if not it's a bug.

Exactly as specified [here](https://github.com/mozilla/DeepSpeech/blob/master/doc/TRAINING.rst#making-a-mmap-able-model-for-inference):

```sh
python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .
```",perform already bug exactly sh python source artifact branch target,issue,negative,positive,positive,positive,positive,positive
586696725,"@lissyx: I was using the master branch.
I will now use the r1.15 branch and update on the result.",master branch use branch update result,issue,negative,neutral,neutral,neutral,neutral,neutral
586692139,"> Thanks, the error changed:
> 
> I think there is someting else missing?
> `bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so`
> 
> ```
> ERROR: /home/<username>/tensorflow/native_client/BUILD:91:1: no such target '//tensorflow/core/kernels:deepspeech_cwise_ops': target 'deepspeech_cwise_ops' not declared in package 'tensorflow/core/kernels' defined by /home/<username>/tensorflow/tensorflow/core/kernels/BUILD and referenced by '//native_client:libdeepspeech.so'
> ERROR: Analysis of target '//native_client:libdeepspeech.so' failed; build aborted: Analysis failed
> INFO: Elapsed time: 0.595s
> INFO: 0 processes.
> FAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)
> ```
> 
> I checked deepspeech_cwise_ops is not present in tensorflow/core/kernels

Are you sure you are on the `r1.15` branch of our fork? ",thanks error think else missing build bash opt error target target declared package defined error analysis target build aborted analysis time build complete successfully loaded checked present sure branch fork,issue,negative,positive,positive,positive,positive,positive
586691240,"Thanks, the error changed:

I think there is someting else missing?
`bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so`

```
ERROR: /home/<username>/tensorflow/native_client/BUILD:91:1: no such target '//tensorflow/core/kernels:deepspeech_cwise_ops': target 'deepspeech_cwise_ops' not declared in package 'tensorflow/core/kernels' defined by /home/<username>/tensorflow/tensorflow/core/kernels/BUILD and referenced by '//native_client:libdeepspeech.so'
ERROR: Analysis of target '//native_client:libdeepspeech.so' failed; build aborted: Analysis failed
INFO: Elapsed time: 0.595s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)
```

I checked deepspeech_cwise_ops is not present in tensorflow/core/kernels",thanks error think else missing build bash opt error target target declared package defined error analysis target build aborted analysis time build complete successfully loaded checked present,issue,negative,positive,positive,positive,positive,positive
586691020,"But if you're just building from source to test code changes, just remove the `//native_client:generate_trie` target from the build command.",building source test code remove target build command,issue,negative,neutral,neutral,neutral,neutral,neutral
586690844,Note that you have to regenerate the lm.binary file with the `-v` option to not include the vocabulary.,note regenerate file option include vocabulary,issue,negative,neutral,neutral,neutral,neutral,neutral
586690690,"Check under `data/lm` there should be a `generate_scorer` script, the new file format bundles the trie inside so no need for the separate tool now. ",check script new file format inside need separate tool,issue,negative,positive,positive,positive,positive,positive
586690387,"> VERSION says: 0.7.0-alpha.1
> What would be the correct build command then?

Remove the generate trie that's all. I think we forgot to update the docs cc @reuben ",version would correct build command remove generate think forgot update,issue,negative,neutral,neutral,neutral,neutral,neutral
586689853,"VERSION says: 0.7.0-alpha.1
What would be the correct build command then?",version would correct build command,issue,negative,neutral,neutral,neutral,neutral,neutral
586689756,What version are you trying to build? On master we don't have generate trie anymore I think? ,version trying build master generate think,issue,negative,neutral,neutral,neutral,neutral,neutral
586689636,"Ah yes, symlink the ds-swig as swig, and you have to set SWIG_LIB env var to the correct documented value. ",ah yes swig set correct value,issue,positive,neutral,neutral,neutral,neutral,neutral
586649747,"I'm not sure if I'll be able to figure this out on my own.  I don't think I even have swig installed correctly, I downloaded the binary from that taskcluster link, but I get these make errors.

```
swig -c++ -javascript -node deepspeech.i
:1: Error: Unable to find 'swig.swg'
:3: Error: Unable to find 'javascript.swg'
deepspeech.i:2: Error: Unable to find 'typemaps.i'
make: *** [deepspeech_wrap.cxx] Error 1
```",sure able figure think even swig correctly binary link get make swig error unable find error unable find error unable find make error,issue,negative,negative,neutral,neutral,negative,negative
586648310,"> @dsteinman Something like:
> 
> ```
>  make -C native_client/javascript \
>       TFDIR=${DS_TFDIR} \
>       NODE_ABI_TARGET=--target=8.0.1 \
>       NODE_DIST_URL=--disturl=https://electronjs.org/headers \
>       NODE_RUNTIME=--runtime=electron \
>       clean node-wrapper npm-pack
> ```

You'd need a `${DS_TFDIR}/bazel-bin/native_client/libdeepspeech.so` but you can build that manually by just re-using existing `.so`.",something like make clean need build manually,issue,positive,positive,positive,positive,positive,positive
586648255,"@dsteinman Something like:
```
 make -C native_client/javascript \
      TFDIR=${DS_TFDIR} \
      NODE_ABI_TARGET=--target=8.0.1 \
      NODE_DIST_URL=--disturl=https://electronjs.org/headers \
      NODE_RUNTIME=--runtime=electron \
      clean node-wrapper npm-pack
```",something like make clean,issue,positive,positive,positive,positive,positive,positive
586633511,"Here https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-build-utils.sh#L176 if you do the make call with the proper electronjs version string.

You might run into issues with swig wrappers that are broken with newer v8, and node-gyp / node-pre-gyp might require updating as well. As for swig, please check our docs on master, we recently revamped the process to try and make it easier for you to rebuild, and we provide pre-built patched binaries of swig.

Try and dig into that and come back if needed, I'm not able to look closer at that before a few days, but I'd welcome patches if you can: at some point, if you are lucky, it's just about adding the new version to SUPPORTED_ELECTRONJS_VERSIONS, and a few copy / paste and adapt of yml tests manifests.",make call proper version string might run swig broken might require well swig please check master recently process try make easier rebuild provide swig try dig come back able look closer day welcome point lucky new version copy paste adapt,issue,positive,positive,positive,positive,positive,positive
586633008,"You should look into our shell scripts `taskcluster/tc-builds.sh`, there are make calls that you could look at to pass the correct variables ",look shell make could look pas correct,issue,negative,neutral,neutral,neutral,neutral,neutral
586565272,"Yes. I have installed the latest version as per documentation.

On Sat, 15 Feb, 2020, 1:15 PM Kelly Davis, <notifications@github.com> wrote:

> Have you installed the ds_ctcdecoder package?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2758?email_source=notifications&email_token=AFLTJIYHJCB3E5CVRJ2NWEDRC6MQTA5CNFSM4KVWCVA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEL3EJWY#issuecomment-586564827>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AFLTJI7O4DPQSBSB27LNUETRC6MQTANCNFSM4KVWCVAQ>
> .
>
",yes latest version per documentation sat kelly wrote package thread reply directly view,issue,negative,positive,positive,positive,positive,positive
586548853,"Ok, I made some changes. Output is now:

```
{
""metadata"":{""confidence"":-59.3978},""words"":[{""word"":""and"",""time"":0,""duration"":0.74},{""word"":""can"",""time"":0.74,""duration"":0.12},{""word"":""even"",""time"":0.94,""duration"":0.32},{""word"":""export"",""time"":1.26,""duration"":0.52},{""word"":""them"",""time"":1.78,""duration"":0.22},{""word"":""to"",""time"":2,""duration"":0.2},{""word"":""common"",""time"":2.24,""duration"":0.44},{""word"":""sub"",""time"":2.68,""duration"":0.1}],
""alternatives"":[
{""metadata"":{""confidence"":-59.7169},""words"":[{""word"":""and"",""time"":0,""duration"":0.74},{""word"":""can"",""time"":0.74,""duration"":0.12},{""word"":""even"",""time"":0.94,""duration"":0.32},{""word"":""export"",""time"":1.26,""duration"":0.52},{""word"":""them"",""time"":1.78,""duration"":0.22},{""word"":""to"",""time"":2,""duration"":0.2},{""word"":""common"",""time"":2.24,""duration"":0.44},{""word"":""sube"",""time"":2.68,""duration"":0.16}]},
{""metadata"":{""confidence"":-58.7618},""words"":[{""word"":""and"",""time"":0,""duration"":0.74},{""word"":""can"",""time"":0.74,""duration"":0.12},{""word"":""even"",""time"":0.94,""duration"":0.32},{""word"":""export"",""time"":1.26,""duration"":0.52},{""word"":""them"",""time"":1.78,""duration"":0.22},{""word"":""to"",""time"":2,""duration"":0.2},{""word"":""common"",""time"":2.24,""duration"":0.44},{""word"":""subtle"",""time"":2.68,""duration"":0.26}]}
]
}
```",made output confidence word time duration word time duration word even time duration word export time duration word time duration word time duration word common time duration word sub time duration confidence word time duration word time duration word even time duration word export time duration word time duration word time duration word common time duration word time duration confidence word time duration word time duration word even time duration word export time duration word time duration word time duration word common time duration word subtle time duration,issue,positive,negative,negative,negative,negative,negative
586309371,This one here is on hold as it should use the `try_model` helper function of #2696 .,one hold use helper function,issue,negative,neutral,neutral,neutral,neutral,neutral
586305224,"> On hold till #2696 lands...

Are we waiting on #2696 to **fix** it or just to do the fix ?",hold till waiting fix fix,issue,negative,neutral,neutral,neutral,neutral,neutral
586103238,"> @JinZhuXing Please, can you give feedback ?

It's the same. I can't do it.
So I will try with english dataset.
Thanks.",please give feedback ca try thanks,issue,positive,positive,positive,positive,positive,positive
585917847,@irvin it appears you already had write access to that repo? I've just made you a maintainer. Please let me know if you need further collaborators added. Thanks for the ping @reuben.,already write access made maintainer please let know need added thanks ping,issue,positive,positive,positive,positive,positive,positive
585874854,"No new messages on the channel since Monday, all users were notified, new link is in the topic. Nothing has caught on fire so far.",new channel since notified new link topic nothing caught fire far,issue,negative,positive,positive,positive,positive,positive
585857806,@irvin sorry I completely missed your comment. I don't have access to the @Common-Voice org here. @mbransn is the one to talk to.,sorry completely comment access one talk,issue,negative,negative,negative,negative,negative,negative
585851833,"@dabinat thanks for the PR, much appreciated! Sorry for the delay in reviewing, we've been busy with a bunch of API clean up and stabilization changes. I've started looking and will finish reviewing by tomorrow.",thanks much sorry delay busy bunch clean stabilization looking finish tomorrow,issue,negative,positive,neutral,neutral,positive,positive
585840797,"Only failure is jcenter infra having issue, the other Java APK test is green anyway ...",failure infra issue test green anyway,issue,negative,negative,negative,negative,negative,negative
585839423,"Okey, I've made a PR with the suggested change, it seems to have solved the issue! 
Thank you guys!",made change issue thank,issue,negative,neutral,neutral,neutral,neutral,neutral
585820154,No new flags. Just move the import into the `vad_split` function.,new move import function,issue,negative,positive,positive,positive,positive,positive
585819600,"> > ```
> > ImportError: /institution/rz/cluster/home/user/myenv/lib/python3.6/site-packages/_webrtcvad.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _intel_fast_memcpy
> > ```
> 
> I'm sorry, but why do you file the issue here? It's a webrtcvad-level issue, it's not our code ...

in the hope to get more answers or ideas on what to do



> > This might maybe also be related to the fact i was not able to execute the following line:
> > `sudo apt-get install python3-dev`
> 
> What do you mean not able to execute? Your system does not offer a package with Python development headers?

like lissyx said, i dont have sudo rights

> > We could make the `webrtcvad` dependency optional, as it's only required for `transcribe.py`.
> 
> That's not completely wrong. @PedroDKE Maybe you could send a PR that does the job described above?

I'll look into it, but i have not been this far into the source code. 
Any idea if i have to make a new flag for this?",undefined symbol sorry file issue issue code hope get might maybe also related fact able execute following line install mean able execute system offer package python development like said dont could make dependency optional completely wrong maybe could send job look far source code idea make new flag,issue,negative,negative,neutral,neutral,negative,negative
585809375,"> We could make the `webrtcvad` dependency optional, as it's only required for `transcribe.py`.

That's not completely wrong. @PedroDKE Maybe you could send a PR that does the job described above?",could make dependency optional completely wrong maybe could send job,issue,negative,negative,negative,negative,negative,negative
585806388,"We could make the `webrtcvad` dependency optional, as it's only required for `transcribe.py`.",could make dependency optional,issue,negative,neutral,neutral,neutral,neutral,neutral
585806001,"> > This might maybe also be related to the fact i was not able to execute the following line:
> > `sudo apt-get install python3-dev`
> 
> What do you mean not able to execute? Your system does not offer a package with Python development headers?

I don't think he has credentials to sudo.",might maybe also related fact able execute following line install mean able execute system offer package python development think,issue,negative,positive,positive,positive,positive,positive
585805738,"> This might maybe also be related to the fact i was not able to execute the following line:
> `sudo apt-get install python3-dev`

What do you mean not able to execute? Your system does not offer a package with Python development headers?",might maybe also related fact able execute following line install mean able execute system offer package python development,issue,negative,positive,positive,positive,positive,positive
585800764,"> ```
> ImportError: /institution/rz/cluster/home/user/myenv/lib/python3.6/site-packages/_webrtcvad.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _intel_fast_memcpy
> ```

I'm sorry, but why do you file the issue here? It's a webrtcvad-level issue, it's not our code ...",undefined symbol sorry file issue issue code,issue,negative,negative,negative,negative,negative,negative
585748074,"> I try audio file for speech to text it give me the correct result but when i gave the audio stream from mic it did not give me the correct result. So, what is the issue ?
> what kind of microphone i have to use and any preprocess the audio ?
> if preprocess audio then what should i do?

There are already dozen and dozen of discussions covering that on Discourse. What you provide is absolutely useless for us to help.",try audio file speech text give correct result gave audio stream give correct result issue kind microphone use audio audio already dozen dozen covering discourse provide absolutely useless u help,issue,positive,positive,neutral,neutral,positive,positive
585747654,"> I try audio file for speech to text it give me the correct result but when i gave the audio stream from mic it did not give me the correct result. So, what is the issue ?
> what kind of microphone i have to use and any preprocess the audio ?
> if preprocess audio then what should i do?

This is your second bug opened in a few minutes.
You obviously don't consider it is worth reading the issue template as well as reading my answers.

Why do you open issues if you don't read the replies we give you ?

Let me copy it another time:
> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).",try audio file speech text give correct result gave audio stream give correct result issue kind microphone use audio audio second bug obviously consider worth reading issue template well reading open read give let copy another time support please use discourse,issue,positive,positive,positive,positive,positive,positive
585747291,"Please reach for support on Discourse, this is not a DeepSpeech bug.",please reach support discourse bug,issue,positive,neutral,neutral,neutral,neutral,neutral
585747170,"> pip install .

That's not what we document. Please follow the documentation and `pip install $(python util/taskcluster.py --decoder)`.",pip install document please follow documentation pip install python,issue,negative,neutral,neutral,neutral,neutral,neutral
585733592,"This is not a bug, please reach for support on Discourse and share more informations on your problem. ",bug please reach support discourse share problem,issue,positive,neutral,neutral,neutral,neutral,neutral
585676784,"> I wrote a python code to convert the files into csv. The code is below :

So no validation at all, no conversion. That's really not a DeepSpeech level issue. Please look at other importers and inspire yours to properly perform CSV import and ensure UTF-8 is well-formed at that point.

Since this is obviously not a DeepSpeech bug, please reach for support on Discourse.",wrote python code convert code validation conversion really level issue please look inspire properly perform import ensure point since obviously bug please reach support discourse,issue,positive,positive,neutral,neutral,positive,positive
585672196,"> How was this imported ?

It had to be unzipped and it had two parts to it. The transcripts and the audio files. I got them in the form to convert to CSV files.


> How were those CSV produced ?

I wrote a python code to convert the files into csv. The code is below : 

```
import glob as glob
import pandas as pd
import os

#Creating and storing list of wav files location in alphabetical orders wav_loc[]
wav_loc = glob.glob('/Users/rohitkhandelwal/Desktop/ezDI database/train/*.wav')
a = len(wav_loc)
print(""Total wav files found : "" + str(a))
wav_loc.sort()
print(wav_loc)


#Get filesize of .wav files
os.chdir('/Users/rohitkhandelwal/Desktop/ezDI database/train/')
wav_size = []
for file in wav_loc:
    wav_size.append(os.stat(file).st_size)
print(wav_size)


#Changing directory to train
os.chdir('/Users/rohitkhandelwal/Desktop/ezDI database/train/')

#Creating and storing names of text files in alphabetical order as txt_loc[]
txt_loc = glob.glob('*.txt')
b = len(txt_loc)
print(""Total textfiles found : "" + str(b))
txt_loc.sort()
print(txt_loc)


#Opening and reading textfiles. Storing in list trans[]
trans = []
for file in txt_loc:
    with open(file, 'r') as f:
        trans.append(f.read())
print(trans)

#Creating a dataframe of the three lists
df = pd.DataFrame({'wav_filename': wav_loc, 'wav_filesize': wav_size, 'transcript': trans})
print(df)

export_csv = df.to_csv(r'/Users/rohitkhandelwal/Desktop/ezDI database\new_train.csv', index=False)
```",two audio got form convert produced wrote python code convert code import import import o list location alphabetical print total found print get file file print directory train text alphabetical order print total found print opening reading list file open file print three print,issue,negative,neutral,neutral,neutral,neutral,neutral
585670598,"> > Which dataset is this ?
> 
> It's a medical dataset which I downloaded through the Ezdi website. I am trying to build a model for speech to text for medical terms.

How was this imported ? How were those CSV produced ?",medical trying build model speech text medical produced,issue,negative,neutral,neutral,neutral,neutral,neutral
585670243,"> > File ""/Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/DeepSpeech/util/feeding.py"", line 24, in read_csvs
> > file = pandas.read_csv(csv, encoding='utf-8')
> 
> Can you look into `util/feeding.py` and print the `csv` value before `pandas.read_csv`, that will point your to the broken CSV file.

With the CSV file and
> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe2 in position 1331: invalid continuation byte

You can find the broken part.",file line file look print value point broken file file ca decode position invalid continuation find broken part,issue,negative,negative,negative,negative,negative,negative
585669592,">   File ""/Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/DeepSpeech/util/feeding.py"", line 24, in read_csvs
>     file = pandas.read_csv(csv, encoding='utf-8')

Can you look into `util/feeding.py` and print the `csv` value before `pandas.read_csv`, that will point your to the broken CSV file.",file line file look print value point broken file,issue,negative,negative,negative,negative,negative,negative
585669549,"> Which dataset is this ?

It's a medical dataset which I downloaded through the Ezdi website. I am trying to build a model for speech to text for medical terms.",medical trying build model speech text medical,issue,negative,neutral,neutral,neutral,neutral,neutral
585668676,"> Also, I am using digits 0 to 9 in my alphabet.txt file. Is this why this error is arising ?

The error explicitely mentions `read_csvs`, so you have something bogus in your dataset. You have the error, you have the data, we can't do anything about that.",also file error error something bogus error data ca anything,issue,negative,neutral,neutral,neutral,neutral,neutral
585657376,"alphabet.txt looks somewhat like this :

```
#Each line in this file represents the Unicode codepoint (UTF-8 encoded)
#associated with a numeric label.
#A line that starts with # is a comment. You can escape it with \# if you wish
#to use '#' as a label.
 
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z
1
2
3
4
5
6
7
8
9
0
.
,
%
'
#The last (non-comment) line needs to end with a newline.
```",somewhat like line file associated label line comment escape wish use label last line need end,issue,positive,neutral,neutral,neutral,neutral,neutral
585653795,"I have made my own runnable script labeled run-test1.sh with the code as below :

```
#!/bin/sh
set -xe
if [ ! -f DeepSpeech.py ]; then
    echo ""Please make sure you run this from DeepSpeech's top level directory.""
    exit 1
fi;

python -u DeepSpeech.py \
  --train_files /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/ezDIdatabase/Training_Testing_data/train/train.csv \
  --dev_files /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/ezDIdatabase/Training_Testing_data/dev/dev.csv \
  --test_files /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/ezDIdatabase/Training_Testing_data/test/test.csv \
  --train_batch_size 80 \
  --dev_batch_size 80 \
  --test_batch_size 40 \
  --n_hidden 375 \
  --epochs 33 \
  --dropout_rate 0.22 \
  --learning_rate 0.00095 \
  --report_count 100 \
  --export_dir /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/DeepSpeech/data/rohit/results/model_export/ \
  --checkpoint_dir /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/DeepSpeech/data/rohit/results/checkout/ \
  --alphabet_config_path /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/DeepSpeech/data/alphabet.txt \
  --lm_binary_path /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/models/lm.binary \
  --lm_trie_path /Users/rohitkhandelwal/PycharmProjects/SpeechTest/venv/models/trie \
  ""$@""
```

Also, I am using digits 0 to 9 in my alphabet.txt file. Is this why this error is arising ? ",made runnable script code set echo please make sure run top level directory exit fi python also file error,issue,negative,positive,positive,positive,positive,positive
585652530,"> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe2 in position 1331: invalid continuation byte

@rohitk9 It looks like your UTF-8 data is somehow invalid, and you have the position here.

> ./bin/run-test1.sh

This is not our code, please share more context.",ca decode position invalid continuation like data somehow invalid position code please share context,issue,positive,neutral,neutral,neutral,neutral,neutral
585323626,"> the rest of the KenLM steps required to create an LM are actually remarkably quick

Great, I must be confusing training an acoustic model with creating the KenLM model.

> I'd suggest you have a go creating an LM, as the instructions are written up clearly in the relevant directory in this repo

Yup, this definitely seems like the way to go. Thanks!",rest create actually remarkably quick great must training acoustic model model suggest go written clearly relevant directory definitely like way go thanks,issue,positive,positive,positive,positive,positive,positive
585123778,"I haven't tried the filtering step myself but the rest of the KenLM steps required to create an LM are actually remarkably quick, which is why I was rather surprised when you said the ""training seems to take quite some time"".

I'd suggest you have a go creating an LM, as the instructions are written up clearly in the relevant directory in this repo and then look at the comment @reuben linked to and you should be able to figure out how to adapt the settings. KenLM itself is also fairly well documented online. Not only will you learn a little from doing it yourself but you'll then be able to make an LM that's specifically suited to your needs.",tried filtering step rest create actually remarkably quick rather said training take quite time suggest go written clearly relevant directory look comment linked able figure adapt also fairly well learn little able make specifically need,issue,positive,positive,positive,positive,positive,positive
585122549,"To use `rnnoise` datasets, we should `normalize the volume` and convert frame rate to `16000` manually, and many of rnnoise audio are almost no sound without normalizing volume.
This `mix noise process` assume every single noise file volume were maximized, so it doesn't calculate dBFS to balance speech/noise volume when processing.",use normalize volume convert frame rate manually many audio almost sound without volume mix noise process assume every single noise file volume calculate balance volume,issue,negative,positive,positive,positive,positive,positive
585039071,"The flag `--scorer` is not part of the 0.6.1 release, see for example [here](https://github.com/mozilla/DeepSpeech/blob/v0.6.1/util/flags.py). Please refer to the correct version of the documentation, in this case the 0.6.1 version of the documentation, and not master.",flag scorer part release see example please refer correct version documentation case version documentation master,issue,negative,neutral,neutral,neutral,neutral,neutral
584998482,"Yes I must have. Would it be possible to publish the LMs of those other sizes, as training seems to take quite some time? If it's possible to go from an existing LM (such as the release version) to a reduced size LM, I would be happy to read through any docs or scripts that would allow me to do so. Sorry if the answer is obvious, but I'm not very well-versed in LMs and training, etc. Thanks!",yes must would possible publish size training take quite time possible go release version reduced size would happy read would allow sorry answer obvious training thanks,issue,positive,positive,neutral,neutral,positive,positive
584587746,Maybe a note about the TC index behavior we're relying on?,maybe note index behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
584586926,"> r+ now that I actually understand this :P

Would it require more doc ?",actually understand would require doc,issue,negative,neutral,neutral,neutral,neutral,neutral
584342817,@reuben Are the smaller LMs available anywhere? I couldn't find any downloads and I can't find any instructions for generating them. Thanks!,smaller available anywhere could find ca find generating thanks,issue,negative,positive,positive,positive,positive,positive
583425831,@lissyx yes I want to work on this. I will ask for help if needed. ,yes want work ask help,issue,positive,neutral,neutral,neutral,neutral,neutral
583094801,"Yeah, I guess hosting ourselves is the easiest solution.",yeah guess hosting easiest solution,issue,positive,neutral,neutral,neutral,neutral,neutral
583043580,"> Thanks for your analysis @lissyx. My apologies for taking your comment the wrong way. Hopefully more good comes out of the issue.

That's also why I emphasize we would welcome PR, it's just that there are multiple colliding things. Nothing unfixable, but we have to pick our battles. Now, we had no Windows support, and @carlfm01 contributed and we ensured it was properly tested, so the call to contribution is not a blind one.",thanks analysis taking comment wrong way hopefully good come issue also emphasize would welcome multiple nothing unfixable pick support properly tested call contribution blind one,issue,positive,positive,neutral,neutral,positive,positive
583042811,"More importantly, Apple has deprecated OpenGL and OpenCL (in addition to macOS no longer supporting NVIDIA graphics chips).

So it seems that in future, Metal will be the ONLY way to do anything with the GPU on a Mac.",importantly apple addition longer supporting graphic chip future metal way anything mac,issue,positive,positive,positive,positive,positive,positive
583042755,Thanks for your analysis @lissyx. My apologies for taking your comment the wrong way. Hopefully more good comes out of the issue.,thanks analysis taking comment wrong way hopefully good come issue,issue,positive,positive,positive,positive,positive,positive
583039824,"> You needn't be mocking @lissyx. Your quote left out the comment ""for very fast processing,"" which is basically the upshot of what Metal is for. I don't think we need to go into the specifics of Metal to explain why it would be a nice feature for DeepSpeech to support it.

There was no mocking in my quotation, sorry if you felt it like that. I was truly asking, because I knew vaguely that Metal was some kind of GPU-related stuff, but that's it, and for me it was tailored at rendering, not the kind of use like OpenCL.


> Metal is Apple's version of GPU accelerated programming. It's a shame that kezakool found out that the LSTM layer can only be run with CPUOnly = true. Not sure what that's about. Again, the pro of having CoreML support should be like having a Tensorflow Lite package, but accelerated for Apple's hardware. The idea is being able to run on macOS and iOS very fast.

Thanks for the complement. Sadly, it seems to be the same story as usual LSTM unable to run on accelerated hardware, and thus round-trip to the CPU kills the win. We have mostly the same on Android with NNAPI as much as I could investigate.

What I lack of view is how much CoreML is / could be mandatory in the future. Also, on a technical note, this means more Apple hardware to build and run tests, which is problematic, so that adds up to the uncertainties.



> Personally, I'm fine if this issue is closed. As I mentioned, there are now native implementations of the kind of features that DeepSpeech offers, which there were not when I made the suggestion.

I'm unsure, there seems to be activity and it looks like bugs that were hitting us were fixed, so I think it's not a waste to keep it open.",need quote left comment fast basically upshot metal think need go metal explain would nice feature support quotation sorry felt like truly knew vaguely metal kind stuff rendering kind use like metal apple version accelerated shame found layer run true sure pro support like lite package accelerated apple hardware idea able run fast thanks complement sadly story usual unable run accelerated hardware thus win mostly android much could investigate lack view much could mandatory future also technical note apple hardware build run problematic personally fine issue closed native kind made suggestion unsure activity like u fixed think waste keep open,issue,positive,positive,positive,positive,positive,positive
583033008,"Metal is Apple's version of GPU accelerated programming. It's a shame that kezakool found out that the LSTM layer can only be run with CPUOnly = true. Not sure what that's about. Again, the pro of having CoreML support should be like having a Tensorflow Lite package, but accelerated for Apple's hardware. The idea is being able to run on macOS and iOS very fast.

No need to be mocking @lissyx. Your quote left out the comment ""for very fast processing,"" which is basically the upshot of what Metal is for. I don't think we need to go into the specifics of Metal to explain why it would be a nice feature for DeepSpeech to support it.

Personally, I'm fine if this issue is closed. As I mentioned, there are now native implementations of the kind of features that DeepSpeech offers, which there were not when I made the suggestion.",metal apple version accelerated shame found layer run true sure pro support like lite package accelerated apple hardware idea able run fast need quote left comment fast basically upshot metal think need go metal explain would nice feature support personally fine issue closed native kind made suggestion,issue,positive,positive,positive,positive,positive,positive
582940887,"@reuben Maybe it would be worth hand-fetching all of them, make a tar that we can attach as a mount-point at the right place in the Windows workers ?",maybe would worth make tar attach right place,issue,negative,positive,positive,positive,positive,positive
582924251,"> CoreML makes it so that the device can take advantage of features like Metal

Completely obscure for someone not aware of the macOS/iOS platform details :-).

If someone is able to provide PR / patches that adds that support, it would be very welcome, of course.",device take advantage like metal completely obscure someone aware platform someone able provide support would welcome course,issue,positive,positive,positive,positive,positive,positive
582909675,"hi, 
just to share my last exp with coreml, I converted a keras implementation of a CNN RNN with CTC Decoder to coreml last year, using coremltool, it works, but the Coreml LSTM layer as to be run with the CPUOnly =True option (because the GPU implementation is different), so be aware of that, i found that a bit desappointing, it loose many of it interest if it can't run optimized on GPU or NPU...
I don't know if it has been corrected since november 2019, but that was the situation",hi share last converted implementation last year work layer run option implementation different aware found bit loose many interest ca run know corrected since situation,issue,negative,positive,positive,positive,positive,positive
582877646,"> evaluate_tflite.py does not print any samples. Shall i add it?

I'd say no then.",print shall add say,issue,negative,neutral,neutral,neutral,neutral,neutral
582873477,"I did mean the voxforge dataset. It has only around 32h of speech data.

i think rnnoise dataset is smaller than the freesound one (6 vs 22 gb, did not find the length in hours).

Also the noise files of rnnoise are in .raw format and freesound already has .wav format. So you need to convert them before to wav somehow.",mean around speech data think smaller one find length also noise format already format need convert somehow,issue,negative,negative,negative,negative,negative,negative
582830851,@DanBmh You might need to factorize / apply that to `evaluate.py` as well as `evaluate_tflite.py`.,might need factorize apply well,issue,negative,neutral,neutral,neutral,neutral,neutral
582827790,"> Maybe the best idea is to print median results too, so that you get a more realistic estimate of the prediction quality? Like this:
> 1
> 2
> [...]
> 5
> 6
> [...]
> 9
> 10

It makes sense, but I have to admit this is not something that ever crossed our mind.",maybe best idea print median get realistic estimate prediction quality like sense admit something ever crossed mind,issue,positive,positive,positive,positive,positive,positive
582793536,"But this is the case only on current master, right? Does it work as expected on 0.6.1?",case current master right work,issue,negative,positive,positive,positive,positive,positive
582793457,"> I tested it with [Freesound Dataset Kaggle 2019](https://zenodo.org/record/3612637#.Xjq7OuEo9rk) which has about 103h of noise data.
> Everything worked as intended. Only i didnt see a great difference in my training results (using Voxforge DE dataset). Maybe its too small.

DId u mean.. the noise dataset is small or Voxforge dataset is small, comparatively. 
One suggestion: If your feel noise dataset is small, you can use rnnoise's (https://people.xiph.org/~jm/demo/rnnoise/rnnoise_contributions.tar.gz) dataset",tested noise data everything worked intended didnt see great difference training de maybe small mean noise small small comparatively one suggestion feel noise small use,issue,negative,negative,neutral,neutral,negative,negative
582789525,"I have beamer slides introducing common voice and DeepSpeech, and another set guiding a class for a 3-4h workshop on building small nodejs based app / web app with voice control. ",beamer common voice another set class workshop building small based web voice control,issue,negative,negative,negative,negative,negative,negative
582781894,"A lot, but a start has already been made by @lissyx who has created some initial training materials that can be the basis for the 1.0 work. @lissyx can maybe comment more on what he already has.",lot start already made initial training basis work maybe comment already,issue,negative,neutral,neutral,neutral,neutral,neutral
582650550,"Hi,

regarding:


> 3.    I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

For me it would be better to be able to supply the amount of transcriptions as an input even in the CLI. 

Background: this might help users to judge without big effort whether DeepSpeech is worth a try / respectively whether the quality of the audio allows a reasonable processing via DeepSpeech at all.
Only getting a limited amount of alternatives could hinder people to use/try DeepSpeech.
",hi regarding client output reasonable course anyone know offering option client open feedback would better able supply amount input even background might help judge without big effort whether worth try respectively whether quality audio reasonable via getting limited amount could hinder people,issue,positive,positive,positive,positive,positive,positive
582640501,"I think that when you're modeling and trying a lot of configurations, you want to know the flaws of your model but also the best it can show in which cases it can excel. I also think this should be an additional flag to DeepSpeech.py, not something by default. ",think modeling trying lot want know model also best show excel also think additional flag something default,issue,positive,positive,positive,positive,positive,positive
582592548,"I didnt know for some time that the examples are the worst predictions from the test set. I thought they were chosen randomly and i was wondering why they were always so bad.  So i did ignore the examples after a while. After i found the flag description (which by the way says they are the best results as lower is better) i understood they are the worst results, This is makes more sense than just printing random ones too. 

So i think  printing both the best and the worst will provide new users with an intuitive way to see that we output the worst results.
Another benefit is that if you have a bad performing network you can still see the network learnt something:)

Maybe the best idea is to print median results too, so that you get a more realistic estimate of the prediction quality? Like this:
1
2
[...]
5
6
[...]
9
10",didnt know time worst test set thought chosen randomly wondering always bad ignore found flag description way best lower better understood worst sense printing random think printing best worst provide new intuitive way see output worst another benefit bad network still see network learnt something maybe best idea print median get realistic estimate prediction quality like,issue,positive,negative,negative,negative,negative,negative
582538463,@DanBmh Can I ask you why you think it's useful to print the best ones ?,ask think useful print best,issue,positive,positive,positive,positive,positive,positive
582512206,"I tested it with [Freesound Dataset Kaggle 2019](https://zenodo.org/record/3612637#.Xjq7OuEo9rk) which has about 103h of noise data. 
Everything worked as intended. Only i didnt see a great difference in my training results (using Voxforge DE dataset).  Maybe its too small.",tested noise data everything worked intended didnt see great difference training de maybe small,issue,negative,positive,positive,positive,positive,positive
582473665,"@imskr So if you want to do this, you can, I'm unsure of the value for you though. What you need to do is:
 - add a dependency against the ctc decoder builds tasks (`darwin-amd64-ctc-opt` and `linux-amd64-ctc-opt`) in the github upload task (`scriptworker-task-github`)
 - add the ctc decoder builds tasks in the `python` list of the github upload task

For context, on our TaskCluster usage, each `.yml` in `taskcluster/` is a task that gets scheduled to run something for CI/CD. Task in TaskCluter are referred to using slug names, and we have tooling that is able to preprocess the `.yml` files and extracts nice tasks names (i.e., filename without `.yml`) and transform that into internal slug identifiers.",want unsure value though need add dependency task add python list task context usage task run something task slug tooling able nice without transform internal slug,issue,positive,positive,positive,positive,positive,positive
582467231,"> @lissyx Would it be possible for @imskr to take this?

Checking the `scriptworker` code, we should just have to add a dependency of the ctc decoder build in the github upload package, but that's really taskclusterish. Though, it would require doing a new alpha to ensure it works, so I'm unsure how much it can be interesting for @imskr to contribute that.",would possible take code add dependency build package really though would require new alpha ensure work unsure much interesting contribute,issue,positive,positive,positive,positive,positive,positive
582270972,I think the history got screwed up in my branch. I'll redo the PR.,think history got screwed branch redo,issue,negative,neutral,neutral,neutral,neutral,neutral
582084239,"No need to have different versions of TF in parallel. I'm an old-school guy: No python env's, no docker, ...",need different parallel guy python docker,issue,negative,neutral,neutral,neutral,neutral,neutral
582057805,"Hello @dabinat , @lissyx, @reuben   (or others :-)  )

I am quite interested to get/use this feature.

I have two years Python programming experience but no DeepSpeech experience. In case I would implement this feature by myself: 

Do you have an idea, how many hours this could (roughly) take me?

I know this is a very difficult question, but perhaps you are able to deliver just a _rough order of magnitude_ estimation.

Thanks in advance. ",hello quite interested feature two python experience experience case would implement feature idea many could roughly take know difficult question perhaps able deliver order estimation thanks advance,issue,positive,positive,positive,positive,positive,positive
582007302,"Some data I gathered:
 - it seemed any `us-east-*` instances would fail
 - it seemed many `us-west-*` instances would succeed.",data would fail many would succeed,issue,negative,neutral,neutral,neutral,neutral,neutral
581962648,"> I am writing a Dockerfile that provides a custom nvidia/cuda environment to run DeepSpeech on

We already have a `Dockerfile` in the repo, why re-invent the wheel ? What is missing ?",writing custom environment run already wheel missing,issue,negative,negative,negative,negative,negative,negative
581961871,"> RUN pip3 install DeepSpeech/native_client/ctcdecode/dist/*.whl --verbose
> [...]
> ERROR: ds_ctcdecoder-0.4.1-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.
> Exception information:

You build for Python 2.7 and install into Python 3.6, this can't work. Please use matching versions.",run pip install verbose error wheel platform exception information build python install python ca work please use matching,issue,negative,neutral,neutral,neutral,neutral,neutral
581961019,">  The installation steps I follow on the dockerfile are exactly the same I do on a real machine however I get a persistent error when I try to install the ctcdecoder for 0.4.1

This is not a bug. 0.4.1 is an old release, unsupported anymore and `ds_ctcdecoder` package is not installable anymore from prebuilts. 

Since you already rebuild things that are still available (why do you rebuild all of them ?) you should just rebuild the ctc decoder package.",installation follow exactly real machine however get persistent error try install bug old release unsupported package since already rebuild still available rebuild rebuild package,issue,negative,positive,positive,positive,positive,positive
581905509,"@JRMeyer there are also breakage on training https://community-tc.services.mozilla.com/tasks/groups/CaBE9HwkQ_SS6sPE3GpPMA:
```
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.
WARNING:tensorflow:From /home/build-user/ds-train/.pyenv/versions/3.5.5/envs/deepspeech-train/lib/python3.5/site-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
W0204 12:03:14.630473 140589220013888 deprecation.py:323] From /home/build-user/ds-train/.pyenv/versions/3.5.5/envs/deepspeech-train/lib/python3.5/site-packages/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
WARNING:tensorflow:From DeepSpeech.py:238: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0204 12:03:14.725249 140589220013888 deprecation.py:323] From DeepSpeech.py:238: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
I Trying to load last saved checkpoint
I Trying to load best saved checkpoint
I Initializing variables from scratch.
I STARTING Optimization
I Training epoch 0...
I Finished training epoch 0 - loss: 369.253021
I Validating epoch 0 on ./data/smoke_test/ldc93s1.csv...
I Finished validating epoch 0 on ./data/smoke_test/ldc93s1.csv - loss: 342.331604
I Saved new best validating model with loss 342.331604 to: /home/build-user/.local/share/deepspeech/checkpoints/best_dev-1
I FINISHED optimization in 0:00:00.810120
I Trying to load last saved checkpoint
I Loading variable from checkpoint: layer_3/bias
I Loading variable from checkpoint: global_step
I Loading variable from checkpoint: layer_6/bias
I Loading variable from checkpoint: layer_1/bias
I Loading variable from checkpoint: layer_2/bias
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
I Loading variable from checkpoint: layer_5/bias
I Loading variable from checkpoint: layer_6/weights
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias
I Loading variable from checkpoint: layer_3/weights
I Loading variable from checkpoint: layer_2/weights
I Loading variable from checkpoint: layer_5/weights
I Loading variable from checkpoint: layer_1/weights
WARNING:tensorflow:From /home/build-user/DeepSpeech/ds/util/helpers.py:63: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
W0204 12:03:16.584431 140589220013888 deprecation.py:323] From /home/build-user/DeepSpeech/ds/util/helpers.py:63: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer Variable.assign which has equivalent behavior in 2.X.
Testing model on ./data/smoke_test/ldc93s1.csv
I Test epoch...
Test on ./data/smoke_test/ldc93s1.csv - WER: 1.000000, CER: 0.884615, loss: 342.331604
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.884615, loss: 342.331604
 - wav: file:///home/build-user/DeepSpeech/ds/data/smoke_test/LDC93S1.wav
 - src: ""she had your dark suit in greasy wash water all year""
 - res: ""and grandeur a problem prolonging probable prolonging ""
--------------------------------------------------------------------------------
+ grep Restored variables from most recent checkpoint /tmp/resume.log
+ echo Did not resume training from checkpoint
Did not resume training from checkpoint
+ exit 1
```",also breakage training related depend functionality listed please file issue warning removed future version please use method instead removed future version please use method instead warning removed future version use broadcast rule removed future version use broadcast rule trying load last saved trying load best saved scratch starting optimization training epoch finished training epoch loss epoch finished epoch loss saved new best model loss finished optimization trying load last saved loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable loading variable warning removed future version prefer equivalent behavior removed future version prefer equivalent behavior testing model test epoch test wer loss wer loss file dark suit greasy wash water year grandeur problem probable recent echo resume training resume training exit,issue,positive,positive,positive,positive,positive,positive
581904894,@JRMeyer still many small lint fixes pending: https://travis-ci.org/mozilla/DeepSpeech/builds/645905527?utm_source=github_status&utm_medium=notification,still many small lint pending,issue,negative,positive,positive,positive,positive,positive
581865779,@JRMeyer I've edit and fixed your conflict so we can see all CI running and verify the status.,edit fixed conflict see running verify status,issue,negative,positive,neutral,neutral,positive,positive
581760856,"Also, Travis is not being run right now because this branch has conflicts with master. But you can run the linter locally: https://github.com/mozilla/DeepSpeech/blob/master/CONTRIBUTING.rst",also travis run right branch master run linter locally,issue,negative,positive,positive,positive,positive,positive
581755365,"@lissyx -- I figured out the errors during training, but the Windows errors I can't make sense of:

```
gyp verb `which` failed Error: not found: python2
```",figured training ca make sense gyp verb error found python,issue,negative,neutral,neutral,neutral,neutral,neutral
581656484,"@JRMeyer just click on ""Details"" where the bold ""T"" is the  review section by your comments. Should take you to travis where you can view all the errors",click bold review section take travis view,issue,negative,positive,positive,positive,positive,positive
581655408,"> > @lissyx -- I see the `NoneType` error, but I don't see the ""many broken things"" you mention... please link to them here
> 
> Look at travis

I don't know how to ""look at travis"". If Travis was documented somewhere in the repo, I would have done that already. I understand it is used for CI, but so is taskcluster, this is not documented and is a barrier to community contributions.",see error see many broken mention please link look travis know look travis travis somewhere would done already understand used barrier community,issue,negative,positive,neutral,neutral,positive,positive
581499180,"> @lissyx -- I see the `NoneType` error, but I don't see the ""many broken things"" you mention... please link to them here

Look at travis",see error see many broken mention please link look travis,issue,negative,positive,neutral,neutral,positive,positive
581495698,"> @JRMeyer There are still many broken things, especially training-wise (the failure on decision task is unrelated): [community-tc.services.mozilla.com/tasks/Rzqd3gboQhm1kVRul-kM3Q/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FRzqd3gboQhm1kVRul-kM3Q%2Fruns%2F0%2Fartifacts%2Fpublic%2Flogs%2Flive.log#L2732-2743](https://community-tc.services.mozilla.com/tasks/Rzqd3gboQhm1kVRul-kM3Q/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FRzqd3gboQhm1kVRul-kM3Q%2Fruns%2F0%2Fartifacts%2Fpublic%2Flogs%2Flive.log#L2732-2743)
> 
> Please also have a look at the Travis builds that reports lots of `pylint` issues.
> 
> Since things are looking more stable now, could you please cherry-pick and adapt TaskCluster changes I've shared in #2703 ?

@lissyx -- I see the `NoneType` error, but I don't see the ""many broken things"" you mention... please link to them here",still many broken especially failure decision task unrelated please also look travis lot since looking stable could please adapt see error see many broken mention please link,issue,negative,negative,neutral,neutral,negative,negative
581488740,"Yes, specially as it's going to take a some time until the new training run with the MFCC fix, which gives us time to fix this without holding the release with a model ready.",yes specially going take time new training run fix u time fix without holding release model ready,issue,positive,positive,positive,positive,positive,positive
581469094,I vote for 0.7.0 so we can get feedback from the ground,vote get feedback ground,issue,negative,neutral,neutral,neutral,neutral,neutral
581462814,Should we put this in 0.7.0 or 1.0.0? Or somewhere else? (I'm leaning towards 0.7.0),put somewhere else leaning towards,issue,negative,neutral,neutral,neutral,neutral,neutral
581444720,"> It have been mentioned on the forum that there is no need to use vad and segment audio files from 0.61 onwards. Do i still need to use vad ?

What has been mentionned was only in reference to the architecture of the network. Your use-case in unclear, and you don't provide any context to properly analyze if there's a bug or just a discrepancy of ressources.

We don't even know what version of DeepSpeech you are referring to.",forum need use segment audio onwards still need use reference architecture network unclear provide context properly analyze bug discrepancy even know version,issue,negative,neutral,neutral,neutral,neutral,neutral
581438653,It have been mentioned on the forum that there is no need to use vad and segment audio files from 0.61 onwards. Do i still need to use vad ?,forum need use segment audio onwards still need use,issue,negative,neutral,neutral,neutral,neutral,neutral
581427071,"There are [examples](https://github.com/mozilla/DeepSpeech-examples) that indicate how to do transcription of long files. For example, see the [vad_transcriber](https://github.com/mozilla/DeepSpeech-examples/blob/r0.6/vad_transcriber/wavTranscription.md) example, the code for which is [here](https://github.com/mozilla/DeepSpeech-examples/tree/r0.6/vad_transcriber).

There are various means to deploy to SaaS production. For example, using a thread pool and one model per thread or using TensorFlow Serving. However, we do not have examples of either. ",indicate transcription long example see example code various deploy production example thread pool one model per thread serving however either,issue,negative,negative,neutral,neutral,negative,negative
581320537,"> I solved this issue, maybe some apt configuration is changed during installing git lfs.
> I searched in internet.
> I got a help from below link
> [wiseman/py-webrtcvad#40](https://github.com/wiseman/py-webrtcvad/issues/40)
> thanks

Would it be possible for you to respect the issue template ?",issue maybe apt configuration git got help link thanks would possible respect issue template,issue,positive,positive,positive,positive,positive,positive
581319688,"@JRMeyer There are still many broken things, especially training-wise (the failure on decision task is unrelated): https://community-tc.services.mozilla.com/tasks/Rzqd3gboQhm1kVRul-kM3Q/runs/0/logs/https%3A%2F%2Fcommunity-tc.services.mozilla.com%2Fapi%2Fqueue%2Fv1%2Ftask%2FRzqd3gboQhm1kVRul-kM3Q%2Fruns%2F0%2Fartifacts%2Fpublic%2Flogs%2Flive.log#L2732-2743

Please also have a look at the Travis builds that reports lots of `pylint` issues.

Since things are looking more stable now, could you please cherry-pick and adapt TaskCluster changes I've shared in https://github.com/mozilla/DeepSpeech/pull/2703 ?",still many broken especially failure decision task unrelated please also look travis lot since looking stable could please adapt,issue,negative,negative,negative,negative,negative,negative
581319590,"I solved this issue, maybe some apt configuration is changed during installing git lfs.
I searched in internet. 
I got a help from below link
https://github.com/wiseman/py-webrtcvad/issues/40
thanks",issue maybe apt configuration git got help link thanks,issue,positive,positive,positive,positive,positive,positive
581184030,"That is massive improvement!
Keep up the good work, and thanks again for your time!
Let's see if I can build a small app around this. :)",massive improvement keep good work thanks time let see build small around,issue,positive,positive,positive,positive,positive,positive
581183284,"> I see the TensorFlow version is newer, but is it the lite version?

Since you pass it the `.tflite` file, and it runs, yes.

Again, speed is highly dependant on the CPU. We have no feedback on that kind of CPU, so it's not surprising. Still, you went from 1 min 10 secs to only 13 secs, so there's improvement, and that confirms it's TFLite running as well. There's not much we can do.",see version lite version since pas file yes speed highly feedback kind surprising still went min improvement running well much,issue,positive,positive,positive,positive,positive,positive
581183041,"@lissyx 

```
#try3:
sudo apt-get install alsa-utils #(Only for recording) 
mkdir ~/DeepSpech
cd ~/DeepSpech
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.7.0-alpha.0/native_client.arm64.cpu.linux.tar.xz
tar xvf ./native_client.arm64.cpu.linux.tar.xz
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz
tar xvf deepspeech-0.6.1-models.tar.gz

#use it
arecord -vv -fdat to_txt.wav
/deepspeech --model deepspeech-0.6.1-models/output_graph.tflite --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio ./to_txt.wav
```
Output:
```
purism@pureos:~/DeepSpech$ time ./deepspeech --model deepspeech-0.6.1-models/output_graph.tflite --lm deepspeech-0.6.1-models/lm.binary --trie deepspeech-0.6.1-models/trie --audio ./to_txt.wav
TensorFlow: v1.15.0-24-gceb46aa
DeepSpeech: v0.7.0-alpha.0-0-g6af68ef
wav: Premature EOF on .wav input file
recording something about stuff and what not

real	0m12.538s
user	0m12.025s
sys	0m0.241s

```
I see the TensorFlow version is newer, but is it the lite version? ",try install recording tar curl tar use model audio output purism time model audio premature input file recording something stuff real user see version lite version,issue,negative,positive,positive,positive,positive,positive
581121763,"Also, please note we only tested those on some ARM64 boards, but the SoC of the purism device is different. Maybe it's time I unbox my dev one :)",also please note tested arm soc purism device different maybe time unbox dev one,issue,negative,neutral,neutral,neutral,neutral,neutral
581121650,">  I'm hoping to use tensorflowlite. The run time is... slow. 1 second takes about 11 to read.

You should be able with current `0.7.0-alpha.0` binaries: we switched ARM64 to default to TFLite runtime after 0.6.1, but this alpha is still graph-compatible with 0.6.1: https://github.com/mozilla/DeepSpeech/releases/download/v0.7.0-alpha.0/native_client.arm64.cpu.linux.tar.xz

Please use 0.6.1 tflite model, not 0.6.0, since it is bugged.",use run time slow second read able current switched arm default alpha still please use model since,issue,negative,positive,neutral,neutral,positive,positive
581121230,">  Quick question, is the TensorFlow version linked to the compiled version? Or did I just install the wrong version. laughing

`libdeepspeech.so` statically links against tensorflow, so you don't have to worry.",quick question version linked version install wrong version laughing statically link worry,issue,negative,negative,neutral,neutral,negative,negative
581119281,"@lissyx Sorry, lots of projects on the go right now. I’ve made a note to look into this as soon as I can.",sorry lot go right made note look soon,issue,negative,negative,negative,negative,negative,negative
581105538,"We can close this. 
Quick question, is the TensorFlow version linked to the compiled version? Or did I just install the wrong version. :laughing: 
I'm hoping to use tensorflowlite. The run time is... slow. 1 second takes about 11 to read. 

solution. I was able to install with:
```
#try2:
sudo apt-get install alsa-utils #(Only for recording) 
mkdir ~/DeepSpech
cd ~/DeepSpech
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/native_client.arm64.cpu.linux.tar.xz
tar xvf ./native_client.arm64.cpu.linux.tar.xz
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz
tar xvf deepspeech-0.6.0-models.tar.gz
```

Test commands:
```
#use it
arecord -vv -fdat to_txt.wav
./deepspeech --model deepspeech-0.6.0-models/output_graph.pbmm --lm deepspeech-0.6.0-models/lm.binary --trie deepspeech-0.6.0-models/trie --audio ./to_txt.wav
```

Output:
```
purism@pureos:~/DeepSpech$ time ./deepspeech --model deepspeech-0.6.0-models/output_graph.pbmm --lm deepspeech-0.6.0-models/lm.binary --trie deepspeech-0.6.0-models/trie --audio ./to_txt.wav
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.1-0-g3df20fe
wav: Premature EOF on .wav input file
this is a test eolipile boys to text feature

real	1m9.250s
user	1m14.323s
sys	0m0.273s
purism@pureos:~/DeepSpech$ time play ./to_txt.wav 
...
real	0m6.066s
user	0m0.171s
sys	0m0.082s
```
@lissyx Thanks for your time!",close quick question version linked version install wrong version laughing use run time slow second read solution able install try install recording tar curl tar test use model audio output purism time model audio premature input file test text feature real user purism time play real user thanks time,issue,positive,positive,neutral,neutral,positive,positive
581038863,"@reuben I'm starting to wonder if i would not be easier to use https://pip.pypa.io/en/stable/user_guide/#using-pip-from-your-program instead of advising people ...

One consideration that refrains me is that I'd hate, as a user, a python code doing that kind of magic.",starting wonder would easier use instead people one consideration hate user python code kind magic,issue,negative,positive,neutral,neutral,positive,positive
581000876,"> I somehow overlooked that doc, sorry!
> It looks like it's an involved process to compile. :)
> Where can I find the pre-build packages for ARM64?

Well, it's not more complicated than what you did. You can find everything on github releases. ",somehow doc sorry like involved process compile find arm well complicated find everything,issue,positive,negative,negative,negative,negative,negative
580984767,"I somehow overlooked that doc, sorry!
It looks like it's an involved process to compile. :)
Where can I find the pre-build packages for ARM64? ",somehow doc sorry like involved process compile find arm,issue,negative,negative,negative,negative,negative,negative
580840458,"As people have said this several times in this thread already, you have to install the same version everywhere. You said you were using v0.6.1 to train, so you should use v0.6.1 for the decoder package too.


> On 31 Jan 2020, at 17:29, Victor Noriega <notifications@github.com> wrote:
> 
> ﻿
> I updated the decoder to 0.7.0 and worked. Thank you @lissyx @carlfm01
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",people said several time thread already install version everywhere said train use package victor wrote worked thank thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
580791491,"> deepspeech 0.6.1
> ds-ctcdecoder 0.6.0a8

Here we go, since you did not share any details on what you were doing, we know what's wrong:
 - you don't need `deepspeech` here, that's only for inference
 - you need to use matching uptodate version of `ds-ctcdecoder` ... which 100% explains your issue.",go since share know wrong need inference need use matching version issue,issue,negative,negative,negative,negative,negative,negative
580790772,"> Are you sure everything in your training is properly uptodate at 0.6.1 ? It's really hard to help with so few informations on your setup: what's your pip list output ?

`Package              Version  
-------------------- ---------
absl-py              0.8.0    
asn1crypto           0.24.0   
astor                0.8.0    
attrdict             2.0.1    
audioread            2.1.8    
bcrypt               3.1.7    
beautifulsoup4       4.8.0    
bs4                  0.0.1    
cachetools           3.1.1    
certifi              2019.9.11
cffi                 1.12.3   
chardet              3.0.4    
cryptography         2.7      
cycler               0.10.0   
decorator            4.4.0    
deepspeech           0.6.1    
ds-ctcdecoder        0.6.0a8  
gast                 0.3.2    
google-auth          1.6.3    
google-auth-oauthlib 0.4.1    
google-pasta         0.1.7    
grpcio               1.16.1   
h5py                 2.10.0   
idna                 2.8      
joblib               0.13.2   
Keras                2.2.4    
Keras-Applications   1.0.8    
Keras-Preprocessing  1.1.0    
kiwisolver           1.1.0    
librosa              0.7.0    
llvmlite             0.29.0   
Markdown             3.1.1    
matplotlib           3.1.1    
mkl-service          2.3.0    
mock                 3.0.5    
numba                0.45.1   
numpy                1.17.3   
oauthlib             3.1.0    
opt-einsum           3.1.0    
pandas               0.25.1   
paramiko             2.6.0    
pip                  19.2.3   
progressbar2         3.47.0   
protobuf             3.9.2    
psutil               5.6.2    
pyasn1               0.4.7    
pyasn1-modules       0.2.7    
pycparser            2.19     
PyNaCl               1.3.0    
pyparsing            2.4.2    
python-dateutil      2.8.0    
python-utils         2.3.0    
pytz                 2019.2   
pyxdg                0.26     
PyYAML               5.1.2    
requests             2.22.0   
requests-oauthlib    1.2.0    
resampy              0.2.2    
rsa                  4.0      
scikit-learn         0.21.3   
scipy                1.3.1    
seaborn              0.9.0    
setuptools           41.2.0   
six                  1.12.0   
SoundFile            0.10.2   
soupsieve            1.9.4    
sox                  1.3.7    
tensorboard          1.14.0   
tensorflow           1.14.0   
tensorflow-estimator 1.14.0   
tensorflow-gpu       1.14.0   
termcolor            1.1.0    
tqdm                 4.32.1   
urllib3              1.25.6   
virtualenv           16.7.8   
webrtcvad            2.0.10   
Werkzeug             0.16.0   
wheel                0.33.6   
wrapt                1.11.2`

> Make sure you are using the generatetrie tool based on master, this happened to me time ago and you only need to make sure you are using the same versions while training and when generating the trie file

I pulled from the repository yesterday before opening this issue, then generated the trie and trained models. Not sure what I'm doing wrong.",sure everything training properly really hard help setup pip list output package version astor cryptography cycler decorator gast markdown mock pip six wheel make sure tool based master time ago need make sure training generating file repository yesterday opening issue trained sure wrong,issue,positive,positive,positive,positive,positive,positive
580789283,"Make sure you are using the generatetrie tool based on master, this happened to me time ago and you only need to make sure you are using the same versions while training and when generating the trie file",make sure tool based master time ago need make sure training generating file,issue,positive,positive,positive,positive,positive,positive
580788104,"> I retrained with DS v0.6.1 and still got the problem. I'm saving the models just for testing later. What should I do?

Are you sure everything in your training is properly uptodate at 0.6.1 ? It's really hard to help with so few informations on your setup: what's your `pip list` output ?",still got problem saving testing later sure everything training properly really hard help setup pip list output,issue,negative,positive,neutral,neutral,positive,positive
580786513,I retrained with DS v0.6.1 and still got the problem. I'm saving the models just for testing later. What should I do?,still got problem saving testing later,issue,negative,neutral,neutral,neutral,neutral,neutral
580782626,Maybe let me flip this question back to you: how would TF2 compatibility in DeepSpeech benefit you?,maybe let flip question back would compatibility benefit,issue,negative,neutral,neutral,neutral,neutral,neutral
580782409,No idea. So far TF2 does not have anything of benefit to DeepSpeech.,idea far anything benefit,issue,negative,positive,neutral,neutral,positive,positive
580684793,We should be covered now. Next alpha release should help us ensure it's the case.,covered next alpha release help u ensure case,issue,positive,neutral,neutral,neutral,neutral,neutral
580628151,"> Given we are now using TF 1.15 do you think it would be possible to try the quantization again? What is the current output type, is it uint8?

I used 1.15 during my previous experiments",given think would possible try quantization current output type used previous,issue,negative,negative,neutral,neutral,negative,negative
580612287,"Given we are now using TF 1.15 do you think it would be possible to try the quantization again? What is the current output type, is it uint8?",given think would possible try quantization current output type,issue,negative,neutral,neutral,neutral,neutral,neutral
580382534,"Sorry. Here's what it printed:

`Downloading https://community-tc.services.mozilla.com/api/index/v1/task/project.deepspeech.deepspeech.native_client.v0.6.1.cpu/artifacts/public/native_client.tar.xz ...
Downloading: 100%`

Yes I know it should be 5 right now. I generated my lm from the kenlm code you provide, and also from the newest version of kpu/kenlm because it may be the proper. Maybe is the model I tested? I'm testing a model I trained with DS 0.5.1 in a 0.6.1 repo. Should I retrain the model with DS 0.6.1 ?",sorry printed yes know right code provide also version may proper maybe model tested testing model trained retrain model,issue,negative,negative,neutral,neutral,negative,negative
580380325,"@victornoriega Are you sure you are using LM from 0.6.1 ? 5 is the proper value, 4 indicates that you are using older version.",sure proper value older version,issue,positive,positive,positive,positive,positive,positive
580377985,"> I executed this:
> 
> `python util/taskcluster.py --target .`
> 
> in a DeepSpeech 0.6.1 cloned repository.

We could still have bugs... The URL should have been printed but you did not shared that, so I can't know for sure. 

Please force `--branch v0.6.1` or use release's `native_client.tar.xz` from github releases v0.6.1, to be sure.",executed python target repository could still printed ca know sure please force branch use release sure,issue,positive,positive,positive,positive,positive,positive
580339351,"I executed this:

`python util/taskcluster.py --target .`

in a DeepSpeech 0.6.1 cloned repository.",executed python target repository,issue,negative,neutral,neutral,neutral,neutral,neutral
580334092,"> When DeepSpeech tried to test after training, it threw me that error. I had seen errors like '4 instead of expected 3' but never this. The trie I generated was from the pre-built generate_trie.cpp that you compiled. I'm using DeepSpeech 0.6.1.

Please ensure `generate_trie` is also from 0.6.1.",tried test training threw error seen like instead never please ensure also,issue,negative,neutral,neutral,neutral,neutral,neutral
580176101,It might mean that. At least this coincides with your initial experiences and these numbers.,might mean least initial,issue,negative,negative,negative,negative,negative,negative
580175046,"> The 5% coincides with the result presented [here](https://www.dpamicrophones.com/mic-university/facts-about-speech-intelligibility) for non-tonal languages
> ![facts-about-speech-fig04_1](https://user-images.githubusercontent.com/12054740/73437781-435e0780-434d-11ea-840e-47c8b088eedc.jpg)
> I'd guess we'd gain more for tonal languages.

That would mean we can safely land that and pick the improvement over the next round of training, without fearing of hyper-parameters changes, then?",result guess gain tonal would mean safely land pick improvement next round training without,issue,positive,negative,neutral,neutral,negative,negative
580171626,"The 5% coincides with the result presented [here](https://www.dpamicrophones.com/mic-university/facts-about-speech-intelligibility) for non-tonal languages
![facts-about-speech-fig04_1](https://user-images.githubusercontent.com/12054740/73437781-435e0780-434d-11ea-840e-47c8b088eedc.jpg)
I'd guess we'd gain more for tonal languages.
",result guess gain tonal,issue,positive,neutral,neutral,neutral,neutral,neutral
580123192,"We have builds more or less ready for NodeJS and .Net, but we don't publish them to their repository. I can create those `deepspeech-tflite` there, so we get them published.  Any objection @kdavis-mozilla @reuben ?",le ready publish repository create get objection,issue,positive,positive,positive,positive,positive,positive
580101905,"@lissyx Yes the task is to ""have an alternative with TFLite usable by people for all platforms we have"".",yes task alternative usable people,issue,negative,neutral,neutral,neutral,neutral,neutral
579992402,"@kdavis-mozilla Does completion of this tasks is ""we have an alternative with TFLite usable by people for all platforms we have"" ? If so, I'll do a new pass to verify, but I think we are covered.",completion alternative usable people new pas verify think covered,issue,negative,positive,positive,positive,positive,positive
579905277,@JRMeyer I've added a commit that could serve you as a bootstrap for TC.,added commit could serve bootstrap,issue,negative,neutral,neutral,neutral,neutral,neutral
579891187,"> @reuben @tilmankamp @lissyx -- this is a push of a WIP

Right, then how much / where do you want review if it's still WIP ?",push right much want review still,issue,negative,positive,positive,positive,positive,positive
579690440,"> > I'm really not sure it's a big deal.
> 
> Whatever we expose in 1.0 we have to live with during 1.x. If we expose two different versions, one SemVer and one truncated, we'll have to maintain both. I'd rather stick to the versioning scheme we've been using so far, which is SemVer.

Agreed, it's just that it's easy to do. Let's keep SemVer only, we'll see if people need more.



> > What makes you think we should expose it?
> 
> Same reason it's currently printed by `DS_PrintVersions`, diagnostics. If you're OK with dropping it I'm OK with it too.

Right, but I'm unsure if it makes sense to do that API-level, since people **might** not share it ahead of time and we get screwed. And having to keep that exposed means we have to keep it for a while :D.

I don't have a very strong opinion here :/",really sure big deal whatever expose live expose two different one one truncated maintain rather stick scheme far agreed easy let keep see people need think expose reason currently printed diagnostics dropping right unsure sense since people might share ahead time get screwed keep exposed keep strong opinion,issue,positive,positive,positive,positive,positive,positive
579689205,"> I'm really not sure it's a big deal.

Whatever we expose in 1.0 we have to live with during 1.x. If we expose two different versions, one SemVer and one truncated, we'll have to maintain both. I'd rather stick to the versioning scheme we've been using so far, which is SemVer.

> What makes you think we should expose it?

Same reason it's currently printed by `DS_PrintVersions`, diagnostics. If you're OK with dropping it I'm OK with it too.",really sure big deal whatever expose live expose two different one one truncated maintain rather stick scheme far think expose reason currently printed diagnostics dropping,issue,negative,positive,positive,positive,positive,positive
579687205,"> I'm not sure how useful C `#define`s are since you can't easily handle the pre-release part

I'm really not sure it's a big deal.



> I'm tempted to simply expose the version strings (DS and TF) at runtime: `char* DS_GetVersion();` and `char* DS_GetTFVersion();`.

Let's go with that, but I'm not sure we should expose TensorFlow version: our library makes it completely hidden, and our deepspeech versioning scheme already handles incompatibilities that might arise from TensorFlow.

What makes you think we should expose it?",sure useful define since ca easily handle part really sure big deal simply expose version char char let go sure expose version library completely hidden scheme already might arise think expose,issue,positive,positive,positive,positive,positive,positive
579682244,"> @lissyx @reuben Thanks for your comments. The ides discussed in #2672 is so nice and I withdraw this request.
> I am looking forward to 0.7.0!

Well, nothing is burnt / settled yet, so feel free to lean ideas on that discussion.",thanks ides nice withdraw request looking forward well nothing burnt settled yet feel free lean discussion,issue,positive,positive,positive,positive,positive,positive
579681413,"@lissyx I don't like doing both at the same time, and I'm not sure how useful C `#define`s are since you can't easily handle the pre-release part. I'm tempted to simply expose the version strings (DS and TF) at runtime: `char* DS_GetVersion();` and `char* DS_GetTFVersion();`.",like time sure useful define since ca easily handle part simply expose version char char,issue,positive,positive,positive,positive,positive,positive
579679970,"> @nmstoker I got this half finished, then I got tied up with other things. But since then a lot of significant structural changes have been made on master, so it seems like maybe it’s actually simpler to just redo it from scratch.
> 
> I should have time within the next week or two to look at it again.

No pressure here @dabinat, but have you made progresses on that ?",got half finished got tied since lot significant structural made master like maybe actually simpler redo scratch time within next week two look pressure made,issue,negative,positive,neutral,neutral,positive,positive
579679950,"@lissyx @reuben Thanks for your comments. The ides discussed in #2672 is so nice and I withdraw this request.
I am looking forward to 0.7.0!",thanks ides nice withdraw request looking forward,issue,positive,positive,positive,positive,positive,positive
579669787,@lissyx Thanks for your comments.  Moving to `std::unique_ptr<>` is a good idea and I agree with your comments on here and #2695.,thanks moving good idea agree,issue,positive,positive,positive,positive,positive,positive
579655306,"@ryojiysd Thanks for your PR and bringing attention to us about this issue that we (thought was?) fixed. I'm taking care of it with `std::unique_ptr` in #2695, feel free to re-check and open new issues.",thanks attention u issue thought fixed taking care feel free open new,issue,positive,positive,positive,positive,positive,positive
579650789,"> #setup tensorflow-lite
> git clone https://github.com/tensorflow/tensorflow
> cd tensorflow
> ./tensorflow/lite/tools/make/download_dependencies.sh
> ./tensorflow/lite/tools/make/build_aarch64_lib.sh
> #ouput is: ./tensorflow/lite/tools/make/gen/linux_aarch64/lib/libtensorflow-lite.a
> cp ./tensorflow/lite/tools/make/gen/linux_aarch64/lib/libtensorflow-lite.a /usr/lib/aarch64-linux-gnu/
> 
> #setup DeepSpeech
> cd ..
> git clone https://github.com/mozilla/DeepSpeech.git
> pip3 install setuptools
> cd ./DeepSpeech/native_client/python/
> python3 ./setup.py install

Nowhere in our docs you will find those instructions: https://github.com/mozilla/DeepSpeech/blob/v0.6.1/native_client/README.rst",setup git clone setup git clone pip install python install nowhere find,issue,negative,neutral,neutral,neutral,neutral,neutral
579640905,"> I'm unable to run the examples
> 
> OS: PureOS (Debian 10)
> Platform: Librem5 (Arm64)
> Python: 3.7.3
> gcc: (Debian 8.3.0-6) 8.3.0
> 
> Step to duplicate:
> 
> ```
> #as root
> apt-get install build-essential git unzip python3-numpy swig python3-setuptools python3-dev
> 
> #setup tensorflow-lite
> git clone https://github.com/tensorflow/tensorflow
> cd tensorflow
> ./tensorflow/lite/tools/make/download_dependencies.sh
> ./tensorflow/lite/tools/make/build_aarch64_lib.sh
> #ouput is: ./tensorflow/lite/tools/make/gen/linux_aarch64/lib/libtensorflow-lite.a
> cp ./tensorflow/lite/tools/make/gen/linux_aarch64/lib/libtensorflow-lite.a /usr/lib/aarch64-linux-gnu/
> 
> #setup DeepSpeech
> cd ..
> git clone https://github.com/mozilla/DeepSpeech.git
> pip3 install setuptools
> cd ./DeepSpeech/native_client/python/
> python3 ./setup.py install
> 
> cd ../../../
> curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz
> tar xvf deepspeech-0.6.0-models.tar.gz
> 
> #examples ONLY
> curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/audio-0.6.0.tar.gz
> tar xvf audio-0.6.0.tar.gz
> deepspeech --model deepspeech-0.6.0-models/output_graph.pbmm --lm deepspeech-0.6.0-models/lm.binary --trie deepspeech-0.6.0-models/trie --audio audio/2830-3980-0043.wav
> ```
> 
> This gives the error:
> 
> ```
> Traceback (most recent call last):
>   File ""/usr/local/lib/python3.7/dist-packages/deepspeech-0.6.1-py3.7-linux-aarch64.egg/deepspeech/impl.py"", line 14, in swig_import_helper
>     return importlib.import_module(mname)
>   File ""/usr/lib/python3.7/importlib/__init__.py"", line 127, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 670, in _load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 583, in module_from_spec
>   File ""<frozen importlib._bootstrap_external>"", line 1043, in create_module
>   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
> ImportError: /usr/local/lib/python3.7/dist-packages/deepspeech-0.6.1-py3.7-linux-aarch64.egg/deepspeech/_impl.cpython-37m-aarch64-linux-gnu.so: undefined symbol: DS_FreeMetadata
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/usr/local/bin/deepspeech"", line 11, in <module>
>     load_entry_point('deepspeech==0.6.1', 'console_scripts', 'deepspeech')()
>   File ""/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py"", line 490, in load_entry_point
>     return get_distribution(dist).load_entry_point(group, name)
>   File ""/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py"", line 2853, in load_entry_point
>     return ep.load()
>   File ""/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py"", line 2444, in load
>     return self.resolve()
>   File ""/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py"", line 2450, in resolve
>     module = __import__(self.module_name, fromlist=['__name__'], level=0)
>   File ""/usr/local/lib/python3.7/dist-packages/deepspeech-0.6.1-py3.7-linux-aarch64.egg/deepspeech/__init__.py"", line 23, in <module>
>     from deepspeech.impl import PrintVersions as printVersions
>   File ""/usr/local/lib/python3.7/dist-packages/deepspeech-0.6.1-py3.7-linux-aarch64.egg/deepspeech/impl.py"", line 17, in <module>
>     _impl = swig_import_helper()
>   File ""/usr/local/lib/python3.7/dist-packages/deepspeech-0.6.1-py3.7-linux-aarch64.egg/deepspeech/impl.py"", line 16, in swig_import_helper
>     return importlib.import_module('_impl')
>   File ""/usr/lib/python3.7/importlib/__init__.py"", line 127, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
> ModuleNotFoundError: No module named '_impl'
> ```
> 
> TensorFlow version:
> 
> ```
> root@pureos:/home/purism/voice_cmd/tensorflow# cat .git/refs/heads/master
> 2c46d0054750b679f6aaae4532ae0cf5fd286fc0
> root@pureos:/home/purism/voice_cmd/tensorflow# git describe --tags
> v1.12.1-23419-g2c46d00547
> ```

You are not following the docs to rebuild. This can't work.

Also, we have pre-built packages for ARM64, have you tried them? ",unable run o platform arm python step duplicate root install git swig setup git clone setup git clone pip install python install curl tar curl tar model audio error recent call last file line return file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line undefined symbol handling exception another exception recent call last file line module file line return group name file line return file line load return file line resolve module file line module import file line module file line return file line return name level package level module version root cat root git describe following rebuild ca work also arm tried,issue,negative,negative,neutral,neutral,negative,negative
579632613,"Yes, that would be a better way to do this. See for example the changes here: https://github.com/mozilla/DeepSpeech/pull/2681/commits/b07e42671c7e637f08de9e4a3d5831c69222a22f#diff-0317a0e76ece10e0dba742af310a2362L108-R143

You could similarly add a `DS_SetDecoderPruningParams(unsigned int cutoff_top_n, float cutoff_prob)` to change the values from their defaults.",yes would better way see example could similarly add unsigned float change,issue,positive,positive,positive,positive,positive,positive
579370302,I vote for this as there is almost no difference in the final accuracy / WERs,vote almost difference final accuracy,issue,negative,neutral,neutral,neutral,neutral,neutral
579363821,"@reuben Maybe this would advocate for your ""getopt-like"" proposal ?",maybe would advocate proposal,issue,negative,neutral,neutral,neutral,neutral,neutral
579361577,"As said on IRC, on french model I could see a ~5% increase in quality, i.e., ~5% decrease in WER, compared to previous training, using the same parameters.",said model could see increase quality decrease wer previous training,issue,negative,negative,negative,negative,negative,negative
579355877,"As written in the issue template, this should have been asked on discourse. Also, a quick search of ""tensorflow 2.0"" reveals https://github.com/mozilla/DeepSpeech/issues/2506",written issue template discourse also quick search,issue,negative,positive,positive,positive,positive,positive
579330167,"> 
> 
> > > Maybe @carlfm01 also has spotted that ?
> > 
> > 
> > Sort of a feeling, but did not dig into it [#2403 (comment)](https://github.com/mozilla/DeepSpeech/issues/2403#issuecomment-544085038)
> > Time ago when the past issue of the memory leak was fixed I let it for a while creating and releasing and it was releasing before a couple runs(.Net Client).
> > So yes, this looks like to confirm my suspicion.
> 
> Could you give a try to #2695 ? I really prefer we take the opportunity to move to `std::unique_ptr<>`, I'm sure I tried that in the past and I don't remember why we failed / discarded it.

I guess the main issue with the trie leak was to big that it was making this one unnoticeable thus reverted this one.

I'll try, just allow me some time.",maybe also spotted sort feeling dig comment time ago past issue memory leak fixed let couple client yes like confirm suspicion could give try really prefer take opportunity move sure tried past remember guess main issue leak big making one unnoticeable thus one try allow time,issue,positive,positive,neutral,neutral,positive,positive
579319279,"> > Maybe @carlfm01 also has spotted that ?
> 
> Sort of a feeling, but did not dig into it [#2403 (comment)](https://github.com/mozilla/DeepSpeech/issues/2403#issuecomment-544085038)
> 
> Time ago when the past issue of the memory leak was fixed I let it for a while creating and releasing and it was releasing before a couple runs(.Net Client).
> 
> So yes, this looks like to confirm my suspicion.

Could you give a try to #2695 ? I really prefer we take the opportunity to move to `std::unique_ptr<>`, I'm sure I tried that in the past and I don't remember why we failed / discarded it.",maybe also spotted sort feeling dig comment time ago past issue memory leak fixed let couple client yes like confirm suspicion could give try really prefer take opportunity move sure tried past remember,issue,positive,positive,neutral,neutral,positive,positive
579318100,"> Maybe @carlfm01 also has spotted that ?

Sort of a feeling, but did not dig into it  https://github.com/mozilla/DeepSpeech/issues/2403#issuecomment-544085038

Time ago when the past issue of the memory leak was fixed I let it for a while creating and releasing and it was releasing after a couple runs(.Net Client).

So yes, this looks like to confirm my suspicion.",maybe also spotted sort feeling dig time ago past issue memory leak fixed let couple client yes like confirm suspicion,issue,negative,negative,neutral,neutral,negative,negative
579296074,"Closing this PR and re-opening from a new, cleaner, more readable branch in #2696 2696",new cleaner readable branch,issue,negative,positive,positive,positive,positive,positive
579252657,"> @lissyx -- I've made changes which allow for transfer learning with a 0.6.1 model trained with cudnn. tests work. I have hosted a russian WAV file and transcript on the web and made an importer for them

There is still a conflict reported on `.compute` in your PR :/",made allow transfer learning model trained work file transcript web made importer still conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
579238586,@lissyx -- I've made changes which allow for transfer learning with a 0.6.1 model trained with cudnn. tests work. I have hosted a russian WAV file and transcript on the web and made an importer for them,made allow transfer learning model trained work file transcript web made importer,issue,negative,neutral,neutral,neutral,neutral,neutral
579188995,"> Actually, I observed a memory leak in my environment:
> 
>     * OS: Windows Server 2019
> 
>     * Compiler: Visual Studio 2015 Update3
> 
>     * Tensorflow 1.15.0
> 
>     * My test case called _DS_CreateModel_ and _DS_FreeModel_ repeatedly.

@ryojiysd It'd be great if you could share you results regarding that leakage, so we are sure there's no specifc Windows behavior here and we are indeed talking about the same thing.

Maybe @carlfm01 also has spotted that ?",actually memory leak environment o server compiler visual studio update test case repeatedly great could share regarding leakage sure behavior indeed talking thing maybe also spotted,issue,positive,positive,positive,positive,positive,positive
579152394,"```
diff --git a/native_client/client.cc b/native_client/client.cc
index 99af904e..92858a15 100644
--- a/native_client/client.cc
+++ b/native_client/client.cc
@@ -366,6 +366,19 @@ main(int argc, char **argv)
     return 1;
   }
 
+  for (int i = 0; i < 20; i++) {
+    ModelState* ctx;
+    int status = DS_CreateModel(model, beam_width, &ctx);
+    if (status != 0) {
+      fprintf(stderr, ""Could not create model.\n"");
+      return 1;
+    }
+    printf(""DS_CreateModel/DS_FreeModel #%d\n"", i);
+    DS_FreeModel(ctx);
+  }
+
+  return 0;
+
   // Initialise DeepSpeech
   ModelState* ctx;
   int status = DS_CreateModel(model, beam_width, &ctx);
```

```
$ tail -n 12 std-unique_ptr.*
==> std-unique_ptr.0.log <==
==25363== 
==25363== LEAK SUMMARY:
==25363==    definitely lost: 32 bytes in 1 blocks
==25363==    indirectly lost: 72 bytes in 3 blocks
==25363==      possibly lost: 330,996 bytes in 1,472 blocks
==25363==    still reachable: 1,551,566 bytes in 33,791 blocks
==25363==                       of which reachable via heuristic:
==25363==                         stdstring          : 396,638 bytes in 11,288 blocks
==25363==                         newarray           : 3,792 bytes in 9 blocks
==25363==         suppressed: 0 bytes in 0 blocks
==25363== 
==25363== ERROR SUMMARY: 28 errors from 28 contexts (suppressed: 0 from 0)

==> std-unique_ptr.1.log <==
==29407== 
==29407== LEAK SUMMARY:
==29407==    definitely lost: 29,920 bytes in 25 blocks
==29407==    indirectly lost: 6,108,730 bytes in 81,381 blocks
==29407==      possibly lost: 610,067 bytes in 5,140 blocks
==29407==    still reachable: 2,009,189 bytes in 39,701 blocks
==29407==                       of which reachable via heuristic:
==29407==                         stdstring          : 528,199 bytes in 12,793 blocks
==29407==                         newarray           : 30,320 bytes in 134 blocks
==29407==         suppressed: 0 bytes in 0 blocks
==29407== 
==29407== ERROR SUMMARY: 321 errors from 321 contexts (suppressed: 0 from 0)
```

Where `std-unique_ptr.0.log` includes the move to `std::unique_ptr<>` and `std-unique_ptr.1.log` is with plain pointers.
",git index main char return status model status could create return return status model tail log leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed error summary suppressed log leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed error summary suppressed log move log plain,issue,negative,negative,neutral,neutral,negative,negative
579149058,"> > Actually, I observed a memory leak in my environment:
> 
> Well, back then we verified extenstively and there was no leak under valgrind on the same.

Re-running valgrind on current `r1.15` does indeed shows leaks. I still have a few even with `std::unique_ptr`, though.",actually memory leak environment well back leak current indeed still even though,issue,negative,neutral,neutral,neutral,neutral,neutral
579136434,We should just move to `std::unique_ptr<>` like we do on TFLite side anyway ...,move like side anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
579133873,"> Actually, I observed a memory leak in my environment:

Well, back then we verified extenstively and there was no leak under valgrind on the same.",actually memory leak environment well back leak,issue,negative,neutral,neutral,neutral,neutral,neutral
579115608,"Actually, I observed a memory leak in my environment:
- OS: Windows Server 2019
- Compiler: Visual Studio 2015 Update3
- Tensorflow 1.15.0
- My test case called *DS_CreateModel* and *DS_FreeModel* repeatedly.

And other person reported the similar issue (https://stackoverflow.com/questions/44879692/tensorflow-c-api-memory-leak).

TensorFlow's official example also delete a Session object using unique_ptr (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/public).

In any case, I think the object created by *new* operator should always be deleted by *delete* operator.",actually memory leak environment o server compiler visual studio update test case repeatedly person similar issue official example also delete session object case think object new operator always delete operator,issue,negative,positive,neutral,neutral,positive,positive
579108771,Pretty sure we already verified that with valgrind and there was no leak. @reuben ,pretty sure already leak,issue,negative,positive,positive,positive,positive,positive
578544354,"> What's wrong with my linker?

No idea, sorry. 

> Will pre-built binaries using `util/taskcluster.py` work out the same as I will build?

Yes. You can also download from pypi / npm / github releases.

Since you confirmed it's not related to our code I'll close. Please feel free to reach for support on Discourse ",wrong linker idea sorry work build yes also since confirmed related code close please feel free reach support discourse,issue,positive,negative,neutral,neutral,negative,negative
578540404,"@lissyx Initially,I have used default GCC which is 7.4.0 giving me the same error. Then as mentioned here ""https://www.tensorflow.org/install/source#tested_build_configurations"" I tried it with GCC 4.8.5 but it again gives me the same error. 
Yes, there is something weird with linker because as you have mentioned `//tensorflow:libtensorflow_cc.so` giving me the same errorr
What's wrong with my linker?

I am trying to build a binaries for my own data. Will pre-built binaries using `util/taskcluster.py` work out the same as I will build?",initially used default giving error tried error yes something weird linker giving wrong linker trying build data work build,issue,negative,negative,negative,negative,negative,negative
578499804,Could you also tell us why you don't use pre-built binaries? ,could also tell u use,issue,negative,neutral,neutral,neutral,neutral,neutral
578497816,"@piyush101 There is something weird with your linker. Why do you use GCC 4.8.5 on Ubuntu 18.04 ? That's not the default setup. Those linking errors are not from DeepSpeech, I'm sure if you build `//tensorflow:libtensorflow_cc.so` you will have them as well.",something weird linker use default setup linking sure build well,issue,negative,neutral,neutral,neutral,neutral,neutral
578113219,">  While using deepspeech for large audio files, it takes a lot of time to generate transcript and I understand that it is usual, but can we add a flag or feature to print the transcription on the go. For example, print transcription as soon as deepspeech generates it. May be current version of deepspeech is building a string and after interference finishes it's work, the entire string get's print, so if we could print transcription on the go it would be more helpful.

Have you had a look at the API ? How does https://deepspeech.readthedocs.io/en/v0.6.1/C-API.html#_CPPv419DS_FeedAudioContentP14StreamingStatePKsj and https://deepspeech.readthedocs.io/en/v0.6.1/C-API.html#_CPPv421DS_IntermediateDecodeP14StreamingState not fit your need ?",large audio lot time generate transcript understand usual add flag feature print transcription go example print transcription soon may current version building string interference work entire string get print could print transcription go would helpful look fit need,issue,positive,positive,neutral,neutral,positive,positive
578061236,"> I missed the fact that this was in 1.0...

I don't know if this has to be in 1.0. We can, if it's too much, delay it for 2.0.

",fact know much delay,issue,negative,positive,positive,positive,positive,positive
577793819,"> > you have to use the latest generate_trie to generate the trie file in order to match the version.
> 
> No, you need to use **matching** version, the latest from master **might** be too recent as well.

Yes, my bad; you need to check the version which you generate the trie and the version of the deepspeech you are using. Cheers.",use latest generate file order match version need use matching version latest master might recent well yes bad need check version generate version,issue,negative,positive,neutral,neutral,positive,positive
577790955,"> you have to use the latest generate_trie to generate the trie file in order to match the version.

No, you need to use **matching** version, the latest from master **might** be too recent as well.",use latest generate file order match version need use matching version latest master might recent well,issue,negative,positive,positive,positive,positive,positive
577785203,"> I think currently TF and TFLite implementations return different error codes for ""format not understood"", so we could make that consistent to help.

We could, but I would also understand that people find this way to deal kind of not completely satifsying.



> For CUDA, I can't think of a reason why you'd want to programaticaly switch the input model depending on that...

For CUDA, I don't remember the rationale but there was something else, some time ago.",think currently return different error format understood could make consistent help could would also understand people find way deal kind completely ca think reason want switch input model depending remember rationale something else time ago,issue,positive,positive,positive,positive,positive,positive
577781728,"you have to use the latest generate_trie to generate the trie file in order to match the version.

[Reference](https://github.com/mozilla/DeepSpeech/blob/d925e6b5fc186f3524e7c03d6eacf440d5366262/data/lm/README.rst)",use latest generate file order match version reference,issue,negative,positive,positive,positive,positive,positive
577716491,"I missed the fact that this was in 1.0, it involves more changes than the ones currently in #2681. It shouldn't be too difficult, but it will complicate the API a bit, as every call that creates a stream will need to take a scorer parameter.",fact currently difficult complicate bit every call stream need take scorer parameter,issue,negative,negative,negative,negative,negative,negative
577693072,"> He was referring to some automation regarding the filenames for the model. Maybe we could avoid exposing that information and just be more intelligent ?
> 
> I'm afraid of exposing too much and we have to deal with strange compatibility workaround in the future ?

Yeah, thinking more about it I feel like it's exposing too much of an implementation detail. Instead I think users should simply try to load models in order of preference and check for errors when loading. I think currently TF and TFLite implementations return different error codes for ""format not understood"", so we could make that consistent to help. For CUDA, I can't think of a reason why you'd want to programaticaly switch the input model depending on that...",regarding model maybe could avoid information intelligent afraid much deal strange compatibility future yeah thinking feel like much implementation detail instead think simply try load order preference check loading think currently return different error format understood could make consistent help ca think reason want switch input model depending,issue,positive,positive,neutral,neutral,positive,positive
577690972,"I think because we are using semver, we should use it consistently, and expose the suffix as well.",think use consistently expose suffix well,issue,negative,positive,positive,positive,positive,positive
577682030,"I do see your point that in C code with a single integer you could then easily do something like:

```c
int version = DS_Version();
int minimum_supported = 0x000600;
int scorer_package = 0x000700;
int runs_on_my_fridge = 0x000800;
if (version <= minimum_supported) {
    DS_EnableDecoderWithLM(...);
} else if (version <= scorer_package) {
    DS_EnableExternalScorer(...);
} else if (version <= runs_on_my_fridge) {
    DS_EnableGroceriesDetection(...);
} // ...and so on
```",see point code single integer could easily something like version version else version else version,issue,positive,positive,positive,positive,positive,positive
577680087,"> Do we care about the alpha part? In this case, `VERSION=0x000700` and that's it

We currently ship our alpha builds, so code relying on checks like that wouldn't be able to differentiate between `v0.7.0-alpha.N` and `v0.7.0` stable. For our diagnostics we'd lose precious information (this person is using an alpha build, and which one).",care alpha part case currently ship alpha code like would able differentiate stable diagnostics lose precious information person alpha build one,issue,positive,positive,positive,positive,positive,positive
577644367,"> > Having work with / on packaging at distro level, I know parsing versions can be a source of issues.
> 
> Even with semver? There's probably a library to parse semver version strings for every language out there.

It's not wrong that semver do comes with much higher standards regarding this problem. Maybe we could live with just that, though I find it a bit painful if, e.g., I need a lib parse and handle `#ifdef` in plain `C`.",work level know source even probably library parse version every language wrong come much higher regarding problem maybe could live though find bit painful need parse handle plain,issue,negative,negative,negative,negative,negative,negative
577642930,"> ```
> 
> ```
> 
> 
> > Someone reported that exposing the underlying runtime might be of help as well, maybe we should to that at the same time ?
> 
> 
> Agreed, that would be a good thing to have.

He was referring to some automation regarding the filenames for the model. Maybe we could avoid exposing that information and just be more intelligent ?

I'm afraid of exposing too much and we have to deal with strange compatibility workaround in the future ?",someone underlying might help well maybe time agreed would good thing regarding model maybe could avoid information intelligent afraid much deal strange compatibility future,issue,positive,positive,positive,positive,positive,positive
577639831,"> I'd rather avoid having to ship version `B.A.D`. How would you encode `v0.7.0-alpha.0` in that scheme? I also don't see how this makes it easier to compare? One would still need to extract the major, minor, patch, pre-release components out of the number and then apply the same logic.

Do we care about the alpha part? In this case, `VERSION=0x000700` and that's it



> I also don't see how this makes it easier to compare?

Correct me if I'm wrong, but `0x000601 < 0x000700`, while it's a bit more painful when you separate MAJOR/MINOR/PATCH.",rather avoid ship version would encode scheme also see easier compare one would still need extract major minor patch number apply logic care alpha part case also see easier compare correct wrong bit painful separate,issue,negative,negative,negative,negative,negative,negative
577638527,"> Having work with / on packaging at distro level, I know parsing versions can be a source of issues.

Even with semver? There's probably a library to parse semver version strings for every language out there.

> We could have VERSION=0x000601 for 0.6.1, this makes it easy to read as well as to use for comparisions.

I'd rather avoid having to ship version `B.A.D`. How would you encode `v0.7.0-alpha.0` in that scheme? I also don't see how this makes it easier to compare? One would still need to extract the major, minor, patch, pre-release components out of the number and then apply the same logic.

If parsing is a problem and we need to expose individual numerical components I'd rather go with

```
VERSION_MAJOR = 0
VERSION_MINOR = 6
VERSION_PATCH = 1
VERSION_PRERELEASE = ''
```

> Someone reported that exposing the underlying runtime might be of help as well, maybe we should to that at the same time ?

Agreed, that would be a good thing to have.",work level know source even probably library parse version every language could easy read well use rather avoid ship version would encode scheme also see easier compare one would still need extract major minor patch number apply logic problem need expose individual numerical rather go someone underlying might help well maybe time agreed would good thing,issue,positive,positive,positive,positive,positive,positive
577629637,"> @lissyx thoughts?

Having work with / on packaging at distro level, I know parsing versions can be a source of issues.
I think the proposal make sense, but I would like to avoid exposing as strings, at least for our version.

We could have `VERSION=0x000601` for 0.6.1, this makes it easy to read as well as to use for comparisions.

I don't think we should expose TensorFlow version, though.

Someone reported that exposing the underlying runtime might be of help as well, maybe we should to that at the same time ?

Like:
```
enum {
    TENSORFLOW_CPU = 0x00,
    TENSORFLOW_GPU_CUDA = 0x01,
    TENSORFLOW_TFLITE = 0x02,
} _runtime;
```

?",work level know source think proposal make sense would like avoid least version could easy read well use think expose version though someone underlying might help well maybe time like,issue,positive,positive,neutral,neutral,positive,positive
577310117,"> Thanks! I was going to update the docs but then I got flashbacks of previous API breaks where users read master docs and the options don't work with the stable release and we get several issues. Maybe it's unavoidable, but perhaps we can land the docs update closer to the v0.7 release when this goes out? What do you think?

That feels like a recipe for forgetting and doing mistakes, I think I still prefer to have to tell people to refer to the correct doc. That should be easier, also, now that we have ReadTheDocs links and versioning there, and that the default version there is 0.6.1.",thanks going update got previous read master work stable release get several maybe unavoidable perhaps land update closer release go think like recipe forgetting think still prefer tell people refer correct doc easier also link default version,issue,positive,positive,neutral,neutral,positive,positive
577288160,"Thanks! I was going to update the docs but then I got flashbacks of previous API breaks where users read master docs and the options don't work with the stable release and we get several issues. Maybe it's unavoidable, but perhaps we can land the docs update closer to the v0.7 release when this goes out? What do you think?",thanks going update got previous read master work stable release get several maybe unavoidable perhaps land update closer release go think,issue,positive,positive,neutral,neutral,positive,positive
577207525,"> Is this done? I think we can't publish Android x86-64 on PyPI?

Well it's only bundled in the `libdeepspeech` AAR. I think it's mostly done, but I would not be against another pair of eyes verifying we have it everywhere, either as default runtime or as an alternative package.",done think ca publish android well think mostly done would another pair everywhere either default alternative package,issue,negative,positive,positive,positive,positive,positive
577202963,Is this done? I think we can't publish Android x86-64 on PyPI?,done think ca publish android,issue,negative,neutral,neutral,neutral,neutral,neutral
577174677,"This is a big one, so I highly recommend reviewing on a per commit basis. GitHub now lets you see changes from a commit range, which helps. The main interesting parts are:

- The new data/lm/generate_package.py script
- The changes to native_client/ctcdecode/scorer.{h,cpp} for the new format
- API changes in b07e42671c7e637f08de9e4a3d5831c69222a22f",big one highly recommend per commit basis see commit range main interesting new script new format,issue,positive,positive,positive,positive,positive,positive
577105244,"@lissyx  Yes, I just came to work and checked the process and everything was successfully built. It was the .cpp file that caused the issue :) Thanks for the help.",yes came work checked process everything successfully built file issue thanks help,issue,positive,positive,positive,positive,positive,positive
577068669,"> @lissyx Yes, there was a dangling swigwrapper_wrap.cpp. I am currently doing a clean bazel build (clean tf, clean DS, just cloned) and am waiting for the results to see if the error appears again. That's why I did not respond sooner. Sorry.

@cli0 So, any news ?",yes dangling currently clean build clean clean waiting see error respond sooner sorry news,issue,positive,positive,positive,positive,positive,positive
577068486,"> what should I do?

Read the documentation and the issue template you removed.



> generate_trie bin : I donwload several prebuild trie bin
> (the link is right now error)

What does that mean ?

>  Error: Trie file version mismatch (4 instead of expected 5). Update your trie file.

`data/lm/trie` is the wrong version. What did you do, exactly ?",read documentation issue template removed bin several bin link right error mean error file version mismatch instead update file wrong version exactly,issue,negative,negative,neutral,neutral,negative,negative
576749464,"> @lissyx Yes, there was a dangling swigwrapper_wrap.cpp. I am currently doing a clean bazel build (clean tf, clean DS, just cloned) and am waiting for the results to see if the error appears again. That's why I did not respond sooner. Sorry.

I'm confident it's going to work ...",yes dangling currently clean build clean clean waiting see error respond sooner sorry confident going work,issue,positive,positive,positive,positive,positive,positive
576741849,"@lissyx  Yes, there was a dangling swigwrapper_wrap.cpp. I am currently doing a clean bazel build (clean tf, clean DS, just cloned) and am waiting for the results to see if the error appears again. That's why I did not respond sooner. Sorry.",yes dangling currently clean build clean clean waiting see error respond sooner sorry,issue,positive,positive,positive,positive,positive,positive
576740252,"> The command I used is
> 
> `bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --config=cuda `
> 
> I am just building DeepSpeech binaries according to: https://github.com/mozilla/DeepSpeech/tree/master/native_client

@cli0 Can you please verify for stale files, as stated above ?",command used build opt building according please verify stale stated,issue,negative,negative,negative,negative,negative,negative
576730728,"> I am just building DeepSpeech binaries according to: https://github.com/mozilla/DeepSpeech/tree/master/native_client

This is documentation for `master`, please use `v0.4.1` documentation.",building according documentation master please use documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
576730245,"The command I used is 

`bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --config=cuda
`

I am just building DeepSpeech binaries according to: https://github.com/mozilla/DeepSpeech/tree/master/native_client",command used build opt building according,issue,negative,neutral,neutral,neutral,neutral,neutral
576730097,@cli0 Could you please ensure you don't have stale files under `native_client/ctcdecode/` ? I suspect you somehow called `make -C native_client/ctcdecode/` and there's a dangling `native_client/ctcdecode/swigwrapper_wrap.cpp` that gets picked by Bazel.,could please ensure stale suspect somehow make dangling picked,issue,negative,negative,negative,negative,negative,negative
576728523,"> I am trying to compile tensorflow and DeepSpeech/native_client/ using bazel and I get this error:

Your error refers to SWIG wrapper for CTC decode. That's not related to Bazel. Can you please clarify what you are doing exactly ?",trying compile get error error swig wrapper decode related please clarify exactly,issue,negative,positive,positive,positive,positive,positive
575627781,"Sure, I think it's likely this will get done before the other items in 0.7.",sure think likely get done,issue,negative,positive,positive,positive,positive,positive
575620965,"Dumb question. As this is more-or-less working, mod clean up and testing, do you want to put it in 0.7.0 which will give time for others to ""kick the tires"" on it before it's in 1.0.0? ",dumb question working clean testing want put give time kick,issue,negative,negative,neutral,neutral,negative,negative
575588814,"The issue template is meant to be read, not deleted blindly. For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).",issue template meant read blindly support please use discourse,issue,positive,negative,negative,negative,negative,negative
574741915,Got it running and producing correct results after loading both the LM and the trie from the same file.,got running correct loading file,issue,negative,neutral,neutral,neutral,neutral,neutral
574730966,"> It's not so complicated:
> 
> ```shell
> # generate LM.binary
> # generate LM.trie
> cat LM.binary LM.trie > LM.package
> ```

It is actually more complicated. Will need to make a tool (e.g. adapt `generate_trie`) to generate the packed format.",complicated shell generate generate cat actually complicated need make tool adapt generate format,issue,negative,negative,negative,negative,negative,negative
574653269,"> **Proposal**: For the suggested API
> 
> ```c++
> int DS_SetScorerOptionInt(ModelState* ctx, int optionCode, int optionValue);
> ```
> 
> people can use it incorrectly (Think of the discourse posts!) doing things like
> 
> ```c++
> DS_SetScorerOptionInt(ctx, DS_SCORER_ALPHA, 3);
> ```

Yes, this is why I included an explicit option:

```c++
int DS_SetScorerAlphaBeta(ModelState* ctx, float alpha, float beta);
```

We would then deprecate the function rather than an individual entry in an enum, and make it conditionally no-op if we ship a new LM implementation that doesn't have alpha and beta hyperparameters.

---

> If we were to ever remove values
> [...]
> we would break the ABI.
> 
> However, we'd only remove values if we dropped support for older LM techniques. Are we OK with requiring an ABI break when we drop support for an old LM technique?

I can't think of any way to remove support for a feature without breaking the API. We should be planning with this in mind, whatever we ship in 1.x will stay until 2.x. We can introduce a new option in 1.x and deprecate old options, but not remove them.

---

> **Implementation details**: Would something less fancy work?
> 
> For example zipping the LM, trie, and a config file (containing alpha + beta) and unzipping, or putting some code in front of KenLM to make it looks like normal files on disk.

Putting some code in front of KenLM to trick it would be much more complicated, we'd have to somehow emulate POSIX file APIs, it sounds like a recipe for disaster to me.

> If we do something like you suggest we'll have to create tooling, and documentation, to allow others to create such ""packed"" language models.

It's not so complicated:

```bash
# generate LM.binary
# generate LM.trie
cat LM.binary LM.trie > LM.package
```

---

> One of the thing I'm wondering is mmap(). As much as I recall, we don't use it for the trie file, but it's being used by KenLM.

I've tested that the approach above (concatenating the files) works for KenLM, I now need to figure out how to get the total LM file size from KenLM to skip to the correct offset for the trie. And we also use `mmap` for the trie.

> Basically, I think your proposal might be a good improvement, but I'm (generally speaking) not a big big fan of that kind of interface (I hate it for getopt). I also don't have a better proposal for the moment.

OK, so for now the no abstraction option is the favorite one. I'll continue working on getting the single file working for now, and after that's working we can revisit the hyperparameter option if needed.",proposal people use incorrectly think discourse like yes included explicit option float alpha float beta would deprecate function rather individual entry make conditionally ship new implementation alpha beta ever remove would break however remove support older break drop support old technique ca think way remove support feature without breaking mind whatever ship stay introduce new option deprecate old remove implementation would something le fancy work example zipping file alpha beta code front make like normal disk code front trick would much complicated somehow emulate file like recipe disaster something like suggest create tooling documentation allow create language complicated bash generate generate cat one thing wondering much recall use file used tested approach work need figure get total file size skip correct offset also use basically think proposal might good improvement generally speaking big big fan kind interface hate also better proposal moment abstraction option favorite one continue working getting single file working working revisit option,issue,positive,positive,neutral,neutral,positive,positive
574645661,"> people can use it incorrectly (Think of the discourse posts!) doing things like

That's what would worry me the most.

> However, we'd only remove values if we dropped support for older LM techniques. Are we OK with requiring an ABI break when we drop support for an old LM technique?

IMHO I'd agree it's an acceptable compromise here.



> For example zipping the LM, trie, and a config file (containing alpha + beta) and unzipping, or putting some code in front of KenLM to make it looks like normal files on disk.

I think that zipping is going to be much painful, adding an extra step and thus latency, even if it's hidden by the API.



> This is hacky, but the goal here is just to move to a single file

Totally agree with that, even if it's hacky. Though, given your proposal and especially `DS_EnableExternalScorer` I think we should ensure this is actually working and that there is no snarky issue that would arise. One of the thing I'm wondering is `mmap()`. As much as I recall, we don't use it for the `trie` file, but it's being used by KenLM.

Basically, I think your proposal might be a good improvement, but I'm (generally speaking) not a big big fan of that kind of interface (I hate it for getopt). I also don't have a better proposal for the moment.",people use incorrectly think discourse like would worry however remove support older break drop support old technique agree acceptable compromise example zipping file alpha beta code front make like normal disk think zipping going much painful extra step thus latency even hidden hacky goal move single file totally agree even hacky though given proposal especially think ensure actually working issue would arise one thing wondering much recall use file used basically think proposal might good improvement generally speaking big big fan kind interface hate also better proposal moment,issue,positive,positive,neutral,neutral,positive,positive
574630182,"> first non-empty line was ""version https://git-lfs.github.com/spec/v1"" not \data\. Byte: 43

This is trivially documented as improper setup of `git lfs`. Please check your setup, and reach for support on Discourse. This is not a DeepSpeech bug.",first line version trivially improper setup git please check setup reach support discourse bug,issue,positive,positive,positive,positive,positive,positive
574567712,"**Proposal**: For the suggested API
```cpp
int DS_SetScorerOptionInt(ModelState* ctx, int optionCode, int optionValue);
int DS_SetScorerOptionFloat(ModelState* ctx, int optionCode, float optionValue);
int DS_SetScorerOptionStr(ModelState* ctx, int optionCode, char* optionValue);
```
people can use it incorrectly (Think of the discourse posts!) doing things like
```cpp
DS_SetScorerOptionInt(ctx, DS_SCORER_ALPHA, 3);
```
Using and enum in this way, as far as I understand, will only _not_ break the ABI if we only add new values, i.e.
```cpp
enum DS_ScorerOptions
{
    DS_SCORER_ALPHA,
    DS_SCORER_BETA,
    DS_SCORER_FOO,
};
```
If we were to ever  remove values
```cpp
enum DS_ScorerOptions
{
    DS_SCORER_FOO,
};
```
we would break the ABI. 

However, we'd only remove values if we dropped support for older LM techniques. Are we OK with requiring an ABI break when we drop support for an old LM technique?

Also, a nit, the string should be immutable
```cpp
int DS_SetScorerOptionStr(ModelState* ctx, int optionCode, const char* optionValue);
```
**Implementation details**: Would something less fancy work?

For example zipping the LM, trie, and a config file (containing alpha + beta) and unzipping, or putting some code in front of KenLM to make it looks like normal files on disk.

If we do something like you suggest we'll have to create tooling, and documentation, to allow others to create such ""packed"" language models.",proposal float char people use incorrectly think discourse like way far understand break add new ever remove would break however remove support older break drop support old technique also nit string immutable char implementation would something le fancy work example zipping file alpha beta code front make like normal disk something like suggest create tooling documentation allow create language,issue,positive,positive,positive,positive,positive,positive
574318999,"> Distribution is through the Play Store and App Store. Most users just won't be willing to download a 1GB app and it's generally seen as pretty bad to have a huge app. That's mostly what I'm referring to.
> 
> There are also some store limitations - on Android it's technically possible but tricky to have your bundle be over 100MB.

Ok, that's mostly what I was expecting. While I agree that 1GB can be problematic (not everybody has LTE with unlimited plan nor WiFi backed by optic) it's still doable, if you want to experiment, to host the data elsewhere. This is what we do in some cases. It brings other issues.

At some point, it's really complicated to solve everything and keep into the APK or other: if you want / need to address several languages, then either your size explodes, or you host them elsewhere.

As much as I recall, Android's way of splitting was also an issue because we would be unable to properly `mmap()` the file, but that's from my memory, not sure it is really the case.",distribution play store store wo willing generally seen pretty bad huge mostly also store android technically possible tricky bundle mostly agree problematic everybody unlimited plan backed optic still doable want experiment host data elsewhere point really complicated solve everything keep want need address several either size host elsewhere much recall android way splitting also issue would unable properly file memory sure really case,issue,positive,positive,neutral,neutral,positive,positive
574314842,"> Are the LMs you were using the same as the ones hosted on [OpenSLR](http://www.openslr.org/11/)? Theirs are 759MB for 3-gram ARPA LM unpruned, down to 13MB for 3-gram ARPA LM pruned with 3e-7.

No. They were built from that dataset though. I built lower order (o=2, o=1) models, and pruned more aggressively (`--prune 0 1` on the `-o 2` models). I then filtered models to the top 100k words in the LibriSpeech LM corpus, following a similar procedure as documented in `data/lm/generate_lm.py`.",unpruned built though built lower order aggressively prune top corpus following similar procedure,issue,negative,positive,positive,positive,positive,positive
574311870,"Distribution is through the Play Store and App Store. Most users just won't be willing to download a 1GB app and it's generally seen as pretty bad to have a huge app. That's mostly what I'm referring to.

There are also some store limitations - on Android it's technically possible but tricky to have your bundle be over 100MB.",distribution play store store wo willing generally seen pretty bad huge mostly also store android technically possible tricky bundle,issue,negative,positive,positive,positive,positive,positive
574304027,"> Do you have any information on how those smaller LMs for the test were generated?

I guess reuben changed the content of the vocabulary, maybe through filtering?


> just that I feel like getting total filesize down to <100MB crosses a threshold where many many more app developers would be willing to use it and include in a production app distribution.

What is currently blocking you precisely ? Just the **amount** in general, or does the size makes it **impossible** for you to distribute, and if the latter, how do you handle distribution ?",information smaller test guess content vocabulary maybe filtering feel like getting total threshold many many would willing use include production distribution currently blocking precisely amount general size impossible distribute latter handle distribution,issue,negative,positive,positive,positive,positive,positive
574300377,"Sorry, I didn't mean to imply that the current system doesn't work or anything, just that I feel like getting total filesize down to <100MB crosses a threshold where many many more app developers would be willing to use it and include in a production app distribution.

My usecase is that I'm working a mobile app for practicing English speaking. The user reads a sentence and we use ASR to recognize that they said it aloud. I'm excited to try to get the tflite model and small LM working for offline ASR.

Do you have any information on how those smaller LMs for the test were generated?",sorry mean imply current system work anything feel like getting total threshold many many would willing use include production distribution working mobile speaking user sentence use recognize said aloud excited try get model small working information smaller test,issue,positive,positive,neutral,neutral,positive,positive
574291618,"> @lissyx Oh, just that a 950MB LM is way too big to practically distribute in a mobile app, so it's not really usable in production as is. 100MB total for tflite+LM is doable though.

I understand it is big, and it can be a problem in some (many?) cases, but it's not really **blocking** in general.

What's your use-case, if you can share ?",oh way big practically distribute mobile really usable production total doable though understand big problem many really blocking general share,issue,negative,positive,positive,positive,positive,positive
574289184,"@lissyx Oh, just that a 950MB LM is way too big to practically distribute in a mobile app, so it's not really usable in production as is. 100MB total for tflite+LM is doable though.",oh way big practically distribute mobile really usable production total doable though,issue,negative,positive,neutral,neutral,positive,positive
574247558,@tarekeldeeb we could also benefit from your feedback here: does that fixes the issue ?,could also benefit feedback issue,issue,negative,neutral,neutral,neutral,neutral,neutral
574230353,"@tarekeldeeb Your model does output only 2-bytes words. This is breaking some of the logic that we have, but the value coming from the API looks sane.",model output breaking logic value coming sane,issue,negative,neutral,neutral,neutral,neutral,neutral
574173543,"```
$ LD_LIBRARY_PATH=/home/alex/codaz/Mozilla/DeepSpeech/tensorflow/tensorflow/bazel-bin/native_client/:. ./deepspeech --model ~/tmp/deepspeech/quran/imam_graph.pb --audio ~/tmp/deepspeech/0.6.0/audio/4507-16021-0012.wav --json
TensorFlow: v1.15.0-22-gbd115ee104
DeepSpeech: v0.6.1-27-g345102da
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
item[0]: start_time=0.000000, character=و
word boundary not found, might set word_start_time: word.length()=2
item[1]: start_time=0.360000, character=َ
word boundary not found, might set word_start_time: word.length()=4
item[2]: start_time=0.960000, character=ٱ
word boundary not found, might set word_start_time: word.length()=6
item[3]: start_time=0.980000, character=ح
word boundary not found, might set word_start_time: word.length()=8
item[4]: start_time=1.000000, character=ْ
word boundary not found, might set word_start_time: word.length()=10
item[5]: start_time=1.160000, character=ض
word boundary not found, might set word_start_time: word.length()=12
item[6]: start_time=1.180000, character=ُ
word boundary not found, might set word_start_time: word.length()=14
item[7]: start_time=1.320000, character=ل
word boundary not found, might set word_start_time: word.length()=16
item[8]: start_time=1.360000, character=ْ
word boundary not found, might set word_start_time: word.length()=18
item[9]: start_time=1.420000, character= 
word boundary found
w: word_start_time=0.000000, word=وَٱحْضُلْ
item[10]: start_time=1.480000, character=ص
word boundary not found, might set word_start_time: word.length()=2
item[11]: start_time=1.500000, character=َ
word boundary not found, might set word_start_time: word.length()=4
item[12]: start_time=1.760000, character=ف
word boundary not found, might set word_start_time: word.length()=6
item[13]: start_time=1.780000, character=ْ
word boundary not found, might set word_start_time: word.length()=8
item[14]: start_time=1.920000, character=ق
word boundary not found, might set word_start_time: word.length()=10
item[15]: start_time=1.940000, character=َ
word boundary not found, might set word_start_time: word.length()=12
item[16]: start_time=2.100000, character=ل
word boundary not found, might set word_start_time: word.length()=14
item[17]: start_time=2.120000, character=ْ
word boundary not found, might set word_start_time: word.length()=16
item[18]: start_time=2.220000, character= 
word boundary found
w: word_start_time=0.000000, word=صَفْقَلْ
item[19]: start_time=2.260000, character=ط
word boundary not found, might set word_start_time: word.length()=2
item[20]: start_time=2.280000, character=َ
word boundary not found, might set word_start_time: word.length()=4
item[21]: start_time=2.460000, character=ي
word boundary not found, might set word_start_time: word.length()=6
item[22]: start_time=2.480000, character=ْ
word boundary found
w: word_start_time=0.000000, word=طَيْ
{""metadata"":{""confidence"":7.73814},""words"":[{""word"":""وَٱحْضُلْ"",""time"":0,""duration"":1.42},{""word"":""صَفْقَلْ"",""time"":0,""duration"":2.22},{""word"":""طَيْ"",""time"":0,""duration"":2.48}]}
```",model audio warning reading entire model file memory transform model file graph reduce heap usage item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found item word boundary found might set item word boundary found might set item word boundary found might set item word boundary found confidence word time duration word time duration word time duration,issue,negative,neutral,neutral,neutral,neutral,neutral
574160516,"> > > Maybe .. but the output string is perfectly fine. I think the RTL makes issues when mixed with latin letters/symbols or when it has multi-lines. Which is not the case here.
> > 
> > 
> > I'm just wondering how training and inference behaves in that case. Could you share your model, so I can investigate ?
> 
> Thanks a lot for your time. Model and language files are found [here](https://github.com/tarekeldeeb/DeepSpeech-Quran/tree/master/data/quran)

Weird. Although r1.14 and r1.15 should be a bit compatible, I'm getting segfaults loading your Protocolbuffer or TFLite models.

@tarekeldeeb Have those been exported with 0.6.0+ ? Tree status is unclear: `This branch is 41 commits ahead, 112 commits behind mozilla:master.`

Could you maybe share the checkpoints, to make sure ?",maybe output string perfectly fine think mixed case wondering training inference case could share model investigate thanks lot time model language found weird although bit compatible getting loading tree status unclear branch ahead behind could maybe share make sure,issue,positive,positive,neutral,neutral,positive,positive
574145307,"I prefer the second option. For a minute I thought about an (API-wise even simpler) parameter-string alternative, but this could easily end up in an implementation nightmare.",prefer second option minute thought even simpler alternative could easily end implementation nightmare,issue,negative,positive,positive,positive,positive,positive
574141330,"@lissyx @kdavis-mozilla @tilmankamp I'd appreciate any feedback you have on the API proposal. In particular, do you think the second option is unnecessarily abstract?",appreciate feedback proposal particular think second option unnecessarily abstract,issue,negative,negative,neutral,neutral,negative,negative
574134889,"> > Maybe .. but the output string is perfectly fine. I think the RTL makes issues when mixed with latin letters/symbols or when it has multi-lines. Which is not the case here.
> 
> I'm just wondering how training and inference behaves in that case. Could you share your model, so I can investigate ?

Thanks a lot for your time. Model and language files are found  [here](https://github.com/tarekeldeeb/DeepSpeech-Quran/tree/master/data/quran)",maybe output string perfectly fine think mixed case wondering training inference case could share model investigate thanks lot time model language found,issue,positive,positive,positive,positive,positive,positive
574134191,"> Maybe .. but the output string is perfectly fine. I think the RTL makes issues when mixed with latin letters/symbols or when it has multi-lines. Which is not the case here.

I'm just wondering how training and inference behaves in that case. Could you share your model, so I can investigate ?",maybe output string perfectly fine think mixed case wondering training inference case could share model investigate,issue,positive,positive,positive,positive,positive,positive
574129472,"> Did you make any modifications to the code?

Not a single line.

> RTL?

Maybe .. but the output string is perfectly fine. I think the RTL makes issues when mixed with latin letters/symbols or when it has multi-lines. Which is not the case here.

> Can you share more details on how you built this model ?

According to the documentation, the following files have been generated [here](https://github.com/tarekeldeeb/DeepSpeech-Quran/tree/master/data/quran): alphabet.txt, arpa, tri and finally lm.binary

{**Please reopen this issue**, it was closed unintentionally}",make code single line maybe output string perfectly fine think mixed case share built model according documentation following tri finally please reopen issue closed unintentionally,issue,positive,positive,neutral,neutral,positive,positive
574045956,Please use matching versions tools to generate your language model. ,please use matching generate language model,issue,negative,neutral,neutral,neutral,neutral,neutral
574045541,"> @reuben this table is quite exciting because while the 950MB LM is out of the question for a mobile app, 50MB is definitely reasonable and the WER doesn't suffer _that_ much. This truly unlocks the mobile usecase for deepspeech! Can you explain how you got the LM down to 50.9MB and 6.5MB - is it just KenLM pruning and quantization?
> 
> Are the LMs you were using the same as the ones hosted on [OpenSLR](http://www.openslr.org/11/)? Theirs are 759MB for 3-gram ARPA LM unpruned, down to 13MB for 3-gram ARPA LM pruned with 3e-7.

Can you explain how this unlocks the use case? Except disk usage, the current lm already gives very good experience on mobile. ",table quite exciting question mobile definitely reasonable wer suffer much truly mobile explain got pruning quantization unpruned explain use case except disk usage current already good experience mobile,issue,positive,positive,positive,positive,positive,positive
573932747,"@reuben this table is quite exciting because while the 950MB LM is out of the question for a mobile app, 50MB is definitely reasonable and the WER doesn't suffer *that* much. This truly unlocks the mobile usecase for deepspeech! Can you explain how you got the LM down to 50.9MB and 6.5MB - is it just KenLM pruning and quantization?

Are the LMs you were using the same as the ones hosted on [OpenSLR](http://www.openslr.org/11/)? Theirs are 759MB for 3-gram ARPA LM unpruned, down to 13MB for 3-gram ARPA LM pruned with 3e-7.",table quite exciting question mobile definitely reasonable wer suffer much truly mobile explain got pruning quantization unpruned,issue,positive,positive,positive,positive,positive,positive
573775053,"@tarekeldeeb You're working on arabic language, right? Is it possible there's a funny behavior because of RTL here ?",working language right possible funny behavior,issue,negative,positive,positive,positive,positive,positive
573774579,">  How can MyModel behave so weirdly, when the textual output is very good?!

Can you share more details on how you built this model ?",behave weirdly textual output good share built model,issue,negative,positive,neutral,neutral,positive,positive
573731766,"> It may be solved that way, but now it's not in the docs of the newest version.

I'm not sure I get your remark @victornoriega It's right at the begining of `doc/TRAINING.rst`: https://deepspeech.readthedocs.io/en/v0.6.1/TRAINING.html#getting-the-training-code ",may way version sure get remark right,issue,negative,positive,positive,positive,positive,positive
573731232,"> It may be solved that way, but now it's not in the docs of the newest version.

What do you mean, it's not in the docs ?",may way version mean,issue,negative,negative,negative,negative,negative,negative
573662069,"@JRMeyer There are still people asking about your branch, could we please rebase, add tests and merge ?",still people branch could please rebase add merge,issue,negative,neutral,neutral,neutral,neutral,neutral
573624987,"It's very weird. The `time` value reported in the metadata output is incremented monotonically in the decoder, there should be no way for a transcription to have a character with the same time as as its parent (previous character). Did you make any modifications to the code?",weird time value output monotonically way transcription character time parent previous character make code,issue,negative,negative,negative,negative,negative,negative
573623602,"Sorry for being late.

MyModel/MyAudio           --> Time=0, Duration is incremental
MyModel/ExampleAudio  --> Time=0, Duration is incremental
ExampleModel/MyData --> Time is Ok, Duration is Ok

Confidence gets either positive or negative values. Did not catch a pattern here.
How can MyModel behave so weirdly, when the textual output is very good?!",sorry late duration incremental duration incremental time duration confidence either positive negative catch pattern behave weirdly textual output good,issue,positive,negative,negative,negative,negative,negative
573611580,"I'm not entirely sure if tokenizing by grapheme or by grapheme cluster makes sense universally, as I don't know if graphemes or clusters always match up with the pronunciation in the languages where this would matter.

If anyone knows how these things are usually handled for e.g. Telugu, Devanagari, Bengali, I'd love to hear about it.",entirely sure cluster sense universally know always match pronunciation would matter anyone usually handled love hear,issue,positive,positive,positive,positive,positive,positive
573610399,"We added basic checks for simple Unicode normalization pitfalls in `util/check_characters.py`, which should cover most, maybe all Latin languages.

For large alphabets like Mandarin we have found that targeting UTF-8 directly works best.

For more complicated cases like Brahmic scripts, we would need grapheme (-cluster) based tokenization rather than the simple per-codepoint tokenization done by Python and currently used by DeepSpeech. So I'll repurpose this issue for that.",added basic simple normalization cover maybe large like mandarin found directly work best complicated like would need based rather simple done python currently used repurpose issue,issue,positive,positive,positive,positive,positive,positive
573607020,Closing due to lack of activity. Feel free to re-open if this is still a problem.,due lack activity feel free still problem,issue,negative,positive,positive,positive,positive,positive
573605583,"Even a tiny LM is significantly better than using the trie alone, this is not worth the added complexity.",even tiny significantly better alone worth added complexity,issue,negative,positive,positive,positive,positive,positive
573605235,We've [added](https://github.com/mozilla/DeepSpeech/blob/master/doc/TRAINING.rst#training-with-augmentation) training time augmentation. So I'm closing this for now.,added training time augmentation,issue,negative,neutral,neutral,neutral,neutral,neutral
573559149,"No. The sizes in the headers are of the AM and LM independently. You have to sum the row with the column to get the total package size. For example, TFLite model (47MB) + 50.9MB LM = 97.9MB total package, WER = 8.9%.",size independently sum row column get total package size example model total package wer,issue,negative,neutral,neutral,neutral,neutral,neutral
573556592,See here for some WER values with varying model sizes: https://github.com/mozilla/DeepSpeech/issues/2529#issuecomment-573553009,see wer model size,issue,negative,neutral,neutral,neutral,neutral,neutral
573342380,Gotcha. Do you have information about the accuracy of the model with and without the language model on test set?,information accuracy model without language model test set,issue,negative,neutral,neutral,neutral,neutral,neutral
573341790,"Yes, but this issue is not actionable, we're always aiming for smaller, faster, more accurate, so there's not much value in keeping this open.

I wrote a description of the system here, it should help with understanding the roles of the acoustic and language models: https://hacks.mozilla.org/2017/11/a-journey-to-10-word-error-rate/",yes issue actionable always aiming smaller faster accurate much value keeping open wrote description system help understanding acoustic language,issue,positive,positive,positive,positive,positive,positive
573341184,Seems like there's still some way to go to get those sizes.,like still way go get size,issue,negative,neutral,neutral,neutral,neutral,neutral
573341031,"Oh, can you shed some light on the difference between acoustic model and language model? And a benchmark will be awesome to see, thanks!",oh shed light difference acoustic model language model awesome see thanks,issue,positive,positive,positive,positive,positive,positive
573340074,(And we are also currently investigating ways to reduce model size both for the acoustic model and the LM.),also currently investigating way reduce model size acoustic model,issue,negative,neutral,neutral,neutral,neutral,neutral
573340047,"It looks like their acoustic model is 5.17MB and their language model is 37.9MB. Our TFLite quantized acoustic model is 47.3MB and our language model is 957.9MB. DeepSpeech can be used without the language model, and in that case it is pretty much the same size as their model. I'll do a benchmarking run to see what our word error rate is without the LM.",like acoustic model language model acoustic model language model used without language model case pretty much size model run see word error rate without,issue,negative,positive,positive,positive,positive,positive
573314837,"I'm sorry, I just saw your blog post and it seems that with your new version 0.6.0, you're pretty much on par. Great work!",sorry saw post new version pretty much par great work,issue,positive,positive,positive,positive,positive,positive
573165027,"@reuben Well that's the problem: I'd like to use it but I'm training from the pretrained checkpoint so I'm limited to the parameters that were originally used. But if you need feedback, I can do some tests on a new training run and see what I come up with.",well problem like use training limited originally used need feedback new training run see come,issue,negative,positive,positive,positive,positive,positive
573162897,I guess for now we'd rather pay the price of somewhat longer training runs than have to figure out yet another hyperparameter. Do you get similar accuracy with faster training on your tests?,guess rather pay price somewhat longer training figure yet another get similar accuracy faster training,issue,negative,neutral,neutral,neutral,neutral,neutral
573161636,Would it be possible to train with mixed precision for 0.7? Is there a reason it wasn't activated for 0.6?,would possible train mixed precision reason,issue,negative,neutral,neutral,neutral,neutral,neutral
573156679,Somehow this still used node@8 in automation. `tc-vars.sh` also has `node@8` in it when setting the `PATH`.,somehow still used node also node setting path,issue,negative,neutral,neutral,neutral,neutral,neutral
572985341,"if i gave system common_voice_en_18885788.mp3 .it asks for common_voice_en_18885789.mp3 .
i went on and now
OSError: input_filepath /home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir/clips/common_voice_en_18885791.mp3 does not exist.

",gave system went exist,issue,negative,neutral,neutral,neutral,neutral,neutral
572983670,"> @lissyx Should we do this for 1.0.0?

We could, but we need a proper plan, I'm not sure I can commit to this.",could need proper plan sure commit,issue,positive,positive,positive,positive,positive,positive
572981357,"Now back to my old question. Does 

/home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir/clips/common_voice_en_18885788.mp3

exist? And do you have permissions to read it?",back old question exist read,issue,negative,positive,neutral,neutral,positive,positive
572976646,It's possible now to work in Urdu or any other spoken language supported by UTF-8.,possible work spoken language,issue,negative,neutral,neutral,neutral,neutral,neutral
572976177,Closing for lack of activity. Feel free to re-open.,lack activity feel free,issue,negative,positive,positive,positive,positive,positive
572976072,Closing due to lack of activity and the speed with which WER can now be calculated.,due lack activity speed wer calculated,issue,negative,negative,negative,negative,negative,negative
572975599,"Adding this to the 1.0.0 project. This may get implemented there, and it may not dependent upon the LM work done there",project may get may dependent upon work done,issue,negative,neutral,neutral,neutral,neutral,neutral
572973616,Closing due to lack of activity and solutions such as using an aligner existing.,due lack activity aligner,issue,negative,negative,negative,negative,negative,negative
572966425,Closing for lack of activity. Feel free to re-open if still a problem.,lack activity feel free still problem,issue,negative,positive,positive,positive,positive,positive
572960473,"I'm putting this in the 1.0.0 project, as that will contain some language model work, which may include this.",project contain language model work may include,issue,negative,neutral,neutral,neutral,neutral,neutral
572959739,"It's still a problem, but I don't have bandwidth to explore this further anytime soon.",still problem explore soon,issue,negative,neutral,neutral,neutral,neutral,neutral
572958978,"ohh ok
bin/import_cv2.py /home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir
was the command!

Loading TSV file:  /home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir/train.tsv
Saving new DeepSpeech-formatted CSV file to:  /home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir/clips/train.csv
Importing mp3 files...
Traceback (most recent call last):
  File ""bin/import_cv2.py"", line 164, in <module>
    _preprocess_data(PARAMS.tsv_dir, AUDIO_DIR, label_filter_fun, PARAMS.space_after_every_character)
  File ""bin/import_cv2.py"", line 43, in _preprocess_data
    _maybe_convert_set(input_tsv, audio_dir, label_filter, space_after_every_character)
  File ""bin/import_cv2.py"", line 99, in _maybe_convert_set
    for i, _ in enumerate(pool.imap_unordered(one_sample, samples), start=1):
  File ""/usr/lib/python3.7/multiprocessing/pool.py"", line 748, in next
    raise value
  File ""/usr/lib/python3.7/multiprocessing/pool.py"", line 121, in worker
    result = (True, func(*args, **kwds))
  File ""bin/import_cv2.py"", line 70, in one_sample
    _maybe_convert_wav(mp3_filename, wav_filename)
  File ""bin/import_cv2.py"", line 133, in _maybe_convert_wav
    transformer.build(mp3_filename, wav_filename)
  File ""/home/arajan/tmp/deepspeech-train-venv/lib/python3.7/site-packages/sox/transform.py"", line 412, in build
    file_info.validate_input_file(input_filepath)
  File ""/home/arajan/tmp/deepspeech-train-venv/lib/python3.7/site-packages/sox/file_info.py"", line 215, in validate_input_file
    ""input_filepath {} does not exist."".format(input_filepath)
OSError: input_filepath /home/arajan/Documents/Abhishek_Rajan/Githubrepo/DeepSpeech-master/tsv_dir/clips/common_voice_en_18885788.mp3 does not exist.

",command loading file saving new file recent call last file line module file line file line enumerate file line next raise value file line worker result true file line file line file line build file line exist exist,issue,positive,positive,neutral,neutral,positive,positive
572958122,I think for 0.7.0 we should at least fix the help texts,think least fix help,issue,negative,negative,negative,negative,negative,negative
572957141,"@AASHISHAG 
Regarding 1: I'll take some of them for the filter rules - thanks!
Regarding 2: Looks like the vocabulary.",regarding take filter thanks regarding like vocabulary,issue,positive,positive,positive,positive,positive,positive
572956447,"There's more, I want to figure out a way to combine alternative sources of data (e.g. OpenWebText, OSCAR) with the LibriSpeech LM data so that we can improve accuracy without significantly impacting LibriSpeech-test-clean WER.",want figure way combine alternative data data improve accuracy without significantly wer,issue,negative,positive,positive,positive,positive,positive
572955591,"I'm going to close for lack of activity. If xz still seems like a problem for OS X developers, feel free to re-open.",going close lack activity still like problem o feel free,issue,negative,positive,positive,positive,positive,positive
572953907,"Closing for lack of activity. If this is still a problem in the current release, feel free to re-open.",lack activity still problem current release feel free,issue,negative,positive,positive,positive,positive,positive
572952684,"As this will likely be external to this repo, I'll close. If there are objections, let me know.",likely external close let know,issue,negative,neutral,neutral,neutral,neutral,neutral
572947238,"ok ran the same command without -- .
same out put!
am i doing some thing wrong?",ran command without put thing wrong,issue,negative,negative,negative,negative,negative,negative
572945553,"command used 
bin/import_cv2.py -h --/home/arajan/Documents/Abhishek Rajan/Githubrepo/DeepSpeech-master/tsv_dir


output:-




usage: import_cv2.py [-h] [--audio_dir AUDIO_DIR]
                     [--filter_alphabet FILTER_ALPHABET] [--normalize]
                     [--space_after_every_character]
                     tsv_dir

Import CommonVoice v2.0 corpora

positional arguments:
  tsv_dir               Directory containing tsv files

optional arguments:
  -h, --help            show this help message and exit
  --audio_dir AUDIO_DIR
                        Directory containing the audio clips - defaults to
                        ""<tsv_dir>/clips""
  --filter_alphabet FILTER_ALPHABET
                        Exclude samples with characters not in provided
                        alphabet
  --normalize           Converts diacritic characters to their base ones
  --space_after_every_character
                        To help transcript join by white space
",command used output usage normalize import corpus positional directory optional help show help message exit directory audio clip exclude provided alphabet normalize diacritic base help transcript join white space,issue,positive,negative,negative,negative,negative,negative
572939699,"hi kdavis i am using 
bin/import_cv2.py tsv_dir 
just to train the data .
tsv_dir contains train.csv , test.csv , dev.tsv
tsv_dir/clips contains audio files
",hi train data audio,issue,negative,neutral,neutral,neutral,neutral,neutral
572934334,"Sorry for the document, I'm not familiar with latex in markdown and also not familiar with some math terms in English, I rewrote a new document, but I haven't studied the `readme2tex` yet.

I also added a `random_search` algorithm,
if there are any better algorithms, we can add them into `finetune_lm_params.py`

After some tests on `random_search`, my observation is:
- `parabola` can fit faster than `random_search` in wider scanning range (0.5 < `alpha` < 1.5).
- `random_search` can find better(lower loss) position in narrow scanning range (set `scan radius` = 0.05).

So, my suggestion is:
For a new language model, the better policy is to scan `parabola` to find `best alpha/beta` then use it as initial position for `random_search`.
For a known language model, we can just scan `random_search` from an known position like pre-trained model use: (0.75, 1.85).

So I add a flag to switch tuning policy:
`--finetune_lm_method` = ['parabola', 'random_search', 'parabola+random_search']",sorry document familiar latex markdown also familiar math new document studied yet also added algorithm better add observation parabola fit faster scanning range alpha find better lower loss position narrow scanning range set scan radius suggestion new language model better policy scan parabola find best use initial position known language model scan known position like model use add flag switch tuning policy,issue,positive,positive,positive,positive,positive,positive
572930766,"Does the file

> ...input_filepath tsv_dir/clips/common_voice_en_18885784.mp3

exist?

From the error message it looks like it does not.

In a related question, what command line arguments did you use?",file exist error message like related question command line use,issue,negative,neutral,neutral,neutral,neutral,neutral
572724413,"> NuGet will support embeded Markdown: https://github.com/NuGet/Home/wiki/Packaging-Documentation-within-the-nupkg but so far, it seems not yet done, and I can't find anything to automatically upload that.

I've got confirmation from nuget people there is nothing in place, so we can't upload through API. @reuben I think we could close this? ",support markdown far yet done ca find anything automatically got confirmation people nothing place ca think could close,issue,negative,positive,neutral,neutral,positive,positive
572598162,"> All of the resampling logic is replicated in each client. For example, here's a few differences in the logic between the C++, Python and Node.JS clients:
> 
>     * C++ and Node.JS clients always feeds the data through SoX, only warns about erratic speech recognition when input sample rate is **LESS THAN** model sample rate.
> 
>     * Python client only feeds the data through SoX when the sample rate differs from the model, and warns about erratic speech recognition when input rate **NOT EQUAL TO** model sample rate.

Yeah, let's do as suggested on IRC: linux amd64 only, TF/TFLite for all of C++, Python and NodeJS/ElectronJS.",logic replicated client example logic python always data erratic speech recognition input sample rate le model sample rate python client data sample rate model erratic speech recognition input rate equal model sample rate yeah let python,issue,negative,neutral,neutral,neutral,neutral,neutral
572594019,"All of the resampling logic is replicated in each client. For example, here's a few differences in the logic between the C++, Python and Node.JS clients:

- C++ and Node.JS clients always feed the data through SoX, only warn about erratic speech recognition when input sample rate is **LESS THAN** model sample rate.
- Python client only feeds the data through SoX when the sample rate differs from the model, and warns about erratic speech recognition when input rate **NOT EQUAL TO** model sample rate.",logic replicated client example logic python always feed data warn erratic speech recognition input sample rate le model sample rate python client data sample rate model erratic speech recognition input rate equal model sample rate,issue,negative,neutral,neutral,neutral,neutral,neutral
572583575,"> Looks good, I left a couple of minor comments inline. Should we also have 8kHz tests for the Python/NodeJS clients?

We could but I'm unsure about the actual value.",good left couple minor also could unsure actual value,issue,positive,positive,positive,positive,positive,positive
572579248,Did you forget to `git add` a file? The definition of `﻿set_ldc_sample_filename` is not here.,forget git add file definition,issue,negative,neutral,neutral,neutral,neutral,neutral
572533321,"> But I guess that's not a problem on your site, so this can be closed.
> I'll figure it out and look for the bufferSize, maybe something is misconfigured in my recording software.
> 
> Thank you very much!

Yes, that's likely the case. As you can see, our code is very simple (as advertised, it is a simple demo). Broken-yet-working audio is not uncommon, and as much as I remember, the playback code is 100% Android-level, while we basically memcpy() based on buffer size :).",guess problem site closed figure look maybe something recording thank much yes likely case see code simple simple audio uncommon much remember playback code basically based buffer size,issue,negative,positive,positive,positive,positive,positive
572531411,"But I guess that's not a problem on your site, so this can be closed.
I'll figure it out and look for the bufferSize, maybe something is misconfigured in my recording software.

Thank you very much!",guess problem site closed figure look maybe something recording thank much,issue,negative,positive,neutral,neutral,positive,positive
572530611,"> > Sorry, I've already done it :/
> 
> No problem :)
> 
> > What do you mean, ""buffer size"" ?
> 
> ```kotlin
> RandomAccessFile wave = new RandomAccessFile(audioFile, ""r"");
> 
> wave.seek(20); 
> char audioFormat = this.readLEChar(wave);
> 
> wave.seek(22); 
> char numChannels = this.readLEChar(wave);
> 
> wave.seek(24); 
> int sampleRate = this.readLEInt(wave);
> 
> wave.seek(34); 
> char bitsPerSample = this.readLEChar(wave);
> 
> wave.seek(40); 
> int bufferSize = this.readLEInt(wave); <--- I mean this
> ```

Hehe, well, 26 means your file is mostly empty.",sorry already done problem mean buffer size wave new char wave char wave wave char wave wave mean well file mostly empty,issue,negative,negative,negative,negative,negative,negative
572530389,"> Sorry, I've already done it :/

No problem :)

> What do you mean, ""buffer size"" ?

```kotlin
RandomAccessFile wave = new RandomAccessFile(audioFile, ""r"");

wave.seek(20); 
char audioFormat = this.readLEChar(wave);

wave.seek(22); 
char numChannels = this.readLEChar(wave);

wave.seek(24); 
int sampleRate = this.readLEInt(wave);

wave.seek(34); 
char bitsPerSample = this.readLEChar(wave);

wave.seek(40); 
int bufferSize = this.readLEInt(wave); <--- I mean this
```
",sorry already done problem mean buffer size wave new char wave char wave wave char wave wave mean,issue,negative,negative,negative,negative,negative,negative
572529218,"> Yeah I'd be happy to fix the typo and contribute :)

Sorry, I've already done it :/



>  The only difference I see between this sample and mine is that the buffer size of that sample is 114750 while mine was only 26. What could that mean?

What do you mean, ""buffer size"" ?",yeah happy fix typo contribute sorry already done difference see sample mine buffer size sample mine could mean mean buffer size,issue,positive,negative,neutral,neutral,negative,negative
572528605,"Okay, I tried `/data/smoke_test/new-home-in-the-stars-16k.wav` and it works!
The only difference I see between this sample and mine is that the buffer size of that sample is 114750 while mine was only 26. What could that mean?",tried work difference see sample mine buffer size sample mine could mean,issue,negative,negative,negative,negative,negative,negative
572527689,"Yeah I'd be happy to fix the typo and contribute :)
",yeah happy fix typo contribute,issue,positive,positive,positive,positive,positive,positive
572492352,"> > Looks like you could send a fix, but I'm surprised this went through, we should have seen that in CI
> 
> The test has the same typo. Probably a result of autocomplete.

So much same.",like could send fix went seen test typo probably result much,issue,negative,positive,positive,positive,positive,positive
572483049,"> Looks like you could send a fix, but I'm surprised this went through, we should have seen that in CI

The test has the same typo. Probably a result of autocomplete.",like could send fix went seen test typo probably result,issue,negative,neutral,neutral,neutral,neutral,neutral
572474513,"My hope is that it would be faster than epoch 0, but on my tests it's just as slow :/",hope would faster epoch slow,issue,negative,negative,negative,negative,negative,negative
572442558,Could you try with the audio samples we release? ,could try audio release,issue,negative,neutral,neutral,neutral,neutral,neutral
572436244,"> I only get an ""i"" as output.

It's a (fixed) symptom of silence. There was an issue about silence being inferred as ""I"". 

>  If I additionally use `enableDecoderWihLM` (there is a typo by the way in this method) with:

Looks like you could send a fix, but I'm surprised this went through, we should have seen that in CI

> when I select an audio sample of my voice (double checked everything: wav, pcm, mono, 16khz, 16 bits per sample, buffer size 26)

This example is very simple. Have you checked logcat for error? Is your audio audible enough? ",get output fixed symptom silence issue silence additionally use typo way method like could send fix went seen select audio sample voice double checked everything mono per sample buffer size example simple checked error audio audible enough,issue,negative,positive,neutral,neutral,positive,positive
572157165,This is most likely made irrelevant by Tilman's feeding changes.,likely made irrelevant feeding,issue,negative,negative,negative,negative,negative,negative
572080125,"> It seems like the links are broken because they link to the files, e.g. `USING.rst#blah-blah-section-name`. But in readthedocs all three files get embedded into a single one, `Basics.rst`, so the first part gets broken. If we keep they all separate the same way they are in the repo, then maybe the links will not be broken?

Yep. Is this way better and works for you ?",like link broken link three get single one first part broken keep separate way maybe link broken yep way better work,issue,negative,negative,neutral,neutral,negative,negative
572073540,"It seems like the links are broken because they link to the files, e.g. `USING.rst#blah-blah-section-name`. But in readthedocs all three files get embedded into a single one, `Basics.rst`, so the first part gets broken. If we keep they all separate the same way they are in the repo, then maybe the links will not be broken?",like link broken link three get single one first part broken keep separate way maybe link broken,issue,negative,negative,negative,negative,negative,negative
572072999,"> Can you keep the split in the docs? Instead of using .include, actually package the files and link to them?

I'm unsure what you mean here.",keep split instead actually package link unsure mean,issue,negative,negative,negative,negative,negative,negative
572071305,"Can you keep the split in the docs? Instead of using .include, actually package the files and link to them?",keep split instead actually package link,issue,negative,neutral,neutral,neutral,neutral,neutral
571970214,"@reuben https://ds-test.readthedocs.io/en/allthedocs/

Looks like we have broken links. Maybe splitting the doc into several files was not such a good idea. But now that we have ReadTheDocs, maybe we should keep a very light README, re-unite current `README.rst`, `USING.rst` and `TRAINING.rst` and direct people to full-blown ReadTheDocs page with extensive informations ?",like broken link maybe splitting doc several good idea maybe keep light current direct people page extensive,issue,negative,positive,positive,positive,positive,positive
571962210,"Not forgotten, I'm just holding it until we release v0.6.1.


> On 8 Jan 2020, at 05:41, Carlos Fonseca <notifications@github.com> wrote:
> 
> ﻿
> Hello @reuben, what about this ?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",forgotten holding release wrote hello reply directly view,issue,negative,positive,neutral,neutral,positive,positive
571783476,"> > Your link seems to suggest `MD` and not `MT`.
> 
> I just read again the link and for MD says **The actual working code is contained in MSVCRversionnumber.DLL, which must be available at run time**
> 
> Also MT vs MD on StackOverflow :https://stackoverflow.com/questions/757418/should-i-compile-with-md-or-mt
> 
> > we need to rebuild **everything** with it, it seems :/
> 
> :/

Ouch, misread msvcp for msvcr :/",link suggest read link actual working code must available run time also need rebuild everything ouch misread,issue,negative,positive,positive,positive,positive,positive
571754448,"> Your link seems to suggest `MD` and not `MT`.

I just read again the link and for MD says **The actual working code is contained in MSVCRversionnumber.DLL, which must be available at run time**

Also MT vs MD on StackOverflow :https://stackoverflow.com/questions/757418/should-i-compile-with-md-or-mt



> we need to rebuild **everything** with it, it seems :/

:/",link suggest read link actual working code must available run time also need rebuild everything,issue,negative,positive,positive,positive,positive,positive
571670188,"Those are only testing inference with non 16k and the up/down sampling, but we don't test training with anything different than 16khz. ",testing inference non sampling test training anything different,issue,negative,neutral,neutral,neutral,neutral,neutral
571545153,"> > How does other solves this ? I've seen other floss project shipping those libs as well.
> 
> Hello @lissyx Sorry for the delay, digging more I found someone mentioned `/MT` to link statically against dependencies at the cost of increasing the size of the native so, using `--copt=""/MT""` compiles for me, I'm now testing to see if it still works.
> I'll need your help to confirm that this removes the dependency requirement.
> 
> https://docs.microsoft.com/en-us/cpp/build/reference/md-mt-ld-use-run-time-library?view=vs-2019

Your link seems to suggest `MD` and not `MT`. Also, `/MT` badly fails, we need to rebuild **everything** with it, it seems :/",seen floss project shipping well hello sorry delay digging found someone link statically cost increasing size native testing see still work need help confirm dependency requirement link suggest also badly need rebuild everything,issue,negative,negative,negative,negative,negative,negative
571499116,"> I need a generate_trie and other binary, so I have to build.

`generate_trie` is bunlded as part of `native_client` tarball we release. So you don't need to build.",need binary build part release need build,issue,negative,neutral,neutral,neutral,neutral,neutral
571497794,"Did you follow the instructions [here](https://github.com/mozilla/DeepSpeech/tree/master/native_client)? (It looks like you did not follow the instructions in the ""Compile libdeepspeech.so & generate_trie"" section.)

Could you include all steps you went through in compiling?",follow like follow compile section could include went,issue,negative,neutral,neutral,neutral,neutral,neutral
571475140,"As documented in the issue template that you erased, please seek support on Discourse. There are multiple third party project that uses DeepSpeech. ",issue template erased please seek support discourse multiple third party project,issue,positive,neutral,neutral,neutral,neutral,neutral
571208312,"> Yes sure ,ii'l do. btw, i had some general doubts regarding usage of deepspeech in a project. Can i personally discuss with you through some medium ? I guarantee would just take 2 minutes.

Please use Discourse private messages for that ?",yes sure general regarding usage project personally discus medium guarantee would take please use discourse private,issue,positive,positive,positive,positive,positive,positive
571193391,"Yes sure ,ii'l do.  btw, i had some general doubts regarding usage of deepspeech in a project. Can i personally discuss with you through some medium ? I guarantee would just take 2 minutes. ",yes sure general regarding usage project personally discus medium guarantee would take,issue,positive,positive,positive,positive,positive,positive
571174263,">  the output comes up after a really long time.

Define ""really long"", define your hardware.



> So is it that real time transcription is more computationally heavy ?

I'm not sure to get your point here.



> And that either an 'i' or an 'a'

Known issue if you look at recently closed issues, we fixed that and it should make it in a 0.6.1 soonish. Silence would be infered as something like ""i"" or ""a"".",output come really long time define really long define hardware real time transcription heavy sure get point either known issue look recently closed fixed make soonish silence would something like,issue,positive,positive,neutral,neutral,positive,positive
571173644,"> Ok, so i got it running by installing 'Sox 14.4.1' and replacing the command by `sox -d -q -V0 -e signed -L -c 1 -b 16 -r 16k -t raw - gain -2` on windows 10.

Could you make a documentation PR for that? It's a good thing you have been able to find a solution. Or even maybe a patch ?",got running command raw gain could make documentation good thing able find solution even maybe patch,issue,positive,positive,positive,positive,positive,positive
571171751,"But there is another problem. the output comes up after a really long time. And that either an 'i' or an 'a' 
I am using the CPU version of deepspeech. So is it that real time transcription is more computationally heavy ?",another problem output come really long time either version real time transcription heavy,issue,negative,negative,neutral,neutral,negative,negative
571170285,"Ok, so i got it running by installing 'Sox 14.4.1' and replacing the command by ```sox -d -q -V0 -e signed -L -c 1 -b 16 -r 16k -t raw - gain -2``` on windows 10.",got running command raw gain,issue,positive,negative,negative,negative,negative,negative
571137766,"> This is my output on running the cmd transcripter.
> 
> ```
> DEBUG:root:Found Model: deepspeech-0.6.0-models\output_graph.pb
> DEBUG:root:Found Language Model: deepspeech-0.6.0-models/lm.binary
> DEBUG:root:Found Trie: deepspeech-0.6.0-models/trie
> TensorFlow: v1.14.0-21-ge77504ac6b
> DeepSpeech: v0.6.0-0-g6d43e21
> Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
> 2020-01-06 01:04:21.864769: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
> DEBUG:root:Loaded model in 1.020s.
> DEBUG:root:Loaded language model in 0.019s.
> Traceback (most recent call last):
>   File ""audioTranscript_cmd.py"", line 92, in <module>
>     main(sys.argv[1:])
>   File ""audioTranscript_cmd.py"", line 78, in main
>     bufsize=0)
>   File ""C:\Users\asus\AppData\Local\Programs\Python\Python37\lib\subprocess.py"", line 775, in __init__
>     restore_signals, start_new_session)
>   File ""C:\Users\asus\AppData\Local\Programs\Python\Python37\lib\subprocess.py"", line 1178, in _execute_child
>     startupinfo)
> FileNotFoundError: [WinError 2] The system cannot find the file specified
> ```

It would have been quicker if you had shared what you are doing precisely from scratch. Instead, I had to do divination on:
 - your command line
 - your operating system

Looks like you are trying to run in streaming mode on Windows. This would execute https://github.com/mozilla/DeepSpeech-examples/blob/r0.6/vad_transcriber/audioTranscript_cmd.py#L76-L78, and I don't think `rec` works on that platform.

Please use `--audio` flag instead.",output running root found model root found language model root found warning reading entire model file memory transform model file graph reduce heap usage binary use root loaded model root loaded language model recent call last file line module main file line main file line file line system find file would precisely scratch instead divination command line operating system like trying run streaming mode would execute think work platform please use audio flag instead,issue,positive,positive,positive,positive,positive,positive
571103789,"> i just did everything to install deepspeech. But it is not installing, there are no icon of deepspeech, so that i should open it. is this normal ? like do i have to use terminal to launch deepspeech or is their something else ?

This is not a bug. Please look for support in Discourse, as you would have learnt about if you read the Github issue template you purposely ignored to fill.

Everything on how to use is already in the documentation you likely have read to perform the install, so please, help yourself and read more.",everything install icon open normal like use terminal launch something else bug please look support discourse would learnt read issue template purposely fill everything use already documentation likely read perform install please help read,issue,positive,positive,neutral,neutral,positive,positive
571080518,Isn't it a raw logit[[1](https://github.com/mozilla/DeepSpeech/blob/0427c1572ac8f7253e46c7041c5e48d8da923cf2/native_client/deepspeech.h#L44)]? Thus it need not be positive.,raw thus need positive,issue,positive,negative,neutral,neutral,negative,negative
571044922,The error is pretty explicit : file not found. Since you don't share your command line we have nothing. ,error pretty explicit file found since share command line nothing,issue,negative,positive,positive,positive,positive,positive
570982100,"Thanks for the comments. I understand the policy.

But in the current implementation, ctc beam search for chinese character set (about 6000 characters) are very slow comparing to English.
(I saw some people reports this issue in the DeepSpeech discussion forum)

So if APIs should not be changed, are any of following options are available?

1. Change the default value of cutoff_prob from 1.0 to 0.99 (*)
2. Change the `get_pruned_log_probs()` and make effective cutoff_top_n even if cutoff_prob is 1.0

(*)
According to the section 7.3 of ""Deep Speech2: End-to-End Speech Recognition in English and Mandarin"", cutoff_prob=0.99 and cutoff_top_n=40 are works well.",thanks understand policy current implementation beam search character set slow saw people issue discussion forum following available change default value change make effective even according section deep speech speech recognition mandarin work well,issue,positive,positive,positive,positive,positive,positive
570790270,"@reuben that would be great and I found that we already have one empty repo here, https://github.com/Common-Voice/mandarin
can you help me to get access to it, and I can start some documents and add some of my scripts inside?",would great found already one empty help get access start add inside,issue,positive,positive,positive,positive,positive,positive
570772336,"I confirm it still works at least with the .NET client (can't test with every single client), using the dependency walker shows that `msvcp140.dll` is gone, it still shows `vcruntime140.dll` :/ only your tests @lissyx or @slaypni will tell if this removes the dependency ",confirm still work least client ca test every single client dependency walker gone still tell dependency,issue,negative,negative,negative,negative,negative,negative
570770096,"> How does other solves this ? I've seen other floss project shipping those libs as well.

Hello @lissyx Sorry for the delay, digging more I found someone mentioned `/MT` to link statically against dependencies at the cost of increasing the size of the native so, using `--copt=""/MT""` compiles for me, I'm now testing to see if it still works. 
I'll need your help to confirm that this removes the dependency requirement.


https://docs.microsoft.com/en-us/cpp/build/reference/md-mt-ld-use-run-time-library?view=vs-2019",seen floss project shipping well hello sorry delay digging found someone link statically cost increasing size native testing see still work need help confirm dependency requirement,issue,negative,negative,negative,negative,negative,negative
570738248,"> @AASHISHAG Regarding your first comment: We should collect all wrong samples and I'll keep this issue up for collecting them till we reached a point where it's worth bundling a first PR as an extension of the following lines (where the secondary `None` will just drop matching statements):
> 
> https://github.com/mozilla/DeepSpeech/blob/85a61a3ab74aa28a08723236ddab740c7a9fa1e3/bin/import_swc.py#L44-L57
> 
> 
> Just for keeping track: Your (first) loss infinity causing one is the one with transcript ""ssss"".

1. This could be an addition to SWC script (referring it from Kaldi Tuda De project)

https://github.com/uhh-lt/kaldi-tuda-de/blob/master/s5_r2/local/prepare_swc_german_wavscp.py#L15

2. The last commit here, says "" Extra words from SWC"". Probably, these are the common occurring symbols in SWC.
https://github.com/uhh-lt/kaldi-tuda-de/blob/master/s5_r2/local/extra_words.txt

",regarding first comment collect wrong keep issue till point worth first extension following secondary none drop matching keeping track first loss infinity causing one one transcript could addition script de project last commit extra probably common,issue,negative,negative,neutral,neutral,negative,negative
570599664,"> > Should we instead package those two deps along with our runtime
> 
> I don't think is the ideal, let's first confirm the issue with the .so .

How does other solves this ? I've seen other floss project shipping those libs as well.",instead package two along think ideal let first confirm issue seen floss project shipping well,issue,positive,positive,positive,positive,positive,positive
570599592,"General comment: A simpler alternative to this that's easier to program and converges faster for a give computational budget is random search. See for example [Random search for hyper-parameter optimization](http://www.jmlr.org/papers/v13/bergstra12a.html). Why not use random search?

In addition random search does not make any of the ""heavy handed"" assumptions that are being made here, e.g. that WER is quadratic in alpha.",general comment simpler alternative easier program faster give computational budget random search see example random search optimization use random search addition random search make heavy handed made wer quadratic alpha,issue,positive,negative,negative,negative,negative,negative
570597628,"General comment. This PR largely assumes that the parameters alpha and beta do not interact, i.e. one can minimize the WER by varying alpha then fix alpha and minimize the WER by varying beta. I doubt that alpha and beta do not interact. Is there any justification for this?",general comment largely alpha beta interact one minimize wer alpha fix alpha minimize wer beta doubt alpha beta interact justification,issue,negative,positive,positive,positive,positive,positive
570530701,"I know the French community started their own repo to collect French specific code, scripts, configuration files so that they could collaborate and share efforts. Maybe something similar could be done for Mandarin? I think this is the repo: https://github.com/Common-Voice/commonvoice-fr @lissyx can confirm",know community collect specific code configuration could collaborate share maybe something similar could done mandarin think confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
570479197,"> Thanks for the PR! This is really cool. I made a review pass and have a few questions and comments about the code.
> 
> Did you run it with any of our pre-trained English models? I'm curious about the results you got.

I used official pretrained model to test `librispeech-test-clean.csv` (2xxx rows), with 512 sampling size, and the result was:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.07449196826011226,
        ""samples_cer"": 0.029717934533042625
    },
    ""finetune_test_result"": {
        ""alpha"": 0.8936087708980639,
        ""beta"": 1.0,
        ""samples_wer"": 0.07261467002128895,
        ""samples_cer"": 0.030412160525297667
    },
    ""finetune_parameters"": {
        ""sample_size"": 512,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/libri-test.csv""
    }
}
```
As we can see, the original parameters `0.75` `1.85` is already good enough, and the `cer` is even better than `finetune_test_result`, and my `tuning target` is `wer`.

I don't know how to plot here, but I can print raw data in scanning log:
```
alpha | wer
0.5   | 0.082927
0.66  | 0.078146
0.833 | 0.076488
1.0   | 0.075707
1.166 | 0.076000
1.33  | 0.079512
1.5   | 0.087805
```

To determine `how parabolic` is the curve might not have a absolute definition, it should depend on fitting `residual value`, but how small is good? I don’t have much sense right now.",thanks really cool made review pas code run curious got used official model test sampling size result alpha beta alpha beta see original already good enough even better tuning target wer know plot print raw data scanning log alpha wer determine parabolic curve might absolute definition depend fitting residual value small good much sense right,issue,positive,positive,positive,positive,positive,positive
570472393,"I share this script because my personal requirement, I use it to manage different datasets.
With directory options: `--from_dir` `--to_dir`, it can easily convert a bunch of csv files (Ex: SLR57, aishell, aidatatang, ...) into another `zh-tw` directory, and keep the same filename like: train.csv, dev.csv, test.csv....
And additionally, because I don't know that there is XSV tool to select columns,
so, maybe we can close this PR.",share script personal requirement use manage different directory easily convert bunch ex another directory keep like additionally know tool select maybe close,issue,positive,positive,positive,positive,positive,positive
570441752,"Their solution seems to have fixed it, thanks!

Edit: For the example to work I had to prefix the command with ``pulseaudio & `` like the example from here https://github.com/mozilla/DeepSpeech-examples/blob/r0.6/mic_vad_streaming/test.sh#L13",solution fixed thanks edit example work prefix command like example,issue,positive,positive,positive,positive,positive,positive
570431771,"OK, I had fixed axis inversion problem in my repo, but I thought the original author would patch it so I didn’t submit it, I'll make a new PR for that.",fixed axis inversion problem thought original author would patch submit make new,issue,negative,positive,positive,positive,positive,positive
570413943,"

> @carlfm01 Do you know how we can get more informations from the Windows linker ?

No, sorry.

>  It might be good if you could also give a try to the C++ native client, this might help excluding hypothesis.

@slaypni please try running the native client and update us. 

",know get linker sorry might good could also give try native client might help excluding hypothesis please try running native client update u,issue,positive,positive,neutral,neutral,positive,positive
570276939,"The actual resulting transcript wasn't specified in the code that caused it, it just penalized empty transcripts to an extent that the model would choose a single letter transcript instead. ""i"" and ""a"" happen to be very frequent unigrams in English, which is probably why they are seen a lot, but it doesn't have to be just those two.",actual resulting transcript code empty extent model would choose single letter transcript instead happen frequent probably seen lot two,issue,negative,negative,neutral,neutral,negative,negative
570274768,"Have there been any reports of a similar problem, where when an empty stream is inferred as ""t"" ?

It happens quite a lot in some of the code I'm working with, it's this line that causes it:

`deepSpeechModel.finishStream(modelStream);`",similar problem empty stream quite lot code working line,issue,negative,negative,neutral,neutral,negative,negative
570236320,"> Bintray supports Markdown/asciiDoc/plaintext, but the README needs to be uploaded through the API with the package. We have code in scriptWorker to do it.

Fixed in https://github.com/mozilla/DeepSpeech/pull/2628, and upload of README.md was re-enabled on scriptworker side.",need package code fixed side,issue,negative,positive,neutral,neutral,positive,positive
570234592,"NuGet will support embeded Markdown: https://github.com/NuGet/Home/wiki/Packaging-Documentation-within-the-nupkg but so far, it seems not yet done, and I can't find anything to automatically upload that.",support markdown far yet done ca find anything automatically,issue,negative,positive,neutral,neutral,positive,positive
570223441,">  ""confidence"": -46.9939

That is also weird, I think it should be > 0",confidence also weird think,issue,negative,negative,negative,negative,negative,negative
570192321,"> @lissyx @reuben Would any of you be able to test the live example and see if it works on a raspberry pi (or just a normal Linux installation)?

Could you verify your pulseaudio setup also? I'm seeing reports: https://community.mycroft.ai/t/alsa-issue-oserror-errno-9997-invalid-sample-rate/5070",would able test live example see work raspberry pi normal installation could verify setup also seeing,issue,negative,positive,positive,positive,positive,positive
570185474,"We need to think about this in terms of the API design, specially as we're going for API stabilization. I don't think adding these parameters to all the CreateStream-like APIs is the best solution. And yes, if we still have plans to do a v0.6.1, then this should wait to go into v0.7.",need think design specially going stabilization think best solution yes still wait go,issue,positive,positive,positive,positive,positive,positive
570185470,"> I tried to run node from Powershell and MSYS on Windows Sandbox where NodeJS and `Microsoft Visual C++ 2015 Redistributable (x64) - 14.0.24215` were additionally installed, however, they seem to fail with the same error. The region was set to US and language was set to English (US).
> 
> ```shell
> WDAGUtilityAccount@90e34f2c-3b35-4963-99e1-91053d1b3331 MSYS ~
> # export LC_ALL=C
> 
> WDAGUtilityAccount@90e34f2c-3b35-4963-99e1-91053d1b3331 MSYS ~
> # ""/c/Program Files/nodejs/npx"" deepspeech -v
> npx: installed 81 in 12.922s
> A dynamic link library (DLL) initialization routine failed.
> \\?\C:\Users\WDAGUtilityAccount\AppData\Roaming\npm-cache\_npx\3084\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64\node-v79\deepspeech.node
> ```

I'm really unable to help more here. @carlfm01 Do you know how we can get more informations from the Windows linker ? Under linux I would `LD_DEBUG=all` and we might know more. I'm surprised we don't have similar tooling for this platform (all I could search would not be helping).",tried run node sandbox visual additionally however seem fail error region set u language set u shell export dynamic link library routine really unable help know get linker would might know similar tooling platform could search would helping,issue,negative,negative,negative,negative,negative,negative
570185161,"> OK, I will test with vanilla Python.
> Thanks, all of you.

@JinZhuXing Any update ?",test vanilla python thanks update,issue,negative,positive,positive,positive,positive,positive
570184940,"Looks like we missed this one. I know we want that @reuben, should we pick it in 0.7 ?",like one know want pick,issue,negative,neutral,neutral,neutral,neutral,neutral
570174559,"@mychiux413 sorry for the delay, I was out on vacation for most of December. I think you're right, the current augmentation functions are flipping the time and frequency axes.",sorry delay vacation think right current augmentation time frequency ax,issue,negative,negative,neutral,neutral,negative,negative
570173463,"You can just run the standard `opencc` binary on a CSV file directly, there shouldn't be a need to write a Python wrapper for it. If your filenames have Mandarin characters in them, you can select just the transcript column using a tool like [XSV](https://github.com/BurntSushi/xsv):

```
$ cat example.csv
wav_filename,wav_filesize,transcript
foo.wav,1,中国

$ xsv select -- transcript example.csv | opencc -c s2t | xsv cat columns <(xsv select -- wav_filename,wav_filesize example.csv) - > example_traditional.csv

$ cat example_traditional.csv
wav_filename,wav_filesize,transcript
foo.wav,1,中國
```",run standard binary file directly need write python wrapper mandarin select transcript column tool like cat transcript select transcript st cat select cat transcript,issue,negative,positive,neutral,neutral,positive,positive
570144713,"If you imported TUDA, you should find the README under `<import-dir>/german-speechdata-package-v2/README`.
The containing archive's URL is constructed like this:
https://github.com/mozilla/DeepSpeech/blob/85a61a3ab74aa28a08723236ddab740c7a9fa1e3/bin/import_tuda.py#L27-L29
Result: http://ltdata1.informatik.uni-hamburg.de/kaldi_tuda_de/german-speechdata-package-v2.tar.gz
",find archive like result,issue,negative,neutral,neutral,neutral,neutral,neutral
570083295,"> The TUDA importer just reproduces their split.
> From the TUDA README:
> 
> > Test / Dev: includes recordings for the test and dev set. These sentences only occur once, there is no overlap with sentences in Train and the Test / Dev recordings were conducted with a different set of speakers. Each sentence in Test / Dev is unique, i.e. just recorded once by one speaker.

I tried to verify it and found some duplicates in Train, Dev and Test. It would be helpful if you can point me to the source of the README from where you got this text.",importer split test dev test dev set occur overlap train test dev different set sentence test dev unique one speaker tried verify found train dev test would helpful point source got text,issue,negative,positive,positive,positive,positive,positive
570068213,"I tried changing my code to use worker_threads, and it works fine outside of Electron.  But in electron the worker thread can't load the electron version of the `deepspeech` npm module.  It's looking for it in a non-existent *node-v75* directory.

I'm not sure what's going on here, for some reason the worker thread is unaware of the Electron environment.

```
Uncaught Exception:
Error: Cannot find module '/Users/dstein/dev/jaxcore/deepspeech-plugin/examples/electron-example/node_modules/deepspeech/lib/binding/v0.6.0/darwin-x64/node-v75/deepspeech.node'
Require stack:
- /Users/dstein/dev/jaxcore/deepspeech-plugin/examples/electron-example/node_modules/deepspeech/index.js
- /Users/dstein/dev/jaxcore/deepspeech-plugin/lib/deepspeech-worker.js
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:717:15)
    at Function.Module._load (internal/modules/cjs/loader.js:622:27)
    at Module.require (internal/modules/cjs/loader.js:775:19)
    at require (internal/modules/cjs/helpers.js:68:18)
    at Object.<anonymous> (/Users/dstein/dev/jaxcore/deepspeech-plugin/examples/electron-example/node_modules/deepspeech/index.js:17:17)
    at Module._compile (internal/modules/cjs/loader.js:880:30)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:892:10)
    at Module.load (internal/modules/cjs/loader.js:735:32)
    at Function.Module._load (internal/modules/cjs/loader.js:648:12)
    at Module.require (internal/modules/cjs/loader.js:775:19)
```",tried code use work fine outside electron electron worker thread ca load electron version module looking directory sure going reason worker thread unaware electron environment uncaught exception error find module require stack require anonymous,issue,negative,positive,positive,positive,positive,positive
570054006,"> hi @lissyx , i cannot reproduce the issue with the example model as well.
> With my trained model the issue persists.

That's super weird. Do you reproduce with your examples audio and ours model? And the inverse? ",hi reproduce issue example model well trained model issue super weird reproduce audio model inverse,issue,positive,negative,neutral,neutral,negative,negative
570052842,"hi @lissyx , i cannot reproduce the issue with the example model as well.
With my trained model the issue persists.",hi reproduce issue example model well trained model issue,issue,negative,neutral,neutral,neutral,neutral,neutral
570040179,"> Yes presumably this approach will work with the nodejs ""worker-thread"" API, that might reduce the amount of RAM required. I've only ever used fork() before this, so that's what I tried first.

It'd be great if you could give us feedback on that 😊",yes presumably approach work might reduce amount ram ever used fork tried first great could give u feedback,issue,positive,positive,positive,positive,positive,positive
570004978,"Yes presumably this approach will work with the nodejs ""worker-thread"" API, that might reduce the amount of RAM required. I've only ever used fork() before this, so that's what I tried first.",yes presumably approach work might reduce amount ram ever used fork tried first,issue,negative,positive,positive,positive,positive,positive
570003119,">  But there's an extra step needed there because DeepSpeech inference is a CPU heavy task - it'll lock up your whole application while processing. So that's what deepspeech-plugin is doing, it does a child_process.fork() and that's where DeepSpeech runs,

Yeah that's normal. One question, can't you use a thread instead of forking a new process? ",extra step inference heavy task lock whole application yeah normal one question ca use thread instead new process,issue,negative,positive,neutral,neutral,positive,positive
569996204,"I finally got DeepSpeech working the way I wanted inside Electron, my latest example project is here and might be worth a look for anyone attempting to do this:

https://github.com/jaxcore/deepspeech-plugin/tree/master/examples/electron-example

There are a few of my own libraries used in this example:

- [bumblebee-hotword](https://github.com/jaxcore/bumblebee-hotword) - a hotword system, this is what I used to capture microphone data in the electron browser window and visualize it, the hotword can be used to trigger DeepSpeech on/off, and do microphone muting
- [jaxcore](https://github.com/jaxcore/jaxcore) my central control library, essentially a general purpose service launcher/connector library
- [deepspeech-plugin](https://github.com/jaxcore/deepspeech-plugin) - a deepspeech wrapper library that I use to spawn a forked instance of DeepSpeech (with VAD stream processing) and connect it to jaxcore

With DeepSpeech 0.6 you can now use Electron 7.1.7.  I was mostly interested in doing microphone recording in the browser (with visualization) and sending the data to DeepSpeech running in Electron/NodeJS.  But there's an extra step needed there because DeepSpeech inference is a CPU heavy task - it'll lock up your whole application while processing.  So that's what deepspeech-plugin is doing, it does a child_process.fork() and that's where DeepSpeech runs, and I send the audio stream there so the main electron process isn't affected.  It seems to be working fairly well so far.

If you're not using live mircrophone data, but rather using .wav files instead you will probably want to do the same thing.  You'd need to stream the .wav data into a forked process and the code I'm using in this example can be largely reused for that task as.  Just be aware the wav file data must be downsampled to the 16bit/16khz before sending to the process.

```
ipcMain.on('stream-data', (event, data) => {  // receive audio from browser window
	deepspeech.streamData(data);  // send to deepspeech-plugin forked processs
});
```",finally got working way inside electron latest example project might worth look anyone used example system used capture microphone data electron browser window visualize used trigger microphone central control library essentially general purpose service library wrapper library use spawn forked instance stream connect use electron mostly interested microphone recording browser visualization sending data running extra step inference heavy task lock whole application send audio stream main electron process affected working fairly well far live data rather instead probably want thing need stream data forked process code example largely task aware file data must sending process event data receive audio browser window data send forked,issue,positive,positive,positive,positive,positive,positive
569951295,"> I don't repro here. Can you verify against the audio examples that we release?

And obviously, english model.",verify audio release obviously model,issue,negative,neutral,neutral,neutral,neutral,neutral
569951112,"@AASHISHAG 
> Could we also do the same with other datasets i.e. Tuda-De and M-Ailabs? Also, it would be great if we could have the script for Voxfogre. The current Voxforge script doesn't support DE version.

The TUDA importer just reproduces their split.
From the TUDA README:

> Test / Dev: includes recordings for the test and dev set. These sentences only occur once, there is no overlap with sentences in Train and the Test / Dev recordings were conducted with a different set of speakers. Each sentence in Test / Dev is unique, i.e. just recorded once by one speaker.

Just to be aware: Each sentence in the TUDA train set is repeated  about five times - one time per microphone/angle. Allowing for selecting just one of them during import would be a great contribution.

Regarding M-Ailabs: The split is not speaker based yet.

Having Voxforge-DE and speakers guaranteed to occur in just one sub-set would indeed be great.",could also also would great could script current script support de version importer split test dev test dev set occur overlap train test dev different set sentence test dev unique one speaker aware sentence train set repeated five time one time per one import would great contribution regarding split speaker based yet occur one would indeed great,issue,positive,positive,positive,positive,positive,positive
569950867,"> > > ""--json"" option
> > 
> > 
> > Which client are you using ? C++ ? JS ? Python ?
> 
> C++ Downloaded with `python util/taskcluster.py --target native_client--arch ""gpu""`

I don't repro here. Can you verify against the audio examples that we release?

```
$ ./tfpb/deepspeech --model eng/deepspeech-0.6.0-models/output_graph.pbmm --audio audio/4507-16021-0012.wav --json
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
2019-12-31 17:02:33.202194: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
{""metadata"":{""confidence"":1.01063},""words"":[{""word"":""why"",""time"":0,""duration"":0.8},{""word"":""should"",""time"":0.86,""duration"":0.22},{""word"":""one"",""time"":1.08,""duration"":0.2},{""word"":""halt"",""time"":1.4,""duration"":0.4},{""word"":""on"",""time"":1.82,""duration"":0.22},{""word"":""the"",""time"":2.06,""duration"":0.14},{""word"":""way"",""time"":2.22,""duration"":0.32}]}
```

```
$ ./tfpb/deepspeech --model eng/deepspeech-0.6.0-models/output_graph.pbmm --audio audio/2830-3980-0043.wav --json
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
2019-12-31 17:01:59.483542: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
{""metadata"":{""confidence"":1.73862},""words"":[{""word"":""experience"",""time"":0,""duration"":1.02},{""word"":""proofsless"",""time"":1.1,""duration"":0.48}]}
```",option client python python target arch verify audio release model audio binary use confidence word time duration word time duration word one time duration word halt time duration word time duration word time duration word way time duration model audio binary use confidence word experience time duration word time duration,issue,positive,neutral,neutral,neutral,neutral,neutral
569950433,"> > ""--json"" option
> 
> Which client are you using ? C++ ? JS ? Python ?

C++ Downloaded with  `python util/taskcluster.py --target native_client--arch ""gpu""`",option client python python target arch,issue,negative,neutral,neutral,neutral,neutral,neutral
569948711,"@AASHISHAG
> I noticed that in SWC script you have used a ""speaker"" flag to identify the speakers and I assume that you are possibly splitting the overall data set in SWC into training, development and test partitions in such a way that speakers or sentences do not overlap across the different sets. Please confirm?

Confirmed (for the speakers).

#2625 is for adding article name and the speaker to CSV columns for debugging - This will let you verify that each speaker is restricted to one set. It also allows excluding ""unknown"" speakers (in case an unknown speaker is actually just an unidentified existing one).
Be aware: There is no ""sentence overlap"" check, as the importer assumes Wikipedia articles not sharing equal sentences.",script used speaker flag identify assume possibly splitting overall data set training development test way overlap across different please confirm confirmed article name speaker let verify speaker restricted one set also excluding unknown case unknown speaker actually unidentified one aware sentence overlap check importer equal,issue,negative,positive,neutral,neutral,positive,positive
569947195,"@AASHISHAG Regarding your first comment: We should collect all wrong samples and I'll keep this issue up for collecting them till we reached a point where it's worth bundling a first PR as an extension of the following lines (where the secondary `None` will just drop matching statements): https://github.com/mozilla/DeepSpeech/blob/85a61a3ab74aa28a08723236ddab740c7a9fa1e3/bin/import_swc.py#L44-L57
Just for keeping track: Your (first) loss infinity causing one is the one with transcript ""ssss"".",regarding first comment collect wrong keep issue till point worth first extension following secondary none drop matching keeping track first loss infinity causing one one transcript,issue,negative,positive,neutral,neutral,positive,positive
569883129,"If you are willing to fix ds_ctcdecoder python wheel to build and run under windows, it should be but we won't be able to seriously support that, in the current context. ",willing fix python wheel build run wo able seriously support current context,issue,negative,positive,positive,positive,positive,positive
569612304,"No, use the tensorflow release and not DeepSpeech one, `--branch r1.14`",use release one branch,issue,negative,neutral,neutral,neutral,neutral,neutral
569411135,"> It's my bad In my dataset somehow empty audio is add. Now its working fine and also I got the intuition of augmentation. Thanks a lot @lissyx @mychiux413.

Can we close or is there anything that can be improved to make it easier for others in similar situations? ",bad somehow empty audio add working fine also got intuition augmentation thanks lot close anything make easier similar,issue,negative,negative,neutral,neutral,negative,negative
569407299,It's my bad In my dataset somehow empty audio is add. Now its working fine and  also I got the intuition of augmentation.  Thanks  a lot @lissyx @mychiux413.,bad somehow empty audio add working fine also got intuition augmentation thanks lot,issue,negative,negative,neutral,neutral,negative,negative
569307596,"sparse_warp and freq_and_time_masking are come from [arxiv-SpecAugment](https://arxiv.org/pdf/1904.08779.pdf)
sparse_warp is a method to distort spectrogram like distort a picture to get different data in training steps.

the `augmentation_speed_up_std=1` is very huge value, the speed up value was chosen by normal distribution value, `augmentation_speed_up_std=1` means 31% audio files are more than double speed up as training data, This is totally far away from the voice of the real world.

`--augmentation_pitch_and_tempo_scaling`, `--augmentation_speed_up_std` they both have `resize_bilinear()` function inside, you can try disabling another one to figure out which one is the source of problem.",come method distort spectrogram like distort picture get different data training huge value speed value chosen normal distribution value audio double speed training data totally far away voice real world function inside try another one figure one source problem,issue,positive,positive,positive,positive,positive,positive
569303047,"@reuben , If silence is all zero deepspeech do not work , 
eg for utterance ""Go back "" - > Deepspeech gives ""back"" 
but if all zero silence of 100ms is added it agains gives back result as ""back""
if we add random values from 0 to 255 for 100ms silence results comes perfecttly ""go back"".

Similarly thing audacity does it adds some short of dithering and with that suprisingly deepspeech
works better.",silence zero work utterance go back back zero silence added back result back add random silence come go back similarly thing audacity short work better,issue,negative,neutral,neutral,neutral,neutral,neutral
569264482,"I also got this error:

command:'python3.7 DeepSpeech.py \
			--lm_binary_path ./data/lm/lm.binary \
			--lm_trie_path ./data/lm/trie \
			--learning_rate 0.0001 \
			--train_batch_size 3 \
			--alphabet_config_path ./data/alphabet.txt \
			--remove_export true \
			--train_files ./data/testing_data/only_wav_new_6_12_2019.csv \
			--export_dir ./export  \
			--checkpoint_dir ./ \
			--epochs 10
                        --augmentation_pitch_and_tempo_scaling true
                        --augmentation_speed_up_std 1'

Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 91.659166                                                                     Traceback (most recent call last):
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: output dimensions must be positive
	 [[{{node cond_1/else/_9/ResizeBilinear}}]]
	 [[tower_0/IteratorGetNext]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 1083, in <module>
    absl.app.run(main)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 1006, in main
    train()
  File ""DeepSpeech.py"", line 634, in train
    train_loss, _ = run_set('train', epoch, train_init_op)
  File ""DeepSpeech.py"", line 602, in run_set
    feed_dict=feed_dict)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/home/administrator/deepspeech_0.6.1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: output dimensions must be positive
	 [[{{node cond_1/else/_9/ResizeBilinear}}]]
	 [[tower_0/IteratorGetNext]]

if I turn off all the augmentation it running perflectly.
error is not only for  0.6.1a also  this error get for 0.6.0.
Thanks",also got error command true true epoch training time loss recent call last file line return file line file line output must positive node handling exception another exception recent call last file line module main file line run main file line main file line main train file line train epoch file line file line run file line file line file line raise type message output must positive node turn augmentation running error also error get thanks,issue,positive,positive,positive,positive,positive,positive
569257025,"Thanks for the reply,@mychiux413
can you explain what is  augmentation_sparse_warp . is there any paper link.

Thanks",thanks reply explain paper link thanks,issue,positive,positive,positive,positive,positive,positive
569250983,"Hi @vigneshgig ,
The `--augmentation_sparse_warp` in my fork is still unstable, if `--augmentation_sparse_warp_time_warping_para` is too large, you might have change to get `matrix invertible error` on short audio, I haven't figured out the solution.
My personal short-term solution is to filter the `audio duration > 0.5s`, and set `--augmentation_sparse_warp_time_warping_para=12` or less, which helps my training process go through 8 million rows data and 15 epochs now, but I'm still monitoring it, so I can't guarantee it won't crash even with this parameters after many epochs.

> Is augmentation depends on other augmentation. can anyone give me a explanation for this behaviour.

Sorry for that, you shouldn't try other augmentations in my fork, it's not an official way to augment data, maybe it's inappropriate for discussion here, I just wanted to demonstrate how short audio got error, and fix freq_and_time_masking can help @NarasimmanSaravana1994 prevent this error.",hi fork still unstable large might change get matrix invertible error short audio figured solution personal solution filter audio duration set le training process go million data still ca guarantee wo crash even many augmentation augmentation anyone give explanation behaviour sorry try fork official way augment data maybe inappropriate discussion demonstrate short audio got error fix help prevent error,issue,negative,positive,neutral,neutral,positive,positive
569210903," the freq_max is `time_max` now, so the 'maxval' for short audio could be negative
one more question so for above mentioned line I can't use augmentation for short audio .if so how can i skip short audio for augmentation.
Thanks",short audio could negative one question line ca use augmentation short audio skip short audio augmentation thanks,issue,negative,negative,neutral,neutral,negative,negative
569208115,"Hi 

> @NarasimmanSaravana1994,
> Because the augment functions consider the shape of spectrogram as `reversed` shape (#2560),
> The DeepSpeech spectrogram shape is [1, Time, Frequency, 1],
> but `spectrogram_augmentations.py` considers the spectrogram's shape as [1, Frequency, Time, 1],
> since it's developed under `librosa`'s spectrogram, the shape is the opposite of DeepSpeech's.
> 
> So, It cause `augment_freq_time_mask()` consider your `short audio`'s time steps size as frequency size,
> look the code `line 13` in `spectrogram_augmentations.py`:
> 
> ```
>   # the freq_max is `time_max` now, so the 'maxval' for short audio could be negative
>   f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_max - f, dtype=tf.dtypes.int32)
> ```
> 
> You can try my fork, I change the shape back.
> 
> ```
> git clone -b 'develop' --single-branch --depth 1 https://github.com/mychiux413/DeepSpeech.git
> ```
> 
> try training with the same arguments, it should not get error again, but here is another error you might encounter then, after the `short audio` augmented, the `time steps` could be shorter than original one (due to `--augmentation_pitch_and_tempo_scaling_max_tempo`), so you might encountered `[ctc loss error] longer outputs than inputs`, which could not be checked before training (the spec shape is randomly determined), or you could re-estimate the `valid audio length` with the coefficient: `--augmentation_pitch_and_tempo_scaling_max_tempo`.
> 
> In my fork, I just add argument `--ctc_loss_ignore_longer_outputs_than_inputs True` to ignore this error, because the invalid spec is very rare to be generated (`short audio` + `big choosen_tempo`), I don't think it will have much impact on my model





Hi @mychiux413  I also encountered the same issue using above solution i able to solve it some what .Can anyone tell me the explanation for the augmentation parameter so i can change it according to my dataset.
case 1 :
no error for: augmentation_sparse_warp True , augmentation_freq_and_time_masking False , augmentation_pitch_and_tempo_scaling True,augmentation_speed_up_std 1
case 2 : 
error for: augmentation_sparse_warp True ,augmentation_freq_and_time_masking True , augmentation_pitch_and_tempo_scaling False,augmentation_speed_up_std 1

case 3:
error for: augmentation_sparse_warp True ,augmentation_freq_and_time_masking True , augmentation_pitch_and_tempo_scaling True , augmentation_speed_up_std 1
case 4:
error for: augmentation_sparse_warp True ,augmentation_freq_and_time_masking False , augmentation_pitch_and_tempo_scaling False , augmentation_speed_up_std 1
case 5:
error for: augmentation_sparse_warp True , augmentation_freq_and_time_masking False , augmentation_pitch_and_tempo_scaling True,augmentation_speed_up_std 0
case 6:
error for: augmentation_sparse_warp True ,augmentation_freq_and_time_masking True , augmentation_pitch_and_tempo_scaling False,augmentation_speed_up_std 0
case 7:
error for: augmentation_sparse_warp True ,augmentation_freq_and_time_masking True , augmentation_pitch_and_tempo_scaling True , augmentation_speed_up_std 0

Is augmentation depends on other augmentation. can anyone give me a explanation for this behaviour.



 
Thanks",hi augment consider shape spectrogram reversed shape spectrogram shape time frequency spectrogram shape frequency time since spectrogram shape opposite cause consider short audio time size frequency size look code line short audio could negative try fork change shape back git clone depth try training get error another error might encounter short audio augmented time could shorter original one due might loss error longer could checked training spec shape randomly determined could valid audio length coefficient fork add argument true ignore error invalid spec rare short audio big think much impact model hi also issue solution able solve anyone tell explanation augmentation parameter change according case error true false true case error true true false case error true true true case error true false false case error true false true case error true true false case error true true true augmentation augmentation anyone give explanation behaviour thanks,issue,positive,positive,positive,positive,positive,positive
569027538,"> > > OK i will check my setup. Another thing is when i start training without checkpoint than everything would be fine and training continue without any issue. If my tensorflow or CUDNN installation is broken than why it is working when i am not using checkpoint.
> > > This is my current training status without including checkpoint.
> > > `Epoch 0 | Training | Elapsed Time: 1 day, 21:40:02 | Steps: 3786 | Loss: 88.452532`
> > 
> > 
> > Are you enabling cudnn in this case?
> 
> In this case i am just using the --checkpoint_dir flag and start training without using any checkpoint.
> But when i am using this command with checkpoint
> 
> > python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/ --export_tflite --export_dir /home/neeha/Tayyab/export --epochs 1 --train_files /home/neeha/Tayyab/CV/clips/train.csv --dev_files /home/neeha/Tayyab/CV/clips/dev.csv --test_files /home/neeha/Tayyab/CV/clips/test.csv --learning_rate 0.0001 --use_cudnn_rnn true --use_allow_growth true
> 
> i receive these error
> 
> > E Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:
> > E
> > E No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at DeepSpeech.py:118) with these attrs: [dropout=0, seed=4568, num_params=8, T=DT_FLOAT, input_mode=""linear_input"", direction=""unidirectional"", rnn_mode=""lstm"", seed2=240]
> > E Registered devices: [CPU, XLA_CPU]
> > E Registered kernels:
> > E   
> > E
> > E        [[tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]]
> > E The checkpoint in /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784 does not match the shapes of the model. Did you change alphabet.txt or the --n_hidden parameter between train runs using the same checkpoint dir? Try moving or removing the contents of /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784.

So we are back to square one: your TensorFlow / CUDNN setup is broken.",check setup another thing start training without everything would fine training continue without issue installation broken working current training status without epoch training time day loss case case flag start training without command python true true receive error likely due mismatch current graph graph please ensure graph based original error registered support used node defined unidirectional registered registered match model change parameter train try moving removing content back square one setup broken,issue,negative,positive,neutral,neutral,positive,positive
568972920,"> > OK i will check my setup. Another thing is when i start training without checkpoint than everything would be fine and training continue without any issue. If my tensorflow or CUDNN installation is broken than why it is working when i am not using checkpoint.
> > This is my current training status without including checkpoint.
> > `Epoch 0 | Training | Elapsed Time: 1 day, 21:40:02 | Steps: 3786 | Loss: 88.452532`
> 
> Are you enabling cudnn in this case?

In this case i am just using the --checkpoint_dir flag and start training without using any checkpoint.
But when i am using this command with checkpoint 
> python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/ --export_tflite --export_dir /home/neeha/Tayyab/export --epochs 1 --train_files /home/neeha/Tayyab/CV/clips/train.csv --dev_files /home/neeha/Tayyab/CV/clips/dev.csv --test_files /home/neeha/Tayyab/CV/clips/test.csv --learning_rate 0.0001 --use_cudnn_rnn true --use_allow_growth true

i receive these error

> E Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:
E
E No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at DeepSpeech.py:118) with these attrs: [dropout=0, seed=4568, num_params=8, T=DT_FLOAT, input_mode=""linear_input"", direction=""unidirectional"", rnn_mode=""lstm"", seed2=240]
E Registered devices: [CPU, XLA_CPU]
E Registered kernels:
E   <no registered kernels>
E
E        [[tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]]
E The checkpoint in /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784 does not match the shapes of the model. Did you change alphabet.txt or the --n_hidden parameter between train runs using the same checkpoint dir? Try moving or removing the contents of /home/neeha/Tayyab/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784.",check setup another thing start training without everything would fine training continue without issue installation broken working current training status without epoch training time day loss case case flag start training without command python true true receive error likely due mismatch current graph graph please ensure graph based original error registered support used node defined unidirectional registered registered registered match model change parameter train try moving removing content,issue,negative,positive,positive,positive,positive,positive
568870634,"@NarasimmanSaravana1994,
Because the augment functions consider the shape of spectrogram as `reversed` shape (#2560), 
The DeepSpeech spectrogram shape is [1, Time, Frequency, 1],
but `spectrogram_augmentations.py` considers the spectrogram's shape as [1, Frequency, Time, 1], 
since it's developed under `librosa`'s spectrogram, the shape is the opposite of DeepSpeech's.

So, It cause `augment_freq_time_mask()` consider your `short audio`'s time steps size as frequency size,
look the code `line 13` in `spectrogram_augmentations.py`:
```
  # the freq_max is `time_max` now, so the 'maxval' for short audio could be negative
  f0 = tf.random.uniform(shape=(), minval=0, maxval=freq_max - f, dtype=tf.dtypes.int32)
```

You can try my fork, I change the shape back.
```
git clone -b 'develop' --single-branch --depth 1 https://github.com/mychiux413/DeepSpeech.git
```
try training with the same arguments, it should not get error again, but here is another error you might encounter then, after the `short audio` augmented, the `time steps` could be shorter than original one (due to `--augmentation_pitch_and_tempo_scaling_max_tempo`), so you might encountered `[ctc loss error] longer outputs than inputs`, which could not be checked before training (the spec shape is randomly determined), or you could re-estimate the `valid audio length` with the coefficient: `--augmentation_pitch_and_tempo_scaling_max_tempo`.

In my fork, I just add  argument `--ctc_loss_ignore_longer_outputs_than_inputs True` to ignore this error, because the invalid spec is very rare to be generated (`short audio` + `big choosen_tempo`), I don't think it will have much impact on my model",augment consider shape spectrogram reversed shape spectrogram shape time frequency spectrogram shape frequency time since spectrogram shape opposite cause consider short audio time size frequency size look code line short audio could negative try fork change shape back git clone depth try training get error another error might encounter short audio augmented time could shorter original one due might loss error longer could checked training spec shape randomly determined could valid audio length coefficient fork add argument true ignore error invalid spec rare short audio big think much impact model,issue,negative,positive,neutral,neutral,positive,positive
568759897,"I tried to run node from Powershell and MSYS on Windows Sandbox where NodeJS and `Microsoft Visual C++ 2015 Redistributable (x64) - 14.0.24215` were additionally installed, however, they seem to fail with the same error. The region was set to US and language was set to English (US).

```shell
WDAGUtilityAccount@90e34f2c-3b35-4963-99e1-91053d1b3331 MSYS ~
# export LC_ALL=C

WDAGUtilityAccount@90e34f2c-3b35-4963-99e1-91053d1b3331 MSYS ~
# ""/c/Program Files/nodejs/npx"" deepspeech -v
npx: installed 81 in 12.922s
A dynamic link library (DLL) initialization routine failed.
\\?\C:\Users\WDAGUtilityAccount\AppData\Roaming\npm-cache\_npx\3084\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64\node-v79\deepspeech.node
```",tried run node sandbox visual additionally however seem fail error region set u language set u shell export dynamic link library routine,issue,negative,negative,negative,negative,negative,negative
568739192,"I agree, we should.

> On 24 Dec 2019, at 11:09, lissyx <notifications@github.com> wrote:
> 
> ﻿
> @lissyx commented on this pull request.
> 
> In taskcluster/tc-python_tflite-tests-prod.sh:
> 
> > +extract_python_versions ""$1"" ""pyver"" ""pyver_pkg"" ""py_unicode_type"" ""pyconf"" ""pyalias""
> +
> +unset PYTHON_BIN_PATH
> +unset PYTHONPATH
> +
> +if [ -d ""${DS_ROOT_TASK}/pyenv.cache/"" ]; then
> +  export PYENV_ROOT=""${DS_ROOT_TASK}/pyenv.cache/ds-test/.pyenv""
> +else
> +  export PYENV_ROOT=""${DS_ROOT_TASK}/ds-test/.pyenv""
> +fi;
> +
> +export PATH=""${PYENV_ROOT}/bin:$PATH""
> +
> +mkdir -p ${PYENV_ROOT} || true
> +
> +model_source=${DEEPSPEECH_PROD_MODEL//.pb/.tflite}
> It would, but right now we don't run Python prod tests at all. Should we ? I think we should.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",agree wrote pull request export export path true would right run python prod think reply directly view,issue,positive,positive,positive,positive,positive,positive
568687170,"You're right. I was wondering if we can remove the pthread dependency outright, but I can do that later. You didn't really answer my question, the error you mention is about CUDA not pthread.",right wondering remove dependency outright later really answer question error mention,issue,negative,positive,positive,positive,positive,positive
568659129,"Hi @reuben, thanks for checking. 

I *did* try to install the code first using `pip install deepspeech-gpu`. I'm running Ubuntu 19.10: 
```
kathyreid@kathyreid-zenbook-ux533fd:~$ uname -a
Linux kathyreid-zenbook-ux533fd 5.3.0-24-generic #26-Ubuntu SMP Thu Nov 14 01:33:18 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

(deepspeech-gpu-venv) kathyreid@kathyreid-zenbook-ux533fd:~$ cat /etc/issue
Ubuntu 19.10 \n \l
```

I suspect the issue is that my CUDA deps are not installed correctly, as I get the same error documented [here](https://github.com/mozilla/DeepSpeech/issues/1666). 

```
(deepspeech-gpu-venv) kathyreid@kathyreid-zenbook-ux533fd:~$ deepspeech --model deepspeech-0.6.0-models/output_graph.pbmm --lm deepspeech-0.6.0-models/lm.binary --trie deepspeech-0.6.0-models/trie --audio audio/2830-3980-0043.wav
Traceback (most recent call last):
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/site-packages/deepspeech/impl.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 670, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 583, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 1043, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/bin/deepspeech"", line 5, in <module>
    from deepspeech.client import main
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/site-packages/deepspeech/__init__.py"", line 23, in <module>
    from deepspeech.impl import PrintVersions as printVersions
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/site-packages/deepspeech/impl.py"", line 17, in <module>
    _impl = swig_import_helper()
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/site-packages/deepspeech/impl.py"", line 16, in swig_import_helper
    return importlib.import_module('_impl')
  File ""/home/kathyreid/tmp/deepspeech-gpu-venv/lib/python3.7/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_impl'
```

I've tried installed CUDA using the Ubuntu `.deb` package to no avail; I have an NVIDIA gpu; 

```
(deepspeech-gpu-venv) kathyreid@kathyreid-zenbook-ux533fd:~$ lspci | grep -i nvidia
02:00.0 3D controller: NVIDIA Corporation GP107M [GeForce GTX 1050 Mobile] (rev a1)
```
but from what I can tell, CUDA is only supported on Ubuntu 18.10. 

It will be a good learning exercise to try and get CUDA installed properly. 

---

In the meantime, I still think the minor documentation changes here are worth merging in ;-) 

Best, Kathy
",hi thanks try install code first pip install running generic cat suspect issue correctly get error model audio recent call last file line return file line return name level package level file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line file frozen line open object file file directory handling exception another exception recent call last file line module import main file line module import file line module file line return file line return name level package level module tried package avail controller corporation mobile rev tell good learning exercise try get properly still think minor documentation worth best,issue,positive,positive,positive,positive,positive,positive
568466780,"FYI I tried setting up a fresh electron-forge project and deepspeech is working for me, with no node version complications:

https://github.com/dsteinman/deepspeech-electron

I just followed the instructions for setting up a new app:

```
npx create-electron-app deepspeech-electron
cd deepspeech-electron/
npm install deepspeech
npm start
```

@euirim did you figure out what the problem was?  I still suspect you were encountering some sort of npm/yarn cache problem.",tried setting fresh project working node version setting new install start figure problem still suspect sort cache problem,issue,negative,positive,positive,positive,positive,positive
568427092,"Awesome, I'd try it on a normal Linux machine myself but my CPU's don't support a lot of instructions required by tensorflow.",awesome try normal machine support lot,issue,positive,positive,positive,positive,positive,positive
568392890,"> @lissyx @reuben Would any of you be able to test the live example and see if it works on a raspberry pi (or just a normal Linux installation)?

I might try ",would able test live example see work raspberry pi normal installation might try,issue,negative,positive,positive,positive,positive,positive
568384605,"> first non-empty line was ""version https://git-lfs.github.com/spec/v1"" not \data\. Byte: 43

Looks like you have not properly setup `git-lfs` and that you don't have the language model.",first line version like properly setup language model,issue,negative,positive,positive,positive,positive,positive
568353266,@lissyx @reuben Would any of you be able to test the live example and see if it works on a raspberry pi (or just a normal Linux installation)?,would able test live example see work raspberry pi normal installation,issue,negative,positive,positive,positive,positive,positive
568338735,"OK, I will test with vanilla Python.
Thanks, all of you.",test vanilla python thanks,issue,negative,positive,positive,positive,positive,positive
568299563,"> Recommendation: Add `python3-dev` to `sudo apt install portaudio19-dev` in `mic_vad_streaming/README`'s _Installation_.

That's not a bad recommandation, i'd be happy to review a PR for it :)",recommendation add apt install bad happy review,issue,negative,positive,positive,positive,positive,positive
568262402,"> @reuben This is runing with production model:
> 
> > * assert_correct_inference 'she had i do utterly was or all year' 'she had reduce and greasy wash water all year' 0
> 
> It's not impossible we have a valid test, I need to test with a re-export of a fixed model.

And with fixed model:
> + assert_correct_inference 'she had educate in greasy wash were all year' 'she had reduce and greasy wash water all year' 0

So it does indeed reproduce the issue :-)",production model utterly year reduce greasy wash water year impossible valid test need test fixed model fixed model educate greasy wash year reduce greasy wash water year indeed reproduce issue,issue,negative,negative,negative,negative,negative,negative
568259724,"@reuben This is runing with production model:
> + assert_correct_inference 'she had i do utterly was or all year' 'she had reduce and greasy wash water all year' 0

It's not impossible we have a valid test, I need to test with a re-export of a fixed model.",production model utterly year reduce greasy wash water year impossible valid test need test fixed model,issue,negative,negative,negative,negative,negative,negative
568259555,"> It is Japanese locale. I run node from Powershell and Command prompt.

It would not be completely impossible this is triggering a bug. It'd be awesome if you could check that:
 - try under msys2 64-bits, with `LC_ALL=C`
 - try under Powershell with C locale (I don't know how to do that)",locale run node command prompt would completely impossible bug awesome could check try try locale know,issue,positive,positive,positive,positive,positive,positive
568254384,"> Are there examples to use the native C++ client?

Alright, I will see it.

> What are those strange characters that are used as path separator in the status bar at the bottom ? We should see \ and not those.

The character &yen; appears in place of \ when setting Japanese locale on Windows. I understand it is just a matter of font.

> Are you using a specific locale ? How are you running node ? From a terminal ? What's your shell ?

It is Japanese locale. I run node from Powershell and Command prompt.",use native client alright see strange used path separator status bar bottom see character yen place setting locale understand matter font specific locale running node terminal shell locale run node command prompt,issue,negative,negative,neutral,neutral,negative,negative
568252449,"> I paste a screenshot of Dependencies against `deepspeech.node`

What are those strange characters that are used as path separator in the status bar at the bottom ? We should see `\` and not those.

Are you using a specific locale ? How are you running node ? From a terminal ? What's your shell ?",paste strange used path separator status bar bottom see specific locale running node terminal shell,issue,negative,negative,neutral,neutral,negative,negative
568252283,"> Are there examples to use the native C++ client?

Yes, please have a look at the documentation.",use native client yes please look documentation,issue,positive,neutral,neutral,neutral,neutral,neutral
568249045,"@tilmankamp : 

Happy Christmas and New Year!! 

I have a question w.r.t. Tuda-De, M-Ailabs and SWC scripts. I read the paper **_Common Voice: A Massively-Multilingual Speech Corpus_** released by the Deep Speech team. They have mentioned:

_""We made dataset splits (c.f. Table (2)) such that one speaker’s recordings are only present in one data split. This allows us to make a fair evaluation of speaker generalization, but as a result, some training sets have very few speakers, making this an even more challenging scenario.""_ 

I noticed that in SWC script you have used a ""**_speaker_**"" flag to identify the speakers and I assume that you are possibly splitting the overall data set in SWC into training, development and test partitions in such a way that speakers or sentences do not overlap across the different sets. Please confirm?

Could we also do the same with other datasets i.e. Tuda-De and M-Ailabs? Also, it would be great if we could have the script for Voxfogre. The current Voxforge script doesn't support DE version.

",happy new year question read paper voice speech deep speech team made table one speaker present one data split u make fair evaluation speaker generalization result training making even scenario script used flag identify assume possibly splitting overall data set training development test way overlap across different please confirm could also also would great could script current script support de version,issue,positive,positive,positive,positive,positive,positive
568248767,"@lissyx I paste a screenshot of Dependencies against `deepspeech.node`. Are there examples to use the native C++ client?
@carlfm01 It seems I have already installed the SDK since Visual Studio is installed on the machine.

![Dependencies screenshot](https://user-images.githubusercontent.com/1160392/71320422-6eec0780-24ee-11ea-9e9d-2939be517b7a.png)
",paste use native client already since visual studio machine,issue,negative,neutral,neutral,neutral,neutral,neutral
568184593,"Thank you @tilmankamp for the above suggestions. 

Also, today I was randomly looking at the pre-processed transcripts. I found a few transcripts don't match the audio. Not sure how many are there. 

Pre-processed transcript: german-dev/sample-014858.wav, schallplatten
Audio: https://drive.google.com/file/d/1_MZ3Vm6Yv-Q9kwpqT2lOjJVfmgCMwhwZ/view?usp=sharing 

Pre-processed transcript: german-dev/sample-014820.wav, für 
Audio: https://drive.google.com/open?id=1dYPAofaep7kWI8aEo22DtE6uP9WjIh1Q

Is there any way to retain the original naming convention? It would be easy to verify it with the original transcripts.",thank also today randomly looking found match audio sure many transcript audio transcript audio way retain original naming convention would easy verify original,issue,positive,positive,positive,positive,positive,positive
568140838,"Did you try running our code before installing libpthread at all? Although it is listed in our dependencies list, it really should already be available with libc in most if not all distros, as pthread is part of POSIX.


> On 21 Dec 2019, at 01:06, Kathy Reid <notifications@github.com> wrote:
> 
> ﻿
> libpthread on Ubuntu (and presumably any other Debian or Debian derivatives) is in the libpthread-stubs0-dev package, it took me a bit of digging to find it. Best, Kathy
> 
> You can view, comment on, or merge this pull request online at:
> 
>   https://github.com/mozilla/DeepSpeech/pull/2616
> 
> Commit Summary
> 
> Update to specify which package libpthread is in
> File Changes
> 
> M USING.rst (8)
> Patch Links:
> 
> https://github.com/mozilla/DeepSpeech/pull/2616.patch
> https://github.com/mozilla/DeepSpeech/pull/2616.diff
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",try running code although listed list really already available part wrote presumably package took bit digging find best view comment merge pull request commit summary update specify package file patch link thread reply directly view,issue,positive,positive,positive,positive,positive,positive
568094028,"I'm receiving the same error as before while using [this](https://www.amazon.com/gp/product/B01MQ2AA0X/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&psc=1) microphone which specifies a frequency response range of 100-16Khz, which is also mentioned to also support the raspberry pi.",error microphone frequency response range also also support raspberry pi,issue,negative,neutral,neutral,neutral,neutral,neutral
567968389,"CoreML makes it so that the device can take advantage of features like Metal for very fast processing. And it works in a more native format. From what I've seen of TFLite, you would have to write interpreter code in C for it to work properly. It's a lot of steps. I'm not sure about how to get the LM decoder working.

This may become moot for for iOS and the Mac because Apple recently added the ability to do on-device speech recognition in several languages, with word-by-word timestamps, which wasn't possible before iOS 13.",device take advantage like metal fast work native format seen would write interpreter code work properly lot sure get working may become moot mac apple recently added ability speech recognition several possible,issue,positive,positive,positive,positive,positive,positive
567911372,"> Do we run prod tests against the TFLite runtime?

Not prod model as much as I remember: `taskcluster/tc-cpp_tflite-ds-tests.sh` and a few others:
```
$ git grep MODEL taskcluster/*tflite*.sh 
taskcluster/tc-cpp_tflite-ds-tests.sh:model_source=${DEEPSPEECH_TEST_MODEL//.pb/.tflite}
taskcluster/tc-cpp_tflite_basic-ds-tests.sh:model_source=${DEEPSPEECH_TEST_MODEL//.pb/.tflite}
taskcluster/tc-node_tflite-tests.sh:model_source=${DEEPSPEECH_TEST_MODEL//.pb/.tflite}
taskcluster/tc-python_tflite-tests.sh:model_source=${DEEPSPEECH_TEST_MODEL//.pb/.tflite}
```",run prod prod model much remember git model,issue,negative,positive,positive,positive,positive,positive
567910574,"> > not
> 
> Sorry wrongly send the text..
> I attached the sample wav please refer that even single file also not working for me.
> [1.wav.zip](https://github.com/mozilla/DeepSpeech/files/3988248/1.wav.zip)

Can you verify with the LDC93S1 sample we have ?",sorry wrongly send text attached sample please refer even single file also working verify sample,issue,negative,negative,negative,negative,negative,negative
567910160,"In the meantime of a new release, re-exporting the model from checkpoint with patch from #2613 should work.",new release model patch work,issue,negative,positive,positive,positive,positive,positive
567908375,"As @reuben suggested on IRC, this might be a side-effect of CUDNN and incomplete testing on my side for TFLite model.",might incomplete testing side model,issue,negative,neutral,neutral,neutral,neutral,neutral
567905475,"> not

Sorry wrongly send the text..
I attached the sample wav please refer that even single file also not working for me.
[1.wav.zip](https://github.com/mozilla/DeepSpeech/files/3988248/1.wav.zip)

",sorry wrongly send text attached sample please refer even single file also working,issue,negative,negative,negative,negative,negative,negative
567903883,"> @lissyx yes I tried it's not working.

What is not working ?",yes tried working working,issue,negative,neutral,neutral,neutral,neutral,neutral
567894315,Regarding the loss-exploding file: Forgot that you provided your CSVs - will look it up by myself.,regarding file forgot provided look,issue,negative,neutral,neutral,neutral,neutral,neutral
567893578,"Still wonder why I wasn't able to reproduce. Could you provide the transcript of your `.../swc/german-train/sample-072692.wav` file?

Regarding your observations:
1. That's right - so far I thought those were only provided (by the source) in case of abbreviations that should be spoken by spelling out each letter. Idea: Merging single-letter sequences that exceed a length of three.
2. I only see one way to get them excluded: Doing a complete inference run on all of them and then listening to the worst WER ones one-by-one and excluding them. A handy tool for this is missing.",still wonder able reproduce could provide transcript file regarding right far thought provided source case spoken spelling letter idea exceed length three see one way get complete inference run listening worst wer excluding handy tool missing,issue,negative,positive,neutral,neutral,positive,positive
567887251,"I'm wondering if (and if, why) we would need adjustements on the LM weights for TFLite:
```
$ ~/tmp/deepspeech/0.6.0/tflite/deepspeech --model ~/tmp/deepspeech/0.6.0/eng/en-us/output_graph.tflite --lm limited_lm.binary --trie limited_lm.trie --audio deepspeech_dump_all.wav --lm_alpha 2.0 --lm_beta 1.0 -t
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
INFO: Initialized TensorFlow Lite runtime.
turn the bedroom light on
cpu_time_overall=11.44250
$ ~/tmp/deepspeech/0.6.0/tflite/deepspeech --model ~/tmp/deepspeech/0.6.0/eng/en-us/output_graph.tflite --lm limited_lm.binary --trie limited_lm.trie --audio deepspeech_dump_all.wav -t
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
INFO: Initialized TensorFlow Lite runtime.
on the bedroom light on
cpu_time_overall=11.42704
```",wondering would need model audio lite turn bedroom light model audio lite bedroom light,issue,negative,positive,positive,positive,positive,positive
567829820,"> Stupid question, what's the advantage of converting to CoreML?
> It seems iOS can run TFLite already?

I have no idea of the use of CoreML. I know for sure that getting iOS supported is a bunch of work:
 - cross-compiling `libdeepspeech.so`
 - setting up iOS CI infra",stupid question advantage converting run already idea use know sure getting bunch work setting infra,issue,negative,negative,negative,negative,negative,negative
567798754,"I'm afraid I can't help here, currently, I don't have a clean VM to deploy and debug. Tried locally but can't replicate, I've removed all the redistributables and I still see the dependency .dll's. Everything still works :/

@slaypni can you try with https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk installed?",afraid ca help currently clean deploy tried locally ca replicate removed still see dependency everything still work try,issue,positive,negative,neutral,neutral,negative,negative
567790875,"> > ```
> >   	--train_batch_size 1 \
> > ```
> 
> Have you tried a bigger batch size ?

Yes I tried batch size 32,16 finally I tried 1 same issue coming for me",tried bigger batch size yes tried batch size finally tried issue coming,issue,negative,neutral,neutral,neutral,neutral,neutral
567790655,"> > Please assist in how to solve this issue. Please refer the above loop conversation for augmentation arguments.
> 
> You obviously know more about the problem than I do. Data augmentation were contributed, and I was not the one reviewing. I won't be able to help you quickly ...

@lissyx who can give a solution for this problem. ",please assist solve issue please refer loop conversation augmentation obviously know problem data augmentation one wo able help quickly give solution problem,issue,positive,positive,positive,positive,positive,positive
567762640,"> I'm able to get a CoreML model out of the converter using latest master by removing the MFCC feature computation subgraph as well as the model_metadata node. Here's what I did:
> 

According to this notebook, it seems that it's no longer necessary to remove the mfcc and metadata node?
https://github.com/apple/coremltools/blob/master/examples/neural_network_inference/tensorflow_converter/Tensorflow_1/deep_speech.ipynb

Even with the CoreML model, there's still work left to do in terms of adding the LM decoder right? What would be the path to get a decoder running on iOS?",able get model converter latest master removing feature computation well node according notebook longer necessary remove node even model still work left right would path get running,issue,negative,positive,positive,positive,positive,positive
567761723,"Stupid question, what's the advantage of converting to CoreML?
It seems iOS can run TFLite already?
Wouldn't we just need to run TFLite then hook it up to a compatible ds_ctcdecoder?

Since there's no support to convert TFLite to CoreML, this seems like the only path left? (without using the full .pb model)",stupid question advantage converting run already would need run hook compatible since support convert like path left without full model,issue,negative,negative,negative,negative,negative,negative
567744287,"Thank you for pointing out the differences. I have now switched to master code, and I was able to find the file causing infinite loss. On removing it, I don't encounter the infinite loss issue.

```
Use tf.where in 2.0, which has the same broadcast rule as np.where
I Initializing variables...
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000
The following files caused an infinite (or NaN) loss: /media/data/LTLab.lan/agarwal/german-speech-corpus/delete/swc/german-train/sample-072692.wav
```

I would like to point you out to some issues that I have encounter while I was browsing the transcripts, (I was not able to verify it with the original transcripts as the processed wav file names  differs from original ones.)

1. Some transcripts have space between the characters. Example: `c h i p` in the below.
`german-train/sample-000006.wav,319724,von zwei tausend zwölf bis zwei tausend dreizehn gab es mit der `c h i p` power play eine neuauflage des magazins an der zahlreiche`
https://drive.google.com/file/d/1IG4gno1WXaImBliX41a320YB2LO4Vj71/view?usp=sharing

2. Some transcripts don't match exactly to the audio file.
`german-train/sample-032501.wav,208364,der inklination i die die orientierung der rotationsachse`
https://drive.google.com/file/d/1FQIbkUVk4JAt3kqrSv6k9G-V1SFKVmb5/view?usp=sharing
`german-train/sample-045211.wav,25004,g g`
https://drive.google.com/file/d/1mOhdeJwDoqSta5VHTHOUPCLRzdPy5qM-/view?usp=sharing

Is it possible to find/correct these transcripts?


",thank pointing switched master code able find file causing infinite loss removing encounter infinite loss issue use broadcast rule starting optimization epoch training time loss following infinite nan loss would like point encounter browsing able verify original file original space example bi gab e power play match exactly audio file die die possible,issue,negative,positive,positive,positive,positive,positive
567714481,"> It's likely this is hitting not just node users, if it is `libdeepspeech.so`

Initially, I thought it was about the node linking, I see the issue now and my suggestion makes no sense.

> Should we instead package those two deps along with our runtime

I don't think is the ideal, let's first confirm the issue with the .so .",likely node initially thought node linking see issue suggestion sense instead package two along think ideal let first confirm issue,issue,positive,positive,positive,positive,positive,positive
567553156,"Running 0.6.0a15 model with 0.6.0 binaries yields """"good"""" results, as exposed above. Running 0.6.0 model with 0.6.0a15 yields """"bad"""" results. I think this advocates that something in the model changed and TFLite export impacts it :/.",running model good exposed running model bad think something model export,issue,negative,positive,neutral,neutral,positive,positive
567545895,Re-exporting the model with different TFLite conversion parameters does not change.,model different conversion change,issue,negative,neutral,neutral,neutral,neutral,neutral
567520438,"> 			--train_batch_size 1 \

Have you tried a bigger batch size ?",tried bigger batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
567519261,"I now tried to reproduce it on my end, but without success (did a couple of runs):
```
[...]
[2019-12-19 12:45:02] [worker 0] + python -u DeepSpeech.py --alphabet_config_path [...]/de/alphabet.txt --lm_binary_path [...]/languages/german/german-lm.binary --lm_trie_path [...]/languages/german/german-lm.trie --train_files [...]/SWC/german-train.csv --dev_files [...]/SWC/german-dev.csv --test_files [...]/SWC/german-test.csv --feature_cache [...]/swc-feature-cache --train_batch_size 24 --dev_batch_size 36 --test_batch_size 36 --learning_rate 0.0001 --dropout_rate 0.30 --epochs 1 --noearly_stop --checkpoint_dir [...]/keep --summary_dir [...]/summaries
[...]
[2019-12-19 12:45:46] [worker 0] I Initializing variables...
[2019-12-19 12:45:49] [worker 0] I STARTING Optimization
[2019-12-19 12:45:49] [worker 0] Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000
[2019-12-19 12:46:06] [worker 0] Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 1 | Loss: 25.703697
[...]
[2019-12-19 12:56:51] [worker 0] Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 691 | Loss: 133.371081
[2019-12-19 12:56:51] [worker 0] Epoch 0 |   Training | Elapsed Time: 0:11:02 | Steps: 691 | Loss: 133.371081
[2019-12-19 12:56:59] [worker 0] Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: [...]/SWC/german-dev.csv
[...]
```
I had some issues on other runs - but those were batch-size OOMs.

There are some differences left between your and my setup:
- SW environment (especially TensorFlow: [We use 1.14.0 now](https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/.compute#L10))
- DeepSpeech version (I tested with current master)
- ß-replacement (haven't done that on my end)

",tried reproduce end without success couple worker python worker worker starting optimization worker epoch training time loss worker epoch training time loss worker epoch training time loss worker epoch training time loss worker epoch validation time loss left setup environment especially use version tested current master done end,issue,negative,positive,neutral,neutral,positive,positive
567511948,"> Please assist in how to solve this issue. Please refer the above loop conversation for augmentation arguments.

You obviously know more about the problem than I do. Data augmentation were contributed, and I was not the one reviewing. I won't be able to help you quickly ...",please assist solve issue please refer loop conversation augmentation obviously know problem data augmentation one wo able help quickly,issue,positive,positive,positive,positive,positive,positive
567507507,"@lissyx 

While training a model from scratch without using checkpoint with default argument it's working fine, the epoch is running.

Refer to the below-mentioned command for training.

```
'python3.7 DeepSpeech.py \
			--lm_binary_path ./data/lm/lm.binary \
			--lm_trie_path ./data/lm/trie \
			--learning_rate 0.0001 \
			--train_batch_size 1 \
			--alphabet_config_path ./data/alphabet_old.txt \
			--remove_export true \
			--train_files ./data/testing_data/16_12_19_only_wav.csv \
			--export_dir ./export  \
			--checkpoint_dir ./scratch_checkpoint \
			--epochs 10')
```

After changing the augmentation for **augmentation_pitch_and_tempo_scaling** to True I'm facing the issue.

While I trace the error in **spectrogram_augmentations.py**  **augment_pitch_and_tempo** funtion i'm facing **resize bilinear** 

Exactly  **spectrogram_aug = tf.image.resize_bilinear(tf.expand_dims(spectrogram, -1), [new_height, new_width])**  this line while calculating the new_hight and new_width while I think -(minus) value comming but how it is comming and unable to get the calculation value i don't know beacause it's comming tensor value.

Please assist in how to solve this issue.  Please refer the above loop conversation for augmentation arguments.

**My end goal I want to do augmentation for my dataset.**

Thanks...
",training model scratch without default argument working fine epoch running refer command training true augmentation true facing issue trace error facing resize bilinear exactly spectrogram line calculating think minus value unable get calculation value know tensor value please assist solve issue please refer loop conversation augmentation end goal want augmentation thanks,issue,positive,positive,positive,positive,positive,positive
567442256,"@JinZhuXing I also see you are using Anaconda. We're got weird behaviors sometimes, can you reproduce with vanilla Python and a new virtualenv properly setup from scratch ?",also see anaconda got weird sometimes reproduce vanilla python new properly setup scratch,issue,negative,negative,negative,negative,negative,negative
567437525,"> Every Chinese character is multibyte in UTF-8.
> […](#)
> On 19 Dec 2019, at 10:25, lissyx ***@***.***> wrote: ﻿ @JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.

Not multi-byte then, but was it multi-point ?",every character wrote also verify character character thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
567430475,"@JinZhuXing Also, can you verify if the offending character is a unicode multi-byte character?",also verify character character,issue,negative,neutral,neutral,neutral,neutral,neutral
567428499,"> > > data/alphabet.txt already contains '母'.
> > 
> > 
> > Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?
> > How did you generate `data/alphabet.txt` ? Did you used `util/check_characters.py` as suggested ?
> 
> Yes. I have generated data/alphabet.txt file using util/check_characters.py.

Well, I can't help more without more data. But you have an unmatched character in your dataset, for sure.

Maybe you could share more of you data ? The offending transcript as well as the alphabet file ?",already well code find make sure mix different alike generate used yes file well ca help without data unmatched character sure maybe could share data transcript well alphabet file,issue,positive,positive,positive,positive,positive,positive
567425870,"> > data/alphabet.txt already contains '母'.
> 
> Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?
> 
> How did you generate `data/alphabet.txt` ? Did you used `util/check_characters.py` as suggested ?

Yes. I have generated data/alphabet.txt file using util/check_characters.py.",already well code find make sure mix different alike generate used yes file,issue,positive,positive,positive,positive,positive,positive
567413616,"@slaypni It might be good if you could also give a try to the C++ native client, this might help excluding hypothesis.",might good could also give try native client might help excluding hypothesis,issue,positive,positive,positive,positive,positive,positive
567413406,"> @lissyx I upgraded NodeJS to the latest one (13.5.0), confirmed `libdeepspeech.so` exists on the certain path and it is readable, however, loading `deepspeech` still produces the same error. I understand it is hard to investigate the problem further unless reproducing the same error on your environment. I'll see if I can find solutions.

What about analyzing `deepspeech.node` as well with `Dependencies` ?",latest one confirmed certain path readable however loading still error understand hard investigate problem unless error environment see find well,issue,negative,positive,positive,positive,positive,positive
567377716,">  data/alphabet.txt already contains '母'.

Well, the code cannot find it. Can you make sure you don't mix different unicode characters that looks alike ?

How did you generate `data/alphabet.txt` ? Did you used `util/check_characters.py` as suggested ?",already well code find make sure mix different alike generate used,issue,positive,positive,positive,positive,positive,positive
567338336,"@lissyx I upgraded NodeJS to the latest one (13.5.0), confirmed `libdeepspeech.so` exists on the certain path and it is readable, however, loading `deepspeech` still produces the same error. I understand it is hard to investigate the problem further unless reproducing the same error on your environment. I'll see if I can find solutions.",latest one confirmed certain path readable however loading still error understand hard investigate problem unless error environment see find,issue,negative,positive,positive,positive,positive,positive
567132179,"Also you do not need that patch for exporting your own trained models.

> On 18 Dec 2019, at 17:18, lissyx <notifications@github.com> wrote:
> 
> ﻿
> Closed #2610.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",also need patch trained wrote closed thread reply directly view,issue,negative,neutral,neutral,neutral,neutral,neutral
567127940,">     * **Exact command to reproduce**: `python DeepSpeech.py --lm data/all_combinations/lm.binary --trie data/all_combinations/trie --export_tflite --export_dir data/all_combinations/ --checkpoint_dir data/2048_tedlium_2/`

I don't see `--nouse_seq_length`: https://github.com/mozilla/DeepSpeech/blob/v0.5.1/util/flags.py#L76.

This is documented properly: https://github.com/mozilla/DeepSpeech/blob/v0.5.1/README.md#exporting-a-model-for-tflite

Since this is not a bug, I'm closing. Please reach out for support on Discourse.",exact command reproduce python see properly since bug please reach support discourse,issue,positive,positive,positive,positive,positive,positive
567037428,"> OK i will check my setup. Another thing is when i start training without checkpoint than everything would be fine and training continue without any issue. If my tensorflow or CUDNN installation is broken than why it is working when i am not using checkpoint.
> This is my current training status without including checkpoint.
> 
> `Epoch 0 | Training | Elapsed Time: 1 day, 21:40:02 | Steps: 3786 | Loss: 88.452532`

Are you enabling cudnn in this case? ",check setup another thing start training without everything would fine training continue without issue installation broken working current training status without epoch training time day loss case,issue,negative,positive,neutral,neutral,positive,positive
567036976,"OK i will check my setup. Another thing is when i start training without checkpoint than everything would be fine and training continue without any issue. If my tensorflow or CUDNN installation is broken than why it is working when i am not using checkpoint.
This is my current training status without including checkpoint.

`Epoch 0 |   Training | Elapsed Time: 1 day, 21:40:02 | Steps: 3786 | Loss: 88.452532`",check setup another thing start training without everything would fine training continue without issue installation broken working current training status without epoch training time day loss,issue,negative,positive,neutral,neutral,positive,positive
567011494,"Pypi seems to accept Markdown as well as reStructuredText, packaged in the deepspeech wheel.
NPM seems to accept only Markdown: https://docs.npmjs.com/about-package-readme-files, packaged in the deepspeech package.",accept markdown well wheel accept markdown package,issue,positive,neutral,neutral,neutral,neutral,neutral
566992900,"No feedback on the proposed solution 10 days ago that was confirmed to work by others. Closing, there's nothing actionable here.",feedback solution day ago confirmed work nothing actionable,issue,negative,positive,positive,positive,positive,positive
566982912,"@reuben Are we properly packaging it for NPM repository? https://www.npmjs.com/package/deepspeech it shows `""Unable to find a readme for deepspeech@0.6.0""`",properly repository unable find,issue,negative,negative,negative,negative,negative,negative
566943732,"> `process.env['PATH']`: `C:\Users\Kazuaki\Desktop\devel\ds\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64;C:\Python37\Scripts\;C:\Python37\;...`

Just to be 100% sure, you do have `C:\Users\Kazuaki\Desktop\devel\ds\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64\libdeepspeech.so` and it is readable by your user, right ?",sure readable user right,issue,negative,positive,positive,positive,positive,positive
566939924,"> If the Runtime is the source of the issue I think checking the installed version and adding the requirement to the docs should be fine.

It's likely this is hitting not just node users, if it is `libdeepspeech.so` that is linked against those runtime. I'm not a big fan of doing those checks in the library (and actually, I dont think we can since the linker will not load us).

@carlfm01 Should we instead package those two deps along with our runtime ? And if so, where should we source those library ? From the builders ?",source issue think version requirement fine likely node linked big fan library actually dont think since linker load u instead package two along source library,issue,negative,positive,positive,positive,positive,positive
566937390,"@l192423 Please check your setup then, you lack the CUDNN kernels. Either you CUDA installation is broken / incomplete, or your TensorFlow is, or both.",please check setup lack either installation broken incomplete,issue,negative,negative,negative,negative,negative,negative
566924356,"> Have you passed the cudnn flags?

Yes sir i have tried --checkpoint_dir and --cudnn_checkpoint both method. ",yes sir tried method,issue,negative,neutral,neutral,neutral,neutral,neutral
566922199,Your error seems to suggest your cudnn installation is wrong. ,error suggest installation wrong,issue,negative,negative,negative,negative,negative,negative
566920894,"> > resolved. i used this flag with their suggestion [link.](https://github.com/keras-team/keras/issues/10634#issuecomment-469970881)
> > **`--use_allow_growth true`**
> > `CUDA_VISIBLE_DEVICES=2,3 python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir deepspeech-0.6.0-checkpoint/ --epochs 3 --train_files data/train_18-11-2019.csv --dev_files data/dev_18-11-2019.csv --test_files data/test_18-11-2019.csv --learning_rate 0.0001 --use_cudnn_rnn true --use_allow_growth true`
> > Thanks @lissyx @reuben
> 
> @MuruganR96 I'm having the same issue that you faced, as i following your solution. This is the error that i am getting. @lissyx @reuben sir your intention is also required. Thanks!
> 
> `Instructions for updating: Use standard file APIs to check for files with this prefix. INFO:tensorflow:Restoring parameters from deepspeech-0.6.0-checkpoint/best_dev-233784 I1218 12:42:33.675762 139888463619840 saver.py:1280] Restoring parameters from deepspeech-0.6.0-checkpoint/best_dev-233784 E Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error: E E No OpKernel was registered to support Op 'CudnnRNNCanonicalToParams' used by node tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams (defined at DeepSpeech.py:118) with these attrs: [seed=4568, dropout=0, num_params=8, T=DT_FLOAT, input_mode=""linear_input"", direction=""unidirectional"", rnn_mode=""lstm"", seed2=240] E Registered devices: [CPU, XLA_CPU] E Registered kernels: E <no registered kernels> E E [[tower_0/cudnn_lstm/cudnn_lstm/CudnnRNNCanonicalToParams]] E The checkpoint in deepspeech-0.6.0-checkpoint/best_dev-233784 does not match the shapes of the model. Did you change alphabet.txt or the --n_hidden parameter between train runs using the same checkpoint dir? Try moving or removing the contents of deepspeech-0.6.0-checkpoint/best_dev-233784.`

Have you passed the cudnn flags? ",resolved used flag suggestion link true python true true thanks issue faced following solution error getting sir intention also thanks use standard file check prefix likely due mismatch current graph graph please ensure graph based original error registered support used node defined unidirectional registered registered registered match model change parameter train try moving removing content,issue,positive,positive,positive,positive,positive,positive
566916643,"@slaypni Then I'm sorry, I don't know how to debug that further. Out of luck, can you try latest NodeJS v13? This is what I was using (13.3.1 I think ?). Have you ran `Dependencies` against `deepspeech.node` to check if it depends on anything else than `libdeepspeech.so` ?",sorry know luck try latest think ran check anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
566862908,"@lissyx Thank you for suggesting actions.

> Please re-verify everything. I just checked with this tools, and it indeeds finds the missing redistribuable libs from its own directory. Obviously, not a directory that is known by Node process.

`Dependencies` shows all DLLs linked from `libdeepspeech.so` are located under `C:\WINDOWS\system32\`.

> On the installed module, can you hack into deepspeech/index.js and add some console.log statement to know about process.env['PATH'] before and after we compute it ?

I printed `oldPath` and `process.env['PATH']` just before `require(binding_path)` where an error occurs.

- `oldPath`: `C:\Python37\Scripts\;C:\Python37\;...`
- `process.env['PATH']`: `C:\Users\Kazuaki\Desktop\devel\ds\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64;C:\Python37\Scripts\;C:\Python37\;...`

It looks PATH is properly set. (`...` is just for truncation.)",thank suggesting please everything checked missing directory obviously directory known node process linked module hack add statement know compute printed require error path properly set truncation,issue,negative,negative,neutral,neutral,negative,negative
566786593,"Hello,

Just tested and it is working for me, the thing is that I have literally all the redistributable versions installed, at the moment I can't remove them to confirm.  
What comes to my mind for now to mitigate the unknown source of the issue is to check that the redistributable is installed by using the regedit key:

something like:

```
var regedit = require('regedit')

regedit.list('HKLM\\SOFTWARE\\Microsoft\\VisualStudio\\14.0\\VC\\Runtimes\\x64', function(err, result) {
     console.log(result['HKLM\\SOFTWARE\\Microsoft\\VisualStudio\\14.0\\VC\\Runtimes\\x64'].values['Version'])
})
```

We need to check from 10.0 to 15.9 and see if at least one is installed(instead of only 14.0)

If the Runtime is the source of the issue I think checking the installed version and adding the requirement to the docs should be fine.",hello tested working thing literally moment ca remove confirm come mind mitigate unknown source issue check key something like require function err result result need check see least one instead source issue think version requirement fine,issue,positive,positive,neutral,neutral,positive,positive
566707460,"> I'm more and more confident that this is some electron-forge problem. Electron-forge does a lot of magic behind the scenes so I'm going to switch to vanilla electron. I'll try to figure it out and post an update. Thank you for your help.

Thanks, yeah if there's a problem in electron-forge I'd be interested to know because I may also want to use it.",confident problem lot magic behind going switch vanilla electron try figure post update thank help thanks yeah problem interested know may also want use,issue,positive,positive,positive,positive,positive,positive
566688671,"> I'm more and more confident that this is some electron-forge problem. Electron-forge does a lot of magic behind the scenes so I'm going to switch to vanilla electron. I'll try to figure it out and post an update. Thank you for your help.

For the record, I hate that kind of magic :/. If you figure it out, please keep is posted !",confident problem lot magic behind going switch vanilla electron try figure post update thank help record hate kind magic figure please keep posted,issue,positive,positive,positive,positive,positive,positive
566686685,I'm more and more confident that this is some electron-forge problem. Electron-forge does a lot of magic behind the scenes so I'm going to switch to vanilla electron. I'll try to figure it out and post an update. Thank you for your help. ,confident problem lot magic behind going switch vanilla electron try figure post update thank help,issue,positive,positive,positive,positive,positive,positive
566685868,"Yes, I get `Runtime: Node`. That's when I call `> $(npm bin)/deepspeech --version`.",yes get node call bin version,issue,negative,neutral,neutral,neutral,neutral,neutral
566684069,@euirim Do you get `Runtime: Node` or just `Node` ? It would not make a lot of sense either ...,get node node would make lot sense either,issue,negative,neutral,neutral,neutral,neutral,neutral
566683683,"> On node, I get `Node` for the last line instead of `undefined`. In that case, would it default to the closest `NODE_MODULE_VERSION`?

It would have been useful that you also shared how you ran that.

From https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/client.js#L20-L28 you can see that `undefined` comes where we should see `Runtime: X`. We have test coverage over ElectronJS v3.1 to v7.1, this is the first time I see that. it makes absolutely no sense. We should at least see `Runtime: `.",node get node last line instead undefined case would default would useful also ran see undefined come see test coverage first time see absolutely sense least see,issue,negative,positive,neutral,neutral,positive,positive
566681755,"Ah, here's what I get:
```sh
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
undefined
```
On node, I get `Node` for the last line instead of `undefined`. In the latter case, would it default to the closest available `NODE_MODULE_VERSION`?",ah get sh undefined node get node last line instead undefined latter case would default available,issue,negative,positive,positive,positive,positive,positive
566679966,"> Sorry, I wasn't clear. When I call deepspeech in the process that is running electron (known as the `main` process), I get the NODE_MODULE_VERSION error pasted in my initial message **before** I can call `deepspeech --version`.

I don't get a thing of what you are doing, sorry. i'm just asking you to run from some terminal `deepspeech --version` using the electron runtime you are using for you application.",sorry clear call process running electron known main process get error pasted initial message call version get thing sorry run terminal version electron application,issue,negative,negative,negative,negative,negative,negative
566679182,"> @euirim is deepspeech a direct dependency of your electron app? Or is it pulled in from another package on your computer?

It's a direct dependency, so electron-rebuild *should* be able to spot it, unless I'm missing something. 

> > @lissyx Unfortunately I get the initial error while running electron before I can do that.
> 
> I'm not sure I understand what you mean here: ""do that"", do what ? ""while running electron"" ?

Sorry, I wasn't clear. When I call deepspeech in the process that is running electron (known as the `main` process), I get the NODE_MODULE_VERSION error pasted in my initial message **before** I can call `deepspeech --version`.",direct dependency electron another package computer direct dependency able spot unless missing something unfortunately get initial error running electron sure understand mean running electron sorry clear call process running electron known main process get error pasted initial message call version,issue,negative,negative,neutral,neutral,negative,negative
566677692,"> @lissyx Unfortunately I get the initial error while running electron before I can do that.

I'm not sure I understand what you mean here: ""do that"", do what ? ""while running electron"" ?",unfortunately get initial error running electron sure understand mean running electron,issue,negative,negative,neutral,neutral,negative,negative
566677422,@euirim is deepspeech a direct dependency of your electron app?  Or is it pulled in from another package on your computer?,direct dependency electron another package computer,issue,negative,positive,neutral,neutral,positive,positive
566677319,"I'm going to close this, since it is not a bug. You should have everything needed to move forward. Please seek further help on Discourse.",going close since bug everything move forward please seek help discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
566677002,"> > > After the rebuild, I try to execute the command:
> > > pip3 install $(python3 util/taskcluster.py --decoder)
> > 
> > 
> > That's not surprising, the rebuild is not going to upload the package to the repository. You need to `pip install path/to/built/whl`
> 
> Could you elaborate on what is whl? where I can find it? and what exactly do I need to install? thanks.

Wheels are python package. You should have one produced under `native_client/` somewhere, named `ds_ctcdecoder*.whl`. Find it, `pip install <path/to/it>`.",rebuild try execute command pip install python surprising rebuild going package repository need pip install could elaborate find exactly need install thanks python package one produced somewhere find pip install,issue,positive,positive,positive,positive,positive,positive
566676637,"> Also, here are my webpack files in case they help:

I really know nothing about Electron, I can't help more than that.",also case help really know nothing electron ca help,issue,positive,positive,positive,positive,positive,positive
566676555,"> > After the rebuild, I try to execute the command:
> > pip3 install $(python3 util/taskcluster.py --decoder)
> 
> That's not surprising, the rebuild is not going to upload the package to the repository. You need to `pip install path/to/built/whl`

Could you elaborate on what is whl? where I can find it? and what exactly do I need to install? thanks.",rebuild try execute command pip install python surprising rebuild going package repository need pip install could elaborate find exactly need install thanks,issue,positive,positive,positive,positive,positive,positive
566674777,"@lissyx Unfortunately I get the initial error while running electron before I can do that. 

Also, here are my webpack files in case they help:

```js
// webpack.main.config.js
/* eslint-disable @typescript-eslint/no-var-requires, global-require */
const plugins = require('./webpack.plugins');

module.exports = {
  /**
   * This is the main entry point for your application, it's the first file
   * that runs in the main process.
   */
  entry: './src/main/main.ts',
  // Put your normal webpack config below here
  module: {
    rules: require('./webpack.rules'),
  },
  plugins,
  resolve: {
    extensions: ['.js', '.ts', '.jsx', '.tsx', '.css'],
  },
};
```

```js
// webpack.plugins.js
/* eslint-disable @typescript-eslint/no-var-requires, global-require, import/no-extraneous-dependencies */
const ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');

module.exports = [
  new ForkTsCheckerWebpackPlugin({
    async: false,
  }),
];
```

```js
// webpack.renderer.config.js
/* eslint-disable @typescript-eslint/no-var-requires, global-require */
const plugins = require('./webpack.plugins');
const rules = require('./webpack.rules');

rules.push({
  test: /\.css$/,
  use: [{ loader: 'style-loader' }, { loader: 'css-loader' }],
});

module.exports = {
  // Put your normal webpack config below here
  module: {
    rules,
  },
  plugins,
  resolve: {
    extensions: ['.js', '.ts', '.jsx', '.tsx', '.css'],
  },
};
```

```js
// webpack.rules.js
module.exports = [
  // Add support for native node modules
  {
    test: /\.node$/,
    use: 'node-loader',
  },
  {
    test: /\.(m?js|node)$/,
    parser: { amd: false },
    use: {
      loader: '@marshallofsound/webpack-asset-relocator-loader',
      options: {
        outputAssetBase: 'native_modules',
      },
    },
  },
  {
    test: /\.tsx?$/,
    exclude: /(node_modules|.webpack)/,
    loaders: [
      {
        loader: 'ts-loader',
        options: {
          transpileOnly: true,
        },
      },
    ],
  },
  {
    test: /\.s[ac]ss$/i,
    use: [
      // Creates `style` nodes from JS strings
      'style-loader',
      // Translates CSS into CommonJS
      'css-loader',
      // Compiles Sass to CSS
      'sass-loader',
    ],
  },
];
```",unfortunately get initial error running electron also case help require main entry point application first file main process entry put normal module require resolve require new false require require test use loader loader put normal module resolve add support native node test use test parser false use loader test exclude loader true test use style,issue,positive,positive,neutral,neutral,positive,positive
566672680,"> > So as you can see, it does properly rely on `{node_abi}=electron-v7.1`.
> 
> Thanks. For some reason though the error output I posted earlier says the node_abi=node-v72, even when the electron app is open. Not sure at all what's going on. Not sure it's a rebuild problem either because you can just set the node_abi manually in the package.json to be electron-v7.1 and it works perfectly.

Could you somehow manage to run `deepspeech --version` with your electron runtime and share it?",see properly rely thanks reason though error output posted even electron open sure going sure rebuild problem either set manually work perfectly could somehow manage run version electron share,issue,positive,positive,positive,positive,positive,positive
566672209,"> I confirmed all DLLs used from `libdeepspeech.so` exist by using [Dependencies](https://github.com/lucasg/Dependencies). (Dependency Walker seems not working on my Windows.)

Please re-verify everything. I just checked with this tools, and it indeeds finds the missing redistribuable libs from its own directory. Obviously, not a directory that is known by Node process.

@slaypni On the installed module, can you hack into `deepspeech/index.js` and add some `console.log` statement to know about `process.env['PATH']` before and after we compute it ?",confirmed used exist dependency walker working please everything checked missing directory obviously directory known node process module hack add statement know compute,issue,negative,positive,neutral,neutral,positive,positive
566671446,"> So as you can see, it does properly rely on `{node_abi}=electron-v7.1`.

Thanks. For some reason though the error output I posted earlier says the node_abi=node-v72, even when the electron app is open. Not sure at all what's going on. Not sure it's a rebuild problem either because you can just set the node_abi manually in the package.json to be electron-v7.1 and it works perfectly. ",see properly rely thanks reason though error output posted even electron open sure going sure rebuild problem either set manually work perfectly,issue,positive,positive,positive,positive,positive,positive
566670463,"> I was experiencing problems exactly like this, not with `deepspeech` but with some of the other npm modules I was using. I did get them work though, so I still think it's some sort of cache problem.
> 
> @euirim When you run `npm rebuild` are you seeing it actually rebuild deepspeech? You should see it in the console messages.

It doesn't seem to actually rebuild. Here are all the lines in the rebuild output that mention deepspeech:

```sh
deepspeech@0.6.0 /home/euirim/Projects/personal/chorus/node_modules/deepspeech
memory-stream@0.0.3 /home/euirim/Projects/personal/chorus/node_modules/deepspeech/node_modules/memory-stream
node-pre-gyp@0.13.0 /home/euirim/Projects/personal/chorus/node_modules/deepspeech/node_modules/node-pre-gyp
```",exactly like get work though still think sort cache problem run rebuild seeing actually rebuild see console seem actually rebuild rebuild output mention sh,issue,negative,positive,neutral,neutral,positive,positive
566669925,"```
$ LD_DEBUG=all ./node_modules/.bin/electron node_modules/.bin/deepspeech --version 2>&1 | grep deepspeech.node | grep 'binding file'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN14V8ErrorHandlerD1Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN14V8ErrorHandlerD1Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN14V8ErrorHandlerD0Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN14V8ErrorHandler5errorEiPKc'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /lib/x86_64-linux-gnu/libc.so.6 [0]: normal symbol `__cxa_finalize' [GLIBC_2.2.5]
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_exports_MetadataItem_clientData'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN2v810PersistentINS_16FunctionTemplateENS_27NonCopyablePersistentTraitsIS1_EEED1Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZN17SWIGV8_ClientDataD1Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZTV14V8ErrorHandler'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_ZTV14V8ErrorHandler'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `_exports_Metadata_clientData'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0]: normal symbol `model_initialize'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `node_module_register'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /lib/x86_64-linux-gnu/libc.so.6 [0]: normal symbol `__cxa_atexit' [GLIBC_2.2.5]
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v87Isolate10GetCurrentEv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v87Isolate17GetCurrentContextEv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v87Context6GlobalEv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v86String11NewFromUtf8EPNS_7IsolateEPKcNS_13NewStringTypeEi'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v87Private6ForApiEPNS_7IsolateENS_5LocalINS_6StringEEE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v86Object10GetPrivateENS_5LocalINS_7ContextEEENS1_INS_7PrivateEEE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v88External3NewEPNS_7IsolateEPv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v86Object10SetPrivateENS_5LocalINS_7ContextEEENS1_INS_7PrivateEEENS1_INS_5ValueEEE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v811HandleScopeC1EPNS_7IsolateE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v820EscapableHandleScopeC1EPNS_7IsolateE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate3NewEPNS_7IsolateEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS_5LocalIS4_EENSA_INS_9SignatureEEEiNS_19ConstructorBehaviorENS_14SideEffectTypeE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate12SetClassNameENS_5LocalINS_6StringEEE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate16InstanceTemplateEv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v814ObjectTemplate21SetInternalFieldCountEi'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate17PrototypeTemplateEv'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v88Template3SetENS_5LocalINS_4NameEEENS1_INS_4DataEEENS_17PropertyAttributeE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v820EscapableHandleScope6EscapeEPm'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v811HandleScopeD2Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v82V818GlobalizeReferenceEPNS_8internal7IsolateEPm'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v814ObjectTemplate11SetAccessorENS_5LocalINS_4NameEEEPFvS3_RKNS_20PropertyCallbackInfoINS_5ValueEEEEPFvS3_NS1_IS5_EERKNS4_IvEEESB_NS_13AccessControlENS_17PropertyAttributeENS1_INS_17AccessorSignatureEEENS_14SideEffectTypeESL_'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v86Object11SetAccessorENS_5LocalINS_7ContextEEENS1_INS_4NameEEEPFvS5_RKNS_20PropertyCallbackInfoINS_5ValueEEEEPFvS5_NS1_IS7_EERKNS6_IvEEENS_10MaybeLocalIS7_EENS_13AccessControlENS_17PropertyAttributeENS_14SideEffectTypeESN_'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate14SetCallHandlerEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS_5LocalIS2_EENS_14SideEffectTypeE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate7InheritENS_5LocalIS0_EE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v816FunctionTemplate11GetFunctionENS_5LocalINS_7ContextEEE'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v86Object3SetENS_5LocalINS_7ContextEEENS1_INS_5ValueEEES5_'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron/dist/electron --version node_modules/.bin/deepspeech [0]: normal symbol `_ZN2v811HandleScopeD1Ev'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/../libdeepspeech.so [0]: normal symbol `DS_PrintVersions'
      8991:     binding file /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/electron-v7.1/deepspeech.node [0] to /lib/x86_64-linux-gnu/libc.so.6 [0]: normal symbol `__cxa_finalize' [GLIBC_2.2.5]
```",version binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file normal symbol binding file version normal symbol binding file normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file version normal symbol binding file normal symbol binding file normal symbol,issue,negative,positive,positive,positive,positive,positive
566669561,"```
alex@portable-alex:~/tmp/deepspeech/0.6.0/electron$ npm install --prefix=$(pwd)/ electron@7.1

> core-js@3.5.0 postinstall /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/core-js
> node -e ""try{require('./postinstall')}catch(e){}""


> electron@7.1.5 postinstall /home/alex/tmp/deepspeech/0.6.0/electron/node_modules/electron
> node install.js

npm WARN saveError ENOENT: no such file or directory, open '/home/alex/tmp/deepspeech/0.6.0/electron/package.json'
npm notice created a lockfile as package-lock.json. You should commit this file.
npm WARN enoent ENOENT: no such file or directory, open '/home/alex/tmp/deepspeech/0.6.0/electron/package.json'
npm WARN electron No description
npm WARN electron No repository field.
npm WARN electron No README data
npm WARN electron No license field.

+ electron@7.1.5
added 85 packages from 91 contributors and audited 102 packages in 5.289s
found 0 vulnerabilities
alex@portable-alex:~/tmp/deepspeech/0.6.0/electron$ ./node_modules/.bin/electron --version
v7.1.5
alex@portable-alex:~/tmp/deepspeech/0.6.0/electron$ npm install --prefix=$(pwd)/ deepspeech
npm WARN saveError ENOENT: no such file or directory, open '/home/alex/tmp/deepspeech/0.6.0/electron/package.json'
npm WARN enoent ENOENT: no such file or directory, open '/home/alex/tmp/deepspeech/0.6.0/electron/package.json'
npm WARN electron No description
npm WARN electron No repository field.
npm WARN electron No README data
npm WARN electron No license field.

+ deepspeech@0.6.0
added 67 packages from 37 contributors and audited 545 packages in 8.467s
found 0 vulnerabilities

alex@portable-alex:~/tmp/deepspeech/0.6.0/electron$ ./node_modules/.bin/electron node_modules/.bin/deepspeech --version
TensorFlow: v1.14.0-21-ge77504a
DeepSpeech: v0.6.0-0-g6d43e21
Runtime: Electron
```",install electron node try require catch electron node warn file directory open notice commit file warn file directory open warn electron description warn electron repository field warn electron data warn electron license field electron added found version install warn file directory open warn file directory open warn electron description warn electron repository field warn electron data warn electron license field added found version electron,issue,negative,neutral,neutral,neutral,neutral,neutral
566669292,"Oh, it's just to create a local app with a GUI that features speech-to-text. Deepspeech using the node terminal works just fine. Just tried combining the two because I heard Deepspeech has electron support. ",oh create local node terminal work fine tried combining two electron support,issue,positive,positive,positive,positive,positive,positive
566668763,"I was experiencing problems exactly like this, not with `deepspeech` but with some of the other npm modules I was using.  I did get them work though, so I still think it's some sort of cache problem.

@euirim When you run `npm rebuild` are you seeing it actually rebuild deepspeech?  You should see it in the console messages.",exactly like get work though still think sort cache problem run rebuild seeing actually rebuild see console,issue,negative,positive,positive,positive,positive,positive
566668489,"> [Electron-builder](https://www.electron.build) compiles electron code into builds ready for distribution on Mac, Windows, and Linux.
> 
> [Electron-forge](https://github.com/electron-userland/electron-forge) is a CLI and boilerplate designed to make building electron apps easier. If you're familiar with React, it's basically like create-react-app. Electron-forge uses electron-builder for the `build` process.

I really don't understand why you would need this, at least not at `deepspeech` level.",electron code ready distribution mac designed make building electron easier familiar react basically like build process really understand would need least level,issue,positive,positive,positive,positive,positive,positive
566668263,"[Electron-builder](https://www.electron.build) compiles electron code into builds ready for distribution on Mac, Windows, and Linux.

[Electron-forge](https://github.com/electron-userland/electron-forge) is a CLI and boilerplate designed to make building electron apps easier. If you're familiar with React, it's basically like create-react-app. Electron-forge uses electron-builder for the `build` process. ",electron code ready distribution mac designed make building electron easier familiar react basically like build process,issue,positive,positive,positive,positive,positive,positive
566668007,"> electron 7 uses v75,

Electron v7.0 uses `electron-v7.0` and Electron v7.1 uses `electron-v7.1`. As much as I can tell, this is working.",electron electron electron much tell working,issue,negative,positive,positive,positive,positive,positive
566667405,"> @lissyx Configuring Dependencies' search path enabled to find `libdeepspeech.so` as you said. Currently I am copying `libdeepspeech.so` on the current directly (and also a directly under PATH), therefore it should be found on runtime, however, it fails to run. I am wondering if the error is really caused by missing DLLs.

Are you sure that your Node process has the same `PATH` ? There should be no need to move the library, please avoid this as it's going to make debugging even more difficult.",search path find said currently current directly also directly path therefore found however run wondering error really missing sure node process path need move library please avoid going make even difficult,issue,negative,neutral,neutral,neutral,neutral,neutral
566665571,"@lissyx Configuring Dependencies' search path enabled to find `libdeepspeech.so` as you said. Currently I am copying `libdeepspeech.so` onto the current directly (and also a directly under PATH), therefore it should be found on runtime, however, it fails to run. I am wondering if the error is really caused by missing DLLs.",search path find said currently onto current directly also directly path therefore found however run wondering error really missing,issue,negative,neutral,neutral,neutral,neutral,neutral
566664768,"Unfortunately clearing the cache doesn't work. I'm pretty certain it's isolated to node-abi. Node 12 uses v72 and electron 7 uses v75, and the node-abi is choosing v72 instead of the existing electron-7.1 for some reason when installing. Somehow the runtime is not being passed correctly, I think. Maybe electron-forge is doing some magic? I might need to try porting over the project to electron-builder to see. ",unfortunately clearing cache work pretty certain isolated node electron choosing instead reason somehow correctly think maybe magic might need try project see,issue,negative,positive,positive,positive,positive,positive
566661331,"> It's that there's a mismatch between the nodejs version that was used to build deepspeech.

That pretty much sounds like, indeed, a `deepspeech` problem. If the module can't be used out-of-the-box without some magic incantation, we have a problem ...",mismatch version used build pretty much like indeed problem module ca used without magic incantation problem,issue,negative,positive,positive,positive,positive,positive
566660731,"@lissyx I meant deepspeech 0.6 is building fine in my electron 7.1.2 project, so I don't think the error @euirim is experiencing is a deepspeech problem.  It's that there's a mismatch between the nodejs version that was used to build deepspeech.  I had errors like this as well in my project with some of the other npm packages that have native dependencies.",meant building fine electron project think error problem mismatch version used build like well project native,issue,negative,positive,positive,positive,positive,positive
566658585,"> My electron 7.1.2 build is working. But I received these node version errors on my native npm packages.

I don't understand what you say here. Can you explain ? ""Your build"" is working ? Is it with the `rebuild` above ?",electron build working received node version native understand say explain build working rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
566658142,"My electron 7.1.2 build is working.  But I received these node version errors on my native npm packages.

@euirim it might be worth a shot to delete your node_modules directory and clear the caches and your lock files, and then try again:

```
rm yarn.lock
rm package-lock.js
yarn cache clean
npm cache clean --force
```",electron build working received node version native might worth shot delete directory clear lock try yarn cache clean cache clean force,issue,positive,positive,positive,positive,positive,positive
566657020,@dsteinman @euirim And `{node_abi}` in `binary.module_path` is supposed to properly detect Node/Electron runtime: https://github.com/mapbox/node-pre-gyp/blob/master/lib/util/versioning.js#L295 so I don't know what is wrong here ...,supposed properly detect know wrong,issue,negative,negative,negative,negative,negative,negative
566656541,"> After the rebuild, I try to execute the command:
> pip3 install $(python3 util/taskcluster.py --decoder)

That's not surprising, the rebuild is not going to upload the package to the repository. You need to `pip install path/to/built/whl`",rebuild try execute command pip install python surprising rebuild going package repository need pip install,issue,negative,positive,positive,positive,positive,positive
566656253,"After the rebuild, I try to execute the command:
pip3 install $(python3 util/taskcluster.py --decoder)
and yet again get the error:

""
HTTP error 404 while getting https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl
Could not install requirement ds-ctcdecoder==0.4.1 from https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl because of error 404 Client Error: Not Found for url: https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl
Could not install requirement ds-ctcdecoder==0.4.1 from https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl for URL https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.4.1.cpu-ctc/artifacts/public/ds_ctcdecoder-0.4.1-cp36-cp36m-manylinux1_x86_64.whl
""",rebuild try execute command pip install python yet get error error getting could install requirement error client error found could install requirement error client error found,issue,negative,neutral,neutral,neutral,neutral,neutral
566655618,"> Although it also shows `deepspeech.node` has one missing module `libdeepspeech.so`, I am not sure if it is a problem.

Check `index.js` we are supposed to force `PATH` to ensure that `libdeepspeech.so` is properly found. It's possible you need to add the path containing it to Dependencies' config.",although also one missing module sure problem check supposed force path ensure properly found possible need add path,issue,negative,positive,neutral,neutral,positive,positive
566654539,"@lissyx I confirmed all DLLs used from `libdeepspeech.so` exist by using [Dependencies](https://github.com/lucasg/Dependencies). (Dependency Walker seems not working on my Windows.) Although it also shows `deepspeech.node` has one missing module `libdeepspeech.so`, I am not sure if it is a problem.

Exact version of my Windows is as follows:
- Edition: Windows 10 Pro
- Version: 1909
- Installed Date: 2019/12/08
- OS Build: 18363.476
",confirmed used exist dependency walker working although also one missing module sure problem exact version edition pro version date o build,issue,negative,positive,positive,positive,positive,positive
566652643,"> Thanks for the fast reply.
> I meant that I got the same error as before.

Same error as before what ?",thanks fast reply meant got error error,issue,negative,positive,positive,positive,positive,positive
566652420,"Thanks for the quick replies. I should have mentioned that I already tried rebuilding with the `npm rebuild` command. Here's my `package.json` if it helps:

```json
{
  ""name"": ""chorus"",
  ""productName"": ""Chorus"",
  ""version"": ""1.0.0-alpha"",
  ""description"": ""My Electron application description"",
  ""main"": "".webpack/main"",
  ""scripts"": {
    ""start"": ""electron-forge start"",
    ""package"": ""electron-forge package"",
    ""make"": ""electron-forge make"",
    ""publish"": ""electron-forge publish"",
    ""lint"": ""tsc --noEmit && eslint '*/**/*.{js,ts,tsx}' --quiet --fix"",
    ""lint-styles"": ""stylelint --ignore-path .eslintignore '**/*.*(css|scss)' --syntax scss"",
    ""lint-styles-fix"": ""npm run --silent lint-styles --fix; exit 0"",
    ""test"": ""jest"",
    ""rebuild"": ""npm rebuild --runtime=electron --target=7.1.5 --disturl=https://electronjs.org/headers --abi=75""
  },
  ""keywords"": [],
  ""author"": {
    ""name"": ""Euirim Choi"",
    ""email"": ""euirim@gmail.com""
  },
  ""license"": ""MIT"",
  ""config"": {
    ""forge"": {
      ""packagerConfig"": {},
      ""makers"": [
        {
          ""name"": ""@electron-forge/maker-squirrel"",
          ""config"": {
            ""name"": ""chorus""
          }
        },
        {
          ""name"": ""@electron-forge/maker-zip"",
          ""platforms"": [
            ""darwin""
          ]
        },
        {
          ""name"": ""@electron-forge/maker-deb"",
          ""config"": {}
        },
        {
          ""name"": ""@electron-forge/maker-rpm"",
          ""config"": {}
        }
      ],
      ""plugins"": [
        [
          ""@electron-forge/plugin-webpack"",
          {
            ""mainConfig"": ""./webpack.main.config.js"",
            ""renderer"": {
              ""config"": ""./webpack.renderer.config.js"",
              ""entryPoints"": [
                {
                  ""html"": ""./src/renderer/index.html"",
                  ""js"": ""./src/renderer/index.tsx"",
                  ""name"": ""main_window""
                }
              ]
            }
          }
        ]
      ]
    }
  },
  ""dependencies"": {
    ""@types/react"": ""^16.9.16"",
    ""@types/react-dom"": ""^16.9.4"",
    ""argparse"": ""^1.0.10"",
    ""bootstrap"": ""^4.4.1"",
    ""deepspeech"": ""^0.6.0"",
    ""electron"": ""7.1.5"",
    ""electron-rebuild"": ""^1.8.8"",
    ""electron-squirrel-startup"": ""^1.0.0"",
    ""memory-stream"": ""^1.0.0"",
    ""node-abi"": ""^2.13.0"",
    ""node-pre-gyp"": ""^0.14.0"",
    ""node-wav"": ""^0.0.2"",
    ""react"": ""^16.12.0"",
    ""react-bootstrap"": ""^1.0.0-beta.16"",
    ""react-dom"": ""^16.12.0"",
    ""sox-stream"": ""^2.0.3""
  },
  ""devDependencies"": {
    ""@electron-forge/cli"": ""6.0.0-beta.46"",
    ""@electron-forge/maker-deb"": ""6.0.0-beta.46"",
    ""@electron-forge/maker-rpm"": ""6.0.0-beta.46"",
    ""@electron-forge/maker-squirrel"": ""6.0.0-beta.46"",
    ""@electron-forge/maker-zip"": ""6.0.0-beta.46"",
    ""@electron-forge/plugin-auto-unpack-natives"": ""^6.0.0-beta.46"",
    ""@electron-forge/plugin-webpack"": ""6.0.0-beta.46"",
    ""@marshallofsound/webpack-asset-relocator-loader"": ""^0.5.0"",
    ""@types/argparse"": ""^1.0.36"",
    ""@types/jest"": ""^24.0.23"",
    ""@types/node-sass"": ""^4.11.0"",
    ""@types/react-bootstrap"": ""^0.32.20"",
    ""@typescript-eslint/eslint-plugin"": ""^2.11.0"",
    ""@typescript-eslint/parser"": ""^2.11.0"",
    ""css-loader"": ""^3.0.0"",
    ""electron"": ""7.1.5"",
    ""eslint"": ""^6.7.2"",
    ""eslint-config-airbnb"": ""^18.0.1"",
    ""eslint-config-prettier"": ""^6.7.0"",
    ""eslint-import-resolver-typescript"": ""^2.0.0"",
    ""eslint-plugin-import"": ""^2.19.1"",
    ""eslint-plugin-jest"": ""^23.1.1"",
    ""eslint-plugin-prettier"": ""^3.1.1"",
    ""eslint-plugin-react"": ""^7.17.0"",
    ""eslint-plugin-react-hooks"": ""^2.3.0"",
    ""fork-ts-checker-webpack-plugin"": ""^3.1.1"",
    ""husky"": ""^3.1.0"",
    ""jest"": ""^24.9.0"",
    ""lint-staged"": ""^10.0.0-beta.8"",
    ""node-loader"": ""^0.6.0"",
    ""node-sass"": ""^4.13.0"",
    ""prettier"": ""^1.19.1"",
    ""sass-loader"": ""^8.0.0"",
    ""style-loader"": ""^0.23.1"",
    ""stylelint"": ""^12.0.0"",
    ""stylelint-scss"": ""^3.13.0"",
    ""ts-jest"": ""^24.2.0"",
    ""ts-loader"": ""^6.2.1"",
    ""typescript"": ""^3.7.3""
  },
  ""lint-staged"": {
    ""*.{js,ts,tsx}"": [
      ""eslint --fix"",
      ""git add""
    ],
    ""*.{css,scss}"": [
      ""stylelint --ignore-path .eslintignore --syntax scss --fix"",
      ""prettier --ignore-path .eslintignore --single-quote --write"",
      ""git add""
    ]
  },
  ""husky"": {
    ""hooks"": {
      ""pre-commit"": ""tsc --noEmit && lint-staged""
    }
  }
}
```",thanks quick already tried rebuild command name chorus chorus version description electron application description main start start package package make make publish publish lint quiet fix syntax run silent fix exit test jest rebuild rebuild author name license forge name name chorus name name name renderer name bootstrap electron react electron husky jest typescript fix git add syntax fix write git add husky,issue,negative,positive,positive,positive,positive,positive
566648911,"> You need to do an electron rebuild, add this to your package.json scripts:
> 
> ```
> ""scripts"": {
>    ""rebuild"": ""npm rebuild --runtime=electron --target=7.1.5 --disturl=https://atom.io/download/atom-shell --abi=75""
> ```
> 
> And then run `npm run rebuild`.

Can you explain why ? What does that rebuild does ?
We already do that kind of step at build time, there's no reason this should be needed.",need electron rebuild add rebuild rebuild run run rebuild explain rebuild already kind step build time reason,issue,positive,positive,positive,positive,positive,positive
566648413,"> I've manually changed the `""module_path""` in deepspeech's `package.json` to use `v0.6.0/linux-x64/electron-v7.1` instead of node-v72, and this error goes away as expected. However, whenever I call `yarn` or `npm install`, it always uses node-v72 as the node-abi instead of electron-v7.1. How do I prevent this from happening?

I actually don't know why it behaves like that. it should be taken care of by https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/native_client/javascript/index.js#L3-L6



> I'm facing a somewhat similar problem trying to get Electron 7.1.5 setup with deepspeech on Node 12.13.1 (LTS), but I encounter an error when trying to start using electron-forge:
> 
> ```shell
> Error: Cannot open /home/euirim/Projects/personal/chorus/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/node-v72/deepspeech.node: Error: The module '/home/euirim/Projects/personal/chorus/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/node-v72/deepspeech.node'
> was compiled against a different Node.js version using
> NODE_MODULE_VERSION 72. This version of Node.js requires
> NODE_MODULE_VERSION 75. Please try re-compiling or re-installing
> the module (for instance, using `npm rebuild` or `npm install`).
> ```
> 
> I've manually changed the `""module_path""` in deepspeech's `package.json` to use `v0.6.0/linux-x64/electron-v7.1` instead of node-v72, and this error goes away as expected. However, whenever I call `yarn` or `npm install`, the `""module_path""` defaults to using node-v72 as the node-abi instead of electron-v7.1. How do I prevent this from happening?
> 
> Apologies if this is a basic question. I'm new to native node module development.

I know nothing about ElectronJS :/",manually use instead error go away however whenever call yarn install always instead prevent happening actually know like taken care facing somewhat similar problem trying get electron setup node encounter error trying start shell error open error module different version version please try module instance rebuild install manually use instead error go away however whenever call yarn install instead prevent happening basic question new native node module development know nothing,issue,negative,negative,neutral,neutral,negative,negative
566648329,"You need to do an electron rebuild, add this to your package.json scripts:

```
""scripts"": {
   ""rebuild"": ""npm rebuild --runtime=electron --target=7.1.5 --disturl=https://atom.io/download/atom-shell --abi=75""
```

And then run `npm run rebuild`.",need electron rebuild add rebuild rebuild run run rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
566647874,"Thanks for the fast reply.
I meant that I got the same error as before.",thanks fast reply meant got error,issue,negative,positive,positive,positive,positive,positive
566646714,"> but it wont work

We need more than ""it won't work"".",wont work need wo work,issue,negative,neutral,neutral,neutral,neutral,neutral
566644086,"I'm facing a somewhat similar problem trying to get Electron 7.1.5 setup with deepspeech on Node 12.13.1 (LTS), but I encounter an error when trying to start using electron-forge:
```sh
Error: Cannot open /home/euirim/Projects/personal/chorus/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/node-v72/deepspeech.node: Error: The module '/home/euirim/Projects/personal/chorus/node_modules/deepspeech/lib/binding/v0.6.0/linux-x64/node-v72/deepspeech.node'
was compiled against a different Node.js version using
NODE_MODULE_VERSION 72. This version of Node.js requires
NODE_MODULE_VERSION 75. Please try re-compiling or re-installing
the module (for instance, using `npm rebuild` or `npm install`).
```

I've manually changed the `""module_path""` in deepspeech's `package.json` to use `v0.6.0/linux-x64/electron-v7.1` instead of node-v72, and this error goes away as expected. However, whenever I call `yarn` or `npm install`, the `""module_path""` defaults to using node-v72 as the node-abi instead of electron-v7.1. How do I prevent this from happening? 

Apologies if this is a basic question. I'm new to native node module development. ",facing somewhat similar problem trying get electron setup node encounter error trying start sh error open error module different version version please try module instance rebuild install manually use instead error go away however whenever call yarn install instead prevent happening basic question new native node module development,issue,negative,positive,neutral,neutral,positive,positive
566634368,"@slaypni Checking with `Dependency Walker`, reading `libdeepspeech.so` with it, I can confirm:
 - `msvcp140.dll`
 - `vcruntime140.dll`
Are the only ones missing after uninstalling the redistribuable package. Please check on your side as well ?",dependency walker reading confirm missing package please check side well,issue,negative,negative,negative,negative,negative,negative
566608616,"> @lissyx Thank you for finding a solution. I installed the specified version of `vc_redist.x64.exe` and tried to run deepspeech, however, the same error occured again.

That's weird, I verified several times with install / uninstall of it, and I would constantly reproduce / fix the issue. That should not be needed, but have you restarted between tests ? It could be possible that the path is not yet updated.

At that point, maybe you lack some other dep, but it seems like Windows is a bit a moving target, this is not something we had to do before.

@slaypni What's your exact Windows version ? Maybe you need other versions of `vc_redist.x64.exe` as well ?",thank finding solution version tried run however error weird several time install would constantly reproduce fix issue could possible path yet point maybe lack like bit moving target something exact version maybe need well,issue,negative,negative,neutral,neutral,negative,negative
566603726,"@lissyx Thank you for finding a solution. I installed the specified version of `vc_redist.x64.exe` and tried to run deepspeech, however, the same error occured again 😫",thank finding solution version tried run however error,issue,negative,neutral,neutral,neutral,neutral,neutral
566572762,"@kdavis-mozilla @reuben I'll need your opinion whether we just update the doc, or whether we should package the libs with ours.",need opinion whether update doc whether package,issue,negative,neutral,neutral,neutral,neutral,neutral
566568218,"@slaypni It looks like you need ""Redistribuable Visual C++ 2015 Update 3 (64 bits)"" to be installed. Can you try from this link ?

https://www.microsoft.com/fr-fr/download/details.aspx?id=53840
Only select the `vc_redist.x64.exe` package. It was enough to get `deepspeech --version` for me. I'm not sure how we should handle that, I don't know well enough Windows' world.",like need visual update try link select package enough get version sure handle know well enough world,issue,positive,positive,positive,positive,positive,positive
566475656,It's ready: https://community-tc.services.mozilla.com/tasks/groups/XInpWzdaQ4u1pIROntylgA you can pick your own flavor and test :),ready pick flavor test,issue,negative,positive,positive,positive,positive,positive
566456168,"> Or could we find someplace for documenting all those self-made tools for normalizing the datasets? For example, in [Wiki](https://github.com/mozilla/DeepSpeech/wiki) and pointed from Readme.

In this case, it is specific to the dataset, so I think it would make sense to take care of that in `import_cv2.py`

@mychiux413 Can you split your changes amongst both files?",could find someplace example pointed case specific think would make sense take care split amongst,issue,negative,neutral,neutral,neutral,neutral,neutral
566441465,"> Just remove it and see if it stops giving ""i"" for silence. It was added because I wanted to penalize empty beams further since it's somewhat common to have single grapheme transcripts in the Mandarin datasets, and those were sometimes being transcribed as empty strings.
> […](#)
> On 17 Dec 2019, at 07:39, lissyx ***@***.***> wrote: ﻿ I believe it's caused by this check I added with the UTF-8 changes: https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L172-175 I'm on vacation with no access to a laptop for the next two weeks so I can't test it and make a PR until then. … On 16 Dec 2019, at 13:32, JohannesW11K @.***> wrote: ﻿ I'm having the same problem when streaming live-audio. I get ""i"" for silence. Also posted on discourse for reference — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe. Do you remember the exact reason for this check ? I can likely try and fix it, but I've lost context on your UTF-8 work :) — You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.

Done in https://github.com/mozilla/DeepSpeech/pull/2607

@abdul-rehman0 @dsteinman I might need your feedback as well once we have a green PR to test that on your side.",remove see giving silence added penalize empty since somewhat common single mandarin sometimes empty wrote believe check added vacation access next two ca test make wrote problem streaming get silence also posted discourse reference thread reply directly view remember exact reason check likely try fix lost context work reply directly view done might need feedback well green test side,issue,negative,negative,neutral,neutral,negative,negative
566422999,"Just remove it and see if it stops giving ""i"" for silence. It was added because I wanted to penalize empty beams further since it's somewhat common to have single grapheme transcripts in the Mandarin datasets, and those were sometimes being transcribed as empty strings.

> On 17 Dec 2019, at 07:39, lissyx <notifications@github.com> wrote:
> 
> ﻿
> I believe it's caused by this check I added with the UTF-8 changes: https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L172-175 I'm on vacation with no access to a laptop for the next two weeks so I can't test it and make a PR until then.
> …
> On 16 Dec 2019, at 13:32, JohannesW11K @.***> wrote: ﻿ I'm having the same problem when streaming live-audio. I get ""i"" for silence. Also posted on discourse for reference — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.
> 
> Do you remember the exact reason for this check ? I can likely try and fix it, but I've lost context on your UTF-8 work :)
> 
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",remove see giving silence added penalize empty since somewhat common single mandarin sometimes empty wrote believe check added vacation access next two ca test make wrote problem streaming get silence also posted discourse reference thread reply directly view remember exact reason check likely try fix lost context work reply directly view,issue,negative,negative,neutral,neutral,negative,negative
566421703,"> I believe it's caused by this check I added with the UTF-8 changes: https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L172-175 I'm on vacation with no access to a laptop for the next two weeks so I can't test it and make a PR until then.
> […](#)
> On 16 Dec 2019, at 13:32, JohannesW11K ***@***.***> wrote: ﻿ I'm having the same problem when streaming live-audio. I get ""i"" for silence. Also posted on discourse for reference — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.

Do you remember the exact reason for this check ? I can likely try and fix it, but I've lost context on your UTF-8 work :)",believe check added vacation access next two ca test make wrote problem streaming get silence also posted discourse reference thread reply directly view remember exact reason check likely try fix lost context work,issue,negative,positive,neutral,neutral,positive,positive
566421039,"> Error: A dynamic link library (DLL) initialization routine failed.
> \\?\C:\Users\Kazuaki\Desktop\devel\ds\node_modules\deepspeech\lib\binding\v0.6.0\win32-x64\node-v79\deepspeech.node

I don't know well enough Windows, but `deepspeech.node` should load `libdeepspeech.so`. Somehow, it is failing :/",error dynamic link library routine know well enough load somehow failing,issue,negative,neutral,neutral,neutral,neutral,neutral
566373128,"Or could we find someplace for documenting all those self-made tools for normalizing the datasets? For example, in [Wiki](https://github.com/mozilla/DeepSpeech/wiki) and pointed from Readme.

Assuming every locale has some similar need, it's good to store info and links of all those tools for other people to re-use while fork and experimenting DeepSpeech.",could find someplace example pointed assuming every locale similar need good store link people fork,issue,negative,positive,positive,positive,positive,positive
566217108,"I've just purchased a microphone that specifically supports 16kHz audio, and should hopefully be able to test it within the upcoming week.",microphone specifically audio hopefully able test within upcoming week,issue,negative,positive,positive,positive,positive,positive
566216603,"No, that's really a case for external tooling. At the same time, I have similar local patches for french.

I really think this might be splitted into a part, the normalization, that would go into common voice importer, and the second part, improving alphabet file generation from dataset. ",really case external tooling time similar local really think might part normalization would go common voice importer second part improving alphabet file generation,issue,negative,positive,neutral,neutral,positive,positive
566207013,"It's valid to reduce variant chars in Traditional Chinese texts by converting it as zh-cn to zh-tw with opencc, actually I [had also collected some variant chars](https://github.com/irvin/cc0-sentences/blob/master/zh-tw_char_variant.json) for my zh-tw cc0 corpus for Common Voice.  

But I'm also wondering if we should put this in DeepSpeech here. I don't find any scripts for other languages here. 
@lissyx Do we have a better place to collect the scripts for cleaning datasets?  
",valid reduce variant traditional converting actually also collected variant corpus common voice also wondering put find better place collect cleaning,issue,negative,positive,neutral,neutral,positive,positive
566141045,"I won't be able to check this in the near future. Since it couldn't be reproduced by @rhamnett in 0.5.1, I'll close the issue.",wo able check near future since could close issue,issue,negative,positive,positive,positive,positive,positive
566132732,"I believe it's caused by this check I added with the UTF-8 changes: https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L172-175

I'm on vacation with no access to a laptop for the next two weeks so I can't test it and make a PR until then.

> On 16 Dec 2019, at 13:32, JohannesW11K <notifications@github.com> wrote:
> 
> ﻿
> I'm having the same problem when streaming live-audio. I get ""i"" for silence. Also posted on discourse for reference
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or unsubscribe.
",believe check added vacation access next two ca test make wrote problem streaming get silence also posted discourse reference thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
566123772,"> > If there is, it should be a large reference table for mandarin, but I can't find a standard normalization package, even the standard rules, because different regions have different consensus.
> 
> Ok, and there's absolutely no generic rule accepted by mostly everyone ?

As far as I know, maybe `opencc` Is the most widely accepted normalization package.

the package `opencc` I used in `bin/convert_csv_zh_cn_to_zh_tw.py` can convert characters between different region(`zh-cn` `zh-hk` `zh-tw`), it said that the character reference table is generated after manual collation, and is also the most consistent with the regionality I have seen so far.
I sometimes use `opencc` to convert `zh-cn` dataset as `zh-cn` to achieve ""normalization"", but I'm not literature expert, and I can't iterate through all the characters, so I can't guarantee whether it will cause any harm to the datasets.

here is another example:
wiki says '戶' '户' '戸' are variant characters, in `zh-tw` is `戶`,  when I use `opencc`:
```
print('to tw: ', opencc.OpenCC('s2tw').convert('戶户戸'))
# to tw:  戶戶戸
```
as above, '戸' should be converted as '戶', but doen't work.",large reference table mandarin ca find standard normalization package even standard different different consensus absolutely generic rule accepted mostly everyone far know maybe widely accepted normalization package package used convert different region said character reference table manual collation also consistent seen far sometimes use convert achieve normalization literature expert ca iterate ca guarantee whether cause harm another example variant use print converted doe work,issue,negative,positive,neutral,neutral,positive,positive
566097303,"> If there is, it should be a large reference table for mandarin, but I can't find a standard normalization package, even the standard rules, because different regions have different consensus.

Ok, and there's absolutely no generic rule accepted by mostly everyone ?",large reference table mandarin ca find standard normalization package even standard different different consensus absolutely generic rule accepted mostly everyone,issue,negative,positive,positive,positive,positive,positive
566095573,"> > for example: '戶'(\xe6\x88\xb6) '戸'(\xe6\x88\xb8) in mandarin are the same pronunciation, same meaning, but in computer, they are different characters. Even in human cognition, we know that they have different representations, neither way of writing is wrong. but when these two characters appear in the same training file, it will be a nightmare.
> 
> Ok, Wouldn't it be possible to normalize to one or the other character ? Instead of just dropping. Of course, this should be done before generating the alphabet, it should be done at importer-level maybe.
> 
> The rationale seems similar to something I recently fixed on Common Voice french dataset, although the issue was much easier to deal with: `NFCD` vs `NFKD`, e.g., for `é`.

If there is, it should be a large reference table for mandarin, but I can't find a standard normalization package, even the standard rules, because different regions have different consensus.

By the way, I happen to be clearing Common Voice English V2 dataset, I found many rows has different space style like:
`I 'm` `I'm`
`dog 's` `women's`

But I can't just use regular expression to clear them, like: `re.sub(r'\s\'', '\'', string)`, because it would convert `to 'super fun playground'` -> `to'super fun playground'`, (I also want to strip `'` out)

TED Release2 datasets also has this problem
LibriSpeech & voxforge are clean.",example mandarin pronunciation meaning computer different even human cognition know different neither way writing wrong two appear training file nightmare would possible normalize one character instead dropping course done generating alphabet done maybe rationale similar something recently fixed common voice although issue much easier deal large reference table mandarin ca find standard normalization package even standard different different consensus way happen clearing common voice found many different space style like dog ca use regular expression clear like string would convert fun playground fun playground also want strip ted release also problem clean,issue,positive,positive,neutral,neutral,positive,positive
566077361,"> for example: '戶'(\xe6\x88\xb6) '戸'(\xe6\x88\xb8) in mandarin are the same pronunciation, same meaning, but in computer, they are different characters. Even in human cognition, we know that they have different representations, neither way of writing is wrong. but when these two characters appear in the same training file, it will be a nightmare.

Ok, Wouldn't it be possible to normalize to one or the other character ? Instead of just dropping. Of course, this should be done before generating the alphabet, it should be done at importer-level maybe.

The rationale seems similar to something I recently fixed on Common Voice french dataset, although the issue was much easier to deal with: `NFCD` vs `NFKD`, e.g., for `é`.",example mandarin pronunciation meaning computer different even human cognition know different neither way writing wrong two appear training file nightmare would possible normalize one character instead dropping course done generating alphabet done maybe rationale similar something recently fixed common voice although issue much easier deal,issue,positive,negative,neutral,neutral,negative,negative
566072161,"> > If we use `util/check_characters.py` with large mandarin datasets, might generate 6xxx ~ 7xxx alphabets.
> 
> Why ?
> 
> > Because mandarin characters contain so many [variant characters](https://en.wikipedia.org/wiki/Variant_Chinese_character), they have SAME meaning, SAME pronunciation, but DIFFERENT character encoding,
> 
> Are we talking about different characters, or differents encoding for the same character ?
> 
for example: '戶'(\xe6\x88\xb6) '戸'(\xe6\x88\xb8) in mandarin are the same pronunciation, same meaning, but in computer, they are different characters. Even in human cognition, we know that they have different representations, neither way of writing is wrong. but when these two characters appear in the same training file, it will be a nightmare.
> > And since it's really hard to build a mandarin version's `unicodedata.normalize` tool, so the better strategy is:
> 
> Still, I don't see how this justifies a separate file. Doing so will only generate noise with people using the wrong tool.

Yes, you are right, misuse can lead to more disasters, I'll remove this one.",use large mandarin might generate mandarin contain many variant meaning pronunciation different character talking different character example mandarin pronunciation meaning computer different even human cognition know different neither way writing wrong two appear training file nightmare since really hard build mandarin version tool better strategy still see separate file generate noise people wrong tool yes right misuse lead remove one,issue,positive,positive,neutral,neutral,positive,positive
566062216,"I'm having the same problem when streaming live-audio to the node.js example. I get `""i""` for silence. Also posted on discourse for [reference](https://discourse.mozilla.org/t/node-js-streaming-example-continuously-producing-the-letter-i-for-noise-silence/50440)",problem streaming example get silence also posted discourse reference,issue,negative,neutral,neutral,neutral,neutral,neutral
566045141,">     * since the transcripts in SLR's mandarin dataset include some weird punctuation like `《`, `》` , the default script will also remove them.

This would likely be rather done on the importer side, not when generating the alphabet: your CSVs should not contain punctuation if you don't want some in the model.

You can't have an alphabet that does not contains all characters that appears in your dataset.",since mandarin include weird punctuation like default script also remove would likely rather done importer side generating alphabet contain punctuation want model ca alphabet,issue,negative,negative,negative,negative,negative,negative
566044035,"> I post the issue here since I assume it's related to my laptop lacking AVX.

This is right, and not a bug. Please use Discourse for support. Your only solution is to rebuild `libdeepspeech.so` without AVX support.",post issue since assume related right bug please use discourse support solution rebuild without support,issue,positive,positive,positive,positive,positive,positive
566041090,"> If we use `util/check_characters.py` with large mandarin datasets, might generate 6xxx ~ 7xxx alphabets.

Why ?



> Because mandarin characters contain so many [variant characters](https://en.wikipedia.org/wiki/Variant_Chinese_character), they have SAME meaning, SAME pronunciation, but DIFFERENT character encoding,

Are we talking about different characters, or differents encoding for the same character ?



> And since it's really hard to build a mandarin version's `unicodedata.normalize` tool, so the better strategy is:

Still, I don't see how this justifies a separate file. Doing so will only generate noise with people using the wrong tool.",use large mandarin might generate mandarin contain many variant meaning pronunciation different character talking different character since really hard build mandarin version tool better strategy still see separate file generate noise people wrong tool,issue,negative,positive,neutral,neutral,positive,positive
566039593,"Thank you, for reopening the issue.

Also, strangely, when I try to train the model on TEST or DEV, the infinite loss is not showing. It seems there are some problematic files still in the TRAIN set. I don't know how I can filter those out. 

I am attaching my TRAIN, DEV and TEST for reference.

Train: https://drive.google.com/file/d/1jGhFlODniKVWUMx05YaQApbWWIHPxTyu/view?usp=sharing
Dev: https://drive.google.com/file/d/17idPGY7NemzEZmDSGMh1NIPrRPAdIlMe/view?usp=sharing
Test: https://drive.google.com/file/d/1tK-rGxba2Iks8iGs0goyrsZYyKJMguMM/view?usp=sharing",thank issue also strangely try train model test dev infinite loss showing problematic still train set know filter train dev test reference train dev test,issue,negative,negative,neutral,neutral,negative,negative
566033061,"If we use `util/check_characters.py` with large mandarin datasets, might generate 6xxx ~ 7xxx alphabets.
But if we filter the rare characters like under 0.00001%, the alphabet size might surprisingly down to 4xxx around.
Because mandarin characters contain so many [variant characters](https://en.wikipedia.org/wiki/Variant_Chinese_character), they have SAME meaning, SAME pronunciation, but DIFFERENT character encoding, which might cause the model choose characters randomly from those variant alphabet, and then got worse loss/wer.

And since it's really hard to build a mandarin version's `unicodedata.normalize` tool, so the better strategy is:
1. To generate alphabet file excluded rare characters first
2. Use this tidy(?) alphabet file to filter those large mandarin datasets, drop those rows which contain rare characters.",use large mandarin might generate filter rare like alphabet size might surprisingly around mandarin contain many variant meaning pronunciation different character might cause model choose randomly variant alphabet got worse since really hard build mandarin version tool better strategy generate alphabet file rare first use tidy alphabet file filter large mandarin drop contain rare,issue,negative,positive,positive,positive,positive,positive
566018496,"@malena1906 There has been quite a few changes since, is this still an issue ?",quite since still issue,issue,negative,neutral,neutral,neutral,neutral,neutral
566018236,"@TrieuLe0801 I don't really see anything actionable here. I'm going to close that issue, people are invited to continue on Discourse. Don't hesitate to file an issue if there's still an actual bug that we need to fix.",really see anything actionable going close issue people continue discourse hesitate file issue still actual bug need fix,issue,negative,positive,neutral,neutral,positive,positive
566015149,"I had been a bit too fast with my answer (actually I missed your note at the end). It just came to my mind that of all the German importers the SWC one was the one with the most ""correction"" work (like numbers and currencies).
I wonder, why [this messages](https://github.com/mozilla/DeepSpeech/blob/551b3dd5f5c36f49af9dc562c69e78d705daee18/DeepSpeech.py#L605) are not showing up in your log.
I'll do the same run as yours on my end and try to get it reproduced and/or a collection of files to further correct or just exclude.",bit fast answer actually note end came mind german one one correction work like wonder showing log run end try get collection correct exclude,issue,negative,positive,neutral,neutral,positive,positive
566001423,">  changing an augmentation argument

Which one ? There's nothing to help us reproduce here, I don't see how we can help you.",augmentation argument one nothing help u reproduce see help,issue,negative,neutral,neutral,neutral,neutral,neutral
565998043,@tarnh Ping ? Can we get an update ? Can you confirm as @a-lunev reported that using the proper Bazel version does indeed unblok you ?,ping get update confirm proper version indeed,issue,negative,neutral,neutral,neutral,neutral,neutral
565971739,Thanks. I know nothing about those languages so I can't really review. But why the second script? We already have that feature in `bin/check_characters.py`,thanks know nothing ca really review second script already feature,issue,negative,positive,positive,positive,positive,positive
565836246,"> Fresh raspbian-buster on a Raspberry Pi 3 Model B Plus Rev 1.3

As noted, please don't expect real time on this device.



> After I got an error regarding which was thrown by numpy (`ImportError: libf77blas.so.3: cannot open shared object file: No such file or directory`) I've installed an additional package via `apt install libatlas-base-dev`.

Yes, I'm sure we have that documented somewhere. Don't hesitate to send a PR to improve documentation if you have opinions on how to make it better.



> Same commands on my macos are working fine.

As documented, RPi3/4 binaries are using the TensorFlow Lite runtime, so you need to pass `output_graph.tflite` and not `output_graph.pbmm`.

Since this is not a bug, I'll close. Feel free to discuss in Disource.",fresh raspberry pi model plus rev noted please expect real time device got error regarding thrown open object file file directory additional package via apt install yes sure somewhere hesitate send improve documentation make better working fine lite need pas since bug close feel free discus,issue,positive,positive,positive,positive,positive,positive
565826573,This is not a bug. Please read the documentation and use pre-built generate_trie from release. What you are trying to do makes absolutely no sense. ,bug please read documentation use release trying absolutely sense,issue,negative,positive,positive,positive,positive,positive
565688963,"> I suppose if @tarnh tries to downgrade Bazel to 0.24.1 like me, it should be fixed as well.

Thanks for confirming it's likely what I asked for in the very first comment :-)",suppose downgrade like fixed well thanks confirming likely first comment,issue,positive,positive,positive,positive,positive,positive
565656568,"> How did you ran `./configure` ? What options did you validate ? That looks like misconfiguration.
> 
> Also, upstream documents Bazel 0.24.1 for this TensorFlow version. Please stick to it.

Today I tried to build Mozilla TensorFlow-1.14 with DeepSpeech 0.6.0 and faced the same issue.
Initially I used Bazel 0.25.2 because there is ""check_bazel_version('0.24.1', '0.25.2')"" line in tensorflow/configure.py file (I followed the instructions here: https://www.tensorflow.org/install/source (""Make sure to install a supported Bazel version: any version between _TF_MIN_BAZEL_VERSION and _TF_MAX_BAZEL_VERSION as specified in tensorflow/configure.py."")).

I tried ""TF_NEED_CUDA=0"" as you suggested. No effect in my case.
Then as you suggested I tried to downgrade Bazel down to 0.24.1, and this helped!
Now I found this: https://www.tensorflow.org/install/source#tested_build_configurations
(tensorflow-1.14.0: Bazel 0.24.1).
It seems https://www.tensorflow.org/install/source is confusing.

I suppose if @tarnh tries to downgrade Bazel to 0.24.1 like me, it should be fixed as well.",ran validate like misconfiguration also upstream version please stick today tried build faced issue initially used line file make sure install version version tried effect case tried downgrade found suppose downgrade like fixed well,issue,positive,positive,positive,positive,positive,positive
565527251,"v0.6.1-alpha.0 just finished building with the changes in #2586, but the Windows package wasn't pushed to PyPI because I forgot to add the Windows task to the PyPI task's dependencies.",finished building package forgot add task task,issue,negative,neutral,neutral,neutral,neutral,neutral
565336514,"> @lissyx Yes, it is a server-side architecture for high-througoutput.

Thanks, we are working on this as well",yes architecture thanks working well,issue,positive,positive,positive,positive,positive,positive
565170809,"I can close the issue since @dabinat suggestion worked fine (i.e download and then load from the file). 

I was trying to literally read the model directly from the S3 bucket; Since the file contents are provided as a byte stream, and not a file, there was no path. Having to download the model AND THEN load it from a file adds an extra step. I was concerned about network latency when spinning up new instances. After trying, it is not an issue.

@lissyx Yes, it is a server-side architecture for high-througoutput.",close issue since suggestion worked fine load file trying literally read model directly bucket since file content provided stream file path model load file extra step concerned network latency spinning new trying issue yes architecture,issue,positive,positive,positive,positive,positive,positive
565109200,"Your import is looking correct.
If you are starting a training from scratch with hyper parameters that are too aggressive, you could under certain circumstances get infinity losses - particularly at the beginning. To overcome this, you could for example lower your `--learning_rate`.
With similar settings I fine-tuned a from-scratch English model (trained using the German alphabet + apostrophe) into a German one using a training-set consisting of _CV-de, TUDA, SWC-de_ and _M-AILABS-de_ and got no ""infs"" at all.
A better place for discussing these kind of questions is our [Discourse forum](https://discourse.mozilla.org/c/deep-speech).",import looking correct starting training scratch hyper aggressive could certain get infinity particularly beginning overcome could example lower similar model trained german alphabet apostrophe german one got better place kind discourse forum,issue,positive,positive,positive,positive,positive,positive
565078580,"@lissyx would appreciate an issue if someone can make it but I will subscribe to new releases of DeepSpeech as well and update accordingly.

@reuben I will make the changes. I am still learning about ML so didn't know if DeepSpeech could work without the LM. Thanks for pointing it out. ",would appreciate issue someone make subscribe new well update accordingly make still learning know could work without thanks pointing,issue,negative,positive,positive,positive,positive,positive
565040537,"Full log doesn't offer much help, nothing about a X server in it: https://community.taskcluster-artifacts.net/a5vQm0D2RXqzx2CqOVe9wA/0/public/logs/live_backing.log",full log offer much help nothing server,issue,negative,positive,positive,positive,positive,positive
565040025,"Thanks for this!

By the way, I noticed that you included a check for the language model being enabled in all of the functions. This is not needed, DeepSpeech can work without a language model. Was it something in our documentation or examples that lead you to believe it was required?",thanks way included check language model work without language model something documentation lead believe,issue,negative,positive,positive,positive,positive,positive
564938206,"> @lissyx have you seen this failure before?

No, but I'm wondering if it would not be just because of some missing system-level dependencies. Do you have a full log ? We should have a fake X server running for the emulator to connect to, this error suggests that Qt-code is unable to connect to X.",seen failure wondering would missing full log fake server running emulator connect error unable connect,issue,negative,negative,negative,negative,negative,negative
564937543,"> a use case where DeepSpeech would not be operating locally; instead multiple instances are to be running in a containerized fashion via Kubernetes or PCF

Ok, I'm sorry I still don't get how in that context it makes it more efficient, but maybe because of my lack of propre knowledge of Kubernetes.



> This way, real-time-transcriptions could be done concurrently. With that being said, the storage solution being explored to host the models (not the audio) was S3. [You don't access your stored resources via paths](https://dluo.me/s3databoto3).

Sorry, but that feel completely orthogonal from my point of view

Also yeah, for performances reasons, as @dabinat noted, we load the model using `mmap()`. That's the reason why at TensorFlow level, I don't think we can address that usecase.

I think TensorFlow has some S3 ability, though, but:
 - that would make a specific, harder-to-test code-path
 - I'm not convinced of the impact, performance-wise, for the reasons exposed above
 - I'm far from being sure it would work with TFLite

@bkkerrig Are you working on deploying some server-side architecture for high-througoutput?",use case would operating locally instead multiple running fashion via sorry still get context efficient maybe lack knowledge way could done concurrently said storage solution host audio access via sorry feel completely orthogonal point view also yeah noted load model reason level think address think ability though would make specific convinced impact exposed far sure would work working architecture,issue,positive,negative,neutral,neutral,negative,negative
564914831,"Nice, thanks for the work! @thecodrr How should we pursue further updates, do you want us to file an issue on your repo on new versions arriving / API breakages, or will you follow the work here ?",nice thanks work pursue want u file issue new follow work,issue,positive,positive,positive,positive,positive,positive
564773061,"They were trying to help, and were [actually correct](https://www.tensorflow.org/install/gpu#hardware_requirements), not that it matters.

In addition, a direct answer to the author's question of how to disable CUDA was already given in this issue. Instead of updating the issue to let us know if the problem still persists or was fixed, the author instead makes a disrespectful comment. This behavior is not acceptable.

@tarnh are you still seeing this issue after setting the environment variable @lissyx mentioned? Can this issue be closed?",trying help actually correct addition direct answer author question disable already given issue instead issue let u know problem still fixed author instead disrespectful comment behavior acceptable still seeing issue setting environment variable issue closed,issue,negative,positive,neutral,neutral,positive,positive
564755124,"For some context, I was exploring a use case where DeepSpeech would not be operating locally; instead multiple instances are to be running in a containerized fashion via Kubernetes or PCF. This way, real-time-transcriptions could be done concurrently. With that being said, the storage solution being explored to host the models (not the audio) was S3. [You don't access your stored resources via paths](https://dluo.me/s3databoto3).

@dabinat That's a good point. I will go ahead with what you suggested in the last paragraph.
",context exploring use case would operating locally instead multiple running fashion via way could done concurrently said storage solution host audio access via good point go ahead last paragraph,issue,positive,positive,positive,positive,positive,positive
564743881,"I can imagine you would have extreme latency if DeepSpeech has to wait for the network to return data every time it needs to read something. Also, this approach is only beneficial in cases where you only need to use a small portion of the file’s data. If you end up using all of the file’s data anyway, you experienced a whole lot of lag for nothing. The whole model needs to be loaded so there would be no benefit even if this worked.

So you’re probably better just downloading the file from S3 and passing in the file path to DeepSpeech. It’s also cheaper than having to receive the same data again and again from S3 for every inference job.",imagine would extreme latency wait network return data every time need read something also approach beneficial need use small portion file data end file data anyway experienced whole lot lag nothing whole model need loaded would benefit even worked probably better file passing file path also receive data every inference job,issue,positive,positive,positive,positive,positive,positive
564728491,"> I am under the impression the only way to get DeepSpeech to load a model is to provide the file path to _[Model](https://github.com/mozilla/DeepSpeech/blob/3ea3a58f9299cbee8d8fd9c6837f64616f8b4d18/native_client/python/__init__.py#L26)_ in the native client. Could capability be added to load from other sources such as a byte stream or file handle? This would be helpful in instances where the model is being loaded from various cloud storage solutions; personally, I am using [S3 buckets](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html).

I don't think TensorFlow does allow this. Also, I'm not really sure to understand the usecase here with S3 buckets and local speech recognition.",impression way get load model provide file path model native client could capability added load stream file handle would helpful model loaded various cloud storage personally think allow also really sure understand local speech recognition,issue,positive,positive,positive,positive,positive,positive
564671252,@reuben It may seem rude to interfere with other people's things. IMHO this applies to telnetd.,may seem rude interfere people,issue,negative,negative,negative,negative,negative,negative
564660954,Tried a bunch of workarounds but nothing seems to work. Maybe there was an update to the Android tooling that broke this recently?,tried bunch nothing work maybe update android tooling broke recently,issue,negative,neutral,neutral,neutral,neutral,neutral
564629179,"Hm, they actually go back at least a week, so we're missing test coverage there.

It fails before tests are run, during `android_setup_emulator`:

```
+ ./tools/emulator -verbose -avd ds-pixel -no-skin -no-audio -no-window -no-boot-anim -accel off
+ adb wait-for-device
emulator:Android emulator version 26.0.3.0 (build_id 3965150)
emulator:Found AVD name 'ds-pixel'
emulator:Found AVD target architecture: arm
emulator:argv[0]: './tools/emulator'; program directory: '/home/build-user/DeepSpeech/Android/SDK/tools'
emulator:  Found directory: /home/build-user/DeepSpeech/Android/SDK/system-images/android-24/google_apis/armeabi-v7a/

emulator:Probing for /home/build-user/DeepSpeech/Android/SDK/system-images/android-24/google_apis/armeabi-v7a//kernel-ranchu: file exists
emulator:Auto-config: -engine qemu2 (based on configuration)
emulator:  Found directory: /home/build-user/DeepSpeech/Android/SDK/system-images/android-24/google_apis/armeabi-v7a/

emulator:try dir /home/build-user/DeepSpeech/Android/SDK/tools
emulator:try dir ./tools/
emulator:try dir ./emulator
emulator:Found target-specific 64-bit emulator binary: /home/build-user/DeepSpeech/Android/SDK/./emulator/qemu/linux-x86_64/qemu-system-armel
emulator:Adding library search path: './emulator/lib64'
emulator:Adding library search path: './emulator/lib64/gles_swiftshader'
emulator:Adding library search path: './emulator/lib64/gles_angle'
emulator:Adding library search path: './emulator/lib64/gles_angle9'
emulator:Adding library search path: './emulator/lib64/gles_angle11'
emulator:Adding library search path: './emulator/lib64/libstdc++'
emulator: Adding library search path for Qt: './emulator/lib64/qt/lib'
emulator: Setting Qt plugin search path: QT_QPA_PLATFORM_PLUGIN_PATH=./emulator/lib64/qt/plugins
emulator: Running :/home/build-user/DeepSpeech/Android/SDK/./emulator/qemu/linux-x86_64/qemu-system-armel
emulator: qemu backend: argv[00] = ""/home/build-user/DeepSpeech/Android/SDK/./emulator/qemu/linux-x86_64/qemu-system-armel""
emulator: qemu backend: argv[01] = ""-verbose""
emulator: qemu backend: argv[02] = ""-avd""
emulator: qemu backend: argv[03] = ""ds-pixel""
emulator: qemu backend: argv[04] = ""-no-skin""
emulator: qemu backend: argv[05] = ""-no-audio""
emulator: qemu backend: argv[06] = ""-no-window""
emulator: qemu backend: argv[07] = ""-no-boot-anim""
emulator: qemu backend: argv[08] = ""-accel""
emulator: qemu backend: argv[09] = ""off""
emulator: Concatenated backend parameters:
 /home/build-user/DeepSpeech/Android/SDK/./emulator/qemu/linux-x86_64/qemu-system-armel -verbose -avd ds-pixel -no-skin -no-audio -no-window -no-boot-anim -accel off
* daemon not running; starting now at tcp:5037
emulator: WARNING: the -no-skin flag is obsolete. to have a non-skinned virtual device, create one through the AVD manager
emulator: autoconfig: -skin 1080x1920
emulator: autoconfig: -skindir (null)
emulator: autoconfig: -kernel /home/build-user/DeepSpeech/Android/SDK/./system-images/android-24/google_apis/armeabi-v7a//kernel-ranchu
emulator: Auto-detect: Kernel image requires new device naming scheme.
emulator: Auto-detect: Kernel does not support YAFFS2 partitions.
emulator: autoconfig: -ramdisk /home/build-user/DeepSpeech/Android/SDK/./system-images/android-24/google_apis/armeabi-v7a//ramdisk.img
emulator: Using initial system image: /home/build-user/DeepSpeech/Android/SDK/./system-images/android-24/google_apis/armeabi-v7a//system.img
emulator: No vendor image
emulator: autoconfig: -initdata /home/build-user/DeepSpeech/Android/SDK/.android/avd/ds-pixel.avd/userdata.img
emulator: autoconfig: -cache /home/build-user/DeepSpeech/Android/SDK/.android/avd/ds-pixel.avd/cache.img
emulator: Increasing RAM size to 1024MB
emulator: VM heap size 0MB is below hardware specified minimum of 256MB,setting it to that value
emulator: System image is read only
emulator: Found 1 DNS servers: 169.254.169.254
emulator: found magic skin width=1080 height=1920 bpp=16

statvfs('/home/build-user/DeepSpeech/Android/SDK/.android/avd/ds-pixel.avd/snapshots/default_boot/ram.img') failed: No such file or directory
emulator: Creating ext4 userdata partition: /home/build-user/DeepSpeech/Android/SDK/.android/avd/ds-pixel.avd/data
emulator: cannot read adb key file: /home/build-user/DeepSpeech/Android/SDK/.android/adbkey.pub
emulator: trying again by copying from home dir
emulator: cannot read adb key file: /home/build-user/DeepSpeech/Android/SDK/.android/adbkey
emulator: trying again by copying from home dir
Creating filesystem with parameters:
    Size: 838860800
    Block size: 4096
    Blocks per group: 32768
    Inodes per group: 7328
    Inode size: 256
    Journal blocks: 3200
    Label: 
    Blocks: 204800
    Block groups: 7
    Reserved block group size: 55
Created filesystem with 60/51296 inodes and 10727/204800 blocks
emulator: WARNING: encryption is off
emulator: Creating empty ext4 cache partition: /home/build-user/DeepSpeech/Android/SDK/.android/avd/ds-pixel.avd/cache.img
Creating filesystem with parameters:
    Size: 69206016
    Block size: 4096
    Blocks per group: 32768
    Inodes per group: 4224
    Inode size: 256
    Journal blocks: 1024
    Label: 
    Blocks: 16896
    Block groups: 1
    Reserved block group size: 7
Created filesystem with 11/4224 inodes and 1302/16896 blocks
emulator: INFO: QtLogger.cpp:68: Warning: could not connect to display  ((null):0, (null))


emulator: INFO: QtLogger.cpp:68: Info: Could not load the Qt platform plugin ""xcb"" in ""./emulator/lib64/qt/plugins"" even though it was found. ((null):0, (null))


Fatal: This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: xcb.
 ((null):0, (null))
emulator: INFO: QtLogger.cpp:68: Fatal: This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: xcb.
 ((null):0, (null))


* daemon started successfully

[taskcluster:error] Task timeout after 3600 seconds. Force killing container.
```",actually go back least week missing test coverage run emulator android emulator version emulator found name emulator found target architecture arm emulator program directory emulator found directory emulator file emulator based configuration emulator found directory emulator try emulator try emulator try emulator found emulator binary emulator library search path emulator library search path emulator library search path emulator library search path emulator library search path emulator library search path emulator library search path emulator setting search path emulator running emulator emulator emulator emulator emulator emulator emulator emulator emulator emulator emulator daemon running starting emulator warning flag obsolete virtual device create one manager emulator emulator null emulator emulator kernel image new device naming scheme emulator kernel support emulator emulator initial system image emulator vendor image emulator emulator emulator increasing ram size emulator heap size hardware minimum setting value emulator system image read emulator found emulator found magic skin file directory emulator partition emulator read key file emulator trying home emulator read key file emulator trying home size block size per group per group size journal label block reserved block group size emulator warning encryption emulator empty cache partition size block size per group per group size journal label block reserved block group size emulator warning could connect display null null emulator could load platform even though found null null fatal application start platform could application may fix problem available platform null null emulator fatal application start platform could application may fix problem available platform null null daemon successfully error task force killing container,issue,negative,positive,positive,positive,positive,positive
564624235,"Getting some weird infra failures in the Pixel tests, seems unrelated to the code:

emulator: INFO: QtLogger.cpp:68: Fatal: This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.",getting weird infra unrelated code emulator fatal application start platform could application may fix problem,issue,negative,negative,negative,negative,negative,negative
564623377,"> I am also trying this from within python but getting the same error. Can we not run tflite model files on desktop?

You can, but it requires a TFLite build of DeepSpeech, which currently is not super easy to install. I recently landed some changes to publish it as `deepspeech-tflite` on desktop platforms, and am in the process of testing them.

In the mean time, you can download the package directly from our build infra here: https://community-tc.services.mozilla.com/tasks/FppLZDBfQau8ThFZStaa7g#artifacts

In the ""Artifacts"" section on the right, choose the appropriate package for your Python version and install it.",also trying within python getting error run model build currently super easy install recently landed publish process testing mean time package directly build infra section right choose appropriate package python version install,issue,positive,positive,positive,positive,positive,positive
564261740,"@tarnh this repository is governed by the [Mozilla Community Participation Guidelines](https://www.mozilla.org/en-US/about/governance/policies/participation/). In particular, see the section ""Be Respectful"" in expected behaviors.

If you believe someone is wrong, either be constructive or don't say anything at all.",repository community participation particular see section respectful believe someone wrong either constructive say anything,issue,negative,positive,neutral,neutral,positive,positive
564253794,"> For now, TensorFlow only supports Nvidia CUDA APIs but to make sure please feel free to check out the official TensorFlow GPU guide. And I will also try to reproduce your problem when I have access to my workstation with Nividia GTX cards to see if that's the code problem or card problem.

Obviously you are wrong.",make sure please feel free check official guide also try reproduce problem access see code problem card problem obviously wrong,issue,negative,positive,positive,positive,positive,positive
563931432,Actually let me rebase this first.,actually let rebase first,issue,negative,positive,positive,positive,positive,positive
563909195,There is no need for GPU support for running decent inference.,need support running decent inference,issue,negative,positive,positive,positive,positive,positive
563662354,"`TensorFlow` only supports the following instruction sets and APIs.

1. NVIDIA® GPU drivers —CUDA 10.0 requires 410.x or higher.
2. CUDA® Toolkit —TensorFlow supports CUDA 10.0 (TensorFlow >= 1.13.0)
3. CUPTI ships with the CUDA Toolkit.
4. cuDNN SDK (>= 7.4.1) 
5. (Optional) TensorRT 5.0 to improve latency and throughput for inference on some models.

REF: https://www.tensorflow.org/install/gpu",following instruction registered higher registered optional improve latency throughput inference ref,issue,negative,positive,positive,positive,positive,positive
563655119,">     * **Have I written custom code**: No
> 
>     * **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch
> 
>     * **TensorFlow installed from (our builds, or upstream TensorFlow)**: Mozilla
> 
>     * **TensorFlow version (use command below)**: 1.14
> 
>     * **Python version**: 3.8.0
> 
>     * **Bazel version (if compiling from source)**: 0.25.0
> 
>     * **GCC/Compiler version (if compiling from source)**: gcc 9.2.0
> 
>     * **CUDA/cuDNN version**: X
> 
>     * **GPU model and memory**: Radeon RX 560
> 
>     * **Exact command to reproduce**:
>       clone https://github.com/mozilla/tensorflow - branch 1.14
> 
> 
> ```
>     cd $srcdir/tensorflow-r1.14
>     ./configure
> 
>     ln -s ../DeepSpeech/native_client ./
>     bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie
> ```
> 
> Error:
> 
> ```
> Starting local Bazel server and connecting to it...
> ERROR: ./tensorflow-r1.14/native_client/BUILD:3:1: file '@org_tensorflow//tensorflow:tensorflow.bzl' does not contain symbol 'if_cuda'
> ERROR: ./tensorflow-r1.14/native_client/BUILD:85:1: name 'tf_cc_shared_object' is not defined
> ERROR: error loading package 'native_client': Package 'native_client' contains errors
> ```

It is simply your card (Radeon RX 560) is not supported yet. For now, TensorFlow only supports Nvidia CUDA APIs  but to make sure please feel free to check out the official TensorFlow GPU guide. And I will also try to reproduce your problem when I have access to my workstation with Nividia GTX cards to see if that's the code problem or card problem. 

GLHF",written custom code o platform distribution arch upstream version use command python version version source version source version model memory exact command reproduce clone branch build bash opt error starting local server error file contain symbol error name defined error error loading package package simply card yet make sure please feel free check official guide also try reproduce problem access see code problem card problem,issue,negative,positive,positive,positive,positive,positive
563372159,NuGet doesn't show any inline listing. I looked for a README being included from the Java bindings but couldn't find it. I'll file a follow up anyway.,show listing included could find file follow anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
563311515,"Thank you @tilmankamp for the reply. Below are the detailed steps, logs and attached alphabet file,

1. Download and pre-process data: 
    Status: Complete

Command:
`DeepSpeech/bin/import_swc.py . --language german --normalize --german_alphabet ../../../dependencies/alphabet.txt`
Logs:
```
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
Progress |#####################################################| 100% completed
No archive ""./SWC_German.tar"" - downloading...
Extracting ""./SWC_German.tar""...
Converting and joining source audio files...
Collecting samples...
Skipped samples:
 - missing timestamps: 106908
 - illegal character: 346
 - too short to decode: 125
 - substitution rule: 52
 - validation: 31
Sub-set ""train"" with 132897 samples (duration: 238.57 h)
Sub-set ""dev"" with 15116 samples (duration: 26.20 h)
Sub-set ""test"" with 14858 samples (duration: 25.76 h)
Creating sample directories...
Splitting audio files...
Writing ""/media/data/LTLab.lan/agarwal/german-speech-corpus/delete/swc/german-train.csv""...
Writing ""/media/data/LTLab.lan/agarwal/german-speech-corpus/delete/swc/german-dev.csv""...
Writing ""/media/data/LTLab.lan/agarwal/german-speech-corpus/delete/swc/german-test.csv""...
Removing intermediate files in ""./german""...
Progress |#####################################################| 100% completed
```


2. Training and Parameters used:
   
```
./DeepSpeech.py --train_files ../german-speech-corpus/delete/swc/train_swc.csv --dev_files ../german-speech-corpus/delete/swc/dev_swc.csv --test_files ../german-speech-corpus/delete/swc/test_swc.csv --alphabet_config_path ../dependencies/alphabet.txt --lm_trie_path ../dependencies/trie --lm_binary_path ../dependencies/lm.binary --test_batch_size 36 --train_batch_size 24 --dev_batch_size 36 --epochs 75 --learning_rate 0.0001 --dropout_rate 0.30 --export_dir ../models

WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.

WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
I Initializing variables...
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:18:08 | Steps: 1845 | Loss: inf
Epoch 0 | Validation | Elapsed Time: 0:00:36 | Steps: 139 | Loss: 270.188871 | Dataset: ../german-speech-corpus/delete/swc/dev_swc.csv
I Saved new best validating model with loss 270.188871 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-1845
Epoch 1 |   Training | Elapsed Time: 0:17:52 | Steps: 1845 | Loss: inf
Epoch 1 | Validation | Elapsed Time: 0:00:35 | Steps: 139 | Loss: 227.384010 | Dataset: ../german-speech-corpus/delete/swc/dev_swc.csv
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I Saved new best validating model with loss 227.384010 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-3690
Epoch 2 |   Training | Elapsed Time: 0:17:52 | Steps: 1845 | Loss: inf
Epoch 2 | Validation | Elapsed Time: 0:00:35 | Steps: 139 | Loss: 218.371178 | Dataset: ../german-speech-corpus/delete/swc/dev_swc.csv
I Saved new best validating model with loss 218.371178 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-5535
Epoch 3 |   Training | Elapsed Time: 0:17:53 | Steps: 1845 | Loss: inf
Epoch 3 | Validation | Elapsed Time: 0:00:35 | Steps: 139 | Loss: 322.072106 | Dataset: ../german-speech-corpus/delete/swc/dev_swc.csv
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I Early stop triggered as (for last 4 steps) validation loss: 322.072106 with standard deviation: 22.604229 and mean: 238.648019
I FINISHED optimization in 1:14:16.207693
I Restored variables from best validation checkpoint at /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-5535, step 5535
Testing model on ../german-speech-corpus/delete/swc/test_swc.csv
Test epoch | Steps: 412 | Elapsed Time: 0:08:00
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
Test on ../german-speech-corpus/delete/swc/test_swc.csv - WER: 0.984189, CER: 0.952155, loss: 221.439163
--------------------------------------------------------------------------------
WER: 3.000000, CER: 1.833333, loss: 90.893661
 - src: ""wurden""
 - res: ""in den hundert""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.789474, loss: 41.020634
 - src: ""umweltveränderungen""
 - res: ""um ein""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 1.200000, loss: 77.087273
 - src: ""array""
 - res: ""er ende""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 2.000000, loss: 86.086899
 - src: ""sex""
 - res: ""in den ""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 1.100000, loss: 120.730904
 - src: ""siebzehnte""
 - res: ""es unendlich""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 1.250000, loss: 157.400894
 - src: ""monotherapie""
 - res: ""die eeeeeeeeeeeee""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 4.250000, loss: 191.515320
 - src: ""doch""
 - res: ""es hunderttausende""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 1.000000, loss: 2.211713
 - src: ""an""
 - res: """"
--------------------------------------------------------------------------------
WER: 1.000000, CER: 1.000000, loss: 2.343423
 - src: ""mit""
 - res: """"
--------------------------------------------------------------------------------
WER: 1.000000, CER: 1.000000, loss: 2.612154
 - src: ""auf""
 - res: """"
--------------------------------------------------------------------------------
I Exporting the model...
I Models exported at ../models
```

3. Alphabet: Please note, I have replaced ß with ss after pre-processing was complete. Also, I trained the language model after replacing ß with ss. There you won't find ß in my alphabet.txt
[alphabet.txt](https://github.com/mozilla/DeepSpeech/files/3940513/alphabet.txt). 

4. I am training my model from scratch.

Here you can find my train_swc.csv for reference: https://drive.google.com/file/d/1jGhFlODniKVWUMx05YaQApbWWIHPxTyu/view?usp=sharing

Note: I used the same above setting for training with other German corpora namely: Tuda-De, Voxforge, Mozilla Common Voice and M-Ailabs and didn't face this infinite loss issue.",thank reply detailed attached alphabet file data status complete command language german normalize progress progress progress progress progress progress progress archive converting joining source audio missing illegal character short decode substitution rule validation train duration dev duration test duration sample splitting audio writing writing writing removing intermediate progress training used warning removed future version instead use python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape warning removed future version handled automatically placer warning removed future version use instead starting optimization epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss warning removed future version use standard file delete prefix saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss warning removed future version use standard file check prefix early stop triggered last validation loss standard deviation mean finished optimization best validation step testing model test epoch time warning removed future version use warning removed future version use test wer loss wer loss den wer loss um wer loss array er wer loss sex den wer loss e wer loss die wer loss e wer loss wer loss wer loss model alphabet please note complete also trained language model wo find training model scratch find reference note used setting training german corpus namely common voice face infinite loss issue,issue,negative,positive,positive,positive,positive,positive
563279962,"@AASHISHAG Please provide more context:
 - Was the import done right/is it complete?
 - What are your training parameters?
 - How does your alphabet look like (or are you performing a UTF-8 based training)?
 - Are you training a German model from scratch or fine-tuning an English model into a German one (recommended)?",please provide context import done complete training alphabet look like based training training german model scratch model german one,issue,positive,positive,neutral,neutral,positive,positive
563145814,@reuben  @lissyx  I actually used a tarball to get DS 0.4.1. After cloning the DS repo as well I don't get this issue anymore. Bazel builds ok. Thank you for the help :),actually used get well get issue thank help,issue,positive,neutral,neutral,neutral,neutral,neutral
562999770,"> ```
> a) Flagged out-of-date & only binary
> b) Flagged out-of-date
> ```
> 
> 
> But I don't want to flame around !

I'm not sure what you mean here, ""flame around"".",binary want flame around sure mean flame around,issue,negative,positive,neutral,neutral,positive,positive
562999679,"> What are the right TF_* options for for a minimal build without CUDA that `./configure` doesn't asks interactive questions?

Default options should be good. We don't need anything fancy. `TF_NEED_CUDA=0` to disable.

Please make sure you stick to the proper Bazel version.",right minimal build without interactive default good need anything fancy disable please make sure stick proper version,issue,negative,positive,positive,positive,positive,positive
562993063,"```
a) Flagged out-of-date & only binary
b) Flagged out-of-date
```
But I don't want to flame around !

What are the right TF_* options for for a minimal build without CUDA that `./configure` doesn't ask interactive questions?",binary want flame around right minimal build without ask interactive,issue,negative,positive,neutral,neutral,positive,positive
562979571,"> Any shit like `pip`, `conda` or `npm` can pollute my filesystem.

Nobody forces you to use them. There is a simple C++ tar as well.



> I use ArchLinux. Today Arch has many weak users, but when you've started 10 years ago you know the rule: _You shall have no other package managers before me_.

I tend to remember someone already made some Arch package. Maybe you should just look into that ?",like pip pollute nobody use simple tar well use today arch many weak ago know rule shall package tend remember someone already made arch package maybe look,issue,negative,positive,neutral,neutral,positive,positive
562978943,"I use ArchLinux. Today Arch has many weak users, but when you've started 10 years ago you know the rule: _You shall have no other package managers before me_.

Any shit like `pip`, `conda` or `npm` can pollute my filesystem.

Additionally I prefer to understand what I'm doing. pip is just a black box.",use today arch many weak ago know rule shall package like pip pollute additionally prefer understand pip black box,issue,negative,negative,neutral,neutral,negative,negative
562971069,@tarnh Can you explain why you want to rebuild from source ? What is not good from our prebuilt binaries ?,explain want rebuild source good,issue,negative,positive,positive,positive,positive,positive
562970946,"How did you ran `./configure` ? What options did you validate ? That looks like misconfiguration.

Also, upstream documents Bazel 0.24.1 for this TensorFlow version. Please stick to it.",ran validate like misconfiguration also upstream version please stick,issue,positive,neutral,neutral,neutral,neutral,neutral
562813078,"resolved. i used this flag with their suggestion [link.](https://github.com/keras-team/keras/issues/10634#issuecomment-469970881)

**`--use_allow_growth true`**

`CUDA_VISIBLE_DEVICES=2,3 python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir deepspeech-0.6.0-checkpoint/ --epochs 3 --train_files data/train_18-11-2019.csv --dev_files data/dev_18-11-2019.csv --test_files data/test_18-11-2019.csv --learning_rate 0.0001 --use_cudnn_rnn true --use_allow_growth true`

Thanks @lissyx @reuben ",resolved used flag suggestion link true python true true thanks,issue,positive,positive,positive,positive,positive,positive
562812439,"@reuben sir. i tried **--use_cudnn_rnn true**. 

`CUDA_VISIBLE_DEVICES=2,3 python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir ./deepspeech-0.6.0-checkpoint --epochs 3 --train_files ./data/csv_files/train.csv --dev_files ./data/csv_files/dev.csv --test_files ./data/csv_files/test.csv --learning_rate 0.0001 --use_cudnn_rnn true`

not yet resolved. :(
```

tensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation.
	 [[{{node save_1/CudnnRNNCanonicalToParams}}]]
```
```

Traceback (most recent call last):
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation.
	 [[{{node save_1/CudnnRNNCanonicalToParams}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 972, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 945, in main
    train()
  File ""DeepSpeech.py"", line 561, in train
    loaded = try_loading(session, best_dev_saver, 'best_dev_checkpoint', 'best validation')
  File ""DeepSpeech.py"", line 403, in try_loading
    saver.restore(session, checkpoint_path)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1286, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation.
	 [[node save_1/CudnnRNNCanonicalToParams (defined at DeepSpeech.py:495) ]]

Original stack trace for 'save_1/CudnnRNNCanonicalToParams':
  File ""DeepSpeech.py"", line 972, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 945, in main
    train()
  File ""DeepSpeech.py"", line 495, in train
    best_dev_saver = tfv1.train.Saver(max_to_keep=1)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 825, in __init__
    self.build()
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 837, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 875, in _build
    build_restore=build_restore)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 508, in _build_internal
    restore_sequentially, reshape)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 350, in _AddRestoreOps
    assign_ops.append(saveable.restore(saveable_tensors, shapes))
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py"", line 744, in restore
    restored_tensors)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py"", line 221, in tf_canonical_to_opaque
    opaque_params = self._cu_canonical_to_opaque(cu_weights, cu_biases)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py"", line 271, in _cu_canonical_to_opaque
    direction=self._direction)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py"", line 917, in cudnn_rnn_canonical_to_params
    seed=seed, seed2=seed2, name=name)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

```",sir tried true python true yet resolved fail find implementation node recent call last file line return file line file line fail find implementation node handling exception another exception recent call last file line module main file line run main file line main file line main train file line train loaded session validation file line session file line restore file line run file line file line file line raise type message fail find implementation node defined original stack trace file line module main file line run main file line main file line main train file line train file line file line build file line file line reshape file line file line restore file line file line file line file line file line return file line file line,issue,negative,positive,neutral,neutral,positive,positive
562630561,The main example at the top of the README works without any issues for me. What sample rate does the microphone need to support?,main example top work without sample rate microphone need support,issue,positive,positive,positive,positive,positive,positive
562575142,@cli0 Does the `ds_git_version.sh` script at least runs ? Are you sure you are not missing any dep ?,script least sure missing,issue,negative,neutral,neutral,neutral,neutral,neutral
562565498,"Yes, you are right. It was a typo. I meant 0.4.1. Unfortunately I can't switch to 0.6.0 for this experiment.

I check the tf and git versions:

```
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.12.0-0-ga6d8ffae09 1.12.0
```

they are not identical grammatically but they are both of the same branch. I also cloned the tf repo (didn't use tarballs) but I cloned the latest version and then switched to the 1.12.

```
$ git clone https://github.com/mozilla/tensorflow.git
$ cd tensorflow
$ git checkout origin/r1.12
```
Any idea how to bypass this?",yes right typo meant unfortunately ca switch experiment check git python import print identical grammatically branch also use latest version switched git clone git idea bypass,issue,negative,positive,neutral,neutral,positive,positive
562551666,"There is no DeepSpeech version 0.14.1. I assume you mean 0.4.1. When building from source, make sure you clone the repository with git rather than just downloading a tarball. I would also suggest upgrading to the latest release 0.6.0.",version assume mean building source make sure clone repository git rather would also suggest latest release,issue,negative,positive,positive,positive,positive,positive
562531385,"> @lissyx sir. my CuDNN setup might be wrong?
> 
> @lissyx sir. how to resolve this issue? what is the problem here i did? :)
> 
> ```
> tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:
> 
> Key cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam not found in checkpoint
> 	 [[node save_1/RestoreV2 (defined at DeepSpeech.py:495) ]]
> ```

Ok, I can't keep repeating over and over the same things. I told you: the error is because it cannot resume using CuDNN. Check your setup if it is supposed to work.",sir setup might wrong sir resolve issue problem likely due variable name graph key missing please ensure graph based original error key found node defined ca keep told error resume check setup supposed work,issue,negative,negative,neutral,neutral,negative,negative
562529191,"@lissyx  sir. my CuDNN setup might be wrong?

@lissyx sir. how to resolve this issue? what is the problem here i did? :) 
```
tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:

Key cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam not found in checkpoint
	 [[node save_1/RestoreV2 (defined at DeepSpeech.py:495) ]]
```
",sir setup might wrong sir resolve issue problem likely due variable name graph key missing please ensure graph based original error key found node defined,issue,negative,negative,neutral,neutral,negative,negative
562527922,"> here i am case 2.
> my system is capable of using CuDNN RNN. then normally with --checkpoint_dir is enough for me.
> 
> but why i need -cudnn_checkpoint?

This is what I asked you in the beginning, if your setup was properly done for CuDNN. The error obviously suggests it's not the case.",case system capable normally enough need beginning setup properly done error obviously case,issue,negative,positive,neutral,neutral,positive,positive
562526053,"@lissyx sir. i have a doubt.


1. if we trying to use --cudnn_checkpoint means the --cudnn_checkpoint flag is only needed when converting a CuDNN RNN checkpoint to a CPU-capable graph. 

2. If your system is capable of using CuDNN RNN, you can just specify the CuDNN RNN checkpoint normally with --checkpoint_dir.
 
here i am case 2. 
my system is capable of using CuDNN RNN. then normally with --checkpoint_dir is enough for me.

but why i need -cudnn_checkpoint? 

@lissyx i am bit confusing. clarify once :)
",sir doubt trying use flag converting graph system capable specify normally case system capable normally enough need bit clarify,issue,negative,positive,positive,positive,positive,positive
562519914,"> it was not picking checkpoint from the directory and not loading. i tested like this,
> 
> > ckpt = tfv1.train.load_checkpoint(""/media/user1/storage-1/Murugan/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784"")

That's not the appropriate way. Please use `--cudnn_checkpoint`.

> ls deepspeech-0.6.0-checkpoint
> best_dev-233784.data-00000-of-00001  best_dev-233784.index  best_dev-233784.meta  best_dev_checkpoint  flags.txt

Try adding a `checkpoint` symlink that links to `best_dev_checkpoint`.",directory loading tested like appropriate way please use try link,issue,positive,positive,positive,positive,positive,positive
562518755,"> You don't clearly answer. What is the content of `./deepspeech-0.6.0-checkpoint/` ?

@lissyx sir, 
```
ls deepspeech-0.6.0-checkpoint
best_dev-233784.data-00000-of-00001  best_dev-233784.index  best_dev-233784.meta  best_dev_checkpoint  flags.txt
```
@lissyx . I found the problem  is, 

`ckpt = tfv1.train.load_checkpoint(FLAGS.cudnn_checkpoint)`

it was not picking checkpoint from the directory and not loading. i tested like this,

> ckpt = tfv1.train.load_checkpoint(""/media/user1/storage-1/Murugan/DeepSpeech/deepspeech-0.6.0-checkpoint/best_dev-233784"")

```
I Initializing missing Adam moment tensors.
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 202 | Loss: 16.245042                                                                                                                                                                  Traceback (most recent call last):
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: Not enough time for target transition sequence (required: 89, available: 53)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[{{node tower_0/CTCLoss}}]]
	 [[Mean_8/_91]]
  (1) Invalid argument: Not enough time for target transition sequence (required: 89, available: 53)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[{{node tower_0/CTCLoss}}]]
0 successful operations.
0 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 971, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 944, in main
    train()
  File ""DeepSpeech.py"", line 637, in train
    train_loss, _ = run_set('train', epoch, train_init_op)
  File ""DeepSpeech.py"", line 605, in run_set
    feed_dict=feed_dict)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: Not enough time for target transition sequence (required: 89, available: 53)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[node tower_0/CTCLoss (defined at DeepSpeech.py:231) ]]
	 [[Mean_8/_91]]
  (1) Invalid argument: Not enough time for target transition sequence (required: 89, available: 53)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[node tower_0/CTCLoss (defined at DeepSpeech.py:231) ]]
0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node tower_0/CTCLoss:
 tower_0/raw_logits (defined at DeepSpeech.py:196)	
 tower_0/DeserializeSparse (defined at DeepSpeech.py:220)

Input Source operations connected to node tower_0/CTCLoss:
 tower_0/raw_logits (defined at DeepSpeech.py:196)	
 tower_0/DeserializeSparse (defined at DeepSpeech.py:220)

Original stack trace for 'tower_0/CTCLoss':
  File ""DeepSpeech.py"", line 971, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 944, in main
    train()
  File ""DeepSpeech.py"", line 474, in train
    gradients, loss, non_finite_files = get_tower_results(iterator, optimizer, dropout_rates)
  File ""DeepSpeech.py"", line 301, in get_tower_results
    avg_loss, non_finite_files = calculate_mean_edit_distance_and_loss(iterator, dropout_rates, reuse=i > 0)
  File ""DeepSpeech.py"", line 231, in calculate_mean_edit_distance_and_loss
    total_loss = tfv1.nn.ctc_loss(labels=batch_y, inputs=logits, sequence_length=batch_seq_len)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/ops/ctc_ops.py"", line 176, in ctc_loss
    ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_ctc_ops.py"", line 335, in ctc_loss
    name=name)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()
```

",clearly answer content sir found problem directory loading tested like missing moment starting optimization epoch training time loss recent call last file line return file line file line root error found invalid argument enough time target transition sequence available turn error warning flag node invalid argument enough time target transition sequence available turn error warning flag node successful derived handling exception another exception recent call last file line module main file line run main file line main file line main train file line train epoch file line file line run file line file line file line raise type message root error found invalid argument enough time target transition sequence available turn error warning flag node defined invalid argument enough time target transition sequence available turn error warning flag node defined successful derived may input operation input source connected node defined defined input source connected node defined defined original stack trace file line module main file line run main file line main file line main train file line train loss file line file line file line file line file line file line return file line file line,issue,negative,positive,positive,positive,positive,positive
562514395,"> yes. everything is fine. **_./deepspeech-0.6.0-checkpoint_** in this folder pretrained checkpoints already present.

You don't clearly answer. What is the content of `./deepspeech-0.6.0-checkpoint/` ?",yes everything fine folder already present clearly answer content,issue,positive,positive,positive,positive,positive,positive
562503666,"yes. everything is fine. **_./deepspeech-0.6.0-checkpoint_**  in this folder pretrained checkpoints already present. 

but it is showing 

> ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory ./deepspeech-0.6.0-checkpoint",yes everything fine folder already present showing could find file given directory,issue,positive,positive,positive,positive,positive,positive
562502848,"> ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory ./deepspeech-0.6.0-checkpoint

Well, have you checked what the error states ?",could find file given directory well checked error,issue,negative,neutral,neutral,neutral,neutral,neutral
562502512,"@lissyx  sir, i added both **--checkpoint_dir  and  --cudnn_checkpoint** both.

`CUDA_VISIBLE_DEVICES=2 python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir ./deepspeech-0.6.0-checkpoint --cudnn_checkpoint ./deepspeech-0.6.0-checkpoint --epochs 3 --train_files ./data/csv_files/train.csv --dev_files ./data/csv_files/dev.csv --test_files ./data/csv_files/test.csv --learning_rate 0.0001`

same error :)
```

I Converting CuDNN RNN checkpoint from ./deepspeech-0.6.0-checkpoint
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 965, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 938, in main
    train()
  File ""DeepSpeech.py"", line 525, in train
    ckpt = tfv1.train.load_checkpoint(FLAGS.cudnn_checkpoint)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 65, in load_checkpoint
    ""given directory %s"" % ckpt_dir_or_file)
ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory ./deepspeech-0.6.0-checkpoint


```",sir added python error converting recent call last file line module main file line run main file line main file line main train file line train file line given directory could find file given directory,issue,negative,positive,positive,positive,positive,positive
562500568,"> ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory ./deepspeech-0.6.0-checkpoint

Are you sure about the path ? How about `--checkpoint_dir` as well ?",could find file given directory sure path well,issue,positive,positive,positive,positive,positive,positive
562500240,"@lissyx sir, i think, you are mentioned this flag.
```
--cudnn_checkpoint: path to a checkpoint created using --use_cudnn_rnn.
    Specifying this flag allows one to convert a CuDNN RNN checkpoint to a
    checkpoint capable of running on a CPU graph.
    (default: '')
```
command:
`
CUDA_VISIBLE_DEVICES=2 python3 DeepSpeech.py --n_hidden 2048 --cudnn_checkpoint ./deepspeech-0.6.0-checkpoint --epochs 3 --train_files ./data/csv_files/train.csv --dev_files ./data/csv_files/dev.csv --test_files ./data/csv_files/test.csv --learning_rate 0.0001`

```
I Converting CuDNN RNN checkpoint from ./deepspeech-0.6.0-checkpoint
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 965, in <module>
    absl.app.run(main)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 938, in main
    train()
  File ""DeepSpeech.py"", line 525, in train
    ckpt = tfv1.train.load_checkpoint(FLAGS.cudnn_checkpoint)
  File ""/media/user1/storage-1/Murugan/DeepSpeech/env/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py"", line 65, in load_checkpoint
    ""given directory %s"" % ckpt_dir_or_file)
ValueError: Couldn't find 'checkpoint' file or checkpoints in given directory ./deepspeech-0.6.0-checkpoint
```
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130

NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1

NVIDIA TITAN RTX
```
@lissyx  sir. what is problem for v0.6.0 pretrained checkpoint files?
in my side i made any mistakes?

",sir think flag path flag one convert capable running graph default command python converting recent call last file line module main file line run main file line main file line main train file line train file line given directory could find file given directory compiler driver copyright corporation built compilation release driver version version sir problem side made,issue,negative,positive,positive,positive,positive,positive
562487808,"Weird. I remember this error when loading a cudnn checkpoint on a non cudnn setup, can you check that? I' the release notes we also document the flag to use in that case, can you test with it? ",weird remember error loading non setup check release also document flag use case test,issue,negative,negative,negative,negative,negative,negative
562469738,"```
Package              Version     
-------------------- ------------
absl-py              0.8.1       
astor                0.8.0       
attrdict             2.0.1       
audioread            2.1.8       
bcrypt               3.1.7       
beautifulsoup4       4.8.1       
bs4                  0.0.1       
certifi              2019.11.28  
cffi                 1.13.2      
chardet              3.0.4       
cryptography         2.8         
cycler               0.10.0      
decorator            4.4.1       
ds-ctcdecoder        0.6.0       
gast                 0.3.2       
google-pasta         0.1.8       
grpcio               1.25.0      
h5py                 2.10.0      
idna                 2.8         
joblib               0.14.0      
Keras-Applications   1.0.8       
Keras-Preprocessing  1.1.0       
kiwisolver           1.1.0       
librosa              0.7.1       
llvmlite             0.30.0      
Markdown             3.1.1       
matplotlib           3.1.2       
numba                0.46.0      
numpy                1.15.4      
pandas               0.25.3      
paramiko             2.7.0       
pip                  19.3.1      
pkg-resources        0.0.0       
progressbar2         3.47.0      
protobuf             3.11.1      
pycparser            2.19        
PyNaCl               1.3.0       
pyparsing            2.4.5       
python-dateutil      2.8.1       
python-utils         2.3.0       
pytz                 2019.3      
pyxdg                0.26        
requests             2.22.0      
resampy              0.2.2       
scikit-learn         0.22        
scipy                1.3.3       
setuptools           42.0.2      
six                  1.13.0      
SoundFile            0.10.3.post1
soupsieve            1.9.5       
sox                  1.3.7       
tensorboard          1.14.0      
tensorflow-estimator 1.14.0      
tensorflow-gpu       1.14.0      
termcolor            1.1.0       
urllib3              1.25.7      
webrtcvad            2.0.10      
Werkzeug             0.16.0      
wheel                0.33.6      
wrapt                1.11.2      
```",package version astor cryptography cycler decorator gast markdown pip six post wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
562467373,@MuruganR96 Can you share `pip list` output ?,share pip list output,issue,negative,neutral,neutral,neutral,neutral,neutral
562464899,"> `https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/` says that it's been tested on the raspberry pi 4. Does my microphone need to support a specific sample rate?

I never played with this example on RPi4. It's not impossible some hardware have different behavior regarding sample rate of microphone.

What was tested is that we are able to perform real-time inference, using C++ client and well as other bindings, that takes existing WAV files.",tested raspberry pi microphone need support specific sample rate never example impossible hardware different behavior regarding sample rate microphone tested able perform inference client well,issue,positive,negative,neutral,neutral,negative,negative
562436273,"I changed my internet connection and used this.

 wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz

The model has been downloaded. Thank you.",connection used model thank,issue,negative,neutral,neutral,neutral,neutral,neutral
562344280,``https://hacks.mozilla.org/2019/12/deepspeech-0-6-mozillas-speech-to-text-engine/`` says that it's been tested on the raspberry pi 4. Does my microphone need to support a specific sample rate?,tested raspberry pi microphone need support specific sample rate,issue,negative,neutral,neutral,neutral,neutral,neutral
562162188,"> I assume you're referring to the microphone and not the raspberry pi?

Maybe, I don't know your setup. ",assume microphone raspberry pi maybe know setup,issue,negative,neutral,neutral,neutral,neutral,neutral
562155581,"Semver is fine with it: https://semver.org/#spec-item-10

But PEP-440 isn't :( https://www.python.org/dev/peps/pep-0440/#local-version-identifiers

I thought PyTorch was doing this, but they have their own package index page, they don't use PyPI  :(",fine thought package index page use,issue,negative,positive,positive,positive,positive,positive
562152916,"I assume you're referring to the microphone and not the raspberry pi?
 ",assume microphone raspberry pi,issue,negative,neutral,neutral,neutral,neutral,neutral
562048019,"> > I am trying to run the pre-trained model for English on Ubuntu 18.0.4
> > I installed it using
> > pip install deepspeech
> > (Version 0.6.0 was installed)
> > then when i use the given commands for pretrained model, it has been stuck for more than three hours
> > (base) kapilg1997@DESKTOP-BAUSO2O:~$ conda activate ds_venv (ds_venv) kapilg1997@DESKTOP-BAUSO2O:~$ curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz
> > It is stuck here. Please help.
> 
> It's hard to help you without more context. What's your internet access? Model is quite big, it might just be slow ?

I have changed my internet connection and I'm trying again.",trying run model pip install version use given model stuck three base activate curl stuck please help hard help without context access model quite big might slow connection trying,issue,positive,negative,negative,negative,negative,negative
562014589,"> I am trying to run the pre-trained model for English on Ubuntu 18.0.4
> I installed it using
> pip install deepspeech
> (Version 0.6.0 was installed)
> then when i use the given commands for pretrained model, it has been stuck for more than three hours
> 
> (base) kapilg1997@DESKTOP-BAUSO2O:~$ conda activate ds_venv (ds_venv) kapilg1997@DESKTOP-BAUSO2O:~$ curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz
> 
> It is stuck here. Please help.

It's hard to help you without more context. What's your internet access? Model is quite big, it might just be slow ?",trying run model pip install version use given model stuck three base activate curl stuck please help hard help without context access model quite big might slow,issue,positive,negative,negative,negative,negative,negative
562002780,"No you don't. Ensure your `pip install deepspeech`, did install v0.6.0.",ensure pip install install,issue,negative,neutral,neutral,neutral,neutral,neutral
561999975,"> Thanks but the doc is right, the argument is not needed anymore.

yes, that is valid if you clone this repo and run the code but if you `pip install deepspeech` then you have to add --alphabet argument in order to run the code successfully. ",thanks doc right argument yes valid clone run code pip install add alphabet argument order run code successfully,issue,positive,positive,positive,positive,positive,positive
561997967,"> I tried running the `mic_vad_streaming` example on my raspberry pi and was met with the following error:
> 
> Output: https://gist.github.com/Technerder/4c95fcbe24911965e276eeea46d68cf8
> Code: https://github.com/mozilla/DeepSpeech/blob/master/examples/mic_vad_streaming/mic_vad_streaming.py
> Command: `python3 mic_vad_streaming.py -m models/output_graph.tflite -l models/lm.binary`
> 
> OS: `Raspbian GNU/Linux 10 (buster) armv7l (Raspberry pi 4)`
> TensorFlow: `v1.14.0-21-ge77504a`
> DeepSpeech: `v0.6.0-0-g6d43e21`
> Python: `3.7.3`
> 
> How can I fix this?

It looks like your hardware does not like the sample rate, sorry. ",tried running example raspberry pi met following error output code command python o buster raspberry pi python fix like hardware like sample rate sorry,issue,negative,negative,negative,negative,negative,negative
561997458,"Thanks but the doc is right, the argument is not needed anymore. ",thanks doc right argument,issue,negative,positive,positive,positive,positive,positive
561805438,"@tilmankamp -- I've put the `.catalog` functionality back into my branch, and rebased new commits from master.

can you check the logic of the `*.catalog` function? I didn't test for that, but I bet you have a catalog file somewhere you can test on",put functionality back branch new master check logic function test bet file somewhere test,issue,negative,positive,neutral,neutral,positive,positive
561772777,"Well, ideally I still want to build the master example when someone makes a PR here on the DeepSpeech repo. I have a simple fix for that, but trying to figure out how to handle the documentation first before I push.",well ideally still want build master example someone simple fix trying figure handle documentation first push,issue,positive,positive,positive,positive,positive,positive
561736548,"@reuben  As we are moving the WPF dependency to NuGet you will need to remove https://github.com/mozilla/DeepSpeech/blob/d79166514a87d6c86f654402ddeed5f93cc592b3/taskcluster/tc-tests-utils.sh#L933 

",moving dependency need remove,issue,negative,neutral,neutral,neutral,neutral,neutral
561726500,Figuring out the inclusion and packaging of the examples into the documentation is going to be more tricky.,inclusion documentation going tricky,issue,negative,neutral,neutral,neutral,neutral,neutral
561705871,"The API documentation isn't enough because there's a lot more involved to get even basic simple example working - it involves AudioContext buffers, a Node VAD library, and starting and stopping a stream.  What would be useful is a fully working example of feedAudioContent() and intermediateDecode().

Unfortunately none of those python or ffmpeg examples can be used in Electron -- eg. I don't want to compile and load and distribute ffmpeg and python inside an Electron app.
",documentation enough lot involved get even basic simple example working node library starting stopping stream would useful fully working example unfortunately none python used electron want compile load distribute python inside electron,issue,negative,negative,neutral,neutral,negative,negative
561676421,"> There isn't an example of how to do streaming in NodeJS though only the [wav example](https://github.com/mozilla/DeepSpeech/tree/v0.6.0/examples/nodejs_wav). I see there is a python streaming example [here](https://github.com/mozilla/DeepSpeech/tree/v0.6.0/examples/mic_vad_streaming):

Isn't it this one? https://github.com/mozilla/DeepSpeech/blob/v0.6.0/examples/ffmpeg_vad_streaming/index.js",example streaming though example see python streaming example one,issue,negative,neutral,neutral,neutral,neutral,neutral
561670891,"> So am I correct, you can't feed a stream of WAV data in and continuously have a stream of recognition results out? You have to segment up the stream using VAD and process each chunk separately?

https://deepspeech.readthedocs.io/en/v0.6.0/NodeJS-API.html#Model.feedAudioContent
https://deepspeech.readthedocs.io/en/v0.6.0/NodeJS-API.html#Model.intermediateDecode

I'm not sure what else you need ?",correct ca feed stream data continuously stream recognition segment stream process chunk separately sure else need,issue,negative,positive,positive,positive,positive,positive
561670425,"ok great, thanks, I raised a tiny PR to update the README instructions of the node example https://github.com/mozilla/DeepSpeech/pull/2571 ",great thanks raised tiny update node example,issue,positive,positive,positive,positive,positive,positive
561669148,"There isn't an example of how to do streaming in NodeJS though only the [wav example](https://github.com/mozilla/DeepSpeech/tree/v0.6.0/examples/nodejs_wav).  I see there is a python streaming example [here](https://github.com/mozilla/DeepSpeech/tree/v0.6.0/examples/mic_vad_streaming):

```
model.feedAudioContent(stream_context, np.frombuffer(frame, np.int16))
```

It looks like the WAV data isn't actually processed until the stream has closed:

```
  text = model.finishStream(stream_context)
```

So am I correct, you can't feed a stream of WAV data in and continuously have a stream of recognition results out?  You have to segment up the stream using VAD and process each chunk separately?",example streaming though example see python streaming example frame like data actually stream closed text correct ca feed stream data continuously stream recognition segment stream process chunk separately,issue,negative,negative,neutral,neutral,negative,negative
561668487,"> ```
> 
> ```
> 
> 
> but still get error message/warning
> 
> > 2019-12-04 14:21:32.541988: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA

Yeha, it's not a big deal, it just says you don't make full use of your CPU ...



> Do you also know if there's a way to get word level timings via the node module?

Have you had a look at the API's documentation ? https://deepspeech.readthedocs.io/en/v0.6.0/NodeJS-API.html#Model.finishStreamWithMetadata

Anyway, there's no bug, please take further discussion to Discourse instead.",still get error binary use big deal make full use also know way get word level via node module look documentation anyway bug please take discussion discourse instead,issue,negative,positive,positive,positive,positive,positive
561667700,"Thanks, it works after updating to the latest models 
```
$ node index.js audio/4507-16021-0012.wav
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.0-0-g6d43e21
2019-12-04 14:21:32.541988: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
audio length 2.735
result: why should one halt on the way
```

but still get error message/warning

>2019-12-04 14:21:32.541988: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA

Do you also know if there's a way to get word level timings via the node module?
",thanks work latest node binary use audio length result one halt way still get error binary use also know way get word level via node module,issue,negative,positive,positive,positive,positive,positive
561657598,"> I followed these instructions for [NodeJS voice recognition example using Mozilla DeepSpeech](https://github.com/mozilla/DeepSpeech/tree/master/examples/nodejs_wav) on Mac OSX but I got the following error
> 
> ```shell
> $ node index.js
> TensorFlow: v1.14.0-21-ge77504ac6b
> DeepSpeech: v0.6.0-0-g6d43e21
> 2019-12-04 12:08:18.846222: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> Unable to fetch graph version: Invalid argument: Session was not created with a graph before Run()!
> 
> /Users/passarellip/CODE/PERSONAL/deepspeech-test/node_modules/deepspeech/index.js:39
>         throw ""CreateModel failed with error code "" + status;
>         ^
> CreateModel failed with error code 8195
> ```
> 
> Am I missing some steps? or does the node module only work with Linux?

That codes expects a `output_graph.pbmm` in the `models/` directory, as well as LM files: https://github.com/mozilla/DeepSpeech/blob/master/examples/nodejs_wav/index.js#L8-L18

Also, it seems the README was not updated and it still refers to v0.4.1 models. Have you downloaded v0.6.0 models or v0.4.1 ?

Your error code 0x2003: https://deepspeech.readthedocs.io/en/v0.6.0/Error-Codes.html#_CPPv425DS_ERR_MODEL_INCOMPATIBLE",voice recognition example mac got following error shell node binary use unable fetch graph version invalid argument session graph run throw error code status error code missing node module work directory well also still error code,issue,negative,negative,negative,negative,negative,negative
561655865,"DeepSpeech has had partial streaming support since v0.2.0 and full streaming support (including the decoder) since v0.5.0. I recommend trying out the latest v0.6.0 model, just released yesterday. And yes, you should be able to just do `npm install`. We have docs here: https://github.com/mozilla/DeepSpeech/blob/v0.6.0/USING.rst#using-a-pre-trained-model

And here: https://deepspeech.readthedocs.io/en/v0.6.0/NodeJS-API.html

And examples here: https://github.com/mozilla/DeepSpeech/tree/v0.6.0/examples/

Examples aren't currently updated to v0.6.0 but they should work by just changing the required version, as they were updated to the last few alpha builds.

In the future, please keep the GitHub issue tracker for bugs or feature requests. For discussion we have a [Discourse forum](https://discourse.mozilla.org/c/deep-speech).",partial streaming support since full streaming support since recommend trying latest model yesterday yes able install currently work version last alpha future please keep issue tracker feature discussion discourse forum,issue,positive,positive,positive,positive,positive,positive
561645077,"Yeah DeepSpeech 0.5 works with Electron 5.1, and I've got it working in my main project [here](https://github.com/jaxcore/jaxcore-desktop-server) which is the electron desktop voice control app.

Getting DeepSpeech working in Electron is the same as any other NPM library, npm install, import and download the deepspeech models, and see the [node_wav example](https://github.com/mozilla/DeepSpeech/tree/master/examples/nodejs_wav).  The two biggest challenges I had was to make DeepSpeech into a live microphone voice control system.  These problems probably won't matter for you if you're just doing speech-to-text, they aren't Electron specific but might be of interest:

1) DeepSpeech doesn't have a built-in microphone recording

2) doesn't have a continuous/stream transcription mode to continuously be recognizing speech (or at least not in the previous versions)

So I had to write my own microphone -> DeepSpeech library, and use a VAD library (voice activity detection) to automatically turn DeepSpeech on and off.  I wrote a separate [speech library](https://github.com/jaxcore/jaxcore-speech) that handles those 2 problems, and another one for Alexa-style [hotword commands](https://github.com/jaxcore/bumblebee-hotword).

Another issue is processing speed.  On my macbook pro DeepSpeech takes the same amount of time to process the speech as the length of the recording (eg. 5 seconds of speech takes about 5 seconds to process).  So in the VAD part of my recording library I cut off the length of the microphone recording to 15 seconds to prevent recording too long of a clip.

The result is I can speak for a few seconds, and then have to wait for that clip to be processed before saying the next sentence.  It's a limitation I was able to live with for now because the kinds of things I wanted to do the most was Star Trek style voice commands, short commands like ""launch game"", ""move up/down"", ""lights on"".  But it might not be suitable right now for long duration dictation, like translating an entire paragraph.  ",yeah work electron got working main project electron voice control getting working electron library install import see example two biggest make live microphone voice control system probably wo matter electron specific might interest microphone recording transcription mode continuously speech least previous write microphone library use library voice activity detection automatically turn wrote separate speech library another one another issue speed pro amount time process speech length recording speech process part recording library cut length microphone recording prevent recording long clip result speak wait clip saying next sentence limitation able live star trek style voice short like launch game move might suitable right long duration dictation like entire paragraph,issue,positive,positive,neutral,neutral,positive,positive
561575914,No longer applicable with new feeding pipeline.,longer applicable new feeding pipeline,issue,negative,positive,positive,positive,positive,positive
561575797,I think this is fixed. Feel free to reopen if not.,think fixed feel free reopen,issue,positive,positive,positive,positive,positive,positive
561574925,"This was fixed at some point. Now if you don't specify train set, no training will be done. Same idea for dev and test sets.",fixed point specify train set training done idea dev test,issue,negative,positive,neutral,neutral,positive,positive
561573970,"`util/check_characters.py` helps with character set consistency, and we now embed the alphabet and other parameters directly in the model, which reduces surface for errors. If you use `util/check_characters.py` to generate alphabet.txt, everything should be consistent. I think this can be considered fixed.",character set consistency embed alphabet directly model surface use generate everything consistent think considered fixed,issue,negative,positive,positive,positive,positive,positive
561572663,No longer applicable with new feeding pipeline. (We now drop the last batch explicitly :P),longer applicable new feeding pipeline drop last batch explicitly,issue,negative,positive,neutral,neutral,positive,positive
561571377,"I'm not sure there's value in keeping this issue open. There's nothing actionable, as Kelly said, we support it already, all you need is the labelled data. If people are interested in experimenting and discussing this approach, please open a thread on [Discourse](https://discourse.mozilla.org/c/deep-speech)",sure value keeping issue open nothing actionable kelly said support already need data people interested approach please open thread discourse,issue,positive,positive,positive,positive,positive,positive
561571033,You could start by running a phonemizer on an existing dataset and training with that. See for example espeak-ng.,could start running training see example,issue,negative,neutral,neutral,neutral,neutral,neutral
561569808,Works for me. (Maybe fixed by the switch to absl-py?),work maybe fixed switch,issue,negative,positive,neutral,neutral,positive,positive
561562784,This is due to the large alphabet you're using. The UTF-8 mode recently introduced should be able to handle this. For Mandarin I recommend using cutoff_prob=0.99 as well to speed up decoding. In the near future I'll write some docs for UTF-8 based training.,due large alphabet mode recently able handle mandarin recommend well speed near future write based training,issue,positive,positive,positive,positive,positive,positive
561559627,Added a reminder about reading the documentation for the version installed.,added reminder reading documentation version,issue,negative,neutral,neutral,neutral,neutral,neutral
561558323,"Also you can't just remove support for the catalog input, it's there for a reason, it's the output of the DSAlign tool.",also ca remove support input reason output tool,issue,negative,neutral,neutral,neutral,neutral,neutral
561507278,"I'd guess that it's simply the documentation for the src parameter that is incorrect, not the code.",guess simply documentation parameter incorrect code,issue,negative,neutral,neutral,neutral,neutral,neutral
561464463,"Sorry, I didn't test the accuracy improvement on large data, my hardware don't allow me to do such 
 huge experiment.

But, I've checked the code in `spectrogram_augmentations.py` for a long time, here is one thing I want to confirm, I notice the other augment functions consider the spectrogram shape as [`Batch`, `Frequency`, `Time`], but when I print the tensor in runtime, the shape was always (1, ?, 257) => the `?` should be dynamic time axis?
Maybe that is why every augment in #2284 had no apparent improvement, or somehow I misunderstood something.
And that's what I mentioned before, I don't know what did I augment out without a visualization function while developing.",sorry test accuracy improvement large data hardware allow huge experiment checked code long time one thing want confirm notice augment consider spectrogram shape batch frequency time print tensor shape always dynamic time axis maybe every augment apparent improvement somehow misunderstood something know augment without visualization function,issue,positive,positive,neutral,neutral,positive,positive
561263737,Let's just unblock 0.6 and figure out the examples problem after that.,let unblock figure problem,issue,negative,neutral,neutral,neutral,neutral,neutral
561247955,The package does not use the checked in README.rst file: https://community-tc.services.mozilla.com/api/queue/v1/task/X2Pzmzu8RGGKezVR187ITw/runs/0/artifacts/public/deepspeech-0.6.0.tgz,package use checked file,issue,negative,neutral,neutral,neutral,neutral,neutral
561233517,Which means that someone browsing the v0.6.0 tag will see the example code pointing to alpha versions. But I don't know another way around that :/,someone browsing tag see example code pointing alpha know another way around,issue,negative,neutral,neutral,neutral,neutral,neutral
561233203,"> Shouldn't we also change all the examples/ deps to stick to v0.6.0 now ?

We can only do that after 0.6.0 is actually published, because otherwise the example task is going to fail.",also change stick actually otherwise example task going fail,issue,negative,negative,negative,negative,negative,negative
561229761,"Is that actually used? I thought it was just included by accident, I guess I'm remembering incorrectly from our chat on IRC. The Makefile overwrites the file with the one from the root directory on build...",actually used thought included accident guess incorrectly chat file one root directory build,issue,negative,neutral,neutral,neutral,neutral,neutral
561172534,"`sparse_image_warp` was originally included in the SpecAugment PR, but [was removed](https://github.com/mozilla/DeepSpeech/pull/2352) because it increased training time drastically without correspondingly drastic improvements in the model. Did you benchmark your implementation for performance and/or model accuracy?",originally included removed training time drastically without correspondingly drastic model implementation performance model accuracy,issue,negative,positive,positive,positive,positive,positive
561082234,"@mychiux413 Thanks for that, it looks like you started this on older code, can you rebase on current master ?",thanks like older code rebase current master,issue,positive,positive,positive,positive,positive,positive
560390582,@reuben I addressed review comments. Could you take another look?,review could take another look,issue,negative,neutral,neutral,neutral,neutral,neutral
560287942,"0.6.0 will be out soon enough, within the week, that backporting 3.8 support is not going to be an efficient use of our time.",soon enough within week support going efficient use time,issue,positive,neutral,neutral,neutral,neutral,neutral
559875580,"`transfer-learning` is not maintained, I think you need to use `transfer-learning2`. Maybe @JRMeyer can give more insight, but it's Thanks Giving, so I doubt you can get feedback from him before next monday.",think need use maybe give insight thanks giving doubt get feedback next,issue,negative,positive,neutral,neutral,positive,positive
559689744,All green modulo some macOS pip weirdness.,green modulo pip weirdness,issue,negative,negative,negative,negative,negative,negative
558783650,"You're looking at the docs for master, but are running an older client. You should look at the docs for the version you're running. For v0.5.1, that's https://github.com/mozilla/DeepSpeech/tree/v0.5.1",looking master running older client look version running,issue,negative,positive,positive,positive,positive,positive
558526416,"> > prior to this change, the .Net bindings would not be on-part with the rest of the bindings
> 
> You are correct, sorry :/

Well that's fine, I've lost the big picture, not being judgmental here.",prior change would rest correct sorry well fine lost big picture,issue,negative,negative,neutral,neutral,negative,negative
558526220,@kapilg1997 We don't have Python bindings for Windows on 0.5.1. That's why you got 0.6 binaries. Please wait until we release 0.6 models.,python got please wait release,issue,negative,neutral,neutral,neutral,neutral,neutral
558518421,"> prior to this change, the .Net bindings would not be on-part with the rest of the bindings

You are correct, sorry :/ ",prior change would rest correct sorry,issue,negative,negative,negative,negative,negative,negative
558504933,"> # Download pre-trained English model and extract
> 
> curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
> tar xvf deepspeech-0.5.1-models.tar.gz
> # Download example audio files
> 
> curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz
> tar xvf audio-0.5.1.tar.gz
> # Transcribe an audio file
> 
> deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav
> 
> Following error occurs
> 
> ![Capture](https://user-images.githubusercontent.com/51714717/69601174-51d03000-1039-11ea-8f91-3bcd77a23ed1.JPG)

You are running mismatching versions. Please avoid posting screenshots, it is hard to read and not searchable for content.

Please use deepspeech 0.5.1 binary to run 0.5.1 models.

This is not a bug, so please take this to Discourse.",model extract curl tar example audio curl tar transcribe audio file model audio following error capture running please avoid posting hard read searchable content please use binary run bug please take discourse,issue,negative,negative,negative,negative,negative,negative
558494342,Anaconda is not supported. Could you try using a virtual environment as documented [here](https://github.com/mozilla/DeepSpeech/tree/v0.5.1#create-a-deepspeech-virtual-environment).,anaconda could try virtual environment,issue,negative,neutral,neutral,neutral,neutral,neutral
558463040,"# Download pre-trained English model and extract
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
tar xvf deepspeech-0.5.1-models.tar.gz

# Download example audio files
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz
tar xvf audio-0.5.1.tar.gz

# Transcribe an audio file
deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav 

Following error occurs

![Capture](https://user-images.githubusercontent.com/51714717/69601174-51d03000-1039-11ea-8f91-3bcd77a23ed1.JPG)
",model extract curl tar example audio curl tar transcribe audio file model audio following error capture,issue,negative,neutral,neutral,neutral,neutral,neutral
558130687,"@carlfm01 Forgive my naive question, but does this means prior to this change, the .Net bindings would not be on-part with the rest of the bindings to run multiple concurrent streams ?",forgive naive question prior change would rest run multiple concurrent,issue,negative,negative,neutral,neutral,negative,negative
558124920,"> cuda version: we installed cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb,
> but it shows as 10.2

Well, I'm sorry but you already diagnosed your issue, and this is obviously not a bug. Please use discourse for support.

Also, you don't share every repro step, so we cannot help you anyway.",version well sorry already issue obviously bug please use discourse support also share every step help anyway,issue,positive,negative,negative,negative,negative,negative
557911033,"> I tried downgrading Electron to 7.0.1 but it still wants to bind against a non-existent v7.1:
> /node_modules/deepspeech/lib/binding/v0.6.0-alpha.15/darwin-x64/electron-v7.1/deepspeech.node

Ok, I thought, since it seems 7.1 and 7.0 are compatible, that loading from 7.1 would try also 7.0 directory.",tried electron still bind thought since compatible loading would try also directory,issue,negative,neutral,neutral,neutral,neutral,neutral
557896995,"I tried downgrading Electron to 7.0.1 but it still wants to bind against a non-existent v7.1:
/node_modules/deepspeech/lib/binding/v0.6.0-alpha.15/darwin-x64/electron-v7.1/deepspeech.node
It's not a big problem for right now because I can use Electron 5 and Deepspeech 5 which do work together.
",tried electron still bind big problem right use electron work together,issue,negative,positive,positive,positive,positive,positive
557894729,"> Great, thanks for adding this! I don't mind waiting until the official deepspeech 6.0 release.

In the meantime, can you check if 7.0 works for runtime 7.1? ",great thanks mind waiting official release check work,issue,positive,positive,positive,positive,positive,positive
557891183,"Great, thanks for adding this! I don't mind waiting until the official deepspeech 6.0 release.",great thanks mind waiting official release,issue,positive,positive,positive,positive,positive,positive
557885441,"@dsteinman From the release pages, it seems `v7.1` should work with the current `v0.6.0a15` package, since they mention this is a release bump for new feature, but still a minor release.",release work current package since mention release bump new feature still minor release,issue,negative,positive,neutral,neutral,positive,positive
557885291,"> Would be it be easy to add this new Electron version to the prebuilt binaries? (v7.1.2 came out just 4 days ago)

It's pretty easy, depending on how much changed in ElectronJS.

We have support for v7.0 in current `v0.6.0a15`. It's more and more painful because of lack of official SWIG NodeJS / V8 newer versions support.


> I'm back to work on my voice control idea and have upgraded yet again to the latest Electron and so I'm experiencing the same issue, there's no ""electron-v7.1"" build in the /deepspeech/lib/binding/v0.5.1/darwin-x64 directory and it's not very clear how to build my own.

You can read `do_deepspeech_nodejs_build` in  `taskcluster/tc-tests-utils.sh`, basically it's just what we document as JavaScript bindings with a few environment variables tweaked.",would easy add new electron version came day ago pretty easy depending much support current painful lack official swig support back work voice control idea yet latest electron issue build directory clear build read basically document environment,issue,positive,positive,positive,positive,positive,positive
557772687,"The readme instructions seem to be about the development version `deepspeech`,  not `deepspeech 0.5.1`, which is normal since the master branch seems to be the development branch. That needs to be clarified in the readme.

`deepspeech 0.5.1`, the version currently installed by `pip` needs an `--alphabet` argument, but the readme instructions removed it.",seem development version normal since master branch development branch need version currently pip need alphabet argument removed,issue,negative,positive,neutral,neutral,positive,positive
557513445,"> I am using Deepspeech library for converting Speech to Text by using custom 16-bit, 16 kHz, mono-channel WAVE audio files. But text is no where related to speech.
> Could you please suggest how I can get expected text output from speech?

Could you please read the issue template and ask that on Discourse ?",library converting speech text custom wave audio text related speech could please suggest get text output speech could please read issue template ask discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
557497269,How to use it if you can give an example. as input wav file? ,use give example input file,issue,negative,neutral,neutral,neutral,neutral,neutral
557496523,"I think that Speaker Diarization would be the most useful here as it does not require any training data. The X-Vector model is one of the most powerful implementations, see the [Kaldi model](https://kaldi-asr.org/models/m6)",think speaker would useful require training data model one powerful see model,issue,positive,positive,positive,positive,positive,positive
557232979,"> Sorry for the confusion, we are not, I was thinking in hypotheticals here. To sum up what I'm saying, shouldn't the normalization across scripts in DeepSpeech be consistent, regardless of which is chosen?

That's why i've implemented this flag for checking. Because ultimately, we don't want to enforce. And the importers here can be used alone, mixed with others we don't know about, so I think it's better we don't try to be smart here, because that would just lead to more complexity.",sorry confusion thinking sum saying normalization across consistent regardless chosen flag ultimately want enforce used alone mixed know think better try smart would lead complexity,issue,negative,positive,neutral,neutral,positive,positive
557232841,"`import_cv2.py` only does NFKD normalization immediately followed by a call to `.encode('ascii', 'ignore')`, which serves as a simple way to eliminate some common diacritics. (And that behavior is behind a flag). It doesn't do NFKD alone, that would break any non-English language.",normalization immediately call simple way eliminate common behavior behind flag alone would break language,issue,negative,negative,negative,negative,negative,negative
557231831,"> Could you please be explicit on the language you imported ? I missed the fact that we were talking 
> about Common Voice.

Sorry for the confusion, we are not, I was thinking in hypotheticals here. To sum up what I'm saying, shouldn't the normalization across scripts in DeepSpeech be consistent, regardless of which is chosen?

> Yeah, but if we have released Common Voice that exposes the behavior, it's another story.

As far as I know, you have not. I am working with a Komi dataset I obtained from a colleague, which I unfortunately cannot share at this time. ",could please explicit language fact talking common voice sorry confusion thinking sum saying normalization across consistent regardless chosen yeah common voice behavior another story far know working colleague unfortunately share time,issue,negative,negative,negative,negative,negative,negative
557227842,"> Right, so if someone follows the workflow import_cv2.py --> check_characters.py like I did (and I think that's the recommended for commonvoice data, right?) they'll run into issues because they use NFKD and NFKC respectively by default.

Could you please be explicit on the language you imported ? I missed the fact that we were talking about Common Voice.

> That's fair, and if someone is using a custom dataset like I am they should probably know enough to figure it out.

Yeah, but if we have **released** Common Voice that exposes the behavior, it's another story.

We had to fix that on some not-yet-released part of Common Voice French, and it's already quite a mess.",right someone like think data right run use respectively default could please explicit language fact talking common voice fair someone custom like probably know enough figure yeah common voice behavior another story fix part common voice already quite mess,issue,positive,positive,neutral,neutral,positive,positive
557226042,"> Ok, so it's at least consistent with our experience :)

Yep! Very edge case problem.

> This should allow you to move forward, right?

I had already moved forward by just manually editing the alphabet file.

> Technically, NFKD or NFKC we don't care, but what it more important is that all your datasets are 
> sharing the same normalization. Otherwise you risk having two different unicode characters for the 
> same ""user-visible"" character. This will obviously impact quality.

Right, so if someone follows the workflow import_cv2.py --> check_characters.py like I did (and I think that's the recommended for commonvoice data, right?) they'll run into issues because they use NFKD and NFKC respectively by default.

> We had discussions about that, but it's not really clear we would like to enforce such a thing.

That's fair, and if someone is using a custom dataset like I am they should probably know enough to figure it out.",least consistent experience yep edge case problem allow move forward right already forward manually alphabet file technically care important normalization otherwise risk two different character obviously impact quality right someone like think data right run use respectively default really clear would like enforce thing fair someone custom like probably know enough figure,issue,positive,positive,positive,positive,positive,positive
557151623,"Is this simply taking the individual rare word cases out of the text or does it remove the sentence featuring that rare word?

I'm thinking the former would result in ungrammatical sentences, having a slight negative impact on the LM.

Purely on a hunch, it also seems plausible that such sentences may be less modern or largely gibberish (as @rhamnett mentions here: https://github.com/mozilla/DeepSpeech/pull/2528#issuecomment-553500642 )",simply taking individual rare word text remove sentence rare word thinking former would result ungrammatical slight negative impact purely hunch also plausible may le modern largely gibberish,issue,negative,positive,positive,positive,positive,positive
556977812,"> I'm working in the Cyrillic alphabet space, and all the other characters worked fine, and as you mentioned above the problem characters I shared are the two-codepoint variants.

Ok, so it's at least consistent with our experience :)



> I ran check_characters on my dataset again with the new tag and it did flag a problem sentence, so based on the change you made, my data isn't in a normalized format.

This should allow you to move forward, right ?



> I have been using a modified version of import_cv2.py (my audio is already in wav files), but I hadn't been using the normalize flag. I did modify it further because it normalizes to NFKD by default. That may cause an issue to others in the future, having import_cv2.py normalize to NFKD and check_characters test for NFKC.

Technically, NFKD or NFKC we don't care, but what it more important is that all your datasets are sharing the same normalization. Otherwise you risk having two different unicode characters for the same ""user-visible"" character. This will obviously impact quality.



> If I could offer one suggestion, I would add ""when generating your csv files"" to the end of ""Consider using NFKC normalization: unicodedata.normalize('NFKC', str).""

We had discussions about that, but it's not really clear we would like to enforce such a thing.",working alphabet space worked fine problem least consistent experience ran new tag flag problem sentence based change made data format allow move forward right version audio already normalize flag modify default may cause issue future normalize test technically care important normalization otherwise risk two different character obviously impact quality could offer one suggestion would add generating end consider normalization really clear would like enforce thing,issue,positive,positive,positive,positive,positive,positive
556976845,"@lissyx So sorry, I got distracted and then forgot to answer.

I'm working in the Cyrillic alphabet space, and all the other characters worked fine, and as you mentioned above the problem characters I shared are the two-codepoint variants. 

In terms of the data itself, it is for research but it is not mine to share. Sorry about that, I know that makes it a bit harder to debug this. 

I ran check_characters on my dataset again with the new tag and it did flag a problem sentence, so based on the change you made, my data isn't in a normalized format. 

I have been using a modified version of import_cv2.py (my audio is already in wav files), but I hadn't been using the normalize flag. I did modify it further because it normalizes to NFKD by default. That may cause an issue to others in the future, having import_cv2.py normalize to NFKD and check_characters test for NFKC. 

**Exact command to reproduce:** python bin/import_cv2.py data/komi_copy/ --normalize

Then I reran check_characters.py and got a slightly different (maybe better? I'll test that when I have time and let you know) alphabet file which normalized the  ̄ to the single codepoint version and captured the ʼ without triggering the error flag. So it seems to be working well, thanks very much for adding that. 

If I could offer one suggestion, I would add ""when generating your csv files"" to the end of ""Consider using NFKC normalization: unicodedata.normalize('NFKC', str).""
",sorry got distracted forgot answer working alphabet space worked fine problem data research mine share sorry know bit harder ran new tag flag problem sentence based change made data format version audio already normalize flag modify default may cause issue future normalize test exact command reproduce python normalize got slightly different maybe better test time let know alphabet file single version without error flag working well thanks much could offer one suggestion would add generating end consider normalization,issue,positive,positive,neutral,neutral,positive,positive
556088704,"@reuben Could  you have a second look (review)? I addressed all your comments, but there are some important changes in `transcribe.py` to prevent memory leaks...",could second look review important prevent memory,issue,negative,positive,positive,positive,positive,positive
555477646,"> Even the start of the readme is wrong. The first usage: # Transcribe an audio file
> deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav needs to include a path to the alphabet: deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --audio audio/8455-210777-0068.wav --alphabet deepspeech-0.5.1-models/alphabet.txt
> Then it works, but still, all the examples core dump.

@MikeyBeez  Can you be more explicit on those examples ?

`pip3 install deepspeech` should install you 0.5.1. Can you check you have that ? `pip3 list | grep deepspeech`",even start wrong first usage transcribe audio file model audio need include path alphabet model audio alphabet work still core dump explicit pip install install check pip list,issue,negative,negative,negative,negative,negative,negative
555360531,Please use the [0.5.1 documentation](https://github.com/mozilla/DeepSpeech/tree/v0.5.1) when using the [0.5.1 models and code](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1) and everything should work as advertised.,please use documentation code everything work,issue,negative,neutral,neutral,neutral,neutral,neutral
555321851,"@reuben amount of silence here is very small .not sure even after removing silence i above issue 
wont be resolved.Probably with Augmentation we have to chop few initial frames of few samples during
training making it robust for ASR.",amount silence small sure even removing silence issue wont augmentation chop initial training making robust,issue,positive,positive,neutral,neutral,positive,positive
554753838,"Last time we were looking into this I verified that webseed requests are tracked normally by GitHub as if it was a ""normal"" download. It can over-count sometimes if a client making several concurrent requests. Of course, if we publish the torrent file itself as part of the release we can also track how many times people are downloading it too.",last time looking tracked normally normal sometimes client making several concurrent course publish torrent file part release also track many time people,issue,negative,positive,positive,positive,positive,positive
554745996,"@lissyx I still worry about the 

> the download statistics are used within Mozilla as a measure of this project's success

issue.",still worry statistic used within measure project success issue,issue,negative,positive,positive,positive,positive,positive
554265509,"@sarasamara7 No feedback, the code is working for us, I'm afraid there's nothing we can do.",feedback code working u afraid nothing,issue,negative,negative,negative,negative,negative,negative
554256317,The current stable version [v0.5.1](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1) does not support python 3.8.0. The latest version of python it supports is 3.7.,current stable version support python latest version python,issue,positive,positive,positive,positive,positive,positive
553972100,"No other reasons other than just providing code example for timestamp extraction from metadata, as many refer client.py as an example to implement it in python code and found many posts on [discourse](https://discourse.mozilla.org/t/native-client-metadata/41199/17) around people asking for timestamp in python",providing code example extraction many refer example implement python code found many discourse around people python,issue,negative,positive,positive,positive,positive,positive
553965476,">  I am new to this so if you feel that it should not be there then it's fine.

Well, there could be legit reasons as to push that, being an example / on-par with the C++ can be a good one. I just want to ensure you are not doing this for other reasons that may be wrong.",new feel fine well could legit push example good one want ensure may wrong,issue,positive,positive,positive,positive,positive,positive
553933725,"Yes you pointed right that it can be another python example. I made changes in client.py looking forward that it might help others to work in getting timestamp info which currently was not there as example for python and many might refer this client.py as an example to use in thier python code.
I am new to this so if you feel that it should not be there then it's fine.",yes pointed right another python example made looking forward might help work getting currently example python many might refer example use python code new feel fine,issue,positive,positive,positive,positive,positive,positive
553927588,So please @aayagar001 can you guide me a bit more into your workflow ? There's no good reason you **need** to do changes to `client.py`.,please guide bit good reason need,issue,positive,positive,positive,positive,positive,positive
553881877,"Well, we could help and use knowledge when people have issues with discourse. But if you just cross post and don't even care to mention that you have an issue with discourse we can't fix it and improve your experience ",well could help use knowledge people discourse cross post even care mention issue discourse ca fix improve experience,issue,positive,neutral,neutral,neutral,neutral,neutral
553848233,"


> @saravananselvamohan Posting the same error everywhere is not going to get your more attention, but it is irritating

I just posted in both Mozilla Community and Github Issue Page bcoz I strucked and I don't know how to proceed forward. Suggestions from you made me to clear that error. Further if it has irrirtated, accept my sorry for that",posting error everywhere going get attention irritating posted community issue page know proceed forward made clear error accept sorry,issue,negative,negative,negative,negative,negative,negative
553789943,"> Yes I wanted to create a python API for subtitle kind of thing so I needed this in python . I used the deepspeech python package programatically in my code with help of client.py and found missing implementation there for timestamp so thought of adding the same. Hope this clarifies.

Sorry, it's still not clear in my mind. Can you explain more your workflow ? How does `client.py` plays a role in your code ?

i'm just worried you are doing something the wrong way in your system, and whether this code should really be in `client.py` or just another Python example.",yes create python subtitle kind thing python used python package code help found missing implementation thought hope sorry still clear mind explain role code worried something wrong way system whether code really another python example,issue,positive,negative,neutral,neutral,negative,negative
553787707,Yes I wanted to create a python API for subtitle kind of thing so I needed this in python . I used the deepspeech python package programatically in my code with help of client.py and found missing implementation there for timestamp so thought of adding the same. Hope this clarifies.,yes create python subtitle kind thing python used python package code help found missing implementation thought hope,issue,positive,positive,positive,positive,positive,positive
553776469,"> Hi @lissyx I tried implementing the code by seeing the c++ code available in client.cc in native client (https://github.com/mozilla/DeepSpeech/blob/master/native_client/client.cc#L293)
> I wanted the time stamp info to be available in python code, metadata info was already available so thought just a post processing similar to c++ code will do.
> Let me know if anything more is needed.

Right, but **why** do you want that information exposed from this tool and as JSON ? Are you doing some processing after in your workflow ?",hi tried code seeing code available native client time stamp available python code already available thought post similar code let know anything right want information exposed tool,issue,negative,positive,positive,positive,positive,positive
553773664,"Hi @lissyx I tried implementing the code by seeing the c++ code available in client.cc in native client (https://github.com/mozilla/DeepSpeech/blob/master/native_client/client.cc#L293)
I wanted the time stamp info to be available in python code, metadata info was already available so thought just a post processing similar to c++ code will do. 
Let me know if anything more is needed.",hi tried code seeing code available native client time stamp available python code already available thought post similar code let know anything,issue,negative,positive,positive,positive,positive,positive
553767325,"@saravananselvamohan Posting the same error everywhere is not going to get your more attention, but it is irritating.",posting error everywhere going get attention irritating,issue,negative,negative,negative,negative,negative,negative
553767068,"@massielislas As I said, please look for the documentation matching the release you are using.",said please look documentation matching release,issue,negative,neutral,neutral,neutral,neutral,neutral
553766826,@samhithaaaa This is not a bug. Please seek support on Discourse and share more informations.,bug please seek support discourse share,issue,positive,neutral,neutral,neutral,neutral,neutral
553613649,@lissyx Tried running those commands today and it gives me the error I pointed out in the post,tried running today error pointed post,issue,negative,neutral,neutral,neutral,neutral,neutral
553613075,"I am looking at the documentation at  https://github.com/mozilla/DeepSpeech on the master branch.
",looking documentation master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
553542130,"@rhamnett I shared one binary here (trie file built for v0.5.1): https://discourse.mozilla.org/t/deep-speech-vs-picovoice-cheetah/48360/4

I don't have a script to share because I've been experimenting interactively for now. Basically trying different estimation and filtering parameters and seeing how it performs on our validation sets.",one binary file built script share basically trying different estimation filtering seeing validation,issue,negative,neutral,neutral,neutral,neutral,neutral
553524284,@reuben are you happy to share your binary and/or the script to create it?,happy share binary script create,issue,positive,positive,positive,positive,positive,positive
553502370,"I've been doing experiments with OpenWebText and getting some interesting preliminary results, but it's a more significant change and I'm trying to play it safe for the upcoming 0.6 release as we already have way too many big changes. And I'm definitely interested in hearing about any experiments related to this, don't hesitate to share. I've created an issue to keep the conversation going: https://github.com/mozilla/DeepSpeech/issues/2529",getting interesting preliminary significant change trying play safe upcoming release already way many big definitely interested hearing related hesitate share issue keep conversation going,issue,positive,positive,positive,positive,positive,positive
553500642,"@dabinat LM is currently made from librispeech ( see https://github.com/mozilla/DeepSpeech/tree/master/data/lm ) and really needs work to reflect modern day language better. I am doing some experiments with open data sets too, i'll post updates as I get them.

If you actually look at the content of the file the LM is generated against it contains a bunch of garbage like ""eeeeoooooouuuu a a a a a a a a"" repeatedly all over the txt file. I have mentioned this a few timse to @lissyx too so they are aware.",currently made see really need work reflect modern day language better open data post get actually look content file bunch garbage like repeatedly file aware,issue,positive,positive,positive,positive,positive,positive
553499446,"The LM is currently built from Wikipedia, right? Maybe it’s worth passing it through the Common Voice wiki cleanup rules / blacklists here: https://github.com/Common-Voice/common-voice-wiki-scraper

I also have a tool to help identify the least-common words and generate blacklists if that’s useful: https://github.com/dabinat/cvtools/blob/master/word_usage.py",currently built right maybe worth passing common voice cleanup also tool help identify generate useful,issue,positive,positive,positive,positive,positive,positive
553494774,Yes. It's a tiny effect on Librispeech: 0.3% relative WER improvement on the clean set and 1% relative WER improvement on the other set.,yes tiny effect relative wer improvement clean set relative wer improvement set,issue,positive,positive,neutral,neutral,positive,positive
553488155,"librosa has some silence trimming functionality that could be useful for cleaning up a dataset that has too much silence, if that's what's affecting model performance: https://librosa.github.io/librosa/generated/librosa.effects.trim.html",silence trimming functionality could useful cleaning much silence affecting model performance,issue,negative,positive,positive,positive,positive,positive
553487042,"No plans, but this would probably be a cool project for someone interested in DeepSpeech.",would probably cool project someone interested,issue,positive,positive,positive,positive,positive,positive
553395900,"aayagar001 <notifications@github.com> schrieb am Mi., 13. Nov. 2019, 07:05:

> Modified client.py to add function for converting metadata to timestamp of
> each word
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/mozilla/DeepSpeech/pull/2524
> Commit Summary
>
>    - client.py for supporting --json argument for timestamp info
>    - Merge pull request #1 from aayagar001/json-timestamp
>    - Added --json timestamp support in python client
>
> File Changes
>
>    - *M* native_client/python/client.py
>    <https://github.com/mozilla/DeepSpeech/pull/2524/files#diff-0> (46)
>
> Patch Links:
>
>    - https://github.com/mozilla/DeepSpeech/pull/2524.patch
>    - https://github.com/mozilla/DeepSpeech/pull/2524.diff
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/pull/2524?email_source=notifications&email_token=AELSTAEQXDKTIMMCK32KOPTQTOKLVA5CNFSM4JMSNYGKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HY4ZIUQ>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AELSTAFF4NMIN5KM4DD5SFDQTOKLVANCNFSM4JMSNYGA>
> .
>
",add function converting word view comment merge pull request commit summary supporting argument merge pull request added support python client file patch link thread reply directly view,issue,positive,positive,positive,positive,positive,positive
553351318,"> 
> 
> @carlfm01 Thanks, but what's MVVM ?

MVVM stands for model-view-view model. And it decouples the logic behind from the view. We will be able to test the viewmodel without touching the view.",thanks model logic behind view able test without touching view,issue,negative,positive,positive,positive,positive,positive
552428533,"@kdavis-mozilla i just now looked at  voice-corpus-tool but its more of offline augmentation , 
adding the real noise ( not guassian or random noise ) online during training is what i am looking. ",augmentation real noise random noise training looking,issue,negative,negative,negative,negative,negative,negative
552363466,@sarasamara7 can you provide actionable feedback on what is unclear in the documentation? ,provide actionable feedback unclear documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
552363151,Are you looking at v0.5.1 README @massielislas ? From your error it looks like you are reading doc from master and apply to v0.5.1. ,looking error like reading doc master apply,issue,negative,neutral,neutral,neutral,neutral,neutral
552361851,Are we supposed to also guess your error? ,supposed also guess error,issue,negative,neutral,neutral,neutral,neutral,neutral
552353220,"Could you fill out the issue template so we can understand what went wrong? Also, could you provide the error message to help us debug.",could fill issue template understand went wrong also could provide error message help u,issue,negative,negative,negative,negative,negative,negative
552347330,@kdavis-mozilla it could be a feature request to integrate rnnoise dataset to augment with speech or should i create a separate bug for feature request?,could feature request integrate augment speech create separate bug feature request,issue,negative,neutral,neutral,neutral,neutral,neutral
552345621,"We'd like to reserve issues for bugs in the github code base or feature requests. As this is related to your modified code and a new data set and not related to a feature request or bug, could you move this to [Discourse](https://discourse.mozilla.org/c/deep-speech) where we tackle such issues. Thanks!",like reserve code base feature related code new data set related feature request bug could move discourse tackle thanks,issue,positive,negative,neutral,neutral,negative,negative
552294192,"rnnoise Dataset is quite huge around 15Gb on extraction , i am augmenting each file..should i augment only few files ? or reduce gain of before mixing with speech.",quite huge around extraction file augment reduce gain speech,issue,positive,positive,positive,positive,positive,positive
551885905,"Because manually debugging, I could see:
```
 + ls -hal /Users/build-user/TaskCluster/Workdir/tasks/tc-workdir/tc-workdir/
```

So I was basically building the wrong path.",manually could see basically building wrong path,issue,negative,negative,negative,negative,negative,negative
551425885,And can you please tell me why are the files sorted according to their size? Is it achieving something specific or is there no particular reason?,please tell sorted according size something specific particular reason,issue,negative,positive,neutral,neutral,positive,positive
551425081,"Try disabling feature caching (remove the `.cache()` call in feeding.py) or caching features to disk rather than memory (specify --feature_cache flag), that's probably what's causing this.",try feature remove call disk rather memory specify flag probably causing,issue,negative,neutral,neutral,neutral,neutral,neutral
551425040,"@lissyx I have 64 GB of RAM on my machine. I don't think it's the issue with RAM. Because when I ran the model without sorting the dataframe, it ran without any issues.",ram machine think issue ram ran model without ran without,issue,negative,neutral,neutral,neutral,neutral,neutral
551424530,"> it occupies 97% for my machine RAM

@shan18 How much RAM do you have ?",machine ram much ram,issue,negative,positive,positive,positive,positive,positive
551421574,BTW the issue was opened on the question of why we sort anyway. ,issue question sort anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
551418514,The massive difference in memory usage seems like it might be a bug though. Is that expected behavior?,massive difference memory usage like might bug though behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
551408034,"This is the sorting for batching file by size, as much as I remember. Maybe @reuben can complete, but this is obviously not a bug for sure. ",file size much remember maybe complete obviously bug sure,issue,negative,positive,positive,positive,positive,positive
551383310,Okay. I have been digging into the code for quite some time. I'll try to update the docs.,digging code quite time try update,issue,negative,neutral,neutral,neutral,neutral,neutral
551196246,"If you are willing to dig into the code and fix the doc you are welcome, though. I started things in https://github.com/mozilla/DeepSpeech/pull/2399",willing dig code fix doc welcome though,issue,negative,positive,positive,positive,positive,positive
551195589,"This documentation is outdated, and I have been too lazy to find time to fix it 😢",documentation outdated lazy find time fix,issue,negative,negative,negative,negative,negative,negative
551007261,Kindly read the documentation. I already replied to this on discourse. ,kindly read documentation already discourse,issue,negative,positive,positive,positive,positive,positive
550874077,"@jrmeyer can you rebase / merge master? Taskcluster changed a lot in the past days, you will need those to be able to run tests ",rebase merge master lot past day need able run,issue,negative,positive,positive,positive,positive,positive
550191281,"Fixed by installing `future` system-wide on the builders, since TensorFlow uses Python2 from the system.",fixed future since python system,issue,negative,positive,neutral,neutral,positive,positive
550184042,"Final package will be checked:
 - ensuring the number of `libdeepspeech.so` matches what we want (arch and versions)
 - running tests with latest version package only, on all arch

This should get us good coverage and not explode the amount of tests we run.",final package checked number want arch running latest version package arch get u good coverage explode amount run,issue,positive,positive,positive,positive,positive,positive
550179356,"Indeed, those rebuilds are **fine** and we are happy to see them. So we should not count them as spurious and just continue.",indeed fine happy see count spurious continue,issue,positive,positive,positive,positive,positive,positive
549763721,"The real proper fix would be to have better macOS infra :-). But that's okay by me, as long as we also keep good enough coverage for the multi-platform package.",real proper fix would better infra long also keep good enough coverage package,issue,positive,positive,positive,positive,positive,positive
549752022,"@NarasimmanSaravana1994 This is not a bug, please use Discourse for support. You are playing with CUDA visibility, please make sure you don't mask any GPU. Please also make sure that TensorFlow is able to see your CUDA setup: `python3 -c ""import tensorflow as tf; tf.Session();""`.",bug please use discourse support visibility please make sure mask please also make sure able see setup python import,issue,positive,positive,positive,positive,positive,positive
549751094,"@lissyx 

Command Executed:
CUDA_VISIBLE_DEVICES=0 python3 DeepSpeech_testing.py --lm_binary_path ./data/deepspeech_dataset/lm.binary --lm_trie_path ./data/deepspeech_dataset/trie --learning_rate 0.0001 --alphabet_config_path ./data/alphabet.txt --beam_width 1024 --use_seq_length false --remove_export true --notest --train_batch_size 30 --train_files ./data/deepspeech_dataset/18-10-19_final_purned.csv --dev_files ./data/deepspeech_dataset/11-10-19_en_test.csv --export_dir ./export  --epochs 10 --dropout_rate4 0.3 --dropout_rate5 0.3


Now that error is solved. But my training is run in CPU only 
1.I install deepspeech-gpu and tensorflow-gpu but it running in cpu 
2.No process is running (showing in nvidia-smi)

What i'm missing i don't know.
Please guild me where i'm missing or need to check.",command executed python false true error training run install running process running showing missing know please guild missing need check,issue,negative,negative,negative,negative,negative,negative
549728792,"Given the few info, it's unlikely to be a bug on our side... ",given unlikely bug side,issue,negative,negative,negative,negative,negative,negative
549723750,@NarasimmanSaravana1994 Could you please fill out the issue template? Otherwise we will be unable to help you.,could please fill issue template otherwise unable help,issue,positive,negative,negative,negative,negative,negative
549662235,@nicolaspanel Are you working on this feature? I am also interested in such a feature.,working feature also interested feature,issue,negative,positive,positive,positive,positive,positive
549413607,"> use deepspeech==0.5.1 instead of ^0.6.0-alpha.11

> All libraries were installed like in instruction with npm. What is wrong?

You changed the version. The API is not the same.

Please use Discourse for support.",use instead like instruction wrong version please use discourse support,issue,positive,negative,negative,negative,negative,negative
549400217,"> The error appears on alpha 6 (since the model constructor changed).
> As you can see I am using the 0.5.1-models. Are there new models that have to be used?

A lot changed, the API has been simplified and we have changed the way metadata are being handled.

No v0.6 model is yet avalable.

This is not a bug, please use Discourse for further discussion.",error alpha since model constructor see new used lot simplified way handled model yet bug please use discourse discussion,issue,negative,positive,positive,positive,positive,positive
549314551,"@hjortnaes Just landed a new parameter to help checking that kind of discrepencies, running `check_characters.py` from current master should detect error-prone normalizations.",landed new parameter help kind running current master detect,issue,positive,positive,positive,positive,positive,positive
549286394,"This works fine on my end:

```
$ xxd ../sample.txt
00000000: 6165 696f 750a 2c2c 6520 c3a9 2065 cc81  aeiou.,,e .. e..
00000010: 2061 6161                                 aaa
$ cat ../sample.txt
aeiou
,,e é é aaa%                                                                                                                                                                                                    $ python util/check_characters.py -csv ../sample.txt
### The following unique characters were found in your transcripts: ###
[' ', 'é', 'a', 'e', '́']
$ python util/check_characters.py -csv ../sample.txt -alpha
### The following unique characters were found in your transcripts: ###
e
 ́
a

é
### ^^^ You can copy-paste these into data/alphabet.txt ###
```",work fine end ca cat python following unique found python following unique found,issue,negative,positive,positive,positive,positive,positive
549258391,"The two chars you shared makes me think it is the case of two codepoints / two bytes. This is kind of broken with this script right now. Can you try with `unicodedata.normalize(""NFKC"", s) ` when you generate your csv files? ",two think case two two kind broken script right try generate,issue,negative,positive,positive,positive,positive,positive
549257381,Can you be more specific? Are those one or multi code points chars? One or multibyte? ,specific one code one,issue,negative,neutral,neutral,neutral,neutral,neutral
549182279,"Yep, I mentioned it o' Bugzilla but in the hurry this may have been forgotten. ",yep hurry may forgotten,issue,negative,neutral,neutral,neutral,neutral,neutral
549173597,"We'll also need to apply the tensorflow changes to the r1.14 branch, right?",also need apply branch right,issue,negative,positive,positive,positive,positive,positive
549167334,I'll give it a try locally with valgrind and/or rr chaos mode ,give try locally chaos mode,issue,negative,neutral,neutral,neutral,neutral,neutral
549150541,Can't reproduce locally on a Pi 4 either :(,ca reproduce locally pi either,issue,negative,neutral,neutral,neutral,neutral,neutral
548848968,"I'm getting empty transcripts, and sometimes segfaults in the TFLite tests. Yet it always works locally and valgrind is clean... D:",getting empty sometimes yet always work locally clean,issue,negative,positive,positive,positive,positive,positive
548410286,"There's mostly nothing to make or from this feature, for now.",mostly nothing make feature,issue,negative,positive,positive,positive,positive,positive
548348706,"After a lot of roadblocks,
```
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ LD_LIBRARY_PATH=/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx/bazel-bin/native_client/: time ./native_client/deepspeech --model ~/tmp/deepspeech/model_opt/output_graph.tflite --alphabet ~/tmp/deepspeech/model/alphabet.txt --audio data/smoke_test/LDC93S1.wav -t
TensorFlow: v1.15.0-0-g590d6eef7e
DeepSpeech: v0.6.0-alpha.11-4-g3d3d5a23
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_requantized op_context.input1->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum/y_requantized op_context.input2->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_1_requantized op_context.input1->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_1/y_requantized op_context.input2->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_2_requantized op_context.input1->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_2/y_requantized op_context.input2->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_3 op_context.input1->type=9
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_3/y_requantized op_context.input2->type=9
audio_win_len_=512
audio_win_step_=320

cpu_time_overall=7.55232
7.55user 0.00system 0:02.32elapsed 324%CPU (0avgtext+0avgdata 48240maxresident)k
0inputs+0outputs (0major+3415minor)pagefaults 0swaps
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ LD_LIBRARY_PATH=/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tensorflow-lissyx/bazel-bin/native_client/: time ./native_client/deepspeech --model ~/tmp/deepspeech/model_nonopt/output_graph.tflite --alphabet ~/tmp/deepspeech/model/alphabet.txt --audio data/smoke_test/LDC93S1.wav -t
TensorFlow: v1.15.0-0-g590d6eef7e
DeepSpeech: v0.6.0-alpha.11-4-g3d3d5a23
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu op_context.input1->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum/y op_context.input2->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_1 op_context.input1->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_1/y op_context.input2->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_2 op_context.input1->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_2/y op_context.input2->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input1->name=Relu_3 op_context.input1->type=1
TfLiteStatus tflite::ops::builtin::maximum_minimum::Prepare(TfLiteContext*, TfLiteNode*)op_context.input2->name=Minimum_3/y op_context.input2->type=1
audio_win_len_=512
audio_win_step_=320
ec et 
cpu_time_overall=1.23065
1.23user 0.00system 0:01.23elapsed 99%CPU (0avgtext+0avgdata 59908maxresident)k
0inputs+0outputs (0major+2559minor)pagefaults 0swaps
```",lot time model alphabet audio time model alphabet audio,issue,negative,neutral,neutral,neutral,neutral,neutral
548303778,"> (deepspeech) C:\Users\165689>pip install --upgrade deepspeech==0.5.1
> ERROR: Could not find a version that satisfies the requirement deepspeech==0.5.1
> (from versions: 0.6.0a11)
> ERROR: No matching distribution found for deepspeech==0.5.1

Filling the Github issue template would have saved us some time.",pip install upgrade error could find version requirement error matching distribution found filling issue template would saved u time,issue,negative,neutral,neutral,neutral,neutral,neutral
548295007,"(deepspeech) C:\Users\165689>pip install --upgrade deepspeech==0.5.1
ERROR: Could not find a version that satisfies the requirement deepspeech==0.5.1
 (from versions: 0.6.0a11)
ERROR: No matching distribution found for deepspeech==0.5.1",pip install upgrade error could find version requirement error matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
548262505,@alokprasad I guess in your case it might be better you change your feeding code yep.,guess case might better change feeding code yep,issue,positive,positive,positive,positive,positive,positive
548259297,"> Is there any command by which I can downgrade deepspeech version?

pip uninstall deepspeech and then pip install --upgrade deepspeech==0.5.1",command downgrade version pip pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
548221796,"1. Is there any command by which I can downgrade deepspeech version?
2. Will my command work after downgrading the deepspeech version to 0.5.x?",command downgrade version command work version,issue,negative,neutral,neutral,neutral,neutral,neutral
548211694,"my usecase is wakeword + speech , where my system feeds (streaming) audio to deepspeech to detect wakeword as soon as it is detected next frame onwards it feeds audio to another instance of deepspeech 
but if gap between wakeword + speech is very less than initial words is missed.

eg. ""Lucifer, why should one hold on the way"" => ds will recognised it as ""should one hold on the way""
what is suggestion , should i change the feeder code for augmentation to remove the silence or in fact trim some audio ( few frames ) and do training?

",speech system streaming audio detect soon next frame onwards audio another instance gap speech le initial one hold way one hold way suggestion change feeder code augmentation remove silence fact trim audio training,issue,negative,neutral,neutral,neutral,neutral,neutral
547872219,"> What is incompatible?

Model v0.5.x requires v0.5.x binary. Use proper version.",incompatible model binary use proper version,issue,negative,neutral,neutral,neutral,neutral,neutral
547871861,"but 

> > (deepspeech) C:\Users\165689\Desktop\chatbot.chatbot>deepspeech --model deepspe
> > ech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.t
> > xt --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --
> > audio audio/2830-3980-0043.wav
> > Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
> > TensorFlow: v1.14.0-18-g351a98ab6e
> > DeepSpeech: v0.6.0-alpha.11-0-gf3694ef
>
> You are running incompatible model / binary.

What is incompatible?
How can I run it?
",model alphabet audio loading model file running incompatible model binary incompatible run,issue,negative,neutral,neutral,neutral,neutral,neutral
547868680,"> (deepspeech) C:\Users\165689\Desktop\chatbot.chatbot>deepspeech --model deepspe
> ech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.t
> xt --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --
> audio audio/2830-3980-0043.wav
> Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
> TensorFlow: v1.14.0-18-g351a98ab6e
> DeepSpeech: v0.6.0-alpha.11-0-gf3694ef

You are running incompatible model / binary.",model alphabet audio loading model file running incompatible model binary,issue,negative,neutral,neutral,neutral,neutral,neutral
547837871,"Thanks, it perfectly illustrates an issue I wanted to take care of ... :)",thanks perfectly issue take care,issue,positive,positive,positive,positive,positive,positive
547836482,"@lissyx You're right with ""unicode-different yet similar-looking char"".
The ""ü""-char, which was the only char doesnt works, exists in my alphabet file, but it wasn't the same char used in my train/dev/test.csv files - it justs looks like it.

I copied the chars from the check_characters script directly in my alphabet file and it works.

Thank you :)",right yet char char doesnt work alphabet file char used like copied script directly alphabet file work thank,issue,positive,positive,positive,positive,positive,positive
547813451,"> @a-lunev The question here is mostly: is there really something that needs to be addressed at the code-level, i.e., adding some magic constant, or could it just be a side-effect of the datasets we are using, that may mostly have longer-silence than what you are exercizing here.
> 
> If it's the later, then the proper solution would not be to workaround in the code but rather improve the training dataset, which might even be easier now that we have data augmentation landed.

I suppose some debug / investigation is required to determine the real cause of the issue. As soon as the cause is determined, the appropriate decision could be made.",question mostly really something need magic constant could may mostly later proper solution would code rather improve training might even easier data augmentation landed suppose investigation determine real cause issue soon cause determined appropriate decision could made,issue,positive,positive,positive,positive,positive,positive
547736250,"@lissyx 
Sorry for late response
here are the samples

1. trimmed

2. silence added to above trimmed file

https://soundcloud.com/alok-prasad-213091558/sets/deepspeech-test-files

actual utterance in the speech file is ""why should one hold on the way"" 
but when fed to deepspeech native original wav gives ouput ""what should one hold on the way"" 
( maybe lm issue)

1>Trimmed
**trimmed_4507-16021-0012.wav**
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=67714
**should an hold on the way**

2>When silence is appended 
**silence_added_at_start_and_trimmed_4507-16021-0012.wav**
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=69210
**what should one hold on the way**

I think this has to be addressed at training level specially when we have augmentation in place,
as most of this ASR will be used in conjunction with some sort of VAD in place ( webrtc or rnnoise)
before it detects the speech some frames may be some silence or speech is already lost, if we buffer previous frames have seen issues asr recognition ( specially if we speak very fast )
",sorry late response silence added file actual utterance speech file one hold way fed native original one hold way maybe issue hold way silence one hold way think training level specially augmentation place used conjunction sort place speech may silence speech already lost buffer previous seen recognition specially speak fast,issue,negative,positive,neutral,neutral,positive,positive
547604978,"@a-lunev The question here is mostly: is there really something that needs to be addressed at the code-level, i.e., adding some magic constant, or could it just be a side-effect of the datasets we are using, that may mostly have longer-silence than what you are exercizing here.

If it's the later, then the proper solution would not be to workaround in the code but rather improve the training dataset, which might even be easier now that we have data augmentation landed.",question mostly really something need magic constant could may mostly later proper solution would code rather improve training might even easier data augmentation landed,issue,positive,positive,positive,positive,positive,positive
547478571,"We are working on releasing non-English models as soon as we get training data sets that are of a sufficient size to train with.

As this conversation is getting rather heated, isn't facilitating the process of getting non-English training data sets of a sufficient size, and is robbing us of time needed to get those data sets, I'm going to close the issue for now.",working soon get training data sufficient size train conversation getting rather process getting training data sufficient size robbing u time get data going close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
547477971,"@lissyx, you didn't  reply on my points. ""equal in dignity"" is not  an insinuation, is just a requirement stated in common voice goals I share.
",reply equal dignity insinuation requirement stated common voice share,issue,positive,negative,negative,negative,negative,negative
547468083,"> To avoid any friction, to lower the learning curve, and to allow non English languages to be considered, sooner or later (a stable release), as English language, **with equal in dignity** ;-)

Please stop your insinuations. If you have 10k hours of Italian, please, share. We'll make a good model asap.",avoid friction lower learning curve allow non considered sooner later stable release language equal dignity please stop please share make good model,issue,positive,positive,positive,positive,positive,positive
547458662,"Hi Daniele.

>Common Voice has like 25 language enabled
>75 languages to unlock

I guess that's perfectly clear for everybody here.

>Now every language based on the amount requires hours of training, machines with hardware >capable, and also will not use only the CV dataset for training. Every language use different datasets 

It doesn't add up, can you clarify that point? In thought each pretrained DeepSpeech dataset (as the English one already availabe in [this repo](https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz)) should be built just from **English language Common Voice dataset**. That's untrue? 

I'm asking because, if each **pre-trained** language model is built not only using Common Voice training set, but it's also enhanced/mixed with **external-sets**, that lead to a collateral issue immo, in terms of replicability, transparency, bias, etc. 

BTW I see a pre-trained model as a foundation data-set, a common **reference** (someone say ""universal""). Afterward the huge value of this opendata+opensource project is that developer could enhances the reference (CV) data-set with his own dataset on-top, producing his own custom model. Right?

>The question that we should do is: We want a good software to generate models and a good >dataset or we want focus only to get the model?

I don't see any trade-off; both are required. Let's stay on focus of DeepSpeech success: we need best datasets (exactly in terms of Common Voice main statements: inclusivity, real spoken language training-mapping, etc.) to achieve best speech recognition success rate. At the end of the day, the power of CV+DS together is to have opensource+opendata enabling a complete open platform for citizens.

So, in my opinion, **this [issue](https://github.com/mozilla/DeepSpeech/issues/2468) should remain open, as CHANGE REQUEST remind**, just because that's strategic.

We need to supply developers simple tools to adopt DeepSpeech platform (and all on behind, mainly CV). To avoid any friction, to lower the learning curve, and to allow non English languages to be considered, sooner or later (a stable release), as English language, **with equal in dignity** ;-)
   
So I renew my proposal to **maintain pre-trained language models**,  immediately availables, in this core github repo, or in a separated language-local repo (does not change much).

giorgio",hi common voice like language unlock guess perfectly clear everybody every language based amount training hardware capable also use training every language use different add clarify point thought one already built language common voice untrue language model built common voice training set also lead collateral issue transparency bias see model foundation common reference someone say universal afterward huge value project developer could reference custom model right question want good generate good want focus get model see let stay focus success need best exactly common voice main real spoken language achieve best speech recognition success rate end day power together complete open platform opinion issue remain open change request remind strategic need supply simple adopt platform behind mainly avoid friction lower learning curve allow non considered sooner later stable release language equal dignity renew proposal maintain language immediately core change much,issue,positive,positive,positive,positive,positive,positive
547368499,"@lissyx sir. 

in my datasets 250 hrs duration.

like youtube datasets segmented with corresponding subtitle transcript.
here some spelling mistakes and mispronunciations files is there.

datasets i was trained in 0.5.1. few epochs after validation went inf loss.

so what i thought is, worst case simply removing the file from our dataset.

so i need to find out problem files.  that's why i am focusing on checking non-finite-loss files to remove.

@lissyx Thank you sir.


",sir duration like segmented corresponding subtitle transcript spelling trained validation went loss thought worst case simply removing file need find problem remove thank sir,issue,negative,negative,negative,negative,negative,negative
547360914,"> Master v0.5.1 is the latest one upto my knowledge

Please be clear, you are mixing everything here.",master latest one knowledge please clear everything,issue,positive,positive,positive,positive,positive,positive
547360509,"> If you continue not to share your patch, it's going to be hard to try and help you.
> 
> Why don't you just use master ?

Master v0.5.1 is the latest one upto my knowledge ?  here did they already implemented **checking non-finite loss files** ?

",continue share patch going hard try help use master master latest one knowledge already loss,issue,negative,positive,positive,positive,positive,positive
547358948,"> so what i did here is, just i applied same concepts in 0.5.1. but i am not getting problem files(non finite files).

If you continue not to share your patch, it's going to be hard to try and help you.

Why don't you just use master ?",applied getting problem non finite continue share patch going hard try help use master,issue,negative,negative,negative,negative,negative,negative
547358761,"> @MuruganR96 As this is not a bug with master, 0.6.X, or any older release version, I suggest this should be moved to [Discourse](https://discourse.mozilla.org/c/deep-speech).

Thank you sir. Please discuss here sir [My issue](https://discourse.mozilla.org/t/not-working-for-checking-non-finite-loss-files/47627?u=muruganrajenthirean)",bug master older release version suggest discourse thank sir please discus sir issue,issue,positive,positive,positive,positive,positive,positive
547357056,"@lissyx  sir.  
>  I'm sure we already have something for that on master.
> > but i can't able to get the list of non finite loss files.
> 
> Please be more specific.

in DeepSpeech v0.5.1 not implemented for **checking non-finite loss files**.

so what i did here is, just i applied same concepts in 0.5.1. but i am not getting problem files(non finite files).

in my 250 hrs of datasets i trained in 0.5.1. few epochs after validation went **inf loss**.
so if i will checking non-finite loss files mean, i can resolve this inf loss issue via removing the problem files.

thank you sir.",sir sure already something master ca able get list non finite loss please specific loss applied getting problem non finite trained validation went loss loss mean resolve loss issue via removing problem thank sir,issue,negative,positive,positive,positive,positive,positive
547356796,"This is something that in Mozilla Italia in our monthly calls and discussion was a common discussion.
The point that seems not everyone has clear about generating a model is:

* Common Voice has like 25 language enabled
* 75 languages to unlock

Now every language based on the amount requires hours of training, machines with hardware capable, and also will not use only the CV dataset for training. Every language use different datasets so this create a level of entropy gigantic.

This is a thing that the communities should do, like Italian or French because they can adapt based on the needs.

Also DS is still at 0.6 so it is not stable!

Common Voice is not DeepSpeech, CV is a way to gather data for DS so they shouldn't be associated at all when we are talking on that point.

The question that we should do is: We want a good software to generate models and a good dataset or we want focus only to get the model? 

Right now the status of both the project is not so stable and strong for the second point, at least until one language reach the goal of 2000 hours of recording.",something monthly discussion common discussion point everyone clear generating model common voice like language unlock every language based amount training hardware capable also use training every language use different create level entropy gigantic thing like adapt based need also still stable common voice way gather data associated talking point question want good generate good want focus get model right status project stable strong second point least one language reach goal recording,issue,positive,positive,positive,positive,positive,positive
547355772,"@MuruganR96 As this is not a bug with master, 0.6.X, or any older release version, I suggest this should be moved to [Discourse](https://discourse.mozilla.org/c/deep-speech).",bug master older release version suggest discourse,issue,negative,positive,positive,positive,positive,positive
547351595,"> but i can't able to get the list of non finite loss files.

Please be more specific.",ca able get list non finite loss please specific,issue,negative,positive,positive,positive,positive,positive
547349074,"@lissyx  @kdavis-mozilla Thank you sir.

yes, i am trying to backport 0.5.1. but i can't able to get the list of non finite loss files. 
am i miss something,  could you explain me?

here the reason why i am back-port 0.5.1 is i can do continue training with my own data-sets in which some datasets are throwing **inf**  loss  and **no-valid-path-found** warning in 0.5.1.

Thank you. :) 



",thank sir yes trying ca able get list non finite loss miss something could explain reason continue training throwing loss warning thank,issue,negative,positive,positive,positive,positive,positive
547319519,">  As for me, ""on the way"" sounds totally equal.

Ask someone blindly, I'm not sure you will get the same results.",way totally equal ask someone blindly sure get,issue,negative,positive,positive,positive,positive,positive
547309033,@MuruganR96 It's a bit unclear in the current form. This change makes it possible to know which files has infinite loss ? I'm sure we already have something for that on master.,bit unclear current form change possible know infinite loss sure already something master,issue,negative,positive,positive,positive,positive,positive
547206253,"> Honestly, listening before reading your comment, in the version cut, my ears don't get ""on"" but ""n"" as well. Once I read your comment, I could only ear ""on"". I'm unsure how much we are just biaised on that sample, but at least that's actionable.

I've just listened to the original (not modified version) 4507-16021-0012.wav and compared it with my modified wav files.
As for me, ""on the way"" sounds totally equal.
When I cut the beginning part of the sentence, I tried to keep ""on the way"" segment untouched.
You could compare all 3 wav files by e.g. Audacity for details (waveform or spectrogram side-by-side).",honestly listening reading comment version cut get well read comment could ear unsure much sample least actionable original version way totally equal cut beginning part sentence tried keep way segment untouched could compare audacity spectrogram,issue,negative,positive,positive,positive,positive,positive
547171815,"> @lissyx Yesterday I tested Mozilla DeepSpeech in both offline (https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/python/client.py) and streaming (https://github.com/mozilla/DeepSpeech/blob/v0.5.1/examples/mic_vad_streaming/mic_vad_streaming.py) modes.
> 
> In my experiments I intentionally not used LM / TRIE.
> 
> The offline (reading audio from a wav file) mode works quite good concerning speech recognition accuracy. However, I was not able to achieve the same quality via my laptop mic. The speech recognition is very bad if I feed audio via my laptop mic.
> My initial thought was that my laptop mic drastically changes the frequency response and/or SNR. Also I was suspecting potential issues with VAD in mic_vad_streaming.py.
> 
> Then I performed the following experiment:
> 
>     1. I took a wav file, let's name it ORIGINAL_AUDIO.
> 
>     2. If I feed it to client.py, the recognition is quite accurate.
> 
>     3. Then I played ORIGINAL_AUDIO to my laptop speaker and recorded the sound via my laptop mic. Let's name the new wav file as RECORDED_AUDIO.
> 
>     4. Then I fed RECORDED_AUDIO wav file to client.py again, and the recognition was still quite accurate.
> 
> 
> Thus I've inferred that the issue is not with my laptop mic.
> 
> Then I performed the next experiment: run mic_vad_streaming.py and played ORIGINAL_AUDIO. The recognition results were very bad.
> 
> Then I added ""--savewav"" option and run mic_vad_streaming.py again, and played ORIGINAL_AUDIO. Let's name the saved file as SAVED_AUDIO.
> I listened to the SAVED_AUDIO. It was good. I was able to hear every word.
> Then I fed SAVED_AUDIO to client.py (offline mode), and the recognition results were as bad as I got with mic_vad_streaming.py.
> 
> After that I found this current issue #2443.
> Unfortunately, I can not provide particularly ORIGINAL_AUDIO and SAVED_AUDIO files from my experiments I described. However, I've just prepared new files by reproducing the same issue close to as @alokprasad explained.
> I did the following:
> 
>     1. took 4507-16021-0012.wav (extracted it from https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz)
> 
>     2. cut ""on the way"" audio segment in Audacity and saved it as ""4507-16021-0012_on_the_way.wav"" file
> 
>     3. generated 0.1 s silence in Audacity in the beginning of ""4507-16021-0012_on_the_way.wav"" file in Audacity and saved it as ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" file
> 
>     4. fed ""4507-16021-0012_on_the_way.wav"" file to deepspeech executable:
> 
> 
> ```
> $ deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --audio audio/4507-16021-0012_on_the_way.wav
> Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
> TensorFlow: v1.13.1-10-g3e0cc53
> DeepSpeech: v0.5.1-0-g4b29b78
> 2019-10-28 22:40:22.269232: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
> 2019-10-28 22:40:22.269287: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
> 2019-10-28 22:40:22.269302: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
> 2019-10-28 22:40:22.269431: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
> Loaded model in 0.00903s.
> Running inference.
> n the way
> ```
> 
> As you can see, ""o"" letter is missing in the output (should be ""on the way"").
> 
>     1. fed ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" file to deepspeech executable:
> 
> 
> ```
> $ deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --audio audio/4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav 
> Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
> TensorFlow: v1.13.1-10-g3e0cc53
> DeepSpeech: v0.5.1-0-g4b29b78
> 2019-10-28 22:43:09.572111: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
> 2019-10-28 22:43:09.572172: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
> 2019-10-28 22:43:09.572196: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
> 2019-10-28 22:43:09.572361: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
> Loaded model in 0.00938s.
> Running inference.
> on the way
> ```
> 
> As you can see, this time the recognition is 100% correct.
> Thus adding a silence in the beginning helped.
> 
> I'm suspecting the issue is somewhere in the feature extraction stage (particularly MFCC?). Or the whole system (feature extraction + NN) requires some initial (dummy) set of input samples to start working (filling buffers or something).
> [test_2443.zip](https://github.com/mozilla/DeepSpeech/files/3780642/test_2443.zip)
> 
> I attached test_2443.zip with ""4507-16021-0012_on_the_way.wav"" and ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" files.
> 
> I hope it would be enough to reproduce the issue and find the cause.

Honestly, listening before reading your comment, in the version cut, my ears don't get ""on"" but ""n"" as well. Once I read your comment, I could only ear ""on"". I'm unsure how much we are just biaised on that sample, but at least that's actionable.",yesterday tested streaming intentionally used reading audio file mode work quite good concerning speech recognition accuracy however able achieve quality via speech recognition bad feed audio via initial thought drastically frequency response also potential following experiment took file let name feed recognition quite accurate speaker sound via let name new file fed file recognition still quite accurate thus issue next experiment run recognition bad added option run let name saved file good able hear every word fed mode recognition bad got found current issue unfortunately provide particularly however prepared new issue close following took extracted cut way audio segment audacity saved file silence audacity beginning file audacity saved file fed file executable model alphabet audio loading model file unknown unknown unknown unknown loaded model running inference way see letter missing output way fed file executable model alphabet audio loading model file unknown unknown unknown unknown loaded model running inference way see time recognition correct thus silence beginning issue somewhere feature extraction stage particularly whole system feature extraction initial dummy set input start working filling something attached hope would enough reproduce issue find cause honestly listening reading comment version cut get well read comment could ear unsure much sample least actionable,issue,positive,positive,neutral,neutral,positive,positive
547169175,"> Use util/check_characters.py

Can you do that and generate the alphabet using this script ? It would not be unsurprising you have some unicode-different yet similar-looking char ...",use generate alphabet script would unsurprising yet char,issue,negative,neutral,neutral,neutral,neutral,neutral
547141302,"@lissyx Yesterday I tested Mozilla DeepSpeech in both offline (https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/python/client.py) and streaming (https://github.com/mozilla/DeepSpeech/blob/v0.5.1/examples/mic_vad_streaming/mic_vad_streaming.py) modes.

In my experiments I intentionally not used LM / TRIE.

The offline (reading audio from a wav file) mode works quite good concerning speech recognition accuracy. However, I was not able to achieve the same quality via my laptop mic. The speech recognition is very bad if I feed audio via my laptop mic.
My initial thought was that my laptop mic drastically changes the frequency response and/or SNR. Also I was suspecting potential issues with VAD in mic_vad_streaming.py.

Then I performed the following experiment:
1) I took a wav file, let's name it ORIGINAL_AUDIO.
2) If I feed it to client.py, the recognition is quite accurate.
3) Then I played ORIGINAL_AUDIO to my laptop speaker and recorded the sound via my laptop mic. Let's name the new wav file as RECORDED_AUDIO.
4) Then I fed RECORDED_AUDIO wav file to client.py again, and the recognition was still quite accurate.

Thus I've inferred that the issue is not with my laptop mic.

Then I performed the next experiment: run mic_vad_streaming.py and played ORIGINAL_AUDIO. The recognition results were very bad.

Then I added ""--savewav"" option and run mic_vad_streaming.py again, and played ORIGINAL_AUDIO. Let's name the saved file as SAVED_AUDIO.
I listened to the SAVED_AUDIO. It was good. I was able to hear every word.
Then I fed SAVED_AUDIO to client.py (offline mode), and the recognition results were as bad as I got with mic_vad_streaming.py.

After that I found this current issue #2443.
Unfortunately, I can not provide particularly ORIGINAL_AUDIO and SAVED_AUDIO files from my experiments I described. However, I've just prepared new files by reproducing the same issue close to as @alokprasad explained.
I did the following:
1) took 4507-16021-0012.wav (extracted it from https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz)

2) cut ""on the way"" audio segment in Audacity and saved it as ""4507-16021-0012_on_the_way.wav"" file

3) generated 0.1 s silence in Audacity in the beginning of ""4507-16021-0012_on_the_way.wav"" file in Audacity and saved it as ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" file

4) fed ""4507-16021-0012_on_the_way.wav"" file to deepspeech executable:
```
$ deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --audio audio/4507-16021-0012_on_the_way.wav
Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
2019-10-28 22:40:22.269232: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-10-28 22:40:22.269287: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-10-28 22:40:22.269302: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-10-28 22:40:22.269431: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.00903s.
Running inference.
n the way
```

As you can see, ""o"" letter is missing in the output (should be ""on the way"").

5) fed ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" file to deepspeech executable:
```
$ deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --audio audio/4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav 
Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
2019-10-28 22:43:09.572111: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-10-28 22:43:09.572172: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-10-28 22:43:09.572196: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-10-28 22:43:09.572361: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.00938s.
Running inference.
on the way
```
As you can see, this time the recognition is 100% correct.
Thus adding a silence in the beginning helped.

I'm suspecting the issue is somewhere in the feature extraction stage (particularly MFCC?). Or the whole system (feature extraction + NN) requires some initial (dummy) set of input samples to start working (filling buffers or something).
[test_2443.zip](https://github.com/mozilla/DeepSpeech/files/3780642/test_2443.zip)

I attached test_2443.zip with ""4507-16021-0012_on_the_way.wav"" and ""4507-16021-0012_on_the_way_with_silence_in_the_beginning.wav"" files.

I hope it would be enough to reproduce the issue and find the cause.",yesterday tested streaming intentionally used reading audio file mode work quite good concerning speech recognition accuracy however able achieve quality via speech recognition bad feed audio via initial thought drastically frequency response also potential following experiment took file let name feed recognition quite speaker sound via let name new file fed file recognition still quite accurate thus issue next experiment run recognition bad added option run let name saved file good able hear every word fed mode recognition bad got found current issue unfortunately provide particularly however prepared new issue close following took extracted cut way audio segment audacity saved file silence audacity beginning file audacity saved file fed file executable model alphabet audio loading model file unknown unknown unknown unknown loaded model running inference way see letter missing output way fed file executable model alphabet audio loading model file unknown unknown unknown unknown loaded model running inference way see time recognition correct thus silence beginning issue somewhere feature extraction stage particularly whole system feature extraction initial dummy set input start working filling something attached hope would enough reproduce issue find cause,issue,negative,positive,neutral,neutral,positive,positive
546718207,"> So my modest suggestion/desire is to have here published an ""official"" (and updated) repo of pre-trained models, for each language in a ""stable"" phase.

Nobody to our knowledge is at that level.",modest official language stable phase nobody knowledge level,issue,negative,positive,neutral,neutral,positive,positive
546717830,">I am not sure I get your point here. What live demo are you referring about ? ""Non-tech experts"", I >don't get it either, DeepSpeech still requires some level of expertise for integration in your app.

well, I mean that having available pre-trained models helps developers that want to try deepspeech, to quickly test and benchmark, without the need of rebuild from scratch.

So my modest suggestion/desire is to have here published an ""official"" (and updated) repo of pre-trained models, for each language in a ""stable"" phase.  
",sure get point live get either still level integration well mean available want try quickly test without need rebuild scratch modest official language stable phase,issue,positive,positive,positive,positive,positive,positive
546717276,"> I do believe that having available a repo of pre-trained models for each languages is a smart ""business/communication"" feature.

it is, but again: we don't have any of those pre-trained model yet.



> speed-up dev of any contribution, especially for not-tech experts (e.g. live demo for next November sprint, isn'it?),

I am not sure I get your point here. What live demo are you referring about ? ""Non-tech experts"", I don't get it either, DeepSpeech still requires some level of expertise for integration in your app.



> low the friction allowing to enlarge quickly communities all around the world.

That's why we are open to feedback / improvements. We are indeed helping the Italian community and they are making good progresses. I also know they can use your help, if you have spare cycles ...



> In order to provide speech technologies in Firefox, there would need to be models for multiple languages. What’s Mozilla’s plan for this? Is it going to be solely reliant on the community?

It is still too early: this landed only behind a pref in Nightly. Sourcing good data is really the biggest issue, but without a clear goal, it's harder to motivate external contributions.",believe available smart feature model yet dev contribution especially live next sprint sure get point live get either still level integration low friction enlarge quickly around world open feedback indeed helping community making good also know use help spare order provide speech would need multiple plan going solely reliant community still early landed behind nightly good data really biggest issue without clear goal harder motivate external,issue,positive,positive,positive,positive,positive,positive
546716886,"In order to provide speech technologies in Firefox, there would need to be models for multiple languages. What’s Mozilla’s plan for this? Is it going to be solely reliant on the community?",order provide speech would need multiple plan going solely reliant community,issue,negative,neutral,neutral,neutral,neutral,neutral
546716872,"@lissyx, Well I understand the ""lack of resources"" and ok, one can set-up his own model ""recompiling all"" from available common voice data (https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#training-your-own-model), 

but having **pre-trained models** already available for **each language** foresee in Common voice data feed project:  

1. speed-up community contributions, especially by not-tech experts (e.g. to set-up live demo for next November sprint..., etc,etc.),
 
2. Drop the newbie friction, allowing to enlarge quickly communities all around the world. 

I do believe that having available a repo of pre-trained models for **each language** is a smart ""business/communication"" feature. 

My two cents
giorgio",well understand lack one model available common voice data already available language foresee common voice data feed project community especially live next sprint drop friction enlarge quickly around world believe available language smart feature two,issue,negative,positive,positive,positive,positive,positive
546713193,There would still be value in at least the thinking process of how we might refer to community contributed models. ,would still value least thinking process might refer community,issue,negative,negative,negative,negative,negative,negative
546712828,"Also we provide everything to allow anyone to produce models, so there is nothing blocking any community from working on that. ",also provide everything allow anyone produce nothing blocking community working,issue,negative,neutral,neutral,neutral,neutral,neutral
546691082,"I add myself to the @lu4p **feature request**.

To grow DeepSpeech (and Common voice on top) user base, a pretrained models for each of available langue could help!

Please supply updated pretrained models for all available languages.

Thanks
giorgio",add feature request grow common voice top user base available could help please supply available thanks,issue,positive,positive,neutral,neutral,positive,positive
546376149,"Please don't use screenshots.

>     2\. python3 ./DeepSpeech.py --train_files clips/pranay2/train.csv ~--dev_files clips/pranay1/dev.csv --test_files clips/pranay1/test.csv

Is this your exact command line? `~--` seems wrong.",please use python exact command line wrong,issue,negative,negative,negative,negative,negative,negative
546137525,"FTR, SciPy is not yet ready for Python 3.8, so it's breaking one of the examples until they release a compatible version.",yet ready python breaking one release compatible version,issue,negative,positive,positive,positive,positive,positive
545305833,"Hello,

> you already have it @carlfm01 ?

No, feel free to ping me for any question, discussion or review.",hello already feel free ping question discussion review,issue,positive,positive,positive,positive,positive,positive
545126211,"FTR, the `r1.14` code is not supporting custom ops, but `r1.15` seems to. Still a lot of work to get something decent, but for now it looks better than it used to.",code supporting custom still lot work get something decent better used,issue,positive,positive,positive,positive,positive,positive
544916778,"Oh, I just looked, it's python, I guess it can't be precompiled...",oh python guess ca,issue,negative,neutral,neutral,neutral,neutral,neutral
544916065,@lissyx thank you! Can I download a pre-compiled executable for that example from somewhere?,thank executable example somewhere,issue,negative,neutral,neutral,neutral,neutral,neutral
544912793,"> @lissyx can you point me to an answer, if it was already asked, why you need to write .wav and not keep a temporary in memory?

That's the contributor's design, not our choice. Seriously, we have plenty of examples, including the bindings, that shows how to use the API from different point of view. Can you just have a look under `native_client/` and `examples/` ?",point answer already need write keep temporary memory contributor design choice seriously plenty use different point view look,issue,negative,negative,negative,negative,negative,negative
544912345,"@lissyx can you point me to an answer, if it was already asked, why you need to write .wav and not keep a temporary in memory?",point answer already need write keep temporary memory,issue,negative,neutral,neutral,neutral,neutral,neutral
544911766,"> Does Discourse requires creating an account? If yes, then no, I can't use it.

Why would not you be able to create an account ? Second, if you had looked at discourse, you would have seen you can logging using Github.",discourse account yes ca use would able create account second discourse would seen logging,issue,positive,positive,positive,positive,positive,positive
544911541,"Does Discourse requires creating an account? If yes, then no, I can't use it.",discourse account yes ca use,issue,negative,neutral,neutral,neutral,neutral,neutral
544911009,"> > Please have a look at examples
> 
> I guess it's this one? https://github.com/mozilla/DeepSpeech/blob/master/examples/mic_vad_streaming/mic_vad_streaming.py
> 
> Why does it saves .wav? Is that .wav temporary? Can I keep temporary in memory rather than saving it to a file?

Can you use Discourse, please ?",please look guess one temporary keep temporary memory rather saving file use discourse please,issue,positive,neutral,neutral,neutral,neutral,neutral
544910773,"> Please have a look at examples

I guess it's this one? https://github.com/mozilla/DeepSpeech/blob/master/examples/mic_vad_streaming/mic_vad_streaming.py

Why does it saves .wav? Is that .wav temporary? Can I keep temporary in memory rather than saving it to a file?",please look guess one temporary keep temporary memory rather saving file,issue,negative,neutral,neutral,neutral,neutral,neutral
544847514,"@lissyx : I am able to run v0.5.0 without any error instead of v0.5.1 (although both v0.5.0 and v0.5.1 seems similar. Not sure what's the issue).

Closing the issue. Thank you.",able run without error instead although similar sure issue issue thank,issue,positive,positive,positive,positive,positive,positive
544829932,">  Now i am able to load the checkpoints. I have done the fine tuning of the model from released checkpoints. But no improvement in WER. Need your suggestion..

Please use Discourse for support.


> I am using 10 Hours of indian accent Audio data for fine tuning model.

Likely 10 hours is not enough. But it also depends on your parameters etc. ...",able load done fine tuning model improvement wer need suggestion please use discourse support accent audio data fine tuning model likely enough also,issue,positive,positive,positive,positive,positive,positive
544829623,"> @tusharrakshe Can you ensure you are on proper commit, with clean index ?

Yes. I solved the problem. 
Now i am able to load the checkpoints. I have done the fine tuning of the model from released checkpoints. But no improvement in WER. Need your suggestion..

I am using 10 Hours of indian accent Audio data for fine tuning model.
",ensure proper commit clean index yes problem able load done fine tuning model improvement wer need suggestion accent audio data fine tuning model,issue,positive,positive,positive,positive,positive,positive
544825767,"> If the answer is no, then this issue is a feature request: I need a simple way to try speech-to-text in real time, not sure if it's possible with this library, but I need it regardless!

Please have a look at `examples/`. And this is obviously not a bug, so please continue discussion on Discourse.",answer issue feature request need simple way try real time sure possible library need regardless please look obviously bug please continue discussion discourse,issue,positive,positive,positive,positive,positive,positive
544733180,"https://github.com/topics/speech-to-text shows DeepSpeech at the top, so I guess this is state of the art?",top guess state art,issue,negative,positive,positive,positive,positive,positive
544716780,"I guess by ""real time"" I mean ""streaming support"", according to (timecode: 33:57): https://www.youtube.com/watch?v=ZJpLldlJYY8&t=2037",guess real time mean streaming support according,issue,negative,negative,neutral,neutral,negative,negative
544704581,"Currently watching ""Mozilla's DeepSpeech and Common Voice projects Open and offline-capable voice recognition for everyone"" by Tilman Kamp: https://www.youtube.com/watch?v=aUSyzNr6iK8",currently watching common voice open voice recognition everyone,issue,negative,negative,neutral,neutral,negative,negative
544563435,"@AASHISHAG This is not something we reproduce, this docker is built in CI and it work well.",something reproduce docker built work well,issue,negative,neutral,neutral,neutral,neutral,neutral
544550964,"Hi @lissyx, 

Sorry, testing took a while. Turned out I had the wrong deepspeech version hence this issue can be closed. Everything is working fine now. ",hi sorry testing took turned wrong version hence issue closed everything working fine,issue,negative,negative,negative,negative,negative,negative
544203820,"@devbas Can you please document what version of the source code you are using ?
Also, I see no setup step documenting creation of a `virtualenv` etc., so it's hard to diagnose. This code is exercised successfully in CI, but after 0.5.1.

Current code is: https://github.com/mozilla/DeepSpeech/blob/469ddd2cf7e96beb53a45ddd741718b9bce0bdf5/examples/vad_transcriber/wavTranscriber.py#L24 with three arguments

Older code is: https://github.com/mozilla/DeepSpeech/blob/v0.5.1/examples/vad_transcriber/wavTranscriber.py#L26 with five arguments.

The line number in the stack matches current code. The error would be consistent with running current code against older version of deepspeech python bindings.

The dependency is properly documented at: https://github.com/mozilla/DeepSpeech/blob/469ddd2cf7e96beb53a45ddd741718b9bce0bdf5/examples/vad_transcriber/requirements.txt#L1

Please make sure you are running against the proper version.",please document version source code also see setup step creation hard diagnose code successfully current code three older code five line number stack current code error would consistent running current code older version python dependency properly please make sure running proper version,issue,positive,positive,neutral,neutral,positive,positive
544118070,"I'm going to close it then, we can still fix the C++ client but if the leak in the lib is fixed it's the most important :)",going close still fix client leak fixed important,issue,negative,positive,positive,positive,positive,positive
544085038,"Thanks @lissyx 

Using :
**TensorFlow:** v1.14.0-16-g3b4ce374f5
**DeepSpeech:** v0.6.0-alpha.10-2-g469ddd2

 First run 53MB, last run 45MB.(.Net client)

I can confirm that issue is fixed for the .Net client.

Testing with Python and C++ client, looks like the C++ client is not releasing completely.
",thanks first run last run client confirm issue fixed client testing python client like client completely,issue,positive,positive,positive,positive,positive,positive
544038240,"@lissyx I'm using `deepspeech = ""==0.5.1""`. I see the issue. I was following the https://github.com/mozilla/DeepSpeech/blob/master/native_client/python/client.py#L71 file which is missing the `N_FEATURES`",see issue following file missing,issue,negative,negative,neutral,neutral,negative,negative
543912852,"@shamoons The Python API mostly directly maps to the C one, e.g., for `Model` look at https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/deepspeech.h#L57-L78 and for `stt` look at https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/deepspeech.h#L110-L126

You can see example usage in https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/python/client.py#L115, e.g., where `fs` is the sample rate.",python mostly directly one model look look see example usage sample rate,issue,negative,positive,neutral,neutral,positive,positive
543911619,"@shamoons Could you please clearly indicate what version of DeepSpeech you are using ? This does not make any sense, we don't have keywords arguments, as you can see on https://github.com/mozilla/DeepSpeech/blob/v0.5.1/native_client/python/client.py#L88 and sample rate is not an argument of `Model` either, so I don't understand where your `TypeError` comes from.",could please clearly indicate version make sense see sample rate argument model either understand come,issue,negative,positive,positive,positive,positive,positive
543773135,"@alokprasad For the sake of reproductibility, could you share your trimmed and trimmed+fixed audio samples ?",sake could share audio,issue,negative,neutral,neutral,neutral,neutral,neutral
543653452,i'm keeping that open until @carlfm01 can confirm this is fixed,keeping open confirm fixed,issue,negative,positive,neutral,neutral,positive,positive
543591202,"@carlfm01 Can you try on your side ? This does improve the situation for me:
```
$ tail -n 10 leaks.2.log 
==24472== LEAK SUMMARY:
==24472==    definitely lost: 24 bytes in 1 blocks
==24472==    indirectly lost: 214 bytes in 5 blocks
==24472==      possibly lost: 0 bytes in 0 blocks
==24472==    still reachable: 8,143 bytes in 134 blocks
==24472==                       of which reachable via heuristic:
==24472==                         stdstring          : 2,180 bytes in 58 blocks
==24472==         suppressed: 0 bytes in 0 blocks
==24472== 
==24472== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
$ tail -n 10 leaks.3.log 
==24557== LEAK SUMMARY:
==24557==    definitely lost: 0 bytes in 0 blocks
==24557==    indirectly lost: 0 bytes in 0 blocks
==24557==      possibly lost: 0 bytes in 0 blocks
==24557==    still reachable: 8,143 bytes in 134 blocks
==24557==                       of which reachable via heuristic:
==24557==                         stdstring          : 2,180 bytes in 58 blocks
==24557==         suppressed: 0 bytes in 0 blocks
==24557== 
==24557== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```",try side improve situation tail log leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed error summary suppressed tail log leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed error summary suppressed,issue,negative,neutral,neutral,neutral,neutral,neutral
543573455,"> I've had the same issue on Ubuntu, redhat and with the Dockerfile. Could be an issue with the latest CV dataset perhaps.

We had no issue with the latest Common Voice dataset. How are you running things ?",issue could issue latest perhaps issue latest common voice running,issue,negative,positive,positive,positive,positive,positive
543552195,"I've had the same issue on Ubuntu, redhat and with the Dockerfile. Could be
an issue with the latest CV dataset perhaps.

On Fri, 18 Oct. 2019, 5:45 pm lissyx, <notifications@github.com> wrote:

> @Murcurio <https://github.com/Murcurio> We have had no issue with UTF-8,
> this is likely your system ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/pull/2447?email_source=notifications&email_token=AINGOBBBF3SDKVWHE2ZZ4VLQPFLO3A5CNFSM4JCBQJYKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBS52OY#issuecomment-543546683>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AINGOBALJ5I35I2QGDVG453QPFLO3ANCNFSM4JCBQJYA>
> .
>
",issue could issue latest perhaps wrote issue likely system reply directly view,issue,negative,positive,positive,positive,positive,positive
543278771,"@carlfm01 I'm having more doubts (and @reuben shares this as well) against `dictionary_` there, which is `std::unique_ptr<>` in `native_client/ctcdecode/scorer.h` and that we `->Copy(true)` in `native_client/ctcdecode/ctc_beam_search_decoder.cpp`. This `Copy()` call triggers a `new` behind.",well copy true copy call new behind,issue,positive,positive,neutral,neutral,positive,positive
543269594,"> Yes, I am using Mozilla's TensorFlow ``r1.14` branch <https://github.com/mozilla/tensorflow/tree/r1.14>`_ as documented there, and my deepspeech version is 0.5.1...

Then use `r1.13`, as documented for `v0.5.1`",yes branch version use,issue,negative,neutral,neutral,neutral,neutral,neutral
543257483,"Yes, I am using Mozilla's TensorFlow ``r1.14` branch <https://github.com/mozilla/tensorflow/tree/r1.14>`_ as documented there, and my deepspeech version is 0.5.1...

I succeed to build the 'generate_trie' binary, but when I attempt to build 'libdeepspeech.so' this error occurs...!!!",yes branch version succeed build binary attempt build error,issue,negative,neutral,neutral,neutral,neutral,neutral
543251577,"@carlfm01 Long-shot, but doing so does not seems to trigger issues here:
```
diff --git a/native_client/ctcdecode/path_trie.cpp b/native_client/ctcdecode/path_trie.cpp
index 51f75ff..dee792d 100644
--- a/native_client/ctcdecode/path_trie.cpp
+++ b/native_client/ctcdecode/path_trie.cpp
@@ -33,6 +33,8 @@ PathTrie::~PathTrie() {
   for (auto child : children_) {
     delete child.second;
   }
+
+  matcher_ = nullptr;
 }
 
 PathTrie* PathTrie::get_path_trie(int new_char, int new_timestep, float cur_log_prob_c, bool reset) {
```

This should make sure that any `PathTrie` destruction frees the matching allocation of `matcher_`.",trigger git index deed auto child delete float bool reset make sure destruction matching allocation,issue,negative,positive,positive,positive,positive,positive
543248457,"@araf-hasan15 Are you using `mozilla/tensorflow` repository with matching branch as documented? Also, you don't document what version of deepspeech you are trying to build.",repository matching branch also document version trying build,issue,negative,neutral,neutral,neutral,neutral,neutral
543045318,"> Do you think you can investigate why the destructor is not called ?

Yes, I'm already trying to spot the issue, but due to my newbie eyes for C++ I'm not making any significant progress.

The only thing that seems wrong apart from the destructor of `MappedFile ` never called is the destructor of `ConstFstImpl` only called for the first run, then never again. I want to see if this happens also on Linux. 




> scoped, is it possible we are missing something at a upper level?

Upper `ConstFstImpl` is `ConstFst` which is used for PathTrie as `FstType` I sort of feel the issue is coming from `PathTrie` and the usage of `share_ptr`: 
https://github.com/mozilla/DeepSpeech/blob/336daa1641b8a0bb6c02befa69b2b68b84161338/native_client/ctcdecode/path_trie.cpp#L83

¿What do you think?",think investigate destructor yes already trying spot issue due making significant progress thing wrong apart destructor never destructor first run never want see also possible missing something upper level upper used sort feel issue coming usage think,issue,negative,negative,neutral,neutral,negative,negative
543033759,"@lissyx Thank you for your reply! As you said, this is the problem that I haven't changed to the proper tag. I tried to change to the v0.5.1 tag with 
`git checkout v0.5.1` 
but in fact, this turns me into the v0.5.1 branch. Finally, I get this
`git checkout tags/v.0.5.1`
worked!
",thank reply said problem proper tag tried change tag git fact turn branch finally get git worked,issue,negative,neutral,neutral,neutral,neutral,neutral
543031739,"@Vampsj This is classic symptom of `tensorflow-gpu==1.13.1` when using current master and not `v0.5.1`, please ensure you are on the proper tag correctly checked out.",classic symptom current master please ensure proper tag correctly checked,issue,positive,positive,neutral,neutral,positive,positive
542820005,"@tusharrakshe Can you ensure you are on proper commit, with clean index ?",ensure proper commit clean index,issue,positive,positive,positive,positive,positive,positive
542707460,"> with my full path to the `cl.exe` of my VS and then running `vcvars64` before the `make` command

Right, reminds me of things I had to do on TaskCluster. I assumed that on developper systems, this should be already dealt with.



> > Can you replicate with the C++ basic client ?
> 
> Yes, is eating the same amount of memory as the .Net client.

Good, at least confirms it's not coming from the bindings. Do you think you can investigate why the destructor is not called ?

We have some code that triggers some lost but still reachable memory under valgrind on linux, and it deals with what calls this, so I'm wondering if this is not the root cause indeed, and we are just more lucky / going through another path on linux to free ?",full path running make command right assumed already dealt replicate basic client yes eating amount memory client good least coming think investigate destructor code lost still reachable memory wondering root cause indeed lucky going another path free,issue,positive,positive,positive,positive,positive,positive
542646814,"> So you mean to say, I cannot fine tune model from released checkpoints.

No, I am saying that you are not on git tag v0.5.1, and that the released checkpoints will only work on it.",mean say fine tune model saying git tag work,issue,negative,positive,neutral,neutral,positive,positive
542646318,"So you mean to say, I cannot fine tune model from released checkpoints. ",mean say fine tune model,issue,negative,positive,neutral,neutral,positive,positive
542645092,"> Yes . Already on 'v0.5.1'

CuDNN training support was added after v0.5.1, so it makes no sense.",yes already training support added sense,issue,positive,neutral,neutral,neutral,neutral,neutral
542639010,"> yes I am doing fine tuning from v0.5.1. If checkpoint is not compatible then how can i fine train model on new dataset.

Your error means you are using checkpoint v0.5.1 from a different tag than v0.5.1 of the code. Please `git checkout v0.5.1`.",yes fine tuning compatible fine train model new error different tag code please git,issue,positive,positive,positive,positive,positive,positive
542638762,yes I am doing fine tuning from v0.5.1. If checkpoint is not compatible then how can i fine train model on new dataset.,yes fine tuning compatible fine train model new,issue,positive,positive,positive,positive,positive,positive
542585076,(On master this would go into TRAINING.rst rather than README.md),master would go rather,issue,negative,neutral,neutral,neutral,neutral,neutral
542467441,"Just realized I wasted my time, Bazel is not detecting changes inside header files :), manually removed the` fst.obj` under `_objs` and now I see the execution path printed (With this I was trying to see where is mapped-file allocated but not released).

Bazel version: **0.24.1**

At this point I don't know which changes were applied for the tests, testing again... :/



Now about the C++ basic client:

> Can you replicate with the C++ basic client ?

Yes, is eating the same amount of memory as the .Net client.

> `make: \bin\amd64\cl.exe: Command not found`

solved this by replacing :

https://github.com/mozilla/DeepSpeech/blob/5fa6d23782d894346e7671a86f4ebdb92998698b/native_client/definitions.mk#L39

with my full path to the `cl.exe` of my VS and then running `vcvars64` before the `make` command



",wasted time inside header manually removed see execution path printed trying see version point know applied testing basic client replicate basic client yes eating amount memory client make command found full path running make command,issue,negative,positive,neutral,neutral,positive,positive
542443544,"hi @reuben what data were you trying with? I did training with the full Common Voice training dataset and got largely similar results (i.e. loss) with and w/o AMP on Tensorflow-GPU 1.14.0 on a V100 GPU:

w/o AMP: `I Early stop triggered as (for last 4 steps) validation loss: 151.621022 with standard deviation: 0.084157 and mean: 151.590638
I FINISHED optimization in 21:30:26.464164`

with AMP: `I Early stop triggered as (for last 4 steps) validation loss: 151.553078 with standard deviation: 0.029790 and mean: 151.706624
I FINISHED optimization in 11:59:06.455024`",hi data trying training full common voice training got largely similar loss early stop triggered last validation loss standard deviation mean finished optimization early stop triggered last validation loss standard deviation mean finished optimization,issue,negative,negative,neutral,neutral,negative,negative
542174964,Looks like I also forgot to purge the caches. Reran the tasks.,like also forgot purge,issue,negative,neutral,neutral,neutral,neutral,neutral
542170940,In my tests this is changing the training behavior even on my laptop without any GPUs and tensorflow (instead of tensorflow-gpu) installed. Here's the loss development log with and without the flag specified with `./bin/run-ldc39s1.sh`. https://gist.github.com/reuben/fe1d4858f2a98238d244e9db10ad428e,training behavior even without instead loss development log without flag,issue,negative,neutral,neutral,neutral,neutral,neutral
542138330,Looks like all green. The macOS failure is due to breaking changes in Homebrew formulas.,like green failure due breaking,issue,negative,negative,negative,negative,negative,negative
542084418,"Perfect, thanks for the update. So worst case you can train on GPUs and just export after. Make sure you keep in sync of versions. Can we close this? ",perfect thanks update worst case train export make sure keep sync close,issue,positive,positive,positive,positive,positive,positive
542021377,"I was able to run successfully on sample ldc93s1 dataset on virtual environment.

```
$ python3 DeepSpeech.py --n_hidden 256 --learning_rate 0.00001 --epochs 1 --export_tflite --export_dir data/modelgen_ldc93s1 --train_files data/ldc93s1/ldc93s1.csv --dev_files data/ldc93s1/ldc93s1.csv  --test_files data/ldc93s1/ldc93s1.csv

W1014 20:39:51.526147 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W1014 20:39:51.665138 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
W1014 20:39:51.665330 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
W1014 20:39:51.665493 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
W1014 20:39:53.206499 4551407040 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1014 20:39:53.208698 4551407040 deprecation.py:506] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1014 20:39:54.003494 4551407040 deprecation.py:323] From DeepSpeech.py:233: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1014 20:39:54.599544 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I1014 20:39:54.601692 4551407040 saver.py:1280] Restoring parameters from /Users/dhanesh/.local/share/deepspeech/checkpoints/train-2
I Restored variables from most recent checkpoint at /Users/dhanesh/.local/share/deepspeech/checkpoints/train-2, step 2
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 350.645477                                                                    
Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 348.510590 | Dataset: data/ldc93s1/ldc93s1.csv                                
I Saved new best validating model with loss 348.510590 to: /Users/dhanesh/.local/share/deepspeech/checkpoints/best_dev-3
I FINISHED optimization in 0:00:02.681611
I1014 20:39:57.697541 4551407040 saver.py:1280] Restoring parameters from /Users/dhanesh/.local/share/deepspeech/checkpoints/best_dev-3
I Restored variables from best validation checkpoint at /Users/dhanesh/.local/share/deepspeech/checkpoints/best_dev-3, step 3
Testing model on data/ldc93s1/ldc93s1.csv
Test epoch | Steps: 1 | Elapsed Time: 0:00:01                                                                                                 
Test on data/ldc93s1/ldc93s1.csv - WER: 1.000000, CER: 0.865385, loss: 348.510590
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.865385, loss: 348.510590
 - wav: file:///Users/dhanesh/learning/DeepSpeech/data/ldc93s1/LDC93S1.wav
 - src: ""she had your dark suit in greasy wash water all year""
 - res: ""cincinnati cachinnation cincinnati cincinnati""
--------------------------------------------------------------------------------
I Exporting the model...
W1014 20:39:59.277595 4551407040 deprecation_wrapper.py:119] From DeepSpeech.py:690: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.

W1014 20:39:59.316530 4551407040 deprecation.py:323] From DeepSpeech.py:129: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.
W1014 20:39:59.352936 4551407040 deprecation.py:323] From DeepSpeech.py:139: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API
W1014 20:39:59.365869 4551407040 deprecation.py:506] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I1014 20:40:00.327216 4551407040 saver.py:1280] Restoring parameters from /Users/dhanesh/.local/share/deepspeech/checkpoints/train-3
W1014 20:40:00.368676 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1014 20:40:00.368858 4551407040 deprecation.py:323] From /Users/dhanesh/anaconda3/envs/machinelearning/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
I1014 20:40:00.399153 4551407040 graph_util_impl.py:311] Froze 12 variables.
I1014 20:40:00.417529 4551407040 graph_util_impl.py:364] Converted 12 variables to const ops.
I Exported model for TF Lite engine as output_graph.tflite
I Models exported at data/modelgen_ldc93s1
```

Now, I need to check on my GPU system, with a clean deepspeech setup. Thanks @lissyx ",able run successfully sample virtual environment python removed future version instead two available python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape semantics differentiable stateful argument making stateful removed future version use removed future version use removed future version use module included information please see related depend functionality listed please file issue calling removed future version call instance argument instead passing constructor removed future version use broadcast rule removed future version use standard file check prefix recent step starting optimization epoch training time loss epoch validation time loss saved new best model loss finished optimization best validation step testing model test epoch time test wer loss wer loss file dark suit greasy wash water year cachinnation model name please use instead removed future version class equivalent removed future version please use cell equivalent calling removed future version call instance argument instead passing constructor removed future version use removed future version use froze converted model lite engine need check system clean setup thanks,issue,positive,positive,positive,positive,positive,positive
542019620,"Hello @lissyx, unfortunately not, last week was a busy week working on TTS. I tried with short time windows but did not get any luck.

I'm back to it :) ",hello unfortunately last week busy week working tried short time get luck back,issue,negative,positive,neutral,neutral,positive,positive
541805713,"> FileNotFoundError: [Errno 2] No such file or directory: 'sox'

As documented, you need to install the `sox` binary.



> Also - why would it try to resample?

The error is already stating: you are feeding 48kHz to a 16kHz model.",file directory need install binary also would try resample error already feeding model,issue,negative,neutral,neutral,neutral,neutral,neutral
541755835,"> > yes I'll test the basic C++ client,
> 
> Dealing with `make: \bin\amd64\cl.exe: Command not found`, I'll read the cluster examples again and try carefully.

Have you been able to sort this out?",yes test basic client dealing make command found read cluster try carefully able sort,issue,negative,positive,positive,positive,positive,positive
541711443,I recommend reviewing this PR commit by commit as they're logically split between individual fixes.,recommend commit commit logically split individual,issue,positive,positive,positive,positive,positive,positive
541705554,"Hi @reuben 

> Thanks for the PR! Can you restore/continue training a mixed precision training checkpoint with mixed precision training disabled?

FP32 and AMP checkpoints are incompatible as there are graph edits carried out by graph rewrite, e.g. type casting nodes. So in my experience, it's not possible to cross-load and retrain in the most straightforward way.  

> 
> And some minor questions:
> 
>     1. In TF2.0 this API is incompatible with `tf.GradientTape`. Do you know if `tf.GradientTape` will be supported in the near term? We would need it for multi-GPU learning with a custom training loop.

Yes tf.GradientTape is supported. See an example of CTL in the TF model zoo for NCF https://github.com/tensorflow/models/pull/7436/files

>     2. Is there any way to know if the API actually did anything? E.g. for logging a diagnostic message.

Usually the API prints out some statistics such as how many nodes it has converted. In case of DeepSpeech, I haven't seen such report though. (But when trying to load from an FP32 checkpoint it will complain).",hi thanks training mixed precision training mixed precision training disabled incompatible graph carried graph rewrite type casting experience possible retrain straightforward way minor incompatible know near term would need learning custom training loop yes see example model zoo way know actually anything logging diagnostic message usually statistic many converted case seen report though trying load complain,issue,negative,positive,neutral,neutral,positive,positive
541695593,"Thanks for the PR! Can you restore/continue training a mixed precision training checkpoint with mixed precision training disabled?

And some minor questions:
1. In TF2.0 this API is incompatible with `tf.GradientTape`. Do you know if `tf.GradientTape` will be supported in the near term? We would need it for multi-GPU learning with a custom training loop.
2. Is there any way to know if the API actually did anything? E.g. for logging a diagnostic message.",thanks training mixed precision training mixed precision training disabled minor incompatible know near term would need learning custom training loop way know actually anything logging diagnostic message,issue,negative,positive,neutral,neutral,positive,positive
541329208,"I see. the pip install deepspeech installs 0.6.0 instead
",see pip install instead,issue,negative,neutral,neutral,neutral,neutral,neutral
541325752,"The error message:

> Specified model file version (0) is incompatible with minimum version supported by this client (3)

hopefully indicates the problem; you need an older client. In particular the 0.5.1 client to work with the 0.5.1 model. Currently, this should be the client installed with say a `pip install`.",error message model file version incompatible minimum version client hopefully problem need older client particular client work model currently client say pip install,issue,negative,positive,positive,positive,positive,positive
541102104,"For merging on master we probably want at least some basic tests that exercise the transfer learning code. It doesn't have to provide anything useful, just run without crashing so we know if we break it. You can extend the existing training tests (taskcluster/tc-train-tests.sh) for this.",master probably want least basic exercise transfer learning code provide anything useful run without know break extend training,issue,negative,neutral,neutral,neutral,neutral,neutral
541006581,"@MetaDhanesh So, I could train and export with your dataset:
```
INFO:tensorflow:Froze 12 variables.
I1011 12:08:48.784405 140341354239808 graph_util_impl.py:311] Froze 12 variables.
INFO:tensorflow:Converted 12 variables to const ops.
I1011 12:08:48.791962 140341354239808 graph_util_impl.py:364] Converted 12 variables to const ops.
I Exported model for TF Lite engine as output_graph.tflite
I Models exported at model_issue2414/
(tf-venv) alexandre@serveur:~/Documents/codaz/Mozilla/DeepSpeech/DeepSpeech-lissyx$ ll model_issue2414/
total 4,2M
drwxr-xr-x 1 alexandre alexandre   68 oct.  11 12:08 .
drwxr-xr-x 1 alexandre alexandre 2,3K oct.  11 12:02 ..
-rw-r--r-- 1 alexandre alexandre 3,3M oct.  11 12:07 output_graph.pb
-rw-r--r-- 1 alexandre alexandre 902K oct.  11 12:08 output_graph.tflite
```

This is definitively an issue on your side.

If you are required to use Jupyter for accessing the GPU, maybe you could:
 - Run the training without `--export_tflite` but with `--checkpoint_dir x` with `x` a directory
 - Then you setup a clean virtualenv, with `tensorflow` and not `tensorflow-gpu`, and from there you can reload the checkpoint and just perform `--export_tflite`

If there's something badly interacting that is related to the Python/Jupyter setup, this could help.",could train export froze froze converted converted model lite engine total definitively issue side use maybe could run training without directory setup clean reload perform something badly related setup could help,issue,negative,positive,positive,positive,positive,positive
540995525,">  However, I am using GPU as shared resource which is accessible only through notebook

If you can reproduce the issue with LDC93S1 dataset (please, ensure you don't have stale checkpoint), you don't need a GPU ...",however resource accessible notebook reproduce issue please ensure stale need,issue,positive,negative,neutral,neutral,negative,negative
540994927,"@MetaDhanesh But in the meantime you can get a clean env, can you at least make sure you test without a stale checkpoint? Your last error is likely because of that ...",get clean least make sure test without stale last error likely,issue,positive,positive,neutral,neutral,positive,positive
540991997,"> Also, I changed the google dataset's file structure so that I can bring all of audio files into one directory. And since multiple files had same names under different sub-directories, I changed the file names. And hence the confusion.
> 
> Changed dataset link is here: [google65k](https://we.tl/t-DUbfsKwRi3)

Ok, I will retry with those and let you know.",also file structure bring audio one directory since multiple different file hence confusion link retry let know,issue,negative,neutral,neutral,neutral,neutral,neutral
540991251,"> @lissyx
> I understand the need for clean python virtualenv. However, I am using GPU as shared resource which is accessible only through notebook. I am looking for a workaround whereby i can run it through clean python env.

Unless you reproduce under a proper clean env, I guess we'll be unable to help. It's 99.99% likely to be an issue on your system. Maybe because of CentOS, I don't know ...",understand need clean python however resource accessible notebook looking whereby run clean python unless reproduce proper clean guess unable help likely issue system maybe know,issue,positive,positive,positive,positive,positive,positive
540989366,"@lissyx 
I understand the need for clean python virtualenv. However, I am using GPU as shared resource which is accessible only through notebook. I am looking for a workaround whereby i can run it through clean python env.

Also, I changed the google dataset's file structure so that I can bring all of audio files into one directory. And since multiple files had same names under different sub-directories, I changed the file names. And hence the confusion.

Changed dataset link is here: [google65k](https://we.tl/t-DUbfsKwRi3)",understand need clean python however resource accessible notebook looking whereby run clean python also file structure bring audio one directory since multiple different file hence confusion link,issue,negative,positive,positive,positive,positive,positive
540950457,the failure is just an temp cache issue on one of the macOS workers,failure temp cache issue one,issue,negative,negative,negative,negative,negative,negative
540950138,@reuben Oh we need to fix the workaround I implemented back then with `DEEPSPEECH_MODEL`: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/examples-base.tyml#L33,oh need fix back,issue,negative,neutral,neutral,neutral,neutral,neutral
540767024,One less hard-coded constant in application code :),one le constant application code,issue,negative,neutral,neutral,neutral,neutral,neutral
540761976,"@mone27 Oh, you mean the **README.md** link in **TRAINING.rst** is broken",mone oh mean link broken,issue,negative,negative,negative,negative,negative,negative
540761583,"> In Training.rst the link at README.md under [https://github.com/mozilla/DeepSpeech/blob/master/TRAINING.rst#exporting-a-model-for-inference] is broken

Can you elaborate @mone27 ? Because it's working for me ...",link broken elaborate mone working,issue,negative,positive,neutral,neutral,positive,positive
540670914,"> I Restored variables from most recent checkpoint at /home/jupyter/.local/share/deepspeech/checkpoints/train-251862, step 251862

It looks like you have not cleaned up something as well. Please ensure you restart and verify from a clean state.

Also @MetaDhanesh I really need you to reproduce under a clean Python virtualenv and not under some Jupyter or anaconda binary. We have had errors due to that in the past.",recent step like something well please ensure restart verify clean state also really need reproduce clean python anaconda binary due past,issue,positive,positive,neutral,neutral,positive,positive
540667342,"@lissyx 
As suggested by you, I ran the following command:
```
./DeepSpeech.py --n_hidden 256 --learning_rate 0.00001 --epochs 1 --export_tflite --export_dir /data/modelgen_ldc93s1 --train_files /data/ldc93s1/ldc93s1.csv --dev_files /data/ldc93s1/ldc93s1.csv  --test_files /data/ldc93s1/ldc93s1.csv

```

However, I got another issue (ZeroDivisionError):
```
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/libs/base/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/jupyter/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From ./DeepSpeech.py:832: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /data/DeepSpeech/util/config.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

W1010 05:29:49.026217 140177034217280 deprecation_wrapper.py:119] From /data/DeepSpeech/util/config.py:60: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From ./DeepSpeech.py:814: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

W1010 05:29:49.031841 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:814: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ./DeepSpeech.py:815: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

W1010 05:29:49.032057 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:815: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
W1010 05:29:49.051225 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
WARNING:tensorflow:From /data/DeepSpeech/util/feeding.py:45: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

W1010 05:29:49.079966 140177034217280 deprecation_wrapper.py:119] From /data/DeepSpeech/util/feeding.py:45: The name tf.read_file is deprecated. Please use tf.io.read_file instead.

WARNING:tensorflow:From ./DeepSpeech.py:375: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

W1010 05:29:49.134636 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:375: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

WARNING:tensorflow:From ./DeepSpeech.py:375: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
W1010 05:29:49.134779 140177034217280 deprecation.py:323] From ./DeepSpeech.py:375: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
WARNING:tensorflow:From ./DeepSpeech.py:376: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
W1010 05:29:49.134902 140177034217280 deprecation.py:323] From ./DeepSpeech.py:376: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
WARNING:tensorflow:From ./DeepSpeech.py:377: DatasetV1.output_classes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(dataset)`.
W1010 05:29:49.135006 140177034217280 deprecation.py:323] From ./DeepSpeech.py:377: DatasetV1.output_classes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(dataset)`.
WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
W1010 05:29:49.137027 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
W1010 05:29:49.137253 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
W1010 05:29:49.137372 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
WARNING:tensorflow:From ./DeepSpeech.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W1010 05:29:49.216144 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:388: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ./DeepSpeech.py:211: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

W1010 05:29:49.219480 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:211: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1010 05:29:49.431784 140177034217280 deprecation.py:506] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From ./DeepSpeech.py:192: The name tf.nn.ctc_loss is deprecated. Please use tf.compat.v1.nn.ctc_loss instead.

W1010 05:29:50.208915 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:192: The name tf.nn.ctc_loss is deprecated. Please use tf.compat.v1.nn.ctc_loss instead.

WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1010 05:29:50.260857 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ./DeepSpeech.py:273: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

W1010 05:29:50.852802 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:273: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From ./DeepSpeech.py:332: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

W1010 05:29:50.927818 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:332: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.

WARNING:tensorflow:From ./DeepSpeech.py:410: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W1010 05:29:51.137559 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:410: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From ./DeepSpeech.py:414: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

W1010 05:29:51.293362 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:414: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From ./DeepSpeech.py:416: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

W1010 05:29:51.294395 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:416: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

WARNING:tensorflow:From ./DeepSpeech.py:421: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W1010 05:29:51.299693 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:421: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W1010 05:29:51.413674 140177034217280 deprecation.py:323] From /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /home/jupyter/.local/share/deepspeech/checkpoints/train-251862
I1010 05:29:51.430413 140177034217280 saver.py:1280] Restoring parameters from /home/jupyter/.local/share/deepspeech/checkpoints/train-251862
WARNING:tensorflow:From ./DeepSpeech.py:357: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1010 05:29:52.337543 140177034217280 deprecation_wrapper.py:119] From ./DeepSpeech.py:357: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

I Restored variables from most recent checkpoint at /home/jupyter/.local/share/deepspeech/checkpoints/train-251862, step 251862
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:02 | Steps: 0 | Loss: 0.000000       
Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: /data/ldc93s1/ldc93s1.csv
Traceback (most recent call last):
  File ""./DeepSpeech.py"", line 832, in <module>
    tf.app.run(main)
  File ""/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/jupyter/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/jupyter/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""./DeepSpeech.py"", line 816, in main
    train()
  File ""./DeepSpeech.py"", line 527, in train
    dev_loss = dev_loss / total_steps
ZeroDivisionError: float division by zero
```

Based on the info given in this discourse [link](https://discourse.mozilla.org/t/which-tensorflow-cuda/37976/6), I checked my csv file too.

```
(nb_env) bash-4.2$ pwd
/data/ldc93s1
(nb_env) bash-4.2$ ls
ldc93s1.csv  LDC93S1.txt  LDC93S1.wav
(nb_env) bash-4.2$ cat ldc93s1.csv
wav_filename,wav_filesize,transcript
/data/ldc93s1/LDC93S1.wav,93638,she had your dark suit in greasy wash water all year
```",ran following command however got another issue passing type synonym type future version understood type type passing type synonym type future version understood type type quint passing type synonym type future version understood type type passing type synonym type future version understood type type quint passing type synonym type future version understood type type passing type synonym type future version understood type type resource conversion second argument float future float import passing type synonym type future version understood type type passing type synonym type future version understood type type quint passing type synonym type future version understood type type passing type synonym type future version understood type type quint passing type synonym type future version understood type type passing type synonym type future version understood type type resource warning name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning removed future version instead two available python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape semantics differentiable stateful argument making stateful removed future version instead two available python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape semantics differentiable stateful argument making stateful warning name please use instead name please use instead warning name please use instead name please use instead warning removed future version use removed future version use warning removed future version use removed future version use warning removed future version use removed future version use warning removed future version use removed future version use warning removed future version use removed future version use warning removed future version use removed future version use warning name please use instead name please use instead warning name please use instead name please use instead warning calling removed future version call instance argument instead passing constructor calling removed future version call instance argument instead passing constructor warning name please use instead name please use instead warning removed future version use broadcast rule removed future version use broadcast rule warning name please use instead name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning name please use instead name please use instead warning removed future version use standard file check prefix removed future version use standard file check prefix warning name please use instead name please use instead recent step starting optimization epoch training time loss epoch validation time loss recent call last file line module main file line run file line run main file line main file line main train file line train float division zero based given discourse link checked file cat transcript dark suit greasy wash water year,issue,positive,positive,neutral,neutral,positive,positive
540480712,"> yes I'll test the basic C++ client,

Dealing with `make: \bin\amd64\cl.exe: Command not found`, I'll read the cluster examples again and try carefully.
",yes test basic client dealing make command found read cluster try carefully,issue,negative,negative,neutral,neutral,negative,negative
540460633,"> [training_csv_files.zip](https://github.com/mozilla/DeepSpeech/files/3710488/training_csv_files.zip)
> 
> I am storing the audio files and csv files (train, dev, test) in `/data/training65kgoogle`

I'm sorry, but those CSV files seems not to be for this dataset, it does not contains the same directories, and files referenced inside do not exists in the linked data.

@MetaDhanesh I really need you to share me reproductible data. And to cross-check on your side with the LDC93S1 sample, to verify that you can perform the export.",audio train dev test sorry inside linked data really need share data side sample verify perform export,issue,negative,negative,negative,negative,negative,negative
540392227,"@MetaDhanesh Please, take a few minutes to reproduce the issue with LDC93S1, it is very important to ensure your system works as intended.

The error you are facing is from within LLVM tooling of the TOCO converter, so it's very very highly unlikely that our code is at fault here.",please take reproduce issue important ensure system work intended error facing within tooling toco converter highly unlikely code fault,issue,negative,negative,neutral,neutral,negative,negative
540384368,"> like I said, I'm new here. can u make me understand about it? how to solve the problem I'm facing?

Being new does not allow you to use Github for support. The problem you are facing is documented in the link I shared earlier.



> I have the alphabet.txt & output graph.pb file how can I generate the lm & trie file for my native language model? can u help me out, please?

Again, please read the documentation.",like said new make understand solve problem facing new allow use support problem facing link output file generate file native language model help please please read documentation,issue,positive,positive,positive,positive,positive,positive
540377892,This is not a bug. Support should be done on discourse. Please read the documentation and the error : you cannot use 0.5.1 model with 0.6 binaries. ,bug support done discourse please read documentation error use model,issue,negative,neutral,neutral,neutral,neutral,neutral
540348912,"[training_csv_files.zip](https://github.com/mozilla/DeepSpeech/files/3710488/training_csv_files.zip)

I am storing the audio files and csv files (train, dev, test) in `/data/training65kgoogle`",audio train dev test,issue,negative,neutral,neutral,neutral,neutral,neutral
540269254,"@nmstoker I got this half finished, then I got tied up with other things. But since then a lot of significant structural changes have been made on master, so it seems like maybe it’s actually simpler to just redo it from scratch.

I should have time within the next week or two to look at it again.",got half finished got tied since lot significant structural made master like maybe actually simpler redo scratch time within next week two look,issue,positive,positive,neutral,neutral,positive,positive
540186483,"After installing 0.6.0a8 I am met with this issue:
```error
(deepspeech-venv) pi@raspberrypi:~ $ deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav
Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
TensorFlow: v1.14.0-16-g3b4ce37
DeepSpeech: v0.6.0-alpha.8-0-gf0e9541
ERROR: Model provided has model identifier '▒x;', should be 'TFL3'

Error at reading model file deepspeech-0.5.1-models/output_graph.pbmm
Traceback (most recent call last):
  File ""/home/pi/tmp/deepspeech-venv/bin/deepspeech"", line 10, in <module>
    sys.exit(main())
  File ""/home/pi/tmp/deepspeech-venv/lib/python3.7/site-packages/deepspeech/client.py"", line 80, in main
    ds = Model(args.model, args.alphabet, BEAM_WIDTH)
  File ""/home/pi/tmp/deepspeech-venv/lib/python3.7/site-packages/deepspeech/__init__.py"", line 39, in __init__
    raise RuntimeError(""CreateModel failed with error code {}"".format(status))
RuntimeError: CreateModel failed with error code 12288
```",met issue error pi model alphabet audio loading model file error model provided model identifier error reading model file recent call last file line module main file line main model file line raise error code status error code,issue,negative,positive,neutral,neutral,positive,positive
540162812,"like I said, I'm new here. can u make me understand about it? how to solve the problem I'm facing?

I have the alphabet.txt & output graph.pb file how can I generate the lm &  trie file for my native language model? can u help me out, please?",like said new make understand solve problem facing output file generate file native language model help please,issue,positive,positive,positive,positive,positive,positive
540158194,"> is the lm.binary & trie file is already given in the repository data folder?& can i use it for any
> language?

Do you understand what you are doing ? Do you understand what the LM files are for ? Have you read the link ?",file already given repository data folder use language understand understand read link,issue,negative,neutral,neutral,neutral,neutral,neutral
540157854," is the lm.binary & trie file is already given in the repository data folder?& can i use it for any
 language?",file already given repository data folder use language,issue,negative,neutral,neutral,neutral,neutral,neutral
540156494,"what about the lm.binary & trie file?

sorry for the inconvenience, I'm new here. ",file sorry inconvenience new,issue,negative,negative,negative,negative,negative,negative
540154389,"This is not a bug, so please continue the discussion on Discourse.",bug please continue discussion discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
540154280,"> how can I get the rest of the 3 files? I'm using it for my native language.

Have you read the documentation ?

https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.rst

If you trained your own model, you should already have produced a valid `alphabet.txt`",get rest native language read documentation trained model already produced valid,issue,negative,neutral,neutral,neutral,neutral,neutral
540126027,"> Can you replicate with the C++ basic client ?

yes I'll test the basic C++ client, allow me some time to complete my builds and switch back to r1.14",replicate basic client yes test basic client allow time complete switch back,issue,positive,positive,neutral,neutral,positive,positive
540095302,"> When trying to import m-ailabs Spanish data using the import_m-ailabs.py, the url to the training data is broken. Is the tar file located somewhere else?

Can you be more exhaustive ? This is working for french, I think @tilmankamp verified with German as well.",trying import data training data broken tar file somewhere else exhaustive working think german well,issue,negative,negative,negative,negative,negative,negative
539993140,"> however, if there is a way to get it in backwards to 0.5.1, it would be nice.

The only way is for you to apply locally the patch on v0.5.1 tag.",however way get backwards would nice way apply locally patch tag,issue,negative,positive,positive,positive,positive,positive
539992774,"this works, however, if there is a way to get it in backwards to 0.5.1, it would be nice. Also, have a look at util/gpu_usage.py I think same logic applies there, but I don't have a gpu to test ATM",work however way get backwards would nice also look think logic test,issue,negative,positive,positive,positive,positive,positive
539979762,"@safa0 If you can check on your side, but that is working for me. This is logic we already had for the decoder anyway ...",check side working logic already anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
539950552,"> We optimize hyperparameters on the _dev_ set not the _test_ set.
> 
> We shouldn't optimize anything on the test set as any results we'd get then would be dishonest.

Oh, I get your point. I think you are right, since TOCO will use this to **optimize** we should definitively use the dev set.",optimize set set optimize anything test set get would dishonest oh get point think right since toco use optimize definitively use dev set,issue,positive,negative,neutral,neutral,negative,negative
539949975,"We optimize hyperparameters on the _dev_ set not the _test_ set.

We shouldn't optimize anything on the test set as any results we'd get then would be dishonest.",optimize set set optimize anything test set get would dishonest,issue,negative,negative,negative,negative,negative,negative
539948023,"Well, current we optimize the WER of the model that we export and then convert to TFLite. So, in this process, IMHO it makes more sense that the representative data set being used for the conversion is the test set, which is already supposed to be representative data set to evaluate model performance.",well current optimize wer model export convert process sense representative data set used conversion test set already supposed representative data set evaluate model performance,issue,positive,neutral,neutral,neutral,neutral,neutral
539942728,"> I guess I'm viewing this under the category of hyperparameters which should be optimized with the dev set.

Right, but I'm not sure we should act this way.",guess category dev set right sure act way,issue,negative,positive,positive,positive,positive,positive
539941751,I guess I'm viewing this under the category of hyperparameters which should be optimized with the dev set.,guess category dev set,issue,negative,neutral,neutral,neutral,neutral,neutral
539941074,"I would expect more bias from the dev set than the test set for that purpose, wouldn't we?",would expect bias dev set test set purpose would,issue,negative,neutral,neutral,neutral,neutral,neutral
539940775,Shouldn't we use the dev set if we're being honest?,use dev set honest,issue,positive,positive,positive,positive,positive,positive
539940029,We could use the training test set (complete ? reduced ?) for that purpose ? @kdavis-mozilla @reuben @tilmankamp ,could use training test set complete reduced purpose,issue,negative,positive,neutral,neutral,positive,positive
539934938,"@MetaDhanesh It looks like the CSV files you are referencing in your issue do not exists in the dataset released by Google at https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html

Can you please share complete STR so I can check whether this is from the dataset itself (I highly doubt it is ...).",like issue please share complete check whether highly doubt,issue,negative,positive,positive,positive,positive,positive
539933506,"@MetaDhanesh It's working on my system when using LDC93S1 sample:
```
(tf-venv) alex@portable-alex:~/codaz/Mozilla/DeepSpeech/deepspeech-kdavis$ python DeepSpeech.py --n_hidden 256 --learning_rate 0.00001 --epochs 1 --export_tflite --export_dir modelgen --train_files data/ldc93s1/ldc93s1.csv --dev_files data/ldc93s1/ldc93s1.csv  --test_files data/ldc93s1/ldc93s1.csv                                                                                       [1/1887]
W1009 12:04:24.991541 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.                                                                                                             
Instructions for updating:                                                
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.

W1009 12:04:25.041713 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
W1009 12:04:25.041825 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
W1009 12:04:25.041942 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
W1009 12:04:25.484676 140319504627520 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1009 12:04:25.486298 140319504627520 deprecation.py:506] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W1009 12:04:25.944385 140319504627520 deprecation.py:323] From DeepSpeech.py:232: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W1009 12:04:26.372065 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I1009 12:04:26.373267 140319504627520 saver.py:1280] Restoring parameters from /home/alex/.local/share/deepspeech/checkpoints/train-1
I Restored variables from most recent checkpoint at /home/alex/.local/share/deepspeech/checkpoints/train-1, step 1
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 354.431152
Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 352.015808 | Dataset: data/ldc93s1/ldc93s1.csv
I Saved new best validating model with loss 352.015808 to: /home/alex/.local/share/deepspeech/checkpoints/best_dev-2
I FINISHED optimization in 0:00:00.635227
I1009 12:04:27.238729 140319504627520 saver.py:1280] Restoring parameters from /home/alex/.local/share/deepspeech/checkpoints/best_dev-2
I Restored variables from best validation checkpoint at /home/alex/.local/share/deepspeech/checkpoints/best_dev-2, step 2
Testing model on data/ldc93s1/ldc93s1.csv
Test epoch | Steps: 1 | Elapsed Time: 0:00:00
Test on data/ldc93s1/ldc93s1.csv - WER: 1.000000, CER: 0.846154, loss: 352.015808
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.846154, loss: 352.015808
 - wav: file:///home/alex/codaz/Mozilla/DeepSpeech/deepspeech-kdavis/data/ldc93s1/LDC93S1.wav
 - src: ""she had your dark suit in greasy wash water all year""
 - res: ""cincinnati c'incominciammo chachachachacha""
--------------------------------------------------------------------------------
I Exporting the model...
W1009 12:04:27.707445 140319504627520 deprecation_wrapper.py:119] From DeepSpeech.py:678: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.

W1009 12:04:27.740257 140319504627520 deprecation.py:323] From DeepSpeech.py:128: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.
W1009 12:04:27.767323 140319504627520 deprecation.py:323] From DeepSpeech.py:138: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API
W1009 12:04:27.773589 140319504627520 deprecation.py:506] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
I1009 12:04:28.316096 140319504627520 saver.py:1280] Restoring parameters from /home/alex/.local/share/deepspeech/checkpoints/train-2
W1009 12:04:28.344184 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W1009 12:04:28.344364 140319504627520 deprecation.py:323] From /home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
I1009 12:04:28.362188 140319504627520 graph_util_impl.py:311] Froze 12 variables.
I1009 12:04:28.366831 140319504627520 graph_util_impl.py:364] Converted 12 variables to const ops.
/home/alex/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.7/site-packages/tensorflow/lite/python/lite.py:769: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.
  "" instead."" % name)
I Exported model for TF Lite engine as output_graph.tflite
I Models exported at modelgen
```
I'm going to test your dataset, can you cross-check on your side with LDC93S1 sample? See `bin/import_ldc93s1.py` and `data/ldc93s1/ldc93s1.csv`.",working system sample python removed future version instead two available python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape semantics differentiable stateful argument making stateful removed future version use removed future version use removed future version use module included information please see related depend functionality listed please file issue calling removed future version call instance argument instead passing constructor removed future version use broadcast rule removed future version use standard file check prefix recent step starting optimization epoch training time loss epoch validation time loss saved new best model loss finished optimization best validation step testing model test epoch time test wer loss wer loss file dark suit greasy wash water year model name please use instead removed future version class equivalent removed future version please use cell equivalent calling removed future version call instance argument instead passing constructor removed future version use removed future version use froze converted property please use instead name model lite engine going test side sample see,issue,positive,positive,positive,positive,positive,positive
539931968,"> /home/jupyter/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:769: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.
>   "" instead."" % name)
> Traceback (most recent call last):
>   File ""./DeepSpeech.py"", line 832, in <module>
>     tf.app.run(main)
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
>     _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
>     _run_main(main, args)
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
>     sys.exit(main(argv))
>   File ""./DeepSpeech.py"", line 824, in main
>     export()
>   File ""./DeepSpeech.py"", line 753, in export
>     tflite_model = converter.convert()
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 898, in convert
>     **converter_kwargs)
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 404, in toco_convert_impl
>     input_data.SerializeToString())
>   File ""/home/jupyter/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 172, in toco_convert_protos
>     ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
> tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
> /libs/base/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
>   from ._conv import register_converters as _register_converters
> Traceback (most recent call last):
>   File ""/home/jupyter/libraries/nb_env/bin/toco_from_protos"", line 11, in <module>
>     sys.exit(main())
>   File ""/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89, in main
>     app.run(main=execute, argv=[sys.argv[0]] + unparsed)
>   File ""/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
>     _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
>   File ""/libs/project/absl/app.py"", line 299, in run
>     _run_main(main, args)
>   File ""/libs/project/absl/app.py"", line 250, in _run_main
>     sys.exit(main(argv))
>   File ""/home/jupyter/libraries/nb_env/lib64/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52, in execute
>     enable_mlir_converter)
> ValueError: Input DebugInfo is invalid.

Obviously never hit that. I see references to Jupyter. Can you reproduce that with a pure Python virtualenv and no other overlay / wrapper?",property please use instead instead name recent call last file line module main file line run file line run main file line main file line main export file line export file line convert file line file line toco see console toco see console conversion second argument float future float import recent call last file line module main file line main unparsed file line run file line run main file line main file line execute input invalid obviously never hit see reproduce pure python overlay wrapper,issue,negative,positive,neutral,neutral,positive,positive
539929779,"FTR, I've come accross this work https://github.com/ina-foss/inaSpeechSegmenter that might be useful in this context.",come work might useful context,issue,negative,positive,positive,positive,positive,positive
539906187,"> The python binary v0.5.0 seems inconsistent and gave blank inference with a model trained on v0.5.0.

Indeed, v0.5.0 was bugged and v0.5.1 was a bugfix release.",python binary inconsistent gave blank inference model trained indeed release,issue,negative,neutral,neutral,neutral,neutral,neutral
539905624,"@lissyx : As you had suggested, python binary v0.5.1 worked well with a model trained on v0.5.0. 

The python binary v0.5.0 seems inconsistent and gave blank inference with a model trained on v0.5.0.

Thanks for the direction. I am closing the ticket.",python binary worked well model trained python binary inconsistent gave blank inference model trained thanks direction ticket,issue,positive,positive,neutral,neutral,positive,positive
539895638,"`MappedFile` as much as I can read in the windows part is all `std::unique_ptr<>` scoped, is it possible we are missing something at a upper level?",much read part possible missing something upper level,issue,negative,neutral,neutral,neutral,neutral,neutral
539888194,@AASHISHAG Could you update us on your status ?,could update u status,issue,negative,neutral,neutral,neutral,neutral,neutral
539877010,"> c# client.

Can you replicate with the C++ basic client ? Just to see if the .Net bindings could have a play in the equation.",client replicate basic client see could play equation,issue,negative,neutral,neutral,neutral,neutral,neutral
539876488,"> Just to make sure, this is not only when using the Python code, this is **always** ?

Yes always, with both, python client and the c# client.",make sure python code always yes always python client client,issue,positive,positive,positive,positive,positive,positive
539870025,"> The deconstructor of `MappedFile` is never called

Just to make sure, this is not only when using the Python code, this is **always** ?",never make sure python code always,issue,negative,positive,positive,positive,positive,positive
539866502,"We have support for RPi4 since #2272, so you can't use `v0.5.1`, you have to use latest 0.6 alpha: `pip3 install deepspeech==0.6.0a8`: https://pypi.org/project/deepspeech/0.6.0a8/",support since ca use use latest alpha pip install,issue,negative,positive,positive,positive,positive,positive
539865836,"> turns out that the python client does no contains `freeModel`

It is handled by the wrapper: https://github.com/mozilla/DeepSpeech/blob/031479d88b02ba7e7c4776f9b511fb26c940a6f5/native_client/python/__init__.py#L42-L45",turn python client handled wrapper,issue,negative,neutral,neutral,neutral,neutral,neutral
539851274,"The destructor of  `MappedFile` is never called: 
https://github.com/mozilla/DeepSpeech/blob/031479d88b02ba7e7c4776f9b511fb26c940a6f5/native_client/ctcdecode/third_party/openfst-1.6.9-win/src/lib/mapped-file.cc#L26

then never executes:

https://github.com/mozilla/DeepSpeech/blob/031479d88b02ba7e7c4776f9b511fb26c940a6f5/native_client/ctcdecode/third_party/openfst-1.6.9-win/src/lib/mapped-file.cc#L38

Before I found that the deconstructor is not called, I tried to replicate with the python client on windows and turns out that the python client does no contains `freeModel`, why @lissyx ? I'm missing something?
Windows Python version : `deepspeech==0.6.0a8`",destructor never never found tried replicate python client turn python client missing something python version,issue,negative,negative,negative,negative,negative,negative
539718610,"@lissyx I merged this patch and ran a training epoch, looks good",patch ran training epoch good,issue,negative,positive,positive,positive,positive,positive
539602418,"> not really doing `mmap()` on windows

Instead is using a custom implementation using a buffer: https://github.com/kkm000/openfst/blob/989affd3043b6357e6047a395565c3e0d979c01f/src/lib/mapped-file.cc#L48

I'll compile and debug that file, I also want to test a few things with https://code.google.com/archive/p/mman-win32/ and see if we can get rid of the buffer implementation. ",really instead custom implementation buffer compile file also want test see get rid buffer implementation,issue,negative,positive,positive,positive,positive,positive
539518251,"Here's what I've used to compare the header vs the filesystem file size:

```python
import os
import wave
import pandas
import sys

def compare_header_and_size(wav_filename):
    with wave.open(wav_filename, 'r') as fin:
        header_fsize = (fin.getnframes() * fin.getnchannels() * fin.getsampwidth()) + 44
    file_fsize = os.path.getsize(wav_filename)
    return header_fsize != file_fsize

df = pandas.read_csv(sys.argv[1])
invalid = df.apply(lambda x: compare_header_and_size(x['wav_filename']), axis=1)
print('The following files are corrupted:')
print(df[invalid].values)
```",used compare header file size python import o import wave import import fin return invalid lambda print following corrupted print invalid,issue,negative,neutral,neutral,neutral,neutral,neutral
539364531,"> Now looking :[kkm000/openfst#8](https://github.com/kkm000/openfst/issues/8)

So it would mean `ConstFst` is not really doing `mmap()` on windows, and thus we leak from there?",looking would mean really thus leak,issue,negative,negative,neutral,neutral,negative,negative
539276495,"Finally compiled and now testing:

Versions:
```
TensorFlow: v1.14.0-16-g3b4ce374f5
DeepSpeech: v0.6.0-alpha.8-16-gfb611ef
```
Valgrind report for 1 run:

```
==32502== LEAK SUMMARY:
==32502==    definitely lost: 24 bytes in 1 blocks
==32502==    indirectly lost: 214 bytes in 5 blocks
==32502==      possibly lost: 331,620 bytes in 1,500 blocks
==32502==    still reachable: 2,115,668 bytes in 39,762 blocks
==32502==                       of which reachable via heuristic:
==32502==                         stdstring          : 465,999 bytes in 11,883 blocks
==32502==                         newarray           : 42,880 bytes in 194 blocks
==32502==         suppressed: 0 bytes in 0 blocks
```

 20 runs:

```
==45309==
==45309== LEAK SUMMARY:
==45309==    definitely lost: 7,520 bytes in 42 blocks
==45309==    indirectly lost: 7,959,270 bytes in 102,263 blocks
==45309==      possibly lost: 2,973,857 bytes in 34,726 blocks
==45309==    still reachable: 2,154,783 bytes in 40,201 blocks
==45309==                       of which reachable via heuristic:
==45309==                         stdstring          : 938,728 bytes in 17,033 blocks
==45309==                         newarray           : 208,224 bytes in 988 blocks
```

>  I do fear this might be Windows-specific.

Given the results looks you are correct.


Now looking :https://github.com/kkm000/openfst/issues/8",finally testing report run leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic fear might given correct looking,issue,negative,neutral,neutral,neutral,neutral,neutral
539195358,"> do you have specific code to share for reproducing?

Just the console example using a for over the same file::https://gist.github.com/carlfm01/fd69a8ca2784837dabf9375d35258953#file-test-cs-L59
To see the memory usage I'm using the VS profiler(poor details of the unmanaged side)

Now I want to compile the console client for Linux to perform the same test, or that was exactly what you did? ",specific code share console example file see memory usage profiler poor unmanaged side want compile console client perform test exactly,issue,negative,negative,neutral,neutral,negative,negative
539179877,@lissyx just wondering - is there any point in taking time to compute a hash when we know that augmentations have been specified in flags - therefore the cache definitely cannot be used? ,wondering point taking time compute hash know therefore cache definitely used,issue,negative,neutral,neutral,neutral,neutral,neutral
539177935,@dabinat / @reuben - has there been any progress on this feature and do you think it might make it in in time for the 0.6.0 release? Would be really handy!,progress feature think might make time release would really handy,issue,negative,positive,positive,positive,positive,positive
539088413,"@carlfm01 Your previous message mentionned growing from 200MB to 700MB over 20 iterations, that would mean we are loosing 25MB per run.

So far, I can only account for ~2MB at best:
```
==22384== LEAK SUMMARY:
==22384==    definitely lost: 24 bytes in 1 blocks
==22384==    indirectly lost: 0 bytes in 0 blocks
==22384==      possibly lost: 332,124 bytes in 1,521 blocks
==22384==    still reachable: 2,655,432 bytes in 33,076 blocks
==22384==                       of which reachable via heuristic:
==22384==                         newarray           : 52,576 bytes in 196 blocks
==22384==         suppressed: 0 bytes in 0 blocks
```

And most of it is from TensorFlow itself, and this might be false-positive from valgrind.

The only items that would connect to language model / decoder would account only for a few bytes (10 occurrences, between 24 bytes and 32 bytes, so at worst it's < 320 bytes per run). Obivously, very far away from what you experience. I do fear this might be Windows-specific. Or at least, not reproductible on Linux / under valgrind.",previous message growing would mean loosing per run far account best leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed might would connect language model would account worst per run far away experience fear might least,issue,negative,negative,neutral,neutral,negative,negative
539058696,So far I have a hard time reproducing the leak. @carlfm01 do you have specific code to share for reproducing ? amounts of memory leaked ?,far hard time leak specific code share memory,issue,negative,negative,neutral,neutral,negative,negative
539042117,"Also note that this is not building anything, just downloading a binary from our infrastructure. If you actually are trying to build you should be using bazel, not taskcluster.py.",also note building anything binary infrastructure actually trying build,issue,negative,neutral,neutral,neutral,neutral,neutral
539041967,"This isn't actually documented anywhere that I can find. You need:

` python util/taskcluster.py --source tensorflow --branch r1.14 --artifact convert_graphdef_memmapped_format --target .`",actually anywhere find need python source branch artifact target,issue,negative,neutral,neutral,neutral,neutral,neutral
538933425,"Without the trie, it keeps in the range from 2GB to 4GB every run, without a noticeable difference in resource usage from the first one and the last one.",without range every run without noticeable difference resource usage first one last one,issue,negative,positive,positive,positive,positive,positive
538914225,@rhamnett I was thinking to generalize that and compute some hash of the dataset to ensure feature cache matches and either fail or cleanup cache,thinking generalize compute hash ensure feature cache either fail cleanup cache,issue,negative,negative,negative,negative,negative,negative
538910521,"> In your tests are you specifying an empty trie path and relying on the Scorer to create it dynamicall

No, I'm using a trie file path, let me see without it.


",empty path scorer create file path let see without,issue,negative,negative,neutral,neutral,negative,negative
538908445,"In your tests are you specifying an empty trie path and relying on the Scorer to create it dynamically? In other words, is `Scorer::fill_dictionary` being called?",empty path scorer create dynamically scorer,issue,negative,negative,neutral,neutral,negative,negative
538905867,The only big changes in that window are indeed related to the LM: 31afc6811f1cacc7eba1943e27931de3d7b8a8dc cc @reuben ,big window indeed related,issue,negative,neutral,neutral,neutral,neutral,neutral
538905527,"> Thanks for that. Do you reproduce on Linux as well?

Not yet, I was testing the Nugets first",thanks reproduce well yet testing first,issue,positive,positive,positive,positive,positive,positive
538905143,"> The issue is coming from `0.6.0-alpha.1`, `0.6.0-alpha.0` works just fine.

Thanks for that. Do you reproduce on Linux as well?",issue coming work fine thanks reproduce well,issue,positive,positive,positive,positive,positive,positive
538869869,"@lissyx Please reply the above questions on discourse. thank you.


https://discourse.mozilla.org/t/deepspeech-training-own-model/46210",please reply discourse thank,issue,positive,neutral,neutral,neutral,neutral,neutral
538868094,"Okay.
Qn 1: Approximately How much data is minimum required to get the response?
Qn 2: How to train from deepspeech 0.5 released model? what should i do to add my corpus in prebuilt model in train test and dev? how more audio should be added?
",approximately much data minimum get response train model add corpus model train test dev audio added,issue,negative,positive,positive,positive,positive,positive
538866877,"@vaibhavsatpathy This is not a bug, please post questions on Discourse.",bug please post discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
538860429,"Please use discourse, this is not a bug. 25 audio files of 2-4 secs, that's just not enough data. That's why you get empty strings. ",please use discourse bug audio enough data get empty,issue,negative,negative,neutral,neutral,negative,negative
538853668,"@lissyx 

Check output

Epoch 2 | Training | Elapsed Time: 0:11:37 | Steps: 24 | Loss: 200.743011
Epoch 2 | Validation | Elapsed Time: 0:00:09 | Steps: 10 | Loss: 145.589038 | Dataset: data/dev/dev.csv
I Saved new best validating model with loss 145.589038 to: /home/yk/.local/share/deepspeech/checkpoints/best_dev-144
Epoch 3 | Training | Elapsed Time: 0:10:26 | Steps: 23 | Loss: 188.129880

Epoch 3 | Training | Elapsed Time: 0:11:38 | Steps: 24 | Loss: 200.469688
Epoch 3 | Validation | Elapsed Time: 0:00:09 | Steps: 10 | Loss: 145.480138 | Dataset: data/dev/dev.csv
I Saved new best validating model with loss 145.480138 to: /home/yk/.local/share/deepspeech/checkpoints/best_dev-168
I Early stop triggered as (for last 4 steps) validation loss: 145.480138 with standard deviation: 0.053664 and mean: 145.650564
I FINISHED optimization in 0:47:13.484660
WARNING:tensorflow:Entity <bound method LSTMBlockWrapper.call of <tensorflow.contrib.rnn.python.ops.lstm_ops.LSTMBlockFusedCell object at 0x7f0637a1a978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: converting <bound method LSTMBlockWrapper.call of <tensorflow.contrib.rnn.python.ops.lstm_ops.LSTMBlockFusedCell object at 0x7f0637a1a978>>: AttributeError: module ‘gast’ has no attribute ‘Num’
W1007 10:09:12.322466 139666740873024 ag_logging.py:145] Entity <bound method LSTMBlockWrapper.call of <tensorflow.contrib.rnn.python.ops.lstm_ops.LSTMBlockFusedCell object at 0x7f0637a1a978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: converting <bound method LSTMBlockWrapper.call of <tensorflow.contrib.rnn.python.ops.lstm_ops.LSTMBlockFusedCell object at 0x7f0637a1a978>>: AttributeError: module ‘gast’ has no attribute ‘Num’
INFO:tensorflow:Restoring parameters from /home/yk/.local/share/deepspeech/checkpoints/best_dev-168
I1007 10:09:12.369412 139666740873024 saver.py:1280] Restoring parameters from /home/yk/.local/share/deepspeech/checkpoints/best_dev-168
I Restored variables from best validation checkpoint at /home/yk/.local/share/deepspeech/checkpoints/best_dev-168, step 168
Testing model on data/test/test.csv
Test epoch | Steps: 7 | Elapsed Time: 0:00:05
Test on data/test/test.csv - WER: 1.000000, CER: 1.000000, loss: 473.767029
WER: 1.000000, CER: 1.000000, loss: 191.858261

wav: file:///home/yk/DeepSpeech/data/test/044.wav
src: “syuui”
res: “”
WER: 1.000000, CER: 1.000000, loss: 491.481476

wav: file:///home/yk/DeepSpeech/data/test/041.wav
src: “oimmyy”
res: “”
WER: 1.000000, CER: 1.000000, loss: 507.216888

wav: file:///home/yk/DeepSpeech/data/test/043.wav
src: “o rrhof i”
res: “”
WER: 1.000000, CER: 1.000000, loss: 510.564240

wav: file:///home/yk/DeepSpeech/data/test/047.wav
src: ""o p ""
res: “”
WER: 1.000000, CER: 1.000000, loss: 512.405273

wav: file:///home/yk/DeepSpeech/data/test/045.wav
src: “ohndieya”
res: “”
WER: 1.000000, CER: 1.000000, loss: 547.843018

wav: file:///home/yk/DeepSpeech/data/test/042.wav
src: “pfnry nya”
res: “”
WER: 1.000000, CER: 1.000000, loss: 554.999878

wav: file:///home/yk/DeepSpeech/data/test/046.wav
src: “o uu”
res: “”",check output epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch training time loss epoch validation time loss saved new best model loss early stop triggered last validation loss standard deviation mean finished optimization warning entity bound method object could executed please report team filing bug set verbosity export attach full output cause converting bound method object module gast attribute entity bound method object could executed please report team filing bug set verbosity export attach full output cause converting bound method object module gast attribute best validation step testing model test epoch time test wer loss wer loss file wer loss file wer loss file wer loss file wer loss file wer loss file wer loss file,issue,negative,positive,positive,positive,positive,positive
538853548,"@lissyx 

Hi i am getting no text in res
out put 
res "" ""

EXplaination about my training model.
I am using english model
created binary file with 45 audio corpus.
using trie from pretrained english model.
train has 25 audios , 2-4 sec each with their transcript and size
dev has 10 audios with size and trans
and test has 7 audios with size and trans

upon running deepspeech.py i am getting this: 
is it normal? if yes then why am i not getting res?",hi getting text put training model model binary file audio corpus model train sec transcript size dev size test size upon running getting normal yes getting,issue,negative,positive,neutral,neutral,positive,positive
538772353,"> If you can check where it comes from and/or if it reproduces under Linux it'd be awesome

Yes, let me get back to my VM tomorrow.

> Can you check if it could be a regression on Windows due to #2384 ?

@lissyx yes, I'll check if it is related, I'll test the previous version to that change and report back.

> For the leak, can you file an issue?

Yes, I will properly file an issue with the specific version that I tested once I get my hands back on it.",check come awesome yes let get back tomorrow check could regression due yes check related test previous version change report back leak file issue yes properly file issue specific version tested get back,issue,positive,positive,neutral,neutral,positive,positive
538720799,Please take that discussion to Discourse.,please take discussion discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
538632946,"> without LM enabled works fine, with about 20 runs of creating and destroying the model the memory usage went from 200MB to 700MB, @lissyx @reuben any thoughts?

Can you check if it could be a regression on Windows due to #2384 ?",without work fine model memory usage went check could regression due,issue,negative,positive,positive,positive,positive,positive
538625269,"For the leak, can you file an issue? If you can check where it comes from and/or if it reproduces under Linux it'd be awesome 😁",leak file issue check come awesome,issue,negative,positive,positive,positive,positive,positive
538371291,We'll close when the last item is done.,close last item done,issue,negative,neutral,neutral,neutral,neutral,neutral
538335344,"> Yes i am training English Model. can i use the prebuilt one?

Then yes.",yes training model use one yes,issue,positive,neutral,neutral,neutral,neutral,neutral
538332008,"Hi
Sorry for the posting here.

Yes i am training English Model. can i use the prebuilt one?",hi sorry posting yes training model use one,issue,negative,negative,negative,negative,negative,negative
538280923,"@cryptoaimdy First, this is not the place to request for help. Please use Discourse for that purpose. Second, you should have formatted properly console output. Third, it is documented to use our tensorflow fork, and branch `r1.14`. Fourth, `generate_trie` is packaged in `native_client.tar.xz` so why do you have to rebuild that ?


>  or can i use DeepSpeech/data/lm/trie (default with clone) ? for my model?

Are you training an English model ?",first place request help please use discourse purpose second properly console output third use fork branch fourth rebuild use default clone model training model,issue,positive,positive,neutral,neutral,positive,positive
538265657,"> Could you please guide, how can I get it fix in v0.5.0?

First, you should use `v0.5.1`. Second, it's inconsistent. Your model, if it was trained with `v0.5.1` would not work with `0.6.0a8`. So I don't know what you mixed together ...",could please guide get fix first use second inconsistent model trained would work know mixed together,issue,negative,positive,neutral,neutral,positive,positive
538149516,"@lissyx : Does it mean we have to train over 75 epochs? 

As you have asked, I trained the same data on master. I also had to create a new TRIE on the master. Here are the logs: 
[nohup.txt](https://github.com/mozilla/DeepSpeech/files/3688254/nohup.txt)

Then I installed: 

`pip3 install deepspeech==0.6.0a8`

and ran:

```
(env-deepspeech-german-test) agarwal@LTLab.lan@wika:~/deepspeech-german-test$ deepspeech --model models/output_graph.pb --alphabet dependencies/alphabet.txt --lm dependencies/lm.binary --trie dependencies/trie --audio ../dataset-german/de_1.wav
Loading model from file models/output_graph.pb
TensorFlow: v1.14.0-16-g3b4ce37
DeepSpeech: v0.6.0-alpha.8-0-gf0e9541
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-10-03 23:55:38.338905: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
Loaded model in 0.166s.
Loading language model from files dependencies/lm.binary dependencies/trie
Loaded language model in 0.000183s.
Running inference.
auf meinen in diesem jahr mit
Inference took 2.562s for 1.490s audio file.
```

Unlike with v0.5.0, the master didn't produce blank inference.

Could you please guide, how can I get it fix in v0.5.0?",mean train trained data master also create new master pip install ran agarwal model alphabet audio loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use loaded model loading language model loaded language model running inference inference took audio file unlike master produce blank inference could please guide get fix,issue,negative,negative,neutral,neutral,negative,negative
537963140,"> Is it empty wavfile. Or corrupted wav file.?
> Mm thank you sir.

I don't have your data, I can't tell you.

> **Invalid argument: Header mismatch: Expected RIFF but found ����**",empty corrupted thank sir data ca tell invalid argument header mismatch riff found,issue,negative,negative,neutral,neutral,negative,negative
537960526," Is it empty wavfile. Or corrupted wav file.? 
Mm thank you sir.",empty corrupted thank sir,issue,negative,negative,neutral,neutral,negative,negative
537928446,"> I am attaching the training logs for a model trained on ~302 hours of data, which produces WER of 24.48%. It ran for 12 Epochs.

Now this is getting interesting, because it does not seems that you have not trained enough. Can you reproduce that on latest master, please ?",training model trained data wer ran getting interesting trained enough reproduce latest master please,issue,positive,positive,positive,positive,positive,positive
537928121,"> how to resolve @lissyx sir.
> thank you sir:)

Find and remove it ?",resolve sir thank sir find remove,issue,positive,neutral,neutral,neutral,neutral,neutral
537905849,"how to resolve @lissyx sir. 
thank you sir:)",resolve sir thank sir,issue,positive,neutral,neutral,neutral,neutral,neutral
537890822,"@lissyx : I was trying to follow the ReadMe for creating TRIE and I mistakenly followed an extra step, Please ignore it.

I am attaching the training logs for a model trained on ~302 hours of data, which produces WER of 24.48%. It ran for 12 Epochs.

```
./DeepSpeech.py --train_files ../german-speech-corpus/data_tuda+voxforge+mozilla/train_100.csv --dev_files ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv --test_files ../german-speech-corpus/data_tuda+voxforge+mozilla/test.csv --alphabet_config_path ../deepspeech-german/data/alphabet.txt --lm_trie_path ../dataset-german/trie --lm_binary_path ../dataset-german/lm.binary --test_batch_size 36 --train_batch_size 24 --dev_batch_size 36 --epochs 75 --learning_rate 0.0001 --dropout_rate 0.30 --export_dir ../models

WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.

WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
I Initializing variables...
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:04:24 | Steps: 445 | Loss: 176.860081
Epoch 0 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 155.113629 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 155.113629 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-445
Epoch 1 |   Training | Elapsed Time: 0:04:12 | Steps: 445 | Loss: 118.930347
Epoch 1 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 122.372937 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
I Saved new best validating model with loss 122.372937 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-890
Epoch 2 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 98.190498
Epoch 2 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 107.649564 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 107.649564 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-1335
Epoch 3 |   Training | Elapsed Time: 0:04:12 | Steps: 445 | Loss: 85.011518
Epoch 3 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 91.951983 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 91.951983 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-1780
Epoch 4 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 75.027806
Epoch 4 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 86.279818 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 86.279818 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-2225
Epoch 5 |   Training | Elapsed Time: 0:04:10 | Steps: 445 | Loss: 67.094796
Epoch 5 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 85.204753 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 85.204753 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-2670
Epoch 6 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 60.479755
Epoch 6 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 81.458550 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 81.458550 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-3115
Epoch 7 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 54.812813
Epoch 7 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 76.570380 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 76.570380 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-3560
Epoch 8 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 49.687799
Epoch 8 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 75.798708 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 75.798708 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-4005
Epoch 9 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 45.490483
Epoch 9 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 74.208162 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 74.208162 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-4450
Epoch 10 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 41.527083
Epoch 10 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 72.952417 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
I Saved new best validating model with loss 72.952417 to: /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-4895
Epoch 11 |   Training | Elapsed Time: 0:04:11 | Steps: 445 | Loss: 38.197429
Epoch 11 | Validation | Elapsed Time: 0:00:14 | Steps: 63 | Loss: 75.873461 | Dataset: ../german-speech-corpus/data_tuda+voxforge+mozilla/dev.csv
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I Early stop triggered as (for last 4 steps) validation loss: 75.873461 with standard deviation: 1.164670 and mean: 74.319763
I FINISHED optimization in 0:53:36.295521
I Restored variables from best validation checkpoint at /home/LTLab.lan/agarwal/.local/share/deepspeech/checkpoints/best_dev-4895, step 4895
Testing model on ../german-speech-corpus/data_tuda+voxforge+mozilla/test.csv
Test epoch | Steps: 190 | Elapsed Time: 0:06:19
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From /home/LTLab.lan/agarwal/python-environments/env/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
Test on ../german-speech-corpus/data_tuda+voxforge+mozilla/test.csv - WER: 0.244884, CER: 0.106593, loss: 34.352589
--------------------------------------------------------------------------------
WER: 3.000000, CER: 0.857143, loss: 15.761712
 - src: ""nochmal""
 - res: ""noch war es""
--------------------------------------------------------------------------------
WER: 2.500000, CER: 0.400000, loss: 51.369308
 - src: ""dialogstatus zurücksetzen""
 - res: ""die noch status zu setzen""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.142857, loss: 3.455172
 - src: ""nochmal""
 - res: ""noch mal""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.142857, loss: 3.665473
 - src: ""nochmal""
 - res: ""noch mal""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.071429, loss: 5.423339
 - src: ""weiterschlafen""
 - res: ""weiter schlafen""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.071429, loss: 5.625791
 - src: ""weiterschlafen""
 - res: ""weiter schlafen""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.071429, loss: 6.189450
 - src: ""weiterschlafen""
 - res: ""weiter schlafen""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.142857, loss: 6.387710
 - src: ""nochmal""
 - res: ""noch mal""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.142857, loss: 7.680886
 - src: ""nochmal""
 - res: ""noch mal""
--------------------------------------------------------------------------------
WER: 2.000000, CER: 0.625000, loss: 8.305445
 - src: ""nächstes""
 - res: ""ist es""
--------------------------------------------------------------------------------
I Exporting the model...
I Models exported at ../models
```

",trying follow mistakenly extra step please ignore training model trained data wer ran warning removed future version instead use python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape warning removed future version handled automatically placer warning removed future version use instead starting optimization epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss warning removed future version use standard file delete prefix saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss saved new best model loss epoch training time loss epoch validation time loss warning removed future version use standard file check prefix early stop triggered last validation loss standard deviation mean finished optimization best validation step testing model test epoch time warning removed future version use warning removed future version use test wer loss wer loss war e wer loss die status wer loss mal wer loss mal wer loss wer loss wer loss wer loss mal wer loss mal wer loss ist e model,issue,negative,positive,positive,positive,positive,positive
537870702,"i also facing same problem. how to resolve this issue.? @shan18 @lissyx @reuben 


`CUDA_VISIBLE_DEVICES=1,2,3  python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir  /media/use/  --dropout_rate 0.12 --epochs 50 --train_files data/train1.csv  --dev_files data/dev1.csv --test_files  data/test1.csv --train_batch_size 32 --test_batch_size 32 --dev_batch_size 32 --learning_rate 0.0001 --export_dir /media/user1/storage-1/suneel/stt/DeepSpeech/model_files_dir/ --one_shot_infer /media/user1/storage-1/suneel/stt/checkpoints/testing/6.wav --es_steps 8 --log_level 0 2>&1 | tee ds.log`

**Invalid argument: Header mismatch: Expected RIFF but found ����**

```

Use standard file APIs to check for files with this prefix.
D Session opened.
I Restored variables from most recent checkpoint at /media/user1/storage-1/suneel/stt/DeepSpeech/ckpt_file_v0.5.1/deepspeech-0.5.1-checkpoint/model.v0.5.1, step 467356
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       2019-10-03 10:49:01.538950: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 63 | Loss: 11.795926     2019-10-03 10:49:21.616019: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at decode_wav_op.cc:55 : Invalid argument: Header mismatch: Expected RIFF but found ����
Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 65 | Loss: 11.783006


```

automatically training killed and no more error log.",also facing problem resolve python tee invalid argument header mismatch riff found use standard file check prefix session recent step starting optimization epoch training time loss successfully library locally epoch training time loss invalid argument header mismatch riff found epoch training time loss automatically training error log,issue,negative,positive,positive,positive,positive,positive
537835863,"> Okay, I'll try once more and report back the logs.

Probably a problem with your dataset.
Maybe with the generated `.csv`. (I had that one too)
Can you show the csv generation process logs. (I think you might find the problem & solution there)",try report back probably problem maybe one show generation process think might find problem solution,issue,negative,neutral,neutral,neutral,neutral,neutral
537830069,"@AASHISHAG Why are you rebuilding the `deepspeech` inference code ?

Training parameters without training log is not useful. How much data do you have ? What WER did you got ? How much epoch did complete ?",inference code training without training log useful much data wer got much epoch complete,issue,negative,positive,positive,positive,positive,positive
537771546,"> I trained on German language, but surprisingly I am getting blank inference results.

I tried to help you, but surprisingly, since there is no information on how you performed your training, I am getting blank results.",trained german language surprisingly getting blank inference tried help surprisingly since information training getting blank,issue,positive,positive,positive,positive,positive,positive
537644638,"Not disabling the cache will mean you will not get any epochs using augmented data at all.

With no cache YMMV but shouldn't be too bad. As I understand it... the pipeline should be able to process the next data by CPU before it's needed in the GPU - see https://www.tensorflow.org/guide/data_performance",cache mean get augmented data cache bad understand pipeline able process next data see,issue,negative,negative,negative,negative,negative,negative
537635185,What performance hit is disabling the cache likely to cause?,performance hit cache likely cause,issue,negative,neutral,neutral,neutral,neutral,neutral
537529208,Ahh @reuben I had removed the .cache() call myself but I was not aware that was strictly necessary! I agree let's close this.,removed call aware strictly necessary agree let close,issue,negative,positive,positive,positive,positive,positive
537470196,"The instruction given here is also not enough. You have to remove the `.cache()` call in `feeding.py`, otherwise it caches to memory by default. Maybe the easiest thing to do is to make caching optional behind a flag that has a default of False.",instruction given also enough remove call otherwise memory default maybe easiest thing make optional behind flag default false,issue,negative,negative,negative,negative,negative,negative
537442231,I did ask about this in IRC twice but had no response. I'd suggest disabling cache if any augmentation flags are found and printing a warning message.,ask twice response suggest cache augmentation found printing warning message,issue,negative,neutral,neutral,neutral,neutral,neutral
537366734,"I'm going to close due the the ""Page Not Found"" error and @ghost not giving any updates over the last 2 years.",going close due page found error ghost giving last,issue,negative,negative,neutral,neutral,negative,negative
536328824,"> Ok, thank you. So is there a way that I can simply test multiple files?

Use the C++ binary ?",thank way simply test multiple use binary,issue,negative,neutral,neutral,neutral,neutral,neutral
536320965,"Ok, thank you. So is there a way that I can simply test multiple files?",thank way simply test multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
536291023,"Thanks for noticing. It seems some part of the upload indeed silently failed back then. I've retriggered task upload, but there's still some 400 error blocking the upload. v0.5.1 is done, we're not going to have the opportunity to fix that.

As you mentionned, the packages are still available from the github page, and it's working. And v0.6 alphas are uploading correctly, so this should be properly dealt with at this time.",thanks part indeed silently back task still error blocking done going opportunity fix still available page working correctly properly dealt time,issue,negative,positive,positive,positive,positive,positive
536268216,">  `IsADirectoryError: [Errno 21] Is a directory: '84-121123wav'`

This is a Python exception. #1232 explicitely states this is supported from the C++ client. Please bear in mind those are mostly demo-purpose, so it's easy to quickly test, but it's not meant for serving directly as your solution.",directory python exception client please bear mind mostly easy quickly test meant serving directly solution,issue,positive,positive,positive,positive,positive,positive
536122057,Thanks reuben. It's working perfectly fine now. ,thanks working perfectly fine,issue,positive,positive,positive,positive,positive,positive
536008194,"> Thank you, But is there any way to convert it using any other command line tool so that i can use it in my python script ?

Anything that produces a valid file that will not choke in this: https://github.com/mozilla/DeepSpeech/blob/master/native_client/client.cc#L210-L246",thank way convert command line tool use python script anything valid file choke,issue,negative,neutral,neutral,neutral,neutral,neutral
536004536,"> This is mentioned on Official Readme
> ""Currently, only 16-bit, 16 kHz, mono-channel WAVE audio files are supported in the Python client"".
> 
> I have also converted and verified using mediainfo in ubuntu for both the files.

My point being: code is hand-crafted for reading perfectly formatted WAVE header. Do not expect it to circumvent buggy files.",official currently wave audio python client also converted point code reading perfectly wave header expect circumvent buggy,issue,positive,positive,positive,positive,positive,positive
536003354,"> The problem is ffmpeg, it's creating a header that doesn't match the output we expect. Same file but `test_sox.wav` was converted from wav to wav using sox:
> 
> ```
> $ xxd ~/Downloads/test.wav | head
> 00000000: 5249 4646 3861 0300 5741 5645 666d 7420  RIFF8a..WAVEfmt
> 00000010: 1000 0000 0100 0100 803e 0000 007d 0000  .........>...}..
> 00000020: 0200 1000 4c49 5354 1a00 0000 494e 464f  ....LIST....INFO
> 00000030: 4953 4654 0e00 0000 4c61 7666 3538 2e32  ISFT....Lavf58.2
> 00000040: 392e 3130 3000 6461 7461 f260 0300 0000  9.100.data.`....
> 00000050: 0000 0000 ffff ffff feff fdff fbff faff  ................
> 00000060: f8ff f6ff f5ff f2ff f0ff eeff ecff e9ff  ................
> 00000070: e7ff e4ff e0ff dfff dcff daff d8ff d4ff  ................
> 00000080: d4ff d1ff d2ff d1ff d1ff d0ff d0ff d1ff  ................
> 00000090: d1ff d2ff d0ff d1ff d2ff d5ff d7ff daff  ................
> $ xxd ~/Downloads/test_sox.wav | head
> 00000000: 5249 4646 1661 0300 5741 5645 666d 7420  RIFF.a..WAVEfmt
> 00000010: 1000 0000 0100 0100 803e 0000 007d 0000  .........>...}..
> 00000020: 0200 1000 6461 7461 f260 0300 0000 0000  ....data.`......
> 00000030: 0000 ffff ffff feff fdff fbff faff f8ff  ................
> 00000040: f6ff f5ff f2ff f0ff eeff ecff e9ff e7ff  ................
> 00000050: e4ff e0ff dfff dcff daff d8ff d4ff d4ff  ................
> 00000060: d1ff d2ff d1ff d1ff d0ff d0ff d1ff d1ff  ................
> 00000070: d2ff d0ff d1ff d2ff d5ff d7ff daff ddff  ................
> 00000080: deff e3ff e6ff e9ff ebff eeff f2ff f6ff  ................
> 00000090: f8ff feff ffff 0800 0900 0d00 1300 1900  ................
> ```


Thank you, But is there any way to convert it using any other command line tool so that i can use it in my python script ?",problem header match output expect file converted head list faff daff daff head faff daff daff thank way convert command line tool use python script,issue,negative,neutral,neutral,neutral,neutral,neutral
536002490,"The problem is ffmpeg, it's creating a header that doesn't match the output we expect. Same file but `test_sox.wav` was converted from wav to wav using sox:

```
$ xxd ~/Downloads/test.wav | head
00000000: 5249 4646 3861 0300 5741 5645 666d 7420  RIFF8a..WAVEfmt
00000010: 1000 0000 0100 0100 803e 0000 007d 0000  .........>...}..
00000020: 0200 1000 4c49 5354 1a00 0000 494e 464f  ....LIST....INFO
00000030: 4953 4654 0e00 0000 4c61 7666 3538 2e32  ISFT....Lavf58.2
00000040: 392e 3130 3000 6461 7461 f260 0300 0000  9.100.data.`....
00000050: 0000 0000 ffff ffff feff fdff fbff faff  ................
00000060: f8ff f6ff f5ff f2ff f0ff eeff ecff e9ff  ................
00000070: e7ff e4ff e0ff dfff dcff daff d8ff d4ff  ................
00000080: d4ff d1ff d2ff d1ff d1ff d0ff d0ff d1ff  ................
00000090: d1ff d2ff d0ff d1ff d2ff d5ff d7ff daff  ................
$ xxd ~/Downloads/test_sox.wav | head
00000000: 5249 4646 1661 0300 5741 5645 666d 7420  RIFF.a..WAVEfmt
00000010: 1000 0000 0100 0100 803e 0000 007d 0000  .........>...}..
00000020: 0200 1000 6461 7461 f260 0300 0000 0000  ....data.`......
00000030: 0000 ffff ffff feff fdff fbff faff f8ff  ................
00000040: f6ff f5ff f2ff f0ff eeff ecff e9ff e7ff  ................
00000050: e4ff e0ff dfff dcff daff d8ff d4ff d4ff  ................
00000060: d1ff d2ff d1ff d1ff d0ff d0ff d1ff d1ff  ................
00000070: d2ff d0ff d1ff d2ff d5ff d7ff daff ddff  ................
00000080: deff e3ff e6ff e9ff ebff eeff f2ff f6ff  ................
00000090: f8ff feff ffff 0800 0900 0d00 1300 1900  ................
```",problem header match output expect file converted head list faff daff daff head faff daff daff,issue,negative,neutral,neutral,neutral,neutral,neutral
536002229,"And this is for the converted file which i have problem.

mediainfo test.wav
General
Complete name                            : test.wav
Format                                   : Wave
File size                                : 216 KiB
Duration                                 : 6 s 919 ms
Overall bit rate mode                    : Constant
Overall bit rate                         : 256 kb/s
Writing application                      : Lavf58.29.100

Audio
Format                                   : PCM
Format settings                          : Little / Signed
Codec ID                                 : 1
Duration                                 : 6 s 919 ms
Bit rate mode                            : Constant
Bit rate                                 : 256 kb/s
Channel(s)                               : 1 channel
Sampling rate                            : 16.0 kHz
Bit depth                                : 16 bits
Stream size                              : 216 KiB (100%)",converted file problem general complete name format wave file size duration overall bit rate mode constant overall bit rate writing application audio format format little id duration bit rate mode constant bit rate channel channel sampling rate bit depth stream size,issue,negative,negative,neutral,neutral,negative,negative
536001935," This is mentioned on Official Readme
""Currently, only 16-bit, 16 kHz, mono-channel WAVE audio files are supported in the Python client"".

I have also converted and verified using mediainfo in ubuntu for both the files.
Media Info for example file given by deepspeech officials.

mediainfo 4507-16021-0012.wav
General
Complete name                            : 4507-16021-0012.wav
Format                                   : Wave
File size                                : 85.5 KiB
Duration                                 : 2 s 735 ms
Overall bit rate mode                    : Constant
Overall bit rate                         : 256 kb/s

Audio
Format                                   : PCM
Format settings                          : Little / Signed
Codec ID                                 : 1
Duration                                 : 2 s 735 ms
Bit rate mode                            : Constant
Bit rate                                 : 256 kb/s
Channel(s)                               : 1 channel
Sampling rate                            : 16.0 kHz
Bit depth                                : 16 bits
Stream size                              : 85.5 KiB (100%)
",official currently wave audio python client also converted medium example file given general complete name format wave file size duration overall bit rate mode constant overall bit rate audio format format little id duration bit rate mode constant bit rate channel channel sampling rate bit depth stream size,issue,negative,negative,neutral,neutral,negative,negative
536001681,"> here is the result after executing one of those files.

Please keep in mind that this `deepspeech.exe` is only intended as demo purpose, and it's explicitely very limited.",result one please keep mind intended purpose limited,issue,negative,negative,neutral,neutral,negative,negative
535999969,"Files provided at this link works fine:
curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz

here is the result after executing one of those files.

(base) C:\Users\israr\Desktop\sample\native_client.amd64.cpu.win>deepspeech.exe  --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio 2830-3980-0043.wav
TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.1-0-g4b29b78
2019-09-27 16:01:28.475058: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-09-27 16:01:28.490500: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-09-27 16:01:28.496062: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-09-27 16:01:28.502660: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-09-27 16:01:28.507335: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=63200
**experience proof this**


",provided link work fine curl result one base model alphabet audio binary use unknown unknown unknown unknown experience proof,issue,negative,negative,negative,negative,negative,negative
535998612,"> Instead of calling deepspeech using that script, can you call it manually with the problem file and post the log? Please copy and paste the log rather than attaching a screenshot.


Sure. Sorry for that. This is the logs i have after executing on the shell or command line directly.

(base) C:\Users\alien\Desktop\sample\native_client.amd64.cpu.win>deepspeech.exe  --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio audios/test.wav
TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.1-0-g4b29b78
2019-09-27 15:56:59.499809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-09-27 15:56:59.514789: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-09-27 15:56:59.519325: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-09-27 15:56:59.525106: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-09-27 15:56:59.530153: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=0",instead calling script call manually problem file post log please copy paste log rather sure sorry shell command line directly base model alphabet audio binary use unknown unknown unknown unknown,issue,negative,negative,negative,negative,negative,negative
535997690,"Instead of calling deepspeech using that script, can you call it manually with the problem file and post the log? Please copy and paste the log rather than attaching a screenshot.",instead calling script call manually problem file post log please copy paste log rather,issue,negative,neutral,neutral,neutral,neutral,neutral
535996900,"> Well, it looks like ffmpeg is writing a size of 0 for the audio data in the file. Can you share the original and converted file that causes the problem?


I have shared the screenshot of the script. if you want i can add my python file as well.",well like writing size audio data file share original converted file problem script want add python file well,issue,positive,positive,positive,positive,positive,positive
535992431,"Well, it looks like ffmpeg is writing a size of 0 for the audio data in the file. Can you share the original and converted file that causes the problem?",well like writing size audio data file share original converted file problem,issue,positive,positive,positive,positive,positive,positive
535990746,"> It means your audio file is not mono. You're probably forgetting to specify that in the conversion process.

I have converted it into mono as well and it's processing without errors but there is still no output. As you can see the details buffer size is also zero. I am testing on files shared by deepspeech all 3 audio files are working fine but i don't know what's the issue with my converted file.
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=0",audio file mono probably forgetting specify conversion process converted mono well without still output see buffer size also zero testing audio working fine know issue converted file,issue,negative,positive,positive,positive,positive,positive
535946219,It means your audio file is not mono. You're probably forgetting to specify that in the conversion process.,audio file mono probably forgetting specify conversion process,issue,negative,neutral,neutral,neutral,neutral,neutral
535934995,"Also, what does it mean:
Assertion failed: num_channels == 1, file client.cc, line 231",also mean assertion file line,issue,negative,negative,negative,negative,negative,negative
535850071,"FTR, also checking with `htop` on RPi4 with 4GB of RAM:
 - prior to the change, memory usage reported by htop would be ~45%
 - after the change, it would only report ~8%.",also ram prior change memory usage would change would report,issue,negative,neutral,neutral,neutral,neutral,neutral
535579102,"@reuben Tested on Pixel 2, after rebooting, using SpeechModule (part of androidspeech): no more huge seconds blocking of the UI when starting inference.",tested part huge blocking starting inference,issue,negative,positive,positive,positive,positive,positive
535539354,"Using `LoadMethod::LAZY`:
```
pi@raspberrypi:~/ds $ echo ""1"" | sudo tee /proc/sys/vm/drop_caches 
1
pi@raspberrypi:~/ds $ time ./deepspeech --model models/output_graph.tflite --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio audio -t
TensorFlow: v1.14.0-16-g3b4ce374f5
DeepSpeech: v0.6.0-alpha.7-8-g513c8e9
INFO: Initialized TensorFlow Lite runtime.
create_model_time=0.00818
setup_time=0.002471
lm_time=0.001803
trie_time=0.000473
Running on directory audio
> audio/4507-16021-0012.wav
why should one halt on the way
cpu_time_overall=3.43854 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/2830-3980-0043.wav
experienced proof less
cpu_time_overall=1.63052 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/8455-210777-0068.wav
your power is sufficient i said
cpu_time_overall=2.31658 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000

real    0m18.207s
user    0m6.506s
sys     0m0.968s
pi@raspberrypi:~/ds $ time ./deepspeech --model models/output_graph.tflite --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio audio -t
TensorFlow: v1.14.0-16-g3b4ce374f5
DeepSpeech: v0.6.0-alpha.7-8-g513c8e9
INFO: Initialized TensorFlow Lite runtime.
create_model_time=0.004335
setup_time=0.000772
lm_time=0.000382
trie_time=0.000247
Running on directory audio
> audio/4507-16021-0012.wav
why should one halt on the way
cpu_time_overall=2.17790 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/2830-3980-0043.wav
experienced proof less
cpu_time_overall=1.58182 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/8455-210777-0068.wav
your power is sufficient i said
cpu_time_overall=2.13153 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000

real    0m5.988s
user    0m5.857s
sys     0m0.130s
```",pi echo tee pi time model alphabet audio audio lite running directory audio one halt way experienced proof le power sufficient said real user pi time model alphabet audio audio lite running directory audio one halt way experienced proof le power sufficient said real user,issue,negative,positive,positive,positive,positive,positive
535532591,"We have 6 seconds of difference on just loading the LM on cold caches:
```
pi@raspberrypi:~/ds $ echo ""1"" | sudo tee /proc/sys/vm/drop_caches                                                                                                                                                                                                                                                                                                                                               
1
pi@raspberrypi:~/ds $ time ./deepspeech --model models/output_graph.tflite --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio audio -t                                                                                                                                                                                                                                              
TensorFlow: v1.14.0-16-g3b4ce374f5
DeepSpeech: v0.6.0-alpha.7-8-g513c8e9
INFO: Initialized TensorFlow Lite runtime.
setup_time=6.82576
lm_time=6.8248
trie_time=0.000511
Running on directory audio
> audio/4507-16021-0012.wav
why should one halt on the way
cpu_time_overall=2.29800 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/2830-3980-0043.wav
experienced proof less
cpu_time_overall=1.58624 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/8455-210777-0068.wav
your power is sufficient i said
cpu_time_overall=2.12006 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000

real    0m49.456s
user    0m5.859s
sys     0m7.298s
pi@raspberrypi:~/ds $ time ./deepspeech --model models/output_graph.tflite --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio audio -t
TensorFlow: v1.14.0-16-g3b4ce374f5
DeepSpeech: v0.6.0-alpha.7-8-g513c8e9
INFO: Initialized TensorFlow Lite runtime.
setup_time=0.784094
lm_time=0.783789
trie_time=0.000177
Running on directory audio
> audio/4507-16021-0012.wav
why should one halt on the way
cpu_time_overall=2.11127 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/2830-3980-0043.wav
experienced proof less
cpu_time_overall=1.57743 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000
> audio/8455-210777-0068.wav
your power is sufficient i said
cpu_time_overall=2.12058 cpu_time_decoding=0.00000 cpu_time_decodeall=0.00000

real    0m6.734s
user    0m5.812s
sys     0m0.922s
``` ",difference loading cold pi echo tee pi time model alphabet audio audio lite running directory audio one halt way experienced proof le power sufficient said real user pi time model alphabet audio audio lite running directory audio one halt way experienced proof le power sufficient said real user,issue,negative,positive,positive,positive,positive,positive
535123485,"> Should this be based on the transfer-learning2 branch rather than master?

@reuben this is up to you / @lissyx / @kdavis-mozilla. If you think people are asking for this often enough, I think it's worth being on master. The only pain with it being in a different branch is keeping it up to date so that newer releases can be used",based branch rather master think people often enough think worth master pain different branch keeping date used,issue,negative,positive,neutral,neutral,positive,positive
535047364,Should this be based on the transfer-learning2 branch rather than master?,based branch rather master,issue,negative,neutral,neutral,neutral,neutral,neutral
534926819,"Thank you, @bernardohenz. I change the width and cutoff_top_n in the  deepspeech.cc. It seems the reducing the beam_width is working. When I change the beam_width from 500(default) to 16, the decode time changes from 2000+s to 54s(source audio is about 3s). If beam_width is 4, decode time will be 15s. But it seems no use when I reduce the cutoff_top_n. How I can get smaller decode time other than reducing beam_width?",thank change width reducing working change default decode time source audio decode time use reduce get smaller decode time reducing,issue,negative,neutral,neutral,neutral,neutral,neutral
534518543,"It is an interesting enhancement and there are quite many existing work related to this as well. One of the notable one (which I am using it as a separate fork in my org) is this one: https://github.com/resemble-ai/Resemblyzer

I would be happy to contribute to the feature of speaker identification and classification after I make myself with the DeepSpeech's codebase",interesting enhancement quite many work related well one notable one separate fork one would happy contribute feature speaker identification classification make,issue,positive,positive,positive,positive,positive,positive
534473266,"@deevyea I'm closing this since there is no issue here. If you think docs should be improved, you are welcome to open a new issue and explain what / where it is unclear and/or send a PR :)",since issue think welcome open new issue explain unclear send,issue,negative,positive,positive,positive,positive,positive
534472787,"@chrisspen We've renamed to `confidence` and improved doc, I'm closing this issue, feel free to open a new one if you have other feedback :)",confidence doc issue feel free open new one feedback,issue,positive,positive,positive,positive,positive,positive
534419899,"> Not everyone can afford to upgrade to an RPi 4 confused

We use the same builds for RPi3 and RPi4, so the improvement will benefit also to those users. It's just that on RPi3 we can't provide faster than realtime.



> Also, what if the GPU is being used for something else?

I suspect you were referring to CPU. Well, as I said, there was plenty of room for other operations.



> would using the GPU anyway yield faster results at all? Worth investigating perhaps?

If you read the history, you will learn I already spent several **weeks** investigating using OpenCL on those boards (and others), and that there are several road blocks.

On RPi3, the driver had so much limitation that it would be far far away from even being able to compile the model to something runnable.

So if you care about that, fund that development and/or insist on TensorFlow upstream to better support OpenCL.",everyone afford upgrade confused use improvement benefit also ca provide faster also used something else suspect well said plenty room would anyway yield faster worth investigating perhaps read history learn already spent several investigating several road driver much limitation would far far away even able compile model something runnable care fund development insist upstream better support,issue,positive,positive,positive,positive,positive,positive
534418246,"> Hi,
> 
> I am getting 404 Error while downloading convert_graphdef_memmapped_format file. Looks like an upstream issues. Would you please have a look and help is much appreciated.
> 
> Please find the command below to reproduce the issue.
> 
> ```
> python util/taskcluster.py --target target-util --source tensorflow --artifact convert_graphdef_memmapped_format
> 
> Downloading https://index.taskcluster.net/v1/task/project.deepspeech.tensorflow.pip.master.cpu/artifacts/public/convert_graphdef_memmapped_format ...
> Traceback (most recent call last):
>   File ""util/taskcluster.py"", line 157, in <module>
>     main()
>   File ""util/taskcluster.py"", line 151, in main
>     maybe_download_tc(target_dir=args.target, tc_url=get_tc_url(args.arch, args.artifact, args.branch))
>   File ""util/taskcluster.py"", line 57, in maybe_download_tc
>     urllib.request.urlretrieve(tc_url, target_file, reporthook=(report_progress if progress else None))
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 248, in urlretrieve
>     with contextlib.closing(urlopen(url, data)) as fp:
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 223, in urlopen
>     return opener.open(url, data, timeout)
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 532, in open
>     response = meth(req, response)
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 642, in http_response
>     'http', request, response, code, msg, hdrs)
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 570, in error
>     return self._call_chain(*args)
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 504, in _call_chain
>     result = func(*args)
>   File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/urllib/request.py"", line 650, in http_error_default
>     raise HTTPError(req.full_url, code, msg, hdrs, fp)
> urllib.error.HTTPError: HTTP Error 404: Not Found
> ```
> 
> The same issue when I try to access from the browser. Could you please help me out here.
> I have followed the thread from this link --> https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984
> 
> No luck so far!

No, that's expected, please use `--branch`, this should generate branch link like: https://index.taskcluster.net/v1/task/project.deepspeech.tensorflow.pip.master.cpu/artifacts/public/convert_graphdef_memmapped_format

I'm not sure how to make that more clear in the docs, it's already stated at several places that TensorFlow version should be X for DeepSpeech release Y.",hi getting error file like upstream would please look help much please find command reproduce issue python target source artifact recent call last file line module main file line main file line progress else none file line data file line return data file line open response response file line request response code file line error return file line result file line raise code error found issue try access browser could please help thread link luck far please use branch generate branch link like sure make clear already stated several version release,issue,positive,positive,positive,positive,positive,positive
534299240,"Not everyone can afford to upgrade to an RPi 4 :confused: 

Also, what if the GPU is being used for something else? And even if the CPU _isn't_ maxed out, would using the GPU anyway yield faster results at all? Worth investigating perhaps?",everyone afford upgrade confused also used something else even would anyway yield faster worth investigating perhaps,issue,negative,negative,neutral,neutral,negative,negative
534277323,"FTR, with RPi4 and switching to TFLite runtime, we exceed realtime with only one core at 100%. So the incentive to leverage GPU on those boards is getting lower.",switching exceed one core incentive leverage getting lower,issue,negative,neutral,neutral,neutral,neutral,neutral
534104848,"Then it's something else. The learning rates are saved, but maybe something else is missing?",something else learning saved maybe something else missing,issue,negative,negative,negative,negative,negative,negative
534103488,">The loss being different is most likely because epoch 0 of the new run is equivalent to starting epoch 5 from scratch again.

epoch 0 of the new run should be equivalent to epoch 5 from scratch, but they are not. This is my question.

Thank you, @reuben .",loss different likely epoch new run equivalent starting epoch scratch epoch new run equivalent epoch scratch question thank,issue,negative,positive,neutral,neutral,positive,positive
534100318,The learning rate and momentum variables of Adam are already saved in the checkpoint. The loss being different is most likely because epoch 0 of the new run is equivalent to starting epoch 5 from scratch again.,learning rate momentum already saved loss different likely epoch new run equivalent starting epoch scratch,issue,negative,positive,neutral,neutral,positive,positive
534097589,"Thank you for replying, @lissyx 

> > Sometimes, basically when you have low resources, your training may stop unexpectedly!
> 
> That should not happen. But again, without more context ...
> 
Ok, here is what I am having:
1. I have run a training on my own data with lr=0.0001.
2. It finished epoch 4 without any problems, this took around 22 hours on my low-resources laptop.
3. During epoch 5, the python process was killed unexpectedly due to RAM issues.
4. I need to continue training from where it left without loosing the progress. 
5. started new training with the same exact parameters, including lr=0.0001. Here, my model was not randomly initialized, but I loaded the best development checkpoint (which was saved after epoch 4) and doing fine tuning on it, again I need not to loose the past work. 
6. The loss results generated of steps from epoch 0 of the new training are different than those of epoch 5 from the killed past training.
7. I think they should be the same in my case. I think this is due to learning rate. starting from lr=0.0001, on epoch 5 the optimizer will work on decayed lr value not the 0.0001. right? 

> > Is it possible to add a feature to load the last reached learning rate value to continue the optimization from there?
> 
> I'm unsure about the need here: you have that in your shell script already

What I have in my shell script is the starting/initial learning rate. You are using AdamOptimizer, which updates the learning rate inside, step by step. The optimization of the next step depends on the this new learning rate value.

sorry for my English, I hope this is more clear now.",thank sometimes basically low training may stop unexpectedly happen without context run training data finished epoch without took around epoch python process unexpectedly due ram need continue training left without loosing progress new training exact model randomly loaded best development saved epoch fine tuning need loose past work loss epoch new training different epoch past training think case think due learning rate starting epoch work decayed value right possible add feature load last learning rate value continue optimization unsure need shell script already shell script learning rate learning rate inside step step optimization next step new learning rate value sorry hope clear,issue,positive,positive,neutral,neutral,positive,positive
534081447,"> This is due to learning rate change, right?

hard to tell without more context ...


> Sometimes, basically when you have low resources, your training may stop unexpectedly!

That should not happen. But again, without more context ...


> Is it possible to add a feature to load the last reached learning rate value to continue the optimization from there?

I'm unsure about the need here: you have that in your shell script already",due learning rate change right hard tell without context sometimes basically low training may stop unexpectedly happen without context possible add feature load last learning rate value continue optimization unsure need shell script already,issue,negative,negative,neutral,neutral,negative,negative
533982002,"Your system is running out of memory during training, from the looks of it at the end of the first epoch. We sort input samples by size, so the largest samples will be processed at the end of epochs. You should probably look if there are any unusually large samples and remove them, or if there aren't any, reduce your batch size.

-- reuben

> On 23 Sep 2019, at 07:24, Narasimman <notifications@github.com> wrote:
> 
> ﻿
> While during custom training I'm getting above mentioned error. Please any once explain what is the error and how to solve that. After that error, the training is automatically starting from first.
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",system running memory training end first epoch sort input size end probably look unusually large remove reduce batch size wrote custom training getting error please explain error solve error training automatically starting first thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
533977810,"> Maybe this topic shouldn't go here, but:
> On the use of VRAM, is there any way not to assign everything when inferring?
> Make a modification to the code ""config.gpu_options.allow_growth = True"" and it works, but only to train the model.

That's not really the problem here ...",maybe topic go use way assign everything make modification code true work train model really problem,issue,negative,positive,positive,positive,positive,positive
533977627,"@NarasimmanSaravana1994 You're getting `OOM`, this means you are exhausting your GPU memory. Without more context that your delebarately removed from the issue template, we cannot help you. Issues are for bugs, please ues Discourse for support.",getting exhausting memory without context removed issue template help please discourse support,issue,positive,negative,negative,negative,negative,negative
533963139,"While during custom training I'm getting above mentioned error. Please any once explain what is the error and how to solve that. After that error, the training is automatically starting from first.",custom training getting error please explain error solve error training automatically starting first,issue,negative,positive,positive,positive,positive,positive
533924391,"@rhamnett both augs on features (additive and multiplicative noise) follow a normal distribution with the indicated standard deviation. If you set the standard deviation of ```data_aug_features_additive``` of 0.5, it means that 99.7% of values that will be added to the features will be within the range [-1.5, 1.5] (which corresponds to 3 stds around the mean). The same goes for multiplicative (but in this case the mean is set to 1, as this the neutral factor of multiplication).

You can check more information about normal distribution in the following links: [std_deviation](https://en.wikipedia.org/wiki/Standard_deviation), [sigma_rule](https://en.wikipedia.org/wiki/68–95–99.7_rule).

Now, to which range of values is the best, I'm afraid you can only find by experimenting different setups. You can try to check/debug which values are normally found on feature-space and try to get some intuition on how to set these parameters, but in the end you will have to try them to check which parameters work best.
",additive multiplicative noise follow normal distribution standard deviation set standard deviation added within range around mean go multiplicative case mean set neutral factor multiplication check information normal distribution following link range best afraid find different try normally found try get intuition set end try check work best,issue,positive,positive,positive,positive,positive,positive
533921652,"Hello, it's difficult to understand what a practical value for the std value of flags such as data_aug_features_additive/data_aug_features_multiplicative without a more detailed explanation or example.

For example, what is the result of the noise by setting it closer to 1 than closer to 0?",hello difficult understand practical value value without detailed explanation example example result noise setting closer closer,issue,negative,negative,neutral,neutral,negative,negative
533905441,"Maybe this topic shouldn't go here, but:
On the use of VRAM, is there any way not to assign everything when inferring?
Make a modification to the code ""config.gpu_options.allow_growth = True"" and it works, but only to train the model. ",maybe topic go use way assign everything make modification code true work train model,issue,negative,positive,positive,positive,positive,positive
533825062,Closing PR will submit again with one clean commit,submit one clean commit,issue,positive,positive,positive,positive,positive,positive
533695572,"https://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html

COPYING
This corpus is licensed under Open Data Commons Attribution License (ODC-By) v1.0.
http://opendatacommons.org/licenses/by/1.0/
http://opendatacommons.org/licenses/by/summary/",corpus licensed open data common attribution license,issue,negative,negative,negative,negative,negative,negative
533621928,"I am a bachelors student. yes please, any help would be appreciated. Plus, I also need some guidance for the collection of Urdu audios data
",student yes please help would plus also need guidance collection data,issue,positive,neutral,neutral,neutral,neutral,neutral
533618677,"There is complete guide for builting language model of some other language.
I will try to find that link.
You can look for that too.
Follow those instructions then.
Once you build it, you will be fine.
Are you a mastere student or bachelors?



On Fri, Sep 20, 2019, 12:11 PM areeba97 <notifications@github.com> wrote:

> I wanted to use this model for urdu language .But I found this in FAQ
> ''
> DeepSpeech's requirements for the data is that the transcripts match the
> [a-z ]+ regex, and that the audio is stored WAV (PCM) files. ''
>
> How can I design a neural network for speech transcription for languages
> like urdu ?
>
> Hi, I wanted to do whether you had any success with the Urdu Language
> Model? I am currently working on Urdu Speech to text for my final year
> project and would love to get some help and guidance?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/634?email_source=notifications&email_token=AKPSMJFXFDJIABQJORMUGD3QKTYZNA5CNFSM4DPKXOE2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7HFVUA#issuecomment-533617360>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AKPSMJBPEPYSX7I6HINJSPDQKTYZNANCNFSM4DPKXOEQ>
> .
>
",complete guide language model language try find link look follow build fine student wrote use model language found data match audio design neural network speech transcription like hi whether success language model currently working speech text final year project would love get help guidance reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
533617659,"> For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).
> 
> If you've found a bug, or have a feature request, then please create an issue with the following information:
> 
> * **Have I written custom code (as opposed to running examples on an unmodified clone of the repository)**: No
> * **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
> * **TensorFlow installed from (our builds, or upstream TensorFlow)**: Docker
> * **TensorFlow version (use command below)**: b'v1.13.1-0-g6612da8951' 1.13.1
> * **Python version**:  python3.6
> * **Bazel version (if compiling from source)**:
> * **GCC/Compiler version (if compiling from source)**:
> * **CUDA/cuDNN version**: Docker
> * **GPU model and memory**: Docker
> * **Exact command to reproduce**:
> 
> You can obtain the TensorFlow version with
> 
> ```shell
> python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
> ```
> 
> Please describe the problem clearly. Be sure to convey here why it's a bug or a feature request.
> 
> Include any logs or source code that would be helpful to diagnose the problem. For larger logs, link to a Gist, not a screenshot. If including tracebacks, please include the full traceback. Try to provide a reproducible test case.
> 
> May i ask whether is normal or could accept that the training loss not lower than 12 ?
> The data is Chinese pinyin format, like `lv4 shi4 yang2 chun1 yan1 jing3 da4 kuai4 wen2 zhang1 de5 di3 se4 si4 yue4 de5 lin2 luan2 geng4 shi4 lv4 de5 xian1 huo2 xiu4 mei4 shi1 yi4 ang4 ran2`
> 
> ```
> Epoch 10 |   Training | Elapsed Time: 4:14:48 | Steps: 30125 | Loss: 12.994944
> Epoch 10 | Validation | Elapsed Time: 0:16:46 | Steps: 1856 | Loss: 18.219204 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 11 |   Training | Elapsed Time: 4:33:18 | Steps: 30125 | Loss: 12.839252
> Epoch 11 | Validation | Elapsed Time: 0:18:26 | Steps: 1856 | Loss: 17.854801 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 12 |   Training | Elapsed Time: 4:30:30 | Steps: 30125 | Loss: 12.885872
> Epoch 12 | Validation | Elapsed Time: 0:19:40 | Steps: 1856 | Loss: 18.398127 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 13 |   Training | Elapsed Time: 4:28:30 | Steps: 30125 | Loss: 12.913519
> Epoch 13 | Validation | Elapsed Time: 0:16:31 | Steps: 1856 | Loss: 17.746488 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 14 |   Training | Elapsed Time: 4:15:46 | Steps: 30125 | Loss: 13.052069
> Epoch 14 | Validation | Elapsed Time: 0:16:49 | Steps: 1856 | Loss: 17.809107 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 15 |   Training | Elapsed Time: 4:14:39 | Steps: 30125 | Loss: 13.011203
> Epoch 15 | Validation | Elapsed Time: 0:16:46 | Steps: 1856 | Loss: 18.019009 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 16 |   Training | Elapsed Time: 4:29:48 | Steps: 30125 | Loss: 12.950395
> Epoch 16 | Validation | Elapsed Time: 0:18:30 | Steps: 1856 | Loss: 17.927670 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 17 |   Training | Elapsed Time: 4:37:58 | Steps: 30125 | Loss: 12.883698
> Epoch 17 | Validation | Elapsed Time: 0:19:39 | Steps: 1856 | Loss: 18.019366 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 18 |   Training | Elapsed Time: 4:30:21 | Steps: 30125 | Loss: 13.077873
> Epoch 18 | Validation | Elapsed Time: 0:16:30 | Steps: 1856 | Loss: 18.595674 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 19 |   Training | Elapsed Time: 4:17:11 | Steps: 30125 | Loss: 13.077543
> Epoch 19 | Validation | Elapsed Time: 0:18:19 | Steps: 1856 | Loss: 18.086610 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 20 |   Training | Elapsed Time: 4:17:33 | Steps: 30125 | Loss: 13.060236
> Epoch 20 | Validation | Elapsed Time: 0:16:46 | Steps: 1856 | Loss: 18.139807 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 21 |   Training | Elapsed Time: 4:27:42 | Steps: 30125 | Loss: 12.917591
> Epoch 21 | Validation | Elapsed Time: 0:18:36 | Steps: 1856 | Loss: 17.726031 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> Epoch 22 |   Training | Elapsed Time: 4:33:30 | Steps: 30125 | Loss: 12.972870
> Epoch 22 | Validation | Elapsed Time: 0:19:48 | Steps: 1856 | Loss: 17.455123 | Dataset: /home/data/total_csv/words_pinyin/data/chn_dev.csv
> ```

Hello @tsungruihon , I have a question about how you generate your THCHS-30 alphabet.txt of pinyin dataset, and what's the format?  Is it [a-z]?",support please use discourse found bug feature request please create issue following information written custom code opposed running unmodified clone repository o platform distribution upstream docker version use command python version python version source version source version docker model memory docker exact command reproduce obtain version shell python import print please describe problem clearly sure convey bug feature request include source code would helpful diagnose problem link gist please include full try provide reproducible test case may ask whether normal could accept training loss lower data format like shi yang chun yan jing da wen de di se si de lin shi de shi ran epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss epoch training time loss epoch validation time loss hello question generate format,issue,negative,positive,positive,positive,positive,positive
533617360,"> 
> 
> I wanted to use this model for urdu language .But I found this in FAQ
> ''
> DeepSpeech's requirements for the data is that the transcripts match the [a-z ]+ regex, and that the audio is stored WAV (PCM) files. ''
> 
> How can I design a neural network for speech transcription for languages like urdu ?

Hi, I wanted to do whether you had any success with the Urdu Language Model? I am currently working on Urdu Speech to text for my final year project and would love to get some help and guidance? ",use model language found data match audio design neural network speech transcription like hi whether success language model currently working speech text final year project would love get help guidance,issue,positive,positive,positive,positive,positive,positive
533295203,"@kjcole I'm going to close that, we're taking steps for making the documentation clearer in #2339, and I think we might re-visit all the READMEs we have. Please do not hesitate to share feedback on the doc, but yours has been valuable in the process of re-thinking docs.",going close taking making documentation clearer think might please hesitate share feedback doc valuable process,issue,positive,neutral,neutral,neutral,neutral,neutral
533294468,"> Even for me when I start training a new model it is continuing from the previous training from a release model checkpoint, I have deleted /root/.local/share/deepspeech/checkpoints and also specified empty folder before I start training a model.

Please check your environment. Looks like there is no issue or nothing actionable here.",even start training new model previous training release model also empty folder start training model please check environment like issue nothing actionable,issue,negative,negative,neutral,neutral,negative,negative
533294094,"> So, I change this beam_width parameter and do not train. Just run the script(compared to the last run script: comment out the two lines --train_files, --dev_files, and change --beam_width)

I'm sorry but I don't understand what you are saying ? Do you change `beam_width` at export time ? That's not enough, as @bernardohenz mentionned above.


> I find a strange phenomenon. When I using gpu-arch deepspeech to infer(using just one Telsa V100). Almost 32G memory of GPU is used, but the GPU-Util is 0%. Is it a cuda/cudnn compatibility issue?

Np, CUDA/CUDNN compatibility issue would just mean not working at all. Decoding is not done on GPU, and you have 32GB used because TensorFlow allocates everything it can, by default. And it's at 0% of utilization because ... decoding is done on CPU.",change parameter train run script last run script comment two change sorry understand saying change export time enough find strange phenomenon infer one almost memory used compatibility issue compatibility issue would mean working done used everything default utilization done,issue,negative,negative,negative,negative,negative,negative
533217790,"Sorry for the delay, even a basic install in an Enterprise is a hassle. 

This cleared up my issue right away, but you may want to capture the 64bit requirement in the documentation. Tensorflow may have done this and I overlooked it, but it can't hurt to duplicate that here. 

Thanks again!",sorry delay even basic install enterprise hassle issue right away may want capture bit requirement documentation may done ca hurt duplicate thanks,issue,negative,negative,neutral,neutral,negative,negative
532846286,"Sounds likely, I attempted to install TensorFlow from source as well, and ran into architecture targeting errors (x86 vs x64). I'll give this a shot and report back. ",likely install source well ran architecture give shot report back,issue,negative,neutral,neutral,neutral,neutral,neutral
532819777,">     * Python Ver: Python-36-32

Try 64-bits version ?",python python try version,issue,negative,neutral,neutral,neutral,neutral,neutral
532041802,"I find a strange phenomenon. When I using gpu-arch deepspeech to infer(using just one Telsa V100). Almost 32G memory of  GPU is used, but the GPU-Util is 0%. Is it a cuda/cudnn compatibility issue?",find strange phenomenon infer one almost memory used compatibility issue,issue,negative,negative,neutral,neutral,negative,negative
532039341,"> > I have asked a man who trained the Chinese model serveral months ago. He said he also meet the same problem. And his solution is reducing the beam_width to < 50.
> 
> Do you have links ?
> 
> > But no matter how I change the beam_width(defalut 1024 -> 128 -> 10 -> 3)，the inference time is still about 2000s.
> 
> Are you sure you are doing it right ?
> 
> > Then I get the new model in the {export dir} and use it to infer. Is this the right way to get the new model?
> 
> I'm not sure I understand your question here.

Sorry, I do not have that link. 
I'm not sure that I do it right. So, I want to describe how I do it. {Then I get the new model in the {export dir} and use it to infer. Is this the right way to get the new model}

Maybe I didn't describe it clearly. 

I mean, I want to change the beam width but  I'm not sure where I should change the code.
I only find it in one place.(parameter --beam_width in train processing which are listed in the session #Train of my problem)
So, I change this beam_width parameter and do not train. Just run the script(compared to the last run script:  comment out  the two lines  --train_files, --dev_files,  and change --beam_width)
python3 -u DeepSpeech.py
--test_files /home/lujiahui/DeepSpeech/data/aishell2/csv/aishell2_test_10.csv
--train_batch_size 64
--dev_batch_size 32
--test_batch_size 2
--learning_rate 0.00005
--n_hidden 1024
--es_steps 6
--epochs 700
--alphabet_config_path /home/lujiahui/DeepSpeech/data/new_alphabet.txt
--checkpoint_dir {...}
--export_dir {...}
--beam_width 10  # change from 128 to 10
""$@""

Then, I can get a new model in the export_dir.
I want to know is this new model with the new beam_width which I just change?




",man trained model ago said also meet problem solution reducing link matter change inference time still sure right get new model export use infer right way get new model sure understand question sorry link sure right want describe get new model export use infer right way get new model maybe describe clearly mean want change beam width sure change code find one place parameter train listed session train problem change parameter train run script last run script comment two change python change get new model want know new model new change,issue,positive,positive,positive,positive,positive,positive
531798579,"I was the one who filed that bug :)

Yes, we workaround it in our tensorflow fork/native client: https://github.com/mozilla/tensorflow/commit/164adb28df02f3375185cf5f8f25624e0a9c9083",one bug yes client,issue,negative,neutral,neutral,neutral,neutral,neutral
531798537,"One way of reducing the inference time on large alphabets is to set a lower cutof_top_n (https://github.com/mozilla/DeepSpeech/blob/master/native_client/deepspeech.cc#L340). Of course, you will have to compile the decoder if you make this change.",one way reducing inference time large set lower course compile make change,issue,negative,positive,positive,positive,positive,positive
531794347,"> I have asked a man who trained the Chinese model serveral months ago. He said he also meet the same problem. And his solution is reducing the beam_width to < 50.

Do you have links ?


> But no matter how I change the beam_width(defalut 1024 -> 128 -> 10 -> 3)，the inference time is still about 2000s.

Are you sure you are doing it right ?


> Then I get the new model in the {export dir} and use it to infer. Is this the right way to get the new model?

I'm not sure I understand your question here.",man trained model ago said also meet problem solution reducing link matter change inference time still sure right get new model export use infer right way get new model sure understand question,issue,positive,positive,positive,positive,positive,positive
531789512,"I have asked a man who trained the Chinese model serveral months ago. He said he also meet the same problem. And his solution is reducing the beam_width to < 50. But no matter  how I change the beam_width(defalut 1024 -> 128 -> 10 -> 3)，the inference time is still about 2000s.
Every time I changed beam_width, I will comment out the --train_files and  --dev_files in the run script and rerun the script. Then I get the new model in the {export dir} and use it to infer.  Is this the right way to get the new model?",man trained model ago said also meet problem solution reducing matter change inference time still every time comment run script rerun script get new model export use infer right way get new model,issue,negative,positive,positive,positive,positive,positive
531776200,"The implementation predates those APIs. We haven't tested it specifically, but I don't see any reason it wouldn't work the same way.",implementation tested specifically see reason would work way,issue,negative,neutral,neutral,neutral,neutral,neutral
531697545,"The TaskCluster route part is what's checked by that code, and that was working fine. But the artifact name was wrong.",route part checked code working fine artifact name wrong,issue,negative,negative,neutral,neutral,negative,negative
531682245,"@reuben It's strange, we have code that checks for this, so it should have been working / failing if we broke it: https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-tests-utils.sh#L804-L824",strange code working failing broke,issue,negative,negative,neutral,neutral,negative,negative
531681437,"This is already reported, decoder takes a longer time than we would like on large-alphabet languages.",already longer time would like,issue,negative,neutral,neutral,neutral,neutral,neutral
531622543,Unfortunately not. I ran into a few issues and work got very busy lately. Hope to come back to but not in the near-term.,unfortunately ran work got busy lately hope come back,issue,negative,negative,negative,negative,negative,negative
531580016,"> @SamahZaro can you try this PR? #2366

It worked great, thank you. Removed `--arch` argument and tried the PR for the `--branch`.",try worked great thank removed arch argument tried branch,issue,positive,positive,positive,positive,positive,positive
531564007,"Oh, wait, looks like we also don't support `--branch` there. Let me take a look.",oh wait like also support branch let take look,issue,positive,neutral,neutral,neutral,neutral,neutral
531536465,"Yes, the initial issue has been solved. Please open a new issue with Visual Studio version, Net version, GPU info, and any other information that you may consider relevant. We faced that issue before so, I'll investigate.

Closing this one.",yes initial issue please open new issue visual studio version net version information may consider relevant faced issue investigate one,issue,positive,positive,neutral,neutral,positive,positive
531523167,My use-case for this would be whenever I am running training I can’t process inference jobs on the same server so the queue starts backing up.,would whenever running training process inference server queue backing,issue,negative,neutral,neutral,neutral,neutral,neutral
531506173,"@carlfm01 Oh, I see the issue now. I thought the Nuget package would only contain the prebuilt .so file, but it is basically a build of the DeepSpeechClient project plus the .so file. It works now thanks!

I do have a follow up issue though. When I use the -GPU package instead of the normal one, there are two issues. The first one is that the .so file does not get added as a project item and hence it is not automatically copied to the build folder. I copied the .so file manually to bin\x64\Debug like it automatically happens with the normal DeepSpeech Nuget package. But for some reason I still get a DllNotFoundException, which is a little odd, since it resides side by side in the same folder with the rest of the files.
Should I open another issue to track this and close this issue?",oh see issue thought package would contain file basically build project plus file work thanks follow issue though use package instead normal one two first one file get added project item hence automatically copied build folder copied file manually like automatically normal package reason still get little odd since side side folder rest open another issue track close issue,issue,positive,positive,neutral,neutral,positive,positive
531499038,"With your files it fails, and looks like somehow it is still holding the latest reference of DeepSpeechClient, so I removed it manually from reference/projects and then installed the NuGet, now it will warn about missing params, that due to a recent change to the params, only need to apply this change: https://github.com/carlfm01/DeepSpeech/commit/c05eac7f47520c62e86b8ed3a6822becb63a56af

",like somehow still holding latest reference removed manually warn missing due recent change need apply change,issue,negative,positive,neutral,neutral,positive,positive
531472726,"@carlfm01 There are no references to local projects other than DeepSpeechConsole referencing DeepSpeechClient. And that reference is needed to build. I cleaned the solution and rebuilt but that didn't change anything.

I have uploaded the contents of bin\x64\Debug here: https://uni-paderborn.sciebo.de/s/lvf90f369uEE4qw in case you want to try and run it on your machine.

Of course, I didn't include the contents of https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz which I also have in that folder.

Any other ideas?",local reference build solution rebuilt change anything content case want try run machine course include content also folder,issue,negative,neutral,neutral,neutral,neutral,neutral
531443115,"I just saw this thread. Another use case: I was trying to integrate this recognition model in a web service along with other deep learning models. By letting the model consume all GPU memory, I won't be able to load/run other models concurrently.",saw thread another use case trying integrate recognition model web service along deep learning model consume memory wo able concurrently,issue,negative,positive,positive,positive,positive,positive
531376685,"> FWIW: When I create another build architecture (x86) I am getting the expected: ""An unhandled exception of type 'System.BadImageFormatException' occurred in DeepSpeechClient.dll
> Additional information: An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)""

That's excpected, DS only runs on x64 configuration.



> I don't need to install things, right?

No, I'm deploying to end user machines and it only needs .Net Framework.



> The steps in my initial post are sufficient, right?

Yes, looks correct. Please before installing the NuGet remove any reference to local projects, then clean the solution and now install the NuGet. ",create another build architecture getting unhandled exception type additional information attempt made load program incorrect format exception configuration need install right end user need framework initial post sufficient right yes correct please remove reference local clean solution install,issue,positive,positive,positive,positive,positive,positive
531368530,"@carlfm01 Yes, it is set to x64.

FWIW: When I create another build architecture (x86) I am getting the expected: ""An unhandled exception of type 'System.BadImageFormatException' occurred in DeepSpeechClient.dll
Additional information: An attempt was made to load a program with an incorrect format. (Exception from HRESULT: 0x8007000B)""

I don't need to install things, right? The steps in my initial post are sufficient, right?",yes set create another build architecture getting unhandled exception type additional information attempt made load program incorrect format exception need install right initial post sufficient right,issue,positive,positive,positive,positive,positive,positive
531367110,"Yes, you are using the correct models, now can you make sure that vs is using x64 on your configuration manager? Sometimes VS resets it, I know it is a pain.
https://discourse.mozilla.org/t/compiling-for-windows/32939/67?u=carlfm01

Sorry, I dont use teamviewer/Skype",yes correct make sure configuration manager sometimes know pain sorry dont use,issue,negative,neutral,neutral,neutral,neutral,neutral
531364303,"Hi @carlfm01 ,

I took the models from here: https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz

I am not getting to the point where audio is loaded. I am simply starting the Sample. The exception is thrown in line 65 of the Console App ""DeepSpeechConsole"".

I can debug into sttClient.CreateModel and in this method the exception gets thrown as described above. That would be line 63 in DeepSpeech.cs.

If you'd be up for it and if it makes sense to sort this out, we could do a quick Teamviewer/Skype/... session.",hi took getting point audio loaded simply starting sample exception thrown line console method exception thrown would line sense sort could quick session,issue,negative,positive,positive,positive,positive,positive
531361382,"Hello @larsbeck, make sure that you are using 0.5.1 models, can you please share more info about your audio?
Additionally can you debug step by step prior to the error using VS?",hello make sure please share audio additionally step step prior error,issue,negative,positive,positive,positive,positive,positive
531356902,Obviously not something we experience in CI. Maybe @carlfm01 can have more insights ?,obviously something experience maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
531349630,"> Is that for the audio driver issue your refered to?

No, WinAppDriver just executes a test project just like selenium. To run the test project WinAppDriver needs to be installed on the test agent, I don't know how to do it with TaskCluster.

The WPF example records the windows audio output and feeds the stream, the issue happens with VM where the audio driver is disabled, thus the example fails on the recording. 

Now about Azure pipelines, is just another CI, with the agents to run WinAppDriver tests.

Before going further with this I'll add a test project to my fork and start testing compatibility from there.",audio driver issue test project like selenium run test project need test agent know example audio output stream issue audio driver disabled thus example recording azure another run going add test project fork start testing compatibility,issue,negative,negative,negative,negative,negative,negative
531183907,"> > > This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?
> > 
> > 
> > I'm not judging, I'm trying to understand your usecase.
> 
> I did not feel judged in anyway, I was just explaining my point of view and just wanted to know why it is counterintuitive from your point of view.

Well it is counter-intuitive for the reasons @reuben gave, but the changes makes sense",available want fully think trying understand feel anyway explaining point view know point view well gave sense,issue,negative,positive,positive,positive,positive,positive
531183499,"> > This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?
> 
> In general with a well behaved dataset and the right batch size you can fully utilize a TITAN RTX doing a single training run, so it's unusual to split a single GPU into two runs. Anyway, I'll gladly take the PR if you add a flag for the allow_growth flag.

My experiment was based on training different batch_size that's why i encountered this case.
I added the required modification.",available want fully think general well right batch size fully utilize single training run unusual split single two anyway gladly take add flag flag experiment based training different case added modification,issue,positive,positive,positive,positive,positive,positive
531182964,"> > This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?
> 
> I'm not judging, I'm trying to understand your usecase.

I did not feel judged in anyway, I was just explaining my point of view and just wanted to know why it is counterintuitive from your point of view.",available want fully think trying understand feel anyway explaining point view know point view,issue,negative,positive,positive,positive,positive,positive
531178036,"> This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?

I'm not judging, I'm trying to understand your usecase.",available want fully think trying understand,issue,negative,positive,positive,positive,positive,positive
531176307,"> This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?

In general with a well behaved dataset and the right batch size you can fully utilize a TITAN RTX doing a single training run, so it's unusual to split a single GPU into two runs. Anyway, I'll gladly take the PR if you add a flag for the allow_growth flag.",available want fully think general well right batch size fully utilize single training run unusual split single two anyway gladly take add flag flag,issue,positive,positive,positive,positive,positive,positive
531175760,"> > > > which in turn block concurrent trainings.
> > > 
> > > 
> > > You are running several training on the same system ? How many GPUs do you have ?
> > 
> > 
> > Yes that was the case, I am training on a NVIDIA TITAN RTX.
> 
> Only one ? That feels counter-intuitive to overload just a single GPU for training

This is the resources available to me now and I want to fully utilise it, so why do you think this is counterintuitive?",turn block concurrent running several training system many yes case training one overload single training available want fully think,issue,negative,positive,positive,positive,positive,positive
531170108,"> > > which in turn block concurrent trainings.
> > 
> > 
> > You are running several training on the same system ? How many GPUs do you have ?
> 
> Yes that was the case, I am training on a NVIDIA TITAN RTX.

Only one ? That feels counter-intuitive to overload just a single GPU for training",turn block concurrent running several training system many yes case training one overload single training,issue,negative,positive,positive,positive,positive,positive
531169723,"> > which in turn block concurrent trainings.
> 
> You are running several training on the same system ? How many GPUs do you have ?

Yes that was the case, I am training on a NVIDIA TITAN RTX.",turn block concurrent running several training system many yes case training,issue,negative,positive,positive,positive,positive,positive
531162660,"> which in turn block concurrent trainings.

You are running several training on the same system ? How many GPUs do you have ?",turn block concurrent running several training system many,issue,negative,positive,positive,positive,positive,positive
531149151,"> I know Azure pipelines supports WinAppDriver, what about using it?

Is that for the audio driver issue your refered to? If that is specific to Azure, we are blocked.



> we already build just to make sure that client changes is not going to break the example

Ok, sorry, I forgot. So I guess we already cover our bases as much as we can in the current context.",know azure audio driver issue specific azure blocked already build make sure client going break example sorry forgot guess already cover base much current context,issue,negative,negative,negative,negative,negative,negative
531052150,"> 
> 
>  Do you think there is value in doing so?

If you mean only building, no, we already build just to make sure that client changes is not going to break the example. Building and testing, yes, but it requires to code a test project and setup https://github.com/Microsoft/WinAppDriver to work with the taskcluster. It may also requires a hack to record output/input to mimic user usage. Time ago I tried to run the output record to test the stream feature on a VM but audio driver error showed up.  Before starting we need to make sure that the audio driver is properly working on the build/test agent.

> 
> Also, all the other examples depends on fixed, released versions. This one seems not

The dependecy to a released NuGet was removed by a request on a PR, instead the recommendation was to use local link to the projects.


I know Azure pipelines supports WinAppDriver, what about using it?

https://github.com/microsoft/WinAppDriver/blob/master/Docs/CI_AzureDevOps.md",think value mean building already build make sure client going break example building testing yes code test project setup work may also hack record mimic user usage time ago tried run output record test stream feature audio driver error starting need make sure audio driver properly working agent also fixed one removed request instead recommendation use local link know azure,issue,positive,positive,positive,positive,positive,positive
531005860,"@carlfm01 I'm wondering about `examples/net_framework/DeepSpeechWPF/`. It's likely I can only build it, not run it. Do you think there is value in doing so?

Also, all the other examples depends on fixed, released versions. This one seems not",wondering likely build run think value also fixed one,issue,negative,positive,neutral,neutral,positive,positive
530794559,"Use the native client, not the Python package, and pass `--json`. Be careful not to mix versions of the code, as it seems you're doing. The parameters you've had to add were recently removed from master, so it seems you're trying to use the master client against an older version of the package.",use native client python package pas careful mix code add recently removed master trying use master client older version package,issue,negative,positive,neutral,neutral,positive,positive
530696850,"There is no Mandarin model, for any of the many written form of Mandarin, as we do not yet have sufficient training data.",mandarin model many written form mandarin yet sufficient training data,issue,negative,positive,positive,positive,positive,positive
530288466,"> @lissyx I don't have any more logs. The training just stops at this point. I waited for 45 mins for it to start, it didn't. Then when I ran it on a single GPU, it worked as usual.

You should have or force having more logs. `TF_CPP_MIN_LOG_LEVEL` does that, and we have `--log_level` to expose that.",training point start ran single worked usual force expose,issue,negative,negative,negative,negative,negative,negative
530284133,"@lissyx  I don't have any more logs. The training just stops at this point. I waited for 45 mins for it to start, it didn't. Then when I ran it on a single GPU, it worked as usual.",training point start ran single worked usual,issue,negative,negative,negative,negative,negative,negative
530282745,">  `Epoch 0 | Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000`

Sharing more logs could have helped us help you.",epoch training time loss could u help,issue,negative,neutral,neutral,neutral,neutral,neutral
530281457,"Okay, I'll check my installation. Thank you for the help.",check installation thank help,issue,positive,neutral,neutral,neutral,neutral,neutral
530280290,"To be clear, we exercise this code daily and it works fine with one or several GPUs.",clear exercise code daily work fine one several,issue,positive,positive,positive,positive,positive,positive
530280060,"I don't see anything wrong with the way you're calling DeepSpeech.py, so the next most likely thing to be causing this would be a problem with your CUDA setup. Maybe try reinstalling the GPU dependencies (CUDA/cuDNN/NVIDIA driver)? Maybe you need a driver upgrade?",see anything wrong way calling next likely thing causing would problem setup maybe try driver maybe need driver upgrade,issue,negative,negative,negative,negative,negative,negative
530278478,"I don't specify any environment variables while running the multi-gpu code. I just run the code in `DeepSpeech.py` as it is. My machine has two GPUs, and it automatically takes both the GPUs in consideration (when I check `nvidia-smi`, it shows both GPU are being used by the same process).",specify environment running code run code machine two automatically consideration check used process,issue,negative,neutral,neutral,neutral,neutral,neutral
529824137,"Yeah, this field should have a better name like ""confidence"". It's a sum of the log-odds over the entire transcription/beam. You can convert it to be bounded between 0 and 1, but should still not interpret the value in isolation.",yeah field better name like confidence sum entire convert bounded still interpret value isolation,issue,positive,positive,positive,positive,positive,positive
529509009,"> > LGTM, but I still see usages of `n_features_` and `n_context_`, is this expected ?
> 
> Yep, they're now being extracted from the model directly so no need to pass in the magic constants in the API.

Nevermind, it looks like we are doing that since a long time ... :)",still see yep extracted model directly need pas magic like since long time,issue,positive,positive,positive,positive,positive,positive
529482392,"> LGTM, but I still see usages of `n_features_` and `n_context_`, is this expected ?

Yep, they're now being extracted from the model directly so no need to pass in the magic constants in the API.",still see yep extracted model directly need pas magic,issue,negative,positive,positive,positive,positive,positive
529433042,(I'll fix the linter error when merging to avoid unnecessary builds),fix linter error avoid unnecessary,issue,negative,negative,negative,negative,negative,negative
529338207,"The loss depends on the language, the noise in the data set, the original audio format.... Basically there is no general rule.

Also, as this is not a bug or feature request could you move the discussion to [discourse](https://discourse.mozilla.org/c/deep-speech). Thanks.",loss language noise data set original audio format basically general rule also bug feature request could move discussion discourse thanks,issue,negative,positive,positive,positive,positive,positive
529075387,"> @sargense I have no idea how your example number two (without a virtualenv) is working, because it's not supposed to. The `deepspeech` binary is installed when you do `pip install deepspeech`, which is missing from that example. There's probably some namespace pollution happening and you're using the binary installed in the previous step, or something like that.

My bad. Definitely not namespace pollution because each install test was done on a fresh cloud instance spun up for testing. But I definitely did ""pip3 install deepspeech"" and accidentally dropped that piece when editing the paste from history. But testing on different cloud instances and providers, pipping requirements before pip3 installing deepspeech will not always work and sometimes other configuring or dependency installs have to be done.

The new steps in the readme make it exactly as easy it looked in the GIF.",idea example number two without working supposed binary pip install missing example probably pollution happening binary previous step something like bad definitely pollution install test done fresh cloud instance spun testing definitely pip install accidentally piece paste history testing different cloud pip always work sometimes dependency done new make exactly easy gif,issue,positive,negative,neutral,neutral,negative,negative
528954592,"Someone correct me if I'm wrong, but now I'm thinking the probability being returned is actually a logit value, not a raw probability. Following [this explanation](https://sebastiansauer.github.io/convert_logit2prob/), if I convert the probability value returned in the metadata via `math.exp(p / (1. + p))` that gives me a value that's always bounded between 0 and 1.
",someone correct wrong thinking probability returned actually value raw probability following explanation convert probability value returned via value always bounded,issue,negative,negative,negative,negative,negative,negative
528927931,"If I recall correctly, when this was implemented one of the devs said that the probability isn't really interpretable by itself but can be used to compare the confidence of a transcription with an alternative transcription.

But I agree that a percentage that could be used independently of other transcriptions would be more useful.",recall correctly one said probability really interpretable used compare confidence transcription alternative transcription agree percentage could used independently would useful,issue,positive,positive,positive,positive,positive,positive
528751031,"As this is not a bug or feature request, could you move this discussion to [discourse](https://discourse.mozilla.org/c/deep-speech)? Thanks.",bug feature request could move discussion discourse thanks,issue,negative,positive,positive,positive,positive,positive
528362029,"> The error message is telling you exactly what's happening:
> 
> ```
> ERROR: invalid target format: '//native_client:bazel_workspace_status_cmd.sh”'; invalid target name 'bazel_workspace_status_cmd.sh”': target names may not contain non-printable characters: '\x80'
> ```
> 
> The problem is that weird quote mark there: https://apps.timwhitlock.info/unicode/inspect/hex/201D
> 
> \x80 is the second byte in its UTF-8 encoding. bazel is likely decoding that as ASCII. Just clean up your command line to remove any special characters like ” (command line double quotes should be "")

You are right, it was the double quote that was causing the issue. 

So I was able to compile deepspeech, but when I try to compile the language bindings I run into another error:
`

- svs@svs-desktop:~/DeepSpeech/native_client$ make deepspeech
- c++   -std=c++11 -o deepspeech `pkg-config --cflags sox` client.cc  -Wl,--no-as-needed -Wl,-rpath,\$ORIGIN -L/home/svs/tensorflow/bazel-bin/native_client  -ldeepspeech  `pkg-config --libs sox`
- /usr/bin/ld: cannot find -ldeepspeech
- collect2: error: ld returned 1 exit status
- Makefile:22: recipe for target 'deepspeech' failed
- make: *** [deepspeech] Error 1

`
Am I missing a file or is there a link missing?

UPDATE:
So the symbolic link to libdeepspeech.so is broken. I looked into the parent directory where the actual libdeepspeech.so is located( ~/.cache/bazel directory ), and wasn't able to find anything except for another broken symbolic link to libdeepspeech.so which is the same link so the search took me in a circle. So I'm guessing that the libdeepspeech.so file was never created except for an empty link to it.
Should I compile the whole thing again or is there a easy fix?   ",error message telling exactly happening error invalid target format invalid target name target may contain problem weird quote mark second likely ascii clean command line remove special like command line double right double quote causing issue able compile try compile language run another error make origin find collect error returned exit status recipe target make error missing file link missing update symbolic link broken parent directory actual directory able find anything except another broken symbolic link link search took circle guessing file never except empty link compile whole thing easy fix,issue,negative,positive,neutral,neutral,positive,positive
528361979,"Having clear examples to confirm basic functionality would be very useful to deter the kind of naïve posts seen so often from people who've barely read the installation details, tried to go ""off road"", got into trouble and then post a limited description, expecting help :slightly_smiling_face: 

I sympathise with the temptation to try something new with the exciting toys but if they can't be sure it's working for the basics then they can easily waste loads of time and don't learn necessary context (eg how long inference or training should typically take on their system)",clear confirm basic functionality would useful deter kind seen often people barely read installation tried go road got trouble post limited description help temptation try something new exciting ca sure working easily waste time learn necessary context long inference training typically take system,issue,positive,positive,neutral,neutral,positive,positive
528257218,"The error message is telling you exactly what's happening:

    ERROR: invalid target format: '//native_client:bazel_workspace_status_cmd.sh”'; invalid target name 'bazel_workspace_status_cmd.sh”': target names may not contain non-printable characters: '\x80'

The problem is that weird quote mark there: https://apps.timwhitlock.info/unicode/inspect/hex/201D

\x80 is the second byte in its UTF-8 encoding. bazel is likely decoding that as ASCII. Just clean up your command line to remove any special characters like ” (command line double quotes should be "")",error message telling exactly happening error invalid target format invalid target name target may contain problem weird quote mark second likely ascii clean command line remove special like command line double,issue,negative,positive,neutral,neutral,positive,positive
528014512,"I am guessing it is not able to locate bazel_workspace_status_cmd.sh or
maybe some of the previous tensorflfow build is conflicting. Not sure man.

On Wed, Sep 4, 2019 at 6:41 PM michaelguo32 <notifications@github.com>
wrote:

> Wait, are you building deepspeech now?
>
> Yes, I started the whole process from the beginning. So basically I have
> installed all the dependencies, built bazel, created a swapfile, linked the
> natvie_client to the tensorflow directory, and finally ran the build
> command above.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2296?email_source=notifications&email_token=AFDCDNF3QKNNOXR45WC522DQH7XMNA5CNFSM4ILCL3Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD54MBYI#issuecomment-528007393>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AFDCDNCEDGYQPVD3HXF4QTTQH7XMNANCNFSM4ILCL3QQ>
> .
>


-- 
Best Regards,
*Mallesh Dasari*
WINGS Lab, Computer Science
Stony Brook University
*http://www3.cs.stonybrook.edu/~mdasari/
<http://www3.cs.stonybrook.edu/~mdasari/>*
",guessing able locate maybe previous build conflicting sure man wed wrote wait building yes whole process beginning basically built linked directory finally ran build command reply directly view mute thread best lab computer science stony brook university,issue,positive,positive,positive,positive,positive,positive
528007393,"> Wait, are you building deepspeech now?

Yes, I started the whole process from the beginning. So basically I have installed all the dependencies, built bazel, created a swapfile, linked the natvie_client to the tensorflow directory, setup the configuration, and finally ran the build command above.

 ",wait building yes whole process beginning basically built linked directory setup configuration finally ran build command,issue,negative,positive,neutral,neutral,positive,positive
528002658,"> Yes, I didn't need tensorflow library. I was compiling for deepspeech library. Did you make changes to following files as described in my document above?
> 
> `tensorflow/lite/kernels/internal/BUILD,`
> `third_party/aws/BUILD.bazel, `
> `third_party/gpus/crosstool/BUILD.tpl`

Yes, I've patched those files. I now tried following your instructions exactly and ran the following command:
`bazel build --workspace_status_command=”bash native_client/bazel_workspace_status_cmd.sh” --config=monolithic --config=cuda -c opt --copt=-O3 --copt=”-std=gnu99” --copt=”-D_GLIBCXX_USE_CXX11_ABI=0” --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie`

I get the following error:
[error.txt](https://github.com/mozilla/DeepSpeech/files/3575772/error.txt)

",yes need library library make following document yes tried following exactly ran following command build bash opt get following error,issue,negative,positive,neutral,neutral,positive,positive
527997057,"If #432 is completed, people would be able to experiment with ways of handling hints and context assistance more easily (possibly with a view to then including the more broadly applicable successful ones as part of the API)

I like the hints idea but I think it might be valuable to gather together the distinct kinds of scenarios people want to be able to solve. In some cases distinct LMs make sense (switching between them or in combination, eg to extent vocabulary) and in others hints of specific words or potentially classes of word make sense (eg if you expect a number reply it could be handy to bias in favour of numbers whilst still coping with other kinds of response)",people would able experiment way handling context assistance easily possibly view broadly applicable successful part like idea think might valuable gather together distinct people want able solve distinct make sense switching combination extent vocabulary specific potentially class word make sense expect number reply could handy bias whilst still coping response,issue,positive,positive,positive,positive,positive,positive
527940343,"We've had a bunch of people mixing up training and inference docs, so I moved all the training stuff to the bottom where they're discussed more thoroughly.",bunch people training inference training stuff bottom thoroughly,issue,negative,neutral,neutral,neutral,neutral,neutral
527842695,"Yes, I didn't need tensorflow library. I was compiling for deepspeech library. Did you make changes to following files as described in my document above? 

`tensorflow/lite/kernels/internal/BUILD,` 
`third_party/aws/BUILD.bazel, `
`third_party/gpus/crosstool/BUILD.tpl`",yes need library library make following document,issue,negative,neutral,neutral,neutral,neutral,neutral
527787445,"> Commands in that GIF are outdated, I think we should just get rid of it or update it ? cc @kdavis-mozilla

I'm all for getting rid of it @reuben why do you think it's useful to keep?",gif outdated think get rid update getting rid think useful keep,issue,negative,negative,neutral,neutral,negative,negative
527785800,"Yea, those are CUDA 10.0 libraries, for CUDA 10.1 (in my case), it is `libcudart.so.10.1, libcublas.so.10.1, libcusolver.so.10.1`.
Ok, I'll try without conda environment, because most of the lib is a system lib, that doesn't exist in conda env.
",yea case try without environment system exist,issue,negative,neutral,neutral,neutral,neutral,neutral
527780610,"> Since, `libdeepspeech.so` depends on these `libcudart.so.10.0, libcublas.so.10, libcusolver.so.10.0` libraries from cuda, will check those cuda lib in previous version, and try to build.

Those are the CUDA 10.0 dependencies, so if you setup CUDA 10.0, it should work. Also, try to avoid anaconda.",since check previous version try build setup work also try avoid anaconda,issue,negative,negative,negative,negative,negative,negative
527774115,"Three points:

- You should checkout the repo with git lfs
- If you are training on Russian you need to create your own language model following a process like [this](https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md).
- Issues like this which are not bugs or feature requests should be moved to [discourse](https://discourse.mozilla.org/c/deep-speech).",three git training need create language model following process like like feature discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
527772857,"Since, `libdeepspeech.so` depends on these `libcudart.so.10.0, libcublas.so.10, libcusolver.so.10.0` libraries from cuda, will check those cuda lib in previous version, and try to build.",since check previous version try build,issue,negative,negative,negative,negative,negative,negative
527771685,">     1. How many unique hours of data would I need to train a production-ready model?

Depends on you application and the target language.

For unrestricted speech on the order of 5k hours of audio, maybe more. For a command and control application, much less. The exact amount would depend on the number of commands and the variance in the end user's speech patterns.

>     2. If possible, can you tell me what dataset was used by mozilla to train their DeepSpeech model in order to get such good accuracy?

This if documented in the [release notes](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1), Fisher, LibriSpeech, and Switchboard training corpora.

",many unique data would need train model application target language unrestricted speech order audio maybe command control application much le exact amount would depend number variance end user speech possible tell used train model order get good accuracy release fisher switchboard training corpus,issue,negative,positive,positive,positive,positive,positive
527769456,"> Yea, saw that. Thanks.

I think that 10.1 has some incompatibilities wrt eigen's use by tensorflow, so I'm not sure you can even build it by yourself, but you can try?",yea saw thanks think use sure even build try,issue,positive,positive,positive,positive,positive,positive
527750448,"> Looks like compiler problem. Adding `--copt=”-std=gnu99”` in the bazel command may help but not sure.

It's still not working. I didn't notice you building the tensorflow library with the command I posted right above in your instructions. I just see that you built the deepspeech library with the following command right after you ran ./configure  for tensorflow:
`bazel build --workspace_status_command=”bash
native_client/bazel_workspace_status_cmd.sh” --config=monolithic
--config=cuda -c opt --copt=-O3 --copt=”-std=gnu99”
--copt=”-D_GLIBCXX_USE_CXX11_ABI=0” --copt=-fvisibility=hidden
//native_client:libdeepspeech.so //native_client:generate_trie`

Are you skipping the tensorflow build step or does this command above cover that? 
Lastly, are you using the master branch of the deepspeech repository?

Thanks!",like compiler problem command may help sure still working notice building library command posted right see built library following command right ran build bash opt skipping build step command cover lastly master branch repository thanks,issue,positive,positive,positive,positive,positive,positive
527726627,"Okay, I understand now.
Can you please just help me out with the following questions as well?
1. How many unique hours of data would I need to train a production-ready model?
2. If possible, can you tell me what dataset was used by mozilla to train their DeepSpeech model in order to get such good accuracy?",understand please help following well many unique data would need train model possible tell used train model order get good accuracy,issue,positive,positive,positive,positive,positive,positive
527620274,"@sargense I have no idea how your example number two (without a virtualenv) is working, because it's not supposed to. The `deepspeech` binary is installed when you do `pip install deepspeech`, which is missing from that example. There's probably some namespace pollution happening and you're using the binary installed in the previous step, or something like that.",idea example number two without working supposed binary pip install missing example probably pollution happening binary previous step something like,issue,negative,negative,negative,negative,negative,negative
527619505,"We should update the GIF for the new params. And probably put the virtualenv creation in the first code listing, as a mandatory step. People who already know how virtualenv works can adapt as needed but I guess it'll simplify the text as a whole.",update gif new probably put creation first code listing mandatory step people already know work adapt guess simplify text whole,issue,negative,positive,positive,positive,positive,positive
527587919,"> > It would be nice, it is a wish, that it could be as easy as it looks in the GIF at the top of the readme. That's it, there is nothing more to the issue other than that. Just a copy-paste these items in this exact order and you have a working deepspeech model. I am not saying the items are not in the readme, but they are not in order.
> 
> Now we progress. Please, do not hesitate to suggest a better ordering.

My point being that we need your feedback to understand what is to be changed in the current doc.",would nice wish could easy gif top nothing issue exact order working model saying order progress please hesitate suggest better point need feedback understand current doc,issue,positive,positive,positive,positive,positive,positive
527577438,"> It would be nice, it is a wish, that it could be as easy as it looks in the GIF at the top of the readme. That's it, there is nothing more to the issue other than that. Just a copy-paste these items in this exact order and you have a working deepspeech model. I am not saying the items are not in the readme, but they are not in order.

Now we progress. Please, do not hesitate to suggest a better ordering.


> something that is literally as easy as it looks in the GIF at the top of the readme

Well, that's already the case. The GIF is outdated wrt the command line parameters etc., but up-to-date instructions would end up in the same.",would nice wish could easy gif top nothing issue exact order working model saying order progress please hesitate suggest better something literally easy gif top well already case gif outdated command line would end,issue,positive,positive,positive,positive,positive,positive
527566721,"It would be nice, it is a wish, that it could be as easy as it looks in the GIF at the top of the readme. That's it, there is nothing more to the issue other than that. Just a copy-paste these items in this exact order and you have a working deepspeech model. I am not saying the items are not in the readme, but they are not in order.

The readme, does not start with venv. You have a GIF that shows pip install deepspeech, then downloads and extracts the models, run deepspeech and that's it. The first two steps in the text are pip install then run. The actual first step is setting up venv which at the top is only ""recommended"". 

Also, not sure what you mean by requirements.txt is wrong, I ran ""pip install -r requirements.txt"" and it worked. I had a working deepspeech install without setting up a venv.

I already know all of the information is in the readme in one section or another. The request is for someone coming to the project with a system with little to no data science or python packages built-up to be able to do steps 1-? in order and get a working install.

I didn't know coming to the project if I was going to be a tourist and just run it once and move on or continue using the project if the test results were good. So it's always nice to have a quick test that can be run as proof that a given project works as advertised hence the desire to have something that is literally as easy as it looks in the GIF at the top of the readme. Nothing more to it than that.",would nice wish could easy gif top nothing issue exact order working model saying order start gif pip install run first two text pip install run actual first step setting top also sure mean wrong ran pip install worked working install without setting already know information one section another request someone coming project system little data science python able order get working install know coming project going tourist run move continue project test good always nice quick test run proof given project work hence desire something literally easy gif top nothing,issue,positive,positive,positive,positive,positive,positive
527552218,"> So not in a venv, the key is ""pip install requirements.txt"". Pretty standard fare.

Honestly, I'm lost. You ask for ""easy to reproduce setup"", which is what we provide. And then you start with something else. And your statement is wrong, `requirements.txt` is required in any case, but that's for training.



> I just like to have the quick test this out and see if it works for you option.

Again, that's exactly what we do document with the virtualenv ...",key pip install pretty standard fare honestly lost ask easy reproduce setup provide start something else statement wrong case training like quick test see work option exactly document,issue,positive,positive,positive,positive,positive,positive
527548246,"So not in a venv, the key is ""pip install requirements.txt"". Pretty standard fare. I just like to have the quick test this out and see if it works for you option. Deepspeech performed pretty well, so it's probably worth getting to work in a variety of setups (I'll be trying the docker build next but adding some other standard DS packages (like Jupyter) and work on adding my own simple API for file uploads that go into a job queue).

These were mostly clean machines, with Tensorflow 1.5 and Jupyter pre-installed by cloud provider.

With venv:
Tested on Ubuntu 16.0.4

1) apt-get update
2) apt-get install python-virtualenv (try apt-get install python3-virtualenv if 3 does not install by default (it should))
3) apt install python3-pip
4) apt-get install wget
5) virtualenv -p python3 $HOME/tmp/deepspeech-venv/
6) source $HOME/tmp/deepspeech-venv/bin/activate
7) wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
8) tar -xzvf deepspeech-0.5.1-models.tar.gz
9) pip3 install deepspeech 
10) deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav

Without a virtualenv:
Tested on Ubuntu 16.0.4

1) apt-get update
2) apt-get install git
3) apt install python3-pip
4) apt-get install wget
5) git clone https://github.com/mozilla/DeepSpeech.git
6) cd DeepSpeech/
7) pip install -r requirements.txt 
8) wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
9) tar -xzvf deepspeech-0.5.1-models.tar.gz 
10) deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav",key pip install pretty standard fare like quick test see work option pretty well probably worth getting work variety trying docker build next standard like work simple file go job queue mostly clean cloud provider tested update install try install install default apt install install python source tar pip install model alphabet audio without tested update install git apt install install git clone pip install tar model alphabet audio,issue,positive,positive,positive,positive,positive,positive
527540722,"> the exact commands in the GIF at the top of the readme it doesn't work on all systems...

Commands in that GIF are outdated, I think we should just get rid of it or update it ? cc @kdavis-mozilla ",exact gif top work gif outdated think get rid update,issue,negative,positive,positive,positive,positive,positive
527540446,"I'd really love to understand what did not work for you, it would really be useful that you share what problem you faced ...",really love understand work would really useful share problem faced,issue,positive,positive,positive,positive,positive,positive
527538987,"I never questioned that the needed information wasn't available. 

In fact, if I type the exact commands in the GIF at the top of the readme it doesn't work on all systems... Just asking that the readme makes it as easy as it looks.

The readme has step 3 first, step 2 second, and step 1 third. The suggestions was for tested on $OS and then steps 1,2,3. This doesn't have to be at the top. I've already gotten deepspeech to work in more than one way. Thanks.",never information available fact type exact gif top work easy step first step second step third tested o top already gotten work one way thanks,issue,positive,positive,positive,positive,positive,positive
527533458,"Common Voice doesn't have enough data at the present time to generate a production-quality model. The solution is to obtain additional data sources or wait until Common Voice has accrued more data.

You're not the first person to be confused by this so I filed an issue to list the number of unique hours on the Datasets page: https://github.com/mozilla/voice-web/issues/2201",common voice enough data present time generate model solution obtain additional data wait common voice data first person confused issue list number unique page,issue,negative,negative,neutral,neutral,negative,negative
527528472,"> The request (which can be turned down) is for having a simple do 1,2,3 series of instructions

https://github.com/mozilla/DeepSpeech/blob/master/README.md#using-the-python-package

1. Create
2. Activate
3. Install

How does that not qualify ?",request turned simple series create activate install qualify,issue,negative,neutral,neutral,neutral,neutral,neutral
527528095,"> he ask was just a request (which can be turned down) to make that process simple and quick with a guaranteed instruction set.

The answer is that **we do that, relying on virtualenv**. You still have not replied on whether you properly followed those steps.



> I've always appreciated it in other projects when the devs say, we built this on Debian after installing A,B,C then did steps 1,2,3.

Again, we document how to setup virtualenv and install. That should work for everybody.",ask request turned make process simple quick instruction set answer still whether properly always say built document setup install work everybody,issue,negative,positive,positive,positive,positive,positive
527527252,"The request (which can be turned down) is for having a simple do 1,2,3 series of instructions that would be guaranteed to work on a fresh system obtainable via container, VM, or cloud provider, not debugging a particular system.

In fact, when moving to clean systems from a cloud provider both GPU and CPU, I ran into other errors when just doing a blind copy-paste starting at the top of the readme. But the errors weren't the same on any given system.

I figured it out and got it to work, so the above isn't a big deal. I did my test of deepspeech vs. another neural network. The ask was just a request (which can be turned down) to make that process simple and quick with a guaranteed instruction set. I've always appreciated it in other projects when the devs say, we built this on Debian after installing A,B,C then did steps 1,2,3. Sometimes that resolves some unexpected bugs caused by some library or another using a different version as a dependency in one distro vs another which can be very helpful when moving from platform to platform with a given project.",request turned simple series would work fresh system obtainable via container cloud provider particular system fact moving clean cloud provider ran blind starting top given system figured got work big deal test another neural network ask request turned make process simple quick instruction set always say built sometimes unexpected library another different version dependency one another helpful moving platform platform given project,issue,positive,positive,positive,positive,positive,positive
527405962,"> In fact, I don't have a ""deepspeech"" command at all. I didn't get an error in the install, pip claimed deepspeech was installed without issue.

Honestly, without more context, that just looks like you have not followed the documentation and created a Python virtualenv. And so the deepspeech binary is installed, and it's path is not in your `$PATH`. Which would be taken care of with virtualenv.",fact command get error install pip without issue honestly without context like documentation python binary path path would taken care,issue,negative,positive,positive,positive,positive,positive
527402314,"Yeah, the issue is that we don't have Python 3.7 packages for older releases, see #2272 ",yeah issue python older see,issue,negative,positive,positive,positive,positive,positive
527335179,"For the [latest release](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1) we provide a list of supported platforms which includes ""Linux x86 64 bit with a modern CPU"" and also ""Linux x86 64 bit with a modern CPU + NVIDIA GPU"". So it's surprising that the install fails.

Also for the latest release we include a [Docker](https://github.com/mozilla/DeepSpeech/blob/v0.5.1/Dockerfile) file too.",latest release provide list bit modern also bit modern surprising install also latest release include docker file,issue,negative,positive,positive,positive,positive,positive
527335103,This is already what we do document. Have you properly setup a virtualenv as documented? ,already document properly setup,issue,negative,neutral,neutral,neutral,neutral,neutral
527316071,I don't think v0.5.1 had support for the RPi4. You can get a version of the v0.5.1 model re-exported to be compatible with the v0.6.0 alphas at https://github.com/reuben/DeepSpeech/releases/v0.6.0-alpha.4,think support get version model compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
527296027,"I did that already. I used only the train/dev/test splits created by the script (which have 26,164 wav files) and the loss on the test set I got was 131.93

The trained model generates the same text for every audio it gets. I think 26,164 samples are just too less to train the model.",already used script loss test set got trained model text every audio think le train model,issue,negative,neutral,neutral,neutral,neutral,neutral
527239915,"I literally copy-pasted the instructions from the readme. Starting with ""pip3 install deepspeech"". The next command after that ""deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav"" didn't work. In fact, I don't have a ""deepspeech"" command at all. I didn't get an error in the install, pip claimed deepspeech was installed without issue.

But I don't want an issue to ask for how to ensure deepspeech works on my particular linux system. I would like the readme to include a guaranteed build environment. Like spin X OS in cloud provider of choice or in VM on your machine, install X,Y,Z and it will work. It could be Ubuntu, Debian, CentOS, etc. I can figure out the specifics of getting it to run on whatever system if it's appropriate to build on top of later, but it's nice to have a quick guaranteed path for experimentation to see how it goes. I did another speech recognition ML experiment and would also like to give these models a try.

Essentially, what linux OS(es), version(s), and architecture(s) are being used or recommended by the development team? ",literally starting pip install next command model alphabet audio work fact command get error install pip without issue want issue ask ensure work particular system would like include build environment like spin o cloud provider choice machine install work could figure getting run whatever system appropriate build top later nice quick path experimentation see go another speech recognition experiment would also like give try essentially o e version architecture used development team,issue,positive,positive,positive,positive,positive,positive
527234868,"No, just the train/dev/test splits created by the script.

-- reuben

> On 2 Sep 2019, at 20:27, Shantanu Acharya <notifications@github.com> wrote:
> 
> ﻿
> Thank you for the response @reuben. So to reproduce the results, I should use the full validation.tsv right?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",script wrote thank response reproduce use full right reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
527233316,"Hello, training 120h using the CPU will take days and the GT 730 is not enough to fit the default batch size, sorry but I guess you need to do an upgrade.

Please for further issues/discussion use the forum, I'll help you there :https://discourse.mozilla.org/",hello training take day enough fit default batch size sorry guess need upgrade please use forum help,issue,positive,negative,neutral,neutral,negative,negative
527231575,We got several reports from people running arch and it works. Can you describe exactly what you do? ,got several people running arch work describe exactly,issue,negative,positive,positive,positive,positive,positive
527219628,"Thank you for the response @reuben. So to reproduce the results, I should use the full validation.tsv right?",thank response reproduce use full right,issue,negative,positive,positive,positive,positive,positive
527216090,Did you use pip or pip3? It should be pip3 but the pip command on your system may be pointing to the earlier version.,use pip pip pip pip command system may pointing version,issue,negative,neutral,neutral,neutral,neutral,neutral
527183385,We have used just the unique subset in our release models.,used unique subset release,issue,negative,positive,positive,positive,positive,positive
527126268,"Sure sir, I am happy with your immediate help I will share my all steps detailed and the error. with the data files. in few minutes. // in new issue. ",sure sir happy immediate help share detailed error data new issue,issue,positive,positive,positive,positive,positive,positive
527125977,"> Because I am stuck at next stage.

Please make sure you read documentation and share actionable data.",stuck next stage please make sure read documentation share actionable data,issue,positive,positive,positive,positive,positive,positive
527125875,"> Can you guide what is PS1 matching a python env? or steps to create it?

Bash PS1, your shell ...


> DeepSpeech]$ pip3 list
> DeepSpeech]$ pip list

Here we go, you are mixing versions ...",guide matching python create bash shell pip list pip list go,issue,negative,neutral,neutral,neutral,neutral,neutral
527125793,Thank you so much for kind help. ,thank much kind help,issue,positive,positive,positive,positive,positive,positive
527125739,Something worked now. I think I should close this now. !!! thank you for kind help. I will open new issue. Because I am stuck at next stage. // ,something worked think close thank kind help open new issue stuck next stage,issue,positive,positive,positive,positive,positive,positive
527122814,"Can you guide what is PS1 matching a python env? or steps to create it?

as the packages in pip list are below 


DeepSpeech]$ pip3 list
Package    Version
---------- -------
pip        19.2.3 
setuptools 39.2.0 
six        1.12.0 


DeepSpeech]$ pip list
DEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support
Package                          Version                      
-------------------------------- -----------------------------
backports.ssl-match-hostname     3.5.0.1                      
Beaker                           1.5.4                        
blivet                           0.61.15.72                   
Brlapi                           0.6.0                        
cffi                             1.6.0                        
chardet                          2.2.1                        
configobj                        4.7.2                        
configshell-fb                   1.1.23                       
coverage                         3.6b3                        
cryptography                     1.7.2                        
cupshelpers                      1.0                          
custodia                         0.3.1                        
decorator                        3.4.0                        
di                               0.3                          
dnspython                        1.12.0                       
enum34                           1.0.4                        
ethtool                          0.8                          
firstboot                        19.5                         
fros                             1.0                          
futures                          3.1.1                        
gssapi                           1.2.0                        
idna                             2.4                          
iniparse                         0.4                          
initial-setup                    0.3.9.43                     
iotop                            0.6                          
ipaclient                        4.6.4                        
ipaddr                           2.1.11                       
ipaddress                        1.0.16                       
ipalib                           4.6.4                        
ipaplatform                      4.6.4                        
ipapython                        4.6.4                        
ipaserver                        4.6.4                        
IPy                              0.75                         
isc                              2.0                          
javapackages                     1.0.0                        
jwcrypto                         0.4.2                        
kdcproxy                         0.3.2                        
kitchen                          1.1.1                        
kmod                             0.1                          
langtable                        0.0.31                       
libvirt-python                   4.5.0                        
lvm                              2.02.180-2-RHEL7.-2018-07-20-
lxml                             3.2.1                        
M2Crypto                         0.21.1                       
Magic-file-extensions            0.2                          
Mako                             0.8.1                        
MarkupSafe                       0.11                         
MySQL-python                     1.2.5                        
netaddr                          0.7.5                        
netifaces                        0.10.4                       
nose                             1.3.7                        
ntplib                           0.3.2                        
numpy                            1.7.1                        
openlmi                          0.5.0                        
Paste                            1.7.5.1                      
perf                             0.1                          
pip                              19.2.3                       
ply                              3.4                          
policycoreutils-default-encoding 0.1                          
psycopg2                         2.5.1                        
pyasn1                           0.1.9                        
pyasn1-modules                   0.0.8                        
pycparser                        2.14                         
pycups                           1.9.63                       
pycurl                           7.19.0                       
pygobject                        3.22.0                       
pygpgme                          0.3                          
pyinotify                        0.9.4                        
pykickstart                      1.99.66.19                   
pyliblzma                        0.5.3                        
PyOpenGL                         3.1.0b2                      
pyOpenSSL                        0.13.1                       
pyparsing                        1.5.6                        
pyparted                         3.9                          
pysmbc                           1.0.13                       
python-augeas                    0.5.0                        
python-dateutil                  1.5                          
python-dmidecode                 3.10.13                      
python-ldap                      2.4.15                       
python-linux-procfs              0.4.9                        
python-meh                       0.25.2                       
python-nss                       0.16.0                       
python-yubico                    1.2.3                        
pytz                             2016.10                      
pyudev                           0.15                         
pyusb                            1.0.0b1                      
pywbem                           0.7.0                        
pyxattr                          0.5.1                        
PyYAML                           3.10                         
qrcode                           5.0.1                        
requests                         2.6.0                        
rtslib-fb                        2.1.63                       
scdate                           1.10.6                       
schedutils                       0.4                          
seobject                         0.1                          
sepolicy                         1.1                          
setproctitle                     1.1.6                        
setroubleshoot                   1.1                          
setuptools                       0.9.8                        
slip                             0.4.0                        
slip.dbus                        0.4.0                        
SSSDConfig                       1.16.2                       
subprocess32                     3.2.6                        
targetcli-fb                     2.1.fb46                     
targetd                          0.8.5                        
Tempita                          0.5.1                        
urlgrabber                       3.10                         
urllib3                          1.10.2                       
urwid                            1.1.1                        
virtualenv                       15.1.0                       
yum-langpacks                    0.4.2                        
yum-metadata-parser              1.1.4 ",guide matching python create pip list pip list package version pip six pip list deprecation python reach end life st please upgrade python python wo date future version pip drop support python python support pip found package version beaker coverage cryptography decorator di kitchen mako nose paste pip ply slip,issue,positive,neutral,neutral,neutral,neutral,neutral
527120833,"> python conda virtual environment is active. !!

Well, again, do not use conda. Share all, precise steps. Your current console output does not show any `PS1` matching a Python virtual env enabled ...",python virtual environment active well use share precise current console output show matching python virtual,issue,positive,positive,neutral,neutral,positive,positive
527120341,"of course the requirements are installed in virtual env. as below. 

1) clone deepspeech
2) conda create -n speech python=3.6
3) activated the environment as conda activate speech
4) Installed requirements
5) then this step task cluster.
6) six error. as shown above.

python conda virtual environment is active. !!",course virtual clone create speech environment activate speech step task six error shown python virtual environment active,issue,negative,negative,negative,negative,negative,negative
527119392,"> made conda environments for deepspeech to be installed there

As documented, please use vanilla python and virtualenv instead of anaconda


> Installed requirements

`six` is part of the `requirements.txt` file


> then this step task cluster.

No `load the virtual environment step` ?",made please use vanilla python instead anaconda six part file step task cluster load virtual environment step,issue,negative,neutral,neutral,neutral,neutral,neutral
527118870,"Steps I did. 

1) I clone Deepspeech
2) made conda environments for deepspeech to be installed there
3) Installed requirements
4) then this step task cluster. 
5) six error. as shown above.  ",clone made step task six error shown,issue,negative,neutral,neutral,neutral,neutral,neutral
527117425,"> Hi.
> 
> I have just started from start and this was command which I run after installations of requirement.

You said you had installed `six`, now you say you did nothing ?",hi start command run requirement said six say nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
527116878,"Hi. 

I have just started from start and this was command which I run after installations of requirement. 
",hi start command run requirement,issue,negative,neutral,neutral,neutral,neutral,neutral
527110715,"> although I have installed six in environment of python3.

Obviously, not. If you don't share details on your setup, we can't help.



> Also, I am not able to install decoder.
> Please help and guide.

Same, we can't do divination on your errors. If you refuse to share details we will have to close the issue.",although six environment python obviously share setup ca help also able install please help guide ca divination refuse share close issue,issue,positive,positive,positive,positive,positive,positive
527077648,"Yeah, don't worry, I'd like to get it working so I'll keep testing on some spare cycles ",yeah worry like get working keep testing spare,issue,negative,neutral,neutral,neutral,neutral,neutral
527059840,Looks like compiler problem. Adding `--copt=”-std=gnu99”` in the bazel command may help but not sure. ,like compiler problem command may help sure,issue,positive,positive,positive,positive,positive,positive
527036199,"I'm testing this code against our Mandarin data to see how it performs against a baseline. So far it looks promising performance wise, matching your results of very little performance overhead. I think we should merge this, but remove the sparse_image_warp transform and code since it's too slow to be useful.",testing code mandarin data see far promising performance wise matching little performance overhead think merge remove transform code since slow useful,issue,positive,positive,positive,positive,positive,positive
526966670,"> @michaelguo32 I listed the issues that I faced and the resources that I referred [here](https://github.com/mdasari823/DeepSpeech-Jetson-Nano/blob/master/Deepspeech-Jetson-Nano.pdf). I had to try out different combinations. Post the issue here if you want me to give you any hint.

When I try to build tensorflow using the following command found at step 7 in this [link](https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/):
`bazel build --config=opt --config=cuda --config=nonccl //tensorflow/tools/pip_package:build_pip_package --verbose_failures --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""`

I get a message saying `FAILED: Build did NOT complete successfully` 

I've successfully built bazel version 0.25.2 following the instructions from the same [link](https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/) above and I'm using the r1.14 branch of the mozilla's tensorflow repository as you suggested as well as gcc-5.

I have attached the full error log and tensorflow configuration below:
[error_log2.txt](https://github.com/mozilla/DeepSpeech/files/3564296/error_log2.txt)
[tf_configuration.txt](https://github.com/mozilla/DeepSpeech/files/3564328/tf_configuration.txt)




",listed faced try different post issue want give hint try build following command found step link build get message saying build complete successfully successfully built version following link branch repository well attached full error log configuration,issue,positive,positive,positive,positive,positive,positive
526947810,"Thanks @carlfm01 for the accurate observations. 
    * Yes I am now working with ciempiess but i really liked the openslr link. i will add more clean data. I am very interested in your 120h Spanish Speech;
    * I will increase the `train_batch_size ` as you suggest. Actually I tried `n_hidden =2048` as suggested below but it jus never ends i will try with 1048;
    * I am working now to create my own `lm`.arpa and `binary` files for mexican spanish. I think thats the main problem. I will share it when done;
    * I am not using GPU by the moment, i am new in DS so this is my first try, but i think i have the right hardware:

```
$ lspci -vnn | grep VGA -A 12
01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GK208B [GeForce GT 730] [10de:1287] (rev a1) (prog-if 00 VGA controller])
	Subsystem: Dell GK208B [GeForce GT 730] [1028:3382]
	Flags: bus master, fast devsel, latency 0, IRQ 128
	Memory at 9c000000 (32-bit, non-prefetchable) [size=16M]
	Memory at 90000000 (64-bit, prefetchable) [size=128M]
	Memory at 9a000000 (64-bit, prefetchable) [size=32M]
	I/O ports at 4000 [size=128]
	Expansion ROM at 000c0000 [disabled] [size=128K]
	Capabilities: <access denied>
	Kernel driver in use: nouveau
	Kernel modules: nvidiafb, nouveau

01:00.1 Audio device [0403]: NVIDIA Corporation GK208 HDMI/DP Audio Controller [10de:0e0f] (rev a1)
```

I need to get more familiar with DS 
",thanks accurate yes working really link add clean data interested speech increase suggest actually tried never try working create binary think thats main problem share done moment new first try think right hardware compatible controller corporation de rev controller subsystem dell bus master fast latency memory memory memory expansion disabled access kernel driver use kernel audio device corporation audio controller de rev need get familiar,issue,positive,positive,positive,positive,positive,positive
526929543,I've already tried to get that working but the intersection between what is supported for EdgeTPU and our current model makes it incompatible. Please see existing threads on discourse and also NNAPI and GPU delegations issues on github. ,already tried get working intersection current model incompatible please see discourse also,issue,negative,neutral,neutral,neutral,neutral,neutral
526907882,@michaelguo32 I listed the issues that I faced and the resources that I referred  [here](https://github.com/mdasari823/DeepSpeech-Jetson-Nano/blob/master/Deepspeech-Jetson-Nano.pdf). I had to try out different combinations. Post the issue here if you want me to give you any hint.,listed faced try different post issue want give hint,issue,negative,neutral,neutral,neutral,neutral,neutral
526892989,"If it helps, I would be happy to fund a Coral USB for you to try. jacob.r.jennings@gmail.com
I think there's potential to cross the real-time barrier on a Pi with this thing. Would be fun for my DIY projects.
",would happy fund coral try think potential cross barrier pi thing would fun,issue,positive,positive,positive,positive,positive,positive
526870790,"> @lissyx thank you so much. Yes, I was running 0.5.1 model on master build. Your new model v0.6.0 is running successfully. Thanks.
> I built it on Nano itself, did not cross compile. It was really slow to build bazel dependency and had many issues. I will post detailed instructions and all commands that I followed. Thanks.

@mdasari823 I'm running into similar issues specifically on building TensorFlow with bazel after configuring it. Do you mind letting me know the steps that you took to get it to work on the Jetson Nano?",thank much yes running model master build new model running successfully thanks built cross compile really slow build dependency many post detailed thanks running similar specifically building mind know took get work,issue,positive,positive,positive,positive,positive,positive
526850815,"Hello @alemol I see that you are using ciempiess data, from my experience with ciempiess the data is not clean enough, wrong transcriptions lead to inf as your log shows. 
See gt transcriptions ""tiones"", ""ciertas ac"" that looks wrong. 

Your train_batch_size is too low, try increasing it to 20, are you training on GPU? 

Did you train a new lm? I see you didn't use the lm param, maybe is falling back to the english one?

Try using data from http://www.openslr.org/resources.php the crowdsourced works for me",hello see data experience data clean enough wrong lead log see wrong low try increasing training train new see use param maybe falling back one try data work,issue,negative,negative,neutral,neutral,negative,negative
526848881,"Maybe is out of question but I had also bad results for Spanish with this configuration the network, after a full day, just learn - res: ""nor""

So i would like to know if other languages than English are supported?

```
python -u DeepSpeech.py \
  --train_files /home/amolina/repo/ciem2ds/ciempiess_ds/sortlen_half_train.csv \
  --test_files /home/amolina/repo/ciem2ds/ciempiess_ds/sortlen_all_test.csv \
  --alphabet_config_path data/mex_alphabet.txt \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 100 \
  --epochs 200 \
  --checkpoint_dir ""$checkpoint_dir"" \
  ""$@""

```
```
I Initializing variables...
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 93.751235  
Epoch 1 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 80.676887  
Epoch 2 |   Training | Elapsed Time: 0:10:01 | Steps: 18595 | Loss: 77.527077  
Epoch 3 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 75.572843  
Epoch 4 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 74.609963  
Epoch 5 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 74.008800  
Epoch 6 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 73.673566  
Epoch 7 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 73.823821  
Epoch 8 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 73.861504  
Epoch 9 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 74.114022  
Epoch 10 |   Training | Elapsed Time: 0:10:01 | Steps: 18595 | Loss: 74.192672 
Epoch 11 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 74.440729 
Epoch 12 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 74.946214 
Epoch 13 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 75.091413 
Epoch 14 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 75.910153 
Epoch 15 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 76.783735 
Epoch 16 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 77.325730 
Epoch 17 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 78.376845 
Epoch 18 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 78.071846 
Epoch 19 |   Training | Elapsed Time: 0:10:01 | Steps: 18595 | Loss: 78.782185 
Epoch 20 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 79.386480 
Epoch 21 |   Training | Elapsed Time: 0:10:01 | Steps: 18595 | Loss: 80.769004 
Epoch 22 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 82.017331 
Epoch 23 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 81.778631 
Epoch 24 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 82.016680 
Epoch 25 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 82.180876 
Epoch 26 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 83.222377 
Epoch 27 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 85.134474 
Epoch 28 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 85.365918 
Epoch 29 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 86.207316 
Epoch 30 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 88.510106 
Epoch 31 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 89.998917 
Epoch 32 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 91.967384 
Epoch 33 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 94.664897 
Epoch 34 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 95.752118 
Epoch 35 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 95.497464 
Epoch 36 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 96.914079 
Epoch 37 |   Training | Elapsed Time: 0:10:01 | Steps: 18595 | Loss: 98.786910 
Epoch 38 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 101.285745
Epoch 39 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 100.534290
Epoch 40 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 101.388670
Epoch 41 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 100.917061
Epoch 42 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 102.530971
Epoch 43 |   Training | Elapsed Time: 0:10:03 | Steps: 18595 | Loss: 102.388037
Epoch 44 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 104.319837
Epoch 45 |   Training | Elapsed Time: 0:10:09 | Steps: 18595 | Loss: 108.247787
Epoch 46 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 107.708419
Epoch 47 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 109.183266
Epoch 48 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 108.231648
Epoch 49 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 106.508821
Epoch 50 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 106.255912
Epoch 51 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 107.416758
Epoch 52 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 114.885837
Epoch 53 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 112.555353
Epoch 54 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 111.840298
Epoch 55 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 111.772296
Epoch 56 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 112.323149
Epoch 57 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 111.255794
Epoch 58 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 112.093249
Epoch 59 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 114.454235
Epoch 60 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 114.721767
Epoch 61 |   Training | Elapsed Time: 0:10:07 | Steps: 18595 | Loss: 112.339738
Epoch 62 |   Training | Elapsed Time: 0:10:02 | Steps: 18595 | Loss: 114.366047
Epoch 63 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 114.660832
Epoch 64 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 114.750480
Epoch 65 |   Training | Elapsed Time: 0:10:10 | Steps: 18595 | Loss: 116.308748
Epoch 66 |   Training | Elapsed Time: 0:10:02 | Steps: 18595 | Loss: 114.976197
Epoch 67 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 117.706127
Epoch 68 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 118.251227
Epoch 69 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 117.428873
Epoch 70 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 118.360602
Epoch 71 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 117.602017
Epoch 72 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 116.247409
Epoch 73 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 116.151155
Epoch 74 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 116.276198
Epoch 75 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 117.054155
Epoch 76 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 117.739245
Epoch 77 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 116.632338
Epoch 78 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 118.185351
Epoch 79 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 117.615691
Epoch 80 |   Training | Elapsed Time: 0:10:00 | Steps: 18595 | Loss: 116.685919
Epoch 81 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 118.425804
Epoch 82 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 117.676715
Epoch 83 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 119.112836
Epoch 84 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 119.567508
Epoch 85 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 124.922071
Epoch 86 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 122.442140
Epoch 87 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.295431
Epoch 88 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 120.293874
Epoch 89 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: inf       
Epoch 90 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.343331
Epoch 91 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.485559
Epoch 92 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 119.955021
Epoch 93 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: inf       
Epoch 94 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 118.938482
Epoch 95 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 118.039395
Epoch 96 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 119.543563
Epoch 97 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 119.752225
Epoch 98 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 118.580545
Epoch 99 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 119.848754
Epoch 100 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 119.836867
Epoch 101 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 121.148597
Epoch 102 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 122.075585
Epoch 103 |   Training | Elapsed Time: 0:09:59 | Steps: 18595 | Loss: 120.502896
Epoch 104 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 121.372918
Epoch 105 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 120.414153
Epoch 106 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: inf      
Epoch 107 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.053317
Epoch 108 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.239684
Epoch 109 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.447390
Epoch 110 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 119.472469
Epoch 111 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 120.860956
Epoch 112 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 121.302663
Epoch 113 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 122.372010
Epoch 114 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 121.246708
Epoch 115 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 121.194381
Epoch 116 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 121.744214
Epoch 117 |   Training | Elapsed Time: 0:09:58 | Steps: 18595 | Loss: 122.417468
Epoch 118 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: inf      
Epoch 119 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: 122.075555
Epoch 120 |   Training | Elapsed Time: 0:09:57 | Steps: 18595 | Loss: inf      
Epoch 121 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 122 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 123 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 124 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 125 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 126 |   Training | Elapsed Time: 0:09:21 | Steps: 18595 | Loss: inf      
Epoch 127 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 128 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 129 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 130 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 131 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 132 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 133 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 134 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 135 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 136 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 137 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 138 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 139 |   Training | Elapsed Time: 0:09:22 | Steps: 18595 | Loss: inf      
Epoch 140 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 141 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 142 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 143 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 144 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 145 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 146 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 147 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 148 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 149 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 150 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 151 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 152 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 153 |   Training | Elapsed Time: 0:09:23 | Steps: 18595 | Loss: inf      
Epoch 154 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 155 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 156 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 157 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 158 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 159 |   Training | Elapsed Time: 0:09:35 | Steps: 18595 | Loss: inf      
Epoch 160 |   Training | Elapsed Time: 0:09:27 | Steps: 18595 | Loss: inf      
Epoch 161 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 162 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 163 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 164 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 165 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 166 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 167 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 168 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 169 |   Training | Elapsed Time: 0:09:24 | Steps: 18595 | Loss: inf      
Epoch 170 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 171 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 172 |   Training | Elapsed Time: 0:09:26 | Steps: 18595 | Loss: inf      
Epoch 173 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 174 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 175 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 176 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 177 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 178 |   Training | Elapsed Time: 0:09:26 | Steps: 18595 | Loss: inf      
Epoch 179 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 180 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 181 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 182 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 183 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 184 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 185 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 186 |   Training | Elapsed Time: 0:09:26 | Steps: 18595 | Loss: inf      
Epoch 187 |   Training | Elapsed Time: 0:09:27 | Steps: 18595 | Loss: inf      
Epoch 188 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 189 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 190 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 191 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 192 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 193 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 194 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 195 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 196 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 197 |   Training | Elapsed Time: 0:09:26 | Steps: 18595 | Loss: inf      
Epoch 198 |   Training | Elapsed Time: 0:09:25 | Steps: 18595 | Loss: inf      
Epoch 199 |   Training | Elapsed Time: 0:09:26 | Steps: 18595 | Loss: inf      
I FINISHED optimization in 1 day, 8:33:03.828819
I Restored variables from most recent checkpoint at data/CIEMhalf_checkpoint/train-3719000, step 3719000
Testing model on /home/amolina/repo/ciem2ds/ciempiess_ds/sortlen_all_test.csv
Computing acoustic model predictions | Steps: 6974 | Elapsed Time: 0:01:09     
Decoding predictions | 100% (6974 of 6974) || Elapsed Time: 0:55:43 Time:  0:55:43
Test on /home/amolina/repo/ciem2ds/ciempiess_ds/sortlen_all_test.csv - WER: 1.000000, CER: 0.955740, loss: inf
--------------------------------------------------------------------------------
WER: 1.000000, CER: 4.000000, loss: 48.384064
 - src: ""doctor""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 4.000000, loss: 59.863789
 - src: ""oscar""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 5.000000, loss: 60.141987
 - src: ""y las""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 9.000000, loss: 67.413864
 - src: ""ciertas ac""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 6.000000, loss: 67.421371
 - src: ""entonces""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 4.000000, loss: 69.112000
 - src: ""doctor""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 6.000000, loss: 71.097443
 - src: ""entonces""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 5.000000, loss: 72.444527
 - src: ""tiones""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 3.000000, loss: 78.303543
 - src: ""corte""
 - res: ""nor""
--------------------------------------------------------------------------------
WER: 1.000000, CER: 7.000000, loss: 78.787231
 - src: ""es decir""
 - res: ""nor""
--------------------------------------------------------------------------------
```",maybe question also bad configuration network full day learn would like know python starting optimization epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss epoch training time loss finished optimization day recent step testing model acoustic model time time time test wer loss wer loss doctor wer loss wer loss la wer loss wer loss wer loss doctor wer loss wer loss wer loss wer loss e,issue,negative,negative,neutral,neutral,negative,negative
526809372,"Even for me when I start training a new model it is continuing from the previous training from a release model checkpoint, I have deleted /root/.local/share/deepspeech/checkpoints and also specified empty folder before I start training a model.
 ",even start training new model previous training release model also empty folder start training model,issue,negative,negative,neutral,neutral,negative,negative
526096994,"Please use Discourse for general discussion of DeepSpeech, the issue tracker is for bugs and feature requests, as described in the issue template you deleted in order to post this.",please use discourse general discussion issue tracker feature issue template order post,issue,negative,positive,neutral,neutral,positive,positive
525870522,"@dabinat hi! Yeah, that is still valid. I fixed one minor point which was that we were computing and returning `beam_size` paths just to throw away all but one. That is fixed by separating beam_width and top_paths in `decoder_decode`. But the overall structure of the work should still be the same.

Returning a list of several paths might be tricky to get working with SWIG plus all our different bindings, so if you get stuck on that part, just open the PR as is and I'll help get the bindings working.

Thanks for the interest!",hi yeah still valid fixed one minor point throw away one fixed separating overall structure work still list several might tricky get working swig plus different get stuck part open help get working thanks interest,issue,positive,positive,neutral,neutral,positive,positive
525841541,"Hey @reuben, does this still need to be done? And is the implementation you listed above still valid with all the changes made recently to master?",hey still need done implementation listed still valid made recently master,issue,negative,neutral,neutral,neutral,neutral,neutral
525813118,"Yes, it's already been fixed in master and should go out with 0.6.0. In the mean time, you can use one of the 0.6 alphas with the re-exported 0.5.1 model: https://github.com/reuben/DeepSpeech/releases/v0.6.0-alpha.4",yes already fixed master go mean time use one model,issue,negative,negative,negative,negative,negative,negative
525755366,"Great, thanks for the pointer, @kdavis-mozilla. Should I close this issue in favour of an existing one?",great thanks pointer close issue one,issue,positive,positive,positive,positive,positive,positive
525639083,"> And yes, in general resampling to 16kHz is the safest choice with DeepSpeech since all the data we use is 16kHz.

Thank you a lot! I will try. Have a good one!",yes general choice since data use thank lot try good one,issue,positive,positive,positive,positive,positive,positive
525638617,"And yes, in general resampling to 16kHz is the safest choice with DeepSpeech since all the data we use is 16kHz.",yes general choice since data use,issue,negative,positive,neutral,neutral,positive,positive
525638323,"It should work, but apparently no one ever tested it with 22050 Hz. I suspect there will be similar edge cases in the native client, where we're probably truncating to int instead of ceiling.",work apparently one ever tested suspect similar edge native client probably instead ceiling,issue,negative,positive,neutral,neutral,positive,positive
525636403,"> 705.6 is 22050*0.032. Are you using 22050 Hz audio files for training? The problem here, as indicated by the stack in the error message, is that Config.audio_window_samples is a floating point value (computed from the sample rate and feature window length), which is not a valid dimension for a shape.
> 
> I _think_ adding a `ceil` call there, in this case making it 706 samples long, would be fine. But you'd also have to check every other part of the code that depends on the sample rate, feature window length, and step length, to make sure they're handling this correctly.
> 
> Or you can tweak the feature_win_len flag to some value that when multiplied by your sample rate is an integer.
> 
> Or you can downsample your files to 16000 Hz.

Thank you for the explanation!
I actually thought that _f.DEFINE_integer('audio_sample_rate', 22050, 'sample rate value expected by model')_ lets me normally run the code with no tweaks. Am I wrong? What that flag searves for?
So, the best (the most clear) solution for now seems to be downsample all audio to 16000 Hz, right?",audio training problem stack error message floating point value sample rate feature window length valid dimension shape ceil call case making long would fine also check every part code sample rate feature window length step length make sure handling correctly tweak flag value sample rate integer thank explanation actually thought rate value model normally run code wrong flag best clear solution audio right,issue,positive,positive,positive,positive,positive,positive
525635406,"You're running out of GPU memory. Probably your augmentation process introduced longer audio files (hence why the problem happens at the end of the epoch, we sort samples by length). Either remove samples that are too long from your dataset or reduce your batch size.",running memory probably augmentation process longer audio hence problem end epoch sort length either remove long reduce batch size,issue,negative,negative,neutral,neutral,negative,negative
525634242,"705.6 is 22050*0.032. Are you using 22050 Hz audio files for training? The problem here, as indicated by the stack in the error message, is that Config.audio_window_samples is a floating point value (computed from the sample rate and feature window length), which is not a valid dimension for a shape.

I *think* adding a `ceil` call there, in this case making it 706 samples long, would be fine. But you'd also have to check every other part of the code that depends on the sample rate, feature window length, and step length, to make sure they're handling this correctly.

Or you can tweak the feature_win_len flag to some value that when multiplied by your sample rate is an integer.

Or you can downsample your files to 16000 Hz.",audio training problem stack error message floating point value sample rate feature window length valid dimension shape think ceil call case making long would fine also check every part code sample rate feature window length step length make sure handling correctly tweak flag value sample rate integer,issue,negative,positive,positive,positive,positive,positive
525631832,"As to how stop training without overfitting, early stopping prevents overfitting.

If you use Control-C there's no guarantee on the validity of any files that are being written. So you should not use it or you'll end up in situations like you are now.

PS: Can we move this to [discourse](https://discourse.mozilla.org/c/deep-speech) as it appears there's no bug per se",stop training without early stopping use guarantee validity written use end like move discourse bug per se,issue,negative,positive,neutral,neutral,positive,positive
525611569,Thanks for the PR! This looks good to me. I created #2325 to run tests on this change.,thanks good run change,issue,positive,positive,positive,positive,positive,positive
525603317,"> If you stop training by hand, e.g. Control-C, how do you know the last checkpoint is completely and correctly written to disk?
> 
> PS: Please do not include screen shots. Include text to allow for searching.

Sorry for the screen shot.
I don't know that 100%, but earlier with the early-stopping feature turned on I had the same problem. 
If I can not use _ctrl+c_, how do I suppose to stop training to get the right, not overfitted model? If I click _ctrl+c_ there still will be the ""_best_devel_checkpoint_"", right? So the model would be generated from that one. 
Let me also mention that I had been waiting for 2 more epoch after the last _best_dev_checkpoint_ was saved. So this should not be the case. ",stop training hand know last completely correctly written disk please include screen include text allow searching sorry screen shot know feature turned problem use suppose stop training get right model click still right model would one let also mention waiting epoch last saved case,issue,negative,positive,neutral,neutral,positive,positive
525328949,"If you stop training by hand, e.g. Control-C, how do you know the last checkpoint is completely and correctly written to disk?

PS: Please do not include screen shots. Include text to allow for searching.",stop training hand know last completely correctly written disk please include screen include text allow searching,issue,positive,positive,neutral,neutral,positive,positive
524986318,"@cahuja1992 Nops. But it is a valid test.

One idea I haven't implemented yet is to use layer- or batch-normalization through timesteps. I've made some tests, but couldn't make it work. ",valid test one idea yet use made could make work,issue,negative,neutral,neutral,neutral,neutral,neutral
524715218,"> @cahuja1992 after all dense layers except the last one. You can replace the code on https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L65 by the following:
> 
> ```python
> def dense(name, x, units, dropout_rate=None, relu=True, layer_norm=False):
>     with tf.variable_scope(name):
>         bias = variable_on_cpu('bias', [units], tf.zeros_initializer())
>         weights = variable_on_cpu('weights', [x.shape[-1], units], tf.contrib.layers.xavier_initializer())
> 
>     output = tf.nn.bias_add(tf.matmul(x, weights), bias)
> 
>     if relu:
>         output = tf.minimum(tf.nn.relu(output), FLAGS.relu_clip)
> 
>     if layer_norm:
>         output = tf.contrib.layers.layer_norm(output)
> 
>     if dropout_rate is not None:
>         output = tf.nn.dropout(output, rate=dropout_rate)
> 
>     return output
> ```
> 
> **Important: If you train using the layernorm, you must remember to evaluate/export using the layernorm as well.

Thanks @bernardohenz , you didn't use layer norm for the LSTM layer ?",dense except last one replace code following python dense name name bias output bias output output output output none output output return output important train must remember well thanks use layer norm layer,issue,positive,positive,positive,positive,positive,positive
524672502,Oh no! Argh. So Sorry this was supposed to be PR to the http://github.com/Tehikumedia/deepspeech not the main Mozilla one. So far from ready. PLease ignore ,oh sorry supposed main one far ready please ignore,issue,negative,negative,neutral,neutral,negative,negative
524525236,"Maybe, but unless we get feedback it's hard to move on. ",maybe unless get feedback hard move,issue,negative,negative,negative,negative,negative,negative
524518116,"@lissyx really? It seems @SSaishruthi had issues with Common Voice data set which supposedly should be clean enough, and I also heard other people facing it with proprietary datasets. ",really common voice data set supposedly clean enough also people facing proprietary,issue,negative,positive,neutral,neutral,positive,positive
524378110,That error happens in inference stage. I guess you changed the code to bypass the whole training process.,error inference stage guess code bypass whole training process,issue,negative,positive,positive,positive,positive,positive
524225672,"> Sorry, now I get the inference result, but the time seems be too long! However, thanks for your answers!
> 
> > 可 是 阳 春 烟 景 大 块 文 张 的 底 色 四 月 的 林 峦 更 是 绿 的 生 活 秀 美 十 一 二 十
> > Inference took 1117.604s for 7.800s audio file.

See github issues / discourse discussion, this is known on large alphabets.",sorry get inference result time long however thanks inference took audio file see discourse discussion known large,issue,negative,negative,neutral,neutral,negative,negative
524225516,"Sorry, now I get the inference result, but the time seems be too long! However, thanks for your answers!

> 可 是 阳 春 烟 景 大 块 文 张 的 底 色 四 月 的 林 峦 更 是 绿 的 生 活 秀 美 十 一 二 十
> Inference took 1117.604s for 7.800s audio file.",sorry get inference result time long however thanks inference took audio file,issue,negative,negative,negative,negative,negative,negative
524223611,"> I have stay on this status for some minutes and there are no errors! Why?
> 
> ![无标题](https://user-images.githubusercontent.com/5274484/63578169-7c39c980-c5c2-11e9-88d2-ffa3d1ab8912.png)

I won't reply to a screenshot.",stay status wo reply,issue,negative,neutral,neutral,neutral,neutral,neutral
524221405,"Now, as you can see here https://pypi.org/project/deepspeech/0.6.0a5/#files, we have 0.6.0a5 for both systems, so I don't know why it would not insall, unless you start sharing more errors / feedback from pip ... ",see know would unless start feedback pip,issue,negative,neutral,neutral,neutral,neutral,neutral
524221048,"> Why the newest version of deepspeech is v0.6.0 on windows, but v0.5.0 on ubuntu?The problem still exists on ubuntu!!!

`pip install --upgrade deepspeech` should not install you alpha versions ...",version problem still pip install upgrade install alpha,issue,negative,neutral,neutral,neutral,neutral,neutral
524218551,"I upgraded my deepspeech by using `pip install deepspeech --upgrade`, and now the error has disappeared! And now it's running inference, maybe I should wait the result for some minutes?",pip install upgrade error running inference maybe wait result,issue,negative,neutral,neutral,neutral,neutral,neutral
524217279,"> Yes, I trained on master! And now I get the error as follow:
> 
> > Error: Trie file version mismatch (4 instead of expected 3). Update your trie file.

I guess I gave you the answer ? Train / infer on matching versions ?",yes trained master get error follow error file version mismatch instead update file guess gave answer train infer matching,issue,negative,neutral,neutral,neutral,neutral,neutral
524216319,"Yes, I trained on master! And now I get the error as follow: 

> Error: Trie file version mismatch (4 instead of expected 3). Update your trie file.",yes trained master get error follow error file version mismatch instead update file,issue,negative,neutral,neutral,neutral,neutral,neutral
524211967,"> So I was confused, is the --checkpoint_dir an input directory or output directory or both?

It's both, and it's working for everybody, so there's something in your setup, as said before.",confused input directory output directory working everybody something setup said,issue,negative,negative,negative,negative,negative,negative
524211387,"> If you want to train a new model just specifying an empty folder is enough. This is a use case that's exercised daily by several people, something weird is going on with your setup.

I set it to empty or ' ' or a directory path

`  --checkpoint_dir  """" \`
`  --checkpoint_dir  "" "" \`
`  --checkpoint_dir  /DeepSpeech/checkpoints/aishell_moz`

it gives the feedback like this 

`E Checkpoint directory (/root/.local/share/deepspeech/checkpoints) does not contain a valid checkpoint state.
`
`E Checkpoint directory ( ) does not contain a valid checkpoint state.`
`E Checkpoint directory (/DeepSpeech/checkpoints/aishell_moz) does not contain a valid checkpoint state.`

So I was confused, is the --checkpoint_dir an input directory or output directory or both? ",want train new model empty folder enough use case daily several people something weird going setup set empty directory path feedback like directory contain valid state directory contain valid directory contain valid confused input directory output directory,issue,negative,negative,negative,negative,negative,negative
524202667,"> I have re-generate my trie file by using the commands as follow (refer to https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md):

Was that from master ? Your inference log shows running 0.5.1 binary. If you trained on master, then your files are not compatible.",file follow refer master inference log running binary trained master compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
524201904,"If you want to train a new model just specifying an empty folder is enough. This is a use case that's exercised daily by several people, something weird is going on with your setup.",want train new model empty folder enough use case daily several people something weird going setup,issue,negative,negative,neutral,neutral,negative,negative
524201861,"I have re-generate my trie file by using the commands as follow (refer to [https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md](https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md)):

```
/DeepSpeech/native_client/kenlm/build/bin/lmplz -o 3 --text thchs30_vocabulary.txt --arpa thchs30-words.arpa
/DeepSpeech/native_client/kenlm/build/bin/build_binary -T -s thchs30-words.arpa thchs30-lm.binary
/DeepSpeech/native_client/generate_trie thchs30_alphabet.txt thchs30-lm.binary thchs30-trie
```

And my trie file format is correct, and maybe I should train the model again?!",file follow refer text file format correct maybe train model,issue,negative,neutral,neutral,neutral,neutral,neutral
524201458,"> > Loading checkpoint should not even happen if you don't give `--checkpoint_dir`.
> 
> `--checkpoint_dir` has a default value of `xdg.BaseDirectory.save_data_path(os.path.join('deepspeech', 'checkpoints'))`, which is where the path in this issue is coming from.

Yes, I know that is a default path. Can I disable checkpoints when I training? Because I want to train a new model, not load any checkpoint. I'm trying to set --checkpoint_dir '', but it also not works.",loading even happen give default value path issue coming yes know default path disable training want train new model load trying set also work,issue,positive,positive,positive,positive,positive,positive
524195819,I decided to just tackle this in #2303 since it was so close to what I was already doing anyway.,decided tackle since close already anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
524195697,I would recommend looking at this commit by commit.,would recommend looking commit commit,issue,positive,neutral,neutral,neutral,neutral,neutral
524193476,"> Loading checkpoint should not even happen if you don't give `--checkpoint_dir`.

`--checkpoint_dir` has a default value of `xdg.BaseDirectory.save_data_path(os.path.join('deepspeech', 'checkpoints'))`, which is where the path in this issue is coming from.",loading even happen give default value path issue coming,issue,negative,neutral,neutral,neutral,neutral,neutral
524191181,"> Is there anyone can tell me what's happened?

Can you tell us what you did ?",anyone tell tell u,issue,negative,neutral,neutral,neutral,neutral,neutral
524150541,"Here is my trie file : 
[thchs30-trie.zip](https://github.com/mozilla/DeepSpeech/files/3532623/thchs30-trie.zip)
Why my trie file's format is not a binary format?",file file format binary format,issue,negative,neutral,neutral,neutral,neutral,neutral
524084364,"OK, I think I deleted the old checkpoints in (/root/.local/share/deepspeech/checkpoints) this file, because it always shows the --n_hidden is not matched when I changed the --n_hidden to 512. But I don't think this is the main problem.",think old file always think main problem,issue,negative,positive,positive,positive,positive,positive
524076439,"> > **E Checkpoint directory (/root/.local/share/deepspeech/checkpoints) does not contain a valid checkpoint state.**
> 
> Loading checkpoint should not even happen if you don't give `--checkpoint_dir`. Is this current master ? Are you referring to https://github.com/mozilla/DeepSpeech/blob/master/Dockerfile ?
> 
> Can you share Docker build logs as well ?

Yes, based on that Dockerfile, I built it the day before yesterday and it has successfully built. The DeepSpeech version is 0.6.0-alpha.4. The weird thing is I can successfully run it yesterday, today is not working,always shows the problem like ' does not contain a valid checkpoint state ', but I did not change any checkpoint stuff.

Docker builds log: https://github.com/iekhwang/Mozilla-DeepSpeech-Issues/blob/master/docker-built-log)
Successfully ran log: https://github.com/iekhwang/Mozilla-DeepSpeech-Issues/blob/master/mandarin-train-log",directory contain valid state loading even happen give current master share docker build well yes based built day yesterday successfully built version weird thing successfully run yesterday today working always problem like contain valid state change stuff docker log successfully ran log,issue,positive,positive,positive,positive,positive,positive
524029429,"> **E Checkpoint directory (/root/.local/share/deepspeech/checkpoints) does not contain a valid checkpoint state.**

Loading checkpoint should not even happen if you don't give `--checkpoint_dir`. Is this current master ? Are you referring to https://github.com/mozilla/DeepSpeech/blob/master/Dockerfile ?

Can you share Docker build logs as well ?",directory contain valid state loading even happen give current master share docker build well,issue,positive,neutral,neutral,neutral,neutral,neutral
523809006,"> my question: is it possible to even output the whole region each character is preticted to be? instead of taking only the peak probability one could combine this with the center of the region the for example character ""a"" is choosen to be most likely

Right, this is the last thing I thought of while looking at this. The information is currently not exposed or kept easily accessible in the decoder, and there's a hard ""forget"" boundary between batches, as each `decoder_next` call only sees 16 time steps at a time for our inference graphs and clients.

I guess as a first step it'd be nice to see some visualizations of the curves of probability over time for the characters over an entire audio file. Then we could think about possible ways to track and use this global info for improving the timings.",question possible even output whole region character instead taking peak probability one could combine center region example character likely right last thing thought looking information currently exposed kept easily accessible hard forget boundary call time time inference guess first step nice see probability time entire audio file could think possible way track use global improving,issue,positive,positive,neutral,neutral,positive,positive
523791386,"Right, i'll close that since it's not a bug, hopefully somebody will find useful informations in it :)",right close since bug hopefully somebody find useful,issue,positive,positive,positive,positive,positive,positive
523790808,"> #2303 looks like it will make it much simpler to achieve anyway.

@reuben said on IRC that #2303 might be more tricky than expected, do you still want to hold your changes ?",like make much simpler achieve anyway said might tricky still want hold,issue,negative,positive,positive,positive,positive,positive
523790070,"> `util/taskcluster.py`
> `whl - not found`

I'm sorry, but it's too short to be helpful, can you share complete errors ?",found sorry short helpful share complete,issue,positive,negative,negative,negative,negative,negative
523788567,"> You don't need `deepspeech` installed for training.

I know.
Not build windows
`util/taskcluster.py`
`whl - not found`
linux - it`s work ",need training know build found work,issue,negative,neutral,neutral,neutral,neutral,neutral
523779681,"> And where to change it in the code? I do not understand you

You need to set that in the environment of your process.",change code understand need set environment process,issue,negative,neutral,neutral,neutral,neutral,neutral
523779321,"> > tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
> > (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 
> That error is documented: https://github.com/mozilla/DeepSpeech/blob/master/README.md#recommendations

And where to change it in the code? I do not understand you",root error found unknown get convolution algorithm probably initialize try looking see warning log message printed error change code understand,issue,negative,negative,neutral,neutral,negative,negative
523778781,"> tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
>   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.

That error is documented: https://github.com/mozilla/DeepSpeech/blob/master/README.md#recommendations",root error found unknown get convolution algorithm probably initialize try looking see warning log message printed error,issue,negative,negative,neutral,neutral,negative,negative
523778092,"> > > > Have you installed `tensorflow-gpu` ?
> > > 
> > > 
> > > Yes.
> > > `numpy` conflict version
> > 
> > 
> > Can you elaborate ?
> 
> ```
> DeepSpeech - numpy == 1.15.4
> TF 1.14.0 numpy == 1.16.2
> ```

You don't need `deepspeech` installed for training.",yes conflict version elaborate need training,issue,negative,positive,positive,positive,positive,positive
523776229,"This is unrelated to batch size and unrelated to multi gpu.

What version of TF and cuDNN do you have installed?",unrelated batch size unrelated version,issue,negative,neutral,neutral,neutral,neutral,neutral
523776137," I usually limit it like that

```
gpu_options = tf.GPUOptions (per_process_gpu_memory_fraction = 0.8)
sess = tf.Session (config = tf.ConfigProto (gpu_options = gpu_options))
```",usually limit like sess,issue,negative,negative,negative,negative,negative,negative
523775525,"> > > Have you installed `tensorflow-gpu` ?
> > 
> > 
> > Yes.
> > `numpy` conflict version
> 
> Can you elaborate ?
```
DeepSpeech - numpy == 1.15.4
TF 1.14.0 numpy == 1.16.2
```
",yes conflict version elaborate,issue,negative,positive,positive,positive,positive,positive
523774938,"> Could you explicitly indicate what command line you ran?

`./DeepSpeech.py --alphabet_config_path /home/rt/data/alphabet.txt --train_files /home/rt/data/clips/train.csv --dev_files /home/rt/data/clips/dev.csv --test_files /home/rt/data/clips/test.csv --train_batch_size 2 --dev_batch_size 2 --test_batch_size 2
`",could explicitly indicate command line ran,issue,negative,neutral,neutral,neutral,neutral,neutral
523773835,"```

Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000                                                                                                                                                                Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node tower_0/conv1d}}]]
         [[tower_1/gradients/tower_1/BiasAdd_4_grad/BiasAddGrad/_117]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node tower_0/conv1d}}]]
0 successful operations.
1 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./DeepSpeech.py"", line 894, in <module>
    tfv1.app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""./DeepSpeech.py"", line 878, in main
    train()
  File ""./DeepSpeech.py"", line 599, in train
    train_loss, _ = run_set('train', epoch, train_init_op)
  File ""./DeepSpeech.py"", line 567, in run_set
    feed_dict=feed_dict)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node tower_0/conv1d (defined at ./DeepSpeech.py:57) ]]
         [[tower_1/gradients/tower_1/BiasAdd_4_grad/BiasAddGrad/_117]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node tower_0/conv1d (defined at ./DeepSpeech.py:57) ]]
0 successful operations.
1 derived errors ignored.

Original stack trace for 'tower_0/conv1d':
  File ""./DeepSpeech.py"", line 894, in <module>
    tfv1.app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""./DeepSpeech.py"", line 878, in main
    train()
  File ""./DeepSpeech.py"", line 447, in train
    gradients, loss, non_finite_files = get_tower_results(iterator, optimizer, dropout_rates)
  File ""./DeepSpeech.py"", line 298, in get_tower_results
    avg_loss, non_finite_files = calculate_mean_edit_distance_and_loss(iterator, dropout_rates, reuse=i > 0)
  File ""./DeepSpeech.py"", line 225, in calculate_mean_edit_distance_and_loss
    logits, _ = create_model(batch_x, batch_seq_len, dropout, reuse=reuse, rnn_impl=rnn_impl)
  File ""./DeepSpeech.py"", line 153, in create_model
    batch_x = create_overlapping_windows(batch_x)
  File ""./DeepSpeech.py"", line 57, in create_overlapping_windows
    batch_x = tf.nn.conv1d(batch_x, eye_filter, stride=1, padding='SAME')
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1624, in conv1d
    name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

```",epoch training time loss recent call last file line return file line file line root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node unknown get convolution algorithm probably initialize try looking see warning log message printed node successful derived handling exception another exception recent call last file line module main file line run file line run main file line main file line main train file line train epoch file line file line run file line file line file line raise type message root error found unknown get convolution algorithm probably initialize try looking see warning log message printed node defined unknown get convolution algorithm probably initialize try looking see warning log message printed node defined successful derived original stack trace file line module main file line run file line run main file line main file line main train file line train loss file line file line dropout file line file line file line return file line return file line file line file line file line return file line file line,issue,negative,positive,positive,positive,positive,positive
523773668,"
Incorrectly asked question.
How to limit memory consumption? `Batch_size` does not work correctly",incorrectly question limit memory consumption work correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
523773386,"It should just work. Also, the screen shot you presented doesn't say anything about an out of memory error.

PS: Please do not include screen shots.",work also screen shot say anything memory error please include screen,issue,negative,neutral,neutral,neutral,neutral,neutral
523768643,"> @lissyx I based on this article to train the model
> https://medium.com/sotuu/hiragana-based-speech-recognition-for-japanese-with-deepspeech-220d14047d51
> I only have 20,000 records including a wave file and a transcript per each record to train the model. Honestly, all my audio files are .wav format, do I need to use import_cv2

Thanks but there is no information whatsoever regarding the versions that have been used.

You also have used some early stopping features, maybe it is too aggressive? Try without any early stop.",based article train model wave file transcript per record train model honestly audio format need use thanks information whatsoever regarding used also used early stopping maybe aggressive try without early stop,issue,positive,positive,positive,positive,positive,positive
523719110,"@lissyx I based on this article to train the model
https://medium.com/sotuu/hiragana-based-speech-recognition-for-japanese-with-deepspeech-220d14047d51
I only have 20,000 records including a wave file and a transcript per each record to train the model. Honestly, all my audio files are .wav format, do I need to use import_cv2",based article train model wave file transcript per record train model honestly audio format need use,issue,negative,positive,positive,positive,positive,positive
523608622,"> the builds are always done on a fresh VM.

I agree, if the build is done by a fresh VM forcing the clean/build makes no sense. Removed the rebuild parameter.

",always done fresh agree build done fresh forcing sense removed rebuild parameter,issue,positive,positive,positive,positive,positive,positive
523556269,"@cahuja1992 after all dense layers except the last one. You can replace the code on https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L65 by the following:
```python
def dense(name, x, units, dropout_rate=None, relu=True, layer_norm=False):
    with tf.variable_scope(name):
        bias = variable_on_cpu('bias', [units], tf.zeros_initializer())
        weights = variable_on_cpu('weights', [x.shape[-1], units], tf.contrib.layers.xavier_initializer())

    output = tf.nn.bias_add(tf.matmul(x, weights), bias)

    if relu:
        output = tf.minimum(tf.nn.relu(output), FLAGS.relu_clip)

    if layer_norm:
        output = tf.contrib.layers.layer_norm(output)

    if dropout_rate is not None:
        output = tf.nn.dropout(output, rate=dropout_rate)

    return output
```

**Important: If you train using the layernorm, you must remember to evaluate/export using the layernorm as well.",dense except last one replace code following python dense name name bias output bias output output output output none output output return output important train must remember well,issue,negative,positive,positive,positive,positive,positive
523506645,"@malena1906 Oooh, great idea importing the labels into Audacity!

I did some experiments and the first word timings with the fix match what they looked like before the peak probability change (5bf6e63f1b87289ab870d0f027b2be185d5ae79e) was introduced. So this is a behavior unrelated to that change or the fix for this issue. Would you mind opening a new issue about this weird first word behavior? I've tried a couple of approaches trying to fix it but it made other things worse, so I'll have to look at it more carefully when I have some time.",great idea audacity first word fix match like peak probability change behavior unrelated change fix issue would mind opening new issue weird first word behavior tried couple trying fix made worse look carefully time,issue,positive,positive,neutral,neutral,positive,positive
523443914,"> There are two comments in test-raspbian-opt-base.tyml and test-armbian-opt-base.tyml that mention Debian Stretch as the justification for a configure option. Are those still true for Buster?

The `--with-fpectl` ? It's likely, I'll give a round of testing without to make sure",two mention stretch justification configure option still true buster likely give round testing without make sure,issue,negative,positive,positive,positive,positive,positive
523410203,"There's Windows support on upstream, so you should be able to get that part working https://pypi.org/project/tensorflow-gpu/#files",support upstream able get part working,issue,negative,positive,positive,positive,positive,positive
523410052,"> I will switch to linux.
> Since on windows it does not even see gpu

Have you installed `tensorflow-gpu` ?",switch since even see,issue,negative,neutral,neutral,neutral,neutral,neutral
523402178,"The fact that we don't currently support training on Windows does not mean we don't care about you getting it. Before contributors sent us feedback / patches we had no build for windows at all, and now it's supported for inference. ",fact currently support training mean care getting sent u feedback build inference,issue,positive,negative,negative,negative,negative,negative
523395988,"@sonfiree sorry but it's hard to do divination with that much details. Unfortunately you need to figure out how / why soxi is still not found. Is it in your PATH? Nobody on the team uses windows, and we only support training on Linux so far.

I'm sure it's just a PATH issue. ",sorry hard divination much unfortunately need figure still found path nobody team support training far sure path issue,issue,positive,negative,negative,negative,negative,negative
523393962,"> @sonfiree again, can you elaborate ? I'd really like to help you, but so far I'm spending more time asking you to just share us errors to **know** what's happening.

I showed the error on top.
`sox` installed, `soxi` not found
",elaborate really like help far spending time share u know happening error top found,issue,positive,positive,positive,positive,positive,positive
523393144,"> `soxi` not work

@sonfiree again, can you elaborate ? I'd really like to help you, but so far I'm spending more time asking you to just share us errors to **know** what's happening.",work elaborate really like help far spending time share u know happening,issue,positive,positive,positive,positive,positive,positive
523382636,"> windows 10
> 
> ```
> import wave
> import contextlib			
> with contextlib.closing(wave.open(wav_filename,'r')) as f:
>    frames = f.getnframes()	
> ```

Sorry, but that is not giving more informations. Re-run the `soxi` command line. Does it works? Then re-run the importer? Share the output.",import wave import sorry giving command line work importer share output,issue,positive,negative,negative,negative,negative,negative
523379276,"> sox it`s work. Code not work

Do you mind sharing more informations ? We can't do anything to help with ""code not work"".",work code work mind ca anything help code work,issue,negative,neutral,neutral,neutral,neutral,neutral
523374437,"Here you can see both OLD and NEW version of the timings in audacity and for the first word its weird, any ideas @reuben ?

![image](https://user-images.githubusercontent.com/48288706/63419851-ce81bb80-c405-11e9-9b83-864aec0d6585.png)
",see old new version audacity first word weird image,issue,negative,negative,neutral,neutral,negative,negative
523373230,"For me it fixes the problem with inconsistencies in increasing timings, but I think the two starting characters are now quite different.
Here is the same output with the changes included. Sorry I haven't had time earlier to response 
0.000	s *****
0.020	h *****
0.360	e
0.460	 
0.480	h
0.520	a
0.580	d
0.620	e
0.780	d
0.960	u
1.020	c
1.100	s
1.200	 
1.220	s
1.280	u
1.300	i
1.340	t
1.360	 
1.420	a
1.440	n
1.460	d
1.500	 
1.560	g
1.580	r
1.620	e
1.660	a
1.680	s
1.800	y
1.900	 
1.940	w
1.980	a
2.020	t
2.080	h
2.240	o
2.280	r
2.380	 
2.500	a
2.560	l
2.680	 
2.740	y
2.780	e
2.800	a
2.820	r
I'll check the behaviour with more examples later but I agree with @dabinat that all of the rest letter timings are now a bit earlier which is not too bad as they were late before anyways (here all settings same as stated in my first coment)",problem increasing think two starting quite different output included sorry time response check behaviour later agree rest letter bit bad late anyways stated first,issue,negative,negative,negative,negative,negative,negative
523364649,"> subprocess.CalledProcessError: Command '['soxi', '-s', 'D:\\spet\\data\\clips\\common_voice_ru_18849089.wav']' returned non-zero exit status 1.

@sonfiree Can you run that command manually ?",command returned exit status run command manually,issue,negative,neutral,neutral,neutral,neutral,neutral
523339137,Closing for lack of activity and likely fixed by #2192,lack activity likely fixed,issue,negative,positive,neutral,neutral,positive,positive
523327063,"I think the `t:Rebuild` is transitive, it's causing DeepSpeechClient to be rebuilt as well:

```
+ do_deepspeech_netframework_wpf_example_build
+ cd /c/builds/tc-workdir//DeepSpeech/ds/examples/net_framework
+ nuget install DeepSpeechWPF/packages.config -OutputDirectory DeepSpeechWPF/packages/
Feeds used:
  C:\Users\task_1566363296\.nuget\packages\
  https://api.nuget.org/v3/index.json

Restoring NuGet package CSCore.1.2.1.2.
Restoring NuGet package NAudio.1.9.0.
  GET https://api.nuget.org/v3-flatcontainer/cscore/1.2.1.2/cscore.1.2.1.2.nupkg
  GET https://api.nuget.org/v3-flatcontainer/naudio/1.9.0/naudio.1.9.0.nupkg
  OK https://api.nuget.org/v3-flatcontainer/naudio/1.9.0/naudio.1.9.0.nupkg 158ms
Installing NAudio 1.9.0.
  OK https://api.nuget.org/v3-flatcontainer/cscore/1.2.1.2/cscore.1.2.1.2.nupkg 323ms
Installing CSCore 1.2.1.2.
Adding package 'NAudio.1.9.0' to folder 'C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\'
Added package 'NAudio.1.9.0' to folder 'C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\'
Adding package 'CSCore.1.2.1.2' to folder 'C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\'
Added package 'CSCore.1.2.1.2' to folder 'C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\'
++ cygpath 'C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\MSBuild.exe'
+ MSBUILD='/c/Program Files (x86)/Microsoft Visual Studio/2017/BuildTools/MSBuild/15.0/Bin/MSBuild.exe'
+ MSYS2_ARG_CONV_EXCL=/
+ '/c/Program Files (x86)/Microsoft Visual Studio/2017/BuildTools/MSBuild/15.0/Bin/MSBuild.exe' DeepSpeechWPF/DeepSpeech.WPF.csproj /t:Rebuild /p:Configuration=Release /p:Platform=x64 /p:OutputPath=bin/x64
Microsoft (R) Build Engine version 15.9.21+g9802d43bc3 for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

Build started 8/21/2019 5:10:20 AM.
Project ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" on node 1 (Rebuild target(s)).
CoreClean:
  Creating directory ""obj\x64\Release\"".
Project ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" (1) is building ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj"" (2:2) on node 1 (Clean target(s)).
CoreClean:
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\Release\DeepSpeechClient.dll"".
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\Release\DeepSpeechClient.pdb"".
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\obj\x64\Release\DeepSpeechClient.csprojAssemblyReference.cache"".
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\obj\x64\Release\DeepSpeechClient.csproj.CoreCompileInputs.cache"".
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\obj\x64\Release\DeepSpeechClient.dll"".
  Deleting file ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\obj\x64\Release\DeepSpeechClient.pdb"".
Done Building Project ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj"" (Clean target(s)).
PrepareForBuild:
  Creating directory ""bin/x64\"".
Project ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" (1) is building ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj"" (2:3) on node 1 (default targets).
GenerateTargetFrameworkMonikerAttribute:
Skipping target ""GenerateTargetFrameworkMonikerAttribute"" because all output files are up-to-date with respect to the input files.
C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Microsoft.CSharp.CurrentVersion.targets(134,9): warning MSB3884: Could not find rule set file ""MinimumRecommendedRules.ruleset"". [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]
CoreCompile:
  C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Roslyn\csc.exe /noconfig /unsafe+ /nowarn:1701,1702 /nostdlib+ /platform:x64 /errorreport:prompt /define:TRACE /highentropyva+ /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\Microsoft.CSharp.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\mscorlib.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Core.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.DataSetExtensions.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Net.Http.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.Linq.dll"" /debug:pdbonly /filealign:512 /optimize+ /out:obj\x64\Release\DeepSpeechClient.dll /subsystemversion:6.00 /target:library /utf8output /deterministic+ DeepSpeech.cs Enums\ErrorCodes.cs Interfaces\IDeepSpeech.cs Extensions\NativeExtensions.cs Models\Metadata.cs Models\MetadataItem.cs NativeImp.cs Properties\AssemblyInfo.cs Structs\ModelState.cs Structs\StreamingState.cs Structs\Metadata.cs Structs\MetadataItem.cs ""C:\builds\tc-workdir\tmp\.NETFramework,Version=v4.6.2.AssemblyAttributes.cs""
  Using shared compilation with compiler from directory: C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Roslyn
CopyFilesToOutputDirectory:
  Copying file from ""obj\x64\Release\DeepSpeechClient.dll"" to ""bin/x64\DeepSpeechClient.dll"".
  DeepSpeechClient -> C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\DeepSpeechClient.dll
  Copying file from ""obj\x64\Release\DeepSpeechClient.pdb"" to ""bin/x64\DeepSpeechClient.pdb"".
Done Building Project ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj"" (default targets).
GenerateBindingRedirects:
  No suggested binding redirects from ResolveAssemblyReferences.
CoreResGen:
  resgen.exe /useSourcePath /r:C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\CSCore.1.2.1.2\lib\net35-client\CSCore.dll /r:C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\DeepSpeechClient.dll /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\Microsoft.CSharp.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\mscorlib.dll"" /r:C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\NAudio.1.9.0\lib\net35\NAudio.dll /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\PresentationCore.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\PresentationFramework.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Core.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.DataSetExtensions.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Net.Http.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Windows.Forms.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xaml.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.Linq.dll"" /r:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\WindowsBase.dll"" /compile Properties\Resources.resx,obj\x64\Release\DeepSpeech.WPF.Properties.Resources.resources
  Processing resource file ""Properties\Resources.resx"" into ""obj\x64\Release\DeepSpeech.WPF.Properties.Resources.resources"".
GenerateTargetFrameworkMonikerAttribute:
Skipping target ""GenerateTargetFrameworkMonikerAttribute"" because all output files are up-to-date with respect to the input files.
C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Microsoft.CSharp.CurrentVersion.targets(134,9): warning MSB3884: Could not find rule set file ""MinimumRecommendedRules.ruleset"". [C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj]
CoreCompile:
  C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Roslyn\csc.exe /noconfig /unsafe+ /nowarn:1701,1702 /nostdlib+ /platform:x64 /errorreport:prompt /warn:4 /define:TRACE /highentropyva+ /reference:C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\CSCore.1.2.1.2\lib\net35-client\CSCore.dll /reference:C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\DeepSpeechClient.dll /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\Microsoft.CSharp.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\mscorlib.dll"" /reference:C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\NAudio.1.9.0\lib\net35\NAudio.dll /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\PresentationCore.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\PresentationFramework.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Core.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.DataSetExtensions.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Data.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Net.Http.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Windows.Forms.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xaml.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\System.Xml.Linq.dll"" /reference:""C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.6.2\WindowsBase.dll"" /debug:pdbonly /filealign:512 /optimize+ /out:obj\x64\Release\DeepSpeech.WPF.exe /subsystemversion:6.00 /resource:obj\x64\Release\DeepSpeech.WPF.g.resources /resource:obj\x64\Release\DeepSpeech.WPF.Properties.Resources.resources /target:winexe /utf8output /deterministic+ App.xaml.cs MainWindow.xaml.cs Properties\AssemblyInfo.cs Properties\Resources.Designer.cs Properties\Settings.Designer.cs C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\obj\x64\Release\MainWindow.g.cs C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\obj\x64\Release\App.g.cs ""C:\builds\tc-workdir\tmp\.NETFramework,Version=v4.6.2.AssemblyAttributes.cs""
  Using shared compilation with compiler from directory: C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Roslyn
_CopyFilesMarkedCopyLocal:
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\NAudio.1.9.0\lib\net35\NAudio.dll"" to ""bin/x64\NAudio.dll"".
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\DeepSpeechClient.pdb"" to ""bin/x64\DeepSpeechClient.pdb"".
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\bin\x64\DeepSpeechClient.dll"" to ""bin/x64\DeepSpeechClient.dll"".
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\CSCore.1.2.1.2\lib\net35-client\CSCore.xml"" to ""bin/x64\CSCore.xml"".
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\CSCore.1.2.1.2\lib\net35-client\CSCore.dll"" to ""bin/x64\CSCore.dll"".
  Copying file from ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\packages\NAudio.1.9.0\lib\net35\NAudio.xml"" to ""bin/x64\NAudio.xml"".
  Creating ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\obj\x64\Release\DeepSpeech.WPF.csproj.CopyComplete"" because ""AlwaysCreate"" was specified.
_CopyAppConfigFile:
  Copying file from ""App.config"" to ""bin/x64\DeepSpeech.WPF.exe.config"".
CopyFilesToOutputDirectory:
  Copying file from ""obj\x64\Release\DeepSpeech.WPF.exe"" to ""bin/x64\DeepSpeech.WPF.exe"".
  DeepSpeech.WPF -> C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\bin\x64\DeepSpeech.WPF.exe
  Copying file from ""obj\x64\Release\DeepSpeech.WPF.pdb"" to ""bin/x64\DeepSpeech.WPF.pdb"".
Done Building Project ""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" (Rebuild target(s)).

Build succeeded.

""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" (Rebuild target) (1) ->
""C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj"" (default target) (2:3) ->
(ResolveCodeAnalysisRuleSet target) -> 
  C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Microsoft.CSharp.CurrentVersion.targets(134,9): warning MSB3884: Could not find rule set file ""MinimumRecommendedRules.ruleset"". [C:\builds\tc-workdir\DeepSpeech\ds\native_client\dotnet\DeepSpeechClient\DeepSpeechClient.csproj]


""C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj"" (Rebuild target) (1) ->
  C:\Program Files (x86)\Microsoft Visual Studio\2017\BuildTools\MSBuild\15.0\Bin\Microsoft.CSharp.CurrentVersion.targets(134,9): warning MSB3884: Could not find rule set file ""MinimumRecommendedRules.ruleset"". [C:\builds\tc-workdir\DeepSpeech\ds\examples\net_framework\DeepSpeechWPF\DeepSpeech.WPF.csproj]

    2 Warning(s)
    0 Error(s)

Time Elapsed 00:00:07.56
```

Do we really need it? As far as I know we don't have any caches setup for build objects on Windows, the builds are always done on a fresh VM.",think rebuild transitive causing rebuilt well install used package package get get package folder added package folder package folder added package folder visual visual visual rebuild build engine version framework copyright corporation reserved build project node rebuild target directory project building node clean target file file file file file file done building project clean target directory project building node default skipping target output respect input visual warning could find rule set file visual prompt trace library compilation compiler directory visual file file done building project default binding resource file skipping target output respect input visual warning could find rule set file visual prompt trace compilation compiler directory visual file file file file file file file file file done building project rebuild target build rebuild target default target target visual warning could find rule set file rebuild target visual warning could find rule set file warning error time really need far know setup build always done fresh,issue,negative,positive,neutral,neutral,positive,positive
523312788,"> --n_hidden 494 --epoch 30

According to the log and those, you've got 3 epochs completed. It's likely your model just learnt nothing ...

Why using 494 ? Our models are trained with 2048.

Also, @TrieuLe0801 you don't document how much data you have to perform training ...",epoch according log got likely model learnt nothing trained also document much data perform training,issue,negative,positive,neutral,neutral,positive,positive
523263235,"@lissyx when it predicted the data test, it didn't respond any. I think maybe I miss some steps",data test respond think maybe miss,issue,negative,neutral,neutral,neutral,neutral,neutral
523168805,"> Do we really want to break backwards compat in the C API/ABI with this change? Clients compiled against older versions will run but crash mysteriously. I had a PR doing a bunch of cleaning up on the API, but it got held back by having to figure out what compatibility strategy we want to have. Technically since we're 0.x anything goes, but we've tried to keep things stable when possible. Thoughts?

I do agree, but I'm also thinking that it's not a good idea we keep useless parameter for nothing. For now, I think the strategy we should have is do not carry any burden we absolutely don't have to: we'll always end up having to keep crap, so we should try and limit as much as possible :)",really want break backwards change older run crash mysteriously bunch cleaning got back figure compatibility strategy want technically since anything go tried keep stable possible agree also thinking good idea keep useless parameter nothing think strategy carry burden absolutely always end keep crap try limit much possible,issue,negative,negative,neutral,neutral,negative,negative
523157183,"Do we really want to break backwards compat in the C API/ABI with this change? Clients compiled against older versions will run but crash mysteriously. I had a PR doing a bunch of cleaning up on the API, but it got held back by having to figure out what compatibility strategy we want to have. Technically since we're 0.x anything goes, but we've tried to keep things stable when possible. Thoughts?",really want break backwards change older run crash mysteriously bunch cleaning got back figure compatibility strategy want technically since anything go tried keep stable possible,issue,negative,positive,neutral,neutral,positive,positive
523087444,"ok i will do that

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: lissyx <notifications@github.com>
Sent: Tuesday, August 20, 2019 7:13:11 PM
To: mozilla/DeepSpeech <DeepSpeech@noreply.github.com>
Cc: Suhad <smalissa17@cit.just.edu.jo>; Mention <mention@noreply.github.com>
Subject: Re: [mozilla/DeepSpeech] Error: Trie file version mismatch (4 instead of expected 3). Update your trie file. terminate called after throwing an instance of 'int' (#2274)


and about share more information about the error, like this [Image]

Thanks for illustrating perfectly why you should never share screenshots but actual plain text content.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/mozilla/DeepSpeech/issues/2274?email_source=notifications&email_token=ALUHX2T3RB7HKBG4DI7FGY3QFQJZPA5CNFSM4IHQNYSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4W2QPQ#issuecomment-523085886>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ALUHX2W5TE24PR6JEH2E7ZDQFQJZPANCNFSM4IHQNYSA>.
",get outlook sent august mention mention subject error file version mismatch instead update file terminate throwing instance share information error like image thanks perfectly never share actual plain text content reply directly view mute thread,issue,positive,negative,neutral,neutral,negative,negative
523085886,">  and about share more information about the error, like this [Image]

Thanks for illustrating perfectly why you should never share screenshots but actual plain text content.",share information error like image thanks perfectly never share actual plain text content,issue,positive,negative,negative,negative,negative,negative
523084585,"ok i will do that.
and about share more information about the error, like this
[Image]

________________________________
From: lissyx <notifications@github.com>
Sent: Tuesday, August 20, 2019 6:59 PM
To: mozilla/DeepSpeech
Cc: Suhad; Mention
Subject: Re: [mozilla/DeepSpeech] Error: Trie file version mismatch (4 instead of expected 3). Update your trie file. terminate called after throwing an instance of 'int' (#2274)


yes i fixed the trie file issue, but again i have another error, when i run my script , the training completed to the end , but the problem in testing , it could not finish or start the testing and give me this error: fatal python error. i try to solve it but i can’t success, please help me

As I said, it's not a bug. Please use Discourse for getting help. And please share more information than ""fatal python error"" ....

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/mozilla/DeepSpeech/issues/2274?email_source=notifications&email_token=ALUHX2WFQIP4AKY6AES4YATQFQIHDA5CNFSM4IHQNYSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4WZFRQ#issuecomment-523080390>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ALUHX2UUIMNF3XZPHYIYFD3QFQIHDANCNFSM4IHQNYSA>.
",share information error like image sent august mention subject error file version mismatch instead update file terminate throwing instance yes fixed file issue another error run script training end problem testing could finish start testing give error fatal python error try solve success please help said bug please use discourse getting help please share information fatal python error reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
523080390,"> yes i fixed the trie file issue, but again i have another error, when i run my script , the training completed to the end , but the problem in testing , it could not finish or start the testing and give me this error: fatal python error. i try to solve it but i can’t success, please help me

As I said, it's not a bug. Please use Discourse for getting help. And please share more information than ""fatal python error"" ....",yes fixed file issue another error run script training end problem testing could finish start testing give error fatal python error try solve success please help said bug please use discourse getting help please share information fatal python error,issue,negative,positive,positive,positive,positive,positive
523071622,"yes i fixed the trie file issue, but again i have  another error, when i run my script , the training completed to the end , but the problem in testing , it could not finish or start the testing and give me this error: fatal python error.
i try to solve it but i can’t success, please help me

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: lissyx <notifications@github.com>
Sent: Tuesday, August 20, 2019 6:24:27 PM
To: mozilla/DeepSpeech <DeepSpeech@noreply.github.com>
Cc: Suhad <smalissa17@cit.just.edu.jo>; Mention <mention@noreply.github.com>
Subject: Re: [mozilla/DeepSpeech] Error: Trie file version mismatch (4 instead of expected 3). Update your trie file. terminate called after throwing an instance of 'int' (#2274)


Closed #2274<https://github.com/mozilla/DeepSpeech/issues/2274>.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/mozilla/DeepSpeech/issues/2274?email_source=notifications&email_token=ALUHX2UVUBP3NZGYLL7N2RTQFQECXA5CNFSM4IHQNYSKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOTEYL7WQ#event-2570108890>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ALUHX2X5TVU3PKU5OTPYL7DQFQECXANCNFSM4IHQNYSA>.
",yes fixed file issue another error run script training end problem testing could finish start testing give error fatal python error try solve success please help get outlook sent august mention mention subject error file version mismatch instead update file terminate throwing instance closed reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
523064530,Yes it got fixed. I used v 0.5.1 to fix the issue. Thanks a ton.,yes got fixed used fix issue thanks ton,issue,positive,positive,positive,positive,positive,positive
523063958,Closing because it is likely outdated. Feel free to open a new issue if required.,likely outdated feel free open new issue,issue,positive,positive,neutral,neutral,positive,positive
523062938,Closing as it seems there is no issue here. Please use Discourse for discussions.,issue please use discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
523061553,"> FileNotFoundError: [Errno 2] File b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs' does not exist: b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs'
> Kindly help me figure out the error ?
> is the problem in tensorflow version , i have version =1.14.0

@suhad999  Do you read the error messages ? It says your file does not exists ...",file exist kindly help figure error problem version version read error file,issue,negative,positive,positive,positive,positive,positive
523050100,Maybe we should take the opportunity of v0.6 to fix that and remove it from the API,maybe take opportunity fix remove,issue,negative,neutral,neutral,neutral,neutral,neutral
523049252,It looks like its use was removed as part of d9a269412e492ca5046c9ab89f0547be51050159 cc @dabinat ,like use removed part,issue,negative,neutral,neutral,neutral,neutral,neutral
522901949,"> I got this problem:

There's no error in that training log, can you please explicit what is wrong here ?",got problem error training log please explicit wrong,issue,negative,negative,negative,negative,negative,negative
522700298,I think this may have been caused by another script and is not actually a DeepSpeech issue. I can no longer reproduce this.,think may another script actually issue longer reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
522698236,"Just FYI. With both of ""--filter_alphabet"" and ""--normalize"", the dataset generated by import_cv2.py can be trained correctly. But I didn't check which one (or both) actually did the trick.",normalize trained correctly check one actually trick,issue,negative,neutral,neutral,neutral,neutral,neutral
522586874,"> Oh, so you want to use TensorFlow to directly load the exported graph? 

Yes exactly. Thanks a lot for your answer",oh want use directly load graph yes exactly thanks lot answer,issue,positive,positive,positive,positive,positive,positive
522584082,"Oh, so you want to use TensorFlow to directly load the exported graph? Then you'll have to use the checkpoint. Our pre-trained models are meant to be used with the native client or their bindings for Python/NodeJS/Rust/etc. Any direct manipulation should be done via the checkpoint rather than the exported model to avoid any weirdness (like the metadata node for example).",oh want use directly load graph use meant used native client direct manipulation done via rather model avoid weirdness like node example,issue,negative,positive,neutral,neutral,positive,positive
522583256,"Sorry, but if I am not mistaken, the README just mentions how to do inference with the pre-trained model using the installed deepspeech package. I don't see any Python code to directly load the frozen graph and do inference (without building the graph and restoring the checkpoint)",sorry mistaken inference model package see python code directly load frozen graph inference without building graph,issue,negative,negative,negative,negative,negative,negative
522531293,@rhamnett All augmentations of this PR work over spectrogram and/or feature space. All of them are implemented using tensorflow funcs. Thus I believe this should be considerably faster compared to augmenting audio data.,work spectrogram feature space thus believe considerably faster audio data,issue,negative,positive,neutral,neutral,positive,positive
522511357,"Thanks a lot for your answer. I have one more question for this inference without building the graph.

>     Is there any possibility of using the fixed graph directly for inference only without being required to build the graph first?
> 
> Of course, that's what our native clients are for!

I am not quite sure how to do that. If I look into the evaluate.py or the DeepSpeech.py (i.e. do_single_file_inference) you always build the graph first by calling create_model before loading the checkpoint. Do you have any example how to just load the frozen graph and do inference? Loading the fixed graph with the few lines of code from the initial post works for v0.1.0 but for newer ones it results in a error regarding the LSTM layer

> tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'BlockLSTM'





",thanks lot answer one question inference without building graph possibility fixed graph directly inference without build graph first course native quite sure look always build graph first calling loading example load frozen graph inference loading fixed graph code initial post work error regarding layer registered support,issue,positive,positive,positive,positive,positive,positive
522321393,I ran import_cv2.py with normalize and saw only regular alphabet chars.,ran normalize saw regular alphabet,issue,negative,neutral,neutral,neutral,neutral,neutral
522318678,"Hi, how does https://github.com/mozilla/DeepSpeech/pull/2252 impact this? looks like duplication of effort",hi impact like duplication effort,issue,negative,neutral,neutral,neutral,neutral,neutral
522318357,"Yes,  I realised in the middle that I should have cross-compiled. Would have been faster. I will git it a try some time this week.  ",yes middle would faster git try time week,issue,negative,neutral,neutral,neutral,neutral,neutral
522315127,"@lissyx I also checked through the other importers, seems just this one was missed where maybe_download was used.",also checked one used,issue,negative,neutral,neutral,neutral,neutral,neutral
522315106,"> I built it on Nano itself, did not cross compile. It was really slow to build bazel dependency and had many issues. I will post detailed instructions and all commands that I followed.

Thanks, I'd really prefer seeing it being cross-compiled: this way it's a first step for us to be able to leverage and provide it.",built cross compile really slow build dependency many post detailed thanks really prefer seeing way first step u able leverage provide,issue,negative,positive,positive,positive,positive,positive
522313398,"@lissyx thank you so much. Yes, I was running 0.5.1 model on master build. Your new model v0.6.0 is running successfully. Thanks. 
I built it on Nano itself, did not cross compile. It was really slow to build bazel dependency and had many issues. I will post detailed instructions and all commands that I followed. Thanks. 
",thank much yes running model master build new model running successfully thanks built cross compile really slow build dependency many post detailed thanks,issue,positive,positive,positive,positive,positive,positive
522312336,"@lissyx  sure, 

from util.downloader import maybe_download

could not be pulled in until the sys.path was inserted - simple as that :)",sure import could inserted simple,issue,negative,positive,positive,positive,positive,positive
522309737,"> Shall I reopen the new issue, with the corrected name ?

@cahuja1992 please do, this is amazing work, want to get it usable ASAP, read the Google info at https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html - awesome",shall reopen new issue corrected name please amazing work want get usable read awesome,issue,positive,positive,positive,positive,positive,positive
522300961,"Try that https://github.com/reuben/DeepSpeech/releases/tag/v0.6.0-alpha.4

Also did you cross compile? ",try also cross compile,issue,negative,neutral,neutral,neutral,neutral,neutral
522300891,"Are you trying to run 0.5.1 model on master build? You need to have matching versions, we have a 0.6.0a4 model on github, maybe @reuben has the link? ",trying run model master build need matching model maybe link,issue,negative,neutral,neutral,neutral,neutral,neutral
522290608,(Didn’t mean to close it - I hit the wrong button on my phone),mean close hit wrong button phone,issue,negative,negative,negative,negative,negative,negative
522290540,"I ran it without normalization because I don’t want it normalized because those transcripts aren’t even supposed to be in the dataset. I want the importer to skip them. One would assume given that the argument is called filter_alphabet that it would filter out transcripts containing those characters but it allows them through.

Even if you switch normalization on, some invalid symbols like + still make it through.",ran without normalization want even supposed want importer skip one would assume given argument would filter even switch normalization invalid like still make,issue,negative,neutral,neutral,neutral,neutral,neutral
522270720,@reuben is there any chance we can get a checkpoint directory for 0.6 with all the corpus training? I can't do any further experiments right now.,chance get directory corpus training ca right,issue,negative,positive,positive,positive,positive,positive
522261464,"@lissyx I finally built the deepspeech libraries for Jetson Nano. But, when I run the model I am getting model incompatibility issues. Please see below for the full error. Any idea how I can proceed?

`essence@essence-desktop:~$ deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --audio audio/2830-3980-0043.wav 
Loading model from file models/output_graph.pbmm
TensorFlow: v1.14.0-14-g1aad02a78e
DeepSpeech: v0.6.0-alpha.4-40-g7f642ed
2019-08-17 19:17:02.068494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-08-17 19:17:02.092676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.092822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA Tegra X1 major: 5 minor: 3 memoryClockRate(GHz): 0.9216
pciBusID: 0000:00:00.0
2019-08-17 19:17:02.092863: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-08-17 19:17:02.092970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.093102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.093163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-08-17 19:17:02.551550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:17:02.551628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-08-17 19:17:02.551658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-08-17 19:17:02.551868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.552063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.552222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:972] ARM64 does not support NUMA - returning NUMA node zero
2019-08-17 19:17:02.552330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 16 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X1, pci bus id: 0000:00:00.0, compute capability: 5.3)
Specified model file version (0) is incompatible with minimum version supported by this client (2). See https://github.com/mozilla/DeepSpeech/#model-compatibility for more information
Traceback (most recent call last):
  File ""/usr/local/bin/deepspeech"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.6/dist-packages/deepspeech/client.py"", line 91, in main
    ds = Model(args.model, N_FEATURES, N_CONTEXT, args.alphabet, BEAM_WIDTH)
  File ""/usr/local/lib/python3.6/dist-packages/deepspeech/__init__.py"", line 23, in __init__
    raise RuntimeError(""CreateModel failed with error code {}"".format(status))
RuntimeError: CreateModel failed with error code 8195`
",finally built run model getting model incompatibility please see full error idea proceed essence model alphabet audio loading model file successfully dynamic library arm support node zero found device name major minor statically linked skip check arm support node zero arm support node zero visible device interconnect strength edge matrix arm support node zero arm support node zero arm support node zero device memory physical device name bus id compute capability model file version incompatible minimum version client see information recent call last file line module main file line main model file line raise error code status error code,issue,positive,positive,neutral,neutral,positive,positive
522209320,"The reason why our inference graph only processes 16 time steps at a time is that we want to support streaming inference, and with a graph that takes the entire audio file at once that's not possible.

The import failure is due to a special metadata node that we put in the graph when saving. IIRC you can simply delete that node from the graph before calling import_graph_def with `del g['model_metadata']`. As you can see, what you're doing is not exactly a supported use case :P

> Is there any possibility of using the fixed graph directly for inference only without being required to build the graph first?

Of course, that's what our native clients are for!",reason inference graph time time want support streaming inference graph entire audio file possible import failure due special node put graph saving simply delete node graph calling see exactly use case possibility fixed graph directly inference without build graph first course native,issue,negative,positive,neutral,neutral,positive,positive
522208807,"@dabinat thanks! sorry for the inconvenience with the breaking changes. FWIW, there's a 0.5.1 model re-exported for current master available here, which we use for tests: https://github.com/reuben/DeepSpeech/releases/v0.6.0-alpha.4",thanks sorry inconvenience breaking model current master available use,issue,negative,positive,neutral,neutral,positive,positive
522202159,"@reuben Letter timings are generally late and it sounds like this may make them earlier, which should improve accuracy. I wrote a script to take the output from DeepSpeech 0.5.1 and split it into clips of up to 8 words (approximating a sentence) and found through trial and error that subtracting 0.1 seconds from the start point prevented it from getting cut off in almost all circumstances.

A big problem I have is testing features that require accurate models because master is often incompatible with the most recent release model and it’s infeasible for me to train a model from scratch every time a breaking change occurs. So I’m experimenting a lot with 0.5.1 but my ability to test certain features on 0.6 is limited.",letter generally late like may make improve accuracy wrote script take output split clip sentence found trial error start point getting cut almost big problem testing require accurate master often incompatible recent release model infeasible train model scratch every time breaking change lot ability test certain limited,issue,negative,positive,neutral,neutral,positive,positive
522201166,"I was going to do some more work on this but it looks like #2303 makes significant changes to this part of the code, so I guess I’ll wait for that to land first and then reimplement. #2303 looks like it will make it much simpler to achieve anyway.",going work like significant part code guess wait land first like make much simpler achieve anyway,issue,positive,positive,positive,positive,positive,positive
522048820,"Thank you for the fast answer. Re-exporting from the checkpoint with `--n_steps -1` does the job. Is there any advantage of the provided models having a fixed batch size?

One additional problem occurs when using a version newer than 0.4.1. Directly loading the model with the code posted in the initial comment (i.e. using `tf.import_graph_def(...)`) causes following error:

> ValueError: NodeDef mentions attr 'feature_win_len' not in Op<name=NoOp; signature= -> >; NodeDef: {{node deepspeech/model_metadata}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

Is there any possibility of using the fixed graph directly for inference only without being required to build the graph first?




",thank fast answer job advantage provided fixed batch size one additional problem version directly loading model code posted initial comment following error node check whether binary date possibility fixed graph directly inference without build graph first,issue,negative,positive,positive,positive,positive,positive
521951931,"@dabinat, since you did the work to expose timings in the API, maybe you have some tooling for checking/visualizing the impact of this change, or at least better intuition on timing quality?",since work expose maybe tooling impact change least better intuition timing quality,issue,negative,positive,neutral,neutral,positive,positive
521951709,"OK, I think I've identified the problem, but it's hard to verify how my fix impacts the quality of the timings.

@malena1906 could you try out PR #2302 and see if it fixes the problem for you? Also, if you have any other inputs that had this problem and could try them as well, I'd appreciate it!",think problem hard verify fix quality could try see problem also problem could try well appreciate,issue,negative,negative,negative,negative,negative,negative
521916477,"> Thanks now this works. Creation of virtual env solved version issues.
> How do I custom train? Accuracy needs to be increased.

There are plenty of docs covering that aspect, as well as threads on Discourse. Since there is indeed no bug here, i'll close that issue.",thanks work creation virtual version custom train accuracy need plenty covering aspect well discourse since indeed bug close issue,issue,positive,positive,positive,positive,positive,positive
521913826,"Thanks now this works. Creation of virtual env  solved version issues.
How do I custom train? Accuracy needs to be increased.",thanks work creation virtual version custom train accuracy need,issue,positive,positive,positive,positive,positive,positive
521891889,"> So, `v0.6.0` seems to be completely breaking compatibility, yes?

Yes, that's why it's a 0.6 and not 0.5.2 :)",completely breaking compatibility yes yes,issue,positive,positive,neutral,neutral,positive,positive
521891344,"> I saw it stopped loading at file TRAVEL1000_0443.wav, but I didn't know what was wrong with it. It is as same as format with others

Well, TensorFlow seems to disagree ... Remove that file from your dataset ?",saw stopped loading file know wrong format well disagree remove file,issue,negative,negative,negative,negative,negative,negative
521884896,"You'll have to re-export from the checkpoint with `--n_steps -1`, take a look at evaluate.py to see how the graph can then be used.

> On 15 Aug 2019, at 21:49, MikeLevene283 <notifications@github.com> wrote:
> 
> With the first DeepSpeech release v0.1.0 it was possible to directly access the trained model (output_graph.pb) for inference with a few lines of code (e.g. something along these lines
> graph = tf.get_default_graph() tf.import_graph_def(graph_def, name=""deepspeech"") input_node = graph.get_tensor_by_name('deepspeech/input_node:0') input_lengths = graph.get_tensor_by_name('deepspeech/input_lengths:0') output = graph.get_tensor_by_name('deepspeech/logits:0')
> 
> For newer versions (e.g. v0.4.0) however this seems to be not possible anymore as the input_node has a fixed dimension (i.e. (1, 16, 19, 26)) compared to the dynamic size in v0.1.0 (i.e. (?,?,494)) which allowed to pass the entire sequence as one batch. How can one directly use the trained models for sequences of arbitrary length?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",take look see graph used wrote first release possible directly access trained model inference code something along graph output however possible fixed dimension dynamic size pas entire sequence one batch one directly use trained arbitrary length thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
521860480,"@lissyx Yeah, I also thought like that. I tried printing to make sure it can load and read the wav files 

```
I Initializing variables...
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000       /home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent302-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4641.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4968.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent311-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent056-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent166-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent225-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4874.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent288-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent056-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent060-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent282-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent060-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent225-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent288-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4873.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4908.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent166-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4769.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4868.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4672.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent201-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent283-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4713.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent279-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4684.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent201-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4988.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4696.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4751.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4850.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_0394.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/precedent130/wav/PRECEDENT130_070.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4622.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent173-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent202-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4849.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0558.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4626.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4693.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4857.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4878.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0456.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0034.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent159-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_1200.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0637.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/loanword128/wav/LOANWORD128_076.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent045-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4958.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0992.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4692.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4679.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_2549.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4950.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0101.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4737.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/loanword128/wav/LOANWORD128_106.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0553.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent119-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_0146.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0374.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0689.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0862.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/loanword128/wav/LOANWORD128_055.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4756.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent277-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_3290.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0396.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0952.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0821.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4989.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/loanword128/wav/LOANWORD128_078.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent045-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0413.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_3150.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent167-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0507.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4858.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0157.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4867.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4995.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0612.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent221-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4762.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0868.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0794.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4636.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0927.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent172-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2462.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4893.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0550.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0310.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0082.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0071.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0052.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0892.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0745.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0934.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4656.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4629.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0061.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0473.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0772.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent097-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0264.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent186-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0991.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_1610.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0774.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0234.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_1000.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent055-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0579.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0436.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0428.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0063.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4275.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0371.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent002-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent078-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0461.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent029-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2743.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0750.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2571.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0626.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0259.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0073.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2115.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0732.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0865.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4886.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0496.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent246-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0795.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0454.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0607.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0679.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent113-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0654.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4991.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2400.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2410.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0905.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4623.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_2813.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4994.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0649.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent202-phrase2.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_1258.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0467.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_2190.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0185.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/japanese-single-speaker-speech-dataset/wav/meian_6063.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4934.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/utparaphrase512/wav/UT-PARAPHRASE-sent126-phrase1.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_1352.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0372.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_0263.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0877.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_1536.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_4877.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0547.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_1140.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/basic5000/wav/BASIC5000_1251.wav
/home/trieulv/work/deepspeech_mozilla/japanese_data/jsut_ver1.1/travel1000/wav/TRAVEL1000_0443.wav
Traceback (most recent call last):
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Bad audio format for WAV: Expected 1 (PCM), but got3
	 [[{{node DecodeWav}}]]
	 [[tower_0/IteratorGetNext]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 894, in <module>
    tfv1.app.run(main)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 878, in main
    train()
  File ""DeepSpeech.py"", line 599, in train
    train_loss, _ = run_set('train', epoch, train_init_op)
  File ""DeepSpeech.py"", line 567, in run_set
    feed_dict=feed_dict)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/home/trieulv/work/deepspeech_mozilla/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Bad audio format for WAV: Expected 1 (PCM), but got3
	 [[{{node DecodeWav}}]]
	 [[tower_0/IteratorGetNext]]
```

I saw it stopped loading at file TRAVEL1000_0443.wav, but I didn't know what was wrong with it. It is as same as format with others
",yeah also thought like tried printing make sure load read starting optimization epoch training time loss recent call last file line return file line file line bad audio format got node handling exception another exception recent call last file line module main file line run file line run main file line main file line main train file line train epoch file line file line run file line file line file line raise type message bad audio format got node saw stopped loading file know wrong format,issue,negative,negative,neutral,neutral,negative,negative
521803859,"EDIT: @reuben addresses this problem on Discourse here: https://discourse.mozilla.org/t/error-on-loading-0-5-1-checkpoints-with-current-master-deepspeech-codebase/43585

------------------------------------------------------------------------------------------------------------
Original post:


@kdavis-mozilla --- the solution discussed here is to downgrade the DeepSpeech to `v0.5.1`

However, is there a solution to re-export checkpoints from a trained `v0.5.1` model using `v0.6.0` code, resulting in a `v0.6.0` model?

We're trying this now, but exporting breaks with the same error as above, specifically:

```
tensorflow.python.framework.errors_impl.NotFoundError: Key cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias not found in checkpoint
```

Also, downgrading tensorflow to `1.13.1`, with deepspeech `v0.6.0` breaks as well, with the same error.

So, `v0.6.0` seems to be completely breaking compatibility, yes?",edit problem discourse original post solution downgrade however solution trained model code resulting model trying error specifically key found also well error completely breaking compatibility yes,issue,negative,positive,positive,positive,positive,positive
521798982,Might be wrong but seems the 0.5.1 was trained with some extra data set missing and will be corrected in 0.6.0,might wrong trained extra data set missing corrected,issue,negative,negative,negative,negative,negative,negative
521618623,@wegamekinglc I haven't tried it yet. Now i am training based on `Pinyin`. ,tried yet training based,issue,negative,neutral,neutral,neutral,neutral,neutral
521608113,"Yes, I am using [this](https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md) procedure and Mozilla's tensorflow. Let me see with the flags that you suggested. Thanks.",yes procedure let see thanks,issue,positive,positive,positive,positive,positive,positive
521604741,"> Ah, I followed those instructions. I am able to compile at least few files so far. The following error is common it seems. Any idea?

Yes, that's inconcistent with your link, again. Bazel will refuse building against headers it does not knows about for reproductibility. So you are likely missing something somewhere. This can be tricky. That's why I suggest relying on our tested aarch64 cross-compilation, I can't debug other's infras.",ah able compile least far following error common idea yes link refuse building likely missing something somewhere tricky suggest tested ca,issue,negative,negative,neutral,neutral,negative,negative
521603884,"> I don't see any other extra configuration specific to CUDA. I following [this](https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/) and I moved a bit further. Now, at least the compilation started and but getting failed in the middle. Here is the error.
> 
> `WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior. INFO: Analysed 2 targets (0 packages loaded, 0 targets configured). INFO: Found 2 targets... ERROR: /home/essence/tensorflow/native_client/BUILD:150:1: undeclared inclusion(s) in rule '//native_client:generate_trie': this rule is missing dependency declarations for the following files included by 'native_client/generate_trie.cpp': '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stddef.h' '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stdarg.h' '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stdint.h' '/usr/lib/gcc/aarch64-linux-gnu/4.8/include-fixed/limits.h' '/usr/lib/gcc/aarch64-linux-gnu/4.8/include-fixed/syslimits.h' INFO: Elapsed time: 7.372s, Critical Path: 6.32s INFO: 0 processes. FAILED: Build did NOT complete successfully`

That error does not match your link: yours refers to GCC 4.8 while the link documents GCC 5.5.

You might want to have a look at https://github.com/mozilla/tensorflow/blob/r1.14/.bazelrc#L76-L81 and re-use similar flags to perform Aarch64 cross-compilation.",see extra configuration specific following bit least compilation getting middle error warning following expanded repeatable twice may lead unexpected behavior loaded found error undeclared inclusion rule rule missing dependency following included time critical path build complete successfully error match link link might want look similar perform,issue,negative,positive,neutral,neutral,positive,positive
521602743,"> I don't see any other extra configuration specific to CUDA

You need to read upstream documentation on building with CUDA. Setup CUDA 10.0, pass TF_* variables at configure time, etc.",see extra configuration specific need read upstream documentation building setup pas configure time,issue,negative,neutral,neutral,neutral,neutral,neutral
521602387,"I don't see any other extra configuration specific to CUDA. I following [this](https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/) and I moved a bit further. Now, at least the compilation started and but getting failed in the middle. Here is the error.

`WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Analysed 2 targets (0 packages loaded, 0 targets configured).
INFO: Found 2 targets...
ERROR: /home/essence/tensorflow/native_client/BUILD:150:1: undeclared inclusion(s) in rule '//native_client:generate_trie':
this rule is missing dependency declarations for the following files included by 'native_client/generate_trie.cpp':
  '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stddef.h'
  '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stdarg.h'
  '/usr/lib/gcc/aarch64-linux-gnu/4.8/include/stdint.h'
  '/usr/lib/gcc/aarch64-linux-gnu/4.8/include-fixed/limits.h'
  '/usr/lib/gcc/aarch64-linux-gnu/4.8/include-fixed/syslimits.h'
INFO: Elapsed time: 7.372s, Critical Path: 6.32s
INFO: 0 processes.
FAILED: Build did NOT complete successfully`",see extra configuration specific following bit least compilation getting middle error warning following expanded repeatable twice may lead unexpected behavior loaded found error undeclared inclusion rule rule missing dependency following included time critical path build complete successfully,issue,negative,positive,neutral,neutral,positive,positive
521601174,"> I just added `--config=cuda `while configuring. Are there any other steps?

Yes, please refer to upstream for configuration steps.",added yes please refer upstream configuration,issue,positive,neutral,neutral,neutral,neutral,neutral
521568628,@TrieuLe0801 So you have a bogus file in your dataset ? You need to find which one.,bogus file need find one,issue,negative,neutral,neutral,neutral,neutral,neutral
521399247,"@kdavis-mozilla @lissyx I am consistently getting this error when building deepspeech on Jetson Nano. Any hints on how to resolve this? 

I am running
```
bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic --config=cuda -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie
```

I am getting
```
INFO: An error occurred during the fetch of repository 'local_config_cuda'
INFO: Call stack for the definition of repository 'local_config_cuda':
 - /home/essence/tensorflow/tensorflow/workspace.bzl:63:5
 - /home/essence/tensorflow/WORKSPACE:94:1
INFO: Repository 'local_config_cuda' used the following cache hits instead of downloading the corresponding file.
 * Hash '85a24f215737af91e0054d3a1cb435bd8ff06178cef14241c029c8a04ff16a79' for https://commondatastorage.googleapis.com/chromium-browser-clang/Linux_x64/clang-348507-1.tgz
If the definition of 'local_config_cuda' was updated, verify that the hashes were also updated.
ERROR: Skipping '//native_client:libdeepspeech.so': error loading package 'native_client': in /root/.cache/bazel/_bazel_root/36a71d6396a743d4c0feae555af85c88/external/org_tensorflow/tensorflow/tensorflow.bzl: Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
```

Attached are the tensorflow configure log and complete error log. I am using r1.14 version of yours. 

[configure-log.txt](https://github.com/mozilla/DeepSpeech/files/3503146/configure-log.txt)
[complete-error-log.txt](https://github.com/mozilla/DeepSpeech/files/3503155/complete-error-log.txt)
",consistently getting error building resolve running build bash opt getting error fetch repository call stack definition repository repository used following cache instead corresponding file hash definition verify also error skipping error loading package error reading extension file package recent call last attached configure log complete error log version,issue,negative,positive,neutral,neutral,positive,positive
521331606,"My last comment may have been ambiguous: I committed those changes and they're available for review. But I'm in no rush for feedback, I just wanted to make sure that was clear.",last comment may ambiguous available review rush feedback make sure clear,issue,positive,positive,positive,positive,positive,positive
521294356,"That worked!
`git checkout -b v0.5.1`
Successfully restored checkpoint and now continuing training the model
Sorry for the misunderstanding and thank you very much for your help!",worked git successfully training model sorry misunderstanding thank much help,issue,positive,positive,positive,positive,positive,positive
521290620,"> we are using deepspeech 0.5.1.
> 
> pip3 install 'deepspeech == 0.5.1'
> 
> and removed alpha build

You are mixing everything. This is not for training, this is for inference. Please ensure `git checkout v0.5.1` in your git clone before running `python DeepSpeech.py`",pip install removed alpha build everything training inference please ensure git git clone running python,issue,positive,neutral,neutral,neutral,neutral,neutral
521289943,"we are using deepspeech 0.5.1. 

pip3 install 'deepspeech == 0.5.1' 

and removed alpha build",pip install removed alpha build,issue,negative,neutral,neutral,neutral,neutral,neutral
521279808,"Missed that detail about Tensorflow 1.13.1. Got that installed and removed old version now i have this error:

```
python3 DeepSpeech.py --checkpoint_dir /home/shop/Downloads/deepspeech-0.5.1-checkpoint/ --trie /home/shop/deepspeech-0.5.1-models/trie --lm_binary_dir /home/shop/deepspeech-0.5.1-models/lm.binary --train_files /home/shop/Downloads/en/clips/train.csv --test_files /home/shop/Downloads/en/clips/test.csv --dev_files /home/shop/Downloads/en/clips/dev.csv --summary_dir /home/shop/DeepSpeech/summary/ --train_batch_size 24 --dev_batch_size 48 --test_batch_size 48 --n_hidden 2048 --learning_rate .0001 --dropout_rate 0.15 --epoch 1 --lm_alpha 0.75 --lm_beta 1.85 --export_dir /home/shop/DeepSpeech/new/new

WARNING:tensorflow:From /home/shop/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 844, in <module>
    tfv1.app.run(main)
  File ""/home/shop/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""DeepSpeech.py"", line 828, in main
    train()
  File ""DeepSpeech.py"", line 411, in train
    iterator = tfv1.data.Iterator.from_structure(tfv1.data.get_output_types(train_set),
AttributeError: module 'tensorflow._api.v1.compat.v1.data' has no attribute 'get_output_types'
```

Also tried different numpy versions 1.13.3 and 1.15.4. Any ideas? Thanks!",detail got removed old version error python epoch warning removed future version instead use python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape recent call last file line module main file line run main file line main train file line train module attribute also tried different thanks,issue,positive,positive,positive,positive,positive,positive
521275132,"What can I do about this failing build? I guess it fails because it is pull request to a branch different than master and it somehow produces error, am I right? So it is not caused by my changes.",failing build guess pull request branch different master somehow error right,issue,negative,positive,positive,positive,positive,positive
521191731,"It appears you are training an existing model using Deep speech 0.5.1.

Training with Deep speech 0.5.1. requires Tensorflow 1.13.1, see the 0.5.1 [README](https://github.com/mozilla/DeepSpeech/tree/v0.5.1#recommendations), not Tensorflow 1.14.0 which it appears that you are using.",training model deep speech training deep speech see,issue,negative,neutral,neutral,neutral,neutral,neutral
520749088,"Shall I reopen the new issue, with the corrected name ?
",shall reopen new issue corrected name,issue,negative,positive,positive,positive,positive,positive
520576843,Okay. I will try my luck on this because the deepspeech model on Pi3 is dog slow it seems. It is taking almost a minute for sentence of few words. Will let you know if I succeed. Thanks man for the suggestions.  ,try luck model pi dog slow taking almost minute sentence let know succeed thanks man,issue,positive,negative,neutral,neutral,negative,negative
520574046,"> Do you mean you cannot upload for Jetson NANO? You guys already have support for Pi3 right? I am now trying to run deepspeech on RPi3.

Yes, but the upload is not done to the pypi repo, but to one that is enabled by default on Raspbian.

I don't know if a similar setup is done on the system running on the jetson nano.",mean already support pi right trying run yes done one default know similar setup done system running,issue,positive,negative,neutral,neutral,negative,negative
520563853,Do you mean you cannot upload for Jetson NANO? You guys already have support for Pi3 right? I am now trying to run deepspeech on RPi3. ,mean already support pi right trying run,issue,negative,negative,neutral,neutral,negative,negative
520562966,"Sad, no hint. To give context, we cannot upload aarch64 wheels for rpi3 to pypi because of lack of proper ABI definition. So even if we get all the CI in place to build aarch64 cuda, I'm unsure we could host them for pypi. ",sad hint give context lack proper definition even get place build unsure could host,issue,negative,negative,negative,negative,negative,negative
520518915,"Given the situation on armv7 / aarch64 for pip wheels, I'm curious to see `pip install --verbose deepspeech` @mdasari823 ",given situation pip curious see pip install verbose,issue,negative,negative,neutral,neutral,negative,negative
520499586,Thank you @kdavis-mozilla. I will give it a shot. I will get back here if I can make it. Thanks.  ,thank give shot get back make thanks,issue,positive,positive,neutral,neutral,positive,positive
520498645,"The supported platforms are indicated in the [0.5.1 Release Notes](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1). Unfortunately, the Jetson NANO is not on the list.

However, that said Jetson NANO is an interesting target platform, and we'd be interested in any progress you make on a port.",release unfortunately list however said interesting target platform interested progress make port,issue,positive,positive,neutral,neutral,positive,positive
520496364,@khsinclair thanks for the tips. I'll try to implement and evaluate this masking on the MFCC-features domain and post it here ASAP.,thanks try implement evaluate domain post,issue,negative,positive,positive,positive,positive,positive
520492980,"Aah, I am not sure. I am using Jetson NANO devkit. I don't see any specific supported platforms in the instructions either. So if this is the reason, the only way to do this I assume is that I have to follow [this](https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md) procedure?",sure see specific either reason way assume follow procedure,issue,negative,positive,positive,positive,positive,positive
520456987,It would be good to get this merged with the spelling mistake corrected as soon as poss,would good get spelling mistake corrected soon po,issue,negative,positive,positive,positive,positive,positive
519930177,"We've been using similar augmentation to train both Mozilla DeepSpeech and Baidu DeepSpeech 2, and have learned a few things.  Our task is quite different: we're retraining the 0.5.1 model with 2000 hours of noisy conversational English, with a baseline WER around 50%.  With Mozilla DeepSpeech, masking in the MFCC domain seems to work better than masking the spectrograms.

The DeepSpeech 2 network input is normalized log-valued linear-frequency spectrograms, and we use essentially the SpecAugment masking policies, and we see the same effect described in the google paper of higher training loss producing lower validation loss, postponing overtraining.  Accuracy on 4 and 15 hour test sets improves from 31% to 29% WER with this augmentation.

Mozilla DeepSpeech network input is non-normalized MFCC coefficients, which I believe includes c0.  We tried a number of policies applying SpecAugment masking to the mel-frequency magnitude or log-valued spectrograms, before the MFCC transform, and never got any consistent accuracy gain.  We tried masking with zeros, with mean values, with noise energy at various SNRs.

What does seem to help is augmentation in the MFCC domain.  Here, we just randomly truncate the input, setting higher-order coefficients to zero.  So the SpecAugment ""F"" mask is interpreted as ""zero every coefficient above random(8,26) for every frame in the utterance"".  ""T"" mask just sets to zero, but aggressive T masking policy doesn't work as well as in the Baidu system.

With this MFCC-domain masking augmentation, accuracy improves from 37.5% to 36% WER.  That's actually good enough for now, though we want to do better next year.

It's not clear to me why DeepSpeech is using MFCC input, I would think normalized log-valued mel-frequency spectrograms would provide better information.  Maybe we'll try that sometime.
",similar augmentation train learned task quite different model noisy conversational wer around domain work better network input use essentially see effect paper higher training loss lower validation loss accuracy hour test wer augmentation network input believe tried number magnitude transform never got consistent accuracy gain tried mean noise energy various seem help augmentation domain randomly truncate input setting zero mask zero every coefficient random every frame utterance mask zero aggressive policy work well system augmentation accuracy wer actually good enough though want better next year clear input would think would provide better information maybe try sometime,issue,positive,positive,neutral,neutral,positive,positive
519908360,"Create a new virtual environment and install deep speech
```
 pip install --upgrade deepspeech==0.5.1
```",create new virtual environment install deep speech pip install upgrade,issue,negative,positive,neutral,neutral,positive,positive
519906637,Hi - what needs to be done?  Please send link for correct binaries version which are compatible.,hi need done please send link correct version compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
519899008,"Yeah, it seems that is indeed where the problem is coming from, but I don't yet fully understand the cause here. I'll take a deeper look.",yeah indeed problem coming yet fully understand cause take look,issue,negative,neutral,neutral,neutral,neutral,neutral
519884741,(Or checkout v0.5.1 and train using that version of the training code).,train version training code,issue,negative,neutral,neutral,neutral,neutral,neutral
519884682,You're training a model on master and then trying to use it with a 0.5.1 client (installed via pip3 install deepspeech-gpu). You need to install the 0.6.0-alpha.4 version of that package.,training model master trying use client via pip install need install version package,issue,negative,neutral,neutral,neutral,neutral,neutral
519865116,@malena1906 That analysis does not look wrong. Maybe we should check timestamp does increase in this `if` branch you are mentionning ?,analysis look wrong maybe check increase branch,issue,negative,negative,negative,negative,negative,negative
519570198,That happens when loading an older pbmm with a newer client. You're probably using one of the 0.6 alphas?,loading older client probably one,issue,negative,positive,positive,positive,positive,positive
519540017,"Your error mentions model version 0, that's weird. ",error model version weird,issue,negative,negative,negative,negative,negative,negative
519525964,"Yes....
Pre-trained models
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
tar xvfz deepspeech-0.5.1-models.tar.gz

Log also says..
Loading model from file models/output_graph.pbmm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78

Thanks",yes tar log also loading model file thanks,issue,positive,positive,positive,positive,positive,positive
519497772,"Kindly help with below. What needs to be done for compatibility issues?

Model compatibility
DeepSpeech models are versioned to keep you from trying to use an incompatible graph with a newer client after a breaking change was made to the code. If you get an error saying your model file version is too old for the client, you should either upgrade to a newer model release, re-export your model from the checkpoint using a newer version of the code, or downgrade your client if you need to use the old model and can't re-export it.",kindly help need done compatibility model compatibility keep trying use incompatible graph client breaking change made code get error saying model file version old client either upgrade model release model version code downgrade client need use old model ca,issue,negative,positive,positive,positive,positive,positive
519427729,"Yeah. I'll close this, and I can make a PR to update the readme later.",yeah close make update later,issue,negative,neutral,neutral,neutral,neutral,neutral
519423603,"> > OK. Thanks for the help. Maybe someone could update the readme sometime.
> 
> PRs are welcome.

Because, as you can see, we cannot test all and possible combinations of node versions. Out of luck, we used 10.12.0 release of NodeJS to build the v0.5.1 package, and this included the `v8::Isolate` symbol.",thanks help maybe someone could update sometime welcome see test possible node luck used release build package included symbol,issue,positive,positive,positive,positive,positive,positive
519421843,"> OK. Thanks for the help. Maybe someone could update the readme sometime.

PRs are welcome.",thanks help maybe someone could update sometime welcome,issue,positive,positive,positive,positive,positive,positive
519421616,OK. Thanks for the help. Maybe someone could update the readme sometime.,thanks help maybe someone could update sometime,issue,positive,positive,positive,positive,positive,positive
519421526,@nmrugg So i'm going to close this and go back to my holidays.,going close go back,issue,negative,neutral,neutral,neutral,neutral,neutral
519419404,"Right, it looks like this might just be upstream issue ?
```
$ objdump -tTC node-v10.1.0-linux-x64/bin/node | grep 'v8::String::Utf8Length'
0000000000a49c20 g     F .text  0000000000000046              v8::String::Utf8Length() const
0000000000a49c20 g    DF .text  0000000000000046  Base        v8::String::Utf8Length() const
$ objdump -tTC node-v10.16.2-linux-x64/bin/node | grep 'v8::String::Utf8Length'
0000000000b0ab50 g     F .text  000000000000031e              v8::String::Utf8Length() const
0000000000b0ae70 g     F .text  000000000000000a              v8::String::Utf8Length(v8::Isolate*) const
0000000000b0ab50 g    DF .text  000000000000031e  Base        v8::String::Utf8Length() const
0000000000b0ae70 g    DF .text  000000000000000a  Base        v8::String::Utf8Length(v8::Isolate*) const

```

",right like might upstream issue base bae base bae base,issue,negative,negative,negative,negative,negative,negative
519418604,"@nmrugg Can you check with `objdump` on your 10.1.0 setup?
```
$ objdump -tTC /usr/bin/node | grep 'v8::String::Utf8Length'
0000000000b0ab50 g     F .text  000000000000031e              v8::String::Utf8Length() const
0000000000b0ae70 g     F .text  000000000000000a              v8::String::Utf8Length(v8::Isolate*) const
0000000000b0ab50 g    DF .text  000000000000031e  Base        v8::String::Utf8Length() const
0000000000b0ae70 g    DF .text  000000000000000a  Base        v8::String::Utf8Length(v8::Isolate*) const
```",check setup bae base bae base,issue,negative,negative,negative,negative,negative,negative
519417189,"> I downloaded them from here:
> https://nodejs.org/dist/v10.1.0/node-v10.1.0-linux-x64.tar.xz
> https://nodejs.org/dist/v10.4.0/node-v10.4.0-linux-x64.tar.xz

Thanks. This should have worked, since we test against those.

Do you reproduce the issue with latest v64, i.e Node.js 10.16.2 ?",thanks worked since test reproduce issue latest,issue,negative,positive,positive,positive,positive,positive
519416032,"> Those are just the versions that I tested and that failed. I had those on my system already. I just tried a few different versions. Those ones didn't work.

Could you please answer the question ? Where does those came from ?",tested system already tried different work could please answer question came,issue,negative,neutral,neutral,neutral,neutral,neutral
519414904,Those are just the versions that I tested and that failed. I had those on my system already. I just tried a few different versions. Those ones didn't work.,tested system already tried different work,issue,negative,neutral,neutral,neutral,neutral,neutral
519407315,"Sorry, I didn't indent this to grow like this.

* Linux Ubuntu 16.04
* Node v10.1.0 or v10.4.0
* Python 2.7.12

I get that error when I run:

```
node client.js --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --lm deepspeech-0.5.1-models/lm.binary --audio test.wav
```

Anything else?",sorry indent grow like node python get error run node model alphabet audio anything else,issue,negative,negative,negative,negative,negative,negative
519406448,@nmrugg You still have not even shared a bit of information on your system. Are we supposed to do divination ? We have a template that is to be filled.,still even bit information system supposed divination template filled,issue,negative,positive,positive,positive,positive,positive
519403737,"It would have been useful that you first reported this error, this would have saved a lot of time to people. Are you using nodesource packages or something else? ",would useful first error would saved lot time people something else,issue,negative,positive,positive,positive,positive,positive
519400212,"Ah, OK. Hmm, maybe it's just certain versions that don't work.

I tried v10.1.0 and v10.4.0, and both gave me the same error:

```
node: symbol lookup error: deepspeech/lib/binding/v0.5.1/linux-x64/node-v64/deepspeech.node: undefined symbol: _ZNK2v86String10Utf8LengthEPNS_7IsolateE
```

But, I just tried v12.4.0, and it works. Maybe something is wrong with the 64 binary.",ah maybe certain work tried gave error node symbol error undefined symbol tried work maybe something wrong binary,issue,negative,negative,negative,negative,negative,negative
519385938,"Interesting.

First off, the readme file says `Please note that as of now, we only support Node.JS versions 4, 5 and 6.`.

Also, in that file list, the highest number I see is `node-v72`, which I assume is 7.2.",interesting first file please note support also file list highest number see assume,issue,positive,positive,positive,positive,positive,positive
519279752,"Great suggestion! While I'm working on that, I'd love to give the same treatment to alphabet errors, which I've also run into with my experiments. My approach makes `text_to_char_array` look like:

```python
def text_to_char_array(series, alphabet):
    r""""""
    Given a Pandas Series containing transcript string, map characters to
    integers and return a numpy array representing the processed string.
    """"""
    try:
        series['transcript'] = np.asarray([alphabet.label_from_string(c) for c in series['transcript']])
    except KeyError as e:
        # Provide the row context (especially wav_filename) for alphabet errors
        raise ValueError(str(e), series)

    if series['transcript'].shape[0] == 0:
        raise ValueError(""Found an empty transcript! You must include a transcript for all training data."", series)

    return series
```

Please let me know if you see problems with this idea",great suggestion working love give treatment alphabet also run approach look like python series alphabet given series transcript string map return array try series series except provide row context especially alphabet raise series series raise found empty transcript must include transcript training data series return series please let know see idea,issue,positive,positive,positive,positive,positive,positive
519077683,@reuben Sorry reuben. That's my fault. I just changed the value but not recompiled the client. ,sorry fault value client,issue,negative,negative,negative,negative,negative,negative
519067841,"> I tried what you suggest and it seems that the inference time does not change at all.

That is weird. Are you sure you properly recompiled the client with the change?",tried suggest inference time change weird sure properly client change,issue,negative,neutral,neutral,neutral,neutral,neutral
519039846,"```
alex@portable-alex:~/tmp/deepspeech$ wget https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0-alpha.4/deepspeech-0.6.0-alpha.4.tgz
--2019-08-07 12:29:34--  https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0-alpha.4/deepspeech-0.6.0-alpha.4.tgz
Résolution de github.com (github.com)… 140.82.118.4                                                                    
Connexion à github.com (github.com)|140.82.118.4|:443… connecté.                                                       
requête HTTP transmise, en attente de la réponse… 302 Found                                                            
Emplacement : https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/e00aa600-a4de-11e9-8868-c97b00e675d0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190807T102935Z&X-Amz-Expires=300&X-Amz-Signature=a20d1c382ee07e994f7e23dd5bd70dfc93a8d34e37a0a686a7737c27383c9a81&X-Amz-SignedHe
aders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.6.0-alpha.4.tgz&response-content-type=application%2Foctet-stream [suivant]
--2019-08-07 12:29:35--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/e00aa600-a4de-11e9-8868-c97b00e675d0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190807%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190807T102935Z&X-Amz-Expires=300&X-Amz-Signature=a20d1c382ee07e994f7e23dd5bd70dfc93a8d34e37a0a686a7737c27383c9a81&X-A
mz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.6.0-alpha.4.tgz&response-content-type=application%2Foctet-stream
Résolution de github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)… 52.216.109.195
Connexion à github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.109.195|:443… connecté.
requête HTTP transmise, en attente de la réponse… 200 OK                                                                  
Taille : 53501797 (51M) [application/octet-stream]                                                                        
Enregistre : «deepspeech-0.6.0-alpha.4.tgz»                                                                               
                                                                                                                          
deepspeech-0.6.0-alpha.4.tgz                                                                   100%[===================================================================================================================================================================================================================================================>]  51,02M  3,18MB/s    ds 16s
                                                                                                                          
2019-08-07 12:29:52 (3,24 MB/s) - «deepspeech-0.6.0-alpha.4.tgz» enregistré [53501797/53501797]   
alex@portable-alex:~/tmp/deepspeech$ tar tvf deepspeech-0.6.0-alpha.4.tgz 
-rw-r--r-- 102/65534      1318 2019-07-12 19:51 package/package.json
-rw-r--r-- 102/65534     24595 2019-07-12 19:51 package/README.md
-rw-r--r-- 102/65534      4913 2019-07-12 19:50 package/client.js
-rw-r--r-- 102/65534      2647 2019-07-12 19:50 package/index.js
-rwxr-xr-x 102/65534  48517496 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/libdeepspeech.so
-rwxr-xr-x 102/65534     57284 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v1.6/deepspeech.node
-rwxr-xr-x 102/65534     57204 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v1.8/deepspeech.node
-rwxr-xr-x 102/65534     57204 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v2.0/deepspeech.node
-rwxr-xr-x 102/65534     57316 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v3.0/deepspeech.node
-rwxr-xr-x 102/65534     57316 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v3.1/deepspeech.node
-rwxr-xr-x 102/65534     57468 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v4.0/deepspeech.node
-rwxr-xr-x 102/65534     57468 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v4.1/deepspeech.node
-rwxr-xr-x 102/65534     57468 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v4.2/deepspeech.node
-rwxr-xr-x 102/65534     58028 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v5.0/deepspeech.node
-rwxr-xr-x 102/65534     57284 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/electron-v1.7/deepspeech.node
-rwxr-xr-x 102/65534     56996 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v46/deepspeech.node
-rwxr-xr-x 102/65534     56996 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v47/deepspeech.node
-rwxr-xr-x 102/65534     57228 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v48/deepspeech.node
-rwxr-xr-x 102/65534     57276 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v51/deepspeech.node
-rwxr-xr-x 102/65534     57196 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v57/deepspeech.node
-rwxr-xr-x 102/65534     57308 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v59/deepspeech.node
-rwxr-xr-x 102/65534     58108 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v64/deepspeech.node
-rwxr-xr-x 102/65534     58140 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v67/deepspeech.node
-rwxr-xr-x 102/65534     58124 2019-07-12 19:48 package/lib/binding/v0.6.0-alpha.4/darwin-x64/node-v72/deepspeech.node
-rwxr-xr-x 102/65534  23426752 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/libdeepspeech.so
-rwxr-xr-x 102/65534     51452 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v1.6/deepspeech.node
-rwxr-xr-x 102/65534     51412 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v1.8/deepspeech.node
-rwxr-xr-x 102/65534     51412 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v2.0/deepspeech.node
-rwxr-xr-x 102/65534     51476 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v3.0/deepspeech.node
-rwxr-xr-x 102/65534     51476 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v3.1/deepspeech.node
-rwxr-xr-x 102/65534     51556 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v4.0/deepspeech.node
-rwxr-xr-x 102/65534     51556 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v4.1/deepspeech.node
-rwxr-xr-x 102/65534     51556 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v4.2/deepspeech.node
-rwxr-xr-x 102/65534     51696 2019-07-12 18:04 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v5.0/deepspeech.node
-rwxr-xr-x 102/65534     51452 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/electron-v1.7/deepspeech.node
-rwxr-xr-x 102/65534     52552 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v46/deepspeech.node
-rwxr-xr-x 102/65534     51304 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v47/deepspeech.node
-rwxr-xr-x 102/65534     51428 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v48/deepspeech.node
-rwxr-xr-x 102/65534     51452 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v51/deepspeech.node
-rwxr-xr-x 102/65534     51412 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v57/deepspeech.node
-rwxr-xr-x 102/65534     51472 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v59/deepspeech.node
-rwxr-xr-x 102/65534     51704 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v64/deepspeech.node
-rwxr-xr-x 102/65534     51724 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v67/deepspeech.node
-rwxr-xr-x 102/65534     51772 2019-07-12 18:03 package/lib/binding/v0.6.0-alpha.4/linux-arm/node-v72/deepspeech.node
-rwxr-xr-x 102/65534  32403248 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/libdeepspeech.so
-rwxr-xr-x 102/65534     62056 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v1.6/deepspeech.node
-rwxr-xr-x 102/65534     62016 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v1.8/deepspeech.node
-rwxr-xr-x 102/65534     62016 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v2.0/deepspeech.node
-rwxr-xr-x 102/65534     66176 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v3.0/deepspeech.node
-rwxr-xr-x 102/65534     66176 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v3.1/deepspeech.node
-rwxr-xr-x 102/65534     66256 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v4.0/deepspeech.node
-rwxr-xr-x 102/65534     66256 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v4.1/deepspeech.node
-rwxr-xr-x 102/65534     66256 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v4.2/deepspeech.node
-rwxr-xr-x 102/65534     66424 2019-07-12 18:00 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v5.0/deepspeech.node
-rwxr-xr-x 102/65534     62056 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/electron-v1.7/deepspeech.node
-rwxr-xr-x 102/65534     64600 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v46/deepspeech.node
-rwxr-xr-x 102/65534     61888 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v47/deepspeech.node
-rwxr-xr-x 102/65534     62032 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v48/deepspeech.node
-rwxr-xr-x 102/65534     62056 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v51/deepspeech.node
-rwxr-xr-x 102/65534     62160 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v57/deepspeech.node
-rwxr-xr-x 102/65534     66176 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v59/deepspeech.node
-rwxr-xr-x 102/65534     66424 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v64/deepspeech.node
-rwxr-xr-x 102/65534     66448 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v67/deepspeech.node
-rwxr-xr-x 102/65534     66472 2019-07-12 17:59 package/lib/binding/v0.6.0-alpha.4/linux-arm64/node-v72/deepspeech.node
-rwxr-xr-x 102/65534  37860680 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/libdeepspeech.so
-rwxr-xr-x 102/65534     64326 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v1.6/deepspeech.node
-rwxr-xr-x 102/65534     64286 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v1.8/deepspeech.node
-rwxr-xr-x 102/65534     64286 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v2.0/deepspeech.node
-rwxr-xr-x 102/65534     68339 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v3.0/deepspeech.node
-rwxr-xr-x 102/65534     68339 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v3.1/deepspeech.node
-rwxr-xr-x 102/65534     68419 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v4.0/deepspeech.node
-rwxr-xr-x 102/65534     68419 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v4.1/deepspeech.node
-rwxr-xr-x 102/65534     68419 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v4.2/deepspeech.node
-rwxr-xr-x 102/65534     68712 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v5.0/deepspeech.node
-rwxr-xr-x 102/65534     64326 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/electron-v1.7/deepspeech.node
-rwxr-xr-x 102/65534     64147 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v46/deepspeech.node
-rwxr-xr-x 102/65534     64171 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v47/deepspeech.node
-rwxr-xr-x 102/65534     64301 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v48/deepspeech.node
-rwxr-xr-x 102/65534     64326 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v51/deepspeech.node
-rwxr-xr-x 102/65534     64286 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v57/deepspeech.node
-rwxr-xr-x 102/65534     68444 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v59/deepspeech.node
-rwxr-xr-x 102/65534     68712 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v64/deepspeech.node
-rwxr-xr-x 102/65534     68732 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v67/deepspeech.node
-rwxr-xr-x 102/65534     68885 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/linux-x64/node-v72/deepspeech.node
-rwxr-xr-x 102/65534  26450432 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/libdeepspeech.so
-rwxr-xr-x 102/65534    174592 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v1.6/deepspeech.node
-rwxr-xr-x 102/65534    174080 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v1.8/deepspeech.node
-rwxr-xr-x 102/65534    174080 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v2.0/deepspeech.node
-rwxr-xr-x 102/65534    173568 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v3.0/deepspeech.node
-rwxr-xr-x 102/65534    173568 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v3.1/deepspeech.node
-rwxr-xr-x 102/65534    624128 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v4.0/deepspeech.node
-rwxr-xr-x 102/65534    624128 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v4.1/deepspeech.node
-rwxr-xr-x 102/65534    624128 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v4.2/deepspeech.node
-rwxr-xr-x 102/65534    625152 2019-07-12 18:08 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v5.0/deepspeech.node
-rwxr-xr-x 102/65534    174592 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/electron-v1.7/deepspeech.node
-rwxr-xr-x 102/65534    176640 2019-07-12 18:06 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v46/deepspeech.node
-rwxr-xr-x 102/65534    176640 2019-07-12 18:06 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v47/deepspeech.node
-rwxr-xr-x 102/65534    178176 2019-07-12 18:06 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v48/deepspeech.node
-rwxr-xr-x 102/65534    178176 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v51/deepspeech.node
-rwxr-xr-x 102/65534    178176 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v57/deepspeech.node
-rwxr-xr-x 102/65534    177152 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v59/deepspeech.node
-rwxr-xr-x 102/65534    625152 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v64/deepspeech.node
-rwxr-xr-x 102/65534    625152 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v67/deepspeech.node
-rwxr-xr-x 102/65534    625664 2019-07-12 18:07 package/lib/binding/v0.6.0-alpha.4/win32-x64/node-v72/deepspeech.node
```",de connexion en de la found emplacement de connexion en de la taille tar,issue,negative,neutral,neutral,neutral,neutral,neutral
519039010,"@nmrugg We also have support for ElectronJS.

You can see the versions we build against at https://github.com/mozilla/DeepSpeech/blob/master/taskcluster/tc-tests-utils.sh#L59-L60",also support see build,issue,negative,neutral,neutral,neutral,neutral,neutral
519036434,"> Now that [SWIG supports Node 2-10](https://sourceforge.net/p/swig/news/2019/04/swig-400-released/), can more node binaries be added?

I don't understand the request. We already have support for NodeJS 4.x to 12.x",swig node node added understand request already support,issue,negative,neutral,neutral,neutral,neutral,neutral
519006110,@reuben thank you reuben. I tried what you suggest and it seems that the inference time does not change at all. In the next step i would like to try use phoneme to train and intent to reduce the alphabet size.,thank tried suggest inference time change next step would like try use phoneme train intent reduce alphabet size,issue,positive,neutral,neutral,neutral,neutral,neutral
518996976,"Oh, and please revert to 2 spaces for indentation, it's what we use in all (most?) of our C++ code.",oh please revert indentation use code,issue,negative,neutral,neutral,neutral,neutral,neutral
518988029,"Try setting `cutoff_prob` in `StreamingState::processBatch` to a value less than 1. Something like 0.98. It should improve decoding performance significantly, specially for large alphabets.",try setting value le something like improve performance significantly specially large,issue,positive,positive,positive,positive,positive,positive
518984735,@chungyeh It seems that it took me about 926.603s inference time for 9s audio file. What about yours ? ,took inference time audio file,issue,negative,neutral,neutral,neutral,neutral,neutral
518980766,"@kdavis-mozilla i think you are correct. 

```
2019-08-07 07:25:31.587818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-07 07:25:31.888516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-07 07:25:31.888545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-07 07:25:31.888551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-07 07:25:31.888635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10426 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-08-07 07:25:31.902141: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-08-07 07:25:31.902172: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-07 07:25:31.902181: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-07 07:25:31.902187: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
Loaded model in 0.403s.
Loading language model from files /home/thchs30_test/thchs30-lm.binary /home/thchs30_test/thchs30-trie
Loaded language model in 0.00249s.
Running inference.
2019-08-07 07:25:32.149073: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
北 京 丰 台 区 农 民 自 计 划 学 筹 办 万 佛 延 寿 似 迎 春 袅 会 欣 文 区 内 六 十 之 江 个 队 参 赛
Inference took 926.603s for 9.858s audio file.
```",think correct visible device interconnect strength edge matrix device memory physical device name ti bus id compute capability unknown unknown unknown unknown loaded model loading language model loaded language model running inference successfully library locally inference took audio file,issue,positive,positive,neutral,neutral,positive,positive
518971788,"@kdavis-mozilla thanks for reply. I noticed the message
`2019-08-07 06:35:08.868703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Ignoring visible gpu device (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2) with Cuda compute capability 5.2.The minimum required Cuda capability is 6.0.`

It seems that the GTX TITAN X capability less than 6 therefore the program use cpu to inference. ",thanks reply message visible device device name bus id compute capability compute capability minimum capability capability le therefore program use inference,issue,negative,positive,positive,positive,positive,positive
518970318,"This is likely a reflection of the size of your alphabet.

For Mandarin the alphabet size is usually around 5-8K, 150-250 times the size for English, which make the softmax layer much more computationally intensive which slows the inference down.",likely reflection size alphabet mandarin alphabet size usually around time size make layer much intensive slows inference,issue,negative,negative,neutral,neutral,negative,negative
518933120,"@chungyeh thanks chungyeh. It seems that the problem is `vocabulary.txt`. I noticed that in https://github.com/ailurus1991/ds_files/, the `thchs30-vocabulary.txt` starts wtih `AND`. 

<hr>
<img width=""977"" alt=""Screen Shot 2019-08-07 at 12 13 21 PM"" src=""https://user-images.githubusercontent.com/11624203/62594376-0c161d00-b90d-11e9-9328-2ea049d48048.png"">
<hr>

After i followed this format, i could succeed generated 45 kb trie files. And got the correct result. #2271 

```
-rwxrwxr-x 1 1005 1005  162766 Aug  6 14:36 thchs30-dev.csv
-rw-r--r-- 1 root root 1261235 Aug  7 03:31 thchs30-lm.binary
-rwxrwxr-x 1 1005 1005  453334 Aug  6 14:36 thchs30-test.csv
-rwxrwxr-x 1 1005 1005 1820244 Aug  6 12:22 thchs30-train.csv
-rw-r--r-- 1 root root   46223 Aug  7 03:32 thchs30-trie
-rw-r--r-- 1 root root 1600592 Aug  7 03:31 thchs30-words.arpa
-rwxrwxr-x 1 1005 1005   11532 Aug  5 08:11 thchs30_alphabet.txt
-rwxrwxr-x 1 1005 1005  130496 Aug  7 03:29 thchs30_vocabulary.txt
```

Finally i would like to say thank you to @lissyx @reuben. Thank you for great patience.",thanks problem screen shot format could succeed got correct result root root root root root root finally would like say thank thank great patience,issue,positive,positive,positive,positive,positive,positive
518932895,"It seems that the problem is `vocabulary.txt`. I noticed that in https://github.com/ailurus1991/ds_files/, the `thchs30-vocabulary.txt` starts wtih `AND`. 

<hr>
<img width=""977"" alt=""Screen Shot 2019-08-07 at 12 13 21 PM"" src=""https://user-images.githubusercontent.com/11624203/62594376-0c161d00-b90d-11e9-9328-2ea049d48048.png"">
<hr>

After i followed this format, i could succeed generated 45 kb trie files. And got the correct result. #2271 

```
-rwxrwxr-x 1 1005 1005  162766 Aug  6 14:36 thchs30-dev.csv
-rw-r--r-- 1 root root 1261235 Aug  7 03:31 thchs30-lm.binary
-rwxrwxr-x 1 1005 1005  453334 Aug  6 14:36 thchs30-test.csv
-rwxrwxr-x 1 1005 1005 1820244 Aug  6 12:22 thchs30-train.csv
-rw-r--r-- 1 root root   46223 Aug  7 03:32 thchs30-trie
-rw-r--r-- 1 root root 1600592 Aug  7 03:31 thchs30-words.arpa
-rwxrwxr-x 1 1005 1005   11532 Aug  5 08:11 thchs30_alphabet.txt
-rwxrwxr-x 1 1005 1005  130496 Aug  7 03:29 thchs30_vocabulary.txt
```",problem screen shot format could succeed got correct result root root root root root root,issue,negative,neutral,neutral,neutral,neutral,neutral
518903113,"Hi,

deepspeech --model models/output_graph.pbmm --audio Thor.wav --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie

Now I am getting model incompatibility error.

Loading model from file models/output_graph.pbmm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
2019-08-07 01:24:02.917095: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-07 01:24:02.979860: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-07 01:24:02.979946: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-07 01:24:02.979960: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-08-07 01:24:02.980127: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Specified model file version (0) is incompatible with minimum version supported by this client (1). See https://github.com/mozilla/DeepSpeech/#model-compatibility for more information
Traceback (most recent call last):
  File ""/home/aic_subscription/anaconda3/bin/deepspeech"", line 11, in <module>
    sys.exit(main())
  File ""/home/aic_subscription/anaconda3/lib/python3.6/site-packages/deepspeech/client.py"", line 88, in main
    ds = Model(args.model, N_FEATURES, N_CONTEXT, args.alphabet, BEAM_WIDTH)
  File ""/home/aic_subscription/anaconda3/lib/python3.6/site-packages/deepspeech/__init__.py"", line 23, in __init__
    raise RuntimeError(""CreateModel failed with error code {}"".format(status))
RuntimeError: CreateModel failed with error code 8195",hi model audio alphabet getting model incompatibility error loading model file binary use unknown unknown unknown unknown model file version incompatible minimum version client see information recent call last file line module main file line main model file line raise error code status error code,issue,negative,negative,neutral,neutral,negative,negative
518895270,"i used http://blog.yuwu.me/wp-content/uploads/2018/07/thchs30-csv.tar.gz from https://blog.yuwu.me/?p=3989

and also refer to https://github.com/mozilla/DeepSpeech/issues/1756 and refer to https://github.com/ailurus1991/ds_files/",used also refer refer,issue,negative,neutral,neutral,neutral,neutral,neutral
518753236,"> Hi,
> File is present. models folder is present. Why this error appears ?

Do you read error messages ? The file is not found. Please check its name.

**`--model models/output_graph.pbm`** or **`--model models/output_graph.pbmm`** ?",hi file present folder present error read error file found please check name model model,issue,negative,neutral,neutral,neutral,neutral,neutral
518746680,"no iam re try the steps again and skip the previous issue  i have problem in genereting the binary files. and now i dp this step right and re run the script again and get this error

```
Traceback (most recent call last):
File ""DeepSpeech.py"", line 844, in 
tfv1.app.run(main)
File ""//anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
File ""//anaconda3/lib/python3.7/site-packages/absl/app.py"", line 300, in run
_run_main(main, args)
File ""//anaconda3/lib/python3.7/site-packages/absl/app.py"", line 251, in _run_main
sys.exit(main(argv))
File ""DeepSpeech.py"", line 828, in main
train()
File ""DeepSpeech.py"", line 409, in train
cache_path=FLAGS.feature_cache)
File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/DeepSpeech/util/feeding.py"", line 68, in create_dataset
df = read_csvs(csvs)
File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/DeepSpeech/util/feeding.py"", line 22, in read_csvs
file = pandas.read_csv(csv, encoding='utf-8', na_filter=False)
File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 702, in parser_f
return _read(filepath_or_buffer, kwds)
File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 429, in _read
parser = TextFileReader(filepath_or_buffer, **kwds)
File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 895, in init
self._make_engine(self.engine)
File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 1122, in _make_engine
self._engine = CParserWrapper(self.f, **self.options)
File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 1853, in init
self._reader = parsers.TextReader(src, **kwds)
File ""pandas/_libs/parsers.pyx"", line 387, in pandas._libs.parsers.TextReader.cinit
File ""pandas/_libs/parsers.pyx"", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs' does not exist: b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs'
```

Kindly help me figure out the error ?
is the problem in tensorflow version , i have  version =1.14.0 
",try skip previous issue problem binary step right run script get error recent call last file line main file line run file line run main file line main file line main train file line train file line file line file file line return file line parser file line file line file line file line file line file exist kindly help figure error problem version version,issue,negative,positive,positive,positive,positive,positive
518744590,"These are both very different errors and the error log tells you what the problems are:

1. The file pointed to by --lm_binary_path must exist and be readable.
2. '/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs' does not exist


As this is not related to the original issue, could you move this discussion to [discourse](https://discourse.mozilla.org/c/deep-speech) please.",different error log file pointed must exist readable exist related original issue could move discussion discourse please,issue,negative,positive,positive,positive,positive,positive
518742477,"i try again and get this error
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 844, in <module>
    tfv1.app.run(main)
  File ""//anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""//anaconda3/lib/python3.7/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""//anaconda3/lib/python3.7/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""DeepSpeech.py"", line 828, in main
    train()
  File ""DeepSpeech.py"", line 409, in train
    cache_path=FLAGS.feature_cache)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/DeepSpeech/util/feeding.py"", line 68, in create_dataset
    df = read_csvs(csvs)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/DeepSpeech/util/feeding.py"", line 22, in read_csvs
    file = pandas.read_csv(csv, encoding='utf-8', na_filter=False)
  File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 895, in __init__
    self._make_engine(self.engine)
  File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File ""//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py"", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File ""pandas/_libs/parsers.pyx"", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File ""pandas/_libs/parsers.pyx"", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs' does not exist: b'/Users/suhadalissa/Desktop/suhad/s112/a1/train/train.cvs'",try get error recent call last file line module main file line run file line run main file line main file line main train file line train file line file line file file line return file line parser file line file line file line file line file line file exist,issue,negative,positive,positive,positive,positive,positive
518713532,"@chungyeh  My email is petertsengruihon@gmail.com, hope you are willing to contact with me. Thanks a lot. 🙏🙏",hope willing contact thanks lot,issue,positive,positive,positive,positive,positive,positive
518692340,"Hi,
File is present.  models folder is present. Why this error appears ?",hi file present folder present error,issue,negative,neutral,neutral,neutral,neutral,neutral
518679186,"@chungyeh thanks for reply. Would you mind sharing your `thchs30-lm.binary`, `thchs30-trie`, `thchs30-vocabulary.txt` and `thchs30-words.arpa` with a `zip` file ?  Thanks a lot. :pray::pray:",thanks reply would mind zip file thanks lot pray,issue,positive,positive,positive,positive,positive,positive
518674497,@reuben thanks reuben. I will try more experiments. The reason i did that cause i follow https://discourse.mozilla.org/t/training-chinese-model/27769. ,thanks try reason cause follow,issue,negative,positive,positive,positive,positive,positive
518673125,"@chungyeh hello chungyeh. According to #2290 @reuben , the `trie` file size should be 9 bytes. 

> If you're using a character-level LM (every space separated word in thchs30_vocabulary.txt is one grapheme long --reuben

Then why could you generate 45K bytes `trie` file ? I am so curious. Please send me a message if you could see this reply. Thanks a lot.",hello according file size every space word one long could generate file curious please send message could see reply thanks lot,issue,positive,positive,neutral,neutral,positive,positive
518672853,"That is unrelated to the trie. You'll probably need to remove spaces from your corpus. You should know that using DeepSpeech with character-level LMs/data is not something we've tested. We're working on it, but you might encounter several problems like this where we can't help yet.",unrelated probably need remove corpus know something tested working might encounter several like ca help yet,issue,positive,neutral,neutral,neutral,neutral,neutral
518671396,"@reuben thanks reuben. If that is true, then why my inference result is lack of space like below ?

```
- src: ""除 中 文 外 还 将 制 作 英 日 等 外 文 版 软 盘 以 方 便 海 外 用 户""
 - res: ""这一安晋图务夫宗的文的外岸儿还将的之的作的一应用的日子转等的用务一个外要有文的儿白儿的儿啊牌它案儿夫一个塞方不边样的儿矮海儿外儿一用五户五不和"" 
```",thanks true inference result lack space like,issue,positive,positive,positive,positive,positive,positive
518667369,"No, you need both. That's why we still generate a trie file even though it's only a 9 byte header.",need still generate file even though header,issue,negative,neutral,neutral,neutral,neutral,neutral
518666562,"@reuben Thanks reuben. so you mean that i don't need `lm_trie_path` in `.sh` file ? Just like below?

```
#!/bin/sh
set -xe
if [ ! -f DeepSpeech.py ]; then
    echo ""Please make sure you run this from DeepSpeech's top level directory.""
    exit 1
fi;

python -u DeepSpeech.py \
  --train_files /home/data/data_thchs30/thchs30_csv/test_collection/thchs30-train.csv \
  --dev_files /home/data/data_thchs30/thchs30_csv/test_collection/thchs30-dev.csv \
  --test_files /home/data/data_thchs30/thchs30_csv/test_collection/thchs30-test.csv \
  --train_batch_size 30 \
  --dev_batch_size 30 \
  --test_batch_size 30 \
  --n_hidden 512 \
  --epoch 50 \
  --beam_width 10 \
  --learning_rate 0.0001 \
  --export_dir result/thchs30_model/ \
  --checkpoint_dir result/thchs30_checkpoint/ \
  --alphabet_config_path /home/data/data_thchs30/thchs30_csv/test_collection/thchs30_alphabet.txt \
  --lm_binary_path /home/data/data_thchs30/thchs30_csv/test_collection/thchs30-lm.binary \
```",thanks mean need file like set echo please make sure run top level directory exit fi python epoch,issue,positive,positive,positive,positive,positive,positive
518666087,"I know there's work being done right now on per-language filtering rules for the wiki extractor. It would need to be stricter for DeepSpeech import, but maybe some of that work could still be ported across.

https://github.com/Common-Voice/common-voice-wiki-scraper/tree/master/src/rules",know work done right filtering extractor would need import maybe work could still ported across,issue,negative,positive,positive,positive,positive,positive
518662431,"This is not a bug. If you're using a character-level LM (every space separated word in `thchs30_vocabulary.txt` is one grapheme long) the trie structure is not needed, so the generated file contains just the header.",bug every space word one long structure file header,issue,negative,negative,neutral,neutral,negative,negative
518630628,"@cahuja1992 The benchmark was run on our private pt-br dataset. Unfortunately, we can't share right now. I couldn't benchmark on the Common Voice Dataset because all our machines are busy.

Thus, you will probably get different WER and loss values, but I believe that the augmentations should improve your numbers similarly as they improved ours.",run private unfortunately ca share right could common voice busy thus probably get different wer loss believe improve similarly,issue,negative,negative,neutral,neutral,negative,negative
518622065,"@lissyx @reuben @kdavis-mozilla  @chungyeh  I have succeed in install deepspeech from DeepSpeech Dockfile(DeepSpeech version is v0.5.1). But i still get the 9 bytes `trie` file. What i did is below 

```
/DeepSpeech/native_client/kenlm/build/bin/lmplz -o 3 --text thchs30_vocabulary.txt --arpa thchs30-words.arpa
/DeepSpeech/native_client/kenlm/build/bin/build_binary -T -s thchs30-words.arpa thchs30-lm.binary
/DeepSpeech/native_client/generate_trie thchs30_alphabet.txt thchs30-lm.binary thchs30-trie
```

And here's the file size.

```
-rwxrwxr-x  1 1005 1005  177947 Aug  5 08:26 thchs30-dev.csv
-rw-r--r--  1 root root 1261151 Aug  6 10:57 thchs30-lm.binary
-rwxrwxr-x  1 1005 1005  495749 Aug  5 08:26 thchs30-test.csv
-rwxrwxr-x  1 1005 1005 1990244 Aug  5 08:24 thchs30-train.csv
-rw-r--r--  1 root root       9 Aug  6 10:58 thchs30-trie
-rw-r--r--  1 root root 1599677 Aug  6 10:57 thchs30-words.arpa
-rwxrwxr-x  1 1005 1005   11532 Aug  5 08:11 thchs30_alphabet.txt
-rwxrwxr-x  1 1005 1005  130492 Aug  5 08:11 thchs30_vocabulary.txt
```

The `trie` file content is below: (vim thchs30-trie)

```
EIRT^C^@^@^@^A
~
~
~                 
```

[Archive.zip](https://github.com/mozilla/DeepSpeech/files/3471853/Archive.zip)


",succeed install version still get file text file size root root root root root root file content vim,issue,negative,neutral,neutral,neutral,neutral,neutral
518613662,">  Not found: models/output_graph.pbm; No such file or directory

Do you read error messages ?",found file directory read error,issue,negative,neutral,neutral,neutral,neutral,neutral
518606604,"@bernardohenz :
When exp_2(2048 n_hidden), exp_3 and exp_4 is tried on Common Voice Dataset, the desired behavior could not be reproduced. Can you please share which dataset you used and along with the parameters?",tried common voice desired behavior could please share used along,issue,positive,negative,negative,negative,negative,negative
518605485,"Hello,
I executed
pip install --upgrade **deepspeech==0.5.1**

deepspeech --model models/output_graph.pbm --audio Thor.wav --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie

Loading model from file models/output_graph.pbm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-08-06 10:08:53.490805: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Not found: models/output_graph.pbm; No such file or directory
Traceback (most recent call last):
  File ""/home/aic_subscription/anaconda3/bin/deepspeech"", line 11, in <module>
    sys.exit(main())
  File ""/home/aic_subscription/anaconda3/lib/python3.6/site-packages/deepspeech/client.py"", line 88, in main
    ds = Model(args.model, N_FEATURES, N_CONTEXT, args.alphabet, BEAM_WIDTH)
  File ""/home/aic_subscription/anaconda3/lib/python3.6/site-packages/deepspeech/__init__.py"", line 23, in __init__
    raise RuntimeError(""CreateModel failed with error code {}"".format(status))
RuntimeError: CreateModel failed with error code 12293

",hello executed pip install upgrade model audio alphabet loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use found file directory recent call last file line module main file line main model file line raise error code status error code,issue,negative,positive,neutral,neutral,positive,positive
518600228,"@reuben I would like to cry when i saw the below even though the words are red...

<img width=""1830"" alt=""Screen Shot 2019-08-06 at 5 54 39 PM"" src=""https://user-images.githubusercontent.com/11624203/62530586-6cf11700-b873-11e9-9563-caf52b844ac8.png"">
",would like cry saw even though red screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
518580622,"> download the source code `deepspeech-v.0.5.1`

Make sure you *clone* the repo and then checkout the v0.5.1 tag (as opposed to downloading the release tarball).",source code make sure clone tag opposed release,issue,negative,positive,positive,positive,positive,positive
518575164,"@reuben @kdavis-mozilla @lissyx thanks reuben, kdavis and lissyx. Now the error is below:

```
[1,899 / 2,012] Compiling tensorflow/core/kernels/maxpooling_op_gpu.cu.cc; 169s local ... (48 actions, 47 running)
ERROR: /tensorflow/native_client/BUILD:16:1: Executing genrule //native_client:ds_git_version failed (Exit 1): bash failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu/:/usr/local/cuda/lib64/stubs/ \
    NCCL_HDR_PATH=/usr/include \
    NCCL_INSTALL_PATH=/usr/lib/x86_64-linux-gnu \
    PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.0 \
    TF_CUDA_VERSION=10.0 \
    TF_CUDNN_VERSION=7 \
    TF_NCCL_VERSION=2 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_NEED_ROCM=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; native_client/ds_git_version.sh >bazel-out/k8-opt/genfiles/native_client/ds_version.h')
INFO: Elapsed time: 326.382s, Critical Path: 221.43s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 1596 processes: 1596 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
The command '/bin/sh -c bazel build --config=monolithic --config=cuda -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}' returned a non-zero code: 1
``` ",thanks error local running error exit bash error command time critical path remote time queue setup process local build complete successfully build complete successfully command build opt returned code,issue,negative,positive,positive,positive,positive,positive
518570137,I just worry about enforcing that all the importers do the same thing. With 20 different importers there may be 20 different alphabets.,worry thing different may different,issue,negative,neutral,neutral,neutral,neutral,neutral
518567738,"The base NVIDIA image already installs libnccl2, although it's a different version (2.4.7), and then holds the package. Maybe that's blocking the install? I thought hold only stopped updates, but maybe not. Try just removing/commenting out that line and see if it builds. Version 2.3.7 might not be a hard requirement.",base image already although different version package maybe blocking install thought hold stopped maybe try line see version might hard requirement,issue,negative,negative,negative,negative,negative,negative
518566384,"@kdavis-mozilla @reuben thanks a lot. 

It seems awkward to me.
```
/data/peter/asr/test/DeepSpeech-0.5.1$ sudo docker build -t deepspeech:v0.5.1 .
Sending build context to Docker daemon  20.71MB
Step 1/70 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04
 ---> bdc0497c2295
Step 2/70 : RUN apt-get update && apt-get install -y --no-install-recommends         build-essential         curl         wget         git         python3         python3-dev         python3-pip         python3-wheel         python3-numpy         libcurl3-dev          ca-certificates         gcc         sox         libsox-fmt-mp3         htop         nano         swig         cmake         libboost-all-dev         zlib1g-dev         libbz2-dev         liblzma-dev         locales         pkg-config         libsox-dev         openjdk-8-jdk         bash-completion         g++         unzip
 ---> Using cache
 ---> 9f4ed950a98c
Step 3/70 : RUN ln -s -f /usr/bin/python3 /usr/bin/python
 ---> Using cache
 ---> 08fce1a1b535
Step 4/70 : RUN apt-get install -qq -y --allow-downgrades --allow-change-held-packages libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0
 ---> Running in 4f8a7cdab089
E: Version '2.3.7-1+cuda10.0' for 'libnccl2' was not found
E: Version '2.3.7-1+cuda10.0' for 'libnccl-dev' was not found
The command '/bin/sh -c apt-get install -qq -y --allow-downgrades --allow-change-held-packages libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0' returned a non-zero code: 100
```",thanks lot awkward docker build sending build context docker daemon step step run update install curl git python swig cache step run cache step run install running version found version found command install returned code,issue,negative,negative,negative,negative,negative,negative
518564601,"No. If you're calling DS_DestroyModel and resources are still not being deallocated that's a TensorFlow bug, because we close the TF Session in DS_DestroyModel.",calling still bug close session,issue,negative,neutral,neutral,neutral,neutral,neutral
518563382,Thanks for response. Is there other way how to close tensorflow's session in nodejs than `FreeMetadata` and `DestroyModel`or restarting whole process? ,thanks response way close session whole process,issue,negative,positive,positive,positive,positive,positive
518560641,"@lissyx @kdavis-mozilla thanks for quick response. What i did is just below:

1. download the source code `deepspeech-v.0.5.1`
2. cd `deepspeech-v.0.5.1`
3. `docker build -t deepspeech:v0.5.1 .`",thanks quick response source code docker build,issue,negative,positive,positive,positive,positive,positive
518559746,"@lissyx @peterhon123 For the 0.5.1 docker file that seems to already be there[[1](https://github.com/mozilla/DeepSpeech/blob/v0.5.1/Dockerfile#L43)]
```
RUN apt-get install -qq -y --allow-downgrades --allow-change-held-packages libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0
```",docker file already run install,issue,negative,neutral,neutral,neutral,neutral,neutral
518557768,"> E: Version '2.3.7-1+cuda10.0' for 'libnccl2' was not found
> E: Version '2.3.7-1+cuda10.0' for 'libnccl-dev' was not found

It looks like this needs to be updated. Can you send a PR @peterhon123 ?",version found version found like need send,issue,negative,neutral,neutral,neutral,neutral,neutral
518549222,@kdavis-mozilla yes. I have installed CUDA and CUDNN. It's quite frustrated that i met so much difficult point while deploying process.  :cry::cry:,yes quite met much difficult point process cry,issue,negative,negative,negative,negative,negative,negative
518479935,"I am trying to run DeepSpeech on a small data set in another language other than english.
 i have mac book air 

Steps I followed:

Cloned deepspeech from github repository

pip3 install -r requirements.txt

python util/taskcluster.py --arch gpu --target native_client

prepare the data: train (6 wav files),dev(3 wav files), test (2 wav files),all wave are mono wave and cvs files ( file name, text) like this : /Desktop⁩/suhad/s112/a1/test/112_1_3475683015.wav,قل هو الله أحد

Then for creating language model:
git clone https://github.com/kpu/kenlm.git (cmake and make )
 alphabet.txt (containing all arabic alphabets), every word in one line like this : 
قل 
هو 
أحد
الله
 الصمد
لم
 يلد 
ولم
 يولد
 يكن  
له
 كفوا


some.txt (corpus of words cover all the words in wav files)

../kenlm/build/bin/lmplz -o 5 <some.txt >lm.arpa

../kenlm/build/bin/build_binary lm.arpa lm.binary

../DeepSpeech/native_client/generate_trie alphabet.txt lm.binary trie

Then ran the following script:
#!/bin/sh
set -xe
if [ ! -f DeepSpeech.py ]; then
    echo ""Please make sure you run this from DeepSpeech's top level directory.""
    exit 1
fi;

python -u DeepSpeech.py \
  --train_files ""/Desktop⁩/suhad/s112/a1/train/train.cvs"" \
  --dev_files ""/Desktop⁩/suhad/s112/a1/dev/dev.cvs"" \
  --test_files ""/Desktop⁩/suhad/s112/a1/test/test.cvs"" \
 --alphabet_config_path ""/Desktop⁩/arabic_models/alphabet.txt"" \
 --lm_binary_path ""/Desktop⁩/arabic_models/lm.binary"" \
--lm_trie_path ""/Desktop⁩/arabic_models/trie"" \
 --decoder_library_path ""/Desktop⁩/mozilla_deepspeech/DeepSpeech/libdeepspeech.so"" \
  --train_batch_size 80 \
  --dev_batch_size 80 \
  --test_batch_size 40 \
  --n_hidden 375 \
  --epoch 33 \
  --validation_step 1 \
  --early_stop True \
  --earlystop_nsteps 6 \
  --estop_mean_thresh 0.1 \
  --estop_std_thresh 0.1 \
  --dropout_rate 0.22 \
  --learning_rate 0.00095 \
  --report_count 100 \
  --use_seq_length False \

  --export_dir ""/Desktop⁩/arabic_models/results""
""$@""
I am getting the following error:
Traceback (most recent call last):
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 528, in _assert_validators
    validator.verify(self)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_validators.py"", line 82, in verify
    raise _exceptions.ValidationError(self.message)
absl.flags._exceptions.ValidationError: The file pointed to by --lm_binary_path must exist and be readable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 844, in <module>
    tfv1.app.run(main)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 294, in run
    flags_parser,
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 351, in _run_init
    flags_parser=flags_parser,
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 213, in _register_and_parse_flags_with_usage
    args_to_main = flags_parser(original_argv)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 31, in _parse_flags_tolerate_undef
    return flags.FLAGS(_sys.argv if argv is None else argv, known_only=True)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/flags.py"", line 112, in __call__
    return self.__dict__['__wrapped'].__call__(*args, **kwargs)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 636, in __call__
    self._assert_all_validators()
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 510, in _assert_all_validators
    self._assert_validators(all_validators)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 531, in _assert_validators
    raise _exceptions.IllegalFlagValueError('%s: %s' % (message, str(e)))
absl.flags._exceptions.IllegalFlagValueError: flag --lm_binary_path=/Desktop⁩/arabic_models/lm.binary: The file pointed to by --lm_binary_path must exist and be readable.
(deepspeech_env) (base) suhads-MacBook-Air:DeepSpeech suhadalissa$ ./run.sh
+ '[' '!' -f DeepSpeech.py ']'
+ python -u DeepSpeech.py --train_files $'/Desktop?\201?/suhad/s112/a1/train/train.cvs' --dev_files $'/Desktop?\201?/suhad/s112/a1/dev/dev.cvs' --test_files $'/Desktop?\201?/suhad/s112/a1/test/test.cvs' --alphabet_config_path $'/Desktop?\201?/arabic_models/alphabet.txt' --lm_binary_path $'/Desktop?\201?/arabic_models/lm.binary' --lm_trie_path $'/Desktop?\201?/arabic_models/trie' --decoder_library_path $'/Desktop?\201?/mozilla_deepspeech/DeepSpeech/libdeepspeech.so' --train_batch_size 80 --dev_batch_size 80 --test_batch_size 40 --n_hidden 375 --epoch 33 --validation_step 1 --early_stop True --earlystop_nsteps 6 --estop_mean_thresh 0.1 --estop_std_thresh 0.1 --dropout_rate 0.22 --learning_rate 0.00095 --report_count 100 --use_seq_length False
Traceback (most recent call last):
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 528, in _assert_validators
    validator.verify(self)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_validators.py"", line 82, in verify
    raise _exceptions.ValidationError(self.message)
absl.flags._exceptions.ValidationError: The file pointed to by --lm_binary_path must exist and be readable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 844, in <module>
    tfv1.app.run(main)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 294, in run
    flags_parser,
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 351, in _run_init
    flags_parser=flags_parser,
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/app.py"", line 213, in _register_and_parse_flags_with_usage
    args_to_main = flags_parser(original_argv)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 31, in _parse_flags_tolerate_undef
    return flags.FLAGS(_sys.argv if argv is None else argv, known_only=True)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/tensorflow/python/platform/flags.py"", line 112, in __call__
    return self.__dict__['__wrapped'].__call__(*args, **kwargs)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 636, in __call__
    self._assert_all_validators()
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 510, in _assert_all_validators
    self._assert_validators(all_validators)
  File ""/Users/suhadalissa/Desktop/mozilla_deepspeech/deepspeech_env/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 531, in _assert_validators
    raise _exceptions.IllegalFlagValueError('%s: %s' % (message, str(e)))
absl.flags._exceptions.IllegalFlagValueError: flag --lm_binary_path=/Desktop⁩/arabic_models/lm.binary: The file pointed to by --lm_binary_path must exist and be readable.
(deepspeech_env) (base) suhads-MacBook-Air:DeepSpeech suhadalissa$ 

Kindly help me figure out the error.


",trying run small data set another language mac book air repository pip install python arch target prepare data train dev test wave mono wave file name text like language model git clone make every word one line like corpus cover ran following script set echo please make sure run top level directory exit fi python epoch true false getting following error recent call last file line self file line verify raise file pointed must exist readable handling exception another exception recent call last file line module main file line run file line run file line file line file line return none else file line return file line file line file line raise message flag file pointed must exist readable base python epoch true false recent call last file line self file line verify raise file pointed must exist readable handling exception another exception recent call last file line module main file line run file line run file line file line file line return none else file line return file line file line file line raise message flag file pointed must exist readable base kindly help figure error,issue,positive,negative,neutral,neutral,negative,negative
518460077,"I used DeepSpeech Dockerfile to build docker image and running in docker.  When build docker image with DeepSpeech Dockerfile, those utilities will be generated. Not sure if this causes difference.

/DeepSpeech/native_client/kenlm/build/bin/lmplz -o 3 --text thchs30-vocabulary.txt --arpa thchs30-words.arpa
/DeepSpeech/native_client/kenlm/build/bin/build_binary -T -s thchs30-words.arpa thchs30-lm.binary
/DeepSpeech/native_client/generate_trie thchs30-alphabet.txt thchs30-lm.binary thchs30-trie

ls -la
1261375 Aug  3 15:22 thchs30-lm.binary
46255 Aug  3 15:21 thchs30-trie
130500 Aug  3 15:21 thchs30-vocabulary.txt
4036589 Aug  3  2018 thchs30-words.arpa
",used build docker image running docker build docker image sure difference text,issue,negative,positive,positive,positive,positive,positive
518296420,"> If not what binaries version do you require?

`pip install --upgrade deepspeech==0.5.1`",version require pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
518290920,@chungyeh thanks chungyeh. Would you mind sharing the process that you generate `trie` file and share your `trie` file ?,thanks would mind process generate file share file,issue,positive,positive,positive,positive,positive,positive
518259672,"pip install deepspeech (python bindings)
version: 0.1.1

If not what binaries version do you require?

Thanks",pip install python version version require thanks,issue,negative,positive,positive,positive,positive,positive
518256154,"@kdavis-mozilla thanks kdavis. After try what you suggested, and then i generate trie file. I would be highly appreciated if you give some hint.

[lm_trie.zip](https://github.com/mozilla/DeepSpeech/files/3468007/lm_trie.zip)
",thanks try generate file would highly give hint,issue,negative,positive,positive,positive,positive,positive
518252848,"Wait it doesn't look like you created a trie language model. Try...
```
/data/peter/kenlm/build/bin/build_binary trie test_word.arpa test_lm.binary
```",wait look like language model try,issue,negative,neutral,neutral,neutral,neutral,neutral
518250643,"@kdavis-mozilla thanks kdavis for reply. As you expected, each char contains one space after each char. Here's my `train.csv`, `test.csv` and `dev.csv`.

[csv_file.zip](https://github.com/mozilla/DeepSpeech/files/3467956/csv_file.zip)
",thanks reply char one space char,issue,negative,positive,positive,positive,positive,positive
518248979,"@tsungruihon Does thchs30-vocabulary.txt contain spaces after each character?

Something like...

> 本 品 的 特 色 为 能 对...",contain character something like,issue,negative,neutral,neutral,neutral,neutral,neutral
518246542,"@kdavis-mozilla thanks kdavis for reply. I create the language model using the below code:

```
/data/peter/kenlm/build/bin/lmplz -o 3 --text thchs30-vocabulary.txt --arpa test_word.arpa
/data/peter/kenlm/build/bin/build_binary -T -s test_word.arpa test_lm.binary
```

[vocabulary_lm.zip](https://github.com/mozilla/DeepSpeech/files/3467913/vocabulary_lm.zip)

And here's my `alphabet` file.
[thchs30_alphabet.txt](https://github.com/mozilla/DeepSpeech/files/3467932/thchs30_alphabet.txt)

",thanks reply create language model code text alphabet file,issue,positive,positive,positive,positive,positive,positive
518244617,"@tsungruihon How did you create the language model?

@reuben maybe you have some insight as you are working on Mandarin now.",create language model maybe insight working mandarin,issue,negative,neutral,neutral,neutral,neutral,neutral
518240326,"@chungyeh thanks chungyeh. My `lm.binary`' s size is `1.3M`. Would you mind telling me whether mine is the same as yours ? 

I have generate the `trie` again. But the `trie` file' size is `9 bytes`. 
[test_lm_alphabet_vocabulary.zip](https://github.com/mozilla/DeepSpeech/files/3467862/test_lm_alphabet_vocabulary.zip)

It would be highly appreciated if you could give me some suggestion. Thank you again.
",thanks size would mind telling whether mine generate file size would highly could give suggestion thank,issue,positive,positive,positive,positive,positive,positive
518233697,"@tsungruihon 9 bytes trie file is bad one. Please use thchs30 vocabulary file to regenerate thchs30-word.arpa (I used 3 gram), then lm.binary and then generate true. The trie file should be about 45KBytes.",file bad one please use vocabulary file regenerate used gram generate true file,issue,negative,negative,negative,negative,negative,negative
518222936,"@tsungruihon I just did exactly as you did but with the language model and alphabet file from the release and got a trie that's 21MB. (I'm on OSX 10.14.5) 

So my guess is either there is a OS specific problem with generate_trie or there's something wrong with your language model and/or alphabet file.",exactly language model alphabet file release got guess either o specific problem something wrong language model alphabet file,issue,negative,negative,neutral,neutral,negative,negative
518222928,"@chungyeh thanks chungyeh. One thing I would like to ask is why my trie file is jut 9 bytes ?
I just typed python util/taskcluster.py --branch “v0.5.1” --target ""."" and then get the trie file using

`native_client/generate_trie /data/peter/asr/data/data_thchs30/thchs30_csv/thchs30_alphabet.txt /data/peter/asr/data/data_thchs30/thchs30_csv/lm.bin /data/peter/asr/data/data_thchs30/thchs30_csv/trie. `
I noticed the README.md in https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md, should i also follow the instruction in https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md ?",thanks one thing would like ask file jut python branch target get file also follow instruction,issue,positive,positive,positive,positive,positive,positive
518218669,"@tsungruihon FYR

Before I trained the model, I do git checkout v0.5.1. Master version seems to have something wrong when I run training or inferences. I forgot the detail. During training thchs30, the lost I got is about 40-50.",trained model git master version something wrong run training forgot detail training lost got,issue,negative,negative,negative,negative,negative,negative
518214186,"@lissyx Hello lissyx, i would like to ask why the `trie` file is jut 9 bytes ? 
I just typed `python util/taskcluster.py --branch “v0.5.1” --target "".""` and then get the  `trie` file using 
```
native_client/generate_trie /data/peter/asr/data/data_thchs30/thchs30_csv/thchs30_alphabet.txt /data/peter/asr/data/data_thchs30/thchs30_csv/lm.bin /data/peter/asr/data/data_thchs30/thchs30_csv/trie. 
```
 I noticed the `README.md `in https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md, should i also follow the instruction in https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md ?",hello would like ask file jut python branch target get file also follow instruction,issue,negative,neutral,neutral,neutral,neutral,neutral
518207376,"@lissyx @chungyeh Here's my inference on `D11_785.wav`. Seems weird.

```
/data/zeng_ruihong/asr/DeepSpeech-0.5.1$ deepspeech --alphabet /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/thchs30_alphabet.txt --lm /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/lm.bin --trie /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/trie --model result/thchs30_model/output_graph.pb --audio /data/zeng_ruihong/asr/data/data_thchs30/data/D11_785.wav
Loading model from file result/thchs30_model/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-08-05 19:02:48.782524: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-05 19:02:49.017306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-08-05 19:02:49.017360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-05 19:06:03.987040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-05 19:06:03.987090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-05 19:06:03.987096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-05 19:06:04.005403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11438 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
2019-08-05 19:06:04.041432: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-05 19:06:04.041484: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-05 19:06:04.041499: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-08-05 19:06:04.041852: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 1.95e+02s.
Loading language model from files /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/lm.bin /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/trie
Loaded language model in 0.0107s.
Running inference.
2019-08-05 19:06:04.484543: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
在安弟晋弟晋北一些京军用行方的在买来的区的农物尼银行的资自己一个划二十七姐全的一条朝的发外二样的夫患案样夫王安一言人十寿用的夫四色儿子十五以影及春的一样某不会委以捕苦及其需月的文的区在内爱的一六有
的十之的及江的不的对的是才不自在儿不在
Inference took 1555.125s for 9.858s audio file.
```




",inference weird alphabet model audio loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability unknown unknown unknown unknown loaded model loading language model loaded language model running inference successfully library locally inference took audio file,issue,positive,negative,neutral,neutral,negative,negative
518188421,"@chungyeh Now my testing result is below :

```
I FINISHED optimization in 1:24:20.813446
WARNING:tensorflow:From /data/zeng_ruihong/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I Restored variables from best validation checkpoint at /data/zeng_ruihong/asr/DeepSpeech-0.5.1/result/thchs30_checkpoint/best_dev-13320, step 13320
Testing model on /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/thchs30-test.csv
Test epoch | Steps: 83 | Elapsed Time: 0:57:10
Test on /data/zeng_ruihong/asr/data/data_thchs30/thchs30_csv/thchs30-test.csv - WER: 1.000000, CER: 1.000000, loss: 170.676422
--------------------------------------------------------------------------------
WER: 1.000000, CER: 1.288889, loss: 40.363464
 - src: ""除 中 文 外 还 将 制 作 英 日 等 外 文 版 软 盘 以 方 便 海 外 用 户""
 - res: ""这一安晋图务夫宗的文的外岸儿还将的之的作的一应用的日子转等的用务一个外要有文的儿白儿的儿啊牌它案儿夫一个塞方不边样的儿矮海儿外儿一用五户五不和""                                                                               
```

It seems that it doesn't have blank to split out the words. Do you have any suggestion .? May i contact you with `wechat` for convenient communication. Or may I send email to you?",testing result finished optimization warning removed future version use standard file check prefix best validation step testing model test epoch time test wer loss wer loss blank split suggestion may contact convenient communication may send,issue,negative,positive,positive,positive,positive,positive
518181089,"I can run normally as below. It uses test file and output is not identical to test file transcription., est/D11_785.wav,315500,北 京 丰 台 区 农 民 自 己 花 钱 筹 办 万 佛 延 寿 寺  迎 春 庙 会 吸 引 了 区 内 六 十 支 秧 歌 队 参 赛.

./deepspeech --alphabet thchs30-alphabet.txt --lm thchs30-lm.binary --trie thchs30-trie  --model output_graph.pb --audio test/D11_785.wav
TensorFlow: v1.13.1-13-g174b4760eb
DeepSpeech: v0.5.1-0-g4b29b78
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-08-04 14:59:28.997947: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-04 14:59:29.071488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-04 14:59:29.072025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.759
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.55GiB
2019-08-04 14:59:29.072039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-04 14:59:29.329167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-04 14:59:29.329192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-04 14:59:29.329197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-04 14:59:29.329324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5324 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-08-04 14:59:29.340582: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-08-04 14:59:29.340608: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-04 14:59:29.340631: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-04 14:59:29.340637: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-08-04 14:59:29.522775: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
北 京 方 坛 区 农 民 自 主 化 学 朝 办 万 佛 延 寿 四 银 春 要 会 心 文 区 内 六 十 珍 张 的 队 参 赛

I followed steps in https://github.com/mozilla/DeepSpeech/issues/1977 to regenerate arpa, lm.binary and trie file due to trie error message during training.",run normally test file output identical test file alphabet model audio warning reading entire model file memory transform model file graph reduce heap usage binary use successful node read negative value must least one node node zero found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability unknown unknown unknown unknown successfully library locally regenerate file due error message training,issue,positive,positive,neutral,neutral,positive,positive
518129770,@suhad999 Could you indicate the steps you have already taken?,could indicate already taken,issue,negative,neutral,neutral,neutral,neutral,neutral
518115967,"@chungyeh Now the training process goes well,  but i still get the blank result while in the test progress. Have you met that situation ?",training process go well still get blank result test progress met situation,issue,positive,neutral,neutral,neutral,neutral,neutral
518103013,"> @cahuja1992 I've added a comparison of TF and librosa spectrogram computation ([link](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA)), and it seems that both work similarly, i.e., it is possible to (partially) reconstruct the audio from its spectrogram (either if it was computed with librosa or TF).
> 
> With respect to log-space, I don't believe this makes any difference in practice. All the augs either deform or rescale the spectrogram, which implies on interpolating values. Although interpolating on linear or log-space makes difference, I think the space of interpolation is not relevant in practice. Concluding: performing the augmentations on linear or log space will result in almost-like spectrograms.,

Thanks. Its just in the SpecAugment paper, google mentioned that they augment over log melspectoram.",added comparison spectrogram computation link work similarly possible partially reconstruct audio spectrogram either respect believe difference practice either deform spectrogram although linear difference think space interpolation relevant practice concluding linear log space result thanks paper augment log,issue,positive,positive,positive,positive,positive,positive
518057985,"@lissyx thank you again. Now the training process goes well. But when i inference a `8.280s` audio using `2080Ti GPU`, the inference time is tremendous long, which is total `1536.754s`. The dataset is `Mozilla Common Voice Chinese` version.

The source is `common_voice_zh-CN_18531546.wav` and the training text is `本 品 的 特 色 为 能 对 抗 多 种 抗 药 性 极 强 的 病 原 体 如 耐 甲 氧 西 林 金 黄 色 葡 萄 球 菌 等`, and the below is inference result:

```
/home/data/peter/asr/DeepSpeech-0.5.1$ deepspeech --model /home/data/peter/asr/DeepSpeech-master/result/model_2/output_graph.pb --audio ../data/zh/clips/common_voice_zh-CN_18531546.wav --alphabet /home/data/peter/asr/DeepSpeech-master/data/zh_alphabat.txt --lm /home/data/peter/asr/data/zh/zh_csv/lm.bin --trie /home/data/peter/asr/data/zh/zh_csv/trie
Loading model from file /home/data/peter/asr/DeepSpeech-master/result/model_2/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-08-04 23:49:02.904135: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-04 23:49:03.048478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:02:00.0
totalMemory: 10.73GiB freeMemory: 10.57GiB
2019-08-04 23:49:03.048534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-04 23:49:03.712763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-04 23:49:03.712817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-04 23:49:03.712825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-04 23:49:03.713531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10217 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2019-08-04 23:49:03.737689: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-04 23:49:03.737757: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-04 23:49:03.737767: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-08-04 23:49:03.737954: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.839s.
Loading language model from files /home/data/peter/asr/data/zh/zh_csv/lm.bin /home/data/peter/asr/data/zh/zh_csv/trie
Loaded language model in 0.00116s.
Running inference.
2019-08-04 23:49:04.085504: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
本仪齿蚁宛隆宛名品铁的土特隋她夫色尔隋忧为们能掳路个土倍对也把谜抗卡航通多龈种朋抗按药的患银性银极行强察的行一定病定没原连群土体辑起银如龈耐患甲银氧银西银留林银金土黄隋色座埠葡萄患呈球普呈菌运么谜
盗谜等
Inference took 1536.754s for 8.280s audio file.
``` 

Also i am confused that i have already add ` (blank)` in `alphabet.txt` but why the inference result seems lack of `blank` character acting splitting function. 

Here`s the training parameter

```
#!/bin/sh
set -xe
if [ ! -f DeepSpeech.py ]; then
    echo ""Please make sure you run this from DeepSpeech's top level directory.""
    exit 1
fi;

python -u DeepSpeech.py \
  --train_files /home/data/peter/asr/data/zh/zh_csv/train_split.csv \
  --test_files /home/data/peter/asr/data/zh/zh_csv/train_split.csv \
  --train_batch_size 80 \
  --test_batch_size 40 \
  --n_hidden 512 \
  --learning_rate 0.0001 \
  --epochs 1000 \
  --beam_width 10 \
  --alphabet_config_path /home/data/peter/asr/DeepSpeech-master/data/zh_alphabat.txt \
  --lm_binary_path /home/data/peter/asr/data/zh/zh_csv/lm.bin \
  --lm_trie_path /home/data/peter/asr/data/zh/zh_csv/trie \
  --checkpoint_dir /home/data/peter/asr/DeepSpeech-master/result/checkpoint_2 \
  --export_dir /home/data/peter/asr/DeepSpeech-master/result/model_2 \
  ""$@""
```",thank training process go well inference audio ti inference time tremendous long total common voice version source training text inference result model audio alphabet loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use found device name ti major minor visible device interconnect strength edge matrix device memory physical device name ti bus id compute capability unknown unknown unknown unknown loaded model loading language model loaded language model running inference successfully library locally inference took audio file also confused already add blank inference result lack blank character acting splitting function training parameter set echo please make sure run top level directory exit fi python,issue,positive,positive,neutral,neutral,positive,positive
517964252,"@cahuja1992 I've added a comparison of TF and librosa spectrogram computation ([link](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA)), and it seems that both work similarly, i.e., it is possible to (partially) reconstruct the audio from its spectrogram (either if it was computed with librosa or TF).

With respect to log-space, I don't believe this makes any difference in practice. All the augs either deform or rescale the spectrogram, which implies on interpolating values. Although interpolating on linear or log-space makes difference, I think the space of interpolation is not relevant in practice. Concluding: performing the augmentations on linear or log space will result in almost-like spectrograms., ",added comparison spectrogram computation link work similarly possible partially reconstruct audio spectrogram either respect believe difference practice either deform spectrogram although linear difference think space interpolation relevant practice concluding linear log space result,issue,negative,positive,positive,positive,positive,positive
517944891,"@bernardohenz This is nice work. I have few doubts.
1. When you are trying to integrate with [feeding.py](https://github.com/bernardohenz/DeepSpeech/blob/ca3a164615956baacb8228e277d52dc01ae1ff28/util/feeding.py#L35), this line actually calculate the spectrogram that is equivalent to tf.stft. Bu the spec augment methods like`augment_sparse_deform` needs log mel-spectrogram. Therefore, I doubt whether this is correct or not. Or else log-mel-spectrogram needs to be calculated 
while using something like this [log_mel_spectrograms](https://www.tensorflow.org/api_docs/python/tf/signal/mfccs_from_log_mel_spectrograms)

2. Method spsi to convert Spectrogram to wav, does works with librosa but have you tried it with tensorflow contrib_audio. audio_spectrogram ?",nice work trying integrate line actually calculate spectrogram equivalent bu spec augment like need log therefore doubt whether correct else need calculated something like method convert spectrogram work tried,issue,positive,positive,positive,positive,positive,positive
517941758,"> pratapaprasanna
> Thank you very much. That worked. Cuda is installed and everything is working!!!!

Thanks for updating us, I'm closing this :)",thank much worked everything working thanks u,issue,positive,positive,positive,positive,positive,positive
517936711," pratapaprasanna 
Thank you very much. That worked. Cuda is installed and everything is working!!!!",thank much worked everything working,issue,negative,positive,positive,positive,positive,positive
517931921,"@lissyx thanks for reply. Really appreciated.

> Have you trained on master ? You are using incompatible binaries vs language model, as mentionned in the error.

Yes, i trained on master and the version is `0.6.0-alpha.4` . How could i fix these error? Please give me some suggestion and i am really grateful for you.  Or which version `deepspeech` is stable enough and which version `deepspeech` would you suggest to use ?

> Please use generate_trie from 0.5.1 if you intend to run on 0.5.1

I use `python3 util/taskcluster.py --branch ""v0.5.1"" --target "".""` and ran `deepspeech --model result_2/model/output_graph.pb --audio ../data/zh/clips/common_voice_zh-CN_18811958.wav --alphabet ../data/zh/zh_csv/zh_alphabat.txt --lm ../data/zh/zh_csv/lm.bin --trie/data/peter/asr/data/zh/zh_csv/trie_2`, the error is below:

```
/data/peter/asr/DeepSpeech$ deepspeech --model result_2/model/output_graph.pb --audio ../data/zh/clips/common_voice_zh-CN_18811958.wav --alphabet ../data/zh/zh_csv/zh_alphabat.txt --lm ../data/zh/zh_csv/lm.bin --trie ../data/peter/asr/data/zh/zh_csv/trie_2
Loading model from file result_2/model/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.1-0-g4b29b78
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-08-03 23:11:05.767553: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-08-03 23:11:06.610785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-03 23:11:06.613840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2019-08-03 23:11:06.613853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-08-03 23:11:07.286389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-03 23:11:07.286418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-08-03 23:11:07.286426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-08-03 23:11:07.287460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10428 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-08-03 23:11:07.311287: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-08-03 23:11:07.311329: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-08-03 23:11:07.311341: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-08-03 23:11:07.311492: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 1.55s.
Loading language model from files ../data/zh/zh_csv/lm.bin ../data/peter/asr/data/zh/zh_csv/trie_2
Loaded language model in 0.00386s.
Running inference.
Error running session: Not found: PruneForTargets: Some target nodes not found: initialize_state
Segmentation fault (core dumped)
```
",thanks reply really trained master incompatible language model error yes trained master version could fix error please give suggestion really grateful version stable enough version would suggest use please use intend run use python branch target ran model audio alphabet error model audio alphabet loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use successful node read negative value must least one node node zero found device name ti major minor visible device interconnect strength edge matrix device memory physical device name ti bus id compute capability unknown unknown unknown unknown loaded model loading language model loaded language model running inference error running session found target found segmentation fault core,issue,positive,positive,neutral,neutral,positive,positive
517903254,"If you already have cuda installed then try setting your environment variable `LD_LIBRARY_PATH`
eg:
In my case
`export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64`
worked for me .
",already try setting environment variable case export worked,issue,negative,neutral,neutral,neutral,neutral,neutral
517902831,">  ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory

Obviously, you don't have proper CUDA 10.0 installed.",open object file file directory obviously proper,issue,negative,neutral,neutral,neutral,neutral,neutral
517902788,"> I use chinese dataset from Moziila common voice dataset. When i finished training model and try to inference, the terminal output error like below:

Have you trained on master ? You are using incompatible binaries vs language model, as mentionned in the error.



> Error: Trie file version mismatch (4 instead of expected 3). Update your trie file.

Please use `generate_trie` from 0.5.1 if you intend to run on 0.5.1",use common voice finished training model try inference terminal output error like trained master incompatible language model error error file version mismatch instead update file please use intend run,issue,negative,negative,negative,negative,negative,negative
517891082,"Thanks @dabinat @tsungruihon.

I met same 'QWDu' error and ffmpeg -c:a copy resolved this issue. It can work normally now.",thanks met error copy resolved issue work normally,issue,negative,positive,positive,positive,positive,positive
517844322,"As far as I know, closing the session should release the GPU memory.",far know session release memory,issue,negative,positive,neutral,neutral,positive,positive
517774114,"Hi. pleaze help me
i did the same as you vibhashahani
I am trying to run DeepSpeech on my small data set.
but i don't understand the step to create a trie even i use  the generate_trie  in native_client.tar.xz but i cant successd .
can you please explain in details this step 
",hi help trying run small data set understand step create even use cant please explain step,issue,negative,negative,negative,negative,negative,negative
517755008,"As much as I remember, this is tensorflow's behavior, am I right @reuben ?",much remember behavior right,issue,negative,positive,positive,positive,positive,positive
517588639,And what is your version of binaries? Lack of version in the output is likely a good hint it is not 0.5.1... How did you installed? ,version lack version output likely good hint,issue,negative,positive,positive,positive,positive,positive
517524887,"I have used pre-trained model
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
tar xvfz deepspeech-0.5.1-models.tar.gz

or is it because of incompatible with my existing supporting libraries
libsox2
libstdc++6
libgomp1
libpthread

or  I need to build from scratch ?",used model tar incompatible supporting need build scratch,issue,negative,positive,positive,positive,positive,positive
517212428,"> Hi how do I solve this? Can you send compatible versions?

It's going to be hard to help you if you don't document what you do. We don't hide any version, you are just likely mixing stuff inappropriately.",hi solve send compatible going hard help document hide version likely stuff inappropriately,issue,negative,negative,negative,negative,negative,negative
517208291,Hi how do I solve this? Can you send compatible versions?,hi solve send compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
517097745,"@dabinat thank you dabinat. What you suggest solved the problem perfectly. Thank again.

```
#!/bin/bash

for name in *.wav;
do
    ffmpeg -i ""$name"" -c:a copy ""tmp/$name""
done
```",thank suggest problem perfectly thank name name copy name done,issue,positive,positive,positive,positive,positive,positive
517005003,"Oh, I overlooked that part, sorry. I disowned the package.",oh part sorry package,issue,negative,negative,negative,negative,negative,negative
516924554,"> I didn't find any corrupted wave files by using my modified script: https://github.com/gqy2468/DeepSpeech/blob/master/bin/wav_check.py
> 
> Usage:
> `python3 bin/wav_check.py data_thchs30/thchs30-train.csv`

Sounds like ffmpeg may be working around the error, in which case you could process every file in the directory with ffmpeg using the ""-c:a copy"" parameter, which will essentially rewrite the file structure to disk without re-encoding the media data. That should fix the error.",find corrupted wave script usage python like may working around error case could process every file directory copy parameter essentially rewrite file structure disk without medium data fix error,issue,negative,neutral,neutral,neutral,neutral,neutral
516846033,"Could you move this to discourse?

I know [eggonlea](https://discourse.mozilla.org/u/eggonlea/summary) has this working already so you can ask [eggonlea](https://discourse.mozilla.org/u/eggonlea/summary) there.",could move discourse know working already ask,issue,negative,neutral,neutral,neutral,neutral,neutral
516842110,"I tried that but it didn't work out for me

I got blank lines in the output

Can you help me with that?",tried work got blank output help,issue,negative,neutral,neutral,neutral,neutral,neutral
516739847,"The [0.5.1. release notes](https://github.com/mozilla/DeepSpeech/releases/tag/v0.5.1) state under the Known Issues section that

> Code not yet thread safe, having multiple concurrent streams tied to the same model leads to bad transcriptions.

A solution is to have multiple threads each with its own model.",release state known section code yet thread safe multiple concurrent tied model bad solution multiple model,issue,negative,negative,neutral,neutral,negative,negative
516665411,"@NicoHood yes, but please do not add me to packages without first consulting me. As I mentioned, I am unable (and unwilling) to [co-]maintain that package at this time, so please work on that yourself/abandon it/look for other help.",yes please add without first consulting unable unwilling maintain package time please work help,issue,positive,negative,negative,negative,negative,negative
516496389,"@reuben I was thinking you were internally converting all audios to the desired SR when loading themfor training, but I think this only occurs in the client.

I've tried to convert the `LDC93S1.wav` to 44k and it seems to work fine in the training now, please ignore the issue.",thinking internally converting desired loading training think client tried convert work fine training please ignore issue,issue,negative,positive,positive,positive,positive,positive
516492834,"@reuben I've used the default `LDC93S1.wav` that is downloaded when running the script.

@kdavis-mozilla I think the problem is the computation of `audio_window_samples` (https://github.com/mozilla/DeepSpeech/blob/master/util/config.py#L97) and/or `audio_step_samples` (https://github.com/mozilla/DeepSpeech/blob/master/util/config.py#L100).

Dividing any of the above by a factor of 2 seems to solve the problem. Maybe there's a problem when computing spectrogram or extracting features using the values computed. In case you wonder, the values obtained when using `SR=44100` are: `Audio Window Samples: 1411.2` and  `Audio Step Samples: 882.0`.


PS: even casting `audio_window_samples` to int doesn't solve the problem",used default running script think problem computation dividing factor solve problem maybe problem spectrogram case wonder audio window audio step even casting solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
516486240,Can you share the audio file you used when replicating it with run-ldc93s1.sh?,share audio file used,issue,negative,neutral,neutral,neutral,neutral,neutral
516485812,"I don't think is the place for it, maybe discourse is more appropriate.

That said, without ever trying 44k before, I've only trained on 16k, I'd guess the learning rate may be to blame. Try lowering by factors of 1/2, 1/4, 1/8,... until you don't see an Inf to find the approximate range for the new learning rate.",think place maybe discourse appropriate said without ever trying trained guess learning rate may blame try lowering see find approximate range new learning rate,issue,negative,positive,neutral,neutral,positive,positive
515978773,"@ssetty You are not providing any context, versions, anything. Your error is textbook mixing of incompatible binaries and trie/LM file.",providing context anything error textbook incompatible file,issue,negative,neutral,neutral,neutral,neutral,neutral
515978493,"> Where is the packaged trie file located?
> This is my DeepSpeech directory.
> ![Screenshot_2019-07-24_11-17-01](https://user-images.githubusercontent.com/31318823/62043309-a5fb0d00-b21d-11e9-8b08-7fe3f6b6b941.png)

Please avoid screenshots. As I said, it's in `native_client.tar.xz`",file directory please avoid said,issue,negative,neutral,neutral,neutral,neutral,neutral
515977260,"Hello,

Attempting to convert .wav to text file gives below exception:

deepspeech models/output_graph.pbm Thor.wav models/alphabet.txt models/lm.binary models/trie 

Loading model from file models/output_graph.pbm
2019-07-29 12:26:58.832839: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Not found: models/output_graph.pbm; No such file or directory
Loaded model in 0.001s.
Loading language model from files models/lm.binary models/trie
terminate called after throwing an instance of 'lm::FormatLoadException'
  what():  native_client/kenlm/lm/binary_format.cc:131 in void lm::ngram::MatchCheck(lm::ngram::ModelType, unsigned int, const lm::ngram::Parameters&) threw FormatLoadException.
The binary file was built for trie with quantization and array-compressed pointers but the inference code is trying to load probing hash tables
Aborted (core dumped)",hello convert text file exception loading model file binary use found file directory loaded model loading language model terminate throwing instance void unsigned threw binary file built quantization inference code trying load hash table aborted core,issue,negative,neutral,neutral,neutral,neutral,neutral
515941365,"You don't need to rebuild generate_trie, use the one packaged. Also use - - branch v0.5.1 for taskcluster.py ",need rebuild use one also use branch,issue,negative,neutral,neutral,neutral,neutral,neutral
515825896,"I didn't find any corrupted wave files by using my modified script: https://github.com/gqy2468/DeepSpeech/blob/master/bin/wav_check.py

Usage:
`python3 bin/wav_check.py data_thchs30/thchs30-train.csv`",find corrupted wave script usage python,issue,negative,neutral,neutral,neutral,neutral,neutral
515709833,"@gqy2468 This script may help: https://github.com/dabinat/deepspeech-tools/blob/master/wav_check.py

Usage:
`python3 wav_check.py <directory to scan> >/dev/null`",script may help usage python directory scan,issue,negative,neutral,neutral,neutral,neutral,neutral
515415609,I just gave you a tool to check if the file is not corrupted: https://github.com/mozilla/DeepSpeech/issues/2271#issuecomment-515354597,gave tool check file corrupted,issue,negative,neutral,neutral,neutral,neutral,neutral
515411267,I have checked all wave files and their sizes are all correct by using a shell script ! Now I have not any tools to check the file is not corrupted and I think the perhaps reason is my computer's memory is not enough ?!,checked wave size correct shell script check file corrupted think perhaps reason computer memory enough,issue,negative,neutral,neutral,neutral,neutral,neutral
515354597,"You most likely have a corrupted file in or around batch 3016. I'd sort the file by wav_filesize, then multiply your training batch size by 3000, let's say the batch size is 10. Then I'd take files 3000\*10 through 3010\*10, and run them with batch size 1. Then you'll be able to find out exactly what the problematic file is.",likely corrupted file around batch sort file multiply training batch size let say batch size take run batch size able find exactly problematic file,issue,negative,positive,positive,positive,positive,positive
515338709,"My training csv files were downloaded from http://blog.yuwu.me/wp-content/uploads/2018/07/thchs30-csv.tar.gz, and my training wave files were downloaded from http://www.openslr.org/resources/18/data_thchs30.tgz!
My training command is as follow:
`python3 -u DeepSpeech.py --alphabet_config_path data_thchs30/thchs30-alphabet.txt --lm_binary_path data_thchs30/thchs30-lm.binary --lm_trie_path data_thchs30/thchs30-trie --train_files data_thchs30/thchs30-train.csv --dev_files data_thchs30/thchs30-dev.csv --test_files data_thchs30/thchs30-test.csv --train_batch_size 3 --dev_batch_size 3 --test_batch_size 3 --n_hidden 512 --learning_rate 0.0001 --epoch 50 --checkpoint_dir thchs30-models --export_dir data_thchs30 --log_level 0`",training training wave training command follow python epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
515337283,"> My reference linking is https://discourse.mozilla.org/t/training-chinese-model/27769

? Can you elaborate ? That's not really helping ...",reference linking elaborate really helping,issue,negative,positive,positive,positive,positive,positive
515329798,"@gqy2468 Well, is it possible your file is just corrupted ? Anyway, if TensorFlow chokes on it, there's not much that we can do, except if it's a bug and assist you filing it upstream.",well possible file corrupted anyway much except bug assist filing upstream,issue,negative,positive,neutral,neutral,positive,positive
515326448,"The largest size of my wave files is only 436KB，it's bitrate is 256 kbps!
Strangely enough, this error was always happend when the elapsed time of my continuous training was about 2:36:00 and the steps was 3016 !!!",size wave strangely enough error always time continuous training,issue,negative,neutral,neutral,neutral,neutral,neutral
515303726,"By default, Wave files use 32-bit headers that limit them to 2 GB in size. Using a 64-bit header allows you to create much larger files.

It seems like DeepSpeech is expecting the file to have a 32-bit header and therefore be less than 2 GB. But that's a reasonable expectation since training usually occurs on lots of very short clips. What is the duration of your file?",default wave use limit size header create much like file header therefore le reasonable expectation since training usually lot short clip duration file,issue,positive,positive,neutral,neutral,positive,positive
514994872,"```
Average inference timings in us: Warmup: 27917.4, Init: 21528106, no stats: 23313.5
============================== Run Order ==============================
                     [node type]                  [start]         [first]        [avg ms]            [%]          [cdf%]          [mem KB]      [times called]  [Name]
                        DELEGATE                    0.000          21.227          21.287        91.329%         91.329%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BiasAdd]
                           SPLIT                   21.287           0.015           0.013         0.056%         91.385%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:1, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:2, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:3]
                             ADD                   21.300           0.021           0.022         0.093%         91.479%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/add]
                        LOGISTIC                   21.322           0.012           0.014         0.059%         91.538%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Sigmoid]
                             MUL                   21.336           0.005           0.007         0.029%         91.567%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/mul]
                        LOGISTIC                   21.343           0.010           0.010         0.045%         91.611%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Sigmoid_1]
                            TANH                   21.353           0.015           0.014         0.061%         91.672%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tanh]
                             MUL                   21.367           0.004           0.002         0.008%         91.680%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/mul_1]
                             ADD                   21.369           0.008           0.003         0.014%         91.694%             0.000              1       [new_state_c]
                        LOGISTIC                   21.373           0.012           0.010         0.045%         91.739%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Sigmoid_2]
                            TANH                   21.383           0.013           0.012         0.053%         91.792%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tanh_1]
                             MUL                   21.396           0.002           0.002         0.009%         91.802%             0.000              1       [new_state_h]
                 FULLY_CONNECTED                   21.398           1.114           1.178         5.053%         96.854%             0.000              1       [Relu_3]
                 FULLY_CONNECTED                   22.576           0.036           0.034         0.145%         96.999%             0.000              1       [BiasAdd_4]
                         SOFTMAX                   22.610           0.005           0.005         0.020%         97.019%             0.000              1       [logits]
                         RESHAPE                   22.615           0.003           0.002         0.009%         97.028%             0.000              1       [ExpandDims]
                AudioSpectrogram                   22.617           0.257           0.245         1.050%         98.078%             0.000              1       [AudioSpectrogram]
                            Mfcc                   22.862           0.389           0.447         1.917%         99.995%             0.000              1       [Mfcc]
                         RESHAPE                   23.309           0.002           0.001         0.005%        100.000%             0.000              1       [mfccs]

============================== Top by Computation Time ==============================
                     [node type]                  [start]         [first]        [avg ms]            [%]          [cdf%]          [mem KB]      [times called]  [Name]
                        DELEGATE                    0.000          21.227          21.287        91.329%         91.329%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BiasAdd]
                 FULLY_CONNECTED                   21.398           1.114           1.178         5.053%         96.382%             0.000              1       [Relu_3]
                            Mfcc                   22.862           0.389           0.447         1.917%         98.299%             0.000              1       [Mfcc]
                AudioSpectrogram                   22.617           0.257           0.245         1.050%         99.349%             0.000              1       [AudioSpectrogram]
                 FULLY_CONNECTED                   22.576           0.036           0.034         0.145%         99.494%             0.000              1       [BiasAdd_4]
                             ADD                   21.300           0.021           0.022         0.093%         99.588%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/add]
                            TANH                   21.353           0.015           0.014         0.061%         99.649%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tanh]
                        LOGISTIC                   21.322           0.012           0.014         0.059%         99.708%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Sigmoid]
                           SPLIT                   21.287           0.015           0.013         0.056%         99.764%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:1, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:2, cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/split:3]
                            TANH                   21.383           0.013           0.012         0.053%         99.817%             0.000              1       [cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tanh_1]

Number of nodes executed: 19
============================== Summary by node type ==============================
                     [Node type]          [count]         [avg ms]          [avg %]         [cdf %]       [mem KB]      [times called]
                        DELEGATE                1           21.286          91.364%         91.364%          0.000              1
                 FULLY_CONNECTED                2            1.210           5.194%         96.558%          0.000              2
                            Mfcc                1            0.446           1.914%         98.472%          0.000              1
                AudioSpectrogram                1            0.244           1.047%         99.519%          0.000              1
                        LOGISTIC                3            0.033           0.142%         99.661%          0.000              3
                            TANH                2            0.026           0.112%         99.773%          0.000              2
                             ADD                2            0.024           0.103%         99.876%          0.000              2
                           SPLIT                1            0.013           0.056%         99.931%          0.000              1
                             MUL                3            0.009           0.039%         99.970%          0.000              3
                         SOFTMAX                1            0.004           0.017%         99.987%          0.000              1
                         RESHAPE                2            0.003           0.013%        100.000%          0.000              2

Timings (microseconds): count=43 first=23150 curr=23055 min=22906 max=26011 avg=23307.6 std=486
Memory (bytes): count=0
19 nodes observed
```",average inference u run order node type start first mem time name delegate split add logistic logistic tanh add logistic tanh reshape reshape top computation time node type start first mem time name delegate add tanh logistic split tanh number executed summary node type node type count mem time delegate logistic tanh add split reshape memory,issue,negative,positive,positive,positive,positive,positive
514991842,"> SPLIT: Operation is not supported.

We still have that Op in the middle of the computation graph. As @reuben analyzed, this is coming from the LSTMCell. Likely if we figure out a way around, we could have all Ops on the GPU.",split operation still middle computation graph coming likely figure way around could,issue,negative,neutral,neutral,neutral,neutral,neutral
514991220,"Google Pixel 2 GPU delegation benchmark:
```
walleye:/data/local/tmp $ ./benchmark_model --graph=/sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048 --output_layer=logits,new_state_c,new_state_h --use_gpu=true                           
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Use legacy nnapi : [0]
Use gpu : [1]
Allow fp16 : [0]
Enable op profiling: [0]
Loaded model /sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: Next operations are not supported by GPU delegate:
CUSTOM AudioSpectrogram: Operation is not supported.
CUSTOM Mfcc: Operation is not supported.
SPLIT: Operation is not supported.
First 5 operations will run on the GPU, and the remaining 18 on the CPU.
INFO: Replacing 5 node(s) with delegate (TfLiteGpuDelegate) node.
Applied GPU delegate.
Initialized session in 21888ms
Running benchmark for at least 1 iterations and at least 0.5 seconds
count=13 first=81932 curr=30012 min=28637 max=81932 avg=39952.8 std=15000

Running benchmark for at least 50 iterations and at least 1 seconds
count=50 first=30008 curr=30004 min=29733 max=30206 avg=29980 std=104

Average inference timings in us: Warmup: 39952.8, Init: 21888050, no stats: 29980
walleye:/data/local/tmp $ ./benchmark_model --graph=/sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048 --output_layer=logits,new_state_c,new_state_h --use_gpu=false                          
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Use legacy nnapi : [0]
Use gpu : [0]
Allow fp16 : [0]
Enable op profiling: [0]
Loaded model /sdcard/Android/data/com.mozilla.speechmodule/files/models/eng/output_graph.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
Initialized session in 5.098ms
Running benchmark for at least 1 iterations and at least 0.5 seconds
count=51 first=63770 curr=8275 min=8260 max=63770 avg=9872.57 std=7754

Running benchmark for at least 50 iterations and at least 1 seconds
count=119 first=8354 curr=8297 min=8251 max=11718 avg=8448.37 std=641

Average inference timings in us: Warmup: 9872.57, Init: 5098, no stats: 8448.37
walleye:/data/local/tmp $ 
```

There are some model changes to get rid of the unsupported `StridedSlice`:
```
@@ -127,7 +127,8 @@ def rnn_impl_static_rnn(x, seq_length, previous_state, reuse):
                                             name='cudnn_compatible_lstm_cell')

         # Split rank N tensor into list of rank N-1 tensors
-        x = [x[l] for l in range(x.shape[0])]
+        # x = [x[l] for l in range(x.shape[0])]
+        x = [tf.squeeze(x, axis=0)]

         output, output_state = tfv1.nn.static_rnn(cell=fw_cell,
                                                   inputs=x,
@@ -136,7 +137,8 @@ def rnn_impl_static_rnn(x, seq_length, previous_state, reuse):
                                                   dtype=tf.float32,
                                                   scope='cell_0')

-        output = tf.concat(output, 0)
+        # output = tf.concat(output, 0)
+        output = output[0]

     return output, output_state

```

Some for removing `Minimum` (obviously not a valid solution, just to get the model to run):
```
@@ -70,7 +70,7 @@ def dense(name, x, units, dropout_rate=None, relu=True):
     output = tf.nn.bias_add(tf.matmul(x, weights), bias)
                                                                     
     if relu:                                                   
-        output = tf.minimum(tf.nn.relu(output), FLAGS.relu_clip)
+        output = tf.nn.relu(output)

     if dropout_rate is not None:
         output = tf.nn.dropout(output, rate=dropout_rate)
```

And some shape changes to avoid shader compilation, as well as moving the `AudioSpectrogram` and `Mfcc` nodes at the end, otherwise GPU delegation code will choke early on those and place no op on the GPU:
```
@@ -156,7 +158,7 @@ def create_model(batch_x, batch_size, seq_length, dropout, reuse=False, previous
     # This is done to prepare the batch for input into the first layer which expects a tensor of rank `2`.

     # Permute n_steps and batch_size
-    batch_x = tf.transpose(batch_x, [1, 0, 2, 3])
+    #batch_x = tf.transpose(batch_x, [1, 0, 2, 3])
     # Reshape to prepare input for first layer
     batch_x = tf.reshape(batch_x, [-1, Config.n_input + 2*Config.n_input*Config.n_context]) # (n_steps*batch_size, n_input + 2*n_input*n_context)
     layers['input_reshaped'] = batch_x
@@ -596,17 +598,12 @@ def test():
 def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
     batch_size = batch_size if batch_size > 0 else None

-    # Create feature computation graph
-    input_samples = tfv1.placeholder(tf.float32, [Config.audio_window_samples], 'input_samples')
-    samples = tf.expand_dims(input_samples, -1)
-    mfccs, _ = samples_to_mfccs(samples, FLAGS.audio_sample_rate)
-    mfccs = tf.identity(mfccs, name='mfccs')
-
     # Input tensor will be of shape [batch_size, n_steps, 2*n_context+1, n_input]
     # This shape is read by the native_client in DS_CreateModel to know the
     # value of n_steps, n_context and n_input. Make sure you update the code
     # there if this shape is changed.
     input_tensor = tfv1.placeholder(tf.float32, [batch_size, n_steps if n_steps > 0 else None, 2 * Config.n_context + 1, Config.n_input], name='input_node')
+    input_tensor = tf.reshape(input_tensor, [-1, Config.n_input + 2*Config.n_input*Config.n_context])
     seq_length = tfv1.placeholder(tf.int32, [batch_size], name='input_lengths')

     if batch_size <= 0:
@@ -663,6 +660,12 @@ def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
     new_state_c = tf.identity(new_state_c, name='new_state_c')
     new_state_h = tf.identity(new_state_h, name='new_state_h')

+    # Create feature computation graph
+    input_samples = tfv1.placeholder(tf.float32, [Config.audio_window_samples], 'input_samples')
+    samples = tf.expand_dims(input_samples, -1)
+    mfccs, _ = samples_to_mfccs(samples, FLAGS.audio_sample_rate)
+    mfccs = tf.identity(mfccs, name='mfccs')
+
     inputs = {
         'input': input_tensor,
         'previous_state_c': previous_state_c,
```",delegation walleye float float starting number must match number example input min min duration delay name output prefix min min duration graph input input use use legacy use allow enable loaded model resolved reporter lite lite delegate error next delegate custom operation custom operation split operation first run node delegate node applied delegate session running least least running least least average inference u walleye float float starting number must match number example input min min duration delay name output prefix min min duration graph input input use use legacy use allow enable loaded model resolved reporter lite session running least least running least least average inference u walleye model get rid unsupported reuse split rank tensor list rank range range output reuse output output output output output output return output removing minimum obviously valid solution get model run dense name output bias output output output output none output output shape avoid shader compilation well moving end otherwise delegation code choke early place dropout previous done prepare batch input first layer tensor rank permute reshape prepare input first layer test else none create feature computation graph input tensor shape shape read know value make sure update code shape else none create feature computation graph,issue,negative,negative,negative,negative,negative,negative
514481520,"Results so far, on Google Pixel 2.

For NNAPI delegate:
 - use of NNAPI does not look faster
 - `lite_benchmark_model` shows a slow **increase** in average execution time

For GPU OpenGL ES delegate:
 - GPU delegation does not work by default, leading to a segfault
 - this could be tracked down to GraphFloat32 having 0 element after `ApplyGeneralTransformations`
 - likely cause is:
```07-23 20:32:49.714 28449 28449 I tflite  : Checking op 1/240: CUSTOM AudioSpectrogram !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 2/240: CUSTOM Mfcc !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 5/240: MINIMUM !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 7/240: MINIMUM !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 9/240: MINIMUM !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 11/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 12/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 13/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 14/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 15/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 16/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 17/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 18/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 19/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 20/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 21/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 22/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 23/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 24/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 25/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 26/240: STRIDED_SLICE !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 29/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 42/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.714 28449 28449 I tflite  : Checking op 55/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 68/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 81/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 94/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 107/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 120/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 133/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 146/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 159/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.715 28449 28449 I tflite  : Checking op 172/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.716 28449 28449 I tflite  : Checking op 185/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.716 28449 28449 I tflite  : Checking op 198/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.716 28449 28449 I tflite  : Checking op 211/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.716 28449 28449 I tflite  : Checking op 224/240: SPLIT !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
07-23 20:32:49.716 28449 28449 I tflite  : Checking op 237/240: MINIMUM !status.ok() isAllFloatInputs=1 isAllFloatOutputs=1
```

So as expected, custom ops have no gpu delegate implementation, but `minimum` and `split` either. And it seems our use of `strided slice` is not compatible.",far delegate use look faster slow increase average execution time e delegate delegation work default leading could tracked element likely cause custom custom minimum minimum minimum split split split split split split split split split split split split split split split split minimum custom delegate implementation minimum split either use slice compatible,issue,negative,negative,neutral,neutral,negative,negative
514480806,"Tentative patch:
```
diff --git a/native_client/BUILD b/native_client/BUILD
index ba7f8f5db..2d44ba000 100644
--- a/native_client/BUILD
+++ b/native_client/BUILD
@@ -98,6 +98,7 @@ tf_cc_shared_object(
     deps = select({
         ""//native_client:tflite"": [
             ""//tensorflow/lite/kernels:builtin_ops"",
+            ""//tensorflow/lite/tools/evaluation:utils"",
         ],
         ""//conditions:default"": [
             ""//tensorflow/core:core_cpu"",
diff --git a/native_client/tflitemodelstate.cc b/native_client/tflitemodelstate.cc
index 8c61a83f1..32e6915cd 100644
--- a/native_client/tflitemodelstate.cc
+++ b/native_client/tflitemodelstate.cc
@@ -1,5 +1,15 @@
 #include ""tflitemodelstate.h""
 
+#ifdef __ANDROID__
+#include <android/log.h>
+#define  LOG_TAG    ""libdeepspeech""
+#define  LOGD(...)  __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, __VA_ARGS__)
+#define  LOGE(...)  __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)
+#else
+#define  LOGD(...)
+#define  LOGE(...)
+#endif // __ANDROID__
+
 using namespace tflite;
 using std::vector;
 
@@ -87,6 +97,42 @@ TFLiteModelState::~TFLiteModelState()
 {
 }
 
+std::map<std::string, tflite::Interpreter::TfLiteDelegatePtr>
+TFLiteModelState::get_delegates()
+{
+  std::map<std::string, tflite::Interpreter::TfLiteDelegatePtr> delegates;
+
+#ifndef __ANDROID__
+  LOGE(""Trying to get GPU delegate ..."");
+  // Try to get GPU delegate
+  {
+    tflite::Interpreter::TfLiteDelegatePtr delegate = evaluation::CreateGPUDelegate(fbmodel_.get());
+    if (!delegate) {
+      LOGE(""GPU delegation not supported"");
+    } else {
+      LOGE(""GPU delegation supported"");
+      delegates.emplace(""GPU"", std::move(delegate));
+    }
+  }
+#endif
+
+#ifdef __ANDROID__
+  LOGE(""Trying to get NNAPI delegate ..."");
+  // Try to get Android NNAPI delegate
+  {
+    tflite::Interpreter::TfLiteDelegatePtr delegate = evaluation::CreateNNAPIDelegate();
+    if (!delegate) {
+      LOGE(""NNAPI delegation not supported"");
+    } else {
+      LOGE(""NNAPI delegation supported"");
+      delegates.emplace(""NNAPI"", std::move(delegate));
+    }
+  }
+#endif 
+
+  return delegates;
+}
+
 int
 TFLiteModelState::init(const char* model_path,
                        unsigned int n_features,
@@ -112,9 +158,20 @@ TFLiteModelState::init(const char* model_path,
     return DS_ERR_FAIL_INTERPRETER;
   }
 
+  LOGE(""Trying to detect delegates ..."");
+  delegates_ = get_delegates();
+  LOGE(""Finished enumerating delegates ..."");
   interpreter_->AllocateTensors();
   interpreter_->SetNumThreads(4);
 
+  LOGE(""Trying to use delegates ..."");
+  for (const auto& delegate : delegates_) {
+    LOGE(""Trying to apply delegate %s"", delegate.first.c_str());
+    if (interpreter_->ModifyGraphWithDelegate(delegate.second.get()) != kTfLiteOk) {
+      LOGE(""FAILED to apply delegate %s to the graph"", delegate.first.c_str());
+    }
+  }
+
   // Query all the index once
   input_node_idx_       = get_input_tensor_by_name(""input_node"");
   previous_state_c_idx_ = get_input_tensor_by_name(""previous_state_c"");
diff --git a/native_client/tflitemodelstate.h b/native_client/tflitemodelstate.h
index 3a6d4971e..5bf19e281 100644
--- a/native_client/tflitemodelstate.h
+++ b/native_client/tflitemodelstate.h
@@ -6,6 +6,7 @@
 
 #include ""tensorflow/lite/model.h""
 #include ""tensorflow/lite/kernels/register.h""
+#include ""tensorflow/lite/tools/evaluation/utils.h""
 
 #include ""modelstate.h""
 
@@ -58,6 +59,9 @@ struct TFLiteModelState : public ModelState
   void copy_tensor_to_vector(int tensor_idx,
                              int num_elements,
                              std::vector<float>& vec);
+
+  std::map<std::string, tflite::Interpreter::TfLiteDelegatePtr> get_delegates();
+  std::map<std::string, tflite::Interpreter::TfLiteDelegatePtr> delegates_;
 };
 
 #endif // TFLITEMODELSTATE_H
```",tentative patch git index select default git index include include define define define loge else define define loge loge trying get delegate try get delegate delegate evaluation delegate loge delegation else loge delegation delegate loge trying get delegate try get android delegate delegate evaluation delegate loge delegation else loge delegation delegate return char unsigned char return loge trying detect loge finished loge trying use auto delegate loge trying apply delegate loge apply delegate graph query index git index ade include include include include public void float,issue,negative,neutral,neutral,neutral,neutral,neutral
514302094,"That repo doesn't have releases, just tags. We could create our own tags but I'm not sure how useful that'd be. In every documentation we tell people to clone the repo and use the r1.14 *branch*, not a tag.",could create sure useful every documentation tell people clone use branch tag,issue,positive,positive,positive,positive,positive,positive
514302068,"> A potential gotcha that confused me is that the source code zip files on the Releases page of the mozilla/tensorflow repo are not the same as what's in the branch trees so you get compilation errors.

Are you talking about https://github.com/mozilla/tensorflow/releases ?

Those tags are from upstream, and the page gets generated automatically.



> So downloading from the Releases page is like not using the Mozilla fork at all.

We never, ever, document doing that.",potential confused source code zip page branch get compilation talking upstream page automatically page like fork never ever document,issue,negative,negative,negative,negative,negative,negative
514193216,"Oh, something I forgot to mention. In this PR, everywhere that says ""pertubation"" should say ""perturbation"" (note the added 'r'). Including file names, documentation, etc.",oh something forgot mention everywhere say perturbation note added file documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
514175023,"> The point of this PR was to resample training samples to 16khz to help with inference(since inference is at 16khz)

Yes, but your message states that inference only handles 16kHz when I showed you it's not the case, so I can't know for you what you want, I'm just pointing out that your first assumption is wrong.



> Training with 44.1khz or 22khz and then running inference on 16khz would be detrimental for the model, wouldn't it?

Yes, it's not expected to work at all.

There could be value in ensuring that training can be done at other sample rates than 16kHz, but I'm unsure that resampling is the proper solution, to be honest.",point resample training help inference since inference yes message inference case ca know want pointing first assumption wrong training running inference would detrimental model would yes work could value training done sample unsure proper solution honest,issue,positive,positive,neutral,neutral,positive,positive
514172445,"> It should be possible to train with others, see discussions on discourse and gitub.

The point of this PR was to resample training samples to 16khz to help with inference(since inference is at 16khz). Training with 44.1khz or 22khz and then running inference on 16khz would be detrimental for the model, wouldn't it? Or is that also handled somewhere in the code which i missed? I'll move this to discourse(If I need a longer discussion). sorry for the clutter.
",possible train see discourse point resample training help inference since inference training running inference would detrimental model would also handled somewhere code move discourse need longer discussion sorry clutter,issue,negative,negative,negative,negative,negative,negative
514163498,"> Oh wait. So is the training restraint to 16khz?

It should be possible to train with others, see discussions on discourse and gitub.",oh wait training restraint possible train see discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
514163135,Oh wait. So is the training restraint to 16khz? ,oh wait training restraint,issue,negative,neutral,neutral,neutral,neutral,neutral
514152111,"> Ah got it. I was using DeepSpeech.py instead of this wrapper. Thanks for pointing this out.

`DeepSpeech.py` is the code for **training**, this code is for **inference** ...",ah got instead wrapper thanks pointing code training code inference,issue,negative,positive,positive,positive,positive,positive
514140751,Ah got it. I was using DeepSpeech.py instead of this wrapper. Thanks for pointing this out.,ah got instead wrapper thanks pointing,issue,negative,positive,positive,positive,positive,positive
514126974,">Currently, only 16-bit, 16 kHz, mono-channel WAVE audio files are supported in the Python client.

@lissyx 
^^ Did i misinterpret this bit? This was in the main ReadMe

I missed where it was done in code. I'll check again.
",currently wave audio python client misinterpret bit main done code check,issue,negative,positive,neutral,neutral,positive,positive
514125228,">  I understand that the python client only supports 16khz currently, so I thought we could just resample the dataset to 16khz if the files are not in 16khz and then train it.

We explicitely have code to leverage `sox` and do that. So I don't know where you understanding comes, but it's wrong.",understand python client currently thought could resample train code leverage know understanding come wrong,issue,negative,negative,negative,negative,negative,negative
514110226,"I'm able to get a CoreML model out of the converter using latest master by removing the MFCC feature computation subgraph as well as the model_metadata node. Here's what I did:

```bash
$ cd DeepSpeech
$ cat <<EOF | patch -p1 -
diff --git a/DeepSpeech.py b/DeepSpeech.py
index 19e16d3..15b4c10 100755
--- a/DeepSpeech.py
+++ b/DeepSpeech.py
@@ -597,10 +597,10 @@ def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
     batch_size = batch_size if batch_size > 0 else None
 
     # Create feature computation graph
-    input_samples = tfv1.placeholder(tf.float32, [Config.audio_window_samples], 'input_samples')
-    samples = tf.expand_dims(input_samples, -1)
-    mfccs, _ = samples_to_mfccs(samples, FLAGS.audio_sample_rate)
-    mfccs = tf.identity(mfccs, name='mfccs')
+    # input_samples = tfv1.placeholder(tf.float32, [Config.audio_window_samples], 'input_samples')
+    # samples = tf.expand_dims(input_samples, -1)
+    # mfccs, _ = samples_to_mfccs(samples, FLAGS.audio_sample_rate)
+    # mfccs = tf.identity(mfccs, name='mfccs')
 
     # Input tensor will be of shape [batch_size, n_steps, 2*n_context+1, n_input]
     # This shape is read by the native_client in DS_CreateModel to know the
@@ -667,7 +667,7 @@ def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
         'input': input_tensor,
         'previous_state_c': previous_state_c,
         'previous_state_h': previous_state_h,
-        'input_samples': input_samples,
+        # 'input_samples': input_samples,
     }
 
     if not FLAGS.export_tflite:
@@ -677,7 +677,7 @@ def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
         'outputs': logits,
         'new_state_c': new_state_c,
         'new_state_h': new_state_h,
-        'mfccs': mfccs,
+        # 'mfccs': mfccs,
     }
 
     return inputs, outputs, layers
@@ -699,7 +699,15 @@ def export():
     output_names = "","".join(output_names_tensors + output_names_ops)
 
     # Create a saver using variables from the above newly created graph
-    saver = tfv1.train.Saver()
+    # Create a saver using variables from the above newly created graph
+    def fixup(name):
+        if name.startswith('cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/'):
+            return name.replace('cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/', 'lstm_fused_cell/')
+        return name
+    mapping = {fixup(v.op.name): v for v in tfv1.global_variables()}
+    import pprint
+    pprint.pprint(mapping)
+    saver = tfv1.train.Saver(mapping)
 
     # Restore variables from training checkpoint
     checkpoint = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)
@@ -741,14 +749,14 @@ def export():
             frozen_graph.version = int(file_relative_read('GRAPH_VERSION').strip())
 
             # Add a no-op node to the graph with metadata information to be loaded by the native client
-            metadata = frozen_graph.node.add()
-            metadata.name = 'model_metadata'
-            metadata.op = 'NoOp'
-            metadata.attr['sample_rate'].i = FLAGS.audio_sample_rate
-            metadata.attr['feature_win_len'].i = FLAGS.feature_win_len
-            metadata.attr['feature_win_step'].i = FLAGS.feature_win_step
-            if FLAGS.export_language:
-                metadata.attr['language'].s = FLAGS.export_language.encode('ascii')
+            # metadata = frozen_graph.node.add()
+            # metadata.name = 'model_metadata'
+            # metadata.op = 'NoOp'
+            # metadata.attr['sample_rate'].i = FLAGS.audio_sample_rate
+            # metadata.attr['feature_win_len'].i = FLAGS.feature_win_len
+            # metadata.attr['feature_win_step'].i = FLAGS.feature_win_step
+            # if FLAGS.export_language:
+            #     metadata.attr['language'].s = FLAGS.export_language.encode('ascii')
 
             with open(output_graph_path, 'wb') as fout:
                 fout.write(frozen_graph.SerializeToString())
EOF
$ python DeepSpeech.py --checkpoint_dir ~/Downloads/deepspeech-0.5.1-checkpoint --n_hidden 2048 --export_dir ~/Downloads/v0.5.1-reexport-coreml
$ ipython
Python 3.7.4 (default, Jul  9 2019, 18:13:23)
Type 'copyright', 'credits' or 'license' for more information
IPython 7.6.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tfcoreml as tf_converter

In [2]: tf_converter.convert(tf_model_path='/Users/reubenmorais/Downloads/v0.5.1-reexport-coreml/output_graph.pb', mlmodel_path='/Users/reubenmorais/Downloads/v0.5.1-reexport-coreml/deepspeech.mlmodel', output_feature_names=['logits', 'new_state_c', 'new_state_h'], input_
   ...: name_shape_dict={ 'input_node': [1,16,19,26], 'input_lengths': [1],  'previous_state_c': [1,2048], 'previous_state_h': [1,2048]}, use_coreml_3=True)
W0723 10:22:30.756310 4457440704 deprecation_wrapper.py:119] From /Users/reubenmorais/.local/share/virtualenvs/DeepSpeech-s4g1Z3_U/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/tensorflow/graphdef_to_ssa.py:21: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0723 10:22:30.756505 4457440704 deprecation_wrapper.py:119] From /Users/reubenmorais/.local/share/virtualenvs/DeepSpeech-s4g1Z3_U/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/tensorflow/graphdef_to_ssa.py:22: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.

0 assert nodes deleted
W0723 10:22:33.274496 4457440704 deprecation_wrapper.py:119] From /Users/reubenmorais/.local/share/virtualenvs/DeepSpeech-s4g1Z3_U/lib/python3.7/site-packages/coremltools/converters/nnssa/frontend/tensorflow/graph_pass/constant_propagation.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-23 10:22:33.274982: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
['cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/limit:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/read:0', 'layer_1/weights/read:0', 'layer_1/bias:0', 'layer_3/weights:0', 'layer_5/bias:0', 'layer_5/weights:0', 'layer_6/weights/read:0', 'layer_5/bias/read:0', 'layer_6/weights:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose/perm:0', 'layer_3/bias:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1:0', 'Minimum_3/y:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1/axis:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/limit:0', 'Reshape_1/shape:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Const:0', 'layer_6/bias:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel:0', 'layer_3/bias/read:0', 'layer_1/weights:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile/multiples:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_2:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias:0', 'raw_logits/shape:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/delta:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2/dim:0', 'Reshape/shape:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Range:0', 'Minimum/y:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat/axis:0', 'layer_3/weights/read:0', 'layer_6/bias/read:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims/dim:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/delta:0', 'layer_5/weights/read:0', 'layer_1/bias/read:0', 'transpose/perm:0', 'Minimum_1/y:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_1:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/shape_as_tensor:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1/dim:0', 'layer_2/bias:0', 'Minimum_2/y:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/start:0', 'layer_2/bias/read:0', 'layer_2/weights/read:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/read:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/start:0', 'Reshape_2/shape:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/Const:0', 'layer_2/weights:0', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims/dim:0']
23 nodes deleted
0 nodes deleted
0 nodes deleted
[Op Fusion] fuse_bias_add() deleted 10 nodes.
6 identity nodes deleted
5 disconnected nodes deleted
[SSAConverter] Converting function main ...
[SSAConverter] [1/64] Converting op input_node: Placeholder
[SSAConverter] [2/64] Converting op input_lengths: Placeholder
[SSAConverter] [3/64] Converting op previous_state_c: Placeholder
[SSAConverter] [4/64] Converting op previous_state_h: Placeholder
[SSAConverter] [5/64] Converting op transpose/perm: Const
[SSAConverter] [6/64] Converting op Reshape/shape: Const
[SSAConverter] [7/64] Converting op Minimum/y: Const
[SSAConverter] [8/64] Converting op Minimum_1/y: Const
[SSAConverter] [9/64] Converting op Minimum_2/y: Const
[SSAConverter] [10/64] Converting op Reshape_1/shape: Const
[SSAConverter] [11/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/read: Const
[SSAConverter] [12/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/read: Const
[SSAConverter] [13/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Range: Const
[SSAConverter] [14/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims/dim: Const
[SSAConverter] [15/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose/perm: Const
[SSAConverter] [16/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims/dim: Const
[SSAConverter] [17/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile/multiples: Const
[SSAConverter] [18/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1/dim: Const
[SSAConverter] [19/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat/axis: Const
[SSAConverter] [20/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2/dim: Const
[SSAConverter] [21/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1/axis: Const
[SSAConverter] [22/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range: Const
[SSAConverter] [23/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1: Const
[SSAConverter] [24/64] Converting op Reshape_2/shape: Const
[SSAConverter] [25/64] Converting op Minimum_3/y: Const
[SSAConverter] [26/64] Converting op raw_logits/shape: Const
[SSAConverter] [27/64] Converting op transpose: Transpose
[SSAConverter] [28/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims: ExpandDims
[SSAConverter] [29/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1: ExpandDims
[SSAConverter] [30/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2: ExpandDims
[SSAConverter] [31/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack: Pack
[SSAConverter] [32/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack_1: Pack
[SSAConverter] [33/64] Converting op Reshape: Reshape
[SSAConverter] [34/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast: Cast
[SSAConverter] [35/64] Converting op MatMul: MatMul
[SSAConverter] [36/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Less: Less
[SSAConverter] [37/64] Converting op Relu: Relu
[SSAConverter] [38/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast_1: Cast
[SSAConverter] [39/64] Converting op Minimum: Minimum
[SSAConverter] [40/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose: Transpose
[SSAConverter] [41/64] Converting op MatMul_1: MatMul
[SSAConverter] [42/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims: ExpandDims
[SSAConverter] [43/64] Converting op Relu_1: Relu
[SSAConverter] [44/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile: Tile
[SSAConverter] [45/64] Converting op Minimum_1: Minimum
[SSAConverter] [46/64] Converting op MatMul_2: MatMul
[SSAConverter] [47/64] Converting op Relu_2: Relu
[SSAConverter] [48/64] Converting op Minimum_2: Minimum
[SSAConverter] [49/64] Converting op Reshape_1: Reshape
[SSAConverter] [50/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/LSTMBlock: LSTMBlock
[SSAConverter] [51/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/get_tuple: get_tuple
[SSAConverter] [52/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM/get_tuple_0: get_tuple
[SSAConverter] [53/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/mul: Mul
[SSAConverter] [54/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat: ConcatV2
[SSAConverter] [55/64] Converting op cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1: ConcatV2
[SSAConverter] [56/64] Converting op Reshape_2: Reshape
[SSAConverter] [57/64] Converting op new_state_c: GatherNd
[SSAConverter] [58/64] Converting op new_state_h: GatherNd
[SSAConverter] [59/64] Converting op MatMul_3: MatMul
[SSAConverter] [60/64] Converting op Relu_3: Relu
[SSAConverter] [61/64] Converting op Minimum_3: Minimum
[SSAConverter] [62/64] Converting op MatMul_4: MatMul
[SSAConverter] [63/64] Converting op raw_logits: Reshape
[SSAConverter] [64/64] Converting op logits: Softmax
[MLModel Pass] 15 disconnected constants are removed from graph.
/Users/reubenmorais/.local/share/virtualenvs/DeepSpeech-s4g1Z3_U/lib/python3.7/site-packages/coremltools/models/model.py:109: RuntimeWarning: You will not be able to run predict() on this Core ML model. Underlying exception message was: Error compiling model: ""Error reading protobuf spec. validator error: The .mlmodel supplied is of version 4, intended for a newer version of Xcode. This version of Xcode supports model version 3 or earlier."".
  RuntimeWarning)
Out[4]:
input {
  name: ""input_lengths""
  type {
    multiArrayType {
      shape: 1
      dataType: DOUBLE
    }
  }
}
input {
  name: ""input_node""
  type {
    multiArrayType {
      shape: 1
      shape: 16
      shape: 19
      shape: 26
      dataType: DOUBLE
    }
  }
}
input {
  name: ""previous_state_c""
  type {
    multiArrayType {
      shape: 1
      shape: 2048
      dataType: DOUBLE
    }
  }
}
input {
  name: ""previous_state_h""
  type {
    multiArrayType {
      shape: 1
      shape: 2048
      dataType: DOUBLE
    }
  }
}
output {
  name: ""logits""
  type {
    multiArrayType {
      dataType: DOUBLE
    }
  }
}
output {
  name: ""new_state_c""
  type {
    multiArrayType {
      dataType: DOUBLE
    }
  }
}
output {
  name: ""new_state_h""
  type {
    multiArrayType {
      dataType: DOUBLE
    }
  }
}

```",able get model converter latest master removing feature computation well node bash cat patch git index else none create feature computation graph input tensor shape shape read know return export create saver newly graph saver create saver newly graph name return return name import saver restore training export add node graph information loaded native client open python python default type information enhanced interactive python type help import name please use instead name please use instead assert name please use instead binary use fusion identity disconnected converting function main converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting converting transpose transpose converting converting converting converting pack converting pack converting reshape reshape converting cast converting converting le converting converting cast converting minimum minimum converting transpose converting converting converting converting tile converting minimum converting converting converting minimum converting reshape converting converting converting converting converting converting converting reshape converting converting converting converting converting minimum converting converting reshape converting pas disconnected removed graph able run predict core model underlying exception message error model error reading spec error version intended version version model version input name type shape double input name type shape shape shape shape double input name type shape shape double input name type shape shape double output name type double output name type double output name type double,issue,negative,positive,positive,positive,positive,positive
514091126,"> Ok I'll be retrying this some time later this month. Actually stuck with other things in my project. So will get back to you soon. But I don't think its anything missing in your documentation. I seem to be missing something somewhere. I'll retry this from scratch soon

So since there is no bug here, I'll advise you to instead come and discuss for help on Discourse rather than Github. I'm closing that issue.",time later month actually stuck project get back soon think anything missing documentation seem missing something somewhere retry scratch soon since bug advise instead come discus help discourse rather issue,issue,negative,negative,neutral,neutral,negative,negative
514090849,"I'm going to close that since it's not a bug and the questions is addressed. Please @Aravindraj92 use Discourse if you have questions, we use Github for bugs only.",going close since bug please use discourse use,issue,negative,neutral,neutral,neutral,neutral,neutral
513879844,"The unit for the timing is seconds.

But be aware that the times listed are when DeepSpeech figured out that a letter was being uttered. So it might be slightly later than the exact point at which the letter actually begins being spoken.",unit timing aware time listed figured letter might slightly later exact point letter actually spoken,issue,negative,positive,positive,positive,positive,positive
513783780,"> Prod tests looking green with the updated model. I've also found out I can remove two more op libs from the deps (bitwise_ops and random_ops), but I'll do that in a X-DeepSpeech: NOBUILD follow-up since the warnings aren't tested for anyway.

Just make sure you test also on CUDA devices, I've ran into funny business trying to aggressively remove ops :)",prod looking green model also found remove two since tested anyway make sure test also ran funny business trying aggressively remove,issue,negative,positive,positive,positive,positive,positive
513779583,"Prod tests looking green with the updated model. I've also found out I can remove two more op libs from the deps (bitwise_ops and random_ops), but I'll do that in a X-DeepSpeech: NOBUILD follow-up since the warnings aren't tested for anyway.",prod looking green model also found remove two since tested anyway,issue,negative,negative,negative,negative,negative,negative
513579168,"If the docker image is built you should have all the necessary binaries in it, no? Can't you get a shell into the machine or something? Then you could follow the rest of the docs.",docker image built necessary ca get shell machine something could follow rest,issue,negative,neutral,neutral,neutral,neutral,neutral
513576144,"And wait, you are running docker on windows? I have no idea what you should expect... ",wait running docker idea expect,issue,negative,neutral,neutral,neutral,neutral,neutral
513575541,"This is a contributed docker image. If you read it, you will learn it's just to build it for GPU.

""run it to convert STT"" can have a lot of ways of being done... We can't provide a dockerfile for each use case. Please read the documentation about inference.

If you were to describe better your use case and/or search on discourse we may be able to help more. In the current scope you still have not explained what your docker command line does in real. No logging, nothing, so we are blind regarding your issue. ",docker image read learn build run convert lot way done ca provide use case please read documentation inference describe better use case search discourse may able help current scope still docker command line real logging nothing blind regarding issue,issue,positive,positive,positive,positive,positive,positive
513574297,Docker image succesfully built but how to run it to make it convert TTS? Nothing about docker given in documentation?,docker image built run make convert nothing docker given documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
513551987,"> Yes, i want to be able to run these dockerfile as it is already there so that I can convert TTS

`docker build -t Dockerfile .` works for us.",yes want able run already convert docker build work u,issue,negative,positive,positive,positive,positive,positive
513551491,"Yes, i want to be able to run these dockerfile as it is already there so that I can convert TTS",yes want able run already convert,issue,negative,positive,positive,positive,positive,positive
513546662,"> So how to build and run it?

Have you read the documentation ? What are you trying to achieve ?",build run read documentation trying achieve,issue,negative,neutral,neutral,neutral,neutral,neutral
513538338,"I'm pretty new to this so first I installed docker and docker compose in the terminal, then I did docker build -t deepspeech https://github.com/mozilla/DeepSpeech.git, This error throws up in the 53rd step that's bazel build.",pretty new first docker docker compose terminal docker build error step build,issue,negative,positive,positive,positive,positive,positive
513534840,How did you set things up for the build? Can you manually go to the DeepSpeech/native_client folder and run `git describe --long --tags`?,set build manually go folder run git describe long,issue,negative,negative,neutral,neutral,negative,negative
513523956,"@chazanov While it would be nice to get that working, I am unable to claim that package at this time due to a lack of time. @NicoHood ping re that upkeep, it's been awhile...",would nice get working unable claim package time due lack time ping upkeep awhile,issue,negative,negative,neutral,neutral,negative,negative
513506888,@9define May you please claim https://aur.archlinux.org/packages/deepspeech/ ? It doesn't build since a long time.,define may please claim build since long time,issue,negative,negative,neutral,neutral,negative,negative
513487474,I have restructured the augmentation framework. Created augmentation as a separate module all together in the utils which has two types of augmentation techniques for audio augmentation and spectrogram augmentation. As of now not integrating the spec augment into feeding.py because it requires mel_filterbanks not `contrib_audio.audio_spectrogram and contrib_audio.mfcc`.,augmentation framework augmentation separate module together two augmentation audio augmentation spectrogram augmentation spec augment,issue,negative,neutral,neutral,neutral,neutral,neutral
513485464,"


> We don't want and need local wheels. Upstream should be used.

Okay , Thank. actually I'm getting this error while building.
ERROR: Process exited with status 128: Process exited with status 128
++ git describe --long --tags
+ tf_git_rev=v1.14.0-14-g1aad02a78e
+ echo 'STABLE_TF_GIT_VERSION v1.14.0-14-g1aad02a78e'
+ pushd native_client
++ git describe --long --tags
fatal: No names found, cannot describe anything.
+ ds_git_rev=
STABLE_TF_GIT_VERSION v1.14.0-14-g1aad02a78e
/tensorflow/native_client /tensorflow
INFO: Elapsed time: 165.796s, Critical Path: 26.41s
INFO: 10 processes: 10 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
The command '/bin/sh -c bazel build --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --config=monolithic --config=cuda -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}' returned a non-zero code: 1
",want need local upstream used thank actually getting error building error process status process status git describe long echo git describe long fatal found describe anything time critical path local build complete successfully build complete successfully command build bash opt returned code,issue,negative,positive,positive,positive,positive,positive
513485145,"I can't really figure out how simpler it might be. In timestamp data, time is the time the word appears and duration is its length? Cc @dabinat who landed this ",ca really figure simpler might data time time word duration length landed,issue,negative,positive,positive,positive,positive,positive
513465246,"> Unless something can be done to speed things up, a slowdown by a factor of over 8.5 times seems unacceptable to me.

Wait. Let me try and clarify a few things here.
It is 8.5(13hrs; it is actually more because the epoch isn't completed) times only if you modulate every sample. But that is not necessary. It is only 1.6(2hr 30 mins) times if you modulate 10% of the samples(Right now, when the epoch timing is 2 and a half hours, the pitch_shifing and time_streching is not mutually exclusive, i.e., More variety of data but more time invested. This could be made mutually exclusive to improve time consumption).

> In addition we are in the process of increasing the size of the data set we train on by about a factor of 4 or more.

This augmentation would(theoretically; Testing ongoing) help for smaller datasets where 1.6x(which could be lowered) would not scale so quickly. But on the flip side, It does make available a new set of data each epoch for better generalizability. This is the hypothesis, I am testing this now(might till Monday or Tuesday before I get concrete anything).
(@lissyx This is why I was supposing the tradeoff between time and data modified was acceptable. Theoretically, near uncountable data variation helping smaller dataset generalize)


>unless something can be done to speed things up

All that said, speeding up still takes top priority, will try and improve performance. 


Also, The augmention can be turned off in the flags, if necessary. 


If this clears something up, what concerns would you still have?

",unless something done speed slowdown factor time unacceptable wait let try clarify actually epoch time modulate every sample necessary time modulate right epoch timing half mutually exclusive variety data time could made mutually exclusive improve time consumption addition process increasing size data set train factor augmentation would theoretically testing ongoing help smaller could would scale quickly flip side make available new set data epoch better hypothesis testing might till get concrete anything supposing time data acceptable theoretically near uncountable data variation helping smaller generalize unless something done speed said speeding still top priority try improve performance also turned necessary something would still,issue,positive,positive,positive,positive,positive,positive
513461216,"> > Do you states that you go from 1h30 per epoch without augmentation to 12h per epoch ?
> 
> Yes. If you try and modulate the pitch or time stretch every sample, then you go from 1hr 30 mins per epoch to something over 13

Unless something can be done to speed things up, a slowdown by a factor of over 8.5 times seems unacceptable to me.

For example, a normal training run for a release model takes about 2 days. This would bring it to around 20 days which is far too long for us.

In addition we are in the process of increasing the size of the data set we train on by about a factor of 4 or more. So this change would mean a training run with this larger data set would take 80 days or more which is far too long for us.",go per epoch without augmentation per epoch yes try modulate pitch time stretch every sample go per epoch something unless something done speed slowdown factor time unacceptable example normal training run release model day would bring around day far long u addition process increasing size data set train factor change would mean training run data set would take day far long u,issue,negative,negative,neutral,neutral,negative,negative
513461033,What is time and duration that json? And I have used 2 seconds audio file here,time duration used audio file,issue,negative,neutral,neutral,neutral,neutral,neutral
513460389,Can you elaborate? I don't see anything obvious. ,elaborate see anything obvious,issue,negative,positive,positive,positive,positive,positive
513445388,"> Do you states that you go from 1h30 per epoch without augmentation to 12h per epoch ?

Yes. If you try and modulate the pitch or time stretch every sample, then you go from 1hr 30 mins per epoch to something over 13(actually much higher because i ran it only for 6300 steps but one epoch is 9396 steps) hrs per epoch. I stopped it earlier because even 12-13 hrs was way too much for an epoch.  So instead of running the augmentation for every sample, I run it only 10%(can be modified in flags) of the time and then i got the time down to 2hrs 36 mins.",go per epoch without augmentation per epoch yes try modulate pitch time stretch every sample go per epoch something actually much higher ran one epoch per epoch stopped even way much epoch instead running augmentation every sample run time got time,issue,negative,positive,positive,positive,positive,positive
513444739,">  **This is reasonable, I suppose. I've pushed the commits for this variant.**

I'm not sure I understand the numbers here. Do you states that you go from 1h30 per epoch without augmentation to 12h per epoch ?",reasonable suppose variant sure understand go per epoch without augmentation per epoch,issue,negative,positive,positive,positive,positive,positive
513442316,"@kdavis-mozilla 

On 1 x Titan V 
VANILLA MOZILA DEEPSPEECH:
1hr 30 mins per EPOCH

MOZILLA DEEPSPEECH WITH AUGMENTATION(every sample either time stretched or pitch shifted):
Epoch 0 |   Training | Elapsed Time: 12:57:25 | Steps: 6720 | Loss: 74.650548
**I didn't even let it run the whole epoch(9396 steps). This was not worth it.**

MOZILLA DEEPSPEECH WITH AUGMENTATION(10%chance on both pitch shifting and time streching):
Epoch 0 |   Training | Elapsed Time: 2:36:15 | Steps: 9396 | Loss: 60.723667
**This is reasonable, I suppose. I've pushed the commits for this variant.** ",vanilla per epoch augmentation every sample either time pitch epoch training time loss even let run whole epoch worth augmentation chance pitch shifting time epoch training time loss reasonable suppose variant,issue,negative,positive,positive,positive,positive,positive
513334079,"<details>

<summary>Submitting the task to Taskcluster failed. Details</summary>

expression is not defined

</details>",summary task expression defined,issue,negative,neutral,neutral,neutral,neutral,neutral
513265396,"Will add the flag. Lets assume i add the flag X for X% pitch modulation, then it would be (1-X)% for time stretch in this implentation. Is that ok? @kdavis-mozilla Regarding the percentage chance flag.


Edit:
Nvm, I've added the edits. Testing performance now. will push with more details.",add flag assume add flag pitch modulation would time stretch regarding percentage chance flag edit added testing performance push,issue,negative,neutral,neutral,neutral,neutral,neutral
513265069,Another problem I could see arising is when the length is increased you can get random OOM errors.,another problem could see length get random,issue,negative,negative,negative,negative,negative,negative
513264459,One problem I could see arising is if the length of the audio is made is smaller than the [minimum required for the transcript](https://github.com/mozilla/DeepSpeech/blob/master/bin/import_cv2.py#L86).,one problem could see length audio made smaller minimum transcript,issue,negative,neutral,neutral,neutral,neutral,neutral
513264052,"I'm going to close this, because it's definitively your problem, running 0.1.1 model with 0.6.0a4 binaries ...",going close definitively problem running model,issue,negative,neutral,neutral,neutral,neutral,neutral
513263730,@lissyx okay I will try this latest version and let you know.,try latest version let know,issue,negative,positive,positive,positive,positive,positive
513263331,@Aravindraj92 The v0.1.1 model is very old. You'll have more luck with the 0.5.1 model.,model old luck model,issue,negative,positive,neutral,neutral,positive,positive
513262775,"> @lissyx i have installed from this link===>https://progur.com/2018/02/how-to-use-mozilla-deepspeech-tutorial.html

How about reading our official docs ?

`pip install deepspeech==0.5.1` + https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz you don't need anything else.",reading official pip install need anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
513261651,"> How performant is this?
> 
> Does anyone have numbers on ""before training took X now it takes N·X""?

training a model right now on CV english(777 hrs). I will post the time difference in a few hours. Also, tI think there might be a bug here with the length of source audio being not long enough. Will only know after 1 entire epoch. 

VANILLA MOZZILA DEEPSPEECH: 
On 1 x Titan V : 1hr 30 mins per EPOCH (I'll retest this again after augmentation)

MOZILLA DEEPSPEECH with augmentation:
(soon)



will try and post the convergence speed/loss graph too.",performant anyone training took training model right post time difference also ti think might bug length source audio long enough know entire epoch vanilla per epoch retest augmentation augmentation soon try post convergence graph,issue,negative,positive,neutral,neutral,positive,positive
513261273,@Aravindraj92 Care to document where this model comes from ?,care document model come,issue,negative,neutral,neutral,neutral,neutral,neutral
513259978,"How performant is this?

Does anyone have numbers on ""before training took X now it takes N·X""?",performant anyone training took,issue,negative,neutral,neutral,neutral,neutral,neutral
513235965,"@lissyx @cahuja1992 would another PR be warranted around this feature? i've added pitch modulation along with speed and randomized which augmentation at each call. 

Nvm i'll send the PR. want a review anyway.",would another warranted around feature added pitch modulation along speed augmentation call send want review anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
513195202,"> Per the other ticket linked just above, [`libdeepspeech`](https://aur.archlinux.org/packages/libdeepspeech/) and [`deepspeech-models`](https://aur.archlinux.org/packages/deepspeech-models/) are now in the AUR. The packages created from this discussion are useful but are out-of-date and should be bumped by their maintainer(s). @NicoHood I think you own at least one of those??

Could you update to 0.5.1 ? The 0.5.0 is bogus",per ticket linked discussion useful maintainer think least one could update bogus,issue,negative,neutral,neutral,neutral,neutral,neutral
513193235,"> Confirmed that loading the checkpoint works. Also, removing the metadata node works, just a simple `del(graph_def.node[-1])`. Thanks!

I guess that means you issue is solved, thanks!",confirmed loading work also removing node work simple thanks guess issue thanks,issue,positive,positive,positive,positive,positive,positive
513183152,"> worrying about reproductibility

How about using Random's RNG to get random int/float(for pitch shift/ timestrech) and set Random seed for reproducibility",worrying random get random pitch set random seed reproducibility,issue,negative,negative,negative,negative,negative,negative
513178982,"> @lissyx the idea here is to do online augmentation, where for every epoch slightly different perturbations are created, and hopefully achieving better generalization. Otherwise you'd have to save to disk every variation of the perturbed dataset before you even begin training.

Sure, I'm just wondering / worrying about reproductibility. For some reason, I kept thinking in my mind that we wanted to avoid explicitely that kind of behavior.",idea augmentation every epoch slightly different hopefully better generalization otherwise save disk every variation perturbed even begin training sure wondering worrying reason kept thinking mind avoid kind behavior,issue,positive,positive,positive,positive,positive,positive
513147391,"> That still means we block re-training with anything else than CUDA.

Yes, it's unfortunate.

> How much is the speedup?

Usually around 2x faster time per epoch.",still block anything else yes unfortunate much usually around faster time per epoch,issue,negative,negative,negative,negative,negative,negative
513144054,"@cahuja1992 Thanks for the PR! Can you take a look at the linter check in the Travis job?

I see that pyrubberband is a wrapper over a command-line utility, so it creates temporary files and spawns a subprocess to process the audio. This could slow down training quite a bit, did you see a significant slowdown in your training runs? If there's no way to do the rubberbanding in memory, then at the very least we should do it before decoding the original WAV, since we're not using the original samples anyway.

Currently the flow looks like this: wav_filename -> read_file -> decode_wav -> rubberband (writes to a file, processes it into a new file, reads the new file) -> rest of input pipeline.

The initial file reading and WAV decoding are useless. We could just call rubberband on the original file, and read the modified file once.",thanks take look linter check travis job see wrapper utility temporary process audio could slow training quite bit see significant slowdown training way memory least original since original anyway currently flow like file new file new file rest input pipeline initial file reading useless could call original file read file,issue,negative,positive,neutral,neutral,positive,positive
513142621,"Okay, isn't it good that every training epoch gets to see different data so that the model becomes more generalized rather than getting overfit. ",good every training epoch see different data model becomes generalized rather getting overfit,issue,negative,positive,positive,positive,positive,positive
513142357,"@lissyx the idea here is to do online augmentation, where for every epoch slightly different perturbations are created, and hopefully achieving better generalization. Otherwise you'd have to save to disk every variation of the perturbed dataset before you even begin training.",idea augmentation every epoch slightly different hopefully better generalization otherwise save disk every variation perturbed even begin training,issue,positive,positive,positive,positive,positive,positive
513136412,"@cahuja1992 Thanks for that, but I don't think it's the right place to apply that kind of changes: deepspeech should remain focused on pulling the dataset, and the perturbations should be applied there, indeed creating a perturbated dataset. ",thanks think right place apply kind remain applied indeed,issue,positive,positive,positive,positive,positive,positive
513108374,"> @lissyx why were you apprehensive of adding the release link to data/readme? was it because it wasn't in the main readme, or was it something else?

Yes, because it's not in the main README, I don't think it should be a place where we bury such a link.",apprehensive release link main something else yes main think place bury link,issue,negative,positive,positive,positive,positive,positive
513076247,"@lissyx why were you apprehensive of adding the release link to data/readme? was it because it wasn't in the main readme, or was it something else?

Asking in case i want to make more PRs.",apprehensive release link main something else case want make,issue,negative,positive,positive,positive,positive,positive
512977206,"> @lissyx Thanks, I was looking for this today, found thi thread and now it's working with tflite, thanks again.

I'll infer from that comment that this issue can be solved as well for @isjosan. Feel free to re-open if required.",thanks looking today found thread working thanks infer comment issue well feel free,issue,positive,positive,positive,positive,positive,positive
512964219,"Well, we can fix this and then close it, now that the prod model has been updated :)",well fix close prod model,issue,negative,neutral,neutral,neutral,neutral,neutral
512933610,"@lissyx Thanks, I was looking for this today, found thi thread and now it's working with tflite, thanks again.",thanks looking today found thread working thanks,issue,positive,positive,positive,positive,positive,positive
512916072,"This is 99.99% likely a dataset issue. Nothing we can help on, please check you WAV files.",likely issue nothing help please check,issue,negative,neutral,neutral,neutral,neutral,neutral
512915829,"Looks like there is nothing more to act on here. Closing, please file a new issue if required.",like nothing act please file new issue,issue,negative,positive,positive,positive,positive,positive
512915677,"> no idea why the training test result is different with recognization result.

Can you elaborate ? I'm not speaking Chinese, so I'm unsure about understand the problem here. But your training command line is a bit strange: data batch of 1, learning rate and epoch seems weird.

Is this an overfitting training test ?



> @kdavis-mozilla Actually I didn't create language model yet, just want to try DeepSpeech out first; maybe next step.

That might have an impact, since your are then using english LM in this setup. Maybe try passing lm alpha and beta parameters with value of `0.0` to nuke their impact ?",idea training test result different result elaborate speaking unsure understand problem training command line bit strange data batch learning rate epoch weird training test actually create language model yet want try first maybe next step might impact since setup maybe try passing alpha beta value nuke impact,issue,negative,positive,neutral,neutral,positive,positive
512871729,"I'm going to close this, since it's obivously a data-issue. Feel free to re-open if you happen to identify an issue code-wise.",going close since feel free happen identify issue,issue,positive,positive,positive,positive,positive,positive
512855117,"> `tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'feature_win_len' not in Op<name=NoOp; signature= -> >; NodeDef: {{node model_metadata}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).`

That's just from some metadata that we add to the exported model. Try to disable that and re-export ?",node check whether binary date binary add model try disable,issue,negative,neutral,neutral,neutral,neutral,neutral
512849496,"Ah, I tried something else. Looking at the `export` function I noticed it was saved as a frozen model, which the latest converter no longer supports:

```
Note: Session bundle and Frozen model formats have been deprecated in TensorFlow.js 1.0. Please use the TensorFlow.js 0.15.x backend to convert these formats, available in tfjs-converter 0.8.6.
```

I downgraded to `0.8.6` and got further before another error:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'feature_win_len' not in Op<name=NoOp; signature= -> >; NodeDef: {{node model_metadata}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
```

Which appears to be related to the version of tf used to originally generate the model. I'll try reverting back to latest and renaming the file before trying to investigate the tf version path.",ah tried something else looking export function saved frozen model latest converter longer note session bundle frozen model please use convert available got another error node check whether binary date related version used originally generate model try back latest file trying investigate version path,issue,negative,positive,positive,positive,positive,positive
512836547,"@beriberikix, seems like the converter looks for `saved_model.pb`, but the graph is saved in `output_graph.pb` instead, so you might need to just rename this file. Other than that, [here](https://github.com/sdll/tfjs-models/blob/122e26aababb5d2df0276cf7d331ae3b247fec90/text-detection/scripts/convert_text_detection_weights.sh#L203) is a working example of how to convert SavedModel. The options
```bash
  --signature_name=serving_default \
  --saved_model_tags=serve
```
are merely default settings, so you might skip setting them if the model was saved without altering them.",like converter graph saved instead might need rename file working example convert bash merely default might skip setting model saved without,issue,positive,negative,negative,negative,negative,negative
512828147,"You should have a look at the `export` function, maybe some parameters needs to be adjusted? ",look export function maybe need,issue,negative,neutral,neutral,neutral,neutral,neutral
512819235,"I'm trying to convert `deepspeech-0.5.1-models.tar.gz` using [tensorflow/tfjs-converter](https://github.com/tensorflow/tfjs-converter) but I'm running into an issue (probably because I've never used the tool before!)

```
SavedModel file does not exist at: 
./deepspeech-0.5.1-models/output_graph.pb/{saved_model.pbtxt|saved_model.pb}
```

Do you know which, if any, signatures and/or tags were used in generating the SavedModel? Per the help output:

```
--signature_name SIGNATURE_NAME
                        Signature of the SavedModel Graph or TF-Hub module to
                        load. Applicable only if input format is ""tf_hub"" or
                        ""tf_saved_model"".
  --saved_model_tags SAVED_MODEL_TAGS
                        Tags of the MetaGraphDef to load, in comma separated
                        string format. Defaults to ""serve"". Applicable only if
                        input format is ""tf_saved_model"".
```",trying convert running issue probably never used tool file exist know used generating per help output signature graph module load applicable input format load comma string format serve applicable input format,issue,negative,neutral,neutral,neutral,neutral,neutral
512818362,"> > Complementing the question of @lissyx for checking, could a non-GPU notebook export a pb file from a CudnnRNN checkpoint?
> 
> Yep.

That still means we block re-training with anything else than CUDA.

How much is the speedup?",question could notebook export file yep still block anything else much,issue,negative,positive,positive,positive,positive,positive
512800327,"@Dev1158 If you want to train on TensorFlow r1.14, please follow the doc and use current master.",dev want train please follow doc use current master,issue,negative,neutral,neutral,neutral,neutral,neutral
512799675,"> running inference using Tensorflow 1.11.

Or that's the point, you were not **training** but **running inference**. The CTC decoder code is statically linked into `libdeepspeech.so` inference library that is being bundled by several bindings, including python ones. TensorFlow package is completely orthogonal to that.",running inference point training running inference code statically linked inference library several python package completely orthogonal,issue,negative,positive,neutral,neutral,positive,positive
512799165,"> I was using the library ""libctc_decoder_with_kenlm.so"" and decoded the DeepSpeech model output while running inference using Tensorflow 1.11.

I highly doubt so. But if it was **really** working, that was just pure luck.",library model output running inference highly doubt really working pure luck,issue,negative,positive,positive,positive,positive,positive
512798825,"I was using the library ""libctc_decoder_with_kenlm.so"" and decoded the DeepSpeech model output while running inference using Tensorflow 1.11.",library model output running inference,issue,negative,neutral,neutral,neutral,neutral,neutral
512797927,"> But I was able to use DeepSpeech 0.2.0 using Tensorflow version 1.11. So, Why is it not possible with Tensorflow 1.14?

I don't know what you mean, but we never supported anything than 1.6 for this version.",able use version possible know mean never anything version,issue,negative,positive,neutral,neutral,positive,positive
512797699,"But I was able to use DeepSpeech 0.2.0 using Tensorflow version 1.11. So, Why is it not possible with Tensorflow 1.14?",able use version possible,issue,negative,positive,positive,positive,positive,positive
512794918,"> So it means that Deepspeech0.2.0 cannot be decoded using Tensorflow1.14.

Yes, that's right.



> Is there some way to build the decoder library for DeepSpeech 0.2.0 using Tensorflow 1.14?

Maybe, but we don't be able to help nor support that.



> I tried without Anaconda environment still facing the same issue.

I explained you the root cause, I just mentionned that ananconda environment itself will also potentially add some similar / different issues.",yes right way build library maybe able help support tried without anaconda environment still facing issue root cause environment also potentially add similar different,issue,positive,positive,positive,positive,positive,positive
512794446,"    custom_op_module = tf.load_op_library(decoder_library_path)
  File ""/home/www/.local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 61, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so: cannot open shared object file: No such file or directory

I tried without Anaconda environment still facing the same issue.",file line open object file file directory tried without anaconda environment still facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
512788237,"@Dev1158 Also, Anaconda might introduce issues, we've got several reports from people using this and having similar problems as well.",dev also anaconda might introduce got several people similar well,issue,negative,neutral,neutral,neutral,neutral,neutral
512787455,">  I just want to load libctc_decoder_with_kenlm.so, any help?

You are using `r1.14` ? This is not what is documented for DeepSpeech v0.2.0. Mismatching TensorFlow version explains your issue. Please stick to documented version. Any reason you want to continue using this 0.2.0 ? It's old and we don't support it anymore.",want load help version issue please stick version reason want continue old support,issue,positive,positive,neutral,neutral,positive,positive
512776185,@lissyx I think i messed up the squashing bit. i'll send new PR after fix.  i think i squashed older commits(not mine) to it. ,think bit send new fix think older mine,issue,negative,positive,positive,positive,positive,positive
512758139,"@kdavis-mozilla squashed.
@lissyx I think I've done everything you requested. Please let me know there's more that needs to be done.

I think i messed up the squashing bit. fixing it. ",think done everything please let know need done think bit fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
512755738,"> @reuben , I remember that a time ago you could continuing training from a pb file (instead of a checkpoint). Couldn't this solve this issue (but losing information about optimizer probably )?

This would be equivalent to my proposed workaround, just initialize the missing optimizer tensors from scratch.

> Complementing the question of @lissyx for checking, could a non-GPU notebook export a pb file from a CudnnRNN checkpoint?

Yep.",remember time ago could training file instead could solve issue losing information probably would equivalent initialize missing scratch question could notebook export file yep,issue,negative,negative,negative,negative,negative,negative
512755329,"@reuben , I remember that a time ago you could continuing training from a pb file (instead of a checkpoint). Couldn't this solve this issue (but losing information about optimizer probably )?

Complementing the question of @lissyx for checking, could a non-GPU notebook export a pb file from a CudnnRNN checkpoint?",remember time ago could training file instead could solve issue losing information probably question could notebook export file,issue,negative,neutral,neutral,neutral,neutral,neutral
512734633,Ok I'll be retrying this some time later this month. Actually stuck with other things in my project. So will get back to you soon. But I don't think its anything missing in your documentation. I seem to be missing something somewhere. I'll retry this from scratch soon,time later month actually stuck project get back soon think anything missing documentation seem missing something somewhere retry scratch soon,issue,negative,negative,neutral,neutral,negative,negative
512687322,"@isjosan We have started experimenting with TFLite lib on other platforms, but it's still experimental. For example, you can find them on this link for your platform: https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.6.0-alpha.4/tflite",still experimental example find link platform,issue,negative,positive,neutral,neutral,positive,positive
512686665,"@isjosan As documented, current distributed binaries are only intended to run TensorFlow models, not TFLite models, except on Android platforms.",current distributed intended run except android,issue,negative,neutral,neutral,neutral,neutral,neutral
512686378,"> Does this produce models that will work for inference on the 0.5.1 native client? Or does the client need to be updated to work with models created via this method?

We broke compatibility with 0.5.1 with the fix for concurrent streams with a single ModelState. But this PR alone does not break compatibility with the clients.

> Ouch, that's going to be complicated. I often re-use checkpoints on my laptop to perform exports :/

Exporting works fine, it's just continuing training from the checkpoint that's problematic.",produce work inference native client client need work via method broke compatibility fix concurrent single alone break compatibility ouch going complicated often perform work fine training problematic,issue,negative,negative,neutral,neutral,negative,negative
512635509,"BTW...I tried to re-export the TFlite model from checkpoint, but get the following exception at the end of execution:

$ ./DeepSpeech.py --checkpoint_dir /home/iqbal/DeepSpeech-model-0.5.1/deepspeech-0.5.1-checkpoint  --export_tflite --export_dir /home/iqbal/DeepSpeech-model-0.5.1/deepspeech-0.5.1-models
.................................................................................................................................................
.................................................................................................................................................
**Exception: TensorFlow Lite currently doesn't support control flow ops: Merge, Switch**
",tried model get following exception end execution exception lite currently support control flow merge switch,issue,negative,neutral,neutral,neutral,neutral,neutral
512506090,"> But if we release CudnnRNN checkpoints, it reduces the audience that can make use of it, as it requires a CUDA GPU

Ouch, that's going to be complicated. I often re-use checkpoints on my laptop to perform exports :/",release audience make use ouch going complicated often perform,issue,negative,negative,negative,negative,negative,negative
512504181,Does this produce models that will work for inference on the 0.5.1 native client? Or does the client need to be updated to work with models created via this method?,produce work inference native client client need work via method,issue,negative,neutral,neutral,neutral,neutral,neutral
512465353,"Confirmed that loading the checkpoint works. Also, removing the metadata node works, just a simple `del(graph_def.node[-1])`. Thanks!",confirmed loading work also removing node work simple thanks,issue,negative,positive,positive,positive,positive,positive
512342824,"You could load the checkpoint instead, which should work. Or I guess you could try removing the metadata node before loading the frozen GraphDef.",could load instead work guess could try removing node loading frozen,issue,negative,neutral,neutral,neutral,neutral,neutral
512314519,I'd like to use the acoustic model logits as input to my own CTC decoder. Is there a better way to do this?,like use acoustic model input better way,issue,positive,positive,positive,positive,positive,positive
512256137,"Upon closer inspection, I don't think fixing the caveat in a bullet proof way is possible with the CudnnCompatible* machinery in TF. It seems geared exclusively for exporting models, basically a last step you do when you're done training. If you try to load a CudnnLSTM checkpoint in a CudnnCompatibleLSTMCell graph you get errors about the Adam tensors not being there.

A possible workaround would be to re-initialize the Adam moment tensors from scratch if they're missing from the checkpoint, but it could interfere significantly with transfer learning and fine tuning.

In summary: using CudnnRNN greatly speeds up training on GPUs, which would be great for our experiments and training runs on large datasets. But if we release CudnnRNN checkpoints, it reduces the audience that can make use of it, as it requires a CUDA GPU. @kdavis-mozilla @lissyx @tilmankamp thoughts?",upon closer inspection think fixing caveat bullet proof way possible machinery geared exclusively basically last step done training try load graph get possible would moment scratch missing could interfere significantly transfer learning fine tuning summary greatly training would great training large release audience make use,issue,positive,positive,positive,positive,positive,positive
512243385,"This PR has one caveat: CuDNN and non-CuDNN training graphs aren't compatible. This means you can't start a training run with `--use_cudnn_rnn` and then continue it on the CPU, or on a GPU but without CuDNN RNN. I'm trying to come up with a clean way to fix it but in the mean time this PR can be reviewed independently, as it doesn't change any defaults.",one caveat training compatible ca start training run continue without trying come clean way fix mean time independently change,issue,negative,positive,neutral,neutral,positive,positive
512137083,Why are you trying to load the graph by hand like that?,trying load graph hand like,issue,positive,neutral,neutral,neutral,neutral,neutral
512122647,@mortont What are you trying to achieve ? Those extra nodes are added at export time to hold some metadata.,trying achieve extra added export time hold,issue,negative,neutral,neutral,neutral,neutral,neutral
512041611,"I'm seeing the same error when trying to load the 0.5.1 pb model. Loading from the checkpoint works and running `evaluate.py` seems to work fine too (removed the deprecation warnings for brevity).
```
python evaluate.py --checkpoint_dir checkpoint/ --test_files datasets/commonvoice/clips/test_small.csv
I Restored variables from most recent checkpoint at checkpoint/model.v0.5.1, step 467356
Testing model on datasets/commonvoice/clips/test_small.csv
Test epoch | Steps: 3 | Elapsed Time: 0:00:03
Test on datasets/commonvoice/clips/test_small.csv - WER: 0.666667, CER: 0.459459, loss: 113.408905
--------------------------------------------------------------------------------
WER: 1.000000, CER: 0.925926, loss: 304.088928
 - src: ""did she ever marry the girl""
 - res: ""yes""
--------------------------------------------------------------------------------
WER: 0.800000, CER: 0.360000, loss: 34.971336
 - src: ""the cup handle has broken""
 - res: ""the cap and it has brought""
--------------------------------------------------------------------------------
WER: 0.000000, CER: 0.000000, loss: 1.166428
 - src: ""do you understand that""
 - res: ""do you understand that""
--------------------------------------------------------------------------------
```
My pb loading code is essentially the same as @fanghuaqi's but I'm using CPU only. Python version 3.7.3 and tensorflow 1.13.1. I've also tried exporting the working checkpoint to a pb and it has the same error. The GraphDef has the attrs mentioned in the error (as expected)
```python
import tensorflow as tf
from tensorflow.python.platform import gfile

GRAPH_PB_PATH = './DeepSpeech/export/output_graph.pb'
with tf.Session() as sess:
   with tf.gfile.GFile(GRAPH_PB_PATH,'rb') as f:
       graph_def = tf.GraphDef()
       graph_def.ParseFromString(f.read())
       print(graph_def.node[-1])
```
```
name: ""model_metadata""
op: ""NoOp""
attr {
  key: ""feature_win_len""
  value {
    i: 32
  }
}
attr {
  key: ""feature_win_step""
  value {
    i: 20
  }
}
attr {
  key: ""sample_rate""
  value {
    i: 16000
  }
}
```",seeing error trying load model loading work running work fine removed deprecation brevity python recent step testing model test epoch time test wer loss wer loss ever marry girl yes wer loss cup handle broken cap brought wer loss understand understand loading code essentially python version also tried working error error python import import sess print name noop key value key value key value,issue,negative,positive,neutral,neutral,positive,positive
511781852,You filed an issue for something unrelated and unsupported since you were not using libdeepspeech.so ... So it would be great we get feedback as soon as possible. Either something is missing in our doc or? ,issue something unrelated unsupported since would great get feedback soon possible either something missing doc,issue,negative,positive,positive,positive,positive,positive
511779749,"Sorry. I did try this, was encountering a few errors. In the meantime I have been trying the other app link you shared with me. I will come back to this in the coming days & update you if I am facing any issues.",sorry try trying link come back coming day update facing,issue,negative,negative,negative,negative,negative,negative
511747732,We recently removed the ability to train on a cluster ([Removed distributed training support](https://github.com/mozilla/DeepSpeech/pull/1988)) as we were not using it and maintenance was too much of an overhead for our small team.,recently removed ability train cluster removed distributed training support maintenance much overhead small team,issue,positive,negative,neutral,neutral,negative,negative
510791275,"Adds a few hundred KiB to the binary on my tests. Shouldn't be any different on CUDA, since this is just adding more op libs, not kernels.",hundred binary different since,issue,negative,neutral,neutral,neutral,neutral,neutral
510688562,Just checking if tests explode. Needs more profiling as well as updating our TensorFlow cwise rule.,explode need well rule,issue,negative,neutral,neutral,neutral,neutral,neutral
510622046,Now that we've merged TensorFlow 1.14 support I plan to merge the CuDNN RNN support into master.,support plan merge support master,issue,positive,neutral,neutral,neutral,neutral,neutral
510614560,"Thanks for the interest, that'd be a great contribution! The approach sounds good, although I'm not entirely sure `get_lob_prob` is the only API we'd have to surface from the `Scorer`. There's also the question of different scorers having different initialization and configuration parameters, and how to expose that in the main DeepSpeech API. But that's a worry for the future, just having an initial abstraction that can be used to experiment with new implementations would be really great to have.",thanks interest great contribution approach good although entirely sure surface scorer also question different different configuration expose main worry future initial abstraction used experiment new would really great,issue,positive,positive,positive,positive,positive,positive
510610987,"@cahuja1992 I strongly recommend you to take a look into the **cudnnrnn** branch. It uses the cudnnLSTM/GRU that, besides being faster, allows you to easily set the number of RNN layers (see the [doc](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTM)). 

My patch is way old, and I couldn't get any improvement with more layers (maybe I was implementing it wrongly)",strongly recommend take look branch besides faster easily set number see doc patch way old could get improvement maybe wrongly,issue,positive,positive,positive,positive,positive,positive
510606898,"I would like to work on making the language model interface more general. Do you think this would be a good approach:

Make Scorer a generic class that subtypes of scorers inherit from (e.g. `KenlmScorer`). Each subtype of scorer would have to implement `get_log_prob()` in their own way. This way, someone could write their own scorer using tensorflow much more easily. @ftyers ",would like work making language model interface general think would good approach make scorer generic class inherit subtype scorer would implement way way someone could write scorer much easily,issue,positive,positive,positive,positive,positive,positive
510466126,"> We can continue the discussion on Common Voice discourse, since we are talking about data collection:
> 
> https://discourse.mozilla.org/t/making-an-open-source-captcha-from-common-voice/42437

That's right, let's keep the discussion on Discourse and keep the bug open, since there's indeed several people interested.",continue discussion common voice discourse since talking data collection right let keep discussion discourse keep bug open since indeed several people interested,issue,negative,positive,neutral,neutral,positive,positive
510463001,"We can continue the discussion on Common Voice discourse, since we are talking about data collection:

https://discourse.mozilla.org/t/making-an-open-source-captcha-from-common-voice/42437",continue discussion common voice discourse since talking data collection,issue,negative,negative,negative,negative,negative,negative
510372487,"> Can you please explain how can I run a binary search on a csv file ?

Just split the dev.csv in two files and run on each, if you get choking on one or the other part, split that part in two and re-do.",please explain run binary search file split two run get choking one part split part two,issue,negative,neutral,neutral,neutral,neutral,neutral
510365403,"Thank you for these details :) Can you please explain how can I run a binary search on a csv file ?
",thank please explain run binary search file,issue,positive,neutral,neutral,neutral,neutral,neutral
510361928,@testdeepv yes it's likely a bogus wav or transcription in `dev.csv`. I can't give you a better advice than running a binary search on `dev.csv` to identify which records is problematic. We already got some reports with some wav file choking within tensorflow's codebase. We have not been able to find why.,yes likely bogus transcription ca give better advice running binary search identify problematic already got file choking within able find,issue,negative,positive,positive,positive,positive,positive
510351784,"the error appeares in the validation steps on dev.csv, does this mean that the problem is with dev.csv ??
How can I debug this ? I checked all wav file, they are all not empty.",error validation mean problem checked file empty,issue,negative,negative,negative,negative,negative,negative
510345904,"> I've read some recent papers for speech recognition [1,2], and I noticed that they all tend to use more than a single LSTM layer.
> [1] Park et al., Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices. NeurIPS 2018.
> [2] He et al., Streaming End-to-end Speech Recognition For Mobile Devices. arXiv:1811.0662, 2018.
> 
> I tried to implement it by myself, and it seems to be working for training/evaluation/exporting. Unfortunately, I need some help about what changes should I make on the binaries.
> 
> The following patch holds the implementation of arbitrary number of LSTMs (haven't created a PR because the binaries were not touched).
> [patch_more_LSTMs.patch.txt](https://github.com/mozilla/DeepSpeech/files/2928944/patch_more_LSTMs.patch.txt)

I am trying to apply this patch. Can you please tell for which tag this tag is for ?",read recent speech recognition tend use single layer park fully neural network based speech recognition mobile streaming speech recognition mobile tried implement working unfortunately need help make following patch implementation arbitrary number touched trying apply patch please tell tag tag,issue,negative,negative,negative,negative,negative,negative
509960370,Properly removing the element from the `std::vector` data structure does get rid of the valgrind-level error for me.,properly removing element data structure get rid error,issue,negative,neutral,neutral,neutral,neutral,neutral
509551429,Sorry for late response. Was just trying the app link you shared above. Will get back to you on this in a while.,sorry late response trying link get back,issue,negative,negative,negative,negative,negative,negative
509154941,"FTR @beriberikix I don't know if the TF.js converter has the same constraints as the one for leveraging EdgeTPU, but we cannot (yet) convert our model for running on EdgeTPU. It's not impossible they may share constraints.",know converter one yet convert model running impossible may share,issue,negative,negative,negative,negative,negative,negative
508950517,"Yeah, threads and SIMD that's still a long way, according to a colleague working on that and wasm. Still curious about what you can get. ",yeah still long way according colleague working still curious get,issue,positive,negative,neutral,neutral,negative,negative
508947090,"Understood, I hope to experiment and report back!

I watched a [recent talk](https://www.youtube.com/watch?v=imzedQr2tTc) by two leads and I'm optimistic, at least of the future perf. Today they're using WebGL to get better speed than vanilla JS and in the future they'll be looking into WebAssembly with Threads and SIMD.",understood hope experiment report back watched recent talk two optimistic least future today get better speed vanilla future looking,issue,positive,positive,neutral,neutral,positive,positive
508946651,"To be honest I fear we won't get any decent perfs with that, given the experiments without vectorization we could perform. ",honest fear wo get decent given without could perform,issue,negative,positive,positive,positive,positive,positive
508927604,@ramrahu Can you please update us ? Have you been able to use `libdeepspeech` ? https://bintray.com/alissy/org.mozilla.deepspeech/libdeepspeech,please update u able use,issue,negative,positive,positive,positive,positive,positive
508785417,Enough green to feel safe.,enough green feel safe,issue,negative,positive,neutral,neutral,positive,positive
508672417,"> I follow the tutorial - https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830
> Is this tutorial proper for the ""master"" checkout? In this tutorial, --decoder_library_path /home/nvidia/tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so was declared.

This tutorial is good except it's old, so `master` from that time has moved on.",follow tutorial tutorial proper master tutorial declared tutorial good except old master time,issue,negative,positive,positive,positive,positive,positive
508671886,"I follow the tutorial - https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830
Is this tutorial proper for the ""master"" checkout? In this tutorial, --decoder_library_path /home/nvidia/tensorflow/bazel-bin/native_client/libctc_decoder_with_kenlm.so was declared.",follow tutorial tutorial proper master tutorial declared,issue,negative,neutral,neutral,neutral,neutral,neutral
508671460,"> (1) My checkout is master, not v0.3.0.

You link doc of v0.3.0, so it's complicated to know what you are trying to do. You don't need `libctc_decoder_with_kenlm` with newer versions but you need a python package (please check the documentation)


>  (2) Do I need to generate my own libctc_decoder_with_kenlm.so for a language other than English? If not, where can I download libctc_decoder_with_kenlm.so? If yes, how can generate it?

Have you found any documentation stating the need to rebuild for a different language ? Because no, there is no need. Have you tried to check the release page? It's documented it is bundled within `native_client` tar.",master link doc complicated know trying need need python package please check documentation need generate language yes generate found documentation need rebuild different language need tried check release page within tar,issue,positive,negative,negative,negative,negative,negative
508670857,"(1) My checkout is master, not v0.3.0.
(2) Do I need to generate my own libctc_decoder_with_kenlm.so for a language other than English? If not, where can I download libctc_decoder_with_kenlm.so? If yes, how can generate it?",master need generate language yes generate,issue,negative,neutral,neutral,neutral,neutral,neutral
508669779,">  I need to train models for taiwanese using dataset downloaded from Common Voice.

I don't see the link here:
 - why would you need to stick to v0.3.0 ?
 - why can't you use prebuilt binaries for `libctc_decoder_with_kenlm.so` if you absolutely need v0.3.0 ?",need train common voice see link would need stick ca use absolutely need,issue,negative,negative,neutral,neutral,negative,negative
508669478,"master, 
I need to train models for taiwanese using dataset downloaded from Common Voice.",master need train common voice,issue,negative,negative,negative,negative,negative,negative
508668165,"> (2) I checked ~/DeepSpeech/native_client/BUILD, there is no ""tf_cc_shared_object(name = ""libctc_decoder_with_kenlm.so"", ..."" declaration as coded in ""https://github.com/mozilla/DeepSpeech/blob/v0.3.0/native_client/BUILD""

Is your checkout of `v0.3.0` or master ?

What is wrong with pre-built binaries, why do you need to rebuild ?",checked name declaration master wrong need rebuild,issue,negative,negative,negative,negative,negative,negative
508667786,@csyang6052 Please use Discourse as documented for questions and help.,please use discourse help,issue,positive,neutral,neutral,neutral,neutral,neutral
508647013,@rhamnett  are you able spot decrease in WER when you are training in 0.5.0. I am also facing an increase in WER when training on a custom dataset in 0.4.1,able spot decrease wer training also facing increase wer training custom,issue,negative,positive,positive,positive,positive,positive
508512535,Closing due to lack of activity. Feel free to open a new PR with comments addressed.,due lack activity feel free open new,issue,negative,positive,positive,positive,positive,positive
508495885,"> `ValueError: NodeDef mentions attr 'feature_win_step' not in Op<name=NoOp; signature= -> >; NodeDef: {{node model_metadata}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).`

Those are extra-metadata that we add at export.

Can you try running with `evaluate.py` ?",node check whether binary date binary add export try running,issue,negative,neutral,neutral,neutral,neutral,neutral
508454877,"> I had already downloaded it before executing make apk

You need to be a bit more specific ... Is it properly exposed in your PATH ? What does `swig -version` shows ?",already make need bit specific properly exposed path swig,issue,negative,neutral,neutral,neutral,neutral,neutral
508439839,">  jni/deepspeech.i:23: Error: Syntax error in input(1).

What version of SWIG do you have ?",error syntax error input version swig,issue,negative,neutral,neutral,neutral,neutral,neutral
508430299,"This is the output I get when I run that command:

./gradlew clean

> Configure project :libdeepspeech 
arm64-v8a armeabi-v7a x86_64

BUILD SUCCESSFUL in 0s
5 actionable tasks: 2 executed, 3 up-to-date
rm -rf *.java jni/deepspeech_wrap.cpp
swig -c++ -java -package org.mozilla.deepspeech.libdeepspeech -outdir libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/ -o jni/deepspeech_wrap.cpp jni/deepspeech.i
jni/deepspeech.i:23: Error: Syntax error in input(1).
make: *** [bindings] Error 1",output get run command clean configure project build successful actionable executed swig error syntax error input make error,issue,negative,positive,positive,positive,positive,positive
508425262,"> ok i'll read through it. how about that error I was getting with that ./gradlew command?

Have you ran `make apk` ?",read error getting command ran make,issue,negative,neutral,neutral,neutral,neutral,neutral
508420753,ok i'll read through it. how about that error I was getting with that ./gradlew command?,read error getting command,issue,negative,neutral,neutral,neutral,neutral,neutral
508414789,"> I understand from the documentation that it will play an existing audio in the phone. But I don't want that. I want to play an audio, the phone should record & then display the decoded results.
> So will running the make apk command serve my purpose?

The purpose of this APK is to demo a trivial use of the API on Android. Please read the code. The SpeechModule app produced from https://github.com/mozilla/androidspeech/ does mostly what you do, you should read its source code as well.",understand documentation play audio phone want want play audio phone record display running make command serve purpose purpose trivial use android please read code produced mostly read source code well,issue,positive,positive,positive,positive,positive,positive
508413718,"I understand from the documentation that it will play an existing audio in the phone. But I don't want that. I want to play an audio, the phone should record & then display the decoded results.
So will running the make apk command serve my purpose?",understand documentation play audio phone want want play audio phone record display running make command serve purpose,issue,positive,neutral,neutral,neutral,neutral,neutral
508408316,"> This will work for only the pre trained model? What if I want to use my own trained model? Same procedure?

I don't understand your question: another model will just be a different `.tflite` file, no change to the library ...",work trained model want use trained model procedure understand question another model different file change library,issue,negative,neutral,neutral,neutral,neutral,neutral
508407737,This will work for only the pre trained model? What if I want to use my own trained model? Same procedure?,work trained model want use trained model procedure,issue,negative,neutral,neutral,neutral,neutral,neutral
508405464,"> I thought that has to be done after running the ./gradlew command

If you read the documentation and the Makefile, you will see that `apk` target will take care of everything.",thought done running command read documentation see target take care everything,issue,negative,neutral,neutral,neutral,neutral,neutral
508405078,I thought that has to be done after running the ./gradlew command,thought done running command,issue,negative,neutral,neutral,neutral,neutral,neutral
508402519,"> This is the output I am getting on executing that command **./gradlew libdeepspeech:build**:
> 
> > Configure project :libdeepspeech
> > arm64-v8a armeabi-v7a x86_64
> > Task :libdeepspeech:compileDebugJavaWithJavac FAILED
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:4: error: cannot find symbol
> > private SWIGTYPE_p_StreamingState _sp;
> > ^
> > symbol:   class SWIGTYPE_p_StreamingState
> > location: class DeepSpeechStreamingState
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:6: error: cannot find symbol
> > public DeepSpeechStreamingState(SWIGTYPE_p_StreamingState sp) {
> > ^
> > symbol:   class SWIGTYPE_p_StreamingState
> > location: class DeepSpeechStreamingState
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:10: error: cannot find symbol
> > public SWIGTYPE_p_StreamingState get() {
> > ^
> > symbol:   class SWIGTYPE_p_StreamingState
> > location: class DeepSpeechStreamingState
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:11: error: cannot find symbol
> > SWIGTYPE_p_p_ModelState _mspp;
> > ^
> > symbol:   class SWIGTYPE_p_p_ModelState
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:12: error: cannot find symbol
> > SWIGTYPE_p_ModelState   _msp;
> > ^
> > symbol:   class SWIGTYPE_p_ModelState
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:32: error: cannot find symbol
> > public Metadata sttWithMetadata(short[] buffer, int buffer_size, int sample_rate) {
> > ^
> > symbol:   class Metadata
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:54: error: cannot find symbol
> > public Metadata finishStreamWithMetadata(DeepSpeechStreamingState ctx) {
> > ^
> > symbol:   class Metadata
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:15: error: cannot find symbol
> > this._mspp = impl.new_modelstatep();
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:16: error: cannot find symbol
> > impl.CreateModel(modelPath, n_cep, n_context, alphabetPath, beam_width, this._mspp);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:17: error: cannot find symbol
> > this._msp  = impl.modelstatep_value(this._mspp);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:21: error: cannot find symbol
> > impl.DestroyModel(this._msp);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:25: error: cannot find symbol
> > impl.EnableDecoderWithLM(this._msp, alphabet, lm, trie, lm_alpha, lm_beta);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:29: error: cannot find symbol
> > return impl.SpeechToText(this._msp, buffer, buffer_size, sample_rate);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:33: error: cannot find symbol
> > return impl.SpeechToTextWithMetadata(this._msp, buffer, buffer_size, sample_rate);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:37: error: cannot find symbol
> > SWIGTYPE_p_p_StreamingState ssp = impl.new_streamingstatep();
> > ^
> > symbol:   class SWIGTYPE_p_p_StreamingState
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:37: error: cannot find symbol
> > SWIGTYPE_p_p_StreamingState ssp = impl.new_streamingstatep();
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:38: error: cannot find symbol
> > impl.SetupStream(this._msp, prealloc_frames, sample_rate, ssp);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:39: error: cannot find symbol
> > return new DeepSpeechStreamingState(impl.streamingstatep_value(ssp));
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:43: error: cannot find symbol
> > impl.FeedAudioContent(ctx.get(), buffer, buffer_size);
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:47: error: cannot find symbol
> > return impl.IntermediateDecode(ctx.get());
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:51: error: cannot find symbol
> > return impl.FinishStream(ctx.get());
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > /home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:55: error: cannot find symbol
> > return impl.FinishStreamWithMetadata(ctx.get());
> > ^
> > symbol:   variable impl
> > location: class DeepSpeechModel
> > 22 errors
> 
> FAILURE: Build failed with an exception.
> 
>     * What went wrong:
>       Execution failed for task ':libdeepspeech:compileDebugJavaWithJavac'.
> 
> 
> > Compilation failed; see the compiler error output for details.
> 
>     * Try:
>       Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.
> 
>     * Get more help at https://help.gradle.org
> 
> 
> BUILD FAILED in 0s
> 10 actionable tasks: 1 executed, 9 up-to-date

https://github.com/mozilla/DeepSpeech/blob/master/native_client/java/README.md#android-demo-apk

`make apk`, did you do this ?",output getting command build configure project task error find symbol private symbol class location class error find symbol public symbol class location class error find symbol public get symbol class location class error find symbol symbol class location class error find symbol symbol class location class error find symbol public short buffer symbol class location class error find symbol public symbol class location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol alphabet symbol variable location class error find symbol return buffer symbol variable location class error find symbol return buffer symbol variable location class error find symbol symbol class location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol return new symbol variable location class error find symbol buffer symbol variable location class error find symbol return symbol variable location class error find symbol return symbol variable location class error find symbol return symbol variable location class failure build exception went wrong execution task compilation see compiler error output try run option get stack trace run option get log output run scan get full get help build actionable executed make,issue,negative,negative,neutral,neutral,negative,negative
508401991,"This is the output I am getting on executing that command **./gradlew libdeepspeech:build**:


> Configure project :libdeepspeech 
arm64-v8a armeabi-v7a x86_64
> Task :libdeepspeech:compileDebugJavaWithJavac FAILED
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:4: error: cannot find symbol
    private SWIGTYPE_p_StreamingState _sp;
            ^
  symbol:   class SWIGTYPE_p_StreamingState
  location: class DeepSpeechStreamingState
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:6: error: cannot find symbol
    public DeepSpeechStreamingState(SWIGTYPE_p_StreamingState sp) {
                                    ^
  symbol:   class SWIGTYPE_p_StreamingState
  location: class DeepSpeechStreamingState
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechStreamingState.java:10: error: cannot find symbol
    public SWIGTYPE_p_StreamingState get() {
           ^
  symbol:   class SWIGTYPE_p_StreamingState
  location: class DeepSpeechStreamingState
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:11: error: cannot find symbol
    SWIGTYPE_p_p_ModelState _mspp;
    ^
  symbol:   class SWIGTYPE_p_p_ModelState
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:12: error: cannot find symbol
    SWIGTYPE_p_ModelState   _msp;
    ^
  symbol:   class SWIGTYPE_p_ModelState
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:32: error: cannot find symbol
    public Metadata sttWithMetadata(short[] buffer, int buffer_size, int sample_rate) {
           ^
  symbol:   class Metadata
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:54: error: cannot find symbol
    public Metadata finishStreamWithMetadata(DeepSpeechStreamingState ctx) {
           ^
  symbol:   class Metadata
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:15: error: cannot find symbol
        this._mspp = impl.new_modelstatep();
                     ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:16: error: cannot find symbol
        impl.CreateModel(modelPath, n_cep, n_context, alphabetPath, beam_width, this._mspp);
        ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:17: error: cannot find symbol
        this._msp  = impl.modelstatep_value(this._mspp);
                     ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:21: error: cannot find symbol
        impl.DestroyModel(this._msp);
        ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:25: error: cannot find symbol
        impl.EnableDecoderWithLM(this._msp, alphabet, lm, trie, lm_alpha, lm_beta);
        ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:29: error: cannot find symbol
        return impl.SpeechToText(this._msp, buffer, buffer_size, sample_rate);
               ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:33: error: cannot find symbol
        return impl.SpeechToTextWithMetadata(this._msp, buffer, buffer_size, sample_rate);
               ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:37: error: cannot find symbol
        SWIGTYPE_p_p_StreamingState ssp = impl.new_streamingstatep();
        ^
  symbol:   class SWIGTYPE_p_p_StreamingState
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:37: error: cannot find symbol
        SWIGTYPE_p_p_StreamingState ssp = impl.new_streamingstatep();
                                          ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:38: error: cannot find symbol
        impl.SetupStream(this._msp, prealloc_frames, sample_rate, ssp);
        ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:39: error: cannot find symbol
        return new DeepSpeechStreamingState(impl.streamingstatep_value(ssp));
                                            ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:43: error: cannot find symbol
        impl.FeedAudioContent(ctx.get(), buffer, buffer_size);
        ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:47: error: cannot find symbol
        return impl.IntermediateDecode(ctx.get());
               ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:51: error: cannot find symbol
        return impl.FinishStream(ctx.get());
               ^
  symbol:   variable impl
  location: class DeepSpeechModel
/home/neha/DeepSpeech/native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/DeepSpeechModel.java:55: error: cannot find symbol
        return impl.FinishStreamWithMetadata(ctx.get());
               ^
  symbol:   variable impl
  location: class DeepSpeechModel
22 errors


FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':libdeepspeech:compileDebugJavaWithJavac'.
> Compilation failed; see the compiler error output for details.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 0s
10 actionable tasks: 1 executed, 9 up-to-date",output getting command build configure project task error find symbol private symbol class location class error find symbol public symbol class location class error find symbol public get symbol class location class error find symbol symbol class location class error find symbol symbol class location class error find symbol public short buffer symbol class location class error find symbol public symbol class location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol alphabet symbol variable location class error find symbol return buffer symbol variable location class error find symbol return buffer symbol variable location class error find symbol symbol class location class error find symbol symbol variable location class error find symbol symbol variable location class error find symbol return new symbol variable location class error find symbol buffer symbol variable location class error find symbol return symbol variable location class error find symbol return symbol variable location class error find symbol return symbol variable location class failure build exception went wrong execution task compilation see compiler error output try run option get stack trace run option get log output run scan get full get help build actionable executed,issue,negative,negative,neutral,neutral,negative,negative
508401062,"> Hi
> I went through the documentation. I followed the steps. Now when I try to run the command ./gradlew libdeepspeech:build
> Execution failed for task ':libdeepspeech:compileDebugJavaWithJavac'

Again, if you don't share more of the output, it's going to be hard to help.",hi went documentation try run command build execution task share output going hard help,issue,positive,negative,negative,negative,negative,negative
508396142,Turns out with some investigation one can reproduce the issue on mostly every NodeJS version ...,turn investigation one reproduce issue mostly every version,issue,negative,positive,positive,positive,positive,positive
508372589,"Hi
I went through the documentation. I followed the steps. Now when I try to run the command ./gradlew libdeepspeech:build
Execution failed for task ':libdeepspeech:compileDebugJavaWithJavac'",hi went documentation try run command build execution task,issue,negative,neutral,neutral,neutral,neutral,neutral
508145688,"So, hacking `native_client/javascript/client.js` for looping around in `metadataToString()`, I could reproduce the issue on my system:

```
==22104== LEAK SUMMARY:
==22104==    definitely lost: 94 bytes in 2 blocks
==22104==    indirectly lost: 0 bytes in 0 blocks
==22104==      possibly lost: 276,282 bytes in 85 blocks
==22104==    still reachable: 949,617,787 bytes in 60,240 blocks
==22104==                       of which reachable via heuristic:
==22104==                         stdstring          : 181 bytes in 4 blocks
==22104==                         newarray           : 67,840 bytes in 225 blocks
==22104==                         multipleinheritance: 312 bytes in 3 blocks
==22104==         suppressed: 0 bytes in 0 blocks
==22104== 
==22104== ERROR SUMMARY: 25 errors from 25 contexts (suppressed: 2 from 2)
==22104== 
==22104== 1 errors in context 1 of 25:
==22104== Jump to the invalid address stated on the next line
==22104==    at 0x0: ???
==22104==    by 0xDE7439: v8::internal::GlobalHandles::PostGarbageCollectionProcessing(v8::internal::GarbageCollector, v8::GCCallbackFlags) (in /home/alex/tmp/deepspeech/0.6.0a1/node-v9.11.2-linux-x64/bin/node)
==22104==    by 0xE16626: v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) (in /home/alex/tmp/deepspeech/0.6.0a1/node-v9.11.2-linux-x64/bin/node)
==22104==    by 0xE1746D: v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) (in /home/alex/tmp/deepspeech/0.6.0a1/node-v9.11.2-linux-x64/bin/node)
==22104==    by 0xDBB371: v8::internal::Factory::NewFillerObject(int, bool, v8::internal::AllocationSpace) (in /home/alex/tmp/deepspeech/0.6.0a1/node-v9.11.2-linux-x64/bin/node)
==22104==    by 0x103430F: v8::internal::Runtime_AllocateInNewSpace(int, v8::internal::Object**, v8::internal::Isolate*) (in /home/alex/tmp/deepspeech/0.6.0a1/node-v9.11.2-linux-x64/bin/node)
==22104==    by 0x2931EBD042FC: ???
==22104==    by 0x2931EBD0C6B3: ???
==22104==    by 0x2931EBDF1EF5: ???
==22104==    by 0x2931EBDBD195: ???
==22104==    by 0x2931EBDBD195: ???
==22104==    by 0x2931EBDBD195: ???
==22104==  Address 0x0 is not stack'd, malloc'd or (recently) free'd
```",hacking looping around could reproduce issue system leak summary definitely lost indirectly lost possibly lost still reachable reachable via heuristic suppressed error summary suppressed context jump invalid address stated next line bool address stack recently,issue,negative,neutral,neutral,neutral,neutral,neutral
508065068,"> Ya because of this error we built our own app and tried the tflite model. If you didn't use Android Studio, then can I know which platform did you use?

As documented under `native_client/java/`, nothing specific, just `gradle` in command-line ...

So you wrote your own code, you don't follow the docs, you don't use the java android bindings.

If you don't share more informations, we can't help you. If you run tflite directly, then you should look at the implementation in `native_client/deepspeech.cc` to see how to run.",ya error built tried model use android studio know platform use nothing specific wrote code follow use android share ca help run directly look implementation see run,issue,negative,positive,neutral,neutral,positive,positive
508053495,"Ya because of this error we built our own app and tried the tflite model. If you didn't use Android Studio, then can I know which platform did you use?",ya error built tried model use android studio know platform use,issue,negative,neutral,neutral,neutral,neutral,neutral
508048178,"> SIMPLE: CMake Error: CMake can not determine linker language for target: deepspeech-jni

This is not really the same error as you reported. We don't use Android Studio, so I can't really help you if it's related. Have you tried following the documented steps ?

Please keep in mind the android app is just a very basic demo.",simple error determine linker language target really error use android studio ca really help related tried following please keep mind android basic,issue,negative,positive,neutral,neutral,positive,positive
508044703,"I tried opening your app. Trying to open your app in android studio throws the following errors:
```
SIMPLE: Build command failed.


SIMPLE: Error while executing process /home/neha/Android/Sdk/cmake/3.6.4111459/bin/cmake with arguments {-H/home/neha/DeepSpeech-master/native_client/java/libdeepspeech -B/home/neha/DeepSpeech-master/native_client/java/libdeepspeech/.externalNativeBuild/cmake/release/arm64-v8a -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=/home/neha/DeepSpeech-master/native_client/java/libdeepspeech/build/intermediates/cmake/release/obj/arm64-v8a -DCMAKE_BUILD_TYPE=Release -DANDROID_NDK=/home/neha/Android/Sdk/ndk-bundle -DCMAKE_CXX_FLAGS= -DCMAKE_TOOLCHAIN_FILE=/home/neha/Android/Sdk/ndk-bundle/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=/home/neha/Android/Sdk/cmake/3.6.4111459/bin/ninja -GAndroid Gradle - Ninja}


SIMPLE: -- Check for working C compiler: /home/neha/Android/Sdk/ndk-bundle/toolchains/llvm/prebuilt/linux-x86_64/bin/clang


SIMPLE: -- Check for working C compiler: /home/neha/Android/Sdk/ndk-bundle/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -- works


SIMPLE: -- Detecting C compiler ABI info


SIMPLE: -- Detecting C compiler ABI info - done


SIMPLE: -- Detecting C compile features


SIMPLE: -- Detecting C compile features - done


SIMPLE: -- Check for working CXX compiler: /home/neha/Android/Sdk/ndk-bundle/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++


SIMPLE: -- Check for working CXX compiler: /home/neha/Android/Sdk/ndk-bundle/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ -- works


SIMPLE: -- Detecting CXX compiler ABI info


SIMPLE: -- Detecting CXX compiler ABI info - done


SIMPLE: -- Detecting CXX compile features


SIMPLE: -- Detecting CXX compile features - done


SIMPLE: -- Configuring done


SIMPLE: CMake Error at CMakeLists.txt:13 (add_library):


SIMPLE:     ../jni/deepspeech_wrap.cpp


SIMPLE:   Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp


SIMPLE:   .hxx .in .txx


SIMPLE: CMake Error: CMake can not determine linker language for target: deepspeech-jni


SIMPLE: -- Generating done


SIMPLE: -- Build files have been written to: /home/neha/DeepSpeech-master/native_client/java/libdeepspeech/.externalNativeBuild/cmake/release/arm64-v8a
```",tried opening trying open android studio following simple build command simple error process simple check working compiler simple check working compiler work simple compiler simple compiler done simple compile simple compile done simple check working compiler simple check working compiler work simple compiler simple compiler done simple compile simple compile done simple done simple error simple simple tried simple simple error determine linker language target simple generating done simple build written,issue,negative,neutral,neutral,neutral,neutral,neutral
507996664,"@reuben This should hopefully force cache under task's directory as well, so we avoid populating /Users/build-users/.npm/ and waste disk space on macOS workers.",hopefully force cache task directory well avoid waste disk space,issue,negative,negative,negative,negative,negative,negative
507664521,"```
ds-worker-vm-sierra-light-9:node9 workeradmin$ ./node_modules/.bin/deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --alphabet deepspeech-0.5.1-models/alphabet.txt --audio audio/2830-3980-0043.wav --extended
Loading model from file deepspeech-0.5.1-models/output_graph.pbmm
TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.1-0-g4b29b78
2019-07-02 14:46:17.295030: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-02 14:46:17.311300: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-07-02 14:46:17.311359: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-07-02 14:46:17.311373: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-07-02 14:46:17.311383: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
Loaded model in 0.08451s.
Running inference.
experienced proof this
Inference took 11.58s for 1.975s audio file.
ds-worker-vm-sierra-light-9:node9 workeradmin$ echo $?
0
```",node model alphabet audio extended loading model file binary use unknown unknown unknown unknown loaded model running inference experienced proof inference took audio file node echo,issue,negative,positive,neutral,neutral,positive,positive
507644176,@zikola Can you share a bit more of context ? Output etc. ? ,share bit context output,issue,negative,neutral,neutral,neutral,neutral,neutral
507392128,Ok thanks for the answer! Feel free to close this issue if you'd like.,thanks answer feel free close issue like,issue,positive,positive,positive,positive,positive,positive
507183167,"I gave a try to run nodejs bindings under valgrind, but could not uncover any memory access issues. There are leakages reported, though.",gave try run could uncover memory access though,issue,negative,neutral,neutral,neutral,neutral,neutral
507182645,"@Scofield666 So you are running v0.3.0 binaries with an incompatible model. Either use a v0.3.0 model or v0.5.1 binaries.

Also, you don't need to install `tensorflow-gpu==1.11.0`, this is only required if you perform training.

Please re-open if that's not solving your problem.",running incompatible model either use model also need install perform training please problem,issue,negative,neutral,neutral,neutral,neutral,neutral
507155750,"Currently, there is no plan to provide a pip install for retraining a model.

PS: Thanks for the encouraging words!",currently plan provide pip install model thanks encouraging,issue,positive,positive,neutral,neutral,positive,positive
507050773,Looks like you are trying to run v0.5 model with v0.3.0. That's not going to work. ,like trying run model going work,issue,negative,neutral,neutral,neutral,neutral,neutral
506994599,"Feel free to try pytorch version of sparse_image_warp: https://github.com/bobchennan/sparse_image_warp_pytorch

Any tests and comparison are welcomed. Code is written by following tensorflow implementation.",feel free try version comparison code written following implementation,issue,positive,positive,positive,positive,positive,positive
506942973,i found it in release and problem solved when i upgrade to v0.6.0-alpha thank you,found release problem upgrade thank,issue,negative,neutral,neutral,neutral,neutral,neutral
506942687,"yes i trained from master like 2 weeks ago ,where can i find v0.6.0 if it is not the version in pip",yes trained master like ago find version pip,issue,positive,neutral,neutral,neutral,neutral,neutral
506942049,"You trained out of master? So your binary is v0.5.1, thus incompatible. Please install some v0.6.0-alpha ",trained master binary thus incompatible please install,issue,negative,neutral,neutral,neutral,neutral,neutral
506936529,it seems the problem with the model i tried pre-trained model and it worked so what is gone wrong with my own model,problem model tried model worked gone wrong model,issue,negative,negative,negative,negative,negative,negative
506935885,"now i tried the following command as in documentation but same error
`deepspeech --model sd/output_graph.pbmm --alphabet sd/alphabet.txt --audio sd/audio.wav`",tried following command documentation error model alphabet audio,issue,negative,neutral,neutral,neutral,neutral,neutral
506935390,it is a model i have trained and i don't know what other method to try the inference on python ,model trained know method try inference python,issue,negative,neutral,neutral,neutral,neutral,neutral
506933582,Where is this model coming from? Why do you run client.py directly? ,model coming run directly,issue,negative,positive,neutral,neutral,positive,positive
506563564,Thank you both for the fast response - and fast implementation!,thank fast response fast implementation,issue,negative,positive,positive,positive,positive,positive
506302545,"> I'm looking to create my own native client (in C++) and to do this you need both the shared library and the appropriate header file. A quick look in the `native_client` directory turns up what appears to be the correct header file (deepspeech.h), but I'm just wondering why this isn't fetched alongside `libdeepspeech.so` by default.

Mostly because we never felt this was really needed. The tooling you refer to is usesul because prebuilt binaries can be non trivial to find and to us help also with CI.

Given the header is directly accessible from Github for downloading, easy to discover, and already here when you `git clone` we never considereed it would ne needed.",looking create native client need library appropriate header file quick look directory turn correct header file wondering fetched alongside default mostly never felt really tooling refer non trivial find u help also given header directly accessible easy discover already git clone never would ne,issue,positive,positive,positive,positive,positive,positive
506302501,"Good point, we should package that with the native client package.",good point package native client package,issue,negative,positive,positive,positive,positive,positive
506047980,"> But this TF page (https://www.tensorflow.org/install/gpu - see ""install cuda with apt"" / ""Ubuntu 18.04 (CUDA 10)"" section) suggests installing cudnn7.6 (not 7.5) for tensorflow on gpu. Although that presumably refers to the tensorflow-gpu version on pypi, which is 1.14 not 1.13.

We did copy from the TensorFlow pages at the time of `r1.13`, after having numeral issues opened by people not using the proper version and not following our link to their docs. So except if we made a mistake or if they did, yes, it's much more likely that `r1.14` is the reason for `v7.6`.


> Would it be worthwhile for me to try installing tensorflow-gpu 1.14 and libcudnn7.6 and then rerunning DeepSpeech? Or would DeepSpeech not be expected to work on tensorflow-gpu 1.14?

Well you may have troubles with `ds_ctcdecoder` package, since it's built against `r1.13`, but that's the only thing that should really block you, if it does.",page see install apt section although presumably version copy time numeral people proper version following link except made mistake yes much likely reason would try would work well may package since built thing really block,issue,negative,positive,positive,positive,positive,positive
506023814,"re: 
> changing cuda or cudnn or tf version to something outside of the DeepSpeech required versions.

> ^ There is no such thing, we just point to TensorFlow's versions.

...this might be a key? So the DeepSpeech readme says ""The GPU capable builds (Python, NodeJS, C++, etc) depend on the same CUDA runtime as upstream TensorFlow. Currently with TensorFlow 1.13 it depends on CUDA 10.0 and CuDNN v7.5."" 

But this TF page (https://www.tensorflow.org/install/gpu - see ""install cuda with apt"" / ""Ubuntu 18.04 (CUDA 10)"" section) suggests installing cudnn7.6 (not 7.5) for tensorflow on gpu. Although that presumably refers to the tensorflow-gpu version on pypi, which is 1.14 not 1.13.

Would it be worthwhile for me to try installing tensorflow-gpu 1.14 and libcudnn7.6 and then rerunning DeepSpeech? Or would DeepSpeech not be expected to work on tensorflow-gpu 1.14?",version something outside thing point might key capable python depend upstream currently page see install apt section although presumably version would try would work,issue,negative,positive,positive,positive,positive,positive
506017351,"> changing cuda or cudnn or tf version to something outside of the DeepSpeech required versions.

There is no such thing, we just point to TensorFlow's versions.



> If you'd like me to submit a PR with a note in the readme with references to those upstream tf issues and the allow_growth ""solution"" that worked for me, let me know and I'll submit one.

That could be a nice middle ground in the mean time, yes.



> I may chime in on one of the upstream tensorflow issues, but the issues I've found (one or two you linked to here) are closed and all proposed solutions seem to be either:

it seems pretty obvious to me the error message is misleading and there is another root in your case.",version something outside thing point like submit note upstream solution worked let know submit one could nice middle ground mean time yes may chime one upstream found one two linked closed seem either pretty obvious error message misleading another root case,issue,positive,positive,neutral,neutral,positive,positive
506016407,"Hi lissyx,

I ran with Python3.7. Happy to update my pipfile to another version if you have one in mind but I'm not optimistic it'll fix it?

I may chime in on one of the upstream tensorflow issues, but the issues I've found (one or two you linked to here) are closed and all proposed solutions seem to be either:
- setting memory_growth to true, or
- changing cuda or cudnn or tf version to something outside of the DeepSpeech required versions.

Hopefully eventually I'll come to enough of an understanding of how cuda/cudnn/tf work together to have more insight into this sort of thing. But at the moment it all seems very mysterious to me.

If you'd like me to submit a PR with a note in the readme with references to those upstream tf issues and the allow_growth ""solution"" that worked for me, let me know and I'll submit one.",hi ran python happy update another version one mind optimistic fix may chime one upstream found one two linked closed seem either setting true version something outside hopefully eventually come enough understanding work together insight sort thing moment mysterious like submit note upstream solution worked let know submit one,issue,positive,positive,positive,positive,positive,positive
506008851,"@MaxPowerWasTaken I guess a note in README would be a good PR at least, we've got already two people chiming in on your solution ...",guess note would good least got already two people solution,issue,positive,positive,positive,positive,positive,positive
506008567,"> Ok finally got it to work (still with `CUDA_VISIBLE_DEVICES=0`) by updating an environment variable. I added: `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` to top of DeepSpeech.py
> 
> ...and now `./bin/run-ldc93s1.sh` trains without errors.

Thank you! I've been dealing with this problem for a LONG time and this finally solved it.",finally got work still environment variable added top without thank dealing problem long time finally,issue,negative,positive,positive,positive,positive,positive
506007908,"Weird, there's no mention of libcudnn or any CUDA libraries at all in that log, like it's not even trying to load them. ",weird mention log like even trying load,issue,negative,negative,negative,negative,negative,negative
505997178,"> Hi lissyx,
> 
> I completely removed miniconda from my machine, then reran. I seem to be getting a very similar log, though confirmed no references to conda anymore.
> 
> https://gist.github.com/MaxPowerWasTaken/71366e8db01e2d07883548b4844a7700

Can you try a different python version ? But at some point, I would really advise sharing that in an upstream issue.",hi completely removed machine seem getting similar log though confirmed try different python version point would really advise upstream issue,issue,negative,positive,positive,positive,positive,positive
505991513,"Hi lissyx, 

I completely removed miniconda from my machine, then reran. I seem to be getting a very similar log, though confirmed no references to conda anymore.

https://gist.github.com/MaxPowerWasTaken/71366e8db01e2d07883548b4844a7700",hi completely removed machine seem getting similar log though confirmed,issue,negative,positive,positive,positive,positive,positive
505923854,"> Hi lissyx,
> 
> Here's a link to my full log from rerunning `./bin/run-ldc93s1.sh ` after replacing `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` with `os.environ['LD_DEBUG'] = 'all'` in my DeepSpeech.py file:
> 
> https://gist.github.com/MaxPowerWasTaken/27a578bd7592077c9658af5981aab996

Weird, there is no mention at all of `libcuda` or `libcudnn` being loaded. But close to the error, we can see some `miniconda3` libs being loaded and used:
```
     30172:	binding file /home/mepstein/miniconda3/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-x86_64-linux-gnu.so [0] to /home/mepstein/miniconda3/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-x86_64-linux-gnu.so [0]: normal symbol `PyInit__posixsubprocess'
```

@MaxPowerWasTaken Could you try to make a `conda`-free virtual environment ?",hi link full log file weird mention loaded close error see loaded used binding file normal symbol could try make virtual environment,issue,negative,negative,neutral,neutral,negative,negative
505917940,"Hi lissyx,

Here's a link to my full log from rerunning `./bin/run-ldc93s1.sh ` after replacing `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` with `os.environ['LD_DEBUG'] = 'all'` in my DeepSpeech.py file:

https://gist.github.com/MaxPowerWasTaken/27a578bd7592077c9658af5981aab996
",hi link full log file,issue,negative,positive,positive,positive,positive,positive
505887546,"So from looking into tensorflow source code: `Grow GPU memory as needed at the cost of fragmentation`. I'm not a big fan of forcing that by default. And given the `nvidia-smi` outputs, I'm unsure why it failed in the first place.

@MaxPowerWasTaken Could you please do the `LD_DEBUG=all` thing, please? We still don't know if there's something else touching cudnn.",looking source code grow memory cost fragmentation big fan forcing default given unsure first place could please thing please still know something else touching,issue,positive,positive,positive,positive,positive,positive
505842086,"> Ok finally got it to work (still with `CUDA_VISIBLE_DEVICES=0`) by updating allow_growth as an environment variable. I added: `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` to top of DeepSpeech.py
> 
> ...and now `./bin/run-ldc93s1.sh` trains without errors.

Thanks ! ",finally got work still environment variable added top without thanks,issue,negative,positive,positive,positive,positive,positive
505725917,"@dabinat This is not easy to do.

Someone may change the width of the network which would change the maximum batch size. Google may change the implementation of LSTM's which would change the maximum batch size. NVIDIA may change the implementation of LSTM's which would change the maximum batch size.... There are many other similar problematic scenarios.

It seems that this cure may be worse than the sickness.",easy someone may change width network would change maximum batch size may change implementation would change maximum batch size may change implementation would change maximum batch size many similar problematic cure may worse sickness,issue,negative,positive,positive,positive,positive,positive
505699418,"Seeing as the batch size is dependent upon VRAM, perhaps DeepSpeech could detect the VRAM and automatically choose an appropriate value?",seeing batch size dependent upon perhaps could detect automatically choose appropriate value,issue,negative,positive,positive,positive,positive,positive
505692247,"Yep, I figured it out, should have commented here after I got it working. I was making sure PR #2212 doesn't break things with submodules.",yep figured got working making sure break,issue,positive,positive,positive,positive,positive,positive
505680051,"```
(base) mepstein@pop-os:~$ nvidia-smi
Tue Jun 25 21:16:52 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 2060    On   | 00000000:01:00.0 Off |                  N/A |
| N/A   42C    P8     3W /  N/A |    324MiB /  5904MiB |      5%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1552      G   /usr/lib/xorg/Xorg                            27MiB |
|    0      1719      G   /usr/bin/gnome-shell                          55MiB |
|    0      2795      G   /usr/lib/xorg/Xorg                           128MiB |
|    0      3083      G   cinnamon                                      60MiB |
|    0      3370      G   ...quest-channel-token=6465864532133321617    50MiB |
+-----------------------------------------------------------------------------+
```
...
```
(base) mepstein@pop-os:~$ cd DeepSpeech/
(base) mepstein@pop-os:~/DeepSpeech$ source dsenv/bin/activate
(dsenv) (base) mepstein@pop-os:~/DeepSpeech$ ./bin/run-ldc93s1.sh 
```

...100 epochs in, while still training, in another shell tab:
```
(dsenv) (base) mepstein@pop-os:~/DeepSpeech$ nvidia-smi
Tue Jun 25 21:21:29 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 2060    On   | 00000000:01:00.0 Off |                  N/A |
| N/A   41C    P5    12W /  N/A |    875MiB /  5904MiB |     23%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1552      G   /usr/lib/xorg/Xorg                            27MiB |
|    0      1719      G   /usr/bin/gnome-shell                          55MiB |
|    0      2795      G   /usr/lib/xorg/Xorg                           128MiB |
|    0      3083      G   cinnamon                                      59MiB |
|    0      3370      G   ...quest-channel-token=6465864532133321617    49MiB |
|    0     19352      C   python                                       541MiB |
+-----------------------------------------------------------------------------+
```
",base tue driver version version name volatile fan temp compute mib mib default memory type process name usage mib mib mib cinnamon mib mib base base source base still training another shell tab base tue driver version version name volatile fan temp compute mib mib default memory type process name usage mib mib mib cinnamon mib mib python mib,issue,positive,negative,negative,negative,negative,negative
505653101,"The issue was because instead of creating a junction I had copied the folder native_client to tensorflow. I moved the folders to an ntfs drive and tried again, this time creating a junction. It now works without issue. Sorry for the noise.",issue instead junction copied folder drive tried time junction work without issue sorry noise,issue,negative,negative,negative,negative,negative,negative
505640250,"Hello, the issue here looks like E: needs admin privileges for writing, please try running the command with admin privileges.
Remove `--config=monolithic`, it says that duplicated configs may lead to unexpected behavior.

Try to use the recommended requirements, I don't know if vs 2015 setup is going to work. https://github.com/mozilla/DeepSpeech/tree/master/native_client/dotnet#prerequisites",hello issue like need writing please try running command remove may lead unexpected behavior try use know setup going work,issue,positive,positive,neutral,neutral,positive,positive
505628949,"> How can I test this scenario?

Possibly something like

```
mkdir test
cd test
git init
git submodule add https://github.com/mozilla/DeepSpeech.git DeepSpeech
git submodule add https://github.com/mozilla/tensorflow.git tensorflow
cd tensorflow 
git checkout r1.13
```
and then building ?

",test scenario possibly something like test test git git add git add git building,issue,negative,neutral,neutral,neutral,neutral,neutral
505623432,"Just out of curiosity, could you share the output of `nvidia-smi` before and during the `bin/run-ldc93s1.sh` execution?",curiosity could share output execution,issue,negative,neutral,neutral,neutral,neutral,neutral
505616675,"> Ok finally got it to work (still with `CUDA_VISIBLE_DEVICES=0`) by updating an environment variable. I added: `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` to top of DeepSpeech.py
> 
> ...and now `./bin/run-ldc93s1.sh` trains without errors.

So it would confirm it's this `allow_growth` and just that your way of setting it was wrong. i'd like to understand better what that option does, and if we should use it.",finally got work still environment variable added top without would confirm way setting wrong like understand better option use,issue,negative,positive,positive,positive,positive,positive
505598701,"Ok finally got it to work (still with `CUDA_VISIBLE_DEVICES=0`) by updating allow_growth as an environment variable. I added: `os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'` to top of DeepSpeech.py

...and now `./bin/run-ldc93s1.sh` trains without errors.
",finally got work still environment variable added top without,issue,negative,positive,positive,positive,positive,positive
505593244,">     * add `c.session_config.gpu_options.allow_growth = True` directly under the following line in `utils/config.py`:

At least that looks like it is consistent with `r1.13` codebase

@MaxPowerWasTaken maybe try do set `LD_DEBUG=all` in your env when running, to catch where `CuDNN` comes from. Maybe there's some mixup somewhere, and it is not the one you want that loads.",add true directly following line least like consistent maybe try set running catch come maybe somewhere one want,issue,negative,positive,neutral,neutral,positive,positive
505586794,"Ok I tried to set allow_growth to True, but I'm still getting the same error with `CUDA_VISIBLE_DEVICES=0`. It's possible I am setting allow_growth wrong, but I don't think I am?

Since `./bin/run-ldc93s1.sh` calls `python -u DeepSpeech.py` and `DeepSpeech.py` imports the session config from utils/config.py, I tried the following:

- add `c.session_config.gpu_options.allow_growth = True` directly under the following line in `utils/config.py`:
    -     c.session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=FLAGS.log_placement,
                                      inter_op_parallelism_threads=FLAGS.inter_op_parallelism_threads,
                                      intra_op_parallelism_threads=FLAGS.intra_op_parallelism_threads)

- reran `./bin/run-ldc93s1.sh` from shell.",tried set true still getting error possible setting wrong think since python session tried following add true directly following line shell,issue,negative,positive,neutral,neutral,positive,positive
505569888,"Let's wait for this, because I don't buy this solution. As reuben said, we do train successfully this script... ",let wait buy solution said train successfully script,issue,positive,positive,positive,positive,positive,positive
505569645,"I don't think that change is solving your issue, it's just hiding all GPUs and thus disabling use of CUDA entirely.",think change issue thus use entirely,issue,negative,neutral,neutral,neutral,neutral,neutral
505569253,"Interesting. I have not tried the growth option yet after the updating `CUDA_VISIBLE_DEVICES` solved my issue, but I will try it soon (with `CUDA_VISIBLE_DEVICES=0`) and report back here.",interesting tried growth option yet issue try soon report back,issue,positive,positive,positive,positive,positive,positive
505568501,"Yes, I'm frequently training on RTX2080TI. have you tried the growth option? ",yes frequently training tried growth option,issue,positive,positive,neutral,neutral,positive,positive
505565843,"Interesting, I wonder why in my case it's necessary. I just confirmed that with original `/bin/run-ldc93s1.sh` I get the original error I posted, and that once again changing that single line of code and rerunning `/bin/run-ldc93s1.sh` trains successfully. 

Just out of curiosity, do you run/test deepspeech on any RTX-series GPUs? I read somewhere today that the RTX 2060/2070 seem to be implicated frequently in these mystery cuda/cudnn errors, and I do have an RTX 2060...

In any case, my issue is solved so I will close this. Thanks again.",interesting wonder case necessary confirmed original get original error posted single line code successfully curiosity read somewhere today seem frequently mystery case issue close thanks,issue,positive,positive,positive,positive,positive,positive
505558795,"That line does not need to be edited first, we run it without changes on systems with and without GPUs with no problems.",line need first run without without,issue,negative,positive,positive,positive,positive,positive
505557994,"So update (good news, and a question):
 - changing `export CUDA_VISIBLE_DEVICES=0` to `export CUDA_VISIBLE_DEVICES=-1` worked!

But I made that change within DeepSpeech's script `./bin/run-ldc93s1.sh`, and the comment above suggests that's because training that dataset (a single audio clip) wouldn't work on GPUs:
```
# Force only one visible device because we have a single-sample dataset
# and when trying to run on multiple devices (like GPUs), this will break
export CUDA_VISIBLE_DEVICES=0
``` 
But the DeepSpeech readme suggests using that script to train on GPUs. Should the DeepSpeech Readme surrounding ""Training a Model....`/bin/run-ldc93s1.sh`..."" be updated in some manner (e.g. that if running on gpu, that one line of `run-ldc93s1.sh` needs to be edited first)? If so, I'd be happy to take out a PR to try and make that clarification in the readme, if that would be helpful.

Thanks again to both of you for the help!",update good news question export export worked made change within script comment training single audio clip would work force one visible device trying run multiple like break export script train surrounding training model manner running one line need first happy take try make clarification would helpful thanks help,issue,positive,positive,positive,positive,positive,positive
505546201,"> removing miniconda from my system (I don't have full anaconda and used venv not conda for virtual env on my DeepSpeech env, but I do have miniconda python distribution) and then recreating venv and trying to retrain model again.

Idon't know what `miniconda` might do, but it's indeed recurrent we got people with issues using this.",removing system full anaconda used virtual python distribution trying retrain model know might indeed recurrent got people,issue,negative,positive,positive,positive,positive,positive
505545868,"> creating a new venv with tf-gpu downgraded to 1.8

Don't, it's not going to work

> ""allow gpu memory growth"" with...

this code might need to be adjusted, it seems to be for TensorFlow v2",new going work allow memory growth code might need,issue,positive,positive,positive,positive,positive,positive
505545142,"Ok thanks for the links and suggestions lissyx and reuben. Based on your suggestions and links, I will try the following things and then report back:

- change `export CUDA_VISIBLE_DEVICES=0` to `export CUDA_VISIBLE_DEVICES=-1` (though I'm not sure where yet, but should be able to figure out quickly)
- creating a new venv with tf-gpu downgraded to 1.8
- ""allow gpu memory growth"" with...
```
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
```
- removing miniconda from my system (I don't have full anaconda and used venv not conda for virtual env on my DeepSpeech env, but I do have miniconda python distribution) and then recreating venv and trying to retrain model again. 

After trying all of these I will report back with what worked (hopefully one of these will), or if the problem persists.",thanks link based link try following report back change export export though sure yet able figure quickly new allow memory growth import import true session removing system full anaconda used virtual python distribution trying retrain model trying report back worked hopefully one problem,issue,positive,positive,positive,positive,positive,positive
505537475,"> I will keep looking into this and appreciate the suggestions but the presumption that I've not tried googling this issue or immediately jumped to posting an issue is just not accurate.

And the presumption that we closed without caring is also inaccurate. People report issue that we don't reproduce, with unsupported CuDNN version, half of the required information are not filled, how can you expect to be able to help then ?


> Hi lissyx, I assure you I've spent more than two days trying to get past this error before filing this issue and have read many many threads on github, discourse, and nvidia devtalk. The Tensorflow issue you pointed to is full of complaints about cuda 9.0 with tensorflow 1.12 and multiple suggestions to downgrade to tf 1.8. Since (per DeepSpeech) I am running cuda 10.0 and tf 1.13, that doesn't seem to be a promising avenue.

Some suggestions seems to apply to multiple versions. Have you tried it?



> It's hard to imagine my current issue is a GPU memory issue since my GPU memory has 573MiB / 5904MiB free and the DeepSpeech training script failed on the first epoch training on a single audio file.

Well, I'm just inferring from the above TensorFlow issue and the behavior of TensorFlow to try to allocate all memory for itself.",keep looking appreciate presumption tried issue immediately posting issue accurate presumption closed without also inaccurate people report issue reproduce unsupported version half information filled expect able help hi assure spent two day trying get past error filing issue read many many discourse issue pointed full multiple downgrade since per running seem promising avenue apply multiple tried hard imagine current issue memory issue since memory mib mib free training script first epoch training single audio file well issue behavior try allocate memory,issue,positive,positive,positive,positive,positive,positive
505536966,Are you using conda in the same system? It has a tendency to break everything that doesn't use the conda installed packages/tools. Check that you're not loading CUDA/cuDNN/NCCL from Conda instead of the upstream installs.,system tendency break everything use check loading instead upstream,issue,negative,neutral,neutral,neutral,neutral,neutral
505536441,"Hi lissyx, I assure you I've spent more than two days trying to get past this error before filing this issue and have read many many threads on github, discourse, and nvidia devtalk. The Tensorflow issue you pointed to is full of complaints about cuda 9.0 with tensorflow 1.12 and multiple suggestions to downgrade to tf 1.8. Since (per DeepSpeech) I am running cuda 10.0 and tf 1.13, that doesn't seem to be a promising avenue. 

It's hard to imagine my current issue is a GPU memory issue since my GPU memory has 573MiB /  5904MiB free and the DeepSpeech training script failed on the first epoch training on a single audio file.

I will keep looking into this and appreciate the suggestions but the presumption that I've not tried googling this issue or immediately jumped to posting an issue is just not accurate. ",hi assure spent two day trying get past error filing issue read many many discourse issue pointed full multiple downgrade since per running seem promising avenue hard imagine current issue memory issue since memory mib mib free training script first epoch training single audio file keep looking appreciate presumption tried issue immediately posting issue accurate,issue,positive,positive,positive,positive,positive,positive
505533481,"@lissyx 

> Technically nothing stops from supporting resuming download, it's been working fine downloading from Github for me.

Initially it was not resuming I don't know if wget was not considering `-c` flag or what, but it used to hang among some of the redirections. Anyway I was able to download in 9 continued trials with a bash scripts.

@kdavis-mozilla 
> the download statistics are used within Mozilla as a measure of this project's success

Of course we understand downloads could be a parameter for evaluation and overcoming that decision is challenging for developers, yet, a very large number of seeders and leechers shows real time popularity and patrons for the project, you just need to convince  :).

@any-other-victim-of-issue

In case any one is having a problem downloading the script I am sharing a download script that might help:

```bash
#!/bin/bash
R=1
x=0
while [[ $R -ne 0 ]] ; do
    echo ""$x Attempt. Last status: $R""
    if [[ ! -f ""deepspeech-0.5.1-models.tar.gz"" ]] ; then
        echo ""No earlier file present. Exiting""
        exit 1
    fi
    wget --continue https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
    R=$?
    sleep .5
    x=$(( $x + 1 ))
done
```
change the url as it changes on release page otherwise you'll get restricted at `v0.5.1`. ",technically nothing supporting working fine initially know considering flag used among anyway able continued bash statistic used within measure project success course understand could parameter evaluation decision yet large number real time popularity project need convince case one problem script script might help bash echo attempt last status echo file present exit fi continue sleep done change release page otherwise get restricted,issue,positive,positive,positive,positive,positive,positive
505533043,"@MaxPowerWasTaken You can notice that the proposed documented fixes are posterior to the original issue you refer to, and that it seems to be related to a GPU memory issue when some other processes are using it.",notice posterior original issue refer related memory issue,issue,negative,positive,positive,positive,positive,positive
505532384,"> There's also an upstream issue: [tensorflow/tensorflow#24828](https://github.com/tensorflow/tensorflow/issues/24828)

Two seconds of googling would unveil that and you could try some of the fix some people are reporting to work.",also upstream issue two would unveil could try fix people work,issue,negative,neutral,neutral,neutral,neutral,neutral
505531306,"> Hi lissyx, thanks for the quick reply! I did not mean to sound argumentative, I only included ""this appears to be a bug to me"" because the prompt I was shown for filling out an issue included ""Please describe the problem clearly. Be sure to convey here why it's a bug or a feature request.""

Yeah, but at some point, we can't reproduce the error, and it's tensorflow-level error, so I'm sorry but when people start mixing unsupported CuDNN version in the mix, it's really not easy to help ...",hi thanks quick reply mean sound argumentative included bug prompt shown filling issue included please describe problem clearly sure convey bug feature request yeah point ca reproduce error error sorry people start unsupported version mix really easy help,issue,positive,positive,positive,positive,positive,positive
505530719,"Hi lissyx, thanks for the quick reply! I did not mean to sound argumentative, I only included ""this appears to be a bug to me"" because the prompt I was shown for filling out an issue included ""Please describe the problem clearly. Be sure to convey here why it's a bug or a feature request.""

I will try to override that `export CUDA_VISIBLE_DEVICES=0` now, thanks for the suggestion.",hi thanks quick reply mean sound argumentative included bug prompt shown filling issue included please describe problem clearly sure convey bug feature request try override export thanks suggestion,issue,positive,positive,positive,positive,positive,positive
505530360,"> tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
> 	 [[node tower_0/conv1d/Conv2D (defined at DeepSpeech.py:56) ]]

This is really not a DeepSpeech level error.",get convolution algorithm probably initialize try looking see warning log message printed node defined really level error,issue,negative,positive,positive,positive,positive,positive
505528861,"> This appears to be a bug to me because another user and I are both getting the same error, from running a DeepSpeech-provided bin script for retraining model, after installing DeepSpeech with the specified versions of TF/cuda/cudnn.

I could argue that it's working fine for a lot of other people ...

> + export CUDA_VISIBLE_DEVICES=0

This hides CUDA devices, have you tried without that ?",bug another user getting error running bin script model could argue working fine lot people export tried without,issue,negative,positive,positive,positive,positive,positive
505505971,"Yeah, I think this is useful to have. Importers tend to be low/zero maintenance so no much harm in adding more.",yeah think useful tend maintenance much harm,issue,negative,positive,positive,positive,positive,positive
505505545,@reuben Do you think I should review this and add it as a feature for others?,think review add feature,issue,negative,neutral,neutral,neutral,neutral,neutral
505435435,"I'll wait for taskcluster build to finish and merge, but you can already cherry-pick that",wait build finish merge already,issue,negative,neutral,neutral,neutral,neutral,neutral
505434973,fd156a6 is working fine. Thanks a lot for looking into this !,working fine thanks lot looking,issue,positive,positive,positive,positive,positive,positive
505433458,"Oh yeah, forgot that. I told you it was tricky :)",oh yeah forgot told tricky,issue,negative,neutral,neutral,neutral,neutral,neutral
505432497,"Sorry, still not working because I forgot to mention one issue: you need to silence pushd and popd:

    pushd $(dirname ${DS_GIT_DIR}) > /dev/null
    popd > /dev/null

Currently 81a09cc doens't build because of that.

```
cat bazel-genfiles/native_client/ds_version.h 
/home/miguel/Development/IPL/investigacao/vad_check/libraries/deepspeech /home/miguel/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
/home/miguel/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
/home/miguel/Development/IPL/investigacao/vad_check/libraries/tensorflow /home/miguel/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
/home/miguel/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
#include <string>
const char* ds_git_version() {
  return ""v0.5.1-1-gfc84863"";
}
const char* tf_local_git_version() {
  return ""v1.13.1-13-g174b4760eb"";
}
```",sorry still working forgot mention one issue need silence currently build cat include string char return char return,issue,negative,negative,negative,negative,negative,negative
505431602,"> Also I can confirm that git versions are not generated with ':' but are generated with ' ':

Maybe I was not passing quotes when testing that. Anyway, I did re-push my PR with proper `-d ' '` and `/bin/bash` shebang, can you ensure you reproduce proper build from scratch after applying this one?",also confirm git maybe passing testing anyway proper shebang ensure reproduce proper build scratch one,issue,negative,neutral,neutral,neutral,neutral,neutral
505429979,"> Looks odd to me, but ... I'll update my PR, can you re-apply from scratch and re-confirm after ?

text inside file is `gitdir: ../../.git/modules/libraries/tensorflow`
with -d':'  you will get ` ../../.git/modules/libraries/tensorflow` (leading space)
with -d' ' you will get  `../../.git/modules/libraries/tensorflow`

I can confirm that changing to `/bin/bash` compiling works and generates correct versions. Also I can confirm that git versions are not generated with ':' but are generated with ' ':

with `-d ':'`
```
 miguel   174b476  …  vad_check  libraries  tensorflow  rm -f bazel-genfiles/native_client/ds_version.h 
 miguel   174b476  …  vad_check  libraries  tensorflow  bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so
INFO: Analysed target //native_client:libdeepspeech.so (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
INFO: From Executing genrule //native_client:ds_git_version:
realpath: ' ../../.git/modules/libraries/deepspeech': No such file or directory
realpath: ' ../../.git/modules/libraries/tensorflow': No such file or directory
fatal: not a git repository: ''
fatal: not a git repository: ''
Target //native_client:libdeepspeech.so up-to-date:
  bazel-bin/native_client/libdeepspeech.so
INFO: Elapsed time: 5.044s, Critical Path: 4.88s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 3 processes: 3 local.
INFO: Build completed successfully, 4 total actions
 miguel   174b476  …  vad_check  libraries  tensorflow  cat bazel-genfiles/native_client/ds_version.h 
#include <string>
const char* ds_git_version() {
  return ""unknown"";
}
const char* tf_local_git_version() {
  return ""unknown"";
}
```
The space causes an error on realpath.

with `-d ' '`
```
 miguel   174b476  …  vad_check  libraries  tensorflow  rm -f bazel-genfiles/native_client/ds_version.h 
 miguel   174b476  …  vad_check  libraries  tensorflow  bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so
INFO: Analysed target //native_client:libdeepspeech.so (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //native_client:libdeepspeech.so up-to-date:
  bazel-bin/native_client/libdeepspeech.so
INFO: Elapsed time: 5.084s, Critical Path: 4.97s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 3 processes: 3 local.
INFO: Build completed successfully, 4 total actions
 miguel   174b476  …  vad_check  libraries  tensorflow  cat bazel-genfiles/native_client/ds_version.h 
#include <string>
const char* ds_git_version() {
  return ""v0.5.1-1-g1686439"";
}
const char* tf_local_git_version() {
  return ""v1.13.1-13-g174b4760eb"";
}
 ```


",odd update scratch text inside file get leading space get confirm work correct also confirm git build opt target loaded found target file directory file directory fatal git repository fatal git repository target time critical path remote time queue setup process local build successfully total cat include string char return unknown char return unknown space error build opt target loaded found target target time critical path remote time queue setup process local build successfully total cat include string char return char return,issue,negative,negative,neutral,neutral,negative,negative
505428792,"Builds finished, it should be transparent now following the docs. Thanks @alchemi5t for reporting.",finished transparent following thanks,issue,negative,positive,neutral,neutral,positive,positive
505426661,"> ```
> file /bin/sh
> /bin/sh: symbolic link to dash
> ```

Yeah, but:
 - I'm not sure `dash` provides `pushd`/`popd`
 - It' bad practice asking for `/bin/sh` and running `bash`-compatible and expecting it to work",file symbolic link dash yeah sure dash bad practice running bash work,issue,negative,negative,neutral,neutral,negative,negative
505426028,"```
file /bin/sh
/bin/sh: symbolic link to dash
```",file symbolic link dash,issue,negative,neutral,neutral,neutral,neutral,neutral
505425983,"> But it seems the build itself fails. Possibly the script is not being run with bash ? it seems not to find pushd and popd.

Yeah, shebang is /bin/sh. Can you change it and confirm it works on your side ?


> With the change from : to ' ' the script itself seems to work:

Looks odd to me, but ... I'll update my PR, can you re-apply from scratch and re-confirm after ?",build possibly script run bash find yeah shebang change confirm work side change script work odd update scratch,issue,negative,negative,neutral,neutral,negative,negative
505424375,"With the change from : to ' ' the script itself seems to work:

```
pwd
/home/miguel/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
 miguel   master  …  919f9f8bd54a24493eab207a22d11837  execroot  org_tensorflow  bash /home/miguel/Development/IPL/investigacao/vad_check/libraries/deepspeech/native_client/ds_git_version.sh 
~/Development/IPL/investigacao/vad_check/libraries/deepspeech ~/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
~/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
~/Development/IPL/investigacao/vad_check/libraries/tensorflow ~/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
~/.cache/bazel/_bazel_miguel/919f9f8bd54a24493eab207a22d11837/execroot/org_tensorflow
#include <string>
const char* ds_git_version() {
  return ""v0.5.1-1-g1686439"";
}
const char* tf_local_git_version() {
  return ""v1.13.1-13-g174b4760eb"";
}
```
But it seems the build itself fails. Possibly the script is not being run with bash ? it seems not to find pushd and popd.

```
cd /home/miguel/Development/IPL/investigacao/vad_check/libraries/tensorflow/
bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so
INFO: Analysed target //native_client:libdeepspeech.so (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
INFO: From Executing genrule //native_client:ds_git_version:
native_client/ds_git_version.sh: 23: native_client/ds_git_version.sh: pushd: not found
grep: .git: No such file or directory
realpath: '': No such file or directory
native_client/ds_git_version.sh: 25: native_client/ds_git_version.sh: popd: not found
native_client/ds_git_version.sh: 28: native_client/ds_git_version.sh: pushd: not found
grep: .git: No such file or directory
realpath: '': No such file or directory
native_client/ds_git_version.sh: 30: native_client/ds_git_version.sh: popd: not found
fatal: not a git repository: ''
fatal: not a git repository: ''
Target //native_client:libdeepspeech.so up-to-date:
  bazel-bin/native_client/libdeepspeech.so
INFO: Elapsed time: 3.663s, Critical Path: 3.46s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]
INFO: 3 processes: 3 local.
INFO: Build completed successfully, 4 total actions
```

If I delete the file and tun build again, I get the same issue.",change script work master bash include string char return char return build possibly script run bash find build opt target loaded found target found file directory file directory found found file directory file directory found fatal git repository fatal git repository target time critical path remote time queue setup process local build successfully total delete file tun build get issue,issue,negative,negative,neutral,neutral,negative,negative
505422444,"> It compiled but it didn't pick the versions correctly:

Just to make sure, did you removed that file and ensured it was properly removed ? Bazel won't re-generate it if it exists.",pick correctly make sure removed file properly removed wo,issue,negative,positive,positive,positive,positive,positive
505422269,"> Ok, one thing is you need to do `cut -d' ' -f2` instead of `cut -d':' -f2` otherwise you get a space at the start of the subpath.

It should not be a problem, `realpath` should be able to deal with that ... With what got populated `$TF_GIT_DIR` and `$DS_GIT_DIR` in your case ? You can add `// ${TF_GIT_DIR}` and `// ${DS_GIT_DIR}` to the top of the `ds_version.h` generation in the script, remove the header and re-run.",one thing need cut instead cut otherwise get space start problem able deal got case add top generation script remove header,issue,negative,positive,positive,positive,positive,positive
505421088,"Ok, one thing is you need to do `cut -d'  ' -f2` instead of `cut -d':' -f2` otherwise you get a space at the start of the subpath.",one thing need cut instead cut otherwise get space start,issue,negative,neutral,neutral,neutral,neutral,neutral
505420648,"> To test the script directly where should cwd be and what should $0 be ?

that's dependant on bazel, that's exactly why I was fearing it would be tricky",test script directly exactly would tricky,issue,negative,positive,positive,positive,positive,positive
505418966,"FWIW bazel genrules are really inappropriate for this, the only reason it works for us is because the automation builds never have the cached genfiles. There's no way to say that the git version is a dependency of the genfile, so bazel will cache them and produce stale values for both the git and the graph versions unless you remember to manually delete the files. bazel does not intend to add an option to change this behavior, and recommends wrapping bazel with a tool that either generates the files directly or checks if the dependencies have changed and bumps a proxy file that is listed as an input of the genrule.

I'm OK with just fixing the script for now if it's broken for submodules, but I just wanted to write this out as I always forget to.",really inappropriate reason work u never way say git version dependency cache produce stale git graph unless remember manually delete intend add option change behavior wrapping tool either directly proxy file listed input fixing script broken write always forget,issue,negative,negative,negative,negative,negative,negative
505417636,"Actually `pushd $(dirname ${TF_GIT_DIR})` should take care of that... 

To test the script directly where should cwd be and what should $0 be ?",actually take care test script directly,issue,negative,positive,neutral,neutral,positive,positive
505416600,"It compiled but it didn't pick the versions correctly:

```
cat bazel-genfiles/native_client/ds_version.h
#include <string>
const char* ds_git_version() {
  return ""unknown"";
}
const char* tf_local_git_version() {
  return ""unknown"";
}
```


           DS_GIT_DIR=$(realpath ""$(grep '^gitdir:' .git | cut -d':' -f2)"") 

I think this will not work as the path inside the file is relative to that directory which will not match cwd. I think you need to build the path by placing the output of `$(realpath ""$(grep '^gitdir:' .git | cut -d':' -f2)"")`  after `$(dirname ""$(realpath ""$0"")"")/../` and the same for tf. Something similar to

   $(dirname ""$(realpath ""$0"")"")/../$(realpath ""$(grep '^gitdir:' .git | cut -d':' -f2)"")

    ",pick correctly cat include string char return unknown char return unknown cut think work path inside file relative directory match think need build path output cut something similar cut,issue,negative,negative,neutral,neutral,negative,negative
505406771,"So #2205 turned out not to be a working approach as we have execution flows through DeepSpeech.py where the batch size flags are optional. If anyone has a better idea on how to fix this in a clean way, feel free to propose it.",turned working approach execution batch size optional anyone better idea fix clean way feel free propose,issue,positive,positive,positive,positive,positive,positive
505406357,Yeah. This is turning out to be more work than I expected. We'd have to make the flag optional at the abseil level and then check ourselves in config.py or something like that :/,yeah turning work make flag optional level check something like,issue,positive,neutral,neutral,neutral,neutral,neutral
505405174,"> Was also working on a patch. :-) Will test your patch. I guess I will have to cherry-pick for v0.5.1.

Thanks. Also it'd be important to make sure `native_client/ds_graph_version.sh` needs or not this (it should not).",also working patch test patch guess thanks also important make sure need,issue,positive,positive,positive,positive,positive,positive
505403441,"> > Ah, no, it was from the original tensorflow repo. Sorry, I swear I did read the readme. :-)
> 
> Is it that you missed reading at the proper place, or is there improvement that could be done to doc ?

No improvements needed, I just didn't read carefully enough. :-)",ah original sorry swear read reading proper place improvement could done doc read carefully enough,issue,positive,negative,neutral,neutral,negative,negative
505399763,Was also working on a patch. :-) Will test your patch. I guess I will have to cherry-pick for v0.5.1.,also working patch test patch guess,issue,negative,neutral,neutral,neutral,neutral,neutral
505393361,"@miguel-negrao Hopefully https://github.com/mozilla/DeepSpeech/pull/2210 would work in your case, can you check it ?",hopefully would work case check,issue,negative,neutral,neutral,neutral,neutral,neutral
505387758,"Also, can you apply this patch, then in tensorflow directory do `bazel-genfiles/native_client/ds_*`, and then rebuild? You should have newer `bazel-genfiles/native_client/ds_version.h`, can you share?
```
diff --git a/native_client/ds_git_version.sh b/native_client/ds_git_version.sh
index 6fb6e41..c3e2c24 100755
--- a/native_client/ds_git_version.sh
+++ b/native_client/ds_git_version.sh
@@ -8,16 +8,24 @@ if [ `uname -o` = ""Msys"" ]; then
    export PATH=""/c/Program Files/Git/bin/:${PATH}""
 fi
 
-DS_GIT_DIR=""$(realpath ""$(dirname ""$(realpath ""$0"")"")/../.git/"")""
-if [ ! -d ""${DS_GIT_DIR}"" ]; then
+DS_GIT_DIR=""$(realpath ""$(dirname ""$(realpath ""$0"")"")/../.git"")""
+if [ ! -d ""${DS_GIT_DIR}"" -a ! -f ""${DS_GIT_DIR}"" ]; then
    return 1
 fi;
 
-TF_GIT_DIR=""$(realpath $(pwd)/tensorflow/../.git/)""
-if [ ! -d ""${TF_GIT_DIR}"" ]; then
+TF_GIT_DIR=""$(realpath $(pwd)/tensorflow/../.git)""
+if [ ! -d ""${TF_GIT_DIR}"" -a ! -f ""${TF_GIT_DIR}"" ]; then
    return 1
 fi;
 
+# Handle the case of git submodules, the .git file contains the path to the tree
+if [ -f ""${DS_GIT_DIR}"" ]; then
+   DS_GIT_DIR=$(grep '^gitdir:' ""${DS_GIT_DIR}"" |cut -d ':' -f2)
+fi;
+if [ -f ""${TF_GIT_DIR}"" ]; then
+   TF_GIT_DIR=$(grep '^gitdir:' ""${TF_GIT_DIR}"" |cut -d ':' -f2)
+fi;
+
 DS_GIT_VERSION=$(git --git-dir=""${DS_GIT_DIR}"" describe --long --tags)
 if [ $? -ne 0 ]; then
    DS_GIT_VERSION=unknown;
@@ -29,6 +37,8 @@ if [ $? -ne 0 ]; then
 fi
 
 cat <<EOF
+// DS_GIT_DIR=${DS_GIT_DIR}
+// TF_GIT_DIR=${TF_GIT_DIR}
 #include <string>
 const char* ds_git_version() {
   return ""${DS_GIT_VERSION}"";
```",also apply patch directory rebuild share git index export path fi return fi return fi handle case git file path tree git describe long fi cat include string char return,issue,negative,negative,neutral,neutral,negative,negative
505384545,">  as there won't be a .git folder in the deepspeech folder.

It seems that there won't be a **`.git` folder** but there is a **`.git` file** that points to the folder",wo folder folder wo folder file folder,issue,negative,neutral,neutral,neutral,neutral,neutral
505382346,"> @miguel-negrao Unfortunately, this is not a setup that we have, so it's not surprising it is broken. You might want to check and fix `native_client/ds_git_version.sh` for that.

Be aware this is tricky because of how `bazel` works ...",unfortunately setup surprising broken might want check fix aware tricky work,issue,negative,positive,neutral,neutral,positive,positive
505382049,"> Ah, no, it was from the original tensorflow repo. Sorry, I swear I did read the readme. :-)

Is it that you missed reading at the proper place, or is there improvement that could be done to doc ?",ah original sorry swear read reading proper place improvement could done doc,issue,positive,negative,neutral,neutral,negative,negative
505381923,"Ah, no, it was from the original tensorflow repo. Sorry, I swear I did read the readme. :-)",ah original sorry swear read,issue,negative,negative,neutral,neutral,negative,negative
505381379,"@miguel-negrao Unfortunately, this is not a setup that we have, so it's not surprising it is broken. You might want to check and fix `native_client/ds_git_version.sh` for that.",unfortunately setup surprising broken might want check fix,issue,negative,negative,neutral,neutral,negative,negative
505380783,"> tensorflow: commit 93dd14dce2e8751bcaab0a0eb363d55eb0cc5813 (HEAD -> for_deepspeech, **origin/r1.13**)

Is this from https://github.com/mozilla/tensorflow ? Because this commit does not match any of the `mozilla/tensorflow r1.13` ...",commit head commit match,issue,positive,neutral,neutral,neutral,neutral,neutral
505378549,"The issue is solved if I comment the offending lines:

```
        #""//tensorflow:rpi3"": LINUX_LINKOPTS + [""-l:libstdc++.a""],
        #""//tensorflow:rpi3-armv8"": LINUX_LINKOPTS + [""-l:libstdc++.a""],
```

In any case, it should be possible to compile the library without any changes to the config file...
",issue comment case possible compile library without file,issue,negative,neutral,neutral,neutral,neutral,neutral
505358664,"> yep!
> pip install --upgrade https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.master.cpu-ctc/artifacts/public/ds_ctcdecoder-0.6.0a0-cp36-cp36m-manylinux1_x86_64.whl
> 
> for python 3.6 if anyone needs it.

Thanks, I just pushed the `v0.6.0-alpha.1` tag so it should be properly handled as soon as the builds finished.",yep pip install upgrade python anyone need thanks tag properly handled soon finished,issue,positive,positive,neutral,neutral,positive,positive
505357892,"yep! 
pip install --upgrade https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.master.cpu-ctc/artifacts/public/ds_ctcdecoder-0.6.0a0-cp36-cp36m-manylinux1_x86_64.whl 

for python 3.6 if anyone needs it.",yep pip install upgrade python anyone need,issue,negative,neutral,neutral,neutral,neutral,neutral
505357395,"Thanks, so we need to release a new alpha then.",thanks need release new alpha,issue,negative,positive,positive,positive,positive,positive
505356872,"HOLY $***!! @lissyx that actually worked! Thanks a ton, mate!",holy actually worked thanks ton mate,issue,negative,positive,neutral,neutral,positive,positive
505353383,@lissyx got it. on it. will reply as soon as i am done testing.,got reply soon done testing,issue,negative,neutral,neutral,neutral,neutral,neutral
505352784,`pip install --upgrade <URL>` with `<URL>` being one of those package on https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.master/cpu-ctc,pip install upgrade one package,issue,negative,neutral,neutral,neutral,neutral,neutral
505352236,"> @lissyx ds-ctcdecoder==0.6.0a0

Ok, can you pick the wheel matching your python version on https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.master/cpu-ctc and retry ?",pick wheel matching python version retry,issue,negative,neutral,neutral,neutral,neutral,neutral
505347019,"> @kdavis-mozilla yes. Let me explain what all i've done.
> 
>     1. git lfs clone
> 
>     2. have all the pre-reqs
> 
>     3. preprocessed the datasets
> 
>     4. run ""CUDA_VISIBLE_DEVICES=0 python DeepSpeech.py --train_files ../et/clips/train.csv --dev_files ../et/clips/dev.csv --test_files ../et/clips/test.csv""

Can you check ? 

```
$ sha1sum data/lm/lm.binary data/lm/trie 
098c71d7f720ff1842650881e2e3ebb9d18bd7d3  data/lm/lm.binary
5f2c59596a977779f27869768e544c82e840290f  data/lm/trie
```",yes let explain done git clone run python check,issue,negative,neutral,neutral,neutral,neutral,neutral
505344646,"@kdavis-mozilla yes. Let me explain what all i've done.

1) git lfs clone <repo>
2) have all the pre-reqs
3) preprocessed the datasets
4) run ""CUDA_VISIBLE_DEVICES=0 python DeepSpeech.py --train_files ../et/clips/train.csv --dev_files ../et/clips/dev.csv --test_files ../et/clips/test.csv""",yes let explain git clone run python,issue,negative,neutral,neutral,neutral,neutral,neutral
505338133,Does your master include the commit 0ea5804?,master include commit ea,issue,negative,neutral,neutral,neutral,neutral,neutral
505284441,"@dabinat Yes.

However, the download statistics are used within Mozilla as a measure of this project's success. So, if the statistics are significantly curtailed as a result of using a torrent, management will think the project isn't healthy and make project cuts.

So if we use a torrent, then we'll need to do so in a manner that maintains some notion of download statistics. I think @reuben has some ideas in this regard.",yes however statistic used within measure project success statistic significantly curtailed result torrent management think project healthy make project use torrent need manner notion statistic think regard,issue,positive,positive,positive,positive,positive,positive
505283065,It seems to me that anyone could put up a torrent so it doesn't necessarily need to be done officially by Mozilla.,anyone could put torrent necessarily need done officially,issue,negative,neutral,neutral,neutral,neutral,neutral
505239017,"@rhamnett you can run a search over all files for ""16000"" and make this dynamic. I believe you can make these variables dependable from the `sample_rate` saved in the model's metadata (exported [here](https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L719))",run search make dynamic believe make dependable saved model,issue,positive,neutral,neutral,neutral,neutral,neutral
505194291,"@reuben this tripped us up today. Perhaps there are some other options:

1. print a warning if people have a batch size of one? 
2. make `--train_batch_size` a mandatory argument ?  -- if people are expected to change it, maybe it shouldn't have default ? 

I agree that expecting people to tune the hyperparameters is reasonable, but I think that there is possibly a way to save people time by anticipating ""typical error cases"".",u today perhaps print warning people batch size one make mandatory argument people change maybe default agree people tune reasonable think possibly way save people time typical error,issue,negative,positive,neutral,neutral,positive,positive
505188317,"There's no better default we can use. A higher value will cause OOMs on people with low VRAM. Training a model is not supposed to be a drag and drop thing, you're expected to tune the hyperparameters as appropriate for your data/system/use case.",better default use higher value cause people low training model supposed drag drop thing tune appropriate case,issue,negative,positive,positive,positive,positive,positive
505132043,"Haha, I get you :) I will try and do some work to more easily cater for sample rates across the different files in a single PR if you wish? Any suggestions welcome before I start",get try work easily cater sample across different single wish welcome start,issue,positive,positive,positive,positive,positive,positive
505045524,"> Can we train Deepspeech on audio files longer than 10 seconds (and less than one minute) ?

This is not a bug, rather a question. Please use Discourse for that: https://discourse.mozilla.org/c/deep-speech",train audio longer le one minute bug rather question please use discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
504993898,The sample rate needs to be changed all over the place but this at least collects it into one place for each of these files rather than having to go back in everywhere when each version is released. It will merge better.,sample rate need place least one place rather go back everywhere version merge better,issue,negative,positive,neutral,neutral,positive,positive
504946184,"> Allows resuming downloads.

Technically nothing stops from supporting resuming download, it's been working fine downloading from Github for me.


> If a torrent is shared while allowing seeding from the main server i.e. aws in this case

We don't have any tracker and we don't control AWS hosting, it's Github's hosting.


> Same goes for sharing data of voice initiative of mozilla but I guess it is different project to talk about.

It's a different project, and the issue has already been raised, you can check on Discourse the discussion. What stopped from doing it for Common Voice, however, is not valid for us, so it might be possible.

> One more issue was raised earlier regarding this #2151 which was closed blindly.

No, that issue was closed because there was no proper discussion / documentation.",technically nothing supporting working fine torrent main server case tracker control hosting hosting go data voice initiative guess different project talk different project issue already raised check discourse discussion stopped common voice however valid u might possible one issue raised regarding closed blindly issue closed proper discussion documentation,issue,negative,negative,neutral,neutral,negative,negative
504903697,"A possibly dumb question, but why allow for the sample rate to be changed when currently the rest of the pipeline doesn't allow for such, and why just this importer?",possibly dumb question allow sample rate currently rest pipeline allow importer,issue,negative,negative,negative,negative,negative,negative
504901383,"As this looks to be more of a conversation than filing a bug or feature request, could you move this request to [discourse](https://discourse.mozilla.org/c/deep-speech) please? We want to reserve issues for bugs and/or feature requests. Thanks.",conversation filing bug feature request could move request discourse please want reserve feature thanks,issue,positive,positive,positive,positive,positive,positive
504780869,"`deepspeech` likely refers to the binary installed when you install the Python package (client.py), rather than DeepSpeech.py (which doesn't accept those parameters and would fail earlier).",likely binary install python package rather accept would fail,issue,negative,negative,negative,negative,negative,negative
504777911,Tried this myself on a stock 0.5.1 with only librivox CLEAN sets only. Can't reproduce ,tried stock clean ca reproduce,issue,negative,positive,positive,positive,positive,positive
504776091,I updated the python client to make this a little bit easier https://github.com/mozilla/DeepSpeech/pull/2199,python client make little bit easier,issue,negative,negative,negative,negative,negative,negative
504680569,"@lissyx it seems there's some sort of caching of Homebrew, as even by pointing to the updated home.tar.xz I was still running into this issue: https://tools.taskcluster.net/groups/YiAbEUIBTtyMuY7ggTmQQQ/tasks/YiAbEUIBTtyMuY7ggTmQQQ

How do I clear that cache?",sort even pointing still running issue clear cache,issue,negative,positive,positive,positive,positive,positive
504664155,Looks like we're actually running code from the tensorflow repo :(,like actually running code,issue,negative,neutral,neutral,neutral,neutral,neutral
504662606,This PR causes a tiny improvement in decoding performance (librispeech-test-clean test epoch from 6:46 to 6:40).,tiny improvement performance test epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
504599630,@testdeepv Can you update us ? Is there still a legit issue here or was it just an improper setup ?,update u still legit issue improper setup,issue,negative,neutral,neutral,neutral,neutral,neutral
504599048,@andysharma1997 Can you please confirm that the issue was because of the typo reported by @dabinat ?,please confirm issue typo,issue,negative,neutral,neutral,neutral,neutral,neutral
504488693,"> Seems like the macOS workers are dead again, as their tests are pending. But otherwise everything looks green.

Looks like we will need to fix proper in task-dir scoping for NPM, pip and Electron, there was a 10GB folder ~/.npm/ ...",like dead pending otherwise everything green like need fix proper pip electron folder,issue,negative,negative,negative,negative,negative,negative
504400385,"Seems like the macOS workers are dead again, as their tests are pending. But otherwise everything looks green.",like dead pending otherwise everything green,issue,negative,negative,negative,negative,negative,negative
504248966,"Don't worry about the commit message, I'll just use squash and merge on the GitHub UI when the tests have run.",worry commit message use squash merge run,issue,negative,neutral,neutral,neutral,neutral,neutral
504248584,"Yeah clicking resolve conversation is fine, but it's more for your own tracking of what was fixed.",yeah resolve conversation fine fixed,issue,positive,positive,positive,positive,positive,positive
504245284,"I also added a check for `--export_dir`, but accidentally added whitespace after removing it and squashing the commit I messed up the commit message, sorry about that!",also added check accidentally added removing commit commit message sorry,issue,negative,negative,negative,negative,negative,negative
504243071,"I've taken care of those two changes. Thanks for the invite! What is the right thing to do with your comments now ? ""Resolve conversation"" ?",taken care two thanks invite right thing resolve conversation,issue,positive,positive,positive,positive,positive,positive
504226028,"@JRMeyer @reuben would a reasonable solution to this be to switch to argparse, and read the options (failing on non-existing ones and value checking them) and then put them into `tf.app.flags.FLAGS` ?

On the other hand, abseil appears to have the capacity to [validate stuff](https://abseil.io/docs/python/guides/flags#flags-validators)

Checking for things can be done in the following way:

```
diff --git a/DeepSpeech.py b/DeepSpeech.py
index 9024640..e29c85a 100755
--- a/DeepSpeech.py
+++ b/DeepSpeech.py
@@ -21,7 +21,7 @@ from six.moves import zip, range
 from tensorflow.python.tools import freeze_graph
 from util.config import Config, initialize_globals
 from util.feeding import create_dataset, samples_to_mfccs, audiofile_to_features
-from util.flags import create_flags, FLAGS
+from util.flags import create_flags, check_flags, FLAGS
 from util.logging import log_info, log_error, log_debug, log_progress, create_progressbar
 
 
@@ -864,6 +864,8 @@ def main(_):
         tf.reset_default_graph()
         do_single_file_inference(FLAGS.one_shot_infer)
 
+
 if __name__ == '__main__':
     create_flags()
+    check_flags()
     tf.app.run(main)
diff --git a/util/flags.py b/util/flags.py
index b5b981b..a4d8c33 100644
--- a/util/flags.py
+++ b/util/flags.py
@@ -1,10 +1,16 @@
 from __future__ import absolute_import, division, print_function
 
+import os
 import tensorflow as tf
 
 
 FLAGS = tf.app.flags.FLAGS
 
+def check_flags():
+    f = tf.app.flags
+    f.register_validator('lm_binary_path',
+                         lambda value: os.path.isfile(value),
+                         message='The file pointed to by --lm_binary_path must exist and be readable.')
 
 def create_flags():
     # Importer
```

Which will lead to the following output if the file does not exist:

```
Traceback (most recent call last):
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 528, in _assert_validators
    validator.verify(self)
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/absl/flags/_validators.py"", line 82, in verify
    raise _exceptions.ValidationError(self.message)
absl.flags._exceptions.ValidationError: The file pointed to by --lm_binary_path must exist and be readable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""DeepSpeech.py"", line 871, in <module>
    tf.app.run(main)
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 119, in run
    argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True)
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/tensorflow/python/platform/flags.py"", line 112, in __call__
    return self.__dict__['__wrapped'].__call__(*args, **kwargs)
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 636, in __call__
    self._assert_all_validators()
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 510, in _assert_all_validators
    self._assert_validators(all_validators)
  File ""/home/ftyers/tmp/deepspeech-venv/lib/python3.6/site-packages/absl/flags/_flagvalues.py"", line 531, in _assert_validators
    raise _exceptions.IllegalFlagValueError('%s: %s' % (message, str(e)))
absl.flags._exceptions.IllegalFlagValueError: flag --lm_binary_path=data/chv/lm/lm.bina: The file pointed to by --lm_binary_path must exist and be readable.

```

This doesn't appear to work with default variables though, e.g. if I don't specify `--lm_binary_path` on the command line then it doesn't run the validator.",would reasonable solution switch read failing value put hand capacity validate stuff done following way git index import zip range import import import import import import main main git index import division o import lambda value value file pointed must exist readable importer lead following output file exist recent call last file line self file line verify raise file pointed must exist readable handling exception another exception recent call last file line module main file line run none else file line return file line file line file line raise message flag file pointed must exist readable appear work default though specify command line run,issue,positive,positive,neutral,neutral,positive,positive
504176317,"It looks like there is a typo in your command:

````
--alphabet deepspeech-0.5.0-models/alphabt.txt
````

I get the same result if I change `--alphabet` to a path that doesn't exist. DeepSpeech should be showing an error message here.",like typo command alphabet get result change alphabet path exist showing error message,issue,negative,neutral,neutral,neutral,neutral,neutral
504159249,"Solved the problem, I had `pip3 install 'tensorflow-gpu==1.6.0'` not `pip3 install 'tensorflow-gpu==1.13.1'`. I need to update my documentation :) Thanks! (and sorry for the email/issue noise)",problem pip install pip install need update documentation thanks sorry noise,issue,negative,negative,negative,negative,negative,negative
504154932,This looks like you installed `tensorflow-gpu` in a system that doesn't have CUDA installed. The error being about CUDA 9 also indicates it's an older version of TF. Try uninstalling `tensorflow-gpu` and installing `tensorflow`.,like system error also older version try,issue,negative,positive,positive,positive,positive,positive
504038110,What source code are you referring to? There's no need to rebuild ,source code need rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
504007689,"Dumb question but what happens if you quote the path
```bash
--audio  /home/istar/Downloads/audio-0.5.0\ (1)/audio/8455-210777-0068.wav
```
entering it on the command line as
```bash
--audio ""/home/istar/Downloads/audio-0.5.0\ (1)/audio/8455-210777-0068.wav""
```",dumb question quote path bash audio entering command line bash audio,issue,negative,negative,negative,negative,negative,negative
503976606,"I am running DeepSpeech 0.5.0 using ""The command-line client""  on Ubuntu 18.04.2 LTS.
I am using
libsox3(for Ubuntu 18.04.2 libsox2 was not available)
libstdc++6
libgomp1
libpthread
TensorFlow version v1.13.1-10
I am not using GPU on my linux or any any other command related to GPU
source code is taken from v0.5.0.tar.gz
Trained model used is deepspeech-0.5.0-models.tar.gz
Example audio files on which i am testing are taken from audio-0.5.0.tar.gz
I am not using any third party bindings
",running client available version command related source code taken trained model used example audio testing taken third party,issue,negative,positive,positive,positive,positive,positive
503776571,"@lissyx the crux of the problem here is that in `decoder_decode` we were sorting the live prefixes still being used by `decoder_next`, which changes the behavior of the decoder over the whole stream. This solution is a bit hacky, it copies the prefix vector, stores the modified scores outside of the vector, and then sorts them with an external score, which keeps all the live prefixes unchanged except for `approx_ctc` (which isn't used in `decoder_next`). A better fix requires more substantial changes to the decoder implementation, but I'd rather fix this quickly for 0.5.1.",crux problem live still used behavior whole stream solution bit hacky prefix vector outside vector external score live unchanged except used better fix substantial implementation rather fix quickly,issue,positive,positive,positive,positive,positive,positive
503511547,"@lissyx I've addressed your comments and also added a test in f12ea5e. The test uses the prod model so it's not actually running, since the graph version was bumped here, but I verified manually. I'll also re-export the 0.5.0 checkpoint and update our prod-model in a separate PR.",also added test test prod model actually running since graph version manually also update separate,issue,negative,neutral,neutral,neutral,neutral,neutral
503263522,Although it should only really matter if you call intermediate decode *very* often.,although really matter call intermediate decode often,issue,negative,positive,positive,positive,positive,positive
503263047,"Yes, it is. I'm trying to design a better way of fixing this, the PathTrie makes it a bit tricky.",yes trying design better way fixing bit tricky,issue,positive,positive,positive,positive,positive,positive
503192024,"And yes, you should also specify `--audio_sample_rate` when exporting the model.",yes also specify model,issue,negative,neutral,neutral,neutral,neutral,neutral
503191633,"You need to call the API directly or modify the clients, as they don't support different sample rates. Also, if you're using TFLite, you'll need to change the code and recompile libdeepspeech.so.",need call directly modify support different sample also need change code recompile,issue,negative,positive,neutral,neutral,positive,positive
503189465,"I didn't see that it was possible, do you only need to modify the samplerate in flags.py ?",see possible need modify,issue,negative,neutral,neutral,neutral,neutral,neutral
503184070,"> I believe, having an API to do deep analysis of the speech itself to extract information (not just text) could be more useful.

We're not saying it's not useful :)


> I think extending the API would be reasonable.

Well, we have a `Metadata` exposed struct that you might be able to extend and experiment with if you are interested.",believe deep analysis speech extract information text could useful saying useful think extending would reasonable well exposed might able extend experiment interested,issue,positive,positive,positive,positive,positive,positive
503180482,"I think we should merge this, it'll make it easier to add a test for this.",think merge make easier add test,issue,negative,neutral,neutral,neutral,neutral,neutral
503180238,@eggonlea can you try this fix and verify if it fixes the bug you found?,try fix verify bug found,issue,negative,neutral,neutral,neutral,neutral,neutral
503179667,"Thanks. One question, is this code you want to merge or just opened the PR for sharing and reproducing the issue? ",thanks one question code want merge issue,issue,negative,positive,positive,positive,positive,positive
503172567,"> It would be really nice to allow lower samplerates like 8kHz, which is really popular for telecommunication, for DeepSpeech.

That's already possible, can you explain more why you filed the issue ?",would really nice allow lower like really popular telecommunication already possible explain issue,issue,positive,positive,positive,positive,positive,positive
503163823,"@lissyx Your concerns are valid. I think extending the API would be reasonable. Currently, STT has pretty limited use case. Sure, adding more data to the output would definitely allow to address a few more use cases. I believe, having an API to do deep analysis of the speech itself to extract information (not just text) could be more useful.",valid think extending would reasonable currently pretty limited use case sure data output would definitely allow address use believe deep analysis speech extract information text could useful,issue,positive,positive,positive,positive,positive,positive
503131995,We have indicated librispeech test-clean WER in the release notes. We have not computed the WER for datasets(dev-clean/dev-other/test-other) The release also contains a command line tool for you to find the others yourself.,wer release wer release also command line tool find,issue,negative,neutral,neutral,neutral,neutral,neutral
502983747,"Confirmed that, without LM, streaming mode works as expected.

**Run native client in legacy mode**
`./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --trie models/trie --audio ../data/ldc93s1/LDC93S1.wav`

**Output:**
she hadeducs suit and greasy wathor al year 

**Run native client in streaming mode**
`./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio ../data/ldc93s1/LDC93S1.wav --stream 1280`

**Output:**
./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --trie models/trie --audio ../data/ldc93s1/LDC93S1.wav --stream 1280

she had
she haded
she hadeducs s
she hadeducs suit and gr
she hadeducs suit and greasy
she hadeducs suit and greasy wath
she hadeducs suit and greasy wathor a
she hadeducs suit and greasy wathor al year",confirmed without streaming mode work run native client legacy mode model alphabet audio output suit greasy al year run native client streaming mode model alphabet audio stream output model alphabet audio stream suit suit greasy suit greasy wath suit greasy suit greasy al year,issue,negative,positive,positive,positive,positive,positive
502757351,"That's not just about the size, it depends on your data. Batch size this big, it feels weird. Make sure you have tensorflow-gpu properly installed (if all gpu memory is allocated by a python process it should be okay but still). And then what is made of your dataset? Batch size 64 is the max I can get for French with common voice and a few other dataset, on RTX2080Ti GPUs (11GB RAM) ",size data batch size big weird make sure properly memory python process still made batch size get common voice ram,issue,negative,negative,neutral,neutral,negative,negative
502753684,"Wow, that was a fast reply. 
Deep learning and tensorflow noob here.
I'm training a model with a batch size of 10000. The processes do show up in the gpu's with almost all of the memory being used on gpu 0, but almost zero utilisation, ocassionally fluctuating between 0 and 1. 
![Screenshot from 2019-06-17 21-35-55](https://user-images.githubusercontent.com/46970219/59620466-8b2b7800-914a-11e9-9355-afd9e47f3262.png)

I did search a couple of discussions that suggested input bottleneck and small batch size to be a possible cause but I've checked that's definitely not the case. 10000 seems a good batch size for 12+16GB of gpu memory and tensorflow placeholders take care of the input pipeline.
What could be the problem?

I'm using a server btw with x128 Intel Xeon Gold 6142 cpu's and 256 GB ram. Also 2 gpu's, an Nvidia P100 and another K40c, their potential being wonderfully wasted.

",wow fast reply deep learning training model batch size show almost memory used almost zero search couple input bottleneck small batch size possible cause checked definitely case good batch size memory take care input pipeline could problem server gold ram also another potential wonderfully wasted,issue,positive,positive,neutral,neutral,positive,positive
502716253,">  Could you explain what does the --display_step and --validation_step mean? Could be very helpful.

As documented, they are indicating when the process of display and validation should be done.



> Hi @bolt163 , I'm also facing a similar problem, while the gpu memory usage is high, the volatile gpu utilisation is almost none. Can't have that.

Without more informations on your context, it's complicated to be definitive on a root cause here.",could explain mean could helpful process display validation done hi bolt also facing similar problem memory usage high volatile almost none ca without context complicated definitive root cause,issue,negative,negative,negative,negative,negative,negative
502704286,"> @lissyx in memory the 5th epoch seems have the same problem, at that time i did not pay so much attention with it and killed it to restart again (seems every 5 epoch?)，
> 
> I referenced the solutions in the above issue #776
> ""
> python -u DeepSpeech.py 
> ...
> --display_step 0 
> --validation_step 1 
> ""
> by setting display_step 0 and validation_step 1, the GPU Volatile GPU-Utilg become normal
> (while in the original run-librivox.sh --display_step 1, --validation_step 5 https://github.com/mozilla/DeepSpeech/blob/master/bin/run-librivox.sh ), but there seems have a OOM after about 20 hours' training， and i kill it then restart again.

Hi @bolt163 , I'm also facing a similar problem, while the gpu memory usage is high, the volatile gpu utilisation is almost none. Can't have that.
Could you explain what does the --display_step and --validation_step mean? Could be very helpful.",memory th epoch problem time pay much attention restart every epoch issue python setting volatile become normal original kill restart hi bolt also facing similar problem memory usage high volatile almost none ca could explain mean could helpful,issue,negative,positive,neutral,neutral,positive,positive
502474064,"@akhilvasvani Unfortunately, there is a bug with the Common Voice data. Could you file a bug with [voice-web](http://github.com/mozilla/voice-web)? Thanks for reporting!",unfortunately bug common voice data could file bug thanks,issue,negative,negative,negative,negative,negative,negative
502467278,"@lissyx, as for proof here is what I can offer:
```
akhil@Minerva:~/DeepSpeech/data/CV/en/clips$ locate 36e1606224ac9671de8435737cd8828fc910b8f841de83ef421be74b734248b5f52477269d8c768705059b4c6fa4ff9c62d802155f249b56de536f33eb90017d.mp3
akhil@Minerva:~/DeepSpeech/data/CV/en/clips$ locate 2cebb7196b292b57a1a2141c4fada2a62318ec53e5deb07a30c89a8bbabfabc2925be2d7159791f8c34f0a9b6f2bd8425a473a9d96f0fefc9054602c084755f7.mp3
/home/akhil/DeepSpeech/data/CV/en/clips/2cebb7196b292b57a1a2141c4fada2a62318ec53e5deb07a30c89a8bbabfabc2925be2d7159791f8c34f0a9b6f2bd8425a473a9d96f0fefc9054602c084755f7.mp3
akhil@Minerva:~/DeepSpeech/data/CV/en/clips$ 
```

So it does not find the missing file. I located another file just for comparsion. And in the first row of the 'train.tsv' file:
client id | path 

2cd9a591b669f14a0b7c039f087c902dc075c19a1be9bb23c8e0fecff255f5be36fb3d72c118c972c00def21b62b1df550f2205eaea066cfb70ef4f4f4e152f7 | 36e1606224ac9671de8435737cd8828fc910b8f841de83ef421be74b734248b5f52477269d8c768705059b4c6fa4ff9c62d802155f249b56de536f33eb90017d
-- | --



",proof offer locate locate find missing file another file first row file client id path,issue,negative,positive,neutral,neutral,positive,positive
502442049,"@akhilvasvani Is this the recent ""en_1085h_2019-06-12"" release of Common Voice?",recent release common voice,issue,negative,negative,negative,negative,negative,negative
502430196,"Well if you can ensure the file is missing in the tarball and its actually referenced in the tsv files, then that's not an importer bug but a common voice release issue. ",well ensure file missing actually importer bug common voice release issue,issue,negative,negative,negative,negative,negative,negative
502429234,"The path is correct. I was already in the root directory. And yes, this is the latest data I downloaded from [here](https://voice.mozilla.org/en/datasets)",path correct already root directory yes latest data,issue,negative,positive,positive,positive,positive,positive
502429037,Are you sure the path is correct? Do you reproduce with full path instead of relative? Is that latest cv release from this week? ,sure path correct reproduce full path instead relative latest release week,issue,negative,positive,positive,positive,positive,positive
502428968,Please use discourse for this kind of question. CUDA 10.1 is not compatible with 10.0.,please use discourse kind question compatible,issue,positive,positive,positive,positive,positive,positive
502091730,"> v0.5.0 does not execute make clean in the native_client subfolder. It looks for bindings-clean, but that is not found.

That's a left-over of era before moving bindings target into their own `Makefile`",execute make clean found era moving target,issue,negative,positive,positive,positive,positive,positive
502086250,"> ```
> $ sha1sum ~/tmp/deepspeech/0.5.0-ckpt/output_graph.*
> ebb290d1cfb1f7bae8268a81dead34d9d1ca5d3e  /home/alex/tmp/deepspeech/0.5.0-ckpt/output_graph.pb
> 5222826d794d060988c17ac80fdc1d18272377f2  /home/alex/tmp/deepspeech/0.5.0-ckpt/output_graph.stripped.pb
> ```
> 
> So the checksum does change.

Well, two consecutive runs of the same export do produce different sha1, so it's not really conclusive.",change well two consecutive export produce different sha really conclusive,issue,negative,positive,neutral,neutral,positive,positive
502085337,"> Does this change our graph at all? E.g does it change its checksum?

Unfortuntaly, the list of ops does not change. So I'm unsure if we should do that. On the other hand, it's likely a good idea to apply it always.",change graph change list change unsure hand likely good idea apply always,issue,positive,positive,positive,positive,positive,positive
502077787,"This was recommended on the issue filed about TensorFlow CoreML exporter, but I can't see any difference for the moment.",issue exporter ca see difference moment,issue,negative,neutral,neutral,neutral,neutral,neutral
502071230,"@reuben I landed a fix for the ElectronJS build issues, you can rebase on top of it.",landed fix build rebase top,issue,negative,positive,positive,positive,positive,positive
502047305,"> So, this means that the 0.4.1 checkpoint no longer works if you want to use it for additional training? About when will there be a compatible version if so?

That's done now.",longer work want use additional training compatible version done,issue,negative,neutral,neutral,neutral,neutral,neutral
502029506,"I have a hard time figuring out exactly how those pieces would have to stick together. IMHO, my experience with such kind of contrib repo is really mixed feelings: often broken, badly maintained. Provides poor user / dev experience, generates frustrations. I understand the need for the feature, but it requires extending the API. How would a contrib repo, in the end, should be integrated to provide that ?",hard time exactly would stick together experience kind really mixed often broken badly poor user dev experience understand need feature extending would end provide,issue,negative,negative,neutral,neutral,negative,negative
502021913,"@div5yesh A `contrib` repo is a reasonable idea. But the we still have to consider the bandwidth required for review and tests of `contrib` code and how`contrib` is updated across non-backward compatible releases.

What's your take @reuben and @lissyx?",reasonable idea still consider review code across compatible take,issue,negative,positive,positive,positive,positive,positive
501826207,"Yes, full logging of variables and gradients slows down our training significantly. I'm planning to make the logging more useful by default but haven't had the time to work on it.

> On 13 Jun 2019, at 11:02, lissyx <notifications@github.com> wrote:
> 
> Didn't we said in a meeting it's here but just not enabled by default for performance reasons ? @reuben
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",yes full logging slows training significantly make logging useful default time work wrote said meeting default performance reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
501773709,"> Maybe a re-ordering of sections too, from simplest to most complex: If I read things right, I would think the simplest use case -- despite the need to run interpreted code from the git repo to set it up -- would be the pre-compiled, binary, command line client, followed by Python / Node.js (in either order) -- which doesn't need the git repo at all(?) -- then the bindings sections, and finally train your own model.

That re-ordering might be tricky, it really is a judgement depending on your own needs. For some people, the very first need is like yours, for some others, it's really training. So I don't really have an opinion as to whether a re-ordering is needed and which proper order is perfect.

> [""Getting the code""](https://github.com/mozilla/DeepSpeech#getting-the-code) seems to be a prerequisite for [""Using the command-line client""](https://github.com/mozilla/DeepSpeech#using-the-command-line-client) since it uses `util/taskcluster.py`, but is not a prerequisite for [""Using the Python package""](https://github.com/mozilla/DeepSpeech#using-the-python-package) since that appears to grab everything it needs via pip.
> 
> Correct?

That's about right yes


> Perhaps it's just my old brain and old eyes. Yes, I saw the section headings. For now, I'm only talking about playing with the interface, not training a model.

Or a different perspective: we know it well, it all seem obivous to us, but that does not mean it's clear to others :).",maybe complex read right would think use case despite need run code git set would binary command line client python either order need git finally train model might tricky really depending need people first need like really training really opinion whether proper order perfect getting code prerequisite client since prerequisite python package since grab everything need via pip correct right yes perhaps old brain old yes saw section talking interface training model different perspective know well seem u mean clear,issue,positive,positive,positive,positive,positive,positive
501770023,"Perhaps it's just my old brain and old eyes. Yes, I saw the section headings. For now, I'm only talking about playing with the interface, not training a model.

[""Getting the code""](https://github.com/mozilla/DeepSpeech#getting-the-code) seems to be a prerequisite for [""Using the command-line client""](https://github.com/mozilla/DeepSpeech#using-the-command-line-client) since it uses `util/taskcluster.py`, but is not a prerequisite for [""Using the Python package""](https://github.com/mozilla/DeepSpeech#using-the-python-package) since that appears to grab everything it needs via pip.

Correct?

Maybe a re-ordering of sections too, from simplest to most complex: If I read things right, I would think the simplest use case -- despite the need to run interpreted code from the git repo to set it up -- would be the pre-compiled, binary, command line client, followed by Python / Node.js (in either order) -- which doesn't need the git repo at all(?) -- then the bindings sections, and finally train your own model.",perhaps old brain old yes saw section talking interface training model getting code prerequisite client since prerequisite python package since grab everything need via pip correct maybe complex read right would think use case despite need run code git set would binary command line client python either order need git finally train model,issue,negative,positive,neutral,neutral,positive,positive
501761506,"Transcription that also label the speakers in the audio for each word or dialogue duration can have useful applications and would relate to metadata for STT.

So maybe having a `contrib` repo, that is an extension to STT which will host features that are related to speech in general. But would result in a powerful DeepSpeech library to cater all kinds of speech related problems.

What do you think?",transcription also label audio word dialogue duration useful would relate maybe extension host related speech general would result powerful library cater speech related think,issue,positive,positive,positive,positive,positive,positive
501757331,"@kjcole Still, if you have suggestions / proposal on how to re-organize, do not hesitate to share input or open a PR.",still proposal hesitate share input open,issue,negative,neutral,neutral,neutral,neutral,neutral
501755968,"e.g., you want to play with the inference ? https://github.com/mozilla/DeepSpeech#using-a-pre-trained-model

you want to train a model ? https://github.com/mozilla/DeepSpeech#training-your-own-model",want play inference want train model,issue,negative,neutral,neutral,neutral,neutral,neutral
501755408,"@kjcole The README does have titles / sections, isn't it enough to give context depending on what is your need ? As much as I can remember, we made sure sections depending on use-cases were properly scoped and self-contained.",enough give context depending need much remember made sure depending properly,issue,negative,positive,positive,positive,positive,positive
501754220,Re-requesting review for the last commit fixing the concurrent streams bug. I'm also going to add a test that exercises this.,review last commit fixing concurrent bug also going add test,issue,negative,neutral,neutral,neutral,neutral,neutral
501717560,"@reuben I guess we can merge that after you rebase, now that 0.5.0 is shipped.",guess merge rebase shipped,issue,negative,neutral,neutral,neutral,neutral,neutral
501716227,Didn't we said in a meeting it's here but just not enabled by default for performance reasons ? @reuben ,said meeting default performance,issue,negative,neutral,neutral,neutral,neutral,neutral
501635787,"As this seems to be moving into more of a conversation, I suggest we move it to [discourse](https://discourse.mozilla.org/c/deep-speech) as we try to reserve issues for bugs and/our feature requests.",moving conversation suggest move discourse try reserve feature,issue,negative,neutral,neutral,neutral,neutral,neutral
501631197,"Oh yes ! thnx
sorry for posting that then !",oh yes sorry posting,issue,negative,negative,negative,negative,negative,negative
501277418,Work has resumed and is progressing on https://github.com/Common-Voice/commonvoice-fr/. Please check the Docker written for reproductibility https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/CONTRIBUTING.md as well as repo's releases.,work please check docker written well,issue,positive,neutral,neutral,neutral,neutral,neutral
501090830,"> @mychiux413 @reuben Added a fix for this [here](df5bb310469adebdb31530367063403a5ea3c1c5). So I'd try with 0.5.0-alpha.9 or later.

I've tried 0.5.0-alpha.11 with ~120GB dataset, the testing did work, so this issue could be closed, thanks for your help.",added fix try later tried testing work issue could closed thanks help,issue,positive,positive,neutral,neutral,positive,positive
501057436,Just wanted to thank you for your efforts! Keep up all the good work,thank keep good work,issue,positive,positive,positive,positive,positive,positive
500955964,"@GommeAntiLegit I'm sorry for being difficult here, I can see you've put a lot of effort into this and we definitely don't want that to go to waste. There's obviously a disagreement between us and you on what's acceptable to land _in this specific PR, at once_. Here's how I think we can work towards a middle ground:

First, you can publish your Java binding separately in your own repository, like the [Go](https://github.com/asticode/go-astideepspeech/) and [Rust](https://github.com/RustAudio/deepspeech-rs) bindings do. We'll list it in the README along with the other language bindings

Then, if you're still interested in uplifting some or all of this code, we can open individual, self-contained issues against our current Java/Android bindings, each describing a specific pain point or deficiency, so that they can be discussed and a rough solution plan can be agreed upon. We can then uplift parts or all of your Java bindings into our Java/Android bindings to fix these issues, but in small chunks at a time, so that we can agree on a solution that is good for users but also an acceptable maintenance burden for the team.

I hope this experience hasn't driven you off entirely from collaborating with us, but I also understand if you're no longer interested, I know it can be frustrating to go through many revisions after you've already spent so much time getting a PR working.",sorry difficult see put lot effort definitely want go waste obviously disagreement u acceptable land specific think work towards middle ground first publish binding separately repository like go rust list along language still interested uplifting code open individual current specific pain point deficiency rough solution plan agreed upon uplift fix small time agree solution good also acceptable maintenance burden team hope experience driven entirely u also understand longer interested know go many already spent much time getting working,issue,positive,positive,neutral,neutral,positive,positive
500880360,"> The problem is that when using the native client ""deepspeech"" i got this error :
> SyntaxError: Non-UTF-8 code starting with '\x83' in file deepspeech on line 2, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
> Is there a difference between using the native client ""deepspeech"" and the installed one ?

Well since i have not been able to understand what you did to get that error, and what you refer to as ""native client deepspeech"", I can't tell.",problem native client got error code starting file line declared see difference native client one well since able understand get error refer native client ca tell,issue,negative,positive,positive,positive,positive,positive
500879937,"may be I have to use the deepspeech in the native client and not the one that I get by doing pip install.
The problem is that when using the native client ""deepspeech"" i got this error : 
SyntaxError: Non-UTF-8 code starting with '\x83' in file deepspeech on line 2, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
Is there a difference between using the native client ""deepspeech"" and the installed one ?
",may use native client one get pip install problem native client got error code starting file line declared see difference native client one,issue,negative,neutral,neutral,neutral,neutral,neutral
500878558,"> my alphabet.txt contains all the caracters gived by this command so I don't think that the empty inferences are caused by that

No, but if you use two differently ordered alphabet for example, it might mess. We've got reports in the past of people messing around with alphabet files and getting empty results.",command think empty use two differently ordered alphabet example might mess got past people messing around alphabet getting empty,issue,negative,negative,negative,negative,negative,negative
500877007,"@GommeAntiLegit I understand the implications of having to copy data around, what I'm asking for is concrete evidence that this is a problem for DeepSpeech. As in, ""I tried to do it the SWIG way and it used X MBs of memory, which is too much"", or ""it had a large real time factor of X, but after I made these optimizations, the RTF is now Y < X"".

We already have several language bindings we have to maintain, and having to update hand-written C/C++ for API changes for each language is just impossible to scale. 

> Are there changes planned to the native library that requires the bindings to be rewritten?

DeepSpeech is on major version 0, so there's no API guarantees. We've broken backwards compatibility in 3 out of 5 releases so far, so despite us not having plans to break things, it does happen, specially as things haven't stabilized for a 1.x release yet.",understand copy data around concrete evidence problem tried swig way used memory much large real time factor made already several language maintain update language impossible scale native library major version broken backwards compatibility far despite u break happen specially release yet,issue,negative,positive,neutral,neutral,positive,positive
500874834,"> > > `nano alphabet.txt` and then add alphabet
> > 
> > 
> > And how did you made sure you covered everything that was in the dataset and in the language model source file ?
> 
> `python3.6 check_characters.py -csv ~/deepspeech_dataset/clips/train.csv`

You could have generated the alphabet using that tool.",add alphabet made sure covered everything language model source file python could alphabet tool,issue,negative,positive,positive,positive,positive,positive
500874521,"> Passing large java arrays to native functions is really expensive.

Define **large**


> Are there changes planned to the native library that requires the bindings to be rewritten?

For the same reason that you never plan to die in a car crash, we don't plan on breaking everything. But we might need to. We already had to take care of exposing more data to existing bindings. That goes into the scope of caring about complexity of maintainance.


> Why almost generate the bindings, when the DeepSpeech functions are not supposed to change in the first place?

Why have to take care of writing boiler plate code that you have to maintain when you can generate it, and that more clever and experience people than you actually made sure it was efficient, and leak-free ?

> The next argument is that the bindings are over-engineered. Compared to other Java libraries, they are really not. I don't even want to think about the hundreds of Factories and Builders and what not.

They are as long as you take care of things that are not required like CPU / CUDA / Android configuration stuff, as well as re-wrap things that are not required like StreamState.


> I just abstracted things that were ignored or not handled in the current bindings additionally such as multi platform support + Cuda support and different types of errors. Telling the programmer what went wrong in a non cryptic way only reduces the amount of issues created on the repository.

Which is a lot of code for a very low usage. Every code that is written has to be tested and taken care of for a long time. Take a look at all the bindings, they package the appropriate `libdeepspeech.so` and so there is no such problem.",passing large native really expensive define large native library reason never plan die car crash plan breaking everything might need already take care data go scope complexity almost generate supposed change first place take care writing boiler plate code maintain generate clever experience people actually made sure efficient next argument really even want think long take care like android configuration stuff well like abstracted handled current additionally platform support support different telling programmer went wrong non cryptic way amount repository lot code low usage every code written tested taken care long time take look package appropriate problem,issue,positive,positive,neutral,neutral,positive,positive
500872580,"> > `nano alphabet.txt` and then add alphabet
> 
> And how did you made sure you covered everything that was in the dataset and in the language model source file ?

`python3.6 check_characters.py -csv ~/deepspeech_dataset/clips/train.csv`",add alphabet made sure covered everything language model source file python,issue,negative,positive,positive,positive,positive,positive
500870939,"> `nano alphabet.txt` and then add alphabet

And how did you made sure you covered everything that was in the dataset and in the language model source file ?",add alphabet made sure covered everything language model source file,issue,negative,positive,positive,positive,positive,positive
500870534,"



> > how can I check this ?
> 
> Check what ?
> 
> > I made in alphabet.txt the french caracters
> 
> How ?

`nano alphabet.txt` and then add alphabet",check check made add alphabet,issue,negative,neutral,neutral,neutral,neutral,neutral
500869599,"I made in alphabet.txt the french caracters
I generated lm.binary like this :
```
kenlm/build/bin/./lmplz --text ~/DeepSpeech/data/vocabulary.txt --arpa ~/DeepSpeech/data/words.arpa --o 5
kenlm/build/bin/./build_binary -T -s ~/DeepSpeech/data/words.arpa ~/DeepSpeech/data/lm/lm.binary
```
and generated trie like this :
`~/tensorflow/bazel-bin/native_client/generate_trie ~/DeepSpeech/data/alphabet.txt ~/DeepSpeech/data/lm.binary ~/DeepSpeech/data/trie
`
how can I check this ?",made like text like check,issue,positive,neutral,neutral,neutral,neutral,neutral
500867331,"> > `sha1sum alphabet.txt`
> 
> this command gives :
> 17d3fd2c19e31be7fdda16f1355053f1b8ca4612 alphabet.txt

Can your quadruple check you are absolutely using the same and the correct alphabet, lm.binary and trie files? 99.99% of the ""empty inferences"", outside of improper training, were related to that.",command quadruple check absolutely correct alphabet empty outside improper training related,issue,negative,positive,neutral,neutral,positive,positive
500866725,">  Saying what is bad is of course valuable information, but I don't see a solution to ""Make stuff less complicated"".

I've documented that above: https://github.com/mozilla/DeepSpeech/pull/2166#issuecomment-500828431",saying bad course valuable information see solution make stuff le complicated,issue,negative,negative,negative,negative,negative,negative
500863299,"didn't get what you mean by ""(sha1 fingerprint)"" :/",get mean sha fingerprint,issue,negative,negative,negative,negative,negative,negative
500860543,"The first aspect is using native heap memory over Java arrays. Passing large java arrays to native functions is really expensive. You don't even notice that, if you let Swig do the boilerplate code for you. Accessing a Java array natively means copying it.
This sums up the problem pretty well:
https://stackoverflow.com/questions/17709210/jni-passing-large-amounts-of-data-between-java-and-native-code/17710121

The main argument is, that the design makes the library hard to maintain. Are there changes planned to the native library that require the bindings to be rewritten? I mean as long as the IO of the DeepSpeech functions does not change, the bindings can remain unchanged for all future versions to come.
Why almost generate the bindings, when the DeepSpeech functions are not supposed to change in the first place? Nobody who uses the native library wants to migrate their code every now and then.

The next argument is that the bindings are over-engineered. Compared to other Java libraries, they are really not. I don't even want to think about the hundreds of Factories and Builders and what not.
Even though this is very subjective, I have to say I did not do that much more abstraction than the previous bindings. I just abstracted things that were ignored or not handled in the current bindings additionally such as multi platform support + Cuda support and different types of errors. Telling the programmer what went wrong in a non cryptic way only reduces the amount of issues created on the repository.

My last question is: What exactly should be changed, as I see you are not very happy with the PR?
Saying what is bad is of course valuable information, but I don't see a solution to ""Make stuff less complicated"".",first aspect native heap memory passing large native really expensive even notice let swig code array natively problem pretty well main argument design library hard maintain native library require mean long io change remain unchanged future come almost generate supposed change first place nobody native library migrate code every next argument really even want think even though subjective say much abstraction previous abstracted handled current additionally platform support support different telling programmer went wrong non cryptic way amount repository last question exactly see happy saying bad course valuable information see solution make stuff le complicated,issue,positive,negative,neutral,neutral,negative,negative
500848956,"Closing the issue, since it was more related to the way (i.e. code) I splitted the data. I worked it out later with shell scripts. If anyone later finds a correct way to split the data using Python, please advice. ",issue since related way code data worked later shell anyone later correct way split data python please advice,issue,negative,neutral,neutral,neutral,neutral,neutral
500843968,"```
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
I Restored variables from most recent checkpoint at ~/results/checkpoints/train-158, step 158
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 1:02:16 | Steps: 159 | Loss: 132.824389   WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
```

then I have steps for each epoch and at the end of each epoch I had this :
```
I Saved new best validating model with loss x to: ~/results/checkpoints/best_dev-325
```

after 10 epochs I get this message : 
```
I Early stop triggered as (for last 4 steps) validation loss: 68.492657 with standard deviation: 0.667485 and mean: 67.559747
I FINISHED optimization in 14:35:47.888453
I Restored variables from best validation checkpoint at ~/results/checkpoints/best_dev-1494, step 1494
Testing model on ~/deepspeech_dataset/clips/test.csv
Test epoch | Steps: 158 | Elapsed Time: 0:24:45                                
Test on ~/deepspeech_dataset/clips/test.csv - WER: 0.709969, CER: 0.413470, loss: 68.295815
WER: 1.500000, CER: 0.333333, loss: 28.491713
 - src: ""en substitution""
 - res: ""on se situation""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.647059, loss: 29.111736
 - src: ""vingtdeux maisons""
 - res: ""va de mal""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.833333, loss: 29.264719
 - src: ""depuis quand""
 - res: ""deux plus fort""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.583333, loss: 30.396891
 - src: ""où habitestu""
 - res: ""ou vite que""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.375000, loss: 30.682699
 - src: ""avis défavorable""
 - res: ""avenue de favorable""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.470588, loss: 30.730188
 - src: ""rendeznous jospin""
 - res: ""route nous juste""
--------------------------------------------------------------------------------
WER: 1.500000, CER: 0.588235, loss: 31.368996
 - src: ""habillezvous vite""
 - res: ""aviez ou les""
--------------------------------------------------------------------------------
I Exporting the model...
I Removing old export
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
I Models exported at ~/results/model_export/
```",python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape warning removed future version handled automatically placer warning removed future version use instead warning removed future version use standard file check prefix recent step starting optimization epoch training time loss warning removed future version epoch end epoch saved new best model loss get message early stop triggered last validation loss standard deviation mean finished optimization best validation step testing model test epoch time test wer loss wer loss en substitution se situation wer loss de mal wer loss plus fort wer loss wer loss avenue de favorable wer loss route nous wer loss model removing old export warning removed future version use warning removed future version use,issue,negative,positive,positive,positive,positive,positive
500839469,Could you share the full training log ?,could share full training log,issue,negative,positive,positive,positive,positive,positive
500838012,"> > my wave file was tested during the learning process and it gives a result. but when I tried to test the same file with my exported model it gives me empty inferences...
> 
> That should not happen. 50 hours and 10 epochs is obviously not enough, but if you test a file from the test set, you should get the same result.

I made epochs = 50 but the training process stopped after 10 epochs and I'm not getting the same result for the same file tested",wave file tested learning process result tried test file model empty happen obviously enough test file test set get result made training process stopped getting result file tested,issue,negative,negative,neutral,neutral,negative,negative
500837238,"> my wave file was tested during the learning process and it gives a result. but when I tried to test the same file with my exported model it gives me empty inferences...

That should not happen. 50 hours and 10 epochs is obviously not enough, but if you test a file from the test set, you should get the same result.",wave file tested learning process result tried test file model empty happen obviously enough test file test set get result,issue,negative,negative,neutral,neutral,negative,negative
500836472,"> Are you saying when you run the client on the same audio files that are in your test CSV file, it gives different results than the training code?

my wave file was tested during the learning process and it gives a result. but when I tried to test the same file with my exported model it gives me empty inferences...",saying run client audio test file different training code wave file tested learning process result tried test file model empty,issue,negative,negative,neutral,neutral,negative,negative
500832598,"Are you saying when you run the client on the same audio files that are in your test CSV file, it gives different results than the training code?",saying run client audio test file different training code,issue,negative,neutral,neutral,neutral,neutral,neutral
500831947,"the command to train deepspeech.py : 
```
python3.6 -u DeepSpeech.py --train_files ~/deepspeech_dataset/clips/train.csv --dev_files ~/deepspeech_dataset/clips/dev.csv --test_files ~/deepspeech_dataset/clips/test.csv --train_batch_size 80 --dev_batch_size 80 --test_batch_size 40 --n_hidden 1024 --epoch 50 --use_seq_length False --report_count 100 --remove_export True --checkpoint_dir ~/results/checkpoints/ --export_dir ~/results/model_export/ --alphabet_config_path ~/DeepSpeech/data/alphabet.txt --lm_binary_path ~/DeepSpeech/data/lm/lm.binary --lm_trie_path ~/DeepSpeech/data/lm/trie
```

and the training stops after 10 epochs with this message :
I Early stop triggered as (for last 4 steps) validation loss: 68.492657 with standard deviation: 0.667485 and mean: 67.559747
I FINISHED optimization in
after that I get the inferences for test.csv (and they were not empty)",command train python epoch false true training message early stop triggered last validation loss standard deviation mean finished optimization get empty,issue,negative,negative,neutral,neutral,negative,negative
500831890,"@GommeAntiLegit you mention performance issues in the comments here and in the issue you filed. Can you give us more detail into the concrete problems you've faced? Basically, this PR trades off maintainability for performance gains, but without knowing what the gains are, it's hard to know if the trade off is worth it. If you could share your experience using DeepSpeech and what performance problems you faced, it'll help us understand the design choices here.",mention performance issue give u detail concrete faced basically performance gain without knowing gain hard know trade worth could share experience performance faced help u understand design,issue,positive,positive,neutral,neutral,positive,positive
500830472,">  getting more data is the best solution to avoid getting empty inferences ?

That and ensuring proper training. Since you have not shared your parameters, I can't tell if it also has a play in your case.",getting data best solution avoid getting empty proper training since ca tell also play case,issue,positive,positive,positive,positive,positive,positive
500828431,"@GommeAntiLegit Overall, the PR is really invasive. You should:
 - split into meaningful and more focused commits or even PRs
 - avoid breaking our system
 - avoid over-engineering like the CPU / CUDA / Android complex system you setup",overall really invasive split meaningful even avoid breaking system avoid like android complex system setup,issue,negative,positive,neutral,neutral,positive,positive
500826952,"Yes, 50 hours is way way way not enough.",yes way way way enough,issue,negative,neutral,neutral,neutral,neutral,neutral
500826489,"just a question concerning the amount of data to get good inferences (50 hours isn't enough ?)
getting more data is the best solution to avoid getting empty inferences ?",question concerning amount data get good enough getting data best solution avoid getting empty,issue,positive,positive,positive,positive,positive,positive
500820894,"> The bindings are now finished and the pull request has been made.

Issue should be closed once the matching PR lands :)",finished pull request made issue closed matching,issue,negative,negative,neutral,neutral,negative,negative
500819260,"@GommeAntiLegit Thanks. I'm really with mixed feeling after having a quick look, because it looks like your thrown a lot of work into that, but at the same time, you have not listened to the feedback we gave you on the issue you filed. That makes the PR basically not mergeable without a lot of re-work. I'll go deeper to give feedback.",thanks really mixed feeling quick look like thrown lot work time feedback gave issue basically without lot go give feedback,issue,positive,positive,positive,positive,positive,positive
500817685,The bindings are now finished and the pull request has been made.,finished pull request made,issue,negative,neutral,neutral,neutral,neutral,neutral
500792409,"Hi all, thanks for reporting. I've made a PR that should fix this: https://github.com/mozilla/DeepSpeech/pull/2165",hi thanks made fix,issue,negative,positive,positive,positive,positive,positive
500791009,"> > > I have to convert my output_graph.pb like this or not ?
> > > $ convert_graphdef_memmapped_format --in_graph=output_graph.pb --out_graph=output_graph.pbmm
> > 
> > 
> > That just means your training was not enough. Hence why I insist on contributing to french model, because you are not the first one training and getting empty inferences, because of not enough data / training / improper parameters.
> 
> For the wav files in the test file I get inferences
> ![image](https://user-images.githubusercontent.com/51698388/59266432-ef7ca200-8c47-11e9-85a9-fa7d64dcbc12.png)
> 
> but when I want to test the exported model I don't get anything

Please avoid posting screenshots, it's very hard to use. Again, that's expected bahavior. Without the full training log it's hard to be definitive, but it's really not surprising ...",convert like training enough hence insist model first one training getting empty enough data training improper test file get image want test model get anything please avoid posting hard use without full training log hard definitive really surprising,issue,negative,positive,neutral,neutral,positive,positive
500790687,"> > I have to convert my output_graph.pb like this or not ?
> > $ convert_graphdef_memmapped_format --in_graph=output_graph.pb --out_graph=output_graph.pbmm
> 
> That just means your training was not enough. Hence why I insist on contributing to french model, because you are not the first one training and getting empty inferences, because of not enough data / training / improper parameters.

For the wav files in the test file I get inferences 
![image](https://user-images.githubusercontent.com/51698388/59266432-ef7ca200-8c47-11e9-85a9-fa7d64dcbc12.png)

but when I want to test the exported model I don't get anything",convert like training enough hence insist model first one training getting empty enough data training improper test file get image want test model get anything,issue,negative,positive,neutral,neutral,positive,positive
500790183,"@testdeepv If you need a model that works right now, there's no best solution than to train on top of english (not yet) released 0.5.0 and with other dataset, as documented in WIP PR https://github.com/Common-Voice/commonvoice-fr/pull/44 as well as https://discourse.mozilla.org/t/un-premier-modele-francais/41100/7",need model work right best solution train top yet well,issue,positive,positive,positive,positive,positive,positive
500789534,"> I have to convert my output_graph.pb like this or not ?
> $ convert_graphdef_memmapped_format --in_graph=output_graph.pb --out_graph=output_graph.pbmm

That just means your training was not enough. Hence why I insist on contributing to french model, because you are not the first one training and getting empty inferences, because of not enough data / training / improper parameters.",convert like training enough hence insist model first one training getting empty enough data training improper,issue,negative,positive,neutral,neutral,positive,positive
500785659,"when i did this and specify the deepspeech path  : 
```
python3.6 /usr/local/bin/deepspeech --model ~/results/model_export/output_graph.pb --alphabet ~/Deepspeech/data/alphabet.txt --lm ~/DeepSpeech/data/lm/lm.binary --trie ~/DeepSpeech/data/lm/trie --audio test.wav -t
I get this : 
Loading model from file ~/results/model_export/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.11-0-g1201739
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-06-11 10:31:48.501980: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions tha
t this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 10:31:48.511050: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR
_NO_DEVICE: no CUDA-capable device is detected
2019-06-11 10:31:48.511184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:148] kernel driver does not appea
r to be running on this host (instance-2): /proc/driver/nvidia/version does not exist
2019-06-11 10:31:48.570438: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" de
vice_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 10:31:48.570541: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" devi
ce_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVarian
t
2019-06-11 10:31:48.570554: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" devi
ce_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-11 10:31:48.570798: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" de
vice_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVa
riant
Loaded model in 0.0733s.
Loading language model from files~/DeepSpeech/data/lm/lm.binary ~/DeepSpeech/data/lm/trie
Loaded language model in 0.0135s.
Running inference.
Inference took 2.695s for 7.160s audio file.
```
I can't understand all this tensorflow warnings :(",specify path python model alphabet audio get loading model file warning reading entire model file memory transform model file graph reduce heap usage tha binary use call device kernel driver running host exist de unknown unknown unknown de unknown riant loaded model loading language model loaded language model running inference inference took audio file ca understand,issue,negative,negative,neutral,neutral,negative,negative
500783571,The only change to that part of the codebase on this range is commit d9a269412e492ca5046c9ab89f0547be51050159 cc @dabinat ,change part range commit,issue,negative,neutral,neutral,neutral,neutral,neutral
500783099,"It would looks like this regressed between alpha 8 and alpha 9 cc @reuben:
```
TensorFlow: v1.13.1-10-g3e0cc53                                                                                                                                              
DeepSpeech: v0.5.0-alpha.8-0-ga4b35d2                                                                                                                                     
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.                                                                                                                                                                                                                                                                                               
2019-06-11 12:27:07.425029: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 12:27:07.429311: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant                                                                                                                                                                                                                                     
2019-06-11 12:27:07.429329: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 12:27:07.429335: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-11 12:27:07.429392: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
{   
  ""metadata"": {
    ""confidence"": 25.0861
  },                
  ""words"": [    
    {                
      ""word"": ""she"",
      ""time"": 0,
      ""duration"": 0.1
    },             
    {                 
      ""word"": ""ha"",
      ""time"": 0.14,
      ""duration"": 0.04      
    },            
    {                 
      ""word"": ""aylalsyalar"",
      ""time"": 0.2,
      ""duration"": 1      
    },             
    {              
      ""word"": ""ruraraua"",
      ""time"": 1.24,
      ""duration"": 1.02     
    },             
    {                 
      ""word"": ""asuorashar"",
      ""time"": 2.28,
      ""duration"": 1.32
    }                                         
  ]
}
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.9-0-g82df4a3
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-06-11 12:27:07.780069: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 12:27:07.784670: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 12:27:07.784691: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 12:27:07.784697: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-11 12:27:07.784785: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
{
  ""metadata"": {
    ""confidence"": 25.0861
  },
  ""words"": [
    {
      ""word"": ""she"",
      ""time"": 0,
      ""duration"": 0.1
    },
    {
      ""word"": ""ha"",
      ""time"": 0.14,
      ""duration"": 0.04
    },
    {
      ""word"": ""aylalsyalar"",
      ""time"": 0.2,
      ""duration"": 0.04
    },
    {
      ""word"": ""ruraraua"",
      ""time"": 0.28,
      ""duration"": 0
    },
    {
      ""word"": ""asuorashar"",
      ""time"": 0.04,
      ""duration"": 0.04
    }
  ]
}
```",would like alpha alpha warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown confidence word time duration word ha time duration word time duration word time duration word time duration warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown confidence word time duration word ha time duration word time duration word time duration word time duration,issue,positive,negative,neutral,neutral,negative,negative
500782882,"> may be I have to install the gpu version of deepspeech ?

No, it's unrelated.",may install version unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
500781887,"@testdeepv Strange. Can you please properly uninstall and then reinstall, using your distro's Python/PIP and a virtualenv as we document ?",strange please properly reinstall document,issue,negative,negative,neutral,neutral,negative,negative
500781468,"```
#!/usr/local/bin/python3.6

# -*- coding: utf-8 -*-
import re
import sys

from deepspeech.client import main

if __name__ == '__main__':
    sys.argv[0] = re.sub(r'(-script\.pyw?|\.exe)?$', '', sys.argv[0])
    sys.exit(main())
```",import import import main main,issue,negative,positive,positive,positive,positive,positive
500780676,">  'ls -hal $(which deepspeech)' gives : -rwxr-xr-x 1 root root 228 Jun 11 10:09 /usr/local/bin/deepspeech

Can you paste its content ?",root root paste content,issue,negative,neutral,neutral,neutral,neutral,neutral
500780390,"> > sudo python3.6 -m pip install deepspeech==0.5.0a11
> 
> You should really follow the docs and use `virtualenv`, installing as root is not a good practice.
> OK
> > python3.6: can't open file 'deepspeech': [Errno 2] No such file or directory
> 
> That's another issue now. What does `which deepspeech` and `ls -hal $(which deepspeech)` gives?

which deepspeech output : /usr/local/bin/deepspeech
'ls -hal $(which deepspeech)' gives : -rwxr-xr-x 1 root root 228 Jun 11 10:09 /usr/local/bin/deepspeech
",python pip install really follow use root good practice python ca open file file directory another issue output root root,issue,negative,positive,positive,positive,positive,positive
500779502,">  sudo python3.6 -m pip install deepspeech==0.5.0a11

You should really follow the docs and use `virtualenv`, installing as root is not a good practice.


>  python3.6: can't open file 'deepspeech': [Errno 2] No such file or directory

That's another issue now. What does `which deepspeech` and `ls -hal $(which deepspeech)` gives?",python pip install really follow use root good practice python ca open file file directory another issue,issue,negative,positive,positive,positive,positive,positive
500778959,"> > then I have to do pip install deepspeech and do not use the deepspeech I have in native client file ?
> 
> There is no good reason in your case to have to rebuild everything, yes. Also, sorry to insist, but it's really important that you join efforts to help produce a french model ...

I did this : 
sudo python3.6 -m pip install deepspeech==0.5.0a11
and when doing this command : 
python3.6 deepspeech --model ~/results/model_export/output_graph.pb --alphabet ~/Deepspeech/data/alphabet.txt --lm ~/DeepSpeech/data/lm/lm.binary --trie ~/DeepSpeech/data/lm/trie --audio test.wav -t
I still get an error: 
python3.6: can't open file 'deepspeech': [Errno 2] No such file or directory",pip install use native client file good reason case rebuild everything yes also sorry insist really important join help produce model python pip install command python model alphabet audio still get error python ca open file file directory,issue,positive,positive,positive,positive,positive,positive
500778506,"> > trained a french model.
> 
> Also, could you please join efforts ? [Common-Voice/commonvoice-fr#44](https://github.com/Common-Voice/commonvoice-fr/pull/44) https://github.com/Common-Voice/commonvoice-fr https://discourse.mozilla.org/c/voice/fr

I will sure do it :)",trained model also could please join sure,issue,positive,positive,positive,positive,positive,positive
500777435,"> then I have to do pip install deepspeech and do not use the deepspeech I have in native client file ?

There is no good reason in your case to have to rebuild everything, yes. Also, sorry to insist, but it's really important that you join efforts to help produce a french model ...",pip install use native client file good reason case rebuild everything yes also sorry insist really important join help produce model,issue,positive,positive,positive,positive,positive,positive
500776816,then I have to do pip install deepspeech and do not use the deepspeech I have in native client file ?,pip install use native client file,issue,negative,neutral,neutral,neutral,neutral,neutral
500775822,"> > > I git cloned deepspeech and mozilla tensorflow, build both of them, generated binaries and trained a french model.
> > 
> > 
> > Why did you do this ? We have prebuilt binaries, you don't have to do that.
> > I changed alphabet.txt to add french caracters and then created lm.binary and trie files

Still, you don't need to rebuild just to change alphabet.",git build trained model add still need rebuild change alphabet,issue,negative,neutral,neutral,neutral,neutral,neutral
500775257,"> > I git cloned deepspeech and mozilla tensorflow, build both of them, generated binaries and trained a french model.
> 
> Why did you do this ? We have prebuilt binaries, you don't have to do that.
> I changed alphabet.txt to add french caracters and then created lm.binary and trie files",git build trained model add,issue,negative,neutral,neutral,neutral,neutral,neutral
500775064,"> trained a french model.

Also, could you please join efforts ? https://github.com/Common-Voice/commonvoice-fr/pull/44 https://github.com/Common-Voice/commonvoice-fr https://discourse.mozilla.org/c/voice/fr",trained model also could please join,issue,positive,neutral,neutral,neutral,neutral,neutral
500774091,">  I didn't pip install deepspeech, I have it in the deepspeech native client after the build

Well then please document exactly what you did.

>  I git cloned deepspeech and mozilla tensorflow, build both of them, generated binaries and trained a french model.

Why did you do this ? We have prebuilt binaries, you don't have to do that.

> I installed python3.6 because in the VM I'm using python3.5 is the default python3.

Python 3.5 should work as well.",pip install native client build well please document exactly git build trained model python python default python python work well,issue,positive,positive,positive,positive,positive,positive
500773588,"I installed python3.6 because in the VM I'm using python3.5 is the default python3.
I git cloned deepspeech and mozilla tensorflow, build both of them, generated binaries and trained a french model.
I didn't pip install deepspeech, I have it in the deepspeech native client after the build
",python python default python git build trained model pip install native client build,issue,negative,neutral,neutral,neutral,neutral,neutral
500773197,"@testdeepv The file `/home/alex/tmp/deepspeech/issue2164/venv/bin/deepspeech` is being generated at `pip install` time. According to your error, it's the one with bogus UTF-8. But we don't control it.",file pip install time according error one bogus control,issue,negative,neutral,neutral,neutral,neutral,neutral
500772673,"```
alex@portable-alex:~/tmp/deepspeech/issue2164$ source venv/bin/activate
(venv) alex@portable-alex:~/tmp/deepspeech/issue2164$ pip install deepspeech==0.5.0a11
Collecting deepspeech==0.5.0a11
  Downloading https://files.pythonhosted.org/packages/b2/fd/bdcb51eae62e6df60a252e8395d49ef145fa101139b530b8e81448ca336e/deepspeech-0.5.0a11-cp37-cp37m-manylinux1_x86_64.whl (15.6MB)
     |████████████████████████████████| 15.6MB 4.9MB/s 
Collecting numpy>=1.14.5 (from deepspeech==0.5.0a11)
  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)
     |████████████████████████████████| 17.3MB 65.5MB/s 
Installing collected packages: numpy, deepspeech
Successfully installed deepspeech-0.5.0a11 numpy-1.16.4
(venv) alex@portable-alex:~/tmp/deepspeech/issue2164$ deepspeech 
usage: deepspeech [-h] --model MODEL --alphabet ALPHABET [--lm [LM]]
                  [--trie [TRIE]] --audio AUDIO [--version] [--extended]
deepspeech: error: the following arguments are required: --model, --alphabet, --audio
(venv) alex@portable-alex:~/tmp/deepspeech/issue2164$ which deepspeech
/home/alex/tmp/deepspeech/issue2164/venv/bin/deepspeech
```",source pip install collected successfully usage model model alphabet alphabet audio audio version extended error following model alphabet audio,issue,negative,positive,positive,positive,positive,positive
500772136,"> I'm running the deepspeech file from the Deepspeech native client

Well, you mention `python3.6` above. So I suspect you did `pip install` ?",running file native client well mention suspect pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
500771850,I'm running the deepspeech file from the Deepspeech native client,running file native client,issue,negative,neutral,neutral,neutral,neutral,neutral
500770881,"> What do you mean by ""setup is straight"" ?

Well, `/usr/local` feels like a non-default distro setup. The `deepspeech` file is being generated at install time.",mean setup straight well like setup file install time,issue,positive,negative,neutral,neutral,negative,negative
500769965,"I have the exact same issue. (expecting time to increase). Binaries from v0.5.0-alpha.11 - `native_client.amd64.cuda.linux`

Full JSON: https://pastebin.com/AF2L7jB1

The audio is from this video: `https://www.youtube.com/watch?v=4mxXdCUXSSs`

Command: ```time ./deepspeech --model ./deepspeech-0.5.0-models/output_graph.pbmm --alphabet ./deepspeech-0.5.0-models/alphabet.txt --lm ./deepspeech-0.5.0-models/lm.binary --trie ./deepspeech-0.5.0-models/trie --audio 4mxXdCUXSSs.wav --json```

TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.11-0-g1201739

```
{
  ""metadata"": {
    ""confidence"": 17082.9
  },
  ""words"": [
    {
      ""word"": ""among"",
      ""time"": 0.3,
      ""duration"": 0
    },
    {
      ""word"": ""so"",
      ""time"": 0.28,
      ""duration"": 0
    },
    {
      ""word"": ""as"",
      ""time"": 0.2,
      ""duration"": 0
    },
    {
      ""word"": ""an"",
      ""time"": 0.06,
      ""duration"": 0.08
    },
    {
      ""word"": ""coveter"",
      ""time"": 0.16,
      ""duration"": 0
    },
    {
      ""word"": ""art"",
      ""time"": 0.26,
      ""duration"": 0
    },
    {
      ""word"": ""so"",
      ""time"": 0.14,
      ""duration"": 0.16
    },
    {
      ""word"": ""as"",
      ""time"": 0.06,
      ""duration"": 0.08
    },
    {
      ""word"": ""far"",
      ""time"": 0.2,
      ""duration"": 0
    },
    {
      ""word"": ""as"",
      ""time"": 0.12,
      ""duration"": 0.08
    },
    {
      ""word"": ""teeple"",
      ""time"": 0.26,
      ""duration"": 0
    },
    {
      ""word"": ""becoming"",
      ""time"": 0.06,
      ""duration"": 0.06
    },
    {
      ""word"": ""billionaires"",
      ""time"": 0.18,
      ""duration"": 0
    },
    {
      ""word"": ""and"",
      ""time"": 0.16,
      ""duration"": 0.08
    },
    {
      ""word"": ""entering"",
      ""time"": 0.3,
      ""duration"": 0
    },
    {
      ""word"": ""it"",
      ""time"": 0.18,
      ""duration"": 0.06
    },
    {
      ""word"": ""to"",
      ""time"": 0.28,
      ""duration"": 0
    },
    {
      ""word"": ""philanthropists"",
      ""time"": 0.08,
      ""duration"": 0.12
    },
...
```

",exact issue time increase full audio video command time model alphabet audio confidence word among time duration word time duration word time duration word time duration word coveter time duration word art time duration word time duration word time duration word far time duration word time duration word time duration word becoming time duration word time duration word time duration word entering time duration word time duration word time duration word time duration,issue,positive,positive,positive,positive,positive,positive
500769169,"As in #1892 , I was expecting this format, where time information is increasing:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```",format time information increasing file duration time word time word time word time word time word time word life time word time word time word studio time word time word time word prime time word minister time word time word make time word good time word morning time word time word lin time word enter time word time word time word time word agree time word time word start time word time word time word time word one time word thing time word time word time word deserving time word time word time word time word time word said time word time word going time word time word time word time word time word time word important time word election time word time word time word son time word time word bite time word time word absolutely time word crucial time word time word time word time word time word time word think time word time word time word simple,issue,positive,positive,positive,positive,positive,positive
500756034,"Strange that your pip is in `/usr/local`, can you make sure your setup is straight ?",strange pip make sure setup straight,issue,negative,positive,positive,positive,positive,positive
500755737,"When I run this command : python3.6 -m pip --version
I get : pip 18.1 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)
I have to upgrade it ?",run command python pip version get pip python upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
500753853,"> SyntaxError: Non-UTF-8 code starting with '\x83' in file deepspeech on line 2, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details
> Any suggestions to resolve this please ?

This is produced by Python itself, and clearly not something I reproduce on my french system. Can you make sure your pip install is uptodate ?",code starting file line declared see resolve please produced python clearly something reproduce system make sure pip install,issue,positive,positive,positive,positive,positive,positive
500720479,"```
$ ./deepspeech --model ../models/augmodel_graph.pbmm --alphabet ../models/alphabet.txt --lm ../models/lm.binary --trie ../models/trie --audio yakov.wav
TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.0-alpha.10-0-g685a0db
2019-06-11 16:24:25.216686: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 16:24:25.223578: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-06-11 16:24:25.223603: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 16:24:25.223614: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 16:24:25.223622: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
miss ever sing at
```",model alphabet audio binary use unknown unknown unknown unknown miss ever sing,issue,negative,negative,neutral,neutral,negative,negative
500719698,"@lissyx I run the same command, middle two words time is same, last word's time is 0:

```
$ ./deepspeech --model ../models/augmodel_graph.pbmm --alphabet ../models/alphabet.txt --lm ../models/lm.binary --trie ../models/trie --audio yakov.wav --json | jq

TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.0-alpha.10-0-g685a0db
2019-06-11 16:18:57.812860: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 16:18:57.819191: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-06-11 16:18:57.819213: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 16:18:57.819223: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 16:18:57.819230: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
{
  ""metadata"": {
    ""confidence"": 29.8088
  },
  ""words"": [
    {
      ""word"": ""miss"",
      ""time"": 0.2,
      ""duration"": 0.02
    },
    {
      ""word"": ""ever"",
      ""time"": 0.3,
      ""duration"": 0
    },
    {
      ""word"": ""sing"",
      ""time"": 0.3,
      ""duration"": 0
    },
    {
      ""word"": ""at"",
      ""time"": 0,
      ""duration"": 0.06
    }
  ]
}

```
",run command middle two time last word time model alphabet audio binary use unknown unknown unknown unknown confidence word miss time duration word ever time duration word sing time duration word time duration,issue,negative,negative,neutral,neutral,negative,negative
500708536,"```
$ ./deepspeech --model ../0.5.0a5/output_graph.pb --alphabet ../0.5.0a5/alphabet.txt --audio ../test-alex.en.wav 
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.11-0-g1201739
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-06-11 08:40:09.851377: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 08:40:09.856714: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 08:40:09.856748: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 08:40:09.856754: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-11 08:40:09.856901: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
she ha aylalsyalar ruraraua asuorashar
```",model alphabet audio warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown ha,issue,negative,negative,neutral,neutral,negative,negative
500708384,"Hm, it looks like I reproduce on the C client:
```
$ ./deepspeech --model ../0.5.0a5/output_graph.pb --alphabet ../0.5.0a5/alphabet.txt --audio ../test-alex.en.wav --json | jq
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.11-0-g1201739
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-06-11 08:40:37.589679: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-11 08:40:37.594863: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-06-11 08:40:37.594927: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-06-11 08:40:37.594933: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-06-11 08:40:37.595058: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
{
  ""metadata"": {
    ""confidence"": 25.0861
  },
  ""words"": [
    {
      ""word"": ""she"",
      ""time"": 0,
      ""duration"": 0.1
    },
    {
      ""word"": ""ha"",
      ""time"": 0.14,
      ""duration"": 0.04
    },
    {
      ""word"": ""aylalsyalar"",
      ""time"": 0.2,
      ""duration"": 0.04
    },
    {
      ""word"": ""ruraraua"",
      ""time"": 0.28,
      ""duration"": 0
    },
    {
      ""word"": ""asuorashar"",
      ""time"": 0.04,
      ""duration"": 0.04
    }
  ]
}
```",like reproduce client model alphabet audio warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown confidence word time duration word ha time duration word time duration word time duration word time duration,issue,positive,negative,neutral,neutral,negative,negative
500706455,">  C interface

You can use the `deepspeech` binary from `native_client.tar.xz` and the `--json` flag",interface use binary flag,issue,negative,neutral,neutral,neutral,neutral,neutral
500704889,"@beknazar Can you share your source file ? Have you reproduced that with other bindings, like NodeJS or with C interface ?",share source file like interface,issue,positive,neutral,neutral,neutral,neutral,neutral
500703821,"> > As you can see above, the timesteps, start_time is not in proper order.
> 
> Sorry, it does not seems that obvious. Can you elaborate more ?

Inference output: ""miss every thing at""
so, if look from top to bottom, character by character, the timing information (both `start_time` and `timestep`) is NOT increasing
For example, timestep is expected to be: 1, 2, 3, 4...
However, we see: 10, 13, 1, 5...",see proper order sorry obvious elaborate inference output miss every thing look top bottom character character timing information increasing example however see,issue,negative,positive,neutral,neutral,positive,positive
500703165,"@dabinat Thanks, but at the same time, changing for a specific compression is painful for a lot of reasons, including that zip performs poorly on the lib. The `native_client.tar.xz` is not really intended for end-user, so I'm not really convinced it is such a big deal a developper has to have proper tooling, and `xz` by itself is quite common.",thanks time specific compression painful lot zip poorly really intended really convinced big deal proper tooling quite common,issue,positive,negative,neutral,neutral,negative,negative
500702590,"> As you can see above, the timesteps, start_time is not in proper order.

Sorry, it does not seems that obvious. Can you elaborate more ?",see proper order sorry obvious elaborate,issue,negative,neutral,neutral,neutral,neutral,neutral
500645530,"Update: seems like it works fine with the models, which are .tar.gz, so I think it's the .xz format that's the issue here, not tar.",update like work fine think format issue tar,issue,positive,positive,positive,positive,positive,positive
500246021,"@reuben : Sorry for the confusion. The code had wrong file name mentioned. But I have verified none of the file is broken and splits are not empty. Before splitting I ran the training on the entire combined dataset. It ran fine. The difference was that the csv had data in sequential order. First dataset1, then dataset2 and then3.

But since the splits are from 3 different datasets, the WAV's are not same size. They vary randomly. But the individual datasets are works well. It's just that they are now in random sequence with different lengths. Please have a look the generated sample. 
[train_50.zip](https://github.com/mozilla/DeepSpeech/files/3269969/train_50.zip) and advice.

The same code works when I create splits on single datasets but not on combined.

I verfied the avaibility of all the files using:

```
import os
import csv

with open('/home/agarwal/german-speech-corpus/data_tuda+voxforge+mozilla/train_70.csv') as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0
    for row in csv_reader:
        print(row[0])
        exists = os.path.isfile(row[0])
        if exists:
            a=1
        else:
            print(""Does not exist:"" + row[0])
```

If shuffling is neither the issue, nor the varying wavs length, can other wav to move ahead to identify the issue?
",sorry confusion code wrong file name none file broken empty splitting ran training entire combined ran fine difference data sequential order first since different size vary randomly individual work well random sequence different please look sample advice code work create single combined import o import open row print row row else print exist row shuffling neither issue length move ahead identify issue,issue,positive,negative,negative,negative,negative,negative
500245131,"Seems like some of the data is broken. Double check that you're actually using the files you're generating, as in the snippet you posted here you generate files ending in `_10.csv` but then in the training run log you pass files ending in `_70.csv` and `_15.csv`. You're also genearting the test CSV in a completely different folder. Make sure none of the splits are empty, and that all the audio files are valid WAVs and have duration > 0.",like data broken double check actually generating snippet posted generate ending training run log pas ending also test completely different folder make sure none empty audio valid duration,issue,negative,negative,neutral,neutral,negative,negative
500144364,"lissyx i got your message loud and clear, thanks anyway",got message loud clear thanks anyway,issue,positive,positive,positive,positive,positive,positive
500136608,"> @Corey-G, i have tensorflow 1.5.0 installed already but i still get the same error message

I've already replied on what you need to share us to be able to help you. Installing TensorFlow will not help.",already still get error message already need share u able help help,issue,positive,positive,positive,positive,positive,positive
500115224,"@Corey-G, i have tensorflow 1.5.0 installed already but i still get the same error message",already still get error message,issue,negative,neutral,neutral,neutral,neutral,neutral
499941216,"> > No. I followed the steps in the ReadMe.md. And it works fine
> 
> I don't know how it's possible, we never had builds ... Because we never even had Windows.

Anyway, I will switch to Linux. I wish to work on this in the near future. Thanks ",work fine know possible never never even anyway switch wish work near future thanks,issue,positive,positive,positive,positive,positive,positive
499940086,"> No. I followed the steps in the ReadMe.md. And it works fine

I don't know how it's possible, we never had builds ... Because we never even had Windows.",work fine know possible never never even,issue,negative,positive,positive,positive,positive,positive
499937023,"> We never supported it, did you build libctc_decoder_with_kenlm on Windows yourself?

No. I followed the steps in the ReadMe.md. And it works fine",never build work fine,issue,negative,positive,positive,positive,positive,positive
499935193,">  Last four month I trained a model on windows and it's working fine

I think that even TensorFlow upstream training support on Windows is still very recent ...",last four month trained model working fine think even upstream training support still recent,issue,positive,positive,positive,positive,positive,positive
499933848,"Okay. Thanks. I am trying to train a model on a Windows machine. Last four month I trained a model on windows and it's working fine. So, why Windows is not supporting anymore?",thanks trying train model machine last four month trained model working fine supporting,issue,positive,positive,positive,positive,positive,positive
499931324,"> ERROR: ds_ctcdecoder-0.5.0a11-cp36-cp36m-windows_AMD64.whl is not a supported wheel on this platform.

We don't have ctcdecoder on Windows and we don't support training on anything else than Linux. What are you trying to achieve ?",error wheel platform support training anything else trying achieve,issue,negative,neutral,neutral,neutral,neutral,neutral
499929434,"> If you are using the 0.4.1 try going down to tensorflow version 1.5.0 which might work.

This does not make any sense.",try going version might work make sense,issue,negative,neutral,neutral,neutral,neutral,neutral
499929085,If you are using the 0.4.1 try going down to tensorflow version 1.5.0 which might work.,try going version might work,issue,negative,neutral,neutral,neutral,neutral,neutral
499849898,@monique94 We have a template that you have not filled. We can't help you. Illegal instruction means your CPU is too old.,template filled ca help illegal instruction old,issue,negative,positive,neutral,neutral,positive,positive
499639218,Pushed a commit fixing multiple concurrent streams per model instance.,commit fixing multiple concurrent per model instance,issue,negative,neutral,neutral,neutral,neutral,neutral
499441030,"The linter only runs on PRs, so it only catches problems in changes. Back when I added the linter CI I did run it over the codebase but I didn't run it on the importers.",linter back added linter run run,issue,negative,neutral,neutral,neutral,neutral,neutral
499410024,"@lissyx done, problem fixed as it seems, thanks again :+1: ",done problem fixed thanks,issue,negative,positive,positive,positive,positive,positive
499406854,I'm wondering if this should have been caught or warned about by your python linter. According to https://travis-ci.org/mozilla/DeepSpeech/builds/538276041 there was nothing spotted.,wondering caught python linter according nothing spotted,issue,negative,neutral,neutral,neutral,neutral,neutral
499405410,@Wissben Could you give a try to the small fix https://github.com/mozilla/DeepSpeech/pull/2152 ?,could give try small fix,issue,negative,negative,negative,negative,negative,negative
499400853,"> Oops, I'll check that

Thanks mate, would be nice to have the issue resolved as soon as possible :smiley: ",check thanks mate would nice issue resolved soon possible,issue,positive,positive,positive,positive,positive,positive
499388171,"As there's not a detailed description of the problem, I'm going to close the issue.",detailed description problem going close issue,issue,negative,positive,positive,positive,positive,positive
499387757,"@lissyx Looks like your ""[Computing audio hours at import ](https://github.com/mozilla/DeepSpeech/commit/17e3f284a5d2bfb018c2d574046ef52f646dcaa7)"" commit uses frames when it's not assigned to. All other frame uses seem to be protected by a check that file_size and thus frames is assigned to.",like audio import commit assigned frame seem check thus assigned,issue,positive,neutral,neutral,neutral,neutral,neutral
499324951,"Alright, I met with Apple engineers, and showed them what I have. Apparently it is not possible to convert Tensorflow Lite to CoreML, only full Tensorflow .pb files. This article ( https://venturebeat.com/2017/12/05/google-brings-core-ml-support-to-tensorflow-lite/ ) is incorrect. I can see the misunderstanding given the official Google linked in it, but no, only full Tensorflow models are convertible.

So I showed them the stack traces and steps I took to convert, and they said it just looks like a bug in the beta software. So at the engineer's request, I both filed a RADAR with Apple, and opened this issue on the converter repository: https://github.com/tf-coreml/tf-coreml/issues/309

Fingers crossed that once it's out of beta, we're in the clear!",alright met apple apparently possible convert lite full article incorrect see misunderstanding given official linked full convertible stack took convert said like bug beta engineer request radar apple issue converter repository crossed beta clear,issue,positive,positive,positive,positive,positive,positive
499271154,"Thank you @reuben . I was able to convert to Tensorflow Lite!

So I've got a Jupyter notebook going.

I install dependencies in the terminal first:
```
# pip install coremltools==3.0b1
# pip install tfcoreml==0.4.0b1
# pip install sympy
```
And that works well to bring in the new beta versions

Then I `import tfcoreml as tf_converter`

Then I use this:
```
tf_converter.convert(tf_model_path = 'path/to/tensorflowlitemodel',
                     mlmodel_path = 'path/to/export/to',
                     output_feature_names = ['logits:0', 'new_state_c:0', 'new_state_h:0'],
                     input_name_shape_dict = { 
                         'input_reshaped:0': [16, 494],
                         'previous_state_c:0': [1,2048],
                         'previous_state_h:0': [1,2048]
                     },
                     use_coreml_3 = True)
```

This starts working, but then dies, apparently because `logits:0` may not be right in the `output_feature_names`

Here is the full output. Ideas about what I might need to have in `output_feature_names`?
```
0 assert nodes deleted
0 nodes deleted
0 nodes deleted
0 nodes deleted
0 disconnected nodes deleted
0 identity nodes deleted
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-2-5b0c391d0611> in <module>()
      7                          'previous_state_h:0': [1,2048]
      8                      },
----> 9                      use_coreml_3 = True)

/anaconda2/envs/CoreMLConversion/lib/python2.7/site-packages/tfcoreml/_tf_coreml_converter.pyc in convert(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions, use_coreml_3)
    592         tf_model_path,
    593         inputs=input_name_shape_dict,
--> 594         outputs=output_feature_names)
    595     if mlmodel_path is not None:
    596       mlmodel.save(mlmodel_path)

/anaconda2/envs/CoreMLConversion/lib/python2.7/site-packages/coremltools/converters/tensorflow/_tf_converter.pyc in convert(filename, inputs, outputs, **kwargs)
     15     try:
     16         from ..nnssa.coreml.ssa_converter import ssa_convert
---> 17         mlmodelspec = ssa_convert(ssa, top_func='main', inputs=inputs, outputs=outputs)
     18     except ImportError as err:
     19         raise ImportError(""Backend converter not found! Error message:\n%s"" % err)

/anaconda2/envs/CoreMLConversion/lib/python2.7/site-packages/coremltools/converters/nnssa/coreml/ssa_converter.pyc in ssa_convert(ssa, top_func, inputs, outputs)
     59         graphviz.Source(dot_string).view(filename='/tmp/ssa_after_passes')
     60 
---> 61     converter = SSAConverter(ssa, top_func=top_func, inputs=inputs, outputs=outputs)
     62     converter.convert()
     63     mlmodel_spec = converter.get_spec()

/anaconda2/envs/CoreMLConversion/lib/python2.7/site-packages/coremltools/converters/nnssa/coreml/ssa_converter.pyc in __init__(self, net_ensemble, top_func, inputs, outputs)
    127             for name in outputs:
    128                 if name not in top_output_names:
--> 129                     raise ValueError('Output ""%s"" is not a nnssa output.' % name)
    130 
    131         top_output_features = list(zip(top_output_names, [None] * len(top_output_names)))

ValueError: Output ""logits:0"" is not a nnssa output.
```",thank able convert lite got notebook going install terminal first pip install pip install pip install work well bring new beta import use true working apparently may right full output might need assert disconnected identity recent call last module true convert none convert try import except err raise converter found error message err converter self name name raise output name list zip none output output,issue,positive,positive,positive,positive,positive,positive
499250889,Pass `--notrain --nodev --notest` to skip the training/testing phases and just do the export.,pas skip phase export,issue,negative,neutral,neutral,neutral,neutral,neutral
499250483,"@lissyx getting closer. I.used ds_ctcdecoder-0.4.1-cp27-cp27m-macosx_10_10_x86_64.whl and this seems to work.

I'm working with the 0.4.1 release. I downloaded the checkpoint and the source code for that release.

To export, I use `./DeepSpeech.py --checkpoint_dir deepspeech-0.4.1-checkpoint/ --nouse_seq_length --export_tflite --export_dir ./` 

But this fails at `def preprocess(csv_files, batch_size, numcep, numcontext, alphabet, hdf5_cache_path=None):` in the `preprocess.py` because my csv_files are blank. That comes from `FLAGS.train_cached_features_path` being blank for line 388 of `DeepSpeech.py`",getting closer work working release source code release export use alphabet blank come blank line,issue,negative,neutral,neutral,neutral,neutral,neutral
499103305,"@MatthewWaller In case it's a bug in selecting matching package, you can try others from https://tools.taskcluster.net/index/project.deepspeech.deepspeech.native_client.v0.4.1/osx-ctc",case bug matching package try,issue,negative,neutral,neutral,neutral,neutral,neutral
499100702,"> @lissyx I'm getting word that ""ds_ctcdecoder-0.4.1-cp27-cp27mu-macosx_10_10_x86_64.whl is not a supported wheel on this platform."" when trying to get DeepSpeech running. Any thoughts? Or alternatively, I could accept the already exported TFLite model and try to convert it. Would be great to get DeepSpeech up and running on this laptop though.

Can you share more verbose `pip install` steps? Can you make sure your `pip` is recent enough ?",getting word wheel platform trying get running alternatively could accept already model try convert would great get running though share verbose pip install make sure pip recent enough,issue,positive,positive,positive,positive,positive,positive
499097891,"@lissyx I'm getting word that ""ds_ctcdecoder-0.4.1-cp27-cp27mu-macosx_10_10_x86_64.whl is not a supported wheel on this platform."" when trying to get DeepSpeech running. Any thoughts? Or alternatively, I could accept the already exported TFLite model and try to convert it. Would be great to get DeepSpeech up and running on this laptop though.
",getting word wheel platform trying get running alternatively could accept already model try convert would great get running though,issue,positive,positive,positive,positive,positive,positive
499077799,@fotiDim @kdavis-mozilla I tried using their software to convert DeepSpeech here from 0.41 release and it failed (there is a new tfconverter) so maybe Apple ran their own version of Baidu’s architecture. Haven’t tried converting tflite though.,tried convert release new maybe apple ran version architecture tried converting though,issue,negative,positive,positive,positive,positive,positive
499011839,"@kdavis-mozilla Yep! Correction, was in the [Platforms State of the Union](https://developer.apple.com/videos/play/wwdc2019/103/) presentation (at 1:21:55).
![Screenshot 2019-06-05 at 11 32 17](https://user-images.githubusercontent.com/2326415/58946242-bcd53400-8785-11e9-81b9-2d0e00df7732.png)
![Screenshot 2019-06-05 at 11 32 21](https://user-images.githubusercontent.com/2326415/58946351-f443e080-8785-11e9-956b-027cae74c5a9.png)

iOS 13 also does offline speech recognition so perhaps they are using DeepSpeech under the hood now. Otherwise why put it on the screen?",yep correction state union presentation also speech recognition perhaps hood otherwise put screen,issue,negative,neutral,neutral,neutral,neutral,neutral
498967534,"""DeepSpeech"" was spotted on one of the slides in the WWDC 2019 - Platforms State of the Union. I
believe there are no blockers anymore.

On Wed, Jun 5, 2019, 8:16 AM lissyx <notifications@github.com> wrote:

> Yes, just --export_dir path/to/export --export_tflite
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/642?email_source=notifications&email_token=AARX7DZAIFL27IS4LSF7A63PY5K4XA5CNFSM4DQA5HZKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODW6WVIA#issuecomment-498952864>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AARX7D2MH73A3VFTP673T2LPY5K4XANCNFSM4DQA5HZA>
> .
>
",spotted one state union believe wed wrote yes thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
498948476,"Hi @lissyx, I've started using a beta version of the Tensorflow to CoreML Converter that was announced today. Is there a way to get ahold of the TensorFlow Lite version of the .pb file? They have a tone of new layers and such that could help.",hi beta version converter today way get lite version file tone new could help,issue,negative,positive,positive,positive,positive,positive
498228378,"> Hm, looks like something is wrong with Taskcluster, it didn't pick up the PR.

Retriggered them, it looks okay",like something wrong pick,issue,negative,negative,negative,negative,negative,negative
498151844,@mychiux413 @reuben Added a fix for this [here](df5bb310469adebdb31530367063403a5ea3c1c5). So I'd try with 0.5.0-alpha.9 or later.,added fix try later,issue,negative,neutral,neutral,neutral,neutral,neutral
498089864,"> > Now, I'm trying version `v0.5.0-alpha.7`, the memory usage seems to be more stable than `v0.4.1`, the RAM doesn't increase over time, the `--feature_cache` works too, I'm keep tracking now...
> 
> Does it holds ? Can we close the issue ?

Training ""Chinese"" dataset (~50GB) with `v0.5.0-alpha.7` still failed at testing phase.
Even I disable the oom-killer and enable the `--feature_cache`, docker runtime would still stuck in testing phase (w/o OOM Message), only `docker stop <container-id>` could shut it down.
The final solution to me is just skip the testing after early stop triggered, and everything will work fine then.",trying version memory usage stable ram increase time work keep close issue training still testing phase even disable enable docker would still stuck testing phase message docker stop could shut final solution skip testing early stop triggered everything work fine,issue,negative,positive,positive,positive,positive,positive
498030259,"@GommeAntiLegit Everywhere else, we assume people won't mix incompatible things together, I feel it's more important right now to improve the quality of the Java bindings of all points you listed above instead of trying to craft too complicated solutions to a problem that barely exists: `libdeepspeech-jni.so` should load `libdeepspeech.so`, that's it. If people improperly package stuff, that's another issue, but we likely don't want to clutter the code with that, at least for now.",everywhere else assume people wo mix incompatible together feel important right improve quality listed instead trying craft complicated problem barely load people improperly package stuff another issue likely want clutter code least,issue,negative,negative,neutral,neutral,negative,negative
498029486,"@GommeAntiLegit Honestly, I fear that's a lot of over-engineering work.",honestly fear lot work,issue,negative,positive,positive,positive,positive,positive
497976857,"Cuda support is now present and works. Due to a bug, I was loading the CPU library, so that is why my GPU was not used. I wonder why... Duh... Many errors that could come up on Cuda runtime initialization are now wrapped with exceptions to make sure errors are human-readable (No random error codes etc).
Cuda Exceptions:
```
CudaInitializationError
CudaInsufficientDriverError
CudaInvalidDeviceError
CudaInvalidValueError
CudaNoDeviceError
CudaNotPermittedError
NoCudaJNIException
UnknownComputingModeError
UnknownCudaError
```
To make that possible I had to provide access to a few native Cuda functions (not accessible from outside the `Cuda` class):
`cudaGetDevice` [See documentation](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g80861db2ce7c29b6e8055af8ae01bc78)
`cudaGetDeviceProperties`  [See documentation](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g1bf9d625a931d657e08db2b4391170f0)
That means that there are now two build configurations for the `libdeepspeech-jni.so` library: 
`CUDA` and `CPU`.
Because of that, there is now one public function that throws a `NoCudaJNIException` when invoked with a CPU `libdeepspeech-jni.so` library loaded. I don't think it is necessary to have two different versions of the bindings. Just don't use `Cuda.getDevice()` when using the CPU version.

Cuda enabled `libdeepspeech.so`s should only be loaded in combination with Cuda enabled `libdeepspeech.so`s.
If the JNI library does not match the configuration specified in the java application, a `WrongJNILibraryException` is thrown.
This error is only possible because there is a function in `libdeepspeech-jni.so` that returns an integer representing the configuration.
But that is not possible for the `libdeepspeech.so` library. You just have to assume it's the correct configuration. Every other way of checking this would only be a cheap hack (eg. checking if certain functions are defined)
May I request this kind of function to be added?

eg: `int DS_GetConfiguration()`
returns 0 for `CPU`, 1 for `CUDA`, etc.",support present work due bug loading library used wonder many could come wrapped make sure random error make possible provide access native accessible outside class see documentation see documentation two build library one public function library loaded think necessary two different use version loaded combination library match configuration application thrown error possible function integer configuration possible library assume correct configuration every way would cheap hack certain defined may request kind function added,issue,positive,positive,positive,positive,positive,positive
497970666,Looks like all tests are green. I've also verified that this does not affect WER with the 0.5.0 model.,like green also affect wer model,issue,negative,negative,negative,negative,negative,negative
497927864,"@rajdeosingh98 It looks like you are using incompatible model / deepspeech binary set. Since you have not documented any installation step nor provided the full output including lib versions, we can't help more.",like incompatible model binary set since installation step provided full output ca help,issue,positive,positive,positive,positive,positive,positive
497927795,"> Any update on this? A pre-trained model compatible for at least 0.5.0a5 or greater?

We're getting closer, it should happen soon now.",update model compatible least greater getting closer happen soon,issue,negative,positive,neutral,neutral,positive,positive
497901822,"Any update on this? A pre-trained model compatible for at least 0.5.0a5 or greater?

Thanks AWESOME Work! Thanks for sharing!",update model compatible least greater thanks awesome work thanks,issue,positive,positive,positive,positive,positive,positive
497895057,"> Which version, you are working on?
> […](#)
```
$pip3 list | grep deepspeech
deepspeech-gpu         0.4.1 
```    

",version working pip list,issue,negative,neutral,neutral,neutral,neutral,neutral
497756121,"Which version, you are working on?


On Fri, May 31, 2019, 7:29 PM cmhashim <notifications@github.com> wrote:

> @Hafsa26 <https://github.com/Hafsa26> Thanks for the info.
> Can you state the training command with all flags so that the generated lm
> are included?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/634?email_source=notifications&email_token=AKPSMJDD7J7LPKTZXLC7PVTPYEY43A5CNFSM4DPKXOE2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVL35A#issuecomment-497729012>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AKPSMJDFQQVDXLPMGV6LW4TPYEY43ANCNFSM4DPKXOEQ>
> .
>
",version working may wrote thanks state training command included reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
497729012,"@Hafsa26 Thanks for the info. 
Can you state the training command with all flags so that the generated lm are included?",thanks state training command included,issue,negative,positive,positive,positive,positive,positive
497720517,"> @cmhashim generate_trie is downloaded when one runs
> 
> ```shell
> kdavis-19htdh:DeepSpeech kdavis$ python3 util/taskcluster.py --target tc/

Thanks @kdavis-mozilla It worked. Usage: ./tc/generate_trie <alphabet> <lm_model> <trie_path>
",one shell python target thanks worked usage alphabet,issue,negative,positive,positive,positive,positive,positive
497700995,"Download the native client, compatible with your version of deep speech.
It has exe file of generate trie.
Follow the commands, Kdvais mentioned.
All the best.

On Fri, May 31, 2019 at 5:20 PM Kelly Davis <notifications@github.com>
wrote:

> @cmhashim <https://github.com/cmhashim> generate_trie is downloaded when
> one runs
>
> kdavis-19htdh:DeepSpeech kdavis$ python3 util/taskcluster.py --target tc/
> Downloading https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.master.osx/artifacts/public/native_client.tar.xz ...
> Downloading: 100%
>
> x generate_trie
> x libdeepspeech.so
> x LICENSE
> x deepspeech
> x README.mozilla
>
> See here
> <https://github.com/mozilla/deepspeech#using-the-command-line-client> for
> more details.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/634?email_source=notifications&email_token=AKPSMJHAVAUBJ5NOZLETCK3PYEJZLA5CNFSM4DPKXOE2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVCBRQ#issuecomment-497688774>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AKPSMJAXIF36OJ55AJCMS4TPYEJZLANCNFSM4DPKXOEQ>
> .
>
",native client compatible version deep speech file generate follow best may kelly wrote one python target license see reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
497688774,"@cmhashim generate_trie is downloaded when one runs
```bash
kdavis-19htdh:DeepSpeech kdavis$ python3 util/taskcluster.py --target tc/
Downloading https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.master.osx/artifacts/public/native_client.tar.xz ...
Downloading: 100%

x generate_trie
x libdeepspeech.so
x LICENSE
x deepspeech
x README.mozilla
```
See [here](https://github.com/mozilla/deepspeech#using-the-command-line-client) for more details.",one bash python target license see,issue,negative,neutral,neutral,neutral,neutral,neutral
497687267,"@Hafsa26  how to obtain trie for Urdu language. I can't use the existing one which is built for English. Am i right? @kdavis-mozilla 
Yeah i have built lm.binary using Kenlm, 
To obtain trie, i need to use command /util/generate_trie alphabet.txt lm.binary vocabulary.txt trie
I can't find generate_trie in util. 
@lissyx Can you help me",obtain language ca use one built right yeah built obtain need use command ca find help,issue,positive,positive,positive,positive,positive,positive
497613106,"No reply to my question, and the issue is obviously an alphabet issue. Closing.",reply question issue obviously alphabet issue,issue,negative,neutral,neutral,neutral,neutral,neutral
497612878,"> Now, I'm trying version `v0.5.0-alpha.7`, the memory usage seems to be more stable than `v0.4.1`, the RAM doesn't increase over time, the `--feature_cache` works too, I'm keep tracking now...

Does it holds ? Can we close the issue ?",trying version memory usage stable ram increase time work keep close issue,issue,positive,neutral,neutral,neutral,neutral,neutral
497493503,@reuben Might be worth doing a new alpha 11 with that (I can take care of it tomorrow if you want),might worth new alpha take care tomorrow want,issue,positive,positive,positive,positive,positive,positive
497486989,Technically to solve this we still need the extra step of saving the input pipeline itself in a checkpoint or with the main model checkpoint. But I'm not sure if this is still a goal. Maybe a nice to have?,technically solve still need extra step saving input pipeline main model sure still goal maybe nice,issue,positive,positive,positive,positive,positive,positive
497475573,"Please keep discussion in our Discourse forum: https://discourse.mozilla.org/c/deep-speech

The issue tracker is for bugs and feature development.",please keep discussion discourse forum issue tracker feature development,issue,negative,neutral,neutral,neutral,neutral,neutral
497443243,"Hi @andrenatal @kst5118 
I am facing the same issue. Do you have any suggested solution?",hi facing issue solution,issue,negative,neutral,neutral,neutral,neutral,neutral
497343119,"@kdavis-mozilla Since we have quantization on TFLite, do you think we should still try and have a look at this ?",since quantization think still try look,issue,negative,neutral,neutral,neutral,neutral,neutral
497342171,"> In my case, in ubuntu 18.04 was solved with the following commands:
> 1 - 'sudo apt-get install libsox-dev'
> 2 - cd /usr/lib/x86_64-linux-gnu/
> 3 - sudo ln -s libsox.so.3 libsox.so.2

Yes, we do link against `libsox.so.2` because we only build on Ubuntu 14.04. Building `libsox` statically is much more of a mess for a low improvement. It also does not looks like we can trick `ld` into accepting that `libsox.so.3` is okay for `libsox.so.2`, the number is explicitely here to notify major ABI changes ...",case following install yes link build building statically much mess low improvement also like trick number notify major,issue,positive,negative,neutral,neutral,negative,negative
497341630,"> The same for Ubuntu 16.04
> `sudo apt-get install libsox-dev`
> helped

That's not the proper solution, you don't require `-dev` package, just the library itself.",install proper solution require package library,issue,negative,neutral,neutral,neutral,neutral,neutral
497341394,"This is usually a symptom of a number in a transcription, and no answer for months now. Closing.",usually symptom number transcription answer,issue,negative,negative,negative,negative,negative,negative
497341056,"> I'm also facing the same issue. This is my test csv.

Can you ensure your alphabet properly covers your dataset ?",also facing issue test ensure alphabet properly,issue,negative,neutral,neutral,neutral,neutral,neutral
497337567,"So as discussed on IRC, we might have a way playing around with the execution plan: limiting it to nodes 1 and 2 for Mfcc, I could get expected behavior of not traversing the whole graph. Only limitation so far is that this too naive approach proves to provide improper final result. It's possible it requires more refinements.",might way around execution plan limiting could get behavior traversing whole graph limitation far naive approach provide improper final result possible,issue,negative,positive,neutral,neutral,positive,positive
497327093,"Yeah, it'd be better to release 0.5 without this regression. But if better subgraph support is coming in, say, TF 1.14, we can always revert the solution we use now to a better one.",yeah better release without regression better support coming say always revert solution use better one,issue,positive,positive,positive,positive,positive,positive
497322361,"> TF had better support for subgraphs.

It might be the case, I saw some commits from februrary toying with that. Not sure which release it is, though, and we may want to have something ready now anyway.",better support might case saw toying sure release though may want something ready anyway,issue,positive,positive,positive,positive,positive,positive
497314883,"> As speed of transcription is about the same, is there any way to verify that my GPU is used?

Yeah, TensorFlow should output some infos about GPUs. You should also get more informations using `TF_CPP_MIN_LOG_LEVEL` env variable, look into the output of it for `device:GPU`.",speed transcription way verify used yeah output also get variable look output device,issue,negative,neutral,neutral,neutral,neutral,neutral
497311046,"I'm currently working on the CUDA support for the bindings. Transcription of the audio is successful with both the CPU and CUDA versions of the DeepSpeech shared library. As speed of transcription is about the same, is there any way to verify that my GPU is used?",currently working support transcription audio successful library speed transcription way verify used,issue,positive,positive,positive,positive,positive,positive
497306904,"This could be fixed cleanly if TF had better support for subgraphs. Right now the .tflite produced by toco has all nodes in the primary subgraph, because other APIs like InterpreterBuilder don't support multiple subgraphs yet.",could fixed cleanly better support right produced toco primary like support multiple yet,issue,positive,positive,positive,positive,positive,positive
497306328,"The two graphs are not connected. This behavior is documented in `tflite::Interpreter::Invoke`, the whole graph is run in topological order.",two connected behavior whole graph run topological order,issue,negative,positive,positive,positive,positive,positive
497236024,"Sorry, I had been trying various CUDA versions all night and missed the Model error. I found another github issue relating to the 0.5 alpha models not existing. Do you have an ETA on a pre-trained 0.5 model being available? I guess you can close this issue.",sorry trying various night model error found another issue alpha eta model available guess close issue,issue,negative,negative,neutral,neutral,negative,negative
497230927,"> The Interpreter API has experimental support for subgraphs, but InterpreterBuilder doesn't support that yet, so we would have to build the graphs manually (by copy-pasting and modifying the InterpreterBuilder code), which is hacky and makes upgrading TF versions difficult, as well as relying on an experimental API.

Right. Something I was wondering but could not check in time is: is the `Mfcc` node connected to the rest of the graph ? Why TensorFlow runtime is able to flow only the `Mfcc` node if it's connected ?
Could it be a bug, either in `toco` or in our export graph, that makes the `Mfcc` node connected to the rest of the graph ?",interpreter experimental support support yet would build manually code hacky difficult well experimental right something wondering could check time node connected rest graph able flow node connected could bug either toco export graph node connected rest graph,issue,positive,positive,neutral,neutral,positive,positive
497230368,"> Because I was trying to use the model from 0.4.1, and have now found that there is no available model for 0.5 alpha so I guess we need to wait?

That's not a training error, that's a runtime inference error. Sorry, but it's unclear what you are doing.

And `libcuda.so.1` needs to be accessible.",trying use model found available model alpha guess need wait training error inference error sorry unclear need accessible,issue,negative,positive,neutral,neutral,positive,positive
497228519,"Seems the error was:
```
RuntimeError: CreateModel failed with error code 8195
```

Because I was trying to use the model from 0.4.1, and have now found that there is no available model for 0.5 alpha so I guess we need to wait?

The reason I got the above issues was I accidentally ran the docker command without the --runtime=nvidia while trying to debug why the container wasn't working via a scripted process.
I wish the nvidia images were able to give a warning when ran without the nvidia runtime to make it more obvious. A good trick is just to run inside the container:
```
$ nvidia-smi
```

If you are not using the nvidia runtime the nvidia-smi command fails.

It seems the compat cuda files are there to allow CPU machines to still run the GPU containers and for tensorflow to still load allowing the programatic detection of GPU or CPU in python and to code switch at the last minute which is handy.

I used the following versions of CUDA / CuDNN:
```
cuda_version: cuda-10-0
cudnn_version: libcudnn7.5
nvidia_repo: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.0.130-1_amd64.deb
cudnn_package: http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/libcudnn7_7.5.1.10-1+cuda10.0_amd64.deb
```

These work with the 0.5 alpha build in this docker image:
```
FROM nvidia/cuda:10.0-cudnn7-runtime-ubuntu16.04
```",error error code trying use model found available model alpha guess need wait reason got accidentally ran docker command without trying container working via process wish able give warning ran without make obvious good trick run inside container command allow still run still load detection python code switch last minute handy used following work alpha build docker image,issue,negative,positive,positive,positive,positive,positive
497226493,"> To be honest, I'm not sure how useful this feature would be compared to implementing some LM fusion technique, which would let applications use a single general language model with contextual biasing. With that, an application wouldn't be forced to do things in two steps and start a new stream with a new LM, which might not fit the intended user flow.

Yes, that's a good point. I thought perhaps one could process a stream multiple times with different LMs and choose words with the highest confidence, but on second thoughts I'm not sure how reliable that would be.

My primary interest is in the ability for my application to infer which words may be likely to occur in the transcript and supply them to DeepSpeech in advance, which then assigns those words a slightly higher priority/weight. I thought this issue might get one step closer to that goal. A fusion model certainly would. I did some digging in the code a few weeks ago with this goal in mind but I wasn't able to figure out how to do it and KenLM seems to be quite poorly documented, so if you have any suggestions I'd definitely appreciate them. 

Having said that, the steps you outlined to accomplish this issue seem pretty straightforward and I'm still happy to do it if you think it would be useful.",honest sure useful feature would fusion technique would let use single general language model contextual application would forced two start new stream new might fit intended user flow yes good point thought perhaps one could process stream multiple time different choose highest confidence second sure reliable would primary interest ability application infer may likely occur transcript supply advance slightly higher thought issue might get one step closer goal fusion model certainly would digging code ago goal mind able figure quite poorly definitely appreciate said outlined accomplish issue seem pretty straightforward still happy think would useful,issue,positive,positive,positive,positive,positive,positive
497225288,In light of #2139 the release may be delayed a bit.,light release may bit,issue,negative,positive,positive,positive,positive,positive
497044504,"@dabinat someone reached out to me expressing interest in contributing to this feature, so if you're also interested in working on #1678, I'd suggest taking that one first.",someone interest feature also interested working suggest taking one first,issue,positive,positive,positive,positive,positive,positive
497027405,"I’d be happy to look at parts 1-3, @reuben. I’ll look through the code and get back to you if I have any questions.",happy look look code get back,issue,positive,positive,positive,positive,positive,positive
497024164,"> As my exams are over, I started work on the Java bindings again. The C++ library is fully accessible in Java. Yet, there is no additional layer of abstraction to make this a little bit more pleasant to use in Java. To use the model of v0.4.1 I tried to re-export it from the checkpoint, but that just resulted in a crash. It seems as if there is some backwards incompatibility with older checkpoints. Someone claimed to have a fix for this and posted a modified version of a function of the python script, but using that function I got a model that I could load, but `speechToText` just returns an empty string no matter what. I was able to reproduce this with both my Java bindings and by calling the unchanged DeepSpeech functions from C++, so, I think that the model that was exported is corrupted. Something that supports that theory is that the v0.5.0-alpha.10 native client for Linux fails to load the model and exits with a RuntimeError. where the Trace-back points to `ds = Model(args.model, N_FEATURES, N_CONTEXT, args.alphabet, BEAM_WIDTH)`. Is there any other pre-trained model available that I can use for the newest version? Training is nearly impossible on my Laptop, so I rely on pre-trained models to properly test the bindings. It does not need to be any good at all. It should just produce some output so I can test the bindings.

For that kind of usage, we would recommend training a LDC93S1 model, it's a one-sample test set, it will make you able to work efficiently.",work library fully accessible yet additional layer abstraction make little bit pleasant use use model tried crash backwards incompatibility older someone fix posted version function python script function got model could load empty string matter able reproduce calling unchanged think model corrupted something theory native client load model model model available use version training nearly impossible rely properly test need good produce output test kind usage would recommend training model test set make able work efficiently,issue,positive,positive,positive,positive,positive,positive
496983409,"As my exams are over, I started work on the Java bindings again. The C++ library is fully accessible in Java. Yet, there is no additional layer of abstraction to make this a little bit more pleasant to use in Java. To use the model of v0.4.1 I tried to re-export it from the checkpoint, but that just resulted in a crash. It seems as if there is some backwards incompatibility with older checkpoints. Someone claimed to have a fix for this and posted a modified version of a function of the python script, but using that function I got a model that I could load, but `speechToText` just returns an empty string no matter what. I was able to reproduce this with both my Java bindings and by calling the unchanged DeepSpeech  functions from C++, so, I think that the model that was exported is corrupted. Something that supports that theory is that the v0.5.0-alpha.10 native client for Linux fails to load the model and exits with a RuntimeError. where the Trace-back points to `ds = Model(args.model, N_FEATURES, N_CONTEXT, args.alphabet, BEAM_WIDTH)`. Is there any other pre-trained model available that I can use for the newest version? Training is nearly impossible on my Laptop, so I rely on pre-trained models to properly test the bindings. It does not need to be any good at all. It should just produce some output so I can test the bindings.",work library fully accessible yet additional layer abstraction make little bit pleasant use use model tried crash backwards incompatibility older someone fix posted version function python script function got model could load empty string matter able reproduce calling unchanged think model corrupted something theory native client load model model model available use version training nearly impossible rely properly test need good produce output test,issue,negative,positive,positive,positive,positive,positive
496946521,"I'm happy to mentor anyone interested in taking this on. Also, if anyone is interested in doing only parts 1-3, I will make sure the bindings work.",happy mentor anyone interested taking also anyone interested make sure work,issue,positive,positive,positive,positive,positive,positive
496945617,"Oh, yeah, and probably the most time consuming part:

4. Make sure changed/new API is properly exposed to our bindings.",oh yeah probably time consuming part make sure properly exposed,issue,negative,positive,positive,positive,positive,positive
496944708,"Currently the decoder API returns a `std::vector` of `beam_size` `Output` structures sorted by descending probability, each struct representing a candidate transcription. Exposing this information in the API would involve the following steps:

1. Add a separate top_paths/top_n parameter to the decoder API that allows applications to specify different values for beam_width and top_paths. Right now they're tied together but it's very reasonable that one would want to decode using a beam width of say, 500, but only look at the top 5 results. This would also speed up `decoder_decode` since currently it's doing a lot of useless work computing the `Output` structures for all beams.
2. Modify or extend API to expose multiple outputs per call. For example, the `*WithMetadata` methods could be changed to return an array of `Metadata` structs rather than just one.
3. Expose the new `top_paths` parameter in the changed/new API.",currently output sorted descending probability candidate transcription information would involve following add separate parameter specify different right tied together reasonable one would want decode beam width say look top would also speed since currently lot useless work output modify extend expose multiple per call example could return array rather one expose new parameter,issue,negative,positive,neutral,neutral,positive,positive
496939253,"In any case, the rough idea I had for how to implement/expose this is by separating language model instances into their own handle, so `DS_EnableDecoderWithLM` would turn into `DS_CreateDecoderWithLM`, which would return an opaque `DecoderState*` that identifies a LM with its hyperparameters. A new `DS_FreeDecoder` function would have to be added.

This `DecoderState` pointer would then be passed into `DS_SetupStream`. The decoder-specific members of `ModelState` (scorer, beam_width, etc) would be moved into the `DecoderState` structure, and `StreamingState` would have a reference to it.",case rough idea separating language model handle would turn would return opaque new function would added pointer would scorer would structure would reference,issue,negative,positive,neutral,neutral,positive,positive
496937011,"@dabinat this bug is for using different language models, not acoustic models. The idea is that you can instantiate multiple language model instances and then for every new stream you could specify what LM to use for decoding. This would you let you implement something like this, for a voice-assistant like UI:

1. By default, use a command LM
2. A command is recognized, it requires further interaction, like saying what's the address to be displayed on a map
3. A new stream is created with an address dictation LM
4. An address is recognized
5. Rinse, repeat

To be honest, I'm not sure how useful this feature would be compared to implementing some LM fusion technique, which would let applications use a single general language model with contextual biasing. With that, an application wouldn't be forced to do things in two steps and start a new stream with a new LM, which might not fit the intended user flow.",bug different language acoustic idea multiple language model every new stream could specify use would let implement something like like default use command command interaction like saying address displayed map new stream address dictation address rinse repeat honest sure useful feature would fusion technique would let use single general language model contextual application would forced two start new stream new might fit intended user flow,issue,positive,positive,positive,positive,positive,positive
496805359,"> Review comments addressed.

You forgot to rebase, so your windows builds are busted :/",review forgot rebase busted,issue,negative,neutral,neutral,neutral,neutral,neutral
496747956,"Facing the same issue when training using common voice English dataset. 
Any suggested solution ?
",facing issue training common voice solution,issue,negative,negative,negative,negative,negative,negative
496605616,"When it's ready 😉

More seriously, I'm starting to write up the release notes. So, assuming nothing goes horribly wrong with testing 0.5.0 will be released in 2-3 weeks.",ready seriously starting write release assuming nothing go horribly wrong testing,issue,positive,negative,neutral,neutral,negative,negative
496577262,@carlfm01 Make sure your rebase against latest master,make sure rebase latest master,issue,negative,positive,positive,positive,positive,positive
496484738,"Good to hear! Closing this issue, but feel free to reopen if you think it's still applicable.",good hear issue feel free reopen think still applicable,issue,positive,positive,positive,positive,positive,positive
496484221,@lissyx The problem is fixed when I switch to swig 3.0.12.,problem fixed switch swig,issue,negative,positive,neutral,neutral,positive,positive
496468786,"@lissyx Sure, I'll have a try and report back to you",sure try report back,issue,negative,positive,positive,positive,positive,positive
496455223,"> swig -python -c++ -keyword -builtin -o impl_wrap.cpp impl.i impl.i:49: Error: Syntax error in input(1). error: command 'swig' failed with exit status 1

There's something going on with your swig setup. We can't diagnose if you don't share more informations on your system: it works with swig from ubuntu 14.04 as well as current swig 4.0.0.


> build native client from source

Any specific reason why you have to build from source ?",swig error syntax error input error command exit status something going swig setup ca diagnose share system work swig well current swig build native client source specific reason build source,issue,negative,neutral,neutral,neutral,neutral,neutral
496433820,@Hafsa26 Any updates on Urdu language model trained on 300 hr of data,language model trained data,issue,negative,neutral,neutral,neutral,neutral,neutral
496379125,"> Just to confirm and proceed with the change, both @reuben @lissyx want to link the WPF example to the master DS project client?

I guess this is what we want",confirm proceed change want link example master project client guess want,issue,negative,neutral,neutral,neutral,neutral,neutral
496378065,"@dabinat The original idea as I understood it was to start the engine with several language models and one acoustic model then be able to, at runtime, select which language model was active.

For example one might have an application that has several distinct ""command and control"" aspects, one dealing with navigation (north, south, east, west) and another dealing with questions (yes, no), another dealing with... and each ""command and control"" aspect would correspond to a language model and the ""command and control"" aspect that was active could be changed at runtime. ",original idea understood start engine several language one acoustic model able select language model active example one might application several distinct command control one dealing navigation north south east west another dealing yes another dealing command control aspect would correspond language model command control aspect active could,issue,positive,positive,positive,positive,positive,positive
496318552,"> but if it's not possible

Yes, is possible to link against the master version.

> example itself doesn't break as master changes.

That's exactly the reason for the change.



> can we at least make sure it's referring to a publicly available version in a package repository

I think this is the best solution, now that Reuben points that the `examples/vad_transcriber` dependes on `deepspeech==0.4.1` makes me think that if we link against current master people will not be able to test the example unless they use a model also trained with master.

Just to confirm and proceed with the change, both @reuben @lissyx want to link the WPF example to the master DS project client?",possible yes possible link master version example break master exactly reason change least make sure publicly available version package repository think best solution think link current master people able test example unless use model also trained master confirm proceed change want link example master project client,issue,positive,positive,positive,positive,positive,positive
496308055,"@reuben I'd be interested in taking a look at this if you can give me more information. It would be great if you could query multiple models and take the result with the highest confidence value.

Also, just to be clear, this only covers the acoustic model, not the KenLM model?",interested taking look give information would great could query multiple take result highest confidence value also clear acoustic model model,issue,positive,positive,positive,positive,positive,positive
496285011,"> my problem was that I was missing ' character in alphabet.txt

Thanks for confirming it's not an issue in our codebase then. The error is a bit unsual for this kind of mistake, though. I'm closing this :)",problem missing character thanks confirming issue error bit kind mistake though,issue,negative,positive,positive,positive,positive,positive
495996055,"> How much time is it until the release? I do have a few exams coming up in the next few days, but I might be able to do it in time, depending how much time there is left.

We don't have a strict date. If you have exams, they should be your top priority. My point was more to re-assure you that we value your feedback and contribution, and to make sure we can either wait for you if it's a quick change, or that you don't feel sending PR for nothing if we decide to go ahead and release soonish. Lots of people are waiting on 0.5.0 because we changed the model.

If the changes do no introduce any backward incompatibility, we could easily pick that in a 0.5.1 I guess.",much time release coming next day might able time depending much time left strict date top priority point value feedback contribution make sure either wait quick change feel sending nothing decide go ahead release soonish lot people waiting model introduce backward incompatibility could easily pick guess,issue,positive,positive,positive,positive,positive,positive
495982215,"> @GommeAntiLegit Since we are close to making a 0.5.0 release, I'd like to know if you have any idea how much time it might require you to make things better? This feels like a lot of changes, with risks of regressions, I'd like to avoid pressuring you into doing it ""in time"".

How much time is it until the release? I do have a few exams coming up in the next few days, but I might be able to do it in time, depending how much time there is left.


> > A rewrite of the java bindings is more than needed.
> 
> Maybe. My point is that we don't want to have to maintain Android **and** non-Android bindings ...

Yes it should be one library.

> @GommeAntiLegit Yes, well, you understand why we stated this was still **experimental** and why I told you we are not fluent in Java. We know a lot of things are not perfect, but there should not be such big leaks as you describe, @reuben carefully checked that we were properly freeing with `DS_FreeString` as well as `DS_FreeMetadata`, and using on-device did not show leaking.
> 
> But yeah, there is a lot to improve, so your feedback and fixes are more than welcome.

Yes, I overlooked this as my IDE displayed the method as unused, as the ""finalize"" method which calls the method is not used itself but invoked by the Garbage collector.",since close making release like know idea much time might require make better like lot like avoid time much time release coming next day might able time depending much time left rewrite maybe point want maintain android yes one library yes well understand stated still experimental told fluent know lot perfect big describe carefully checked properly freeing well show yeah lot improve feedback welcome yes ide displayed method unused finalize method method used garbage collector,issue,positive,positive,positive,positive,positive,positive
495979211,"@GommeAntiLegit Since we are close to making a 0.5.0 release, I'd like to know if you have any idea how much time it might require you to make things better? This feels like a lot of changes, with risks of regressions, I'd like to avoid pressuring you into doing it ""in time"".",since close making release like know idea much time might require make better like lot like avoid time,issue,positive,positive,positive,positive,positive,positive
495979112,"@GommeAntiLegit Yes, well, you understand why we stated this was still **experimental** and why I told you we are not fluent in Java. We know a lot of things are not perfect, but there should not be such big leaks as you describe, @reuben carefully checked that we were properly freeing with `DS_FreeString` as well as `DS_FreeMetadata`, and using on-device did not show leaking.

But yeah, there is a lot to improve, so your feedback and fixes are more than welcome.",yes well understand stated still experimental told fluent know lot perfect big describe carefully checked properly freeing well show yeah lot improve feedback welcome,issue,positive,positive,positive,positive,positive,positive
495978401,"> .NET tests green, I'll merge.

Could you please avoid merging when not even 1/3 of tests have ran ?",green merge could please avoid even ran,issue,negative,negative,negative,negative,negative,negative
495978215,"> A rewrite of the java bindings is more than needed.

Maybe. My point is that we don't want to have to maintain Android **and** non-Android bindings ...",rewrite maybe point want maintain android,issue,negative,neutral,neutral,neutral,neutral,neutral
495977437,"A rewrite of the java bindings is more than needed. Java naming conventions are neglected, they do not free native memory at all, so, many STT calls result in a gigantic memory leak. Sometimes native memory is allocated (not freed) that is not even used once before the pointer is overridden with an address to newly allocated memory. Loading of the native library must be more configurable or you end up with many cheap hacks in your code just to link the Cuda libraries. With more library loading options Android compatibility could be achieved with the same bindings. The bindings lack documentation or partially even parameter names (var1, var2, var3). The bindings are full of TODOS and comments stating ""We should have something better than this"". I'm currently rewriting them because I'm used to clean native libraries such as LWJGL which provide great documentation and insight what parameter types actually mean on the native side. eg usage of a long to represent a pointer or the usage of an IntBuffer to represent a call by reference integer. The bindings are using Java Arrays that are passed to JNI functions. This is not efficient at all as java array contents must be copied to be accessed natively as Java Objects do not have a static memory location and can be moved around by the Garage collector. Java NIO buffers should be used instead as they are a wrapper around native memory. The native memory is freed when the wrapper object is garbage collected. The memory of those buffers can be directly accessed by the functions of DeepSpeech without any conversion that results in a loss in performance. This is very important as audio data is often very large and copying of millions of bytes just to be freed again for nothing is not very efficient. On top of the pure bindings will also be an object oriented layer of abstraction similar to what is already present. ",rewrite naming free native memory many result gigantic memory leak sometimes native memory freed even used pointer address newly memory loading native library must end many cheap code link library loading android compatibility could lack documentation partially even parameter full something better currently used clean native provide great documentation insight parameter actually mean native side usage long represent pointer usage represent call reference integer efficient array content must copied natively static memory location around garage collector used instead wrapper around native memory native memory freed wrapper object garbage collected memory directly without conversion loss performance important audio data often large million freed nothing efficient top pure also object layer abstraction similar already present,issue,positive,positive,positive,positive,positive,positive
495953819,"Nevermind, I didn't see that the DS_PrintVersions problems were fixed.

-- reuben

> On 25 May 2019, at 18:06, lissyx <notifications@github.com> wrote:
> 
> Yeah, that sounds like a lot of what is already done in native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/, and we have nothing Android-specific there, can you make sure you're not reinventing the wheel?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",see fixed may wrote yeah like lot already done nothing make sure wheel thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
495953787,"Could this be related to the C++ name mangling we recently fixed?

-- reuben

> On 25 May 2019, at 18:06, lissyx <notifications@github.com> wrote:
> 
> Yeah, that sounds like a lot of what is already done in native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/, and we have nothing Android-specific there, can you make sure you're not reinventing the wheel?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",could related name mangling recently fixed may wrote yeah like lot already done nothing make sure wheel thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
495948504,"Yeah, that sounds like a lot of what is already done in `native_client/java/libdeepspeech/src/main/java/org/mozilla/deepspeech/libdeepspeech/`, and we have nothing Android-specific there, can you make sure you're not reinventing the wheel?",yeah like lot already done nothing make sure wheel,issue,negative,positive,positive,positive,positive,positive
495943271,"I'm currently implementing the JNI functions that call the deepspeech functions. printVersions is already tested and printed: 
""TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.10-0-g685a0db""
So, there is no reason why the other functions shouldn't work. I will make a pull request when I get it working.
It's just a lot of boiler plate code to write that does nothing but making java strings c strings or the other way around, converting java arrays to c arrays, releasing of memory etc.",currently call already tested printed reason work make pull request get working lot boiler plate code write nothing making way around converting memory,issue,negative,neutral,neutral,neutral,neutral,neutral
495940839,"> ### EDIT: THIS ISSUE IS RESOLVED. IF YOU HAVE A SIMILAR ISSUE, SCROLL DOWN TO THE ""EDIT:"" HEADER
> 
> I'm creating new Java bindings using the JNI. I have successfully linked the Java native function to the implementation in the shared library, but when DeepSpeech functions are called natively, Java reports an unknown symbol at runtime.
> 
> `/usr/lib/jvm/java-8-oracle/bin/java: symbol lookup error: /mnt/E08026E98026C63E/LIN_SSD_EXT/Development/Java/deep-speech-test/libdeepspeech-jni.so: undefined symbol: DS_PrintVersions`
> 
> The function invoked by Java is: `Java_org_mozilla_deepspeech_NativeImpl_printVersions` which then calls `DS_PrintVersions`.
> 
> `nm -D ./libdeepspeech-jni.so` prints:
> 
> ```
> 0000000000201028 B __bss_start
>                  w __cxa_finalize
>                  U DS_PrintVersions
> 0000000000201028 D _edata
> 0000000000201030 B _end
> 0000000000000624 T _fini
>                  w __gmon_start__
> 00000000000004e8 T _init
>                  w _ITM_deregisterTMCloneTable
>                  w _ITM_registerTMCloneTable
> 000000000000060a T Java_org_mozilla_deepspeech_NativeImpl_printVersions
> ```
> 
> `DS_PrintVersions` is unimplemented in this library, as I declared it as an extern function. The function is implemented in `libdeepspeech.so` from `native_client.amd64.cuda.linux.tar.xz` version `v0.5.0-alpha.10`.
> 
> `nm -D ./libdeepspeech.so` states that the following functions (and also many more) are defined:
> 
> ```
> 0000000000cd19e0 T DS_CreateModel
> 0000000000cd19b0 T DS_DestroyModel
> 0000000000ccd770 T DS_DiscardStream
> 0000000000ccd5e0 T DS_EnableDecoderWithLM
> 0000000000cd15e0 T DS_FeedAudioContent
> 0000000000cd16b0 T DS_FinishStream
> 0000000000cd1700 T DS_FinishStreamWithMetadata
> 0000000000ccd7d0 T DS_FreeMetadata
> 0000000000ccd850 T DS_FreeString
> 0000000000ccde20 T DS_IntermediateDecode
> 0000000000ccd860 T DS_PrintVersions
> 0000000000ccef50 T DS_SetupStream
> 0000000000cd16e0 T DS_SpeechToText
> 0000000000cd1730 T DS_SpeechToTextWithMetadata
> ```
> 
> I'm loading both native libraries from Java:
> 
> ```
> System.load(new File(""libdeepspeech.so"").getAbsolutePath());
> System.load(new File(""libdeepspeech-jni.so"").getAbsolutePath());
> NativeImpl.printVersions();
> ```
> 
> Execution ends with exit code 127 and this is print to the error stream: `/usr/lib/jvm/java-8-oracle/bin/java: symbol lookup error: /mnt/E08026E98026C63E/LIN_SSD_EXT/Development/Java/deep-speech-test/libdeepspeech-jni.so: undefined symbol: DS_PrintVersions`
> 
> The C++ function that is invoked here is:
> 
> ```
> JNIEXPORT void JNICALL Java_org_mozilla_deepspeech_NativeImpl_printVersions(JNIEnv *, jclass) {
>     DS_PrintVersions();
> }
> ```
> 
> I'm using CMake to build this shared library ""libdeepspeech-jni.so"".
> 
> This is my CMakeLists.txt:
> 
> ```
> cmake_minimum_required(VERSION 3.13)
> project(deepspeech-jni)
> 
> set(CMAKE_CXX_STANDARD 14)
> 
> add_library(deepspeech-jni SHARED org_mozilla_deepspeech_NativeImpl.h impl/native_impl.cpp deepspeech/deepspeech.h)
> 
> set_target_properties(deepspeech-jni PROPERTIES LINKER_LANGUAGE CXX)
> 
> link_directories(${PROJECT_SOURCE_DIR}/lib)
> link_libraries(deepspeech-jni deepspeech)
> ```
> 
> `org_mozilla_deepspeech_NativeImpl.h` contains the method prototypes that Java calls.
> 
> `NativeImp.printVersions()` is defined as
> 
> ```
> JNIEXPORT void JNICALL Java_org_mozilla_deepspeech_NativeImpl_printVersions(JNIEnv *, jclass);
> ```
> 
> The implementation of this prototype is present in `native_impl.cpp`.
> `deepspeech/deepspeech.h` contains all prototypes for extern functions that are present in `libdeepspeech.so` such as `extern void DS_PrintVersions();`
> 
> I'm also linking the shared library against the `libdeepspeech.so`.
> 
> I can't really figure out why `DS_PrintVersions` is not found.
> 
> Thank you for your help.
> ### EDIT:
> 
> The library was linked incorrectly in my CMakeLists.txt.
> This is fixed now:
> 
> ```
> cmake_minimum_required(VERSION 3.13)
> project(deepspeech-jni)
> 
> set(CMAKE_CXX_STANDARD 14)
> 
> add_library(deepspeech-jni SHARED org_mozilla_deepspeech_NativeImpl.h impl/native_impl.cpp deepspeech/deepspeech.h)
> 
> add_library(deepspeech SHARED IMPORTED)
> set_target_properties( deepspeech PROPERTIES IMPORTED_LOCATION ${CMAKE_SOURCE_DIR}/lib/libdeepspeech.so )
> 
> target_link_libraries(deepspeech-jni deepspeech)
> ```

Should we assume it means it works properly, indeed? That's awesome news!",edit issue resolved similar issue scroll edit header new successfully linked native function implementation library natively unknown symbol symbol error undefined symbol function library declared extern function function version following also many defined loading native new file new file execution exit code print error stream symbol error undefined symbol function void build library version project set method defined void implementation prototype present extern present extern void also linking library ca really figure found thank help edit library linked incorrectly fixed version project set assume work properly indeed awesome news,issue,positive,positive,positive,positive,positive,positive
495929005,"### EDIT: THIS ISSUE IS RESOLVED. IF YOU HAVE A SIMILAR ISSUE, SCROLL DOWN TO THE ""EDIT:"" HEADER


I'm creating new Java bindings using the JNI. I have successfully linked the Java native function to the implementation in the shared library, but when DeepSpeech functions are called natively, Java reports an unknown symbol at runtime.

`/usr/lib/jvm/java-8-oracle/bin/java: symbol lookup error: /mnt/E08026E98026C63E/LIN_SSD_EXT/Development/Java/deep-speech-test/libdeepspeech-jni.so: undefined symbol: DS_PrintVersions`

The function invoked by Java is: `Java_org_mozilla_deepspeech_NativeImpl_printVersions` which then calls `DS_PrintVersions`.

`nm -D ./libdeepspeech-jni.so` prints:

```
0000000000201028 B __bss_start
                 w __cxa_finalize
                 U DS_PrintVersions
0000000000201028 D _edata
0000000000201030 B _end
0000000000000624 T _fini
                 w __gmon_start__
00000000000004e8 T _init
                 w _ITM_deregisterTMCloneTable
                 w _ITM_registerTMCloneTable
000000000000060a T Java_org_mozilla_deepspeech_NativeImpl_printVersions
```
`DS_PrintVersions` is unimplemented in this library, as I declared it as an extern function. The function is implemented in `libdeepspeech.so` from `native_client.amd64.cuda.linux.tar.xz` version `v0.5.0-alpha.10`.

`nm -D ./libdeepspeech.so` states that the following functions (and also many more) are defined:

```
0000000000cd19e0 T DS_CreateModel
0000000000cd19b0 T DS_DestroyModel
0000000000ccd770 T DS_DiscardStream
0000000000ccd5e0 T DS_EnableDecoderWithLM
0000000000cd15e0 T DS_FeedAudioContent
0000000000cd16b0 T DS_FinishStream
0000000000cd1700 T DS_FinishStreamWithMetadata
0000000000ccd7d0 T DS_FreeMetadata
0000000000ccd850 T DS_FreeString
0000000000ccde20 T DS_IntermediateDecode
0000000000ccd860 T DS_PrintVersions
0000000000ccef50 T DS_SetupStream
0000000000cd16e0 T DS_SpeechToText
0000000000cd1730 T DS_SpeechToTextWithMetadata
```

I'm loading both native libraries from Java:

```
System.load(new File(""libdeepspeech.so"").getAbsolutePath());
System.load(new File(""libdeepspeech-jni.so"").getAbsolutePath());
NativeImpl.printVersions();
```

Execution ends with exit code 127 and this is print to the error stream: `/usr/lib/jvm/java-8-oracle/bin/java: symbol lookup error: /mnt/E08026E98026C63E/LIN_SSD_EXT/Development/Java/deep-speech-test/libdeepspeech-jni.so: undefined symbol: DS_PrintVersions`

The C++ function that is invoked here is:
```
JNIEXPORT void JNICALL Java_org_mozilla_deepspeech_NativeImpl_printVersions(JNIEnv *, jclass) {
    DS_PrintVersions();
}
```

I'm using CMake to build this shared library ""libdeepspeech-jni.so"".

This is my CMakeLists.txt:
```
cmake_minimum_required(VERSION 3.13)
project(deepspeech-jni)

set(CMAKE_CXX_STANDARD 14)

add_library(deepspeech-jni SHARED org_mozilla_deepspeech_NativeImpl.h impl/native_impl.cpp deepspeech/deepspeech.h)

set_target_properties(deepspeech-jni PROPERTIES LINKER_LANGUAGE CXX)

link_directories(${PROJECT_SOURCE_DIR}/lib)
link_libraries(deepspeech-jni deepspeech)
```
`org_mozilla_deepspeech_NativeImpl.h` contains the method prototypes that Java calls.

`NativeImp.printVersions()` is defined as

```
JNIEXPORT void JNICALL Java_org_mozilla_deepspeech_NativeImpl_printVersions(JNIEnv *, jclass);
```

The implementation of this prototype is present in `native_impl.cpp`.
`deepspeech/deepspeech.h` contains all prototypes for extern functions that are present in `libdeepspeech.so` such as `extern void DS_PrintVersions();`

I'm also linking the shared library against the `libdeepspeech.so`.

I can't really figure out why `DS_PrintVersions` is not found.

Thank you for your help.

### EDIT:

The library was linked incorrectly in my CMakeLists.txt.
This is fixed now:

```
cmake_minimum_required(VERSION 3.13)
project(deepspeech-jni)

set(CMAKE_CXX_STANDARD 14)

add_library(deepspeech-jni SHARED org_mozilla_deepspeech_NativeImpl.h impl/native_impl.cpp deepspeech/deepspeech.h)

add_library(deepspeech SHARED IMPORTED)
set_target_properties( deepspeech PROPERTIES IMPORTED_LOCATION ${CMAKE_SOURCE_DIR}/lib/libdeepspeech.so )

target_link_libraries(deepspeech-jni deepspeech)
```",edit issue resolved similar issue scroll edit header new successfully linked native function implementation library natively unknown symbol symbol error undefined symbol function library declared extern function function version following also many defined loading native new file new file execution exit code print error stream symbol error undefined symbol function void build library version project set method defined void implementation prototype present extern present extern void also linking library ca really figure found thank help edit library linked incorrectly fixed version project set,issue,negative,positive,positive,positive,positive,positive
495903000,"Even with dynamic models, its more accurate to provide context in the form of phrase hints at the time of inference. Because a language model with those phrase hints would apply to each inference, whereas you would rather have certain phrases apply on certain inferences during a session, not all.",even dynamic accurate provide context form phrase time inference language model phrase would apply inference whereas would rather certain apply certain session,issue,positive,positive,positive,positive,positive,positive
495796896,"> As it turns out, libdeepspeech.jni.so is also a required native library, which only works on Android because it requires libraries such as liblog.so, which are part of the Android NDK.

Yes, but it's a by-product of the Gradle build system for Android. I don't know how all of that should be handled for non-Android Java platforms.",turn also native library work android part android yes build system android know handled,issue,negative,neutral,neutral,neutral,neutral,neutral
495789582,"As it turns out, libdeepspeech.jni.so is also a required native library, which only works on Android because it requires libraries such as liblog.so, which are part of the Android NDK.",turn also native library work android part android,issue,negative,neutral,neutral,neutral,neutral,neutral
495750512,"@GommeAntiLegit So here is the gradle file for Android: https://github.com/mozilla/DeepSpeech/blob/685a0dbb894e3b7e68435cbab3aae34cdfed90ce/native_client/java/build.gradle

I guess we would need something similar for non android platforms? Though I have to admit I'm not knowledgeable a lot regarding Java world, so that's also why we have not spent too much time on that.",file android guess would need something similar non android though admit knowledgeable lot regarding world also spent much time,issue,negative,positive,neutral,neutral,positive,positive
495746143,"Well, current bindings are really targetting Android because we have no use outside of Android for Java so far. Supporting other should not be impossible, but it requires you write proper packaging as JAR I guess. We have no plans for that yet, but if you can provide PR it's welcome.

Also, it's possible there might be some stuff that is currently really only okay under Android, but nothing not fixable.

>  Or even better: Is there any way how I could build natives for Linux x64 myself?

I guess it's just a matter of building current bindings as a JAR and properly loading `libdeepspeech.so`, for which you can rely on prebuilt ones.

>  Is there anything I need to pay attention to, to also have CUDA support?

On Java side, no idea. If you pick the CUDA enabled `libdeepspeech.so` it should work. But we don't have that on macOS though.",well current really android use outside android far supporting impossible write proper jar guess yet provide welcome also possible might stuff currently really android nothing fixable even better way could build guess matter building current jar properly loading rely anything need pay attention also support side idea pick work though,issue,positive,positive,positive,positive,positive,positive
495572479,"> @Scofield666 ping ?

Sorry, can you provide the downloading link which contains libctc_decoder_with_kenlm.so again? I could't find it in the previous link you gave.",ping sorry provide link find previous link gave,issue,negative,negative,negative,negative,negative,negative
495526267,"@fabien4455 Use what suits you the best, there's enough things to fix for getting a french model, so any help is welcome.",use best enough fix getting model help welcome,issue,positive,positive,positive,positive,positive,positive
495524917,"It's sad that everybody use NVIDIA.. AMD is not a bad card but there is less community... 

I think i can find AMD docker image ! ",sad everybody use bad card le community think find docker image,issue,negative,negative,negative,negative,negative,negative
495524337,"> The first require is not that i got : Ensure you have a running setup of NVIDIA Docker
> 
> Maybe I can use Docker ROCM ( AMD ? ) Against Nvidia I'm not sure...

That's exactly why I said maybe you can contribute one for your usecase. I don't know if AMD provides easy-to-use Docker images like NVIDIA does.

At worst, have a look at the shell scripts that imports data and triggers training ...",first require got ensure running setup docker maybe use docker sure exactly said maybe contribute one know docker like worst look shell data training,issue,negative,neutral,neutral,neutral,neutral,neutral
495523928,"The first require is not that i got : Ensure you have a running setup of NVIDIA Docker

Maybe I can use Docker ROCM ( AMD ? ) Against Nvidia I'm not sure... 

Need to check that. I'll try 500 of batch size to see if it does something.. ",first require got ensure running setup docker maybe use docker sure need check try batch size see something,issue,positive,positive,positive,positive,positive,positive
495522845,"> I tried to set batch size to 80 and 120.

Well, maybe try more? You have 16GB, that leaves some room. Also, maybe Common Voice is not enough at this scale? Again, the linked dockerfile includes other datasets (but I'm still in the process of checking what needs to be curated on some of them ...)",tried set batch size well maybe try leaf room also maybe common voice enough scale linked still process need,issue,negative,negative,negative,negative,negative,negative
495522107,"I tried to set batch size to 80 and 120.

Now GPU usage can be at 80-90W but only for less than a second, then idling then one little usage at 80W then idling at 3W for 15-20 seconds...  etc.. it's a loop

My CPU is now at 90% of use all of the time",tried set batch size usage le second one little usage loop use time,issue,negative,negative,neutral,neutral,negative,negative
495518995,"@fabien4455 There are a lot of actionable items on the commonvoice-fr repo to improve the quality of the Common Voice French dataset. There's also some ready-to-use Dockerfile: https://github.com/Common-Voice/commonvoice-fr/blob/master/DeepSpeech/CONTRIBUTING.md

You could likely contribute one that allows training on AMD GPUs, for example ...",lot actionable improve quality common voice also could likely contribute one training example,issue,negative,negative,negative,negative,negative,negative
495518024,"> Come where ? On discourse ? My account has been locked by something i don't know why, i can't write or reply anything... :/

On discourse under the Common Voice French category, as well as on the commonvoice-fr repo ...
I've pinged people about your locking.",come discourse account locked something know ca write reply anything discourse common voice category well people locking,issue,negative,negative,negative,negative,negative,negative
495514675,"Come where ? On discourse ? My account has been locked by something i don't know why, i can't write or reply anything... :/ ",come discourse account locked something know ca write reply anything,issue,negative,neutral,neutral,neutral,neutral,neutral
495514035,"> We use this dataset : https://voice.mozilla.org/fr/datasets

So you should definitively come and help us, there's a lot to fix / improve on Common Voice ...",use definitively come help u lot fix improve common voice,issue,positive,negative,negative,negative,negative,negative
495512448,"> Ok sorry, it's because I'm the administrator, and i write from my devs...

Well, still, it'd be great if you shared experiments on Discourse. We also have a category for french, as well as are seeking help to train french model: https://discourse.mozilla.org/c/voice/fr https://github.com/Common-Voice/commonvoice-fr/issues",sorry administrator write well still great discourse also category well seeking help train model,issue,positive,positive,positive,positive,positive,positive
495511754,"Ok sorry, it's because I'm the administrator, and i write from my devs... 

I tell them to increase the batch size",sorry administrator write tell increase batch size,issue,negative,negative,negative,negative,negative,negative
495511152,"> I have 16 GB HBM2 RAM, how to contact you on discourse ?

First line of the issue template: `For support and discussions, please use our Discourse forums.`",ram contact discourse first line issue template support please use discourse,issue,positive,positive,positive,positive,positive,positive
495510671,"What's DATASET please ? 

I have 16 GB HBM2 RAM, how to contact you on discourse ? ",please ram contact discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
495510390,"> What number to you suggest me ? for train, dev, test, export ?

I can't suggest anything, it depends on your dataset and how much memory you have. With 11GB NVIDIA cards, depending on the dataset, I can go up to 68 or 80.

Though it's not a bug so we should continue discussion on Discourse.",number suggest train dev test export ca suggest anything much memory depending go though bug continue discussion discourse,issue,negative,positive,positive,positive,positive,positive
495509771,"What number to you suggest me ? for train, dev, test, export ? 
",number suggest train dev test export,issue,negative,neutral,neutral,neutral,neutral,neutral
495509269,"> My Batch size is 1 according to util/flags.py :

Then you should increase it, it's expected that default batch size of 1 will not use GPUs efficiently.",batch size according increase default batch size use efficiently,issue,positive,neutral,neutral,neutral,neutral,neutral
495506930,"> > Here is all what i got... I'm waiting now
> 
> I'm sorry but this is not really DeepSpeech related. Also, we don't have AMD hardware to test.
> 
> What's your dataset, batch size?

My Batch size is 1 according to util/flags.py : 

``` # Batch sizes

    f.DEFINE_integer('train_batch_size', 1, 'number of elements in a training batch')
    f.DEFINE_integer('dev_batch_size', 1, 'number of elements in a validation batch')
    f.DEFINE_integer('test_batch_size', 1, 'number of elements in a test batch')

    f.DEFINE_integer('export_batch_size', 1, 'number of elements per batch on the exported graph') 
``` ",got waiting sorry really related also hardware test batch size batch size according batch size training batch validation batch test batch per batch graph,issue,negative,negative,negative,negative,negative,negative
495284832,"> Is there a tip to ask deepspeech to use GPU 100% of time instead CPU ?

It's really not DeepSpeech here, it's TensorFlow that handles that.",tip ask use time instead really,issue,negative,positive,positive,positive,positive,positive
495280364,"> Here is all what i got... I'm waiting now

I'm sorry but this is not really DeepSpeech related. Also, we don't have AMD hardware to test. 

What's your dataset, batch size?",got waiting sorry really related also hardware test batch size,issue,negative,negative,negative,negative,negative,negative
495127849,So the GPU is used sometimes but not enough... I got peak of use for less than 1 second then idling and oh 1 second and idling again... Maybe my config is bad ? Is there a tip to ask deepspeech to use GPU 100% of time instead CPU ? ,used sometimes enough got peak use le second oh second maybe bad tip ask use time instead,issue,negative,negative,negative,negative,negative,negative
495122886,"I found something, sometimes my GPU is used but for fraction of second.. When idling my gpu is between 3 and 5W. 

When i run deepspeech, if i enter sensors command a lot of times i got sometimes 40W-50W of power reading... 

But my CPU is used like 50% everytime.. 

What is wrong ? Bad conf ? ",found something sometimes used fraction second run enter command lot time got sometimes power reading used like wrong bad,issue,negative,negative,negative,negative,negative,negative
494976301,"@ashupednekar @Sushantmkarande As suggested above, you need to investigate broken data in your dataset.",need investigate broken data,issue,negative,negative,negative,negative,negative,negative
494871793,"@rpratesh So there was indeed an issue, looks like the API will have to evolve to properly fix that. PR https://github.com/mozilla/DeepSpeech/pull/2126 includes a fix but that will not be cool for thread-safety. You should be able to trivially apply that fix to 0.4.1 and rebuild with it.",indeed issue like evolve properly fix fix cool able trivially apply fix rebuild,issue,positive,positive,positive,positive,positive,positive
494848685,@rpratesh It looks like I do reproduce it on current master with TFLite on Linux and not just Android.,like reproduce current master android,issue,negative,neutral,neutral,neutral,neutral,neutral
494823873,"> So you suggest me to use libdeepspeech through JNI instead of C++ deepspeech client ? And will v0.4.1 be good for that?

Yes, that's what i'm suggesting. If the issue is within TFLite itself, it won't help, but at least you should be at some point in a stack where foundations are better.

> I can test with current master but then that's lots of change , mainly in terms of tensorflow version. Trying to get this resolved with 0.4.1 release itself.

Sorry, but we explicitely stated on 0.4.1 release this was **experimental**.",suggest use instead client good yes suggesting issue within wo help least point stack better test current master lot change mainly version trying get resolved release sorry stated release experimental,issue,positive,positive,neutral,neutral,positive,positive
494820910,"> We only really care about `libdeepspeech` through JNI so no.

So you suggest me to use libdeepspeech through JNI instead of C++ deepspeech client ? And will v0.4.1 be good for that?

> Ok, I would really need that you re-test from Java level. I do insist, TFLite on 0.4.1 is really new, don't be surprised too much if it's not perfect. Please test with current master as well.

I can test with current master but then that's lots of change , mainly in terms of tensorflow version. Trying to get this resolved with 0.4.1 release itself.

",really care suggest use instead client good would really need level insist really new much perfect please test current master well test current master lot change mainly version trying get resolved release,issue,positive,positive,positive,positive,positive,positive
494810868,"> We are getting consistent result if we tried with .tflite model of Deepspeech with 494 n_hidden trained on LDC93S1, but with DS0.4.1 ckpts based .tflite model, it's still inconsistent with 0.4.1 native client.

Ok, I would really need that you re-test from Java level. I do insist, TFLite on 0.4.1 is really new, don't be surprised too much if it's not perfect. Please test with current master as well.",getting consistent result tried model trained based model still inconsistent native client would really need level insist really new much perfect please test current master well,issue,positive,positive,positive,positive,positive,positive
494809661,"> We are using Qualcomm Snapdragon 820 development board. Also, may I know if u tried DS041 ckpts based .tflite model on the above platforms over multiple iterations and still got the consistent results.

We only really care about `libdeepspeech` through JNI so no.

> If the C++ deepspeech code is buggy, then wouldn't be the native_client results on Linux also give inconsistent results (while I am getting consistent results using Linux native client)

Same answer, the C++ `deepspeech` is here just for some testing facilites, it's also advertised not to rely on it.",snapdragon development board also may know tried based model multiple still got consistent really care code buggy would also give inconsistent getting consistent native client answer testing also rely,issue,positive,positive,positive,positive,positive,positive
494805131,"> > **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android P
> 
> Can you share more details on the platform ? I don't recall hitting any issue on Android 8.0 and Android 9.0, respectively on Xperia XZ and Pixel 2 devices.

We are using Qualcomm Snapdragon 820 development board. Also, may I know if u tried DS041 ckpts based .tflite model on the above platforms over multiple iterations and still got the consistent results.

> @rpratesh It seems you have a different alphabet. Can you reproduce with exactly our model ? With `LDC93S1` sample ?

The alphabet.txt is the same English alphabet.txt as shared by Deepspech team.
We are getting consistent result if we tried with .tflite model of Deepspeech with 494 n_hidden trained on LDC93S1, but with DS0.4.1 ckpts based .tflite model, it's still inconsistent with 0.4.1 native client.

Hopefully 

> The C++ `deepspeech` sample is not really intended for final use, it's possible the code is buggy when running on multiple WAVs.

If the C++ deepspeech code is buggy, then wouldn't be the native_client results on Linux also give inconsistent results (while I am getting consistent results using Linux native client)

",o platform distribution android share platform recall issue android android respectively snapdragon development board also may know tried based model multiple still got consistent different alphabet reproduce exactly model sample team getting consistent result tried model trained based model still inconsistent native client hopefully sample really intended final use possible code buggy running multiple code buggy would also give inconsistent getting consistent native client,issue,positive,positive,positive,positive,positive,positive
494777201,"We also did quite some changes to the codebase regarding TFLite since v0.4.1, that may impact behavior as well, it would be great if you could try and verify this with current master on a smaller model (LDC93S1 for example).",also quite regarding since may impact behavior well would great could try verify current master smaller model example,issue,positive,positive,positive,positive,positive,positive
494775341,"> **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android P

Can you share more details on the platform ? I don't recall hitting any issue on Android 8.0 and Android 9.0, respectively on Xperia XZ and Pixel 2 devices.",o platform distribution android share platform recall issue android android respectively,issue,positive,neutral,neutral,neutral,neutral,neutral
494774881,"@rpratesh It seems you have a different alphabet. Can you reproduce with exactly our model ? With `LDC93S1` sample ?

TFLite model has been measured with a little more WER compared to pure protocolbuffer (approximately +2, from 8.5% WER to 10.2%), and the C++ `deepspeech` sample is not really intended for final use, it's possible the code is buggy when running on multiple WAVs.",different alphabet reproduce exactly model sample model measured little wer pure approximately wer sample really intended final use possible code buggy running multiple,issue,negative,positive,neutral,neutral,positive,positive
494703048,"Hey @hmitsch 
Cool now I can post on Discourse 
Thx for the help :) ",hey cool post discourse help,issue,positive,positive,positive,positive,positive,positive
494700467,"Hi @YasineNifa, the Discourse moderation tools put you ""on hold"". I have now changed that. Could you please try to post on Discourse again. Sorry for the inconveniences.

Best regards,
   Henrik
",hi discourse moderation put hold could please try post discourse sorry best,issue,positive,positive,positive,positive,positive,positive
494696343,"
unfortunately I can not post on Discourse 
Here is a message I receive : 
```
Hello,

This is an automated message from Mozilla Discourse to let you know that your account has been temporarily placed on hold as a precautionary measure.

Please do continue to browse, but you won’t be able to reply or create topics until a staff member reviews your most recent posts. We apologize for the inconvenience.

For additional guidance, refer to our community guidelines.



```",unfortunately post discourse message receive hello message discourse let know account temporarily hold precautionary measure please continue browse able reply create staff member recent apologize inconvenience additional guidance refer community,issue,negative,neutral,neutral,neutral,neutral,neutral
494694306,"> I already create an account on Discoure, but I think I have a problem with posting

Well, you should have told that earlier, we need to unblock that. Please share more details on your issue on Discourse, there's nothing I can do without more informations.",already create account think problem posting well told need unblock please share issue discourse nothing without,issue,positive,neutral,neutral,neutral,neutral,neutral
494693520,"I already create an account on Discoure, but I think I have a problem with posting
Thx for your time @lissyx ",already create account think problem posting time,issue,negative,neutral,neutral,neutral,neutral,neutral
494689642,">  Because I ask there and I think the publication is not yet approved.

Can you elaborate ? Are you having issues logging in on Discoure ? Posting ?",ask think publication yet elaborate logging posting,issue,negative,positive,positive,positive,positive,positive
494684884,"Hey !
Because I ask there and I think the publication is not yet approved.
",hey ask think publication yet,issue,negative,neutral,neutral,neutral,neutral,neutral
494643684,I rebased it into a single commit. Does anyone else need to review it or can I merge it?,single commit anyone else need review merge,issue,negative,negative,neutral,neutral,negative,negative
494540699,I think this PR is OK to take but can you remove the flags in the code to something more explicit like `space_after_every_character` or something like that?,think take remove code something explicit like something like,issue,positive,neutral,neutral,neutral,neutral,neutral
494540425,"I haven't used Mandarin Common Voice, I've been using the AISHELL corpus and am now experimenting with some other corpora as well:

https://www.openslr.org/38/
https://www.openslr.org/47/
https://www.openslr.org/62/",used mandarin common voice corpus corpus well,issue,negative,negative,negative,negative,negative,negative
494498107,"Hi @reuben, I've tried to train with the transcript without space after the characters. But the performance  are still very bad. 
Can you share the hyper parameters for the common voice dataset in Mandarin? Thanks!",hi tried train transcript without space performance still bad share hyper common voice mandarin thanks,issue,negative,negative,negative,negative,negative,negative
494282471,@YasineNifa Why do you keep posting questions on Github when we document Discourse ? Have you properly read the documentation and checked out our TensorFlow repo and branches ?,keep posting document discourse properly read documentation checked,issue,negative,neutral,neutral,neutral,neutral,neutral
494254921,"Ok, I've addressed all of the requests and also fixed some comments I forgot to update.",also fixed forgot update,issue,negative,positive,neutral,neutral,positive,positive
494050098,"Yes I own the package, but I did not check it for a long time. I am happy to disown the package or add another co-maintainer.",yes package check long time happy disown package add another,issue,positive,positive,positive,positive,positive,positive
493877589,"@YasineNifa This kind of question is exactly why we have https://discourse.mozilla.org/c/voice/fr https://github.com/Common-Voice/commonvoice-fr

Please use it.",kind question exactly please use,issue,positive,positive,positive,positive,positive,positive
493839800,"Hi @reuben, for my experiments with Chinese adding space performance is much better than no space.
Maybe you can check out this discussion!
https://discourse.mozilla.org/t/training-chinese-model/27769

And I think it's also mention in DeepSpeech2 paper the reason why need to separate character (section 3.9):
https://arxiv.org/pdf/1512.02595.pdf",hi space performance much better space maybe check discussion think also mention paper reason need separate character section,issue,negative,positive,positive,positive,positive,positive
493787553,"Per the other ticket linked just above, [`libdeepspeech`](https://aur.archlinux.org/packages/libdeepspeech/) and [`deepspeech-models`](https://aur.archlinux.org/packages/deepspeech-models/) are now in the AUR. The packages created from this discussion are useful but are out-of-date and should be bumped by their maintainer(s). @NicoHood I think you own at least one of those??",per ticket linked discussion useful maintainer think least one,issue,negative,neutral,neutral,neutral,neutral,neutral
493775726,Okay cool. What is the expected date for the stable 0.5 release.,cool date stable release,issue,positive,positive,positive,positive,positive,positive
493774427,Not for now. We'll release a compatible model with the stable 0.5 release.,release compatible model stable release,issue,negative,neutral,neutral,neutral,neutral,neutral
493773983,"Hi, 

Any alternative other than training it from scratch? ... can it be converted from the older version?  ",hi alternative training scratch converted older version,issue,negative,positive,positive,positive,positive,positive
493771514,0.5.0a8 is an alpha release and does not have a published model to go with it.,alpha release model go,issue,negative,neutral,neutral,neutral,neutral,neutral
493739142,">  But I'm sure that I had installed CUDA 10.0 and configured cuDNN 7.5 correctly ,and I had re-installed it once more , I had search for this issue ,someone said it's caused by the too high version of tensorflow ,is that the true reason?OR I just omitted some step when I installed them?

We can't tell since you don't give more context. Please stick to TensorFlow recommended versions, this is not a bug on DeepSpeech obviously.",sure correctly search issue someone said high version true reason step ca tell since give context please stick bug obviously,issue,positive,positive,positive,positive,positive,positive
493699861,"The name `epochs` is valid for current master, but not on `0.4.1`. Please use `--epoch`.",name valid current master please use epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
493652794,I refactored all of this and got it working. Just need to tidy it up a bit and then I'll post a PR.,got working need tidy bit post,issue,negative,positive,positive,positive,positive,positive
493522153,"@lissyx Ok I think I will submit these packages to the AUR then. I can open a PR to get these merged into the repo if you'd like. If nothing else, at least it would start a conversation there about what you just mentioned.",think submit open get like nothing else least would start conversation,issue,negative,negative,negative,negative,negative,negative
493520962,"Though I have to admit the idea of packaging the models as well is something we thought about, but we never pushed through ...",though admit idea well something thought never,issue,negative,neutral,neutral,neutral,neutral,neutral
493518732,"@9define I just thought it was worth mentionning there might some some existing `PKGBUILD` you may want to build on top, but honestly, I'm not ArchLinux fluent, so you should do it as you'd like :)",define thought worth might may want build top honestly fluent like,issue,positive,positive,positive,positive,positive,positive
493501769,"@lissyx Ah, I missed that issue, my apologies. It seems as though one of the main topics of that thread was a focus on creating a package that builds DS from sources, which is good for a `deepspeech-git` package (which I did find on the AUR but is very outdated). What I am suggesting is a non-`-git` package whose purpose is to install released pre-built binaries/libs, as well as a package to install the models for that release. I think this kind of package fits a pattern that other packages have created (think of any large codebases that people don't want to install a new build system just to compile).

I can hop on to that issue above if you'd like, but I'm not sure if yall want me to bump an old thread. Also, as it seems relevant, I uploaded my PKGBUILDs to pastebin, they can be found [here](https://pastebin.com/368Y8r8L) and [here](https://pastebin.com/VawqdU5j). Please let me know if you'd like to see these upstreamed to the AUR or if there's more work to be done. Thanks!",ah issue though one main thread focus package good package find outdated suggesting package whose purpose install well package install release think kind package pattern think large people want install new build system compile hop issue like sure want bump old thread also relevant found please let know like see work done thanks,issue,positive,positive,positive,positive,positive,positive
493443739,For my experiments with Mandarin I've been simply removing all spaces. Can you explain why adding a space after every character is useful for DeepSpeech?,mandarin simply removing explain space every character useful,issue,negative,positive,positive,positive,positive,positive
493352344,"Do I have to comment this part of code :
```
# Early stopping
                    if FLAGS.early_stop and len(dev_losses) >= FLAGS.es_steps:
                        mean_loss = np.mean(dev_losses[-FLAGS.es_steps:-1])
                        std_loss = np.std(dev_losses[-FLAGS.es_steps:-1])
                        dev_losses = dev_losses[-FLAGS.es_steps:]
                        log_debug('Checking for early stopping (last %d steps) validation loss: '
                                  '%f, with standard deviation: %f and mean: %f' %
                                  (FLAGS.es_steps, dev_losses[-1], std_loss, mean_loss))
                        if dev_losses[-1] > np.max(dev_losses[:-1]) or \
                           (abs(dev_losses[-1] - mean_loss) < FLAGS.es_mean_th and std_loss < FLAGS.es_std_th):
                            log_info('Early stop triggered as (for last %d steps) validation loss:'
                                     ' %f with standard deviation: %f and mean: %f' %
                                     (FLAGS.es_steps, dev_losses[-1], std_loss, mean_loss))
                            break
```",comment part code early stopping early stopping last validation loss standard deviation mean stop triggered last validation loss standard deviation mean break,issue,negative,negative,neutral,neutral,negative,negative
493346129,"> @lissyx Did #979 ""fizzle out""? I haven't seen any recent progress.

It's stalled but the bug is still open, and it documents that there were already AUR packages done, so it's part of @9define proposal, so I thought maybe it was worth mentionning to avoid re-doing work for nothing :)",fizzle seen recent progress bug still open already done part define proposal thought maybe worth avoid work nothing,issue,negative,positive,neutral,neutral,positive,positive
493337517,"@lissyx Did #979 ""fizzle out""? I haven't seen any recent progress.",fizzle seen recent progress,issue,negative,neutral,neutral,neutral,neutral,neutral
493298987,"> I met this error in ubuntu 14.04. I solved it by executed command 'sudo apt-get install libsox-dev'

Work in Ubuntu 18.04 too",met error executed command install work,issue,negative,neutral,neutral,neutral,neutral,neutral
493249570,I'd suggest the implementation of another verification like this [one](https://github.com/tensorflow/tensorflow/blob/9590c4c32dd4346ea5c35673336f5912c6072bf2/tensorflow/core/kernels/spectrogram_test.cc) in the preprocess step. ,suggest implementation another verification like one step,issue,negative,neutral,neutral,neutral,neutral,neutral
493177420,"Ok, I confirm that after removing the files that scipy's `wavfile.py` accused to be faulty, I managed to complete an epoch on commit 1a73372a0d29221184b5135a81390066ad4a574a  with TF 1.12.0 and scipy 1.2.0. Latest master with TF 1.13.0 and scipy 1.2.1 is still failing.

So I think would be a good idea to figure why `wavfile.py` is not failing on the newer version since seems some other users are also having this issue, once TF error does not point to which file is failing (well, neither `wavfile.py `does, but at least one can easily modify the script to print the filename inside the exception's catch)",confirm removing accused faulty complete epoch commit latest master still failing think would good idea figure failing version since also issue error point file failing well neither least one easily modify script print inside exception catch,issue,negative,positive,positive,positive,positive,positive
493151027,Sounds like a good idea. I downgraded tensorflow to 1.12.0 and all the warnings have disappeared! Thanks for the help!,like good idea thanks help,issue,positive,positive,positive,positive,positive,positive
493137236,"> Do you think I would encounter any significant errors that will affect my training? Meaning I must specifically download Tensorflow 1.12?

You already hit one of those. It's totally possible you may have some other in the future.",think would encounter significant affect training meaning must specifically already hit one totally possible may future,issue,negative,positive,positive,positive,positive,positive
493127747,Do you think I would encounter any significant errors that will affect my training? Meaning I must specifically download Tensorflow 1.12?,think would encounter significant affect training meaning must specifically,issue,negative,positive,positive,positive,positive,positive
493117319,"> To solve this, I searched up some forums on the problem and found that I should change line 21 in DeepSpeech.py from the line ""from tensorflow.contrib.lite.python import"" to **""from tensorflow.lite.python import tflite_convert""** . Because for some reason, tensorflow decided that they'd want to remove the .contrib part, screwing up any old code for their previous versions.

That means you downloaded 0.4.1 and are running it on TensorFlow 1.13.1 and not TensorFlow 1.12 as documented. You may experience a lot of other ""weirdness"" if you don't use proper versions.",solve problem found change line line import import reason decided want remove part screwing old code previous running may experience lot weirdness use proper,issue,negative,negative,neutral,neutral,negative,negative
493113144,"Thanks for the advice, but I actually solved the issue before I saw your suggestion!

Basically, instead of cloning the https://github.com/mozilla/DeepSpeech , I specifically cloned v0.4.1.tar.gz from https://github.com/mozilla/DeepSpeech/releases/tag/v0.4.1 so as to ensure that I was using the right version. 

At this point, tensorflow still throws the following error:

Traceback (most recent call last):
File ""DeepSpeech.py"", line 21, in 
from tensorflow.contrib.lite.python import tflite_convert
ImportError: cannot import name 'tflite_convert' 


To solve this, I searched up some forums on the problem and found that I should change line 21 in DeepSpeech.py from the line ""from tensorflow.contrib.lite.python import"" to **""from tensorflow.lite.python import tflite_convert""** . Because for some reason, tensorflow decided that they'd want to remove the .contrib part, screwing up any old code for their previous versions. 

I still need to figure out how to make the --epoch parameter work and address a few tensorflow warnings, but it trains and the binary works!

Worst warning still being thrown during training: 
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W Parameter --validation_step needs to be >0 for early stopping to work

Closing the issue. ",thanks advice actually issue saw suggestion basically instead specifically ensure right version point still following error recent call last file line import import name solve problem found change line line import import reason decided want remove part screwing old code previous still need figure make epoch parameter work address binary work worst warning still thrown training please use rate instead rate set rate parameter need early stopping work issue,issue,negative,negative,neutral,neutral,negative,negative
492951682,"1.13.1

I think some of my files might be panicking TF here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/wav/wav_io.cc#L88, even though sox says it's good.  

Am saying that because I'm now running the same dataset on an slightly older version of deepspeech, and I'm hitting this issue in the preprocessing step (which doesn't occur in the box with the newer version but same dataset):

` File ""/home/ubuntu/projects/DeepSpeech/util/preprocess.py"", line 21, in process_single_file
    features = audiofile_to_input_vector(file.wav_filename, numcep, numcontext)
  File ""/home/ubuntu/projects/DeepSpeech/util/audio.py"", line 15, in audiofile_to_input_vector
    fs, audio = wav.read(audio_filename)
  File ""/home/ubuntu/projects/tmp/venv/lib/python3.5/site-packages/scipy/io/wavfile.py"", line 246, in read
    raise ValueError(""Unexpected end of file."", filename)
ValueError: ('Unexpected end of file.', '/home/ubuntu/projects/corpora/ptbr/293456/audio.wav')`

I modified `wavfile.py` to print the offending file and am manually removing one by one to see if at least I can get one epoch finished in this box with the older version. If it succeeds, I'll then try removing the same set of files from the corpus in the box with the newer version and retry.

This [test](https://github.com/tensorflow/tensorflow/blob/9590c4c32dd4346ea5c35673336f5912c6072bf2/tensorflow/core/kernels/spectrogram_test.cc) uses the function that is failing to generate the spectrogram, so I think I'll call it with each of the wav files to determine where it's breaking if the above method doesn't work.",think might even though good saying running slightly older version issue step occur box version file line file line audio file line read raise unexpected end file end file print file manually removing one one see least get one epoch finished box older version try removing set corpus box version retry test function failing generate spectrogram think call determine breaking method work,issue,negative,positive,positive,positive,positive,positive
492944037,"This
```bash
TensorFlow version (use command below): 'v1.13.1-0-g6612da8951' 1.13.1
```
along with this
```bash
TensorFlow: v1.12.0-10-ge232881 (why is this different from my tensorflow version?)
```
makes it appear that you are mixing TensorFlow versions.

What happens if you follow the ""[Using the Python package](https://github.com/mozilla/DeepSpeech/tree/v0.4.1#using-the-python-package)"" instructions in a new virtual environment? (Note I linked to the 0.4.1 version of ""[Using the Python package](https://github.com/mozilla/DeepSpeech/tree/v0.4.1#using-the-python-package)"".)
",bash version use command along bash ge different version appear follow python package new virtual environment note linked version python package,issue,negative,positive,neutral,neutral,positive,positive
492928954,"I also tried cloning v0.4.1.tar.gz from https://github.com/mozilla/DeepSpeech/releases/tag/v0.4.1, but the same training command threw this error: 

(deepspeech-venv) richard@DESKTOP-E345TDD:/mnt/d/richardhu/tensorflow-master/tensorflow/examples/gitLFS_fordeepspeech/scratch/DeepSpeech-041$ python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir /mnt/d/Mozilla/trainings/tester_checkpoints --epochs 1 --train_files /mnt/d/UA_Data/implementation/tester/train.csv --dev_files /mnt/d/UA_Data/implementation/tester/validate.csv --test_files /mnt/d/UA_data/implementation/tester/validate2.csv --learning_rate 0.0001 --alphabet_config_path /mnt/d/richardhu/tensorflow-master/tensorflow/examples/GitLFS_forDeepSpeech/DeepSpeech/data/alphabet.txt export_dir /mnt/d/allModels/UA/tester

**Traceback (most recent call last):
  File ""DeepSpeech.py"", line 21, in <module>
    from tensorflow.contrib.lite.python import tflite_convert
ImportError: cannot import name 'tflite_convert'**",also tried training command threw error python recent call last file line module import import name,issue,negative,neutral,neutral,neutral,neutral,neutral
492925254,"I can't, sorry... Because I was using the screen visualization from my server. 
But after searching some things around the discussion area, I noticed some people were using the alphabet parameter. So I decided to use it, and guess what? My loss reduced to 50 and it's now converging.",ca sorry screen visualization server searching around discussion area people alphabet parameter decided use guess loss reduced converging,issue,negative,negative,negative,negative,negative,negative
492924597,"Thanks for the clarification!

Since the command line lists the version of DeepSpeech as ""DeepSpeech: v0.4.1-0-g0e40db6,"" can I at least safely assume that I am running the 0.4.1 version? I'm still getting some CreateModel error. 

Or by 0.4.1 code, do you mean that cloning from https://github.com/mozilla/DeepSpeech gives me an alpha version, and I need to train using another deepspeech folder that specifically says 0.4.1 ? ",thanks clarification since command line version least safely assume running version still getting error code mean alpha version need train another folder specifically,issue,negative,positive,neutral,neutral,positive,positive
492923798,Could you post your training log please?,could post training log please,issue,negative,neutral,neutral,neutral,neutral,neutral
492923636,"The 0.4.1 model is compatible with the 0.4.1 code.

The 0.4.1 model is _not_ compatible with master or the 0.5.0-alpha.[0-8] releases.",model compatible code model compatible master,issue,negative,neutral,neutral,neutral,neutral,neutral
492919071,"What version of TensorFlow are you using?

Also,  using a virtual environment for training is supported, see [README](https://github.com/mozilla/DeepSpeech#training-your-own-model), while anaconda3 is not tested.",version also virtual environment training see anaconda tested,issue,negative,neutral,neutral,neutral,neutral,neutral
492898900,"I'm also hitting this issue when using my pt-br dataset, and I can confirm the data is pretty clean and validated, but this seems to be an issue with TF.",also issue confirm data pretty clean issue,issue,positive,positive,positive,positive,positive,positive
492863319,"Actually, I think I did that -- but I'll do it again anyway. Guess I'll retrain after following this suggestion?

Do you think that would fix this particular problem?

Update: same problem",actually think anyway guess retrain following suggestion think would fix particular problem update problem,issue,negative,positive,neutral,neutral,positive,positive
492849741,"> pip install tensorflow

Try `pip3 install tensorflow` instead.",pip install try pip install instead,issue,negative,neutral,neutral,neutral,neutral,neutral
492628899,"Hello again !!
Please what are the default values of the MOZILLA deepspeech model parameters",hello please default model,issue,negative,neutral,neutral,neutral,neutral,neutral
492622805,"Since there is no further feedback and no final *solution*, would you like me to close this ticket? Or should it stay open for further investigation?",since feedback final solution would like close ticket stay open investigation,issue,positive,neutral,neutral,neutral,neutral,neutral
492472651,"> If you're trying to fine tune our release checkpoints, they're no longer compatible with master code due to a recent refactoring to remove distributed training. Try specifying an empty checkpoint_dir (and training from scratch), or downgrade the code to an older version.

So, this means that the 0.4.1 checkpoint no longer works if you want to use it for additional training? About when will there be a compatible version if so?",trying fine tune release longer compatible master code due recent remove distributed training try empty training scratch downgrade code older version longer work want use additional training compatible version,issue,negative,positive,neutral,neutral,positive,positive
492235421,"ok thank you,
Can you please provide me with a tutorial to install cuda 10.0 because every time I follow a tutorial to install cuda 10.0 I finish by installing cuda 10.1",thank please provide tutorial install every time follow tutorial install finish,issue,positive,neutral,neutral,neutral,neutral,neutral
492147874,">  I have the 9.0 version and it requires the 10.0 version . Am I right ?

Yes, we are based on TensorFlow r1.13 which depends on CUDA 10.0",version version right yes based,issue,negative,positive,positive,positive,positive,positive
492144592,"it gives me this error :` ImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory`
I think it is a problem with the CUDA version
I have the 9.0 version and it requires the 10.0 version . Am I right ?",error open object file file directory think problem version version version right,issue,negative,positive,positive,positive,positive,positive
492129215,"So you are using a newer model, trained using master, with an older command line tool, 0.4.1. They are not compatible.

You need to, as lissyx suggested above, create a new virtualenv and install the newest deep speech
```bash
pip install --upgrade deepspeech-gpu==0.5.0a8
```
in this new virtualenv.",model trained master older command line tool compatible need create new install deep speech bash pip install upgrade new,issue,negative,positive,positive,positive,positive,positive
492127443,"this cmd :  `deepspeech --version`
 give me this output : 
```
TensorFlow: v1.12.0-10-ge232881
DeepSpeech: v0.4.1-0-g0e40db6
```
And I use the master model from `https://github.com/mozilla/DeepSpeech` for training ",version give output ge use master model training,issue,negative,neutral,neutral,neutral,neutral,neutral
492125315,"Is the model you are using our 0.4.1 model? If so, it's not compatible with 0.5.0a7.

You need to train a new model using the 0.5.0a7 code or revert the install to to 0.4.1.",model model compatible need train new model code revert install,issue,negative,positive,positive,positive,positive,positive
492123523,"Thank you for the quick answer.
When I install deepspeech-gpu using this cmd : pip3 install deepspeech-gpu 
And I run the command : 

`deepspeech --model output_graph.pbmm --alphabet DeepSpeech/data/alphabet.txt --audio my_audio_file.wav`

I get this error : 
```
Not found: Op type not registered 'AudioSpectrogram' in binary running on MSI-GAMING. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
RuntimeError: CreateModel failed with error code 5
```",thank quick answer install pip install run command model alphabet audio get error found type registered binary running make sure kernel registered binary running process note loading saved graph used done graph lazily registered module first error code,issue,negative,positive,positive,positive,positive,positive
492114336,">  bash: /home/innovation/.local/bin/deepspeech: Aucun fichier ou dossier de ce type

Please verify your virtualenv setup and re-do one from scratch, it's not able to find your `deepspeech` install",bash dossier de ce type please verify setup one scratch able find install,issue,negative,positive,positive,positive,positive,positive
492109456,"Hello, 
I have the same error as @gianlucaT1989.
I do this command to change the version of the deepspeech-gpu : pip install --upgrade deepspeech-gpu==0.5.0a7 and 0.5.0a6 but it does not work in both case. It gives me this error : 
`deepspeech --model output_graph.pbmm --alphabet DeepSpeech/data/alphabet.txt  --audio my_audio_file.wav`
bash: /home/innovation/.local/bin/deepspeech: Aucun fichier ou dossier de ce type",hello error command change version pip install upgrade work case error model alphabet audio bash dossier de ce type,issue,negative,neutral,neutral,neutral,neutral,neutral
492107135,"Hello,
PLease I have the same error as Orest-Divintari and I did what Lissyx said! But it does not work for me 
It gives me this error :  bash: /home/innovation/.local/bin/deepspeech: Aucun fichier ou dossier de ce type",hello please error said work error bash dossier de ce type,issue,negative,neutral,neutral,neutral,neutral,neutral
491882259,"@lissyx Thanks for the quick reply, today I tried to reproduce the problem, that was I tried one month before, the environment changed a lot during the time.
Seems I adjusted  alphabet using all character, now seem the infer is working:

The training steps:
`
python DeepSpeech.py \
	--alphabet_config_path ./data/thchs30/alphabet.txt \
	--train_files ./data/thchs30/train.csv \
	--dev_files ./data/thchs30/train.csv \
	--test_files ./data/thchs30/train.csv \
	--train_batch_size 1 \
	--dev_batch_size 1 \
	--test_batch_size 1 \
	--n_hidden 2048 \
	--learning_rate 0.0001 \
	--checkpoint_dir /tmp/thchs30/checkpoints \
	--checkpoint_secs 60 \
	--validation_step 50 \
	--export_dir ./data/thchs30/ \
	--epoch 1000
`
Test - WER: 1.000000, CER: 52.000000, loss: 0.000852
WER: 1.000000, CER: 52.000000, loss: 0.000852
 - src: ""绿 是 阳 春 烟 景 大 块 文 章 的 底 色 四 月 的 林 峦 更 是 绿 得 鲜 活 秀 媚 诗 意 盎 然 ""
 - res: ""更是阳块烟色文底月得诗""

The infer steps:
`deepspeech \
	--model ./data/thchs30/output_graph.pbmm \
	--alphabet ./data/thchs30/alphabet.txt \
	--audio ./data/data_thchs30/train/A11_0.wav`
Running inference.
绿 是 阳 春 烟 景 大 块 文 章 的 底 色 四 月 的 林 峦 更 是 绿 得 鲜 活 秀 媚 诗 意 盎 然

no idea why the training test result is different with recognization result.

@kdavis-mozilla Actually I didn't create language model yet, just want to try DeepSpeech out first; maybe next step.
",thanks quick reply today tried reproduce problem tried one month environment lot time alphabet character seem infer working training python epoch test wer loss wer loss infer model alphabet audio running inference idea training test result different result actually create language model yet want try first maybe next step,issue,negative,positive,positive,positive,positive,positive
491682873,OH ok I got it now. Was looking for the wrong thing. Thanks!,oh got looking wrong thing thanks,issue,negative,negative,negative,negative,negative,negative
491681783,"Sorry, one last thing. Where can I find the aforementioned binary?",sorry one last thing find binary,issue,negative,negative,negative,negative,negative,negative
491681078,"@20richardh , You can download the pre-build binary for 0.5.0 a4. You can run the pre-trained model of 0.4.1 with 0.5.0 a4 binary.",binary run model binary,issue,negative,neutral,neutral,neutral,neutral,neutral
491680730,Cool! I'll try that out and see what happens then. So it's also compatible with deepspeech-0.4.1-models.tar.gz (that pre-built binary)?,cool try see also compatible binary,issue,negative,positive,positive,positive,positive,positive
491679412,Any idea when it will come out? Or will 0.4.1 be the latest one for the next few weeks?,idea come latest one next,issue,negative,positive,positive,positive,positive,positive
491612094,"Can we move this to [Discourse](https://discourse.mozilla.org/c/deep-speech) as this becoming more of a discussion than an issue, ie a bug or feature request which we reserve issues for.",move discourse becoming discussion issue ie bug feature request reserve,issue,negative,positive,positive,positive,positive,positive
491602390,"@bolt163 May I ask a question? Do you know is there any release Chinese models by  someone or company? How about your train of Chinese model, Success? Thanks.",bolt may ask question know release someone company train model success thanks,issue,positive,positive,positive,positive,positive,positive
491588987,"Lets suppose in English Transcription, if there are digits too. Would it
increase WER?




On Sun, May 12, 2019, 3:09 PM Hafsa Farooq <hafsafarooq13@gmail.com> wrote:

> Digits.
>
> On Sun, May 12, 2019, 3:07 PM Kelly Davis <notifications@github.com>
> wrote:
>
>> By ""numbers"" do you mean digits ""1,2,3,4..."" or do you mean their
>> textural form ""one, two, three, four...""?
>>
>> How are the numbers read aloud in Urdu? If I read the text ""three two
>> one"" do I say it verbally as ""one two three""? In other words how do RTL and
>> LTR interact for numbers in Urdu?
>>
>> —
>> You are receiving this because you commented.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/mozilla/DeepSpeech/issues/2077#issuecomment-491582162>,
>> or mute the thread
>> <https://github.com/notifications/unsubscribe-auth/AKPSMJEFD5IQOCTICJDDFC3PU7T5ZANCNFSM4HIYIEFA>
>> .
>>
>
",suppose transcription would increase wer sun may wrote sun may kelly wrote mean mean textural form one two three four read aloud read text three two one say verbally one two three interact reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
491582438,"@raultang Two questions:

1. What happens to inference when you **do not** use any language model?
2. How did you create your language model?",two inference use language model create language model,issue,negative,neutral,neutral,neutral,neutral,neutral
491582344,"Digits.

On Sun, May 12, 2019, 3:07 PM Kelly Davis <notifications@github.com> wrote:

> By ""numbers"" do you mean digits ""1,2,3,4..."" or do you mean their textural
> form ""one, two, three, four...""?
>
> How are the numbers read aloud in Urdu? If I read the text ""three two one""
> do I say it verbally as ""one two three""? In other words how do RTL and LTR
> interact for numbers in Urdu?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2077#issuecomment-491582162>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AKPSMJEFD5IQOCTICJDDFC3PU7T5ZANCNFSM4HIYIEFA>
> .
>
",sun may kelly wrote mean mean textural form one two three four read aloud read text three two one say verbally one two three interact reply directly view mute thread,issue,negative,negative,negative,negative,negative,negative
491582162,"By ""numbers"" do you mean digits ""1,2,3,4..."" or do you mean their textural form ""one, two, three, four...""?

How are the numbers read aloud in Urdu? If I read the text ""three two one"" do I say it verbally as ""one two three""? In other words how do RTL and LTR interact for numbers in Urdu?",mean mean textural form one two three four read aloud read text three two one say verbally one two three interact,issue,negative,negative,negative,negative,negative,negative
491580134,"@pksubbarao Any news ? CTC decoder has moved into a Python module, might be easier to get working on PPC",news python module might easier get working,issue,negative,neutral,neutral,neutral,neutral,neutral
491579621,"@raultang Can you share more details on your single-file example ? We need network parameters, training parameter to have anything conclusive. Please see what we do with `LDC93S1` sample.

We've got a lot of people able to train on Chinese, so it's unlikely that this is the problem here. I do insist again, examples shown when we finish training and **the worst ones**. It's hard to have any definitive conclusion when the only informations we have here are incomplete:
 - end of training with empty strings
 - lack of matching model runtime test on some files
 - lack of output allowing us to identify what release / build this is",share example need network training parameter anything conclusive please see sample got lot people able train unlikely problem insist shown finish training worst hard definitive conclusion incomplete end training empty lack matching model test lack output u identify release build,issue,negative,negative,negative,negative,negative,negative
491579335,">  Seems there are more people have this issue:

Maybe, but none of my questions above have been answered, it's hard to help in this context.",people issue maybe none hard help context,issue,negative,negative,negative,negative,negative,negative
491574198,"@lissyx Seems there are more people have this issue:
https://discourse.mozilla.org/t/training-chinese-model/27769/25

I tried with one wav file from data_thchs30 data set, but infer nothing.
```
wav_filename,wav_filesize,transcript
/data/data_thchs30/train/A11_0.wav,249644,绿 是 阳 春 烟 景 大 块 文 章 的 底 色 四 月 的 林 峦 更 是 绿 得 鲜 活 秀 媚 诗 意 盎 然
```
",people issue tried one file data set infer nothing transcript,issue,negative,neutral,neutral,neutral,neutral,neutral
491571354,"@kdavis, and what about if numbers are in data, would It increase WER? 
I am working on Urdu language which is RTL, while, numers are LTR. 
I checked by adding numbers in data, training goes fine but I am specifically asking for effect on WER? ",data would increase wer working language checked data training go fine specifically effect wer,issue,negative,positive,positive,positive,positive,positive
491481001,"So, I had to uninstall progressbar, it looks like a random bug... now it's working like always.",like random bug working like always,issue,positive,negative,negative,negative,negative,negative
491444161,"Currently, the decoder we use (`native_client/ctcdecode`) exposes a batch API that takes a probabilities matrix and returns a list of decoded strings. The implementation is a beam search loop over all the time steps in the input probabilities. To implement a streaming decoder, one would have to refactor the decoder API from a single `ctc_beam_search_decoder()` call into a state-struct style API which is split into three stages: `decoder_init`, `decoder_next`, and `decoder_finish` or `decoder_decode`. At the start, you set the state for the decoder with the `decoder_init()` call:

https://github.com/mozilla/DeepSpeech/blob/a4b35d2f2487de69ce5ef2926fcd26e2698c7d69/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L26-L46

Which returns a decoder state struct which contains all of the variables needed for the main loop. Then eventually you feed a batch of probabilities into the decoder with a `decoder_next()` step which performs N steps of the main loop over time:

https://github.com/mozilla/DeepSpeech/blob/a4b35d2f2487de69ce5ef2926fcd26e2698c7d69/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L48-L121

And then finally you'd have a `decoder_finish()` or `decoder_decode()` step that does the final score adjustments if necessary and returns a list of decoder strings.

https://github.com/mozilla/DeepSpeech/blob/a4b35d2f2487de69ce5ef2926fcd26e2698c7d69/native_client/ctcdecode/ctc_beam_search_decoder.cpp#L124-L175

This step could then be called from `DS_IntermediateDecode` to quickly get the current decoding of the stream without having to always start from scratch. With this API in place, after a batch is computed with the acoustic model we can immediately feed the probabilities into the `decoder_next()` step. I'm fairly certain there are more performance gains to be had in the decoder, but this would be an amazing first step.",currently use batch matrix list implementation beam search loop time input implement streaming one would single call style split three start set state call state main loop eventually feed batch step main loop time finally step final score necessary list step could quickly get current stream without always start scratch place batch acoustic model immediately feed step fairly certain performance gain would amazing first step,issue,positive,positive,positive,positive,positive,positive
491362692,"Ok, thank you. I'll check back in when you have the checkpoints and official models for 0.5.0",thank check back official,issue,negative,neutral,neutral,neutral,neutral,neutral
491358716,"Why do you keep on building ? Use prebuilt binaries, those are tested.",keep building use tested,issue,negative,neutral,neutral,neutral,neutral,neutral
491358394,"And after using pip to install tensorflow, i just need to complete the `Preparation` and `Building` part in [https://github.com/mozilla/DeepSpeech/tree/v0.3.0/native_client#building](url) to generate the libs, after which i can use `tf.load_op_library` in this tensorflow env?",pip install need complete preparation building part generate use,issue,negative,positive,neutral,neutral,positive,positive
491356885,"> So do you mean that I just need to use `pip3 install tensorflow` to install tensorflow instead of install from source?

Yes. Make sure you setup a virtualenv, to avoid any clash with Conda, and `pip install tensorflow-gpu` ...",mean need use pip install install instead install source yes make sure setup avoid clash pip install,issue,negative,positive,neutral,neutral,positive,positive
491355102,"> > so there is no need to build pip package?
> 
> Yes, no need to build pip package, only follow what we document. But there's no reason you need to rebuild, it should work with pypi's tensorflow.

Emm, I'm sorry that i'm new about this. So do you mean that I just need to use `pip3 install tensorflow` to install tensorflow instead of install from source?",need build pip package yes need build pip package follow document reason need rebuild work sorry new mean need use pip install install instead install source,issue,negative,negative,negative,negative,negative,negative
491353266,"> How would be able to download the latest deepspeech-gpu for TensorFlow r.1.13, CUDA 10.0, and CuDNN v7.4.1?

Just `pip install --upgrade deepspeech-gpu==0.5.0a7`

But we don't yet have checkpoints nor official models for 0.5.0.",would able latest pip install upgrade yet official,issue,negative,positive,positive,positive,positive,positive
491352846,"> so there is no need to build pip package?

Yes, no need to build pip package, only follow what we document. But there's no reason you need to rebuild, it should work with pypi's tensorflow.",need build pip package yes need build pip package follow document reason need rebuild work,issue,negative,neutral,neutral,neutral,neutral,neutral
491352008,"> Could you try outside of conda and use official builds from PyPi ? This is what we test against.

Fine, and questions about installing tensorflow from source on [https://www.tensorflow.org/install/install_sources](url): following these instructions, does it mean I have installed tensorflow when I have done `./configure` command, so there is no need to build pip package?",could try outside use official test fine source following mean done command need build pip package,issue,negative,positive,neutral,neutral,positive,positive
491348880,Could you try outside of conda and use official builds from PyPi ? This is what we test against.,could try outside use official test,issue,negative,neutral,neutral,neutral,neutral,neutral
491348671,"> This is mismatching between your TensorFlow and what we built against. How was installed your TensorFlow ?
> 
> I'm not sure `tf.load_op_library(""libdeepspeech.so"")` is a conclusive test, since it's not implementing anything from TensorFlow framework.

I directly used `conda install tensorflow-gpu=1.11` to install the tensorflow, just for some testing. So do you mean that I have to install tensorflow from source and then try to load this library? 
",built sure conclusive test since anything framework directly used install install testing mean install source try load library,issue,negative,positive,neutral,neutral,positive,positive
491343906,"Thank you for the quick response. Oh that makes sense, I read the master documentation and not the 0.4.1 documentation. How would be able to download the latest deepspeech-gpu for TensorFlow r.1.13, CUDA 10.0, and CuDNN v7.4.1?

Note: my GTX Ti 1080 will not let me use CUDA 9.0.  

Would the call be ``` pip3 install deepspeech-gpu-0.4.2```? Or should I clone the latest deepspeech repo, train the model locally, and then run it so I can use CUDA 10.0 and CuDNN 7.4.1? 

I apologize if my questions are stupid. I am new to running models on the GPU and implementing CUDA ",thank quick response oh sense read master documentation documentation would able latest note ti let use would call pip install clone latest train model locally run use apologize stupid new running,issue,negative,positive,positive,positive,positive,positive
491340261,I'm starting to suspect discrepancy regarding `_GLIBCXX_USE_CXX11_ABI` ...,starting suspect discrepancy regarding,issue,negative,neutral,neutral,neutral,neutral,neutral
491339116,"This is mismatching between your TensorFlow and what we built against. How was installed your TensorFlow ?

I'm not sure `tf.load_op_library(""libdeepspeech.so"")` is a conclusive test, since it's not implementing anything from TensorFlow framework.",built sure conclusive test since anything framework,issue,negative,positive,positive,positive,positive,positive
491332919,@est31 @asticode You may want to check if your bindings needs changes :-),may want check need,issue,negative,neutral,neutral,neutral,neutral,neutral
491261477,"> Looks good to me. What's up with the ""Epic"" label here?

It's urgent. :)",good epic label urgent,issue,positive,positive,positive,positive,positive,positive
491150994,"The call...
```bash
pip3 install deepspeech-gpu
```
installs Deep Speech 0.4.1.

The [0.4.1 documentation](https://github.com/mozilla/DeepSpeech/tree/v0.4.1#cuda-dependency), not the [master documentation](https://github.com/mozilla/deepspeech#cuda-dependency), indicates the following CUDA dependency
> Currently with TensorFlow r1.12 it depends on CUDA 9.0 and CuDNN v7.2.",call bash pip install deep speech documentation master documentation following dependency currently,issue,negative,neutral,neutral,neutral,neutral,neutral
490816226,"Wow that was easy

I did the upgrade and it worked 

Thank you very much",wow easy upgrade worked thank much,issue,positive,positive,positive,positive,positive,positive
490815444,"> I installed deep speech using
> 
> `pip install deepspeech`
> 
> I just ran
> 
> `deepspeech --version`
> 
> and the output is this :
> 
> TensorFlow: v1.12.0-10-ge232881c5a
> DeepSpeech: v0.4.1-0-g0e40db6

We need to know which branch of the DeepSpeech repo you used to perform training. It's very likely given the error that it was master, so your model is incompatible with 0.4.1 binaries.

Please `pip install --upgrade deepspeech==0.5.0a7` then.",deep speech pip install ran version output need know branch used perform training likely given error master model incompatible please pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
490812844,"I installed deep speech using 

`pip install deepspeech`

I just ran 

`deepspeech --version`

and the output is this : 

TensorFlow: v1.12.0-10-ge232881c5a
DeepSpeech: v0.4.1-0-g0e40db6",deep speech pip install ran version output,issue,negative,neutral,neutral,neutral,neutral,neutral
490811321,Did you train the model with master or with the 0.4.1 version of Deep Speech?,train model master version deep speech,issue,negative,neutral,neutral,neutral,neutral,neutral
490744737,Ok thank you for the quick response. Can't run cuda9 on my RTX card so I'll have to look for another speech2text model. Closing for now and will revisit if/when there's 0.5 models,thank quick response ca run card look another model revisit,issue,negative,positive,positive,positive,positive,positive
490741987,"Did you un-install deepspeech-gpu before installing deepspeech 0.5.0A7 over it?

Also, there is no model released for any 0.5.0A* version so using the 0.4.1 model, which I assume output_graph.pbmm is, with 0.5.0A7 will not work.

I'd suggest using the 0.4.1 deepspeech-gpu and referring to the [0.4.1. documents](https://github.com/mozilla/DeepSpeech/tree/v0.4.1). ",also model version model assume work suggest,issue,negative,neutral,neutral,neutral,neutral,neutral
490738628,@Scofield666 As we've solved your original problem and issues are to be used for bugs/feature requests. Could you move this discussion to [discourse](https://discourse.mozilla.org/c/deep-speech). Thanks.,original problem used could move discussion discourse thanks,issue,negative,positive,positive,positive,positive,positive
490722321,"When I am trying to use load_op_library function to load this library like `a = tf.load_op_library(""/usr/whz/generative_audio_attack/DeepSpeech/native_client/libctc_decoder_with_kenlm.so"")` in python console, with tensorflow 12.0. It went wrong

```
Traceback (most recent call last):
  File ""/home/ww/anaconda3/envs/speech/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3267, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-8-a4a3e007e0ff>"", line 1, in <module>
    a = tf.load_op_library(""/usr/whz/generative_audio_attack/DeepSpeech/native_client/libctc_decoder_with_kenlm.so"")
  File ""/home/ww/anaconda3/envs/speech/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 60, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/whz/generative_audio_attack/DeepSpeech/native_client/libctc_decoder_with_kenlm.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv
```
What does this mean? I'm sure that the libctc_decoder_with_kenlm.so has been moved to the right path, but it still failed to load. Why?",trying use function load library like python console went wrong recent call last file line file line module file line undefined symbol mean sure right path still load,issue,negative,negative,neutral,neutral,negative,negative
490562872,This is unrealted. Please follow the doc if you have `libctc_decoder_with_kenlm.so` in a non-standard path and set the `--decoder_path` flag at training time ...,please follow doc path set flag training time,issue,negative,neutral,neutral,neutral,neutral,neutral
490557213,"Thanks for your reply. 
I am still confused with an issue when I saw problems discussed on [https://github.com/mozilla/DeepSpeech/issues/1418](url). This issue makes me wonder is there any need for me to configure the LD_LIBRARY_PATH or ld.so.conf so that I can moved libctc_decoder_with_kenlm.so anywhere for other use?",thanks reply still confused issue saw issue wonder need configure anywhere use,issue,negative,negative,neutral,neutral,negative,negative
490407468,">  I follow the instructions in [https://www.tensorflow.org/install/source](url) and I just stop after `./configure` without compiling pip packages.

Nope, that's what you should be doing, no need to build pip package.

> Does this mean `make deepspeech` successfully?

If you don't have any other output, and your have a `deepspeech` binary in your folder, then yes.",follow stop without pip nope need build pip package mean make successfully output binary folder yes,issue,positive,positive,positive,positive,positive,positive
490402343,"```
(deepspeechv3) ww@Jenny's Group /usr/whz/generative_audio_attack/DeepSpeech/native_client $ make deepspeech 
c++ -std=c++11 -o deepspeech   `pkg-config --cflags sox` client.cc  -Wl,--no-as-needed -Wl,-rpath,\$ORIGIN -L/usr/whz/generative_audio_attack/tensorflow/bazel-bin/native_client  -ldeepspeech  `pkg-config --libs sox
```
Does this mean `make deepspeech` successfully?",jenny group make origin mean make successfully,issue,negative,positive,positive,positive,positive,positive
490392626,Now I think something might go wrong with the tensorflow configuration. I follow the instructions in [https://www.tensorflow.org/install/source](url) and I just stop after `./configure` without compiling pip packages. So I wonder if it is necessary to build the pip packages until the `Success: TensorFlow is now installed.` ,think something might go wrong configuration follow stop without pip wonder necessary build pip success,issue,negative,negative,neutral,neutral,negative,negative
490388665,"> What if you rm your tensorflow checkout, check 1.11 out again, and start fresh to make sure there are no artifacts from your old build with the wrong version of tensorflow?

You may also want to ensure the bazel cache is properly cleaned.",check start fresh make sure old build wrong version may also want ensure cache properly,issue,positive,positive,neutral,neutral,positive,positive
490387019,"Maybe just use the nuclear option:
```
$ strace -ff python -c ""import tensorflow as tf; module = tf.load_op_library(""../DeepSpeech/native_client/libctc_decoder_with_kenlm.so"")"" 2>&1 | grep ""libctc_decoder_with_kenlm""
```

And then look where it tries to load the library?",maybe use nuclear option python import module look load library,issue,negative,neutral,neutral,neutral,neutral,neutral
490385427,"> The error above occurs when `make deepspeech`.

Yes but the error indicates it's a a linking problem. There are undefined symbols.

> The main problem I am confused with now is that I still cannot use function `tf.load_library` to load `libctc_decoder_with_kenlm.so` even after I moved the generated library to the current native-client folder. 

Before we try something off the beaten path I'd suggest getting the standard case of `make deepspeech` working.

What if you rm your tensorflow checkout, check 1.11 out again, and start fresh to make sure there are no artifacts from your old build with the wrong version of tensorflow?",error make yes error linking problem undefined main problem confused still use function load even library current folder try something beaten path suggest getting standard case make working check start fresh make sure old build wrong version,issue,negative,positive,neutral,neutral,positive,positive
490383405,"The error above occurs when `make deepspeech`. 
The main problem I am confused with now is that I still cannot use function `tf.load_library` to load `libctc_decoder_with_kenlm.so` even after I moved the generated library to the current native-client folder. The error is 
```
ERROR: The decoder library file does not exist. Make sure you have downloaded or built the native client binaries and pass the appropriate path to the binaries in the --decoder_library_path parameter.
```
According to the error info, it looks like it cannot load the `native-client` folder, but it actually exists with generated binaries in it. 
I don't know whether the generated library is right or not, or there is something wrong with the path. Really confusing.",error make main problem confused still use function load even library current folder error error library file exist make sure built native client pas appropriate path parameter according error like load folder actually know whether library right something wrong path really,issue,negative,positive,neutral,neutral,positive,positive
490371392,Makefile error? The above [problem](https://github.com/mozilla/DeepSpeech/issues/2101#issuecomment-490309780) is a linking error. Is there some other problem?,error problem linking error problem,issue,negative,neutral,neutral,neutral,neutral,neutral
490356493,"> What version of gcc are you using?

version 5.4.0 
```
ww@Jenny's Group /usr/xjc/tensorflow/bazel-bin/native_client $ gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/local/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper
Target: x86_64-unknown-linux-gnu
Configured with: ../gcc-5.4.0/configure --enable-checking=release --enable-languages=c,c++ --disable-multilib
Thread model: posix
gcc version 5.4.0 (GCC) 
```

Is this related to the makefile error?",version version jenny group spec target thread model version related error,issue,negative,neutral,neutral,neutral,neutral,neutral
490309780,"> Looks like you do have a newer version of tensorflow. Try...
> 
> ```shell
> kdavis-19htdh:mozilla kdavis$ git clone https://github.com/mozilla/tensorflow.git
> Cloning into 'tensorflow'...
> remote: Enumerating objects: 4, done.
> remote: Counting objects: 100% (4/4), done.
> remote: Compressing objects: 100% (4/4), done.
> remote: Total 549136 (delta 0), reused 1 (delta 0), pack-reused 549132
> Receiving objects: 100% (549136/549136), 322.00 MiB | 263.00 KiB/s, done.
> Resolving deltas: 100% (443183/443183), done.
> Checking out files: 100% (16472/16472), done.
> kdavis-19htdh:mozilla kdavis$ cd tensorflow/
> kdavis-19htdh:tensorflow kdavis$ git checkout r1.11
> Checking out files: 100% (12549/12549), done.
> Branch 'r1.11' set up to track remote branch 'r1.11' from 'origin'.
> Switched to a new branch 'r1.11'
> ```

Yes, I have checked out the right version and successfully generating the binaries using the command
```
bazel build -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //native_client:libctc_decoder_with_kenlm.so
bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie
```
Then My file structure looks like this, implying that I have generated libctc_decoder_with_kenlm.so successfully.
```
ww@Jenny's Group /usr/whz/generative_audio_attack/tensorflow/bazel-bin/native_client $ tree -L 1
.
├── generate_trie
├── generate_trie-2.params
├── generate_trie.runfiles
├── generate_trie.runfiles_manifest
├── libctc_decoder_with_kenlm.so
├── libctc_decoder_with_kenlm.so-2.params
├── libctc_decoder_with_kenlm.so.runfiles
├── libctc_decoder_with_kenlm.so.runfiles_manifest
├── libdeepspeech.so
├── libdeepspeech.so-2.params
├── libdeepspeech.so.runfiles
├── libdeepspeech.so.runfiles_manifest
└── _objs

```
So here my problem is when I generated libctc_decoder_with_kenlm.so, can I directly copy this to the path for calling it using the code like `module = tf.load_op_library(""../DeepSpeech/native_client/libctc_decoder_with_kenlm.so"")`?

And after 
```
export TFDIR=/usr/whz/generative_audio_attack/tensorflow/
cd ../DeepSpeech/native_client
make deepspeech
```
Something went wrong like
```
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::shape_inference::InferenceContext::Multiply(tensorflow::shape_inference::DimensionHandle, tensorflow::shape_inference::DimensionOrConstant, tensorflow::shape_inference::DimensionHandle*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::monitoring::CollectionRegistry::Register(tensorflow::monitoring::AbstractMetricDef const*, std::function<void (tensorflow::monitoring::MetricCollectorGetter)> const&)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::CancellationManager::~CancellationManager()'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::shape_inference::InferenceContext::FullyDefined(tensorflow::shape_inference::ShapeHandle)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::thread::ThreadPool::~ThreadPool()'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::OpKernelContext::mutable_input(int, bool)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::Tensor::AsProtoField(tensorflow::TensorProto*) const'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::SessionOptions::SessionOptions()'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::Env::NewReadOnlyMemoryRegionFromFile(std::string const&, std::unique_ptr<tensorflow::ReadOnlyMemoryRegion, std::default_delete<tensorflow::ReadOnlyMemoryRegion> >*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `google::protobuf::internal::LogMessage::operator<<(char const*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::ResourceMgr::DoLookup(std::string const&, std::type_index, std::string const&, tensorflow::ResourceBase**) const'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::OpDefBuilder::SetShapeFn(tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*))'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::GraphRunner::GraphRunner(tensorflow::Env*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::OpInfo_TensorProperties::~OpInfo_TensorProperties()'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::FunctionLibraryDefinition::ReplaceFunction(std::string const&, tensorflow::FunctionDef const&)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `vtable for tensorflow::DeviceResolverLocal'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::io::internal::JoinPathImpl(std::initializer_list<absl::string_view>)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::FormatFromString(std::string const&, tensorflow::TensorFormat*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::CallableOptions::CallableOptions()'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::FunctionDef* google::protobuf::Arena::CreateMaybeMessage<tensorflow::FunctionDef>(google::protobuf::Arena*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `stream_executor::Stream::ThenPoolForward(stream_executor::dnn::PoolingDescriptor const&, stream_executor::dnn::BatchDescriptor const&, stream_executor::DeviceMemory<float> const&, stream_executor::dnn::BatchDescriptor const&, stream_executor::DeviceMemory<float>*, stream_executor::ScratchAllocator*)'
/usr/whz/generative_audio_attack/tensorflow//bazel-bin/native_client/libdeepspeech.so: undefined reference to `tensorflow::Rendezvous::Recv(tensorflow::Rendezvous::ParsedKey const&, tensorflow::Rendezvous::Args const&, tensorflow::Tensor*, bool*, long long)'
collect2: error: ld returned 1 exit status
make: *** [deepspeech] Error 1
```

I don't know how to solve it, any help? Thanks",like version try shell git clone remote done remote counting done remote done remote total delta delta mib done done done git done branch set track remote branch switched new branch yes checked right version successfully generating command build opt build opt file structure like successfully jenny group tree problem directly copy path calling code like module export make something went wrong like undefined reference undefined reference void undefined reference undefined reference undefined reference undefined reference bool undefined reference undefined reference undefined reference undefined reference char undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference undefined reference float float undefined reference bool long long collect error returned exit status make error know solve help thanks,issue,positive,positive,neutral,neutral,positive,positive
490214444,"Looks like you do have a newer version of tensorflow. Try...
```bash
kdavis-19htdh:mozilla kdavis$ git clone https://github.com/mozilla/tensorflow.git
Cloning into 'tensorflow'...
remote: Enumerating objects: 4, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 549136 (delta 0), reused 1 (delta 0), pack-reused 549132
Receiving objects: 100% (549136/549136), 322.00 MiB | 263.00 KiB/s, done.
Resolving deltas: 100% (443183/443183), done.
Checking out files: 100% (16472/16472), done.
kdavis-19htdh:mozilla kdavis$ cd tensorflow/
kdavis-19htdh:tensorflow kdavis$ git checkout r1.11
Checking out files: 100% (12549/12549), done.
Branch 'r1.11' set up to track remote branch 'r1.11' from 'origin'.
Switched to a new branch 'r1.11'
```",like version try bash git clone remote done remote counting done remote done remote total delta delta mib done done done git done branch set track remote branch switched new branch,issue,negative,negative,neutral,neutral,negative,negative
490155277,"> Odd, looks like errors you'd see if you were using a newer version of TF with an older bazel.
> 
> Is TF really the 1.11 version of Mozilla's fork and is bazel really 0.15.0?

bazel is exactly 0.15.0
I am not sure if TF is 1.11 because I visited [https://github.com/mozilla/tensorflow/tree/r1.11](url) and cloned it with `git clone https://github.com/mozilla/tensorflow.git`, but it seems that this URL refers to the newest version? BTW, how can I clone the r1.11 version, maybe I should `git checkout origin/r1.11`?",odd like see version older really version fork really exactly sure git clone version clone version maybe git,issue,negative,positive,positive,positive,positive,positive
490153100,"Odd, looks like errors you'd see if you were using a newer version of TF with an older bazel.

Is TF really the 1.11 version of Mozilla's fork and is bazel really 0.15.0?",odd like see version older really version fork really,issue,negative,positive,neutral,neutral,positive,positive
490147383,"I follow the instructions listed in 0.3.0 documents and I encountered errors when executing command
```
 bazel build -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" 
 //native_client:libctc_decoder_with_kenlm.so`
```
the error is

```
WARNING: while reading option defaults file '/usr/whz/generative_audio_attack/tensorflow/.bazelrc':

  invalid command name 'try-import'.
WARNING: while reading option defaults file '/usr/whz/generative_audio_attack/tensorflow/.bazelrc':
  invalid command name 'try-import'.
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:101:9: //external:bazel_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:110:9: //external:docker_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:119:9: //external:gcloud_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:128:9: //external:launchpad_openjdk_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:138:9: //external:golang_release: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:147:9: //external:debian8_clang_release: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:155:9: //external:ubuntu16_04_clang_release: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:164:9: //external:debian8_libcxx_release: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:172:9: //external:ubuntu16_04_libcxx_release: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0141_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0150_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0152_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0161_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0171_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0172_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0180_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0181_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0190_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0192_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0200_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0210_installer: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:196:9: //external:azul_open_jdk: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: /home/ww/.cache/bazel/_bazel_ww/7b32ff1c0ac316bf710c70621fc9fbba/external/bazel_toolchains/repositories/repositories.bzl:204:9: //external:azul_open_jdk_src: no such attribute 'downloaded_file_path' in 'http_file' rule
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': error loading package 'external': Could not load //external package
ERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': error loading package 'external': Could not load //external package
INFO: Elapsed time: 8.590s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```

Can you help me?Thanks.",follow listed command build opt error warning reading option file invalid command name warning reading option file invalid command name error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error attribute rule error error loading package error reading extension file package error loading package could load package error error loading package error reading extension file package error loading package could load package time build complete successfully loaded help thanks,issue,negative,positive,positive,positive,positive,positive
490129155,"The [0.3.0 documents](https://github.com/mozilla/DeepSpeech/tree/v0.3.0/native_client#building) indicate to build libctc_decoder_with_kenlm.so differently from the way you built it. They suggest...
```bash
bazel build -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //native_client:libctc_decoder_with_kenlm.so
```",indicate build differently way built suggest bash build opt,issue,negative,neutral,neutral,neutral,neutral,neutral
490109228,"> What about using the method documented in the [0.3.0 README.md](https://github.com/mozilla/DeepSpeech/blob/v0.3.0/README.md)?

Actually, My problem lies in 
I could successfully generate the libctc_decoder_with_kenlm.so after bazel build command, but something went wrong in my code calling this library.
`ERROR: The decoder library file does not exist. Make sure you have downloaded or built the native client binaries and pass the appropriate path to the binaries in the --decoder_library_path parameter.` 
So it seems that i need to do something with the path instead of copying libctc_decoder_with_kenlm.so?",method actually problem could successfully generate build command something went wrong code calling library error library file exist make sure built native client pas appropriate path need something path instead,issue,negative,positive,positive,positive,positive,positive
489594109,"@lissyx thank you for your quick answer, it's worked ",thank quick answer worked,issue,negative,positive,positive,positive,positive,positive
489426992,"It looks like #2002 removed that information, I've added it back: https://github.com/mozilla/DeepSpeech/blob/c1816d6dfc80b8f9ab13cbb94e4e79dce3cf17f5/README.md#cuda-dependency

Please ensure you have proper CUDA and CUDNN versions. I'm closing this, feel free to reopen if it's not working properly after you made sure you use CUDA 10.0 and CUDNN 7.5.",like removed information added back please ensure proper feel free reopen working properly made sure use,issue,positive,positive,positive,positive,positive,positive
489426637,"It looks like this removed the CUDA versions informations, leading to people mislead as in #2094 ",like removed leading people mislead,issue,negative,neutral,neutral,neutral,neutral,neutral
489426351,"> * **TensorFlow installed from**: upstream TensorFlow
> 
> * **TensorFlow version**: 1.10.0
> 
> * **Python version**: 3.5
> 
> * **CUDA/cuDNN version**: V9.0.176 / 7.1

That's inconsistent. Can you describe your installation steps ? Only versions of Python bindings on Windows are TensorFlow r1.13 based, so you need CUDA 10.0",upstream version python version version inconsistent describe installation python based need,issue,negative,neutral,neutral,neutral,neutral,neutral
489148738,"> Well, the idea was new to me... but if it has already been discussed, it might be not worth the effort. Thank you for your feedback!

Well, I remember throwing out the idea, but it was not ""discussed"" in the sense that we took a decision. And you're not the first one to suggest it, so with more polish it's likely not a bad idea!",well idea new already might worth effort thank feedback well remember throwing idea sense took decision first one suggest polish likely bad idea,issue,negative,negative,neutral,neutral,negative,negative
489148271,"@lissyx 
> I'm a bit confused about the pictures one, I don't get the idea

Well, this would be a kind of dictionary verification / enlargement. Since there are lots of words in a dictionary and many of them are language specific, it could be useful to build dictionaries with words, render them as pictures and let the user select the words, that are common in his language to verify dictionaries.

@dabinat 
> If the audio hasn’t yet been validated, how would it know the transcription the end-user entered was correct?

This is a good question... it is not possible, but since reCAPTCHA also uses a ""NEXT"" and a ""VERIFY"" Button, it would be possible to make the user qualify 1 or 2 samples, that are not validated yet and then end up with a validated one from the database.

Well, the idea was new to me... but if it has already been discussed, it might be not worth the effort. Thank you for your feedback!
",bit confused one get idea well would kind dictionary verification enlargement since lot dictionary many language specific could useful build render let user select common language verify audio yet would know transcription correct good question possible since also next verify button would possible make user qualify yet end one well idea new already might worth effort thank feedback,issue,positive,positive,positive,positive,positive,positive
489078525,"Cool. I was simply confused as when I inspected the trained model in tensorboard, the ""logits:0"" layer does not, in fact, contain logits, but probabilities.

Thanks!!",cool simply confused trained model layer fact contain thanks,issue,negative,positive,neutral,neutral,positive,positive
489063045,"Logits is the accepted term used for the input to Tensorflow's  [softmax](https://www.tensorflow.org/api_docs/python/tf/nn/softmax). Quoting the documentation:
```python
tf.nn.softmax(
    logits,
    axis=None,
    name=None,
    dim=None
)
```
As for the outputs of the softmax, yes logit is an inappropriate choice of name. You can suggest a more appropriate name in a PR.",accepted term used input documentation python yes inappropriate choice name suggest appropriate name,issue,positive,positive,positive,positive,positive,positive
489052774,"I've edited the console output you mentioned.

Here are some updates:

1. Because my training environment was on nvidia-docker, so the pid was killed by docker, not by system, so `sysctl` didn't help, I tried the command with params below, which made the memory usage more stable:
```
docker run \
    --memory-swappiness 100 \
    --memory <YOUR RAMSIZE> \
    --memory-swap <YOUR RAM + SWAP SIZE> \
    --oom-kill-disable \
    --runtime=nvidia -it <YOUR DeepSpeech IMAGE> bash
```
2. I've trained on cloud with kubernetes, which had no swap setting, so everything should process in RAM, but the RAM usage still increase over time while training Chinese model, even `--train_cached_features_path` didn't help, so the pod will be removed until the RAM exploded, but English model still trainable in kubernetes (English's RAM usage was stable even larger dataset).
3. Now, I'm trying version `v0.5.0-alpha.7`, the memory usage seems to be more stable than `v0.4.1`, the RAM doesn't increase over time, the `--feature_cache` works too, I'm keep tracking now...",console output training environment docker system help tried command made memory usage stable docker run memory ram swap size image bash trained cloud swap setting everything process ram ram usage still increase time training model even help pod removed ram exploded model still trainable ram usage stable even trying version memory usage stable ram increase time work keep,issue,positive,neutral,neutral,neutral,neutral,neutral
488858519,"Oh, nice catch @dabinat. In that case, ignore that comment and just read my review instead :)",oh nice catch case ignore comment read review instead,issue,negative,positive,positive,positive,positive,positive
488857969,"> The SpecAugment code seems to be taken from https://github.com/shelling203/SpecAugment which is published without a license.

There doesn’t appear to be an actual license file in the repo but the readme says it’s Apache 2.0. ",code taken without license appear actual license file apache,issue,negative,neutral,neutral,neutral,neutral,neutral
488853822,"If the audio hasn’t yet been validated, how would it know the transcription the end-user entered was correct? It has the original sentence but it would have to assume the speaker uttered that sentence perfectly.",audio yet would know transcription correct original sentence would assume speaker sentence perfectly,issue,positive,positive,positive,positive,positive,positive
488790058,"The SpecAugment code seems to be taken from https://github.com/shelling203/SpecAugment which is published without a license. Unfortunately, that means we cannot accept this into the repo. Please get in touch with the author about licensing this as otherwise this code is All rights reserved.",code taken without license unfortunately accept please get touch author otherwise code reserved,issue,negative,negative,negative,negative,negative,negative
488780276,"Here's a start:

```diff
diff --git a/util/feeding.py b/util/feeding.py
index fda98f0..17b7b1f 100644
--- a/util/feeding.py
+++ b/util/feeding.py
@@ -13,6 +13,7 @@ from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio
 
 from util.config import Config
 from util.text import text_to_char_array
+from util.spec_augment import spec_augment
 
 
 def read_csvs(csv_files):
@@ -29,24 +30,24 @@ def read_csvs(csv_files):
     return source_data
 
 
-def samples_to_mfccs(samples, sample_rate, spec_augment=False):
+def samples_to_mfccs(samples, sample_rate, augment=False):
     spectrogram = contrib_audio.audio_spectrogram(samples,
                                                   window_size=Config.audio_window_samples,
                                                   stride=Config.audio_step_samples,
                                                   magnitude_squared=True)
-    if spec_augment:
-		warped_masked_spectrogram = spec_augment(mel_spectrogram=spectrogram)
-	mfccs = contrib_audio.mfcc(spectrogram, sample_rate, dct_coefficient_count=Config.n_input)
-   
-	mfccs = tf.reshape(mfccs, [-1, Config.n_input])
+    if augment:
+        spectrogram = spec_augment(mel_spectrogram=spectrogram)
+
+    mfccs = contrib_audio.mfcc(spectrogram, sample_rate, dct_coefficient_count=Config.n_input)
+    mfccs = tf.reshape(mfccs, [-1, Config.n_input])
 
     return mfccs, tf.shape(mfccs)[0]
 
 
-def audiofile_to_features(wav_filename, spec_augment=False):
+def audiofile_to_features(wav_filename, augment=False):
     samples = tf.read_file(wav_filename)
     decoded = contrib_audio.decode_wav(samples, desired_channels=1)
-    features, features_len = samples_to_mfccs(decoded.audio, decoded.sample_rate, spec_augment)
+    features, features_len = samples_to_mfccs(decoded.audio, decoded.sample_rate, augment)
 
     return features, features_len
 
diff --git a/util/spec_augment.py b/util/spec_augment.py
index da61544..81d907b 100644
--- a/util/spec_augment.py
+++ b/util/spec_augment.py
@@ -50,8 +50,8 @@ def spec_augment(mel_spectrogram, time_warping_para=80, frequency_masking_para=2
     # Returns
       mel_spectrogram(numpy array): warped and masked mel spectrogram.
     """"""
-    v = mel_spectrogram.shape[0]
-    tau = mel_spectrogram.shape[1]
+    v = int(mel_spectrogram.shape[0])
+    tau = int(mel_spectrogram.shape[1])
 
     # Step 1 : Time warping
     # Image warping control point setting.
```",start git index import import import import return spectrogram spectrogram augment spectrogram spectrogram return augment return git index da array warped masked mel tau tau step time warping image warping control point setting,issue,negative,neutral,neutral,neutral,neutral,neutral
488584604,"Well, this is an idea a few of us already had years ago now, but, personnally, I'm asking myself:
 - is it really part of the upstream deepspeech project to take care of that? we are a small team, with a lot of items on our plate
 - I'm not sure it's good to rely only on audio: I'm personnally 99% of the time on mute when browsing, and it's very inconvenient to have sound. Though your other solutions are interesting (I'm a bit confused about the pictures one, I don't get the idea).",well idea u already ago really part upstream project take care small team lot plate sure good rely audio time mute browsing inconvenient sound though interesting bit confused one get idea,issue,positive,positive,positive,positive,positive,positive
488579179,Another Mozilla associated noise reduction project created a large noise dataset that might be useful to you. It’s downloadable at the bottom of this page: https://people.xiph.org/~jm/demo/rnnoise/,another associated noise reduction project large noise might useful bottom page,issue,negative,positive,positive,positive,positive,positive
487547591,">     4\. **TensorFlow:** v1.12.0-10-ge232881 **((((??????? why not match????)))**

As Reuben said, that's your issue. We can't explain since you don't provide your installation steps. Please use `0.5.0-alpha.6` or above prebuilt binaries.",ge match said issue ca explain since provide installation please use,issue,negative,neutral,neutral,neutral,neutral,neutral
487547223,Please stop posting the same issue and refer to the solution in #2047 ,please stop posting issue refer solution,issue,negative,neutral,neutral,neutral,neutral,neutral
487546982,"Looks like there's consensus, I'll merge, thanks !",like consensus merge thanks,issue,positive,positive,positive,positive,positive,positive
487542544,Looks like you're trying to use the v0.4.1 client with a newer model.,like trying use client model,issue,negative,neutral,neutral,neutral,neutral,neutral
487477418,As the core question is answered and this is evolving into a discussion I suggest it move to our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).,core question discussion suggest move discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
487474478,"> @waynetrx You can't continue training with changing alphabets.


You are a life-saver! I accidentally modify my data/alphabet.txt and added digits into it. After replacing with the original alphabet.txt, it works! 

I didn't realise that Deepspeech actually uses data/alphabet.txt

Is it normal to fine-tune  from epoch 225336?",ca continue training accidentally modify added original work actually normal epoch,issue,negative,positive,positive,positive,positive,positive
487460035,"I have cloned master .
Kindly tell me which branch do i checkout to so that this issue is resolved .
I can only use tensorflow >=1.13.1",master kindly tell branch issue resolved use,issue,positive,positive,positive,positive,positive,positive
487451330,"Currently there are no plans to add a noise reduction component to Deep Speech. However, we are planning to train the upcoming [0.6.0](https://github.com/mozilla/DeepSpeech/projects) release with background noise which should address this problem.",currently add noise reduction component deep speech however train upcoming release background noise address problem,issue,negative,neutral,neutral,neutral,neutral,neutral
487405580,"> However, I would also be fine to move it to another dockerfile. How should we go one?

I'll defer to @GeorgeFedoseev but honestly in the current shape we could avoid splitting into different files.",however would also fine move another go one defer honestly current shape could avoid splitting different,issue,negative,positive,positive,positive,positive,positive
487392119,"@lissyx  @GeorgeFedoseev I made some changes to fit your comments. However, I would also be fine to move it to another dockerfile. How should we go one?",made fit however would also fine move another go one,issue,positive,positive,positive,positive,positive,positive
487379855,"@GeorgeFedoseev So this is not really for training but just to build easily locally, right? If so, then @cfreemoser maybe it'd be best to have a different `Dockerfile`. At least would make sense to me.",really training build easily locally right maybe best different least would make sense,issue,positive,positive,positive,positive,positive,positive
487375218,"Hello!
I think this Dockerfile is for development purposes, so you will probably do some changes and will want to commit to your fork from inside container. So for this, I think better to have .git folder references already setup to your fork when building container. I don't see a development use case for cloning it from the main GitHub/mozilla/DeepSpeech repo.",hello think development probably want commit fork inside container think better folder already setup fork building container see development use case main,issue,positive,positive,positive,positive,positive,positive
487368948,"> * 
> 
> * include git-lfs
> 
> * allow checkout from GitHub instead of local copy step

That seems quite invasive compared to the original usecase of this Dockerfile, i'd like opinion from @GeorgeFedoseev ",include allow instead local copy step quite invasive original like opinion,issue,positive,positive,positive,positive,positive,positive
487362994,"Actually, I run in some trouble with the dockerfile. Since it is using python2 some error msg are not shown as supposed. For example, the util/text.py is not able to show which character is not included in the alphabet. Cause the way how the exception is raised requires python3. Therefore I made some changes to the Dockerfile and created a PR. https://github.com/mozilla/DeepSpeech/pull/2079",actually run trouble since python error shown supposed example able show character included alphabet cause way exception raised python therefore made,issue,negative,positive,neutral,neutral,positive,positive
487285361,Those questions should be posted on discourse. I don't know what is UNCLASS. For handling more than one file please look at discourse others already shared solutions. ,posted discourse know handling one file please look discourse already,issue,negative,neutral,neutral,neutral,neutral,neutral
487284361,"For a little side project, we use the dockerfile to train a deep speech model. We changed the dockerfile to checkout deepspeech from GitHub instead of copying it. It also includes GIT LFS. Maybe it's helpful for you

[dockerfile.txt](https://github.com/mozilla/DeepSpeech/files/3123896/dockerfile.txt)

",little side project use train deep speech model instead also git maybe helpful,issue,negative,negative,neutral,neutral,negative,negative
487101253,Closing for lack of activity and nothing actionable. New Common Voice releases should be imported with `import_cv2.py` anyway.,lack activity nothing actionable new common voice anyway,issue,negative,negative,neutral,neutral,negative,negative
486639873,"It looks like with this release, a new ElectronJS came as well: https://electronjs.org/releases/stable#5.0.0",like release new came well,issue,positive,positive,positive,positive,positive,positive
486627955,"```
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node_modules/.bin:$PATH deepspeech --model ../0.5.0a5/output_graph.pb --alphabet ../models/alphabet.txt --audio ../test-alex.en.wav --extended
Loading model from file ../0.5.0a5/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.6-0-gec06f94
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-04-25 13:05:38.262814: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-25 13:05:38.267767: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-04-25 13:05:38.267791: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-04-25 13:05:38.267800: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-04-25 13:05:38.267881: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.006755s.
Running inference.
she ha aylalsyalar ruraraua asuorashar
Inference took 0.3521s for 3.625s audio file.
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node_modules/.bin:$PATH node --version
v10.15.2
```",path model alphabet audio extended loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown loaded model running inference ha inference took audio file path node version,issue,negative,negative,neutral,neutral,negative,negative
486627730,"```
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node-v12.0.0-linux-x64/bin/:$(pwd)/node_modules/.bin:$PATH deepspeech --model ../0.5.0a5/output_graph.pb --alphabet ../models/alphabet.txt --audio ../test-alex.en.wav --extended
Loading model from file ../0.5.0a5/output_graph.pb
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.6-0-gec06f94
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-04-25 13:04:24.781264: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-25 13:04:24.790602: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-04-25 13:04:24.790654: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-04-25 13:04:24.790661: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-04-25 13:04:24.790759: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.01131s.
Running inference.
she ha aylalsyalar ruraraua asuorashar
Inference took 0.3618s for 3.625s audio file.
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node-v12.0.0-linux-x64/bin/:$(pwd)/node_modules/.bin:$^C
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node-v12.0.0-linux-x64/bin/:$(pwd)/node_modules/.bin:$PATH deepspeech --version
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.6-0-gec06f94
Runtime: Node
alex@portable-alex:~/tmp/deepspeech/SWIG$ PATH=$(pwd)/node-v12.0.0-linux-x64/bin/:$(pwd)/node_modules/.bin:$PATH node --version
v12.0.0
```",path model alphabet audio extended loading model file warning reading entire model file memory transform model file graph reduce heap usage binary use unknown unknown unknown unknown loaded model running inference ha inference took audio file path version node path node version,issue,negative,negative,neutral,neutral,negative,negative
486595025,"@mychiux413 Also please use code formatting for console output, it's very hard to read and follow otherwise.",also please use code console output hard read follow otherwise,issue,negative,negative,negative,negative,negative,negative
486593652,"> the kernel would be killed until memory usage increased to ~60G

You said your system had 128GB swap ? You have not documented how much RAM you have, not which processes are using it ...",kernel would memory usage said system swap much ram,issue,negative,positive,positive,positive,positive,positive
486577474,"Hi everyone,
Here is my training log today, I insert the memory log during training per 5 mins and remove some redundant info.

Here are few summaries:
0. env: DeepSpeech V0.4.1 / Chinese model with ~7000 alphabets / nvidia-docker 16.04-cuda9.0-cudnn7
1. memory usage increased ~0.1G per 5 mins during training
2. the kernel would be killed until memory usage increased to ~60G
3. my commit limit was below `grep -i commit /proc/meminfo`:
CommitLimit:    157183852 kB (~149.9G)
Committed_AS:   11557960 kB (~11.G)
4. At 04/25 04:30 (UTC+0), I set sysctl to disable the oom killer with `sudo sysctl -w vm.overcommit_memory=1` , but when 04/25 06:20 (UTF+0), the memory usage increased to ~60G, the system killed my kernel again, should I do more command to refresh vm.overcommit_memory?
5. This is my sysctl after 04/25 04:30 (UTC+0), `sysctl -a`:
```
vm.nr_hugepages = 0
vm.nr_hugepages_mempolicy = 0
vm.nr_overcommit_hugepages = 0
vm.numa_stat = 1
vm.numa_zonelist_order = Node
vm.oom_dump_tasks = 1
vm.oom_kill_allocating_task = 0
vm.overcommit_kbytes = 0
vm.overcommit_memory = 1
vm.overcommit_ratio = 70
vm.page-cluster = 3
vm.panic_on_oom = 0
vm.percpu_pagelist_fraction = 0
vm.stat_interval = 1
sysctl: permission denied on key 'vm.stat_refresh'
vm.swappiness = 60
vm.user_reserve_kbytes = 131072
vm.vfs_cache_pressure = 100
vm.watermark_scale_factor = 10
vm.zone_reclaim_mode = 0
```
6. My memory spec is:
```
 * RAM: 32G
 * SWAP: 128G
```



**>>>>>>>> Log Start <<<<<<<<**
```
**** [Running Command] ****
['/root/miniconda3/envs/py36/bin/python', '-u', '/DeepSpeech/DeepSpeech.py', '--alphabet_config_path', '/config/data/alphabet.txt', '--checkpoint_dir', '/log/checkpoint', '--checkpoint_secs', '7200', '--dev_batch_size', '24', '--dev_files', '/speech-data/zh-cn/dev_all.csv,/config/data/dev.csv', '--dropout_rate', '0.2', '--epoch', '-30', '--estop_mean_thresh', '0.3', '--estop_std_thresh', '0.3', '--export_dir', '/export', '--learning_rate', '0.0001', '--limit_test', '64', '--lm_alpha', '1.0', '--lm_beta', '1.85', '--lm_binary_path', '/export/lm.binary', '--lm_trie_path', '/export/trie', '--max_to_keep', '1', '--n_hidden', '1536', '--n_steps', '128', '--report_count', '64', '--test_batch_size', '24', '--test_files', '/speech-data/zh-cn/test_all.csv', '--train_batch_size', '24', '--train_files', '/config/data/train.csv', '--validation_step', '2']

logging at <_io.TextIOWrapper name='/log/deepspeech.txt' mode='a' encoding='UTF-8'>, <_io.TextIOWrapper name='/log/deepspeech-err.txt' mode='a' encoding='UTF-8'>

[Memory] 04/24 06:43
memtype total	used	free	buffers	cached
Virtual	31.3G	1.2G	3.5G	0.2G	26.4G
Swap	128.0G	1.7G	126.3G	     	     
Preprocessing ['/config/data/train.csv']
     	     
[Memory] 04/24 07:03
     	total	used	free	buffers	cached
Virtual	31.3G	27.7G	0.3G	0.2G	3.1G
S	128.0G	1.8G	126.2G	     	     
Preprocessing done
Preprocessing ['/speech-data/zh-cn/dev_all.csv', '/config/data/dev.csv']
Preprocessing done
I STARTING Optimization
I Training epoch 5...

[Memory] 04/24 07:13
memtype	total	used	free	buffers	cached
Virtual	31.3G	29.7G	0.4G	0.0G	1.2G
Swap	128.0G	6.5G	121.5G	     	     

[Memory] 04/24 07:18
memtype	total	used	free	buffers	cached
Virtual	31.3G	29.7G	0.4G	0.0G	1.2G
Swap	128.0G	6.6G	121.4G	     	     
.
.
.

[Memory] 04/24 09:53
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	17.3G	110.7G	     	     
I Training of Epoch 5 - loss: 100.668000
I Training epoch 6...   	     
.
.
.     	     

[Memory] 04/24 12:28
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	29.5G	98.5G	     	     

[Memory] 04/24 12:43
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.6G	0.4G	0.0G	4.2G
Swap	128.0G	30.8G	97.2G	     	     
I Training of Epoch 6 - loss: 75.468284
I Validating epoch 6...
I Validation of Epoch 6 - loss: 54.855226
I Training epoch 7...

[Memory] 04/24 12:48
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.2G	0.8G	0.0G	4.2G
Swap	128.0G	31.4G	96.6G	     	     

[Memory] 04/24 12:53
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.5G	0.4G	0.0G	4.3G
Swap	128.0G	31.4G	96.6G	     	     

.
.
.

[Memory] 04/24 14:28
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.8G	0.3G	0.0G	4.2G
Swap	128.0G	33.0G	95.0G	     	     

>>>>>   Now, The Kernel has been killed, So my program re run the training <<<<<<
* I lost syslog here

Preprocessing ['/config/data/train.csv']


[Memory] 04/24 14:43
memtype	total	used	free	buffers	cached
Virtual	31.3G	8.0G	6.8G	0.2G	16.2G
Swap	128.0G	0.2G	127.8G	     	     
    

[Memory] 04/24 14:58
memtype	total	used	free	buffers	cached
Virtual	31.3G	27.6G	0.3G	0.2G	3.2G
Swap	128.0G	0.2G	127.8G	     	     
Preprocessing done
Preprocessing ['/speech-data/zh-cn/dev_all.csv', '/config/data/dev.csv']
Preprocessing done
I STARTING Optimization
I Training epoch 7...

[Memory] 04/24 15:13
memtype	total	used	free	buffers	cached
Virtual	31.3G	29.8G	0.4G	0.0G	1.1G
Swap	128.0G	4.5G	123.5G	 

.
.
.
     	     

[Memory] 04/24 17:48
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	14.6G	113.4G	     	     
I Training of Epoch 7 - loss: 59.782993
I Training epoch 8...

[Memory] 04/24 20:33
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	27.2G	100.8G	

[Memory] 04/24 20:38
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	27.7G	100.3G	     	     
I Training of Epoch 8 - loss: 54.081356
I Validating epoch 8...
I Validation of Epoch 8 - loss: 39.263215
I Training epoch 9...

.
.
.


[Memory] 04/24 22:30
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.9G	0.2G	0.0G	4.2G
Swap	128.0G	30.7G	97.3G	 
    	     
>>>>>   Now, The Kernel has been killed, This is sys log with 'oom' keyword below <<<<<<
* my txt log time is UTC+0, and sys log is UTC+8

Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594646.252242] gsd-color invoked oom-killer: gfp_mask=0x14200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0
Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594646.252256]  oom_kill_process+0x220/0x440
Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594646.252346] [ pid ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594675.027262] python invoked oom-killer: gfp_mask=0x14200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0
Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594675.027276]  oom_kill_process+0x220/0x440
Apr 25 06:31:56 yihuachiu-GTX1080 kernel: [594675.027361] [ pid ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
Apr 25 06:31:57 yihuachiu-GTX1080 kernel: [594677.436088] oom_reaper: reaped process 29918 (python), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
==========================sys log end ================

>>>>>   So my program rerun the training again <<<<<<

Preprocessing ['/config/data/train.csv']

[Memory] 04/24 22:35
memtype	total	used	free	buffers	cached
Virtual	31.3G	5.3G	16.8G	0.2G	9.1G
Swap	128.0G	0.5G	127.5G

[Memory] 04/24 22:55
memtype	total	used	free	buffers	cached
Virtual	31.3G	30.9G	0.2G	0.0G	0.1G
Swap	128.0G	0.9G	127.1G	     	     
Preprocessing done
Preprocessing ['/speech-data/zh-cn/dev_all.csv', '/config/data/dev.csv']
Preprocessing done
I STARTING Optimization
I Training epoch 9...

[Memory] 04/25 01:15
memtype	total	used	free	buffers	cached
Virtual	31.3G	28.7G	0.2G	0.0G	2.4G
Swap	128.0G	12.3G	115.7G	

.
.
.

[Memory] 04/25 04:30
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.4G	0.0G	4.2G
Swap	128.0G	29.7G	98.3G	     	     
I Training of Epoch 10 - loss: 47.904078
I Validating epoch 10...

[Memory] 04/25 04:35
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.5G	0.5G	0.0G	4.2G
Swap	128.0G	30.3G	97.7G	     	     
I Validation of Epoch 10 - loss: 33.457280
I Training epoch 11...

.
.
.
     	     

[Memory] 04/25 06:20
memtype	total	used	free	buffers	cached
Virtual	31.3G	26.7G	0.3G	0.0G	4.2G
Swap	128.0G	32.1G	95.9G	     	     

>>>>>   Now, The Kernel has been killed, This is sys log with 'oom' keyword below <<<<<<
* my txt log time is UTC+0, and sys log is UTC+8

Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622905.852000] python invoked oom-killer: gfp_mask=0x14200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0
Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622905.852016]  oom_kill_process+0x220/0x440
Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622905.852101] [ pid ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622910.187847] python invoked oom-killer: gfp_mask=0x14200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0
Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622910.187864]  oom_kill_process+0x220/0x440
Apr 25 14:22:31 yihuachiu-GTX1080 kernel: [622910.187951] [ pid ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
Apr 25 14:22:33 yihuachiu-GTX1080 kernel: [622912.355795] oom_reaper: reaped process 31842 (python), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
==========================sys log end ================

Preprocessing ['/config/data/train.csv']

[Memory] 04/25 06:45
memtype	total	used	free	buffers	cached
Virtual	31.3G	30.6G	0.3G	0.1G	0.3G
Swap	128.0G	1.4G	126.6G	     	     
Preprocessing done
Preprocessing ['/speech-data/zh-cn/dev_all.csv', '/config/data/dev.csv']
Preprocessing done
I STARTING Optimization
I Training epoch 12...

[Memory] 04/25 07:35
memtype	total	used	free	buffers	cached
Virtual	31.3G	29.7G	0.4G	0.0G	1.2G
Swap	128.0G	6.4G	121.6G	     	     



[Memory] 04/25 08:00
memtype	total	used	free	buffers	cached
Virtual	31.3G	29.6G	0.4G	0.0G	1.3G
Swap	128.0G	7.6G	120.4G	     	     
```",hi everyone training log today insert memory log training per remove redundant model memory usage per training kernel would memory usage commit limit commit set disable killer memory usage system kernel command refresh node permission key memory spec ram swap log start running command epoch logging memory total used free virtual swap memory total used free virtual done done starting optimization training epoch memory total used free virtual swap memory total used free virtual swap memory total used free virtual swap training epoch loss training epoch memory total used free virtual swap memory total used free virtual swap training epoch loss epoch validation epoch loss training epoch memory total used free virtual swap memory total used free virtual swap memory total used free virtual swap kernel program run training lost memory total used free virtual swap memory total used free virtual swap done done starting optimization training epoch memory total used free virtual swap memory total used free virtual swap training epoch loss training epoch memory total used free virtual swap memory total used free virtual swap training epoch loss epoch validation epoch loss training epoch memory total used free virtual swap kernel log log time log kernel null kernel kernel name kernel python null kernel kernel name kernel process python log end program rerun training memory total used free virtual swap memory total used free virtual swap done done starting optimization training epoch memory total used free virtual swap memory total used free virtual swap training epoch loss epoch memory total used free virtual swap validation epoch loss training epoch memory total used free virtual swap kernel log log time log kernel python null kernel kernel name kernel python null kernel kernel name kernel process python log end memory total used free virtual swap done done starting optimization training epoch memory total used free virtual swap memory total used free virtual swap,issue,positive,positive,positive,positive,positive,positive
486524080,"For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech). 

Issues are for bugs and feature requests.",support please use discourse feature,issue,positive,neutral,neutral,neutral,neutral,neutral
486375841,"It looks like `~/.node-gyp/12.0.0/include/node/common.gypi` started to define `V8_IMMINENT_DEPRECATION_WARNINGS`, and `~/.node-gyp/12.0.0/include/node/v8.h` has:
```
#if !defined(V8_IMMINENT_DEPRECATION_WARNINGS)                                                                                                                                                                                                                                                                                
// Handle is an alias for Local for historical reasons.
template <class T>
using Handle = Local<T>;
#endif
```",like define defined handle alias local historical template class handle local,issue,negative,neutral,neutral,neutral,neutral,neutral
486359771,"Might be non trivial wrt SWIG:
```
../deepspeech_wrap.cxx: At global scope:                                                                                         
../deepspeech_wrap.cxx:3543:23: error: variable or field ‘model_initialize’ declared void                                                                                                
 void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                                                                                    
                       ^~~~~~                                                                                                  
../deepspeech_wrap.cxx:3543:23: error: ‘Handle’ is not a member of ‘v8’                                                                                                                  
../deepspeech_wrap.cxx:3543:40: error: expected primary-expression before ‘>’ token                                                                                                                                                                                                                                                                                                                             void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                                                                                                                                                                                                                                                                                                          
                                        ^                                                                                                                                                    
../deepspeech_wrap.cxx:3543:42: error: ‘exports’ was not declared in this scope                                                                                                              
 void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                              
                                          ^~~~~~~                                                                                                                                    
../deepspeech_wrap.cxx:3543:55: error: ‘Handle’ is not a member of ‘v8’                                                                                                              
 void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                                                                                                                                                                                                                                                                                                                                                                 ^~~~~~                                                                                                                                                                                                                                                                                                                                                  
../deepspeech_wrap.cxx:3543:72: error: expected primary-expression before ‘>’ token                                                                                                         
 void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                                                                                       
                                                                        ^                                                                                                                  
../deepspeech_wrap.cxx:3543:84: error: expected primary-expression before ‘)’ token                                                                                                        
 void SWIGV8_INIT (v8::Handle<v8::Object> exports, v8::Handle<v8::Object> /*module*/)                                            
                                                                                    ^                                                                                                            
In file included from ../deepspeech_wrap.cxx:171:                                                                                                                                                
../deepspeech_wrap.cxx:3659:20: error: ‘model_initialize’ was not declared in this scope                                 
 NODE_MODULE(model, model_initialize)                                                                                                                                        
```",might non trivial swig global scope error variable field declared void void module error handle member error token void module error declared scope void module error handle member void module error token void module error token void module file included error declared scope model,issue,negative,neutral,neutral,neutral,neutral,neutral
486095157,"Issues are for bugs and/or feature requests. For support and discussions, please use our [Discourse forums](https://discourse.mozilla.org/c/deep-speech).",feature support please use discourse,issue,positive,neutral,neutral,neutral,neutral,neutral
485869292,"> > I got same issue at Chinese Model, and my English Dataset (~100GB) is almost twice than Chinese one, the English Model never crash during training.
> 
> Please document what happens precisely. Not just ""crashed here"", actual error ...

Sorry, the ""crashed here"" means there is nothing more to print, 
so I couldn't find more logs to show,
the pid seems to be killed by sys and subprocess exit code is -9.
google says it OOM error,
I didn't keep tracking the RAM Usage,
But I remember when epoch at 2 or 3, the free space of CPU RAM (include swap) still have 50% more.
I will try to record the RAM v.s. time table and report here.

My training environment was in nvidia-docker cuda9.0 cudnn7 ubuntu16,
 and I executed deepspeech.py by python subprocess.run.",got issue model almost twice one model never crash training please document precisely actual error sorry nothing print could find show exit code error keep ram usage remember epoch free space ram include swap still try record ram time table report training environment executed python,issue,negative,negative,neutral,neutral,negative,negative
485853227,"I have an importer working at least for french and a model that gets trained on those french data.

One last bit to investigate is why we would require `ignore_longer_outputs_than_inputs=True` on the `ctc_loss` call.",importer working least model trained data one last bit investigate would require call,issue,negative,negative,negative,negative,negative,negative
485737185,">  I got same issue at Chinese Model, and my English Dataset (~100GB) is almost twice than Chinese one, the English Model never crash during training.

Please document what happens precisely. Not just ""crashed here"", actual error ...",got issue model almost twice one model never crash training please document precisely actual error,issue,negative,neutral,neutral,neutral,neutral,neutral
485736345,"Hi,
I got same issue at Chinese Model, and my English Dataset (~100GB) is almost twice than Chinese one, the English Model never crash during training.

This is what I have observed below:
0. DeepSpeech Version: v0.4.1 
1. I constraint max audio length under 20 seconds
2. the size of my chinese alphabet is ~7000, which include en character & chinese character (utf8)
3. My utf8 alphabet has rare character (4 bytes character)
4. In English model, CPU RAM usage will be stable after preprocessing train/dev (cached feature) , but I noticed that in Chinese Version, the CPU RAM usage will grow up after few train/dev epochs, but I can't get any pattern.
5. It was not only crashed on testing, I have tried different CPU RAM & batch size:
    Use larger batch size could suffer few train/dev epochs, but dead sooner than small batch size under same CPU RAM.
    Use larger CPU RAM will suffer more train/dev epochs, but also dead in the end under same batch size.
    The longer I trained, the more likely I failed.
6. I use 128G swap, which works well in English Large Dataset.

* my short term solution is using param: 'train_cached_feature_path' to keep continue after RAM crashed.


****************************************** LOG1 - transfer learning ***********************************************
>>>> [Running Command] <<<<
['/root/miniconda3/envs/py36/bin/python', '-u', '/DeepSpeech/DeepSpeech.py', '--alphabet_config_path', '/config/data/alphabet.txt', '--checkpoint_dir', '/log/checkpoint', '--checkpoint_secs', '7200', '--dev_batch_size', '8', '--dev_files', '/config/data/dev.csv', '--dropout_rate', '0.2', '--epoch', '-30', '--estop_mean_thresh', '0.3', '--estop_std_thresh', '0.3', '--export_dir', '/export', '--learning_rate', '0.0001', '--limit_test', '64', '--lm_alpha', '0.8006789096436977', '--lm_beta', '1.85', '--lm_binary_path', '/export/lm.binary', '--lm_trie_path', '/export/trie', '--max_to_keep', '1', '--n_hidden', '1280', '--n_steps', '128', '--report_count', '64', '--test_batch_size', '8', '--test_files', '/config/data/dev.csv', '--train_batch_size', '8', '--train_files', '/config/data/train.csv', '--validation_step', '1', '--summary_dir', '/log/summary']

logging at <_io.TextIOWrapper name='/log/deepspeech.txt' mode='a' encoding='UTF-8'>, <_io.TextIOWrapper name='/log/deepspeech-err.txt' mode='a' encoding='UTF-8'>
Preprocessing ['/config/data/train.csv']
Preprocessing done
Preprocessing ['/config/data/dev.csv']
Preprocessing done
I STARTING Optimization
I Training epoch 55...
I Training of Epoch 55 - loss: 23.294167
I Validating epoch 55...
I Validation of Epoch 55 - loss: 18.385086
I Training epoch 56...
.
.
.
.
I Validating epoch 69...
I Validation of Epoch 69 - loss: 10.784154
I Early stop triggered as (for last 4 steps) validation loss: 10.784154 with standard deviation: 0.303692 and mean: 10.175885
I FINISHED Optimization - training time: 10:17:31
Preprocessing ['/config/data/dev.csv']
Preprocessing done
Computing acoustic model predictions...
************************** CRASHED HERE even test the same csv as dev.csv ***************************

************************************************* LOG2 - new model ********************************************

>>>> [Running Command] <<<<
['/root/miniconda3/envs/py36/bin/python', '-u', '/DeepSpeech/DeepSpeech.py', '--alphabet_config_path', '/config/data/alphabet.txt', '--checkpoint_dir', '/log/checkpoint', '--checkpoint_secs', '7200', '--dev_batch_size', '24', '--dev_cached_features_path', '/log/dev.cached', '--dev_files', '/speech-data/zh-cn/dev_all.csv,/config/data/dev.csv', '--dropout_rate', '0.2', '--epoch', '-30', '--estop_mean_thresh', '0.3', '--estop_std_thresh', '0.3', '--export_dir', '/export', '--learning_rate', '0.0001', '--limit_test', '64', '--lm_alpha', '1.0', '--lm_beta', '1.85', '--lm_binary_path', '/export/lm.binary', '--lm_trie_path', '/export/trie', '--max_to_keep', '1', '--n_hidden', '1536', '--n_steps', '128', '--report_count', '64', '--show_progressbar', 'False', '--test_batch_size', '24', '--test_cached_features_path', '/log/test.cached', '--test_files', '/speech-data/zh-cn/test_all.csv', '--train_batch_size', '24', '--train_cached_features_path', '/log/train.cached', '--train_files', '/config/data/train.csv', '--validation_step', '2']

logging at <_io.TextIOWrapper name='/log/deepspeech.txt' mode='a' encoding='UTF-8'>, <_io.TextIOWrapper name='/log/deepspeech-err.txt' mode='a' encoding='UTF-8'>Preprocessing ['/config/data/train.csv']
Saving to /log/train.cached
Preprocessing done
Preprocessing ['/speech-data/zh-cn/dev_all.csv', '/config/data/dev.csv']
Saving to /log/dev.cached
Preprocessing done
I STARTING Optimization
I Training epoch 0...
I Training of Epoch 0 - loss: 114.681121
I Training epoch 1...
I Training of Epoch 1 - loss: 112.573020
I Training epoch 2...
I Training of Epoch 2 - loss: 111.198199
I Validating epoch 2...
I Validation of Epoch 2 - loss: 132.356261
I Training epoch 3...
I Training of Epoch 3 - loss: 111.352473
I Training epoch 4...
I Training of Epoch 4 - loss: 110.923097
I Validating epoch 4...
I Validation of Epoch 4 - loss: 134.511714
I Training epoch 5...
I Training of Epoch 5 - loss: 110.544768
I Training epoch 6...
******************************* CRASHED HERE  ***************************",hi got issue model almost twice one model never crash training version constraint audio length size alphabet include en character character alphabet rare character character model ram usage stable feature version ram usage grow ca get pattern testing tried different ram batch size use batch size could suffer dead sooner small batch size ram use ram suffer also dead end batch size longer trained likely use swap work well large short term solution param keep continue ram log transfer learning running command epoch logging done done starting optimization training epoch training epoch loss epoch validation epoch loss training epoch epoch validation epoch loss early stop triggered last validation loss standard deviation mean finished optimization training time done acoustic model even test log new model running command epoch logging saving done saving done starting optimization training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss epoch validation epoch loss training epoch training epoch loss training epoch training epoch loss epoch validation epoch loss training epoch training epoch loss training epoch,issue,negative,negative,neutral,neutral,negative,negative
485710351,@reuben So basically the .Net bindings part has been done by @carlfm01 for proper marshalling. He checked thoroughly and there should be no memory leak.,basically part done proper checked thoroughly memory leak,issue,negative,neutral,neutral,neutral,neutral,neutral
485406727,"Thank you @lissyx sir.
`Current model 0.4.1 needs to be reexported for this version.`

sir i created new exported model which is trained on my own data and tried to infer but got error. is this only are you saying? or something else. can you please explain me, what is  exactly **reexported**  here? ",thank sir current model need sir new model trained data tried infer got error saying something else please explain exactly,issue,negative,positive,positive,positive,positive,positive
485402781,Current model 0.4.1 needs to be reexported for this version. ,current model need version,issue,negative,neutral,neutral,neutral,neutral,neutral
485292020,"Please use the [Discourse forums](https://discourse.mozilla.org/c/deep-speech) for this, as documented in the issue template.",please use discourse issue template,issue,negative,neutral,neutral,neutral,neutral,neutral
485086705,Please avoid images for console output ,please avoid console output,issue,negative,neutral,neutral,neutral,neutral,neutral
485056822,"> > python3 process is killed because of OOM.
> 
> Kernel OOM ? GPU OOM ? There's no mention of the GPU nor its memory, nor the system's memory. I don't see how we can help more, not to mention the lack of any log as requested by @kdavis-mozilla

It should be the GPU OOM. The GPU used situation when failing to output model that day is in the picture.
![image](https://user-images.githubusercontent.com/33015549/56452617-5fb42900-6365-11e9-96e7-dbdf48079ab6.png)
",python process kernel mention memory system memory see help mention lack log used situation failing output model day picture image,issue,negative,neutral,neutral,neutral,neutral,neutral
485056449,"> Can you provide a log file?

Sorry for my late reply. I don't find other log. The followed content is in the /var/log/kern.log. Apr 14 is just the day I try to output model. 

```
Apr 14 09:19:17 gpu kernel: [1942044.048852] [ 4727]     0  4727 16688962  7485317   19123      46   949207             0 python3
Apr 14 09:19:17 gpu kernel: [1942044.048854] [ 4789]   115  4789     4284      300      14       3       45             0 nvidia-persiste
Apr 14 09:19:17 gpu kernel: [1942044.048856] [ 5059]   120  5059    77313       19      60       3      475          -900 postgres
Apr 14 09:19:17 gpu kernel: [1942044.048857] Out of memory: Kill process 4727 (python3) score 494 or sacrifice child
Apr 14 09:19:17 gpu kernel: [1942044.048983] Killed process 4727 (python3) total-vm:66755848kB, anon-rss:0kB, file-rss:29941268kB
Apr 14 09:19:17 gpu kernel: [1942072.385910] irqbalance invoked oom-killer: gfp_mask=0x24200ca, order=0, oom_score_adj=0
Apr 14 09:19:17 gpu kernel: [1942072.385914] irqbalance cpuset=/ mems_allowed=0
Apr 14 09:19:17 gpu kernel: [1942072.385918] CPU: 10 PID: 1584 Comm: irqbalance Tainted: P           OE   4.4.0-62-generic #83-Ubuntu
Apr 14 09:19:17 gpu kernel: [1942072.385920] Hardware name: ASUS All Series/X99-E WS/USB 3.1, BIOS 3402 11/14/2016
Apr 14 09:19:17 gpu kernel: [1942072.385921]  0000000000000286 0000000092a35c8f ffff8808786b79b0 ffffffff813f7c63
Apr 14 09:19:17 gpu kernel: [1942072.385924]  ffff8808786b7b88 ffff880868460000 ffff8808786b7a20 ffffffff8120ad4e
Apr 14 09:19:17 gpu kernel: [1942072.385926]  ffffffff8113f5ca ffff8808786b7a50 ffffffff811a6b6d ffff8802300a5460
Apr 14 09:19:17 gpu kernel: [1942072.385928] Call Trace:
Apr 14 09:19:17 gpu kernel: [1942072.385933]  [<ffffffff813f7c63>] dump_stack+0x63/0x90
Apr 14 09:19:17 gpu kernel: [1942072.385937]  [<ffffffff8120ad4e>] dump_header+0x5a/0x1c5
Apr 14 09:19:17 gpu kernel: [1942072.385941]  [<ffffffff8113f5ca>] ? __delayacct_freepages_end+0x2a/0x30
Apr 14 09:19:17 gpu kernel: [1942072.385944]  [<ffffffff811a6b6d>] ? do_try_to_free_pages+0x2ed/0x410
Apr 14 09:19:17 gpu kernel: [1942072.385947]  [<ffffffff811926c2>] oom_kill_process+0x202/0x3c0
Apr 14 09:19:17 gpu kernel: [1942072.385949]  [<ffffffff81192ae9>] out_of_memory+0x219/0x460
Apr 14 09:19:17 gpu kernel: [1942072.385952]  [<ffffffff81198a5d>] __alloc_pages_slowpath.constprop.88+0x8fd/0xa70
Apr 14 09:19:17 gpu kernel: [1942072.385954]  [<ffffffff81198e56>] __alloc_pages_nodemask+0x286/0x2a0
Apr 14 09:19:17 gpu kernel: [1942072.385956]  [<ffffffff8113f276>] ? delayacct_end+0x56/0x60
Apr 14 09:19:17 gpu kernel: [1942072.385960]  [<ffffffff811e3f5e>] alloc_pages_vma+0xbe/0x240
Apr 14 09:19:17 gpu kernel: [1942072.385962]  [<ffffffff811d49de>] __read_swap_cache_async+0xee/0x140
Apr 14 09:19:17 gpu kernel: [1942072.385964]  [<ffffffff811d4a56>] read_swap_cache_async+0x26/0x60
Apr 14 09:19:17 gpu kernel: [1942072.385965]  [<ffffffff811d4b95>] swapin_readahead+0x105/0x1b0
Apr 14 09:19:17 gpu kernel: [1942072.385969]  [<ffffffff811c1b16>] handle_mm_fault+0x1196/0x1820
Apr 14 09:19:17 gpu kernel: [1942072.385972]  [<ffffffff8106b4f7>] __do_page_fault+0x197/0x400
Apr 14 09:19:17 gpu kernel: [1942072.385974]  [<ffffffff8106b782>] do_page_fault+0x22/0x30
Apr 14 09:19:17 gpu kernel: [1942072.385978]  [<ffffffff8183a778>] page_fault+0x28/0x30
Apr 14 09:19:17 gpu kernel: [1942072.385979] Mem-Info:
Apr 14 09:19:17 gpu kernel: [1942072.385985] active_anon:7465474 inactive_anon:503708 isolated_anon:1024
Apr 14 09:19:17 gpu kernel: [1942072.385985]  active_file:206 inactive_file:198 isolated_file:0
Apr 14 09:19:17 gpu kernel: [1942072.385985]  unevictable:914 dirty:0 writeback:13 unstable:0
Apr 14 09:19:17 gpu kernel: [1942072.385985]  slab_reclaimable:30486 slab_unreclaimable:47402
Apr 14 09:19:17 gpu kernel: [1942072.385985]  mapped:7485714 shmem:7970208 pagetables:21503 bounce:0
Apr 14 09:19:17 gpu kernel: [1942072.385985]  free:52080 free_pcp:0 free_cma:0
Apr 14 09:19:17 gpu kernel: [1942072.385988] Node 0 DMA free:15892kB min:32kB low:40kB high:48kB active_anon:0kB inactive_anon:0kB active_file:0kB inactive_file:0kB unevictable:0kB isolated(anon):0kB isolated(file):0kB present:15996kB managed:15900kB mlocked:0kB dirty:0kB writeback:0kB mapped:0kB shmem:0kB slab_reclaimable:0kB slab_unreclaimable:8kB kernel_stack:0kB pagetables:0kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:0 all_unreclaimable? yes
Apr 14 09:19:17 gpu kernel: [1942072.385992] lowmem_reserve[]: 0 1303 32020 32020 32020
Apr 14 09:19:17 gpu kernel: [1942072.385995] Node 0 DMA32 free:125616kB min:2748kB low:3432kB high:4120kB active_anon:922088kB inactive_anon:308776kB active_file:12kB inactive_file:4kB unevictable:472kB isolated(anon):0kB isolated(file):0kB present:1465680kB managed:1385060kB mlocked:472kB dirty:0kB writeback:4kB mapped:925884kB shmem:1230904kB slab_reclaimable:5404kB slab_unreclaimable:5664kB kernel_stack:240kB pagetables:3652kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:7511248 all_unreclaimable? yes
Apr 14 09:19:17 gpu kernel: [1942072.385999] lowmem_reserve[]: 0 0 30717 30717 30717
Apr 14 09:19:17 gpu kernel: [1942072.386001] Node 0 Normal free:66812kB min:64800kB low:81000kB high:97200kB active_anon:28939808kB inactive_anon:1706056kB active_file:812kB inactive_file:788kB unevictable:3184kB isolated(anon):4096kB isolated(file):0kB present:31981568kB managed:31454928kB mlocked:3184kB dirty:0kB writeback:48kB mapped:29016972kB shmem:30649928kB slab_reclaimable:116540kB slab_unreclaimable:183936kB kernel_stack:5712kB pagetables:82360kB unstable:0kB bounce:0kB free_pcp:0kB local_pcp:0kB free_cma:0kB writeback_tmp:0kB pages_scanned:184394568 all_unreclaimable? yes
Apr 14 09:19:17 gpu kernel: [1942072.386005] lowmem_reserve[]: 0 0 0 0 0
Apr 14 09:19:17 gpu kernel: [1942072.386008] Node 0 DMA: 1*4kB (U) 0*8kB 1*16kB (U) 2*32kB (U) 3*64kB (U) 0*128kB 1*256kB (U) 0*512kB 1*1024kB (U) 1*2048kB (M) 3*4096kB (M) = 15892kB
Apr 14 09:19:17 gpu kernel: [1942072.386016] Node 0 DMA32: 242*4kB (UME) 87*8kB (ME) 67*16kB (ME) 42*32kB (ME) 27*64kB (UME) 14*128kB (E) 25*256kB (UME) 16*512kB (UE) 7*1024kB (UE) 1*2048kB (M) 23*4096kB (M) = 125616kB
Apr 14 09:19:17 gpu kernel: [1942072.386025] Node 0 Normal: 815*4kB (MEH) 250*8kB (MEH) 265*16kB (UMEH) 249*32kB (UMEH) 89*64kB (MEH) 63*128kB (UEH) 39*256kB (UEH) 26*512kB (UMEH) 10*1024kB (UEH) 1*2048kB (U) 0*4096kB = 66812kB
Apr 14 09:19:17 gpu kernel: [1942072.386035] Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=1048576kB
Apr 14 09:19:17 gpu kernel: [1942072.386036] Node 0 hugepages_total=0 hugepages_free=0 hugepages_surp=0 hugepages_size=2048kB
Apr 14 09:19:17 gpu kernel: [1942072.386037] 7971282 total pagecache pages
Apr 14 09:19:17 gpu kernel: [1942072.386039] 32 pages in swap cache
Apr 14 09:19:17 gpu kernel: [1942072.386040] Swap cache stats: add 493338025, delete 493337993, find 204125073/346446887
Apr 14 09:19:17 gpu kernel: [1942072.386041] Free swap  = 28418196kB
Apr 14 09:19:17 gpu kernel: [1942072.386042] Total swap = 33463292kB
Apr 14 09:19:17 gpu kernel: [1942072.386043] 8365811 pages RAM
Apr 14 09:19:17 gpu kernel: [1942072.386043] 0 pages HighMem/MovableOnly
Apr 14 09:19:17 gpu kernel: [1942072.386044] 151839 pages reserved
Apr 14 09:19:17 gpu kernel: [1942072.386045] 0 pages cma reserved
Apr 14 09:19:17 gpu kernel: [1942072.386046] 0 pages hwpoisoned
```",provide log file sorry late reply find log content day try output model kernel python kernel kernel kernel memory kill process python score sacrifice child kernel process python kernel kernel kernel oe generic kernel hardware name bios kernel kernel kernel kernel call trace kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel kernel dirty unstable kernel kernel bounce kernel free kernel node free min low high isolated anon isolated file present dirty unstable bounce yes kernel kernel node free min low high isolated anon isolated file present dirty unstable bounce yes kernel kernel node normal free min low high isolated anon isolated file present dirty unstable bounce yes kernel kernel node kernel node ume ume ume kernel node normal kernel node kernel node kernel total kernel swap cache kernel swap cache add delete find kernel free swap kernel total swap kernel ram kernel kernel reserved kernel reserved kernel,issue,negative,negative,neutral,neutral,negative,negative
484865211,">  python3 process is killed because of OOM.

Kernel OOM ? GPU OOM ? There's no mention of the GPU nor its memory, nor the system's memory. I don't see how we can help more, not to mention the lack of any log as requested by @kdavis-mozilla ",python process kernel mention memory system memory see help mention lack log,issue,negative,neutral,neutral,neutral,neutral,neutral
484765217,"Prebuilt binaries are working as intended, your model re-export is wrong, there was some variables changes and it's expected not to work from 0.4.1 checkpoints.",working intended model wrong work,issue,negative,negative,negative,negative,negative,negative
484764977,"@lissyx , I want to profile the inference time in more detail for each run. So I need to compile libdeepspeech.so from source after making the necessary changes in /native_client/deepspeech.cc",want profile inference time detail run need compile source making necessary,issue,negative,neutral,neutral,neutral,neutral,neutral
484702914,"@sranjeet81 Also, C++ native client for Android is not of real use besides our testing, and we already have prebuilt binaries. Why do you need to rebuild ?",also native client android real use besides testing already need rebuild,issue,negative,positive,positive,positive,positive,positive
484702701,Are you sure you are using the proper tensorflow sources? We have local patches to avoid this issue.,sure proper local avoid issue,issue,negative,positive,positive,positive,positive,positive
484400636,"> ~$ deepspeech --help

try: `python evaluate.py --help`",help try python help,issue,positive,neutral,neutral,neutral,neutral,neutral
484382958,"We've done some tests of fine-tuning from one language to another, but no fine-tuning from one language to it's IPA version. So, I'm not sure I have a good intuition as to how the fine-tuning should proceed.",done one language another one language version sure good intuition proceed,issue,positive,positive,positive,positive,positive,positive
484362572,"Makes sense, of course thanks! 

I wonder if there's merit in doing some fine-tuning against the current trained English model, part of the experimentation being progressively resetting / retraining more of the higher layers until you get the right level of automatic feature detection that overlaps between English characters and IPA phonetics (of which there appear to be [173 unique ones including various modifiers](https://www.quora.com/How-many-phonetic-symbols-are-there)). 

This would in theory get IPA generation for English phones, but would not be trained on IPA phones that don't occur in English I guess.

My rationale is that while it's a many-to-many mapping between sequences of English characters and IPA symbols, it is a closed set that should map to the spectrogram cleanly, but I don't know. Someone shout if this seems conceptually misplaced. ",sense course thanks wonder merit current trained model part experimentation progressively higher get right level automatic feature detection phonetics appear unique various would theory get generation would trained occur guess rationale closed set map spectrogram cleanly know someone shout conceptually,issue,positive,positive,positive,positive,positive,positive
484322551,"After I type ~$ deepspeech --help

It shows optional arguments:

> -h,-- help      show this help message and exit
> -- model MODEL path to the model(protocol buffer binary file)
> -- alphabet ALPHABET Path to the configuration file specifying the alphabet used by the network
> --lm [LM]  Path to the language model binary file
> --trie[TRIE]   Path to the language model trie file created with native_client/generate_trie
> --audio AUDIO  PAth to the audio file to run (WAV format)
> --version  Print version and exits

I don't know which command do I need to type",type help optional help show help message exit model model path model protocol buffer binary file alphabet alphabet path configuration file alphabet used network path language model binary file path language model file audio audio path audio file run format version print version know command need type,issue,positive,neutral,neutral,neutral,neutral,neutral
484312078,"[image: Capture.PNG]
I didn't find the evaluation options here

Kelly Davis <notifications@github.com> 于2019年4月17日周三 下午9:46写道：

> Use the --help flag to find the arguments.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/2059#issuecomment-484049431>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AjzQfZsgPqdtir4Tq3HQO11438K-voolks5vhwmAgaJpZM4c0MzH>
> .
>
",image find evaluation kelly use help flag find thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
484070398,"The apk should work, it's tested but it's only here as a demo ... Regarding your build error please make sure you correctly follow the steps. Also why do you not use pre-built binaries? ",work tested regarding build error please make sure correctly follow also use,issue,negative,positive,positive,positive,positive,positive
484063103,"@lissyx ,


Yes, Now I can run the apk. Thankyou.

However, the decoded text message is not shown on apk. Only the inference time is shown. I have seen the similar issue while running with adb-shell command.

Also, when i try to compile libdeepspeech.so for android-arm64 from source, i get compile error regarding ctddecode.


",yes run however text message shown inference time shown seen similar issue running command also try compile source get compile error regarding,issue,negative,neutral,neutral,neutral,neutral,neutral
484049431,Use the ``--help`` flag to find the arguments.,use help flag find,issue,negative,neutral,neutral,neutral,neutral,neutral
484044695,"Well, the Dockerfile was contributed by some external people for their own need at first, and I don't think it covers training directly inside the Docker file, hence why there's no git-lfs: there was no need.

Regarding python 3, we still have things working with python2 so that's not such big of a deal, event hough 2.7 is getting closer and closer to death.

PR welcome if you require it, but bear in mind bundling language model will increase significantly the docker image.",well external people need first think training directly inside docker file hence need regarding python still working python big deal event hough getting closer closer death welcome require bear mind language model increase significantly docker image,issue,negative,positive,positive,positive,positive,positive
484037140,"> You can use [evaluate.py](https://github.com/mozilla/DeepSpeech/blob/master/evaluate.py)

what command do I need to write?",use command need write,issue,negative,neutral,neutral,neutral,neutral,neutral
483989302,"> @lissyx, I tried to make the AAR package following the title ""Anroid Java / JNI bindings: libdeepspeech""
> and used the following command.
> ./gradlew libdeepspeech:build
> 
> However, there is build error like below:
> /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1510: error: undefined reference to 'DS_FreeString(char*)'
> /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1585: error: undefined reference to 'DS_FreeString(char*)'
> /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1600: error: undefined reference to 'DS_FreeString(char*)'
> /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1650: error: undefined reference to 'DS_FreeString(char*)'
> clang++: error: linker command failed with exit code 1 (use -v to see invocation)
> ninja: build stopped: subcommand failed.

Means you don't have the matching `libdeepspeech.so` with `DS_FreeString` symbol. Why do you need to rebuild yourself ?

https://bintray.com/alissy/org.mozilla.deepspeech/libdeepspeech/0.5.0-alpha.5",tried make package following title used following command build however build error like error undefined reference char error undefined reference char error undefined reference char error undefined reference char error linker command exit code use see invocation build stopped matching symbol need rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
483939513,"If you have audio transcribed to IPA, you can train your own model with the current code now. There is nothing saying the alphabet used has to be ""normal"" letters.",audio train model current code nothing saying alphabet used normal,issue,negative,positive,neutral,neutral,positive,positive
483914077,"@lissyx, I tried to make the AAR package following the title ""Anroid Java / JNI bindings: libdeepspeech""
and used the following command.
./gradlew libdeepspeech:build

However, there is build error like below:
/DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1510: error: undefined reference to 'DS_FreeString(char*)'
  /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1585: error: undefined reference to 'DS_FreeString(char*)'
  /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1600: error: undefined reference to 'DS_FreeString(char*)'
  /DeepSpeechv0.5/native_client/java/jni/deepspeech_wrap.cpp:1650: error: undefined reference to 'DS_FreeString(char*)'
  clang++: error: linker command failed with exit code 1 (use -v to see invocation)
  ninja: build stopped: subcommand failed.",tried make package following title used following command build however build error like error undefined reference char error undefined reference char error undefined reference char error undefined reference char error linker command exit code use see invocation build stopped,issue,negative,neutral,neutral,neutral,neutral,neutral
483894966,"IPA is about a [language-independent representation -- the phones](http://www.internationalphoneticalphabet.org/ipa/). This is to be contrasted against phonemes are language-dependent semantic interpretations. E.g. the ""p"" in spot vs pot are functionally the same in English but two separate phones from the 9 different kinds of ""[voiceless bilabial stops](https://en.wikipedia.org/wiki/Voiceless_bilabial_stop)"" or ""p""s that are pronounced in human languages around the world. 

I'm by no means an expert in this territory and appreciate that given other threads, IPA support may not be core to DeepSpeech and therefore may require a fork. 
",representation semantic spot pot functionally two separate different voiceless bilabial pronounced human around world expert territory appreciate given support may core therefore may require fork,issue,positive,neutral,neutral,neutral,neutral,neutral
483628715,Please use the documented build steps. It's likely you miss generating the wrapper with swig... ,please use build likely miss generating wrapper swig,issue,negative,neutral,neutral,neutral,neutral,neutral
483612263,"> A lot of text is lost. Seems like some audio is lost while previous inferencing is under process.

That's another story, it's possible there are bugs in the code, it's an example usage.",lot text lost like audio lost previous process another story possible code example usage,issue,negative,negative,neutral,neutral,negative,negative
483610386,"> https://github.com/nodesource/distributions/blob/master/README.md#deb

updated nodejs to v10.15.3. Seems to be working fine now. Followed the above installation process.
A lot of text is lost. Seems like some audio is lost while previous inferencing is under process.

",working fine installation process lot text lost like audio lost previous process,issue,negative,positive,positive,positive,positive,positive
483602390,"Unfortunately you are not the first one, I don't know what they do on the Ubuntu package. ",unfortunately first one know package,issue,negative,positive,positive,positive,positive,positive
483602374,"@kdavis-mozilla I tried that article, except for the install using NVM part. I'll try updating nodejs using NVM if you think that might be responsible for the error. I'll update once it's done.",tried article except install part try think might responsible error update done,issue,negative,positive,positive,positive,positive,positive
483600015,"@lissyx I am currently on nodejs v8.10.0 which i installed from ubuntu repos. I tried installing from nodesource PPA but it shows 'not currently supported'

The ffmpeg_vad_streaming runs for some time producing a couple of transcripts before giving the error.
Also, the result is poor (signigicant amount of text is lost) compared to mic_vad_streaming",currently tried currently time couple giving error also result poor amount text lost,issue,negative,negative,negative,negative,negative,negative
483596867,"> What happens if you upgrade node to 8.12 or later?

I tried upgrading to current LTS version 10.x and 8.x from PPA, which produces the following message:

``` Your distribution, identified as ""bionic"", is not currently supported, please contact NodeSource at https://github.com/nodesource/distributions/issues if you think this is incorrect or would like your distribution to be considered for support```

> It looks like you are on 5.7, which should work. But there might be a bug in node below 8.12.

```
$nodejs -v
v8.10.0
```
Is there any other way to upgrade to v8.12 or above?
",upgrade node later tried current version following message distribution currently please contact think incorrect would like distribution considered support like work might bug node way upgrade,issue,positive,neutral,neutral,neutral,neutral,neutral
483587020,Please use official node release,please use official node release,issue,negative,neutral,neutral,neutral,neutral,neutral
483586814,"It's for testing purposes, shows transcript built from the Metadata structure and matching API call ",testing transcript built structure matching call,issue,negative,neutral,neutral,neutral,neutral,neutral
483546412,"@reuben As I mentioned I dont' have time to do the review. If tilman gave it a r+, I'm fine with that.",dont time review gave fine,issue,negative,positive,positive,positive,positive,positive
483538924,"What happens if you upgrade node to 8.12 or later?

It looks like you are on 5.7, which should work. But there might be a bug in node below 8.12.",upgrade node later like work might bug node,issue,negative,neutral,neutral,neutral,neutral,neutral
483529294,"Also, @lissyx, I noticed you'd made some changes to the implementation in #2022, such as splitting it up into separate --extended and --csv args. I can replicate this for the JSON implementation but I was curious what the purpose of --extended by itself was? It appears to output just the transcription by itself, which is equivalent to not specifying it at all.",also made implementation splitting separate extended replicate implementation curious purpose extended output transcription equivalent,issue,negative,negative,neutral,neutral,negative,negative
483501935,"Ok, I've got it working now. Before I submit a PR, I had one question: what is the unit of the probability variable in the Metadata struct? I'm getting values like 377.149292 so it doesn't seem like it's a percentage.",got working submit one question unit probability variable getting like seem like percentage,issue,positive,neutral,neutral,neutral,neutral,neutral
483491452,"> Check the duration of the audio files in the large test CSV. There's probably a few files that are very long and cause the OOM.

The biggest audio file in my train/dev/test csv is no more than 0.6MB. It may not be the reason.",check duration audio large test probably long cause biggest audio file may reason,issue,negative,positive,neutral,neutral,positive,positive
483485674,Check the duration of the audio files in the large test CSV. There's probably a few files that are very long and cause the OOM.,check duration audio large test probably long cause,issue,negative,positive,neutral,neutral,positive,positive
483397360,"maybe... but Anaconda is very useful and I can't refuse it. I have one off topic more question, do you have pretrained model for 0.5 version of deepspeech? Or I need train it from the beginning? ",maybe anaconda useful ca refuse one topic question model version need train beginning,issue,negative,positive,positive,positive,positive,positive
483395692,I suspect the underlying problem here was Anaconda.,suspect underlying problem anaconda,issue,negative,neutral,neutral,neutral,neutral,neutral
483377784,"> I'll reset/clear my OS and repeat all steps to install deepspeech again. I think I did mistake from the begin.

Thanks, I'll close the issue but feel free to give us feedback here or in a new issue if you spot something we need to fix!",o repeat install think mistake begin thanks close issue feel free give u feedback new issue spot something need fix,issue,positive,positive,positive,positive,positive,positive
483377349,I'll reset/clear my OS and repeat all steps to install deepspeech again. I think I did mistake from the begin.,o repeat install think mistake begin,issue,negative,neutral,neutral,neutral,neutral,neutral
483376924,"> > Thank you for your time! I fixed it. I added to my PATH all paths to libs and now all work good!!! Thank you!
> 
> That feels wrong. Is it possible you have other leftovers somewhere? Could you try and find the root cause, in case someone else runs into that ?

@rimidalv There's no good reason `pip install deepspeech-gpu` would result in being unable to load `libdeepspeech.so` especially when `which deepspeech` is the expected python script installed when you install the package. We package `libdeepspeech.so` into the module and we set `RPATH` to make sure it's properly loaded when linking `_impl.cpython-36m-x86_64-linux-gnu.so`, so it should not fail like it did for you.",thank time fixed added path work good thank wrong possible somewhere could try find root cause case someone else good reason pip install would result unable load especially python script install package package module set make sure properly loaded linking fail like,issue,positive,positive,neutral,neutral,positive,positive
483376349,"> Thank you for your time! I fixed it. I added to my PATH all paths to libs and now all work good!!! Thank you!

That feels wrong. Is it possible you have other leftovers somewhere? Could you try and find the root cause, in case someone else runs into that ?",thank time fixed added path work good thank wrong possible somewhere could try find root cause case someone else,issue,positive,positive,neutral,neutral,positive,positive
483376062,Thank you for your time! I fixed it. I added to my PATH all paths to libs and now all work good!!! Thank you!,thank time fixed added path work good thank,issue,positive,positive,positive,positive,positive,positive
483374546,"> (deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ TFDIR=~ /tensorflow
> (deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ make deepspeech

This is wrong, you don't have `TFDIR` set when running `make deepspeech`, but again, can we focus on the root issue ?",deep deep make wrong set running make focus root issue,issue,negative,negative,negative,negative,negative,negative
483374324,"> (deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ PREFIX=/usr/local sudo make install

Can we please avoid doing unrelated steps ?",deep make install please avoid unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
483373568,Well I dont know what's going on but it's not searching in the appropriate places. ,well dont know going searching appropriate,issue,negative,positive,positive,positive,positive,positive
483371265,"I rebuild with python 3.6 and now I have got the same problem as like as I installed from pip

**(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ TFDIR=~ /tensorflow
(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ make deepspeech**
c++   -std=c++11 -o deepspeech `pkg-config --cflags sox` client.cc  -Wl,--no-as-needed -Wl,-rpath,\$ORIGIN -L/home/rimidalv/tensorflow/bazel-bin/native_client  -ldeepspeech  `pkg-config --libs sox`
**(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ cd python/
(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client/python$ cd ..
(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ PREFIX=/usr/local sudo make install**
[sudo] password for rimidalv: 
install -d /usr/local/lib
install -m 0644 /home/rimidalv/tensorflow/bazel-bin/native_client/libdeepspeech.so /usr/local/lib/
install -d /usr/local/bin
install -m 0755 deepspeech /usr/local/bin/
**(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client$ cd python/
(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client/python$ make bindings**
pip install --quiet numpy wheel==0.31.0 setuptools==39.1.0
PATH=:$PATH AS=as CC=gcc CXX=c++ LD=ld CFLAGS="" "" LDFLAGS=""-Wl,--no-as-needed '-Wl,-rpath,\$ORIGIN/lib/' -Wl,-rpath,\$ORIGIN"" MODEL_LDFLAGS=""-L/home/rimidalv/tensorflow/bazel-bin/native_client "" MODEL_LIBS=""-ldeepspeech ""   python ./setup.py build_ext 
/home/rimidalv/anaconda3/envs/deep/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'
  warnings.warn(msg)
/home/rimidalv/anaconda3/envs/deep/lib/python3.6/site-packages/setuptools/dist.py:388: UserWarning: Normalizing '0.5.0-alpha.5' to '0.5.0a5'
  normalized_version,
running build_ext
building 'deepspeech._impl' extension
swigging impl.i to impl_wrap.cpp
swig -python -c++ -keyword -o impl_wrap.cpp impl.i
creating temp_build
gcc -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/rimidalv/anaconda3/envs/deep/lib/python3.6/site-packages/numpy/core/include -I../ -I./ -I/home/rimidalv/anaconda3/envs/deep/include/python3.6m -c impl_wrap.cpp -o temp_build/impl_wrap.o
cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++
creating temp_build/deepspeech
c++ -pthread -shared -B /home/rimidalv/anaconda3/envs/deep/compiler_compat -L/home/rimidalv/anaconda3/envs/deep/lib -Wl,-rpath=/home/rimidalv/anaconda3/envs/deep/lib -Wl,--no-as-needed -Wl,--sysroot=/ -Wl,--no-as-needed -Wl,-rpath,$ORIGIN/lib/ -Wl,-rpath,$ORIGIN temp_build/impl_wrap.o -L/home/rimidalv/tensorflow/bazel-bin/native_client -ldeepspeech -o temp_build/deepspeech/_impl.cpython-36m-x86_64-linux-gnu.so
> MANIFEST.in
SRC_FILE=temp_build/deepspeech/*.so; TARGET_LIB_DIR=temp_build/deepspeech/lib; MANIFEST_IN=MANIFEST.in; echo ""Analyzing $SRC_FILE copying missing libs to $SRC_FILE""; echo ""Maybe outputting to $MANIFEST_IN""; (mkdir $TARGET_LIB_DIR || true); missing_libs=""""; for lib in $SRC_FILE; do if [ ""Linux"" = ""Darwin"" ]; then new_missing=""$( (for f in $(otool -L $lib 2>/dev/null | tail -n +2 | awk '{ print $1 }' | grep -v '$lib'); do ls -hal $f; done;) 2>&1 | grep 'No such' | cut -d':' -f2 | xargs basename -a)""; missing_libs=""$missing_libs $new_missing""; elif [ ""Linux"" = """" ]; then missing_libs=""libdeepspeech.so""; else missing_libs=""$missing_libs $(ldd  $lib | grep 'not found' | awk '{ print $1 }')""; fi; done; for missing in $missing_libs; do find /home/rimidalv/tensorflow/bazel-bin/ -type f -name ""$missing"" -exec cp {} $TARGET_LIB_DIR \; ; chmod +w $TARGET_LIB_DIR/*.so ; if [ ! -z ""$MANIFEST_IN"" ]; then echo ""include $TARGET_LIB_DIR/$missing"" >> $MANIFEST_IN; fi; done; if [ ""Linux"" = ""Darwin"" ]; then for lib in $SRC_FILE; do for dep in $( (for f in $(otool -L $lib 2>/dev/null | tail -n +2 | awk '{ print $1 }' | grep -v '$lib'); do ls -hal $f; done;) 2>&1 | grep 'No such' | cut -d':' -f2 ); do dep_basename=$(basename ""$dep""); install_name_tool -change ""$dep"" ""@rpath/$dep_basename"" ""$lib""; done; done; fi;
Analyzing temp_build/deepspeech/*.so copying missing libs to temp_build/deepspeech/*.so
Maybe outputting to MANIFEST.in
cat MANIFEST.in
include temp_build/deepspeech/lib/libdeepspeech.so
rm -f temp_build/*_wrap.o temp_build/Release/*_wrap.obj
AS=as CC=gcc CXX=c++ LD=ld CFLAGS="" "" LDFLAGS=""-Wl,--no-as-needed '-Wl,-rpath,\$ORIGIN/lib/' -Wl,-rpath,\$ORIGIN"" MODEL_LDFLAGS=""-L/home/rimidalv/tensorflow/bazel-bin/native_client "" MODEL_LIBS=""-ldeepspeech ""   python ./setup.py bdist_wheel  
/home/rimidalv/anaconda3/envs/deep/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'
  warnings.warn(msg)
/home/rimidalv/anaconda3/envs/deep/lib/python3.6/site-packages/setuptools/dist.py:388: UserWarning: Normalizing '0.5.0-alpha.5' to '0.5.0a5'
  normalized_version,
running bdist_wheel
running build
running build_ext
running build_py
file deepspeech.py (for module deepspeech) not found
copying ./__init__.py -> temp_build/deepspeech
copying ./client.py -> temp_build/deepspeech
copying ./impl.py -> temp_build/deepspeech
file deepspeech.py (for module deepspeech) not found
running egg_info
creating deepspeech.egg-info
writing deepspeech.egg-info/PKG-INFO
writing dependency_links to deepspeech.egg-info/dependency_links.txt
writing entry points to deepspeech.egg-info/entry_points.txt
writing requirements to deepspeech.egg-info/requires.txt
writing top-level names to deepspeech.egg-info/top_level.txt
writing manifest file 'deepspeech.egg-info/SOURCES.txt'
file deepspeech.py (for module deepspeech) not found
reading manifest file 'deepspeech.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
writing manifest file 'deepspeech.egg-info/SOURCES.txt'
installing to temp_build
running install
running install_lib
running install_egg_info
Copying deepspeech.egg-info to temp_build/deepspeech-0.5.0a5-py3.6.egg-info
running install_scripts
creating temp_build/deepspeech-0.5.0a5.dist-info/WHEEL
creating '/home/rimidalv/DeepSpeech/native_client/python/dist/deepspeech-0.5.0a5-cp36-cp36m-linux_x86_64.whl' and adding '.' to it
adding 'deepspeech/__init__.py'
adding 'deepspeech/_impl.cpython-36m-x86_64-linux-gnu.so'
adding 'deepspeech/client.py'
adding 'deepspeech/impl.py'
adding 'deepspeech/lib/libdeepspeech.so'
adding 'deepspeech-0.5.0a5.dist-info/entry_points.txt'
adding 'deepspeech-0.5.0a5.dist-info/top_level.txt'
adding 'deepspeech-0.5.0a5.dist-info/WHEEL'
adding 'deepspeech-0.5.0a5.dist-info/METADATA'
adding 'deepspeech-0.5.0a5.dist-info/RECORD'
removing temp_build
**(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client/python$ pip install dist/deepspeech***
Processing ./dist/deepspeech-0.5.0a5-cp36-cp36m-linux_x86_64.whl
Requirement already satisfied: numpy in /home/rimidalv/anaconda3/envs/deep/lib/python3.6/site-packages (from deepspeech==0.5.0a5) (1.15.4)
Installing collected packages: deepspeech
Successfully installed deepspeech-0.5.0a5
**(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client/python$ deepspeech -h**
deepspeech: error while loading shared libraries: libdeepspeech.so: cannot open shared object file: No such file or directory


AND

~ /tensorflow/native_client/python$ LD_DEBUG=libs deepspeech --version
     15017:	find library=libdeepspeech.so [0]; searching
     15017:	 search path=/usr/local/bin/tls/x86_64/x86_64:/usr/local/bin/tls/x86_64:/usr/local/bin/tls/x86_64:/usr/local/bin/tls:/usr/local/bin/x86_64/x86_64:/usr/local/bin/x86_64:/usr/local/bin/x86_64:/usr/local/bin		(RUNPATH from file deepspeech)
     15017:	  trying file=/usr/local/bin/tls/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/tls/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/local/bin/libdeepspeech.so
     15017:	 search cache=/etc/ld.so.cache
     15017:	 search path=/lib/x86_64-linux-gnu/tls/x86_64/x86_64:/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls/x86_64:/lib/x86_64-linux-gnu/tls:/lib/x86_64-linux-gnu/x86_64/x86_64:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu/x86_64:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu/tls/x86_64/x86_64:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls/x86_64:/usr/lib/x86_64-linux-gnu/tls:/usr/lib/x86_64-linux-gnu/x86_64/x86_64:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu/x86_64:/usr/lib/x86_64-linux-gnu:/lib/tls/x86_64/x86_64:/lib/tls/x86_64:/lib/tls/x86_64:/lib/tls:/lib/x86_64/x86_64:/lib/x86_64:/lib/x86_64:/lib:/usr/lib/tls/x86_64/x86_64:/usr/lib/tls/x86_64:/usr/lib/tls/x86_64:/usr/lib/tls:/usr/lib/x86_64/x86_64:/usr/lib/x86_64:/usr/lib/x86_64:/usr/lib		(system search path)
     15017:	  trying file=/lib/x86_64-linux-gnu/tls/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/tls/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64-linux-gnu/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/tls/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/tls/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64-linux-gnu/libdeepspeech.so
     15017:	  trying file=/lib/tls/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/tls/libdeepspeech.so
     15017:	  trying file=/lib/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/x86_64/libdeepspeech.so
     15017:	  trying file=/lib/libdeepspeech.so
     15017:	  trying file=/usr/lib/tls/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/tls/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/tls/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/x86_64/libdeepspeech.so
     15017:	  trying file=/usr/lib/libdeepspeech.so
     15017:	
deepspeech: error while loading shared libraries: libdeepspeech.so: cannot open shared object file: No such file or directory
(deep) rimidalv@rimidalv-desktop:~ /tensorflow/native_client/python$ 
",rebuild python got problem like pip deep deep make origin deep deep deep make install password install install install install deep deep make pip install quiet path origin python unknown distribution option running building extension swig warning command line option valid origin echo missing echo maybe true tail print done cut else found print fi done missing find missing echo include missing fi done tail print done cut done done fi missing maybe cat include origin python unknown distribution option running running build running running file module found file module found running writing writing writing entry writing writing writing manifest file file module found reading manifest file reading manifest template writing manifest file running install running running running removing deep pip install requirement already satisfied collected successfully deep error loading open object file file directory version find searching search file trying trying trying trying trying trying trying trying search search system search path trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying trying error loading open object file file directory deep,issue,negative,negative,neutral,neutral,negative,negative
483366599,Also paste output of `LD_DEBUG=libs deepspeech - - version` ? ,also paste output version,issue,negative,neutral,neutral,neutral,neutral,neutral
483366223,Could you try outside of anaconda? ,could try outside anaconda,issue,negative,neutral,neutral,neutral,neutral,neutral
483364252,There's something seriously wrong on your system. What's `which deepspeech`? ,something seriously wrong system,issue,negative,negative,negative,negative,negative,negative
483363267,"because it isn't work :(

For example: 
~/DeepSpeech/native_client/python$ deepspeech -h
deepspeech: error while loading shared libraries: libdeepspeech.so: cannot open shared object file: No such file or directory

or

~/DeepSpeech/native_client$ deepspeech -h
deepspeech: error while loading shared libraries: libdeepspeech.so: cannot open shared object file: No such file or directory

or

$ pip install --upgrade deepspeech-gpu==0.5.0a5
Collecting deepspeech-gpu==0.5.0a5
  Downloading https://files.pythonhosted.org/packages/ff/27/4ddcf69338bc8efe5009c4237f8f410ba781d496228f395dffbd2bc2560c/deepspeech_gpu-0.5.0a5-cp36-cp36m-manylinux1_x86_64.whl (44.3MB)
    100% |████████████████████████████████| 44.3MB 305kB/s 
Requirement already satisfied, skipping upgrade: numpy>=1.7.0 in /home/rimidalv/anaconda3/envs/deep/lib/python3.6/site-packages (from deepspeech-gpu==0.5.0a5) (1.15.4)
Installing collected packages: deepspeech-gpu
  Found existing installation: deepspeech-gpu 0.4.1
    Uninstalling deepspeech-gpu-0.4.1:
      Successfully uninstalled deepspeech-gpu-0.4.1
Successfully installed deepspeech-gpu-0.5.0a5
(deep) rimidalv@rimidalv-desktop:~/tensorflow$ deepspeech -h
deepspeech: error while loading shared libraries: libdeepspeech.so: cannot open shared object file: No such file or directory

",work example error loading open object file file directory error loading open object file file directory pip install upgrade requirement already satisfied skipping upgrade collected found installation successfully uninstalled successfully deep error loading open object file file directory,issue,negative,positive,positive,positive,positive,positive
483362199,Please make sure you build a matching version and/or use `pip install - - upgrade deepspeech-gpu==0.5.0a5`,please make sure build matching version use pip install upgrade,issue,positive,positive,positive,positive,positive,positive
483359637,"According to your pip install of deepspeech-gpu this is python 3.6 and you try to install 3.7 build, that's not going to work. We already have 0.5.0a5 available on pypi why do you need to rebuild? ",according pip install python try install build going work already available need rebuild,issue,negative,positive,positive,positive,positive,positive
483287184,"The probability field is a log probability of the entire transcription according to CTC only, with LM scoring removed. Its value should probably not be interpreted directly, but rather be used only when comparing two transcriptions given by the same model/LM setup.",probability field log probability entire transcription according scoring removed value probably directly rather used two given setup,issue,negative,positive,neutral,neutral,positive,positive
483285791,"* The entire transcript probability
* Python access is in the process of being exposed in PR #2022 which addresses issue #2006 ",entire transcript probability python access process exposed issue,issue,negative,neutral,neutral,neutral,neutral,neutral
483130462,As documented [here](https://github.com/mozilla/deepspeech#getting-the-code) you need to use Git Large File Storage to check out the code.,need use git large file storage check code,issue,negative,positive,positive,positive,positive,positive
483054586,"Very strange. 
I cloned the project to users home folder and now all works good. ",strange project home folder work good,issue,negative,positive,positive,positive,positive,positive
483048061,"I think something is wrong with the way you're setting the TFDIR variable. In your shell it points to /home/rimidalv/tensorflow, but in the error it points to /home/rimidalv/Projects/ML/tensorflow.",think something wrong way setting variable shell error,issue,negative,negative,negative,negative,negative,negative
483046885,"The Makefile will look for libdeepspeech.so inside $TFDIR/bazel-bin/native_client. If that file is not there, it means something went wrong with your libdeepspeech.so build, so double check there.",look inside file something went wrong build double check,issue,negative,negative,negative,negative,negative,negative
483046590,"> You have to set the TFDIR variable as documented: https://github.com/mozilla/DeepSpeech/tree/master/native_client/#compile-language-bindings

I have already had TFDIR:```

(deep) rimidalv@rimidalv-desktop: ~/tensorflow/native_client$ $TFDIR
bash: /home/rimidalv/tensorflow: Is a directory
(deep) rimidalv@rimidalv-desktop:~/tensorflow/native_client$ make deepspeech 
c++   -std=c++11 -o deepspeech `pkg-config --cflags sox` client.cc  -Wl,--no-as-needed -Wl,-rpath,\$ORIGIN -L/home/rimidalv/Projects/ML/tensorflow/bazel-bin/native_client  -ldeepspeech  `pkg-config --libs sox`
/usr/bin/ld: cannot find -ldeepspeech
collect2: error: ld returned 1 exit status
Makefile:22: recipe for target 'deepspeech' failed
make: *** [deepspeech] Error 1
(deep) rimidalv@rimidalv-desktop:~/tensorflow/native_client$
```
",set variable already deep bash directory deep make origin find collect error returned exit status recipe target make error deep,issue,negative,neutral,neutral,neutral,neutral,neutral
483023133,"I had a similar problem - my model was created with an four-months old version of deepspeech, re-exporting with recent version failed due to name changes of some variables. Specifically, changes from bx and hx to layer_x/bias and layer_x/weights.

Making some changes on DeepSpeech.py, function dense(...), running it for re-exporting on that old checkpoint just solved the issue for me. Below is my code, maybe it helps you.

```
def dense(name, x, units, dropout_rate=None, relu=True):
    #BEGIN change
    #with tf.variable_scope(name):
    new_name_1 = 'bias'
    new_name_2 = 'weights'
    try:
        var = int(name[-1])  #Checking whether the scope 'name' is of form layer_<int>
        new_name_1 = 'b' + str(var)
        new_name_2 = 'h' + str(var)
    except:
        new_name_1 = 'bias'
        new_name_2 = 'weights'
    bias = variable_on_cpu(new_name_1, [units], tf.zeros_initializer())
    weights = variable_on_cpu(new_name_2, [x.shape[-1], units], tf.contrib.layers.xavier_initializer())
    #END change

    output = tf.nn.bias_add(tf.matmul(x, weights), bias)

    if relu:
        output = tf.minimum(tf.nn.relu(output), FLAGS.relu_clip)

    if dropout_rate is not None:
        output = tf.nn.dropout(output, rate=dropout_rate)

    return output
```",similar problem model old version recent version due name specifically making function dense running old issue code maybe dense name begin change name try name whether scope form except bias end change output bias output output none output output return output,issue,negative,positive,neutral,neutral,positive,positive
482998498,Take a look at the existing mapping logic we have to load LSTMFusedCell variables into a normal LSTMCell.,take look logic load normal,issue,negative,positive,positive,positive,positive,positive
482998258,"`--notrain`, `--nodev` and `--notest` were removed in favor of just checking if `{train,dev,test}_files` were specified. You're misunderstanding the problem here, it's not that it's failing because it's trying to train first. The training and export graph are independent, the export graph is built from scratch every time, regardless if you trained or not during the run. The problem here is that some of the variables were renamed between 0.4.1 and master, so it's trying to load the variables from checkpoint and not finding them there. Specifying a custom mapping to the Saver object to map the old names to the new ones should let you export.",removed favor train dev test misunderstanding problem failing trying train first training export graph independent export graph built scratch every time regardless trained run problem master trying load finding custom saver object map old new let export,issue,negative,positive,positive,positive,positive,positive
482991638,"Nope, still the same error. I noticed in the commit history that the train/test options were recently removed and training / testing is now controlled by whether or not the user has specified the --train_files or --test_files arguments.",nope still error commit history recently removed training testing whether user,issue,negative,neutral,neutral,neutral,neutral,neutral
482948110,Can you try with - - notrain - - notest? It usually worked pretty well ,try usually worked pretty well,issue,positive,neutral,neutral,neutral,neutral,neutral
482883123,"We try to include notable changes with the release notes when we do a release. We haven't done any releases since that change landed, so it's not listed anywhere yet. It's an unfortunate side effect if you're tracking master, you gotta keep an eye on the commit log!",try include notable release release done since change landed listed anywhere yet unfortunate side effect master got ta keep eye commit log,issue,negative,neutral,neutral,neutral,neutral,neutral
482853952,"ok, perfect then, when you do updates like this, is there a note with the changes somewhere?
Thanks a lot!",perfect like note somewhere thanks lot,issue,positive,positive,positive,positive,positive,positive
482847466,"Yes, this is expected. Due to the new tf.data input pipeline, we don't know the size of the dataset upfront, so there's no way to compute an ETA.",yes due new input pipeline know size way compute eta,issue,negative,positive,neutral,neutral,positive,positive
482777858,"In theory this is complete, except I can't actually test it due to this issue:
https://discourse.mozilla.org/t/upgrading-pre-trained-model-to-version-1/38220",theory complete except ca actually test due issue,issue,negative,negative,neutral,neutral,negative,negative
482478053,"Ahh... It's my fool. Yes, I forgot to checkout the branch.
Thank you @kdavis-mozilla , it's the master branch.",fool yes forgot branch thank master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
482243854,"@carlfm01 I'm gonna merge as this is just shuffling of files around, but keep the review flag so you're aware of the change.",gon na merge shuffling around keep review flag aware change,issue,negative,positive,positive,positive,positive,positive
482136181,"Turns out numpy.i already allows input arrays to be anything that can be converted to the specified type, including a list of lists or a list of np.array.",turn already input anything converted type list list,issue,negative,neutral,neutral,neutral,neutral,neutral
482102770,@carlfm01 I might need your help for .Net as well,might need help well,issue,positive,neutral,neutral,neutral,neutral,neutral
482071652,"And answering the question directly, no, there's no easy way to calculate it directly.",question directly easy way calculate directly,issue,negative,positive,positive,positive,positive,positive
482071535,"You can flip the sort order in `util/feeding.py` so that the largest files go in the first batch, then you should see OOM errors much faster. The problem is that by having a few super long files, you're hurting the performance of your entire training run, as the batch size is fixed for the whole epoch, so it has to accommodate for the largest samples in the dataset.

Consider looking through your data and removing or splitting super long samples.",flip sort order go first batch see much faster problem super long hurting performance entire training run batch size fixed whole epoch accommodate consider looking data removing splitting super long,issue,positive,positive,positive,positive,positive,positive
482059380,"Is there any way to calculate batch size. On my instance with CPU i have 32GB of memory, and with batch sizes 12:8:8 there is no ResourceExhaustedError on same dataset. Is batch sizes 3:2:2 is fit for GPU with 8GB of memory, or it is only possible to calculate it by practical consideration?",way calculate batch size instance memory batch size batch size fit memory possible calculate practical consideration,issue,negative,positive,positive,positive,positive,positive
482058808,"It looks like you're basing off an old version of master that no longer merges cleanly. In latest master, the dependencies are already grouped and commented in a different way, so closing this.",like old version master longer cleanly latest master already grouped different way,issue,negative,positive,positive,positive,positive,positive
482057568,You are running out of memory on your GPU as it has access to less memory than your CPU.,running memory access le memory,issue,negative,neutral,neutral,neutral,neutral,neutral
482057510,"Validation epochs are normally so fast that I don't think I've ever actually cached them in runs, so I can't give you numbers, but that goes to show that it probably does not make a huge difference :)

As for test epochs, the acoustic model prediction is usually done in the same time as the validation sets, it's the decoding that takes the majority of the time.",validation normally fast think ever actually ca give go show probably make huge difference test acoustic model prediction usually done time validation majority time,issue,negative,positive,neutral,neutral,positive,positive
482002957,"Consider not training on any clips over 10 seconds. I think that, and selecting a reasonable batch size, should solve this problem.",consider training clip think reasonable batch size solve problem,issue,negative,positive,positive,positive,positive,positive
481991863,"I second @reuben here, I don't see the point and it's duplicating build steps and documentation that we will forget to update.",second see point build documentation forget update,issue,negative,neutral,neutral,neutral,neutral,neutral
481985570,"@xpowerman Two questions:

- Are you still using ""n_hidden 2048"" or something bigger?
- What's the longest, in seconds, audio clip you are training on?",two still something bigger audio clip training,issue,negative,neutral,neutral,neutral,neutral,neutral
481956683,"So, I reduce train batch size from 12 to 6, dev and test batch size from 8 to 4. And after 0 epoch have same error.

```
Use standard file APIs to delete files with this prefix.
Epoch 0 | Elapsed Time: 2:50:23 | Steps: 4607 | Loss: 87.997542                                                                                                                                            T
raceback (most recent call last):
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[36930,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node tower_0/MatMul_4}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[{{node tower_0/gradients/tower_0/lstm_fused_cell/BlockLSTM_grad/BlockLSTMGrad}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./DeepSpeech/DeepSpeech.py"", line 833, in <module>
    tf.app.run(main)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./DeepSpeech/DeepSpeech.py"", line 817, in main
    train()
  File ""./DeepSpeech/DeepSpeech.py"", line 511, in train
    train_loss = run_set('train', train_init_op)
  File ""./DeepSpeech/DeepSpeech.py"", line 482, in run_set
    feed_dict=feed_dict)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[36930,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node tower_0/MatMul_4 (defined at ./DeepSpeech/DeepSpeech.py:68) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[node tower_0/gradients/tower_0/lstm_fused_cell/BlockLSTM_grad/BlockLSTMGrad (defined at ./DeepSpeech/DeepSpeech.py:261) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

Caused by op 'tower_0/MatMul_4', defined at:
  File ""./DeepSpeech/DeepSpeech.py"", line 833, in <module>
    tf.app.run(main)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./DeepSpeech/DeepSpeech.py"", line 817, in main
    train()
  File ""./DeepSpeech/DeepSpeech.py"", line 400, in train
    gradients, loss = get_tower_results(iterator, optimizer, dropout_rates)
  File ""./DeepSpeech/DeepSpeech.py"", line 252, in get_tower_results
    avg_loss = calculate_mean_edit_distance_and_loss(iterator, i, dropout_rates, reuse=i>0)
  File ""./DeepSpeech/DeepSpeech.py"", line 185, in calculate_mean_edit_distance_and_loss
    logits, _ = create_model(batch_x, batch_seq_len, dropout, reuse=reuse)
  File ""./DeepSpeech/DeepSpeech.py"", line 153, in create_model
    layers['layer_6'] = layer_6 = dense('layer_6', layer_5, Config.n_hidden_6, relu=False)
  File ""./DeepSpeech/DeepSpeech.py"", line 68, in dense
    output = tf.nn.bias_add(tf.matmul(x, weights), bias)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 2455, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 5333, in mat_mul
    name=name)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[36930,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node tower_0/MatMul_4 (defined at ./DeepSpeech/DeepSpeech.py:68) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[node tower_0/gradients/tower_0/lstm_fused_cell/BlockLSTM_grad/BlockLSTMGrad (defined at ./DeepSpeech/DeepSpeech.py:261) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
```
Is there some way or formula to calculate batch size for my environment, or a reason of this error not a batch size?",reduce train batch size dev test batch size epoch error use standard file delete prefix epoch time loss recent call last file line return file line file line tensor shape type float allocator node hint want see list add current allocation node hint want see list add current allocation handling exception another exception recent call last file line module main file line run main file line main train file line train file line file line run file line file line file line raise type message tensor shape type float allocator node defined hint want see list add current allocation node defined hint want see list add current allocation defined file line module main file line run main file line main train file line train loss file line file line dropout file line dense file line dense output bias file line file line file line file line return file line file line see tensor shape type float allocator node defined hint want see list add current allocation node defined hint want see list add current allocation way formula calculate batch size environment reason error batch size,issue,negative,positive,neutral,neutral,positive,positive
481923962,"@reuben ---  please take a look at `native_client/README.md` again. I caught some issues we missed earlier.

All of your reviews/comments were integrated already.

",please take look caught already,issue,negative,neutral,neutral,neutral,neutral,neutral
481917559,"It's also yet another place where we'll have to maintain TensorFlow and Bazel versions and dependencies as well as TensorFlow configure script variables. We already have a Dockerfile that builds everything, and even works on macOS. Can we make it more useful somehow?",also yet another place maintain well configure script already everything even work make useful somehow,issue,positive,positive,positive,positive,positive,positive
481916602,"@kdavis-mozilla @reuben --- In general, I think this script is very useful, but at the same time it is very limited in scope.

This will only work for Linux systems (only debian?), and there's some hard coded links to `TensorFlow` and `Bazel`.

Thoughts?",general think script useful time limited scope work hard link,issue,negative,negative,neutral,neutral,negative,negative
481846400,"Okay I'm looking forward to it, and will try it out as soon as it's released.  Thanks for all the help.",looking forward try soon thanks help,issue,positive,positive,positive,positive,positive,positive
481810612,"> But is there any ETA for this new 0.5 version?

Not yet",eta new version yet,issue,negative,positive,positive,positive,positive,positive
481773835,"> But is there any ETA for this new 0.5 version?

I think biggest blocker is on my end with the exposure of metadata struct to bindings, JS and Python have a working solution but not yet Java.",eta new version think biggest blocker end exposure python working solution yet,issue,negative,positive,positive,positive,positive,positive
481769347,"No problem, I'm not quite confident enough that I'll be able to figure it out on my own so I don't mind waiting.  But is there any ETA for this new 0.5 version?",problem quite confident enough able figure mind waiting eta new version,issue,negative,positive,positive,positive,positive,positive
481762399,"We don't release model files with alpha releases, but yes, new models will be required. You may be able to re-export the 0.4.1 models with the latest code to get a working model, but we haven't tried it yet and don't know how hard it would be.",release model alpha yes new may able latest code get working model tried yet know hard would,issue,negative,positive,positive,positive,positive,positive
481761849,"Will a new set of 0.5-alpha model files be required?  The files in deepspeech-0.4.1-models.tar.gz is giving me this error:

```
TensorFlow: v1.13.1-10-g3e0cc5374d
DeepSpeech: v0.5.0-alpha.4-92-gdcee783
2019-04-10 12:21:04.963447: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-10 12:21:04.975890: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2019-04-10 12:21:04.975922: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-04-10 12:21:04.975934: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-04-10 12:21:04.975944: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
Specified model file version (0) is incompatible with minimum version supported by this client (1). See https://github.com/mozilla/DeepSpeech/#model-compatibility for more information

/deepspeech-node/index.js:28
        throw ""CreateModel failed with error code "" + status;
        ^
CreateModel failed with error code 8195
```",new set model giving error binary use unknown unknown unknown unknown model file version incompatible minimum version client see information throw error code status error code,issue,negative,negative,neutral,neutral,negative,negative
481707589,"Great work @lissyx I downloaded that package and yeah it looks like it's working so far.  I have some more code to load in but this is going to be really awesome.  If you're curious what I'm doing with it, I'm using an electron app so I can connect DeepSpeech to web pages (client-side) through a web browser extension.  Not sure if anyone has thought to do this but so far it's working reasonably well.",great work package yeah like working far code load going really awesome curious electron connect web web browser extension sure anyone thought far working reasonably well,issue,positive,positive,positive,positive,positive,positive
481697453,"> @lissyx Terrific! Unfortunately I don't have a quick way to test this out yet because I don't have DeepSpeech and TensorFlow compiling locally but I'll probably work on it today.

Well in a few minutes you should be able to see a working package at https://tools.taskcluster.net/groups/OLINF0wXR8uzo0aF8cirPQ/tasks/bVVTsw2oTsuRgKiBdnbWaA/runs/0/artifacts

I still have a few changes to push to add more test coverage, but assuming this will go smoothly on v3.8, v4.0 for linux/macOS/windows, we should be able to merge today",terrific unfortunately quick way test yet locally probably work today well able see working package still push add test coverage assuming go smoothly able merge today,issue,negative,positive,positive,positive,positive,positive
481696281,@lissyx Terrific! Unfortunately I don't have a quick way to test this out yet because I don't have DeepSpeech and TensorFlow compiling locally but I'll probably work on it today.,terrific unfortunately quick way test yet locally probably work today,issue,negative,positive,positive,positive,positive,positive
481636562,"> shape[36048,35]

Can you try reducing batch size? Your GPU has only 8GB of memory, that might explain.",shape try reducing batch size memory might explain,issue,negative,neutral,neutral,neutral,neutral,neutral
481635955,"So, I update to latest master, change `--epoch` to `--epochs`, and run training again. It finish 0 epoch with error:

```
Use standard file APIs to delete files with this prefix.
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
    train_loss = run_set('train', train_init_op)
    run_metadata)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[36048,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node tower_0/MatMul_4 (defined at ./DeepSpeech/DeepSpeech.py:68) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[node tower_0/gradients/tower_0/lstm_fused_cell/BlockLSTM_grad/BlockLSTMGrad (defined at ./DeepSpeech/DeepSpeech.py:261) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


Caused by op 'tower_0/MatMul_4', defined at:
  File ""./DeepSpeech/DeepSpeech.py"", line 833, in <module>
    tf.app.run(main)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./DeepSpeech/DeepSpeech.py"", line 817, in main
    train()
  File ""./DeepSpeech/DeepSpeech.py"", line 400, in train
    gradients, loss = get_tower_results(iterator, optimizer, dropout_rates)
  File ""./DeepSpeech/DeepSpeech.py"", line 252, in get_tower_results
    avg_loss = calculate_mean_edit_distance_and_loss(iterator, i, dropout_rates, reuse=i>0)
  File ""./DeepSpeech/DeepSpeech.py"", line 185, in calculate_mean_edit_distance_and_loss
    logits, _ = create_model(batch_x, batch_seq_len, dropout, reuse=reuse)
  File ""./DeepSpeech/DeepSpeech.py"", line 153, in create_model
    layers['layer_6'] = layer_6 = dense('layer_6', layer_5, Config.n_hidden_6, relu=False)
  File ""./DeepSpeech/DeepSpeech.py"", line 68, in dense
    output = tf.nn.bias_add(tf.matmul(x, weights), bias)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 2455, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 5333, in mat_mul
    name=name)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[36048,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node tower_0/MatMul_4 (defined at ./DeepSpeech/DeepSpeech.py:68) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[node tower_0/gradients/tower_0/lstm_fused_cell/BlockLSTM_grad/BlockLSTMGrad (defined at ./DeepSpeech/DeepSpeech.py:261) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

```
And exit.",update latest master change epoch run training finish epoch error use standard file delete prefix hint want see list add current allocation file line raise type message tensor shape type float allocator node defined hint want see list add current allocation node defined hint want see list add current allocation defined file line module main file line run main file line main train file line train loss file line file line dropout file line dense file line dense output bias file line file line file line file line return file line file line see tensor shape type float allocator node defined hint want see list add current allocation node defined hint want see list add current allocation exit,issue,negative,positive,neutral,neutral,positive,positive
481634030,"We can build for a lot of ElectronJS flavors, but I suggest we stick with testing at least linux/macOS/windows on amd64. We can try and add more testing later, depending on people's usecases and feedback.",build lot suggest stick testing least try add testing later depending people feedback,issue,negative,negative,negative,negative,negative,negative
481631782,"So far Python and NodeJS should be okay, still have to take care of Java ...",far python still take care,issue,negative,positive,neutral,neutral,positive,positive
481628906,"Seems to work here:
```
alex@portable-alex:~/tmp/deepspeech/0.5.0a5$  node_modules/electron/dist/electron node_modules/deepspeech/client.js --version
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.5-5-g8fa3551
Runtime: Electron
alex@portable-alex:~/tmp/deepspeech/0.5.0a5$ node_modules/electron/dist/electron node_modules/deepspeech/client.js --model ../output_graph_test.pbmm --audio ../test-alex.en.wav --alphabet ../models/alphabet.txt 
Loading model from file ../output_graph_test.pbmm
TensorFlow: v1.13.1-10-g3e0cc53
DeepSpeech: v0.5.0-alpha.5-5-g8fa3551
2019-04-10 12:09:48.412286: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-10 12:09:48.416918: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2019-04-10 12:09:48.416941: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2019-04-10 12:09:48.416950: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2019-04-10 12:09:48.416997: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
Loaded model in 0.006207s.
Running inference.
she ha h h h h harea e eaha e h h h ha
Inference took 0.3959s for 3.625s audio file.
process.versions.electron=4.1.1
```",work version electron model audio alphabet loading model file binary use unknown unknown unknown unknown loaded model running inference ha ha inference took audio file,issue,positive,negative,neutral,neutral,negative,negative
481591862,"Looks like adding `'use strict';` does not help. And I'm reluctant poking around `node-pre-gyp` dependencies to force it to an older version.

@reuben Maybe it's time to remove NodeJS v4 and v5 ?",like strict help reluctant poking around force older version maybe time remove,issue,negative,positive,positive,positive,positive,positive
481579066,"Ok @dsteinman I got it, one also need to give proper download URL so in the previous patch you need to add a `$(NODE_DIST_URL)` and add that to the `make` call: `NODE_DIST_URL=--disturl=https://atom.io/download/electron`

Then I don't have any error but I'm facing a big issue: I don't know how to test that. We can likely quickly add build for many versions of ElecronJS, but so far you should not expect ""support"". If you can send PR for a test, it would be helpful.",got one also need give proper previous patch need add add make call error facing big issue know test likely quickly add build many far expect support send test would helpful,issue,negative,positive,positive,positive,positive,positive
481571332,"At runtime, though:
```
$  node_modules/electron/dist/electron node_modules/deepspeech/index.js 
App threw an error during load
Error: The module '/home/alex/tmp/deepspeech/0.5.0a5/node_modules/deepspeech/lib/binding/v0.5.0-alpha.5/linux-x64/electron-v4.1/deepspeech.node'
was compiled against a different Node.js version using
NODE_MODULE_VERSION 46. This version of Node.js requires
NODE_MODULE_VERSION 69. Please try re-compiling or re-installing
```",though threw error load error module different version version please try,issue,negative,neutral,neutral,neutral,neutral,neutral
481562737,"@dsteinman So I don't have an electron runtime but: `native_client/javascript/lib/binding/v0.5.0-alpha.5/linux-x64/electron-v4.1/deepspeech.node`

```
diff --git a/native_client/javascript/Makefile b/native_client/javascript/Makefile
index 54e39d9..87ad53e 100644
--- a/native_client/javascript/Makefile
+++ b/native_client/javascript/Makefile
@@ -36,13 +36,13 @@ configure: deepspeech_wrap.cxx package.json
        $(NODE_BUILD_TOOL) configure $(NODE_BUILD_VERBOSE)
 
 build: configure deepspeech_wrap.cxx
-       AS=$(AS) CC=$(CC) CXX=$(CXX) LD=$(LD) CFLAGS=""$(CFLAGS)"" CXXFLAGS=""$(CXXFLAGS)"" LDFLAGS=""$(RPATH_NODEJS) $(LDFLAGS)"" LIBS=$(LIBS) $(NODE_BUILD_TOOL) $(NODE_PLATFORM_TARGET) $(NODE_ABI_TARGET) rebuild $(NODE_BUILD_VERBOSE)
+       AS=$(AS) CC=$(CC) CXX=$(CXX) LD=$(LD) CFLAGS=""$(CFLAGS)"" CXXFLAGS=""$(CXXFLAGS)"" LDFLAGS=""$(RPATH_NODEJS) $(LDFLAGS)"" LIBS=$(LIBS) $(NODE_BUILD_TOOL) $(NODE_PLATFORM_TARGET) $(NODE_RUNTIME) $(NODE_ABI_TARGET) rebuild $(NODE_BUILD_VERBOSE)
 
 copy-deps: build
        $(call copy_missing_libs,lib/binding/*/*/*/deepspeech.node,lib/binding/*/*/)
 
 node-wrapper: copy-deps build
-       $(NODE_BUILD_TOOL) $(NODE_PLATFORM_TARGET) $(NODE_ABI_TARGET) package $(NODE_BUILD_VERBOSE)
+       $(NODE_BUILD_TOOL) $(NODE_PLATFORM_TARGET) $(NODE_RUNTIME) $(NODE_ABI_TARGET) package $(NODE_BUILD_VERBOSE)
 
 npm-pack: clean package.json README.md index.js
        npm install node-pre-gyp@0.12.x
```

and then:
```
$ PATH=$HOME/node_modules/.bin/:$PATH make -C native_client/javascript/ TFDIR=/home/alex/tmp/deepspeech/0.5.0a5 NODE_RUNTIME=--runtime=electron NODE_ABI_TARGET=--target=4.1.0 clean node-wrapper clean npm-pack
```",electron git index ade configure configure build configure rebuild rebuild build call build package package clean install path make clean clean,issue,positive,positive,positive,positive,positive,positive
481447138,"Is suspect the breakage comes from `needle` v2.3.0 released 9 hours ago, and that pulled an update of `debug` package: https://github.com/tomas/needle/commit/78309e5543f9491e25198300a053ceae772b41a2",suspect breakage come needle ago update package,issue,negative,neutral,neutral,neutral,neutral,neutral
481425541,"@lissyx I appreciate the help, yes I think indeed adding the right node-gyp variables in the right place within the DeepSpeech build tools could do the trick, I found this as well:

https://electronjs.org/docs/tutorial/using-native-node-modules

```
Usually those modules work fine under Electron, but sometimes when Electron uses a newer version of V8 than Node, and there are ABI changes, bad things may happen. So in general it is recommended to always build native modules from source code.
```",appreciate help yes think indeed right right place within build could trick found well usually work fine electron sometimes electron version node bad may happen general always build native source code,issue,positive,positive,neutral,neutral,positive,positive
481420343,"@dsteinman https://github.com/mapbox/node-pre-gyp/issues/437#issuecomment-456422192 According to that comment, then we could pass `--runtime=electron` to `node-pre-gyp` with the suggestions from above. Hoping that the `SWIG`-generated bindings are good as well ...",according comment could pas swig good well,issue,positive,positive,positive,positive,positive,positive
481416788,@dsteinman https://electronjs.org/releases/stable#release-notes-for-v410 Can you try and find more informations about that: `Electron 4.1.0 was released to work around issues users were experiencing with node-pre-gyp based native modules and our ABI number in Electron >= 4.0.4.` ?,try find electron work around based native number electron,issue,negative,neutral,neutral,neutral,neutral,neutral
481414490,"> And I also tried Electron 3.1.8, which wants node-v64, but then that fails for a different reason:

On the bug you linked it seemed they followed different ABI, that might explain it

> I haven't tried to compile DeepSpeech manually, but at this point I don't think that's going to matter unless I know how to link the deepspeech.node in electron.

No need to rebuild `libdeepspeech.so`, and I already gave you hints on how you might want to try for `deepspeech.node` with v69. It's also possible `swig` will not be a good friend here",also tried electron different reason bug linked different might explain tried compile manually point think going matter unless know link electron need rebuild already gave might want try also possible swig good friend,issue,positive,positive,positive,positive,positive,positive
481400617,"@reuben perhaps, it looks like some other way to do this linking may be required for Electron support.

Downgrading Electron has also not been successful.  Both Electron v4.0.3 and v4.0.0 want to link against node-v69 for some reason.

And I also tried Electron 3.1.8, which wants node-v64, but then that fails for a different reason:

```
[0] Starting the development server...
[0] 
[1] Debugger listening on ws://127.0.0.1:5858/74a3b116-e716-465c-bc61-91430f2ac313
[1] For help, see: https://nodejs.org/en/docs/inspector
[1] dyld: lazy symbol binding failed: Symbol not found: __ZN2v816FunctionTemplate3NewEPNS_7IsolateEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS_5LocalIS4_EENSA_INS_9SignatureEEEiNS_19ConstructorBehaviorENS_14SideEffectTypeE
[1]   Referenced from: electron-app/node_modules/deepspeech/lib/binding/v0.4.1/darwin-x64/node-v64/deepspeech.node
[1]   Expected in: flat namespace
[1] 
[1] dyld: Symbol not found: __ZN2v816FunctionTemplate3NewEPNS_7IsolateEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS_5LocalIS4_EENSA_INS_9SignatureEEEiNS_19ConstructorBehaviorENS_14SideEffectTypeE
[1]   Referenced from: electron-app/node_modules/deepspeech/lib/binding/v0.4.1/darwin-x64/node-v64/deepspeech.node
[1]   Expected in: flat namespace
```

I did previously have this working with Electron 2.0.2 and node-v57 but these are too old and have vulnerabilities.

I haven't tried to compile DeepSpeech manually, but at this point I don't think that's going to matter unless I know how to link the deepspeech.node in electron.",perhaps like way linking may electron support electron also successful electron want link reason also tried electron different reason starting development server listening help see lazy symbol binding symbol found flat symbol found flat previously working electron old tried compile manually point think going matter unless know link electron,issue,positive,positive,neutral,neutral,positive,positive
481395222,"From the linked issue there it seems like Electron is moving to their own ABI version, separate from Node.JS, and next Node releases won't fix it? Or am I reading it incorrectly?",linked issue like electron moving version separate next node wo fix reading incorrectly,issue,negative,neutral,neutral,neutral,neutral,neutral
481376827,"> If there's no way to update Deepspeech to 69 right now I'll just downgrade my version of Electron and find a version which ships with v67.

Maybe worth you give a try to what I suggested, otherwise we have to wait for next NodeJS release.",way update right downgrade version electron find version maybe worth give try otherwise wait next release,issue,negative,positive,positive,positive,positive,positive
481370363,"Okay it didn't occur to me that Electron could actually be ahead of NodeJS in terms of these module numbers.  I did a google search and I did find some hits on this same issue.

If there's no way to update Deepspeech to 69 right now I'll just downgrade my version of Electron and find a version which ships with v67.",occur electron could actually ahead module search find issue way update right downgrade version electron find version,issue,negative,positive,positive,positive,positive,positive
481369561,"@dsteinman Here: https://github.com/mapbox/node-pre-gyp/blob/master/lib/util/abi_crosswalk.json there's no `v69` either, but maybe you can add it manually and hope it will work, except I have no idea about the matching `v8`, and there might be other sites to update.",either maybe add manually hope work except idea matching might update,issue,negative,neutral,neutral,neutral,neutral,neutral
481368967,"@dsteinman You can try to just rebuild, there's the `make` call here, you might not need everything, basically just the proper node verison: https://github.com/mozilla/DeepSpeech/blob/master/tc-tests-utils.sh#L1105-L1110

Followed by that other `make` call: https://github.com/mozilla/DeepSpeech/blob/master/tc-tests-utils.sh#L1116

You should download latest stable native_client.tar.xz and create `bazel-bin/native_client/` directory where you place `libdeepspeech`. Then in both of the above `make specify `TFDIR=` with the path containing your `bazel-bin/`.

I can't promise that `node-gyp` and `node-pre-gyp` will be happy about this `v69` since they also have some mapping, but maybe you can start from here and get there.",try rebuild make call might need everything basically proper node make call latest stable create directory place make specify path ca promise happy since also maybe start get,issue,positive,positive,positive,positive,positive,positive
481367763,"> So I'm guessing 2 additional lines should be added:
> 
> prep_12: 'nvm install 10.15.2 && nvm use 10.15.0'
> prep_13: 'nvm install 11.13.0 && nvm use 11.13.0'

Those are fine, the `NODE_MODULE_VERSION` is the same as the ones we currently have.",guessing additional added install use install use fine currently,issue,negative,positive,positive,positive,positive,positive
481366994,"> How else could NPM could be giving me the error ""This version of Node.js requires [1] NODE_MODULE_VERSION 69"" if v69 does not exist?

I can't do divination ... But you mention electron. Maybe they have more recent `NODE_MODULE_VERSION` ?",else could could giving error version exist ca divination mention electron maybe recent,issue,negative,neutral,neutral,neutral,neutral,neutral
481366011,"Is it possible that list is wrong or out of date?

How else could NPM could be giving me the error ""This version of Node.js requires [1] NODE_MODULE_VERSION 69"" if v69 does not exist?",possible list wrong date else could could giving error version exist,issue,negative,negative,negative,negative,negative,negative
481287531,Please use the Discourse forums for things that aren't bugs or feature requests.,please use discourse feature,issue,negative,neutral,neutral,neutral,neutral,neutral
481248570,Please update to latest master and try again.,please update latest master try,issue,negative,positive,positive,positive,positive,positive
481237778,"The underlying problem is being masked by tf.train.Coordinator.stop_on_exception(). Please update to latest master and re-run to check. Also, the flags is now called `--epochs`, not `--epoch`.",underlying problem masked please update latest master check also epoch,issue,negative,positive,positive,positive,positive,positive
481237589,"> So, it train single epoch, export model and finished(but --epoch is set to 25)

There's no error at all here, and the loss values would suggest that early stop did its work. At the expense of repeating myself, can you make sure of it by disabling early stop?",train single epoch export model finished epoch set error loss would suggest early stop work expense make sure early stop,issue,negative,positive,positive,positive,positive,positive
481228971,"Here is current script body:

```
$ cat ./scripts/train_model.sh 
#!/bin/sh


python -u ./DeepSpeech/DeepSpeech.py \
  --train_files $1/train/train.csv \
  --dev_files $1/dev/dev.csv \
  --test_files $1/test/test.csv \
  --train_batch_size 12 \
  --dev_batch_size 8 \
  --test_batch_size 8 \
  --n_hidden 2048 \
  --epoch 25 \
  --learning_rate 0.0001 \
  --display_step 0 \
  --validation_step 1 \
  --dropout_rate 0.2367 \
  --default_stddev 0.046875 \
  --checkpoint_step 1 \
  --loglevel 0 \
  --wer_log_pattern ""GLOBAL LOG: logwer('${COMPUTE_ID}', '%s', '%s', %f)"" \
  --checkpoint_dir $1/checkpoints/ \
  --export_dir $1/results/model_export/ \
  --alphabet_config_path $1/alphabet.txt \
  --lm_binary_path $1/lm.binary \
  --lm_trie_path $1/trie \
  ""$@""

```
Ensure that there are no checkpoint dir:

```
$ ls /opt/deepspeech/datasets/ru
alphabet.txt  dev  lm.binary  stat  test  train  trie  vocabulary.txt  words.arpa
```

Starting script:

```
$ ./scripts/train_model.sh /opt/deepspeech/datasets/ru
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, use
    tf.py_function, which takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
I Initializing...
I STARTING Optimization
I STARTING Optimization
I Training epoch 0 ...
 81% (1885 of 2306) |###############################################################################################################                          | Elapsed Time: 1:00:01 ETA:   0:22:31WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
 99% (2295 of 2306) |######################################################################################################################################## | Elapsed Time: 1:26:36 ETA:   0:02:37WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
Computing acoustic model predictions...                                                                                                                                                             
100% (494 of 494) |###########################################################################################################################################| Elapsed Time: 0:05:06 Time:  0:05:06
Decoding predictions...                                                                                                                                                                             
100% (494 of 494) |###########################################################################################################################################| Elapsed Time: 0:16:13 Time:  0:16:13
Test - WER: 1.000264, CER: 0.803587, loss: 101.817192                                                                                                                                               
 99% (2295 of 2306) |######################################################################################################################################## | Elapsed Time: 1:48:30 ETA:   4:03:25WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
--------------------------------------------------------------------------------                                                                                                                    
WER: 7.000000, CER: 25.000000, loss: 259.393799
 - src: ""бергли""
 - res: ""та а с сен не от гсенеедстю""
--------------------------------------------------------------------------------
WER: 6.000000, CER: 11.000000, loss: 48.537945
 - src: ""арестантам""
 - res: ""а а с кое ста а""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 4.749997
 - src: ""заплакал""
 - res: ""а та та""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 5.000000, loss: 5.031825
 - src: ""леонато""
 - res: ""я а то""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 5.000000, loss: 5.808981
 - src: ""леонато""
 - res: ""я а то""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 7.061111
 - src: ""бенедикт""
 - res: ""я не де""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 7.395775
 - src: ""бенедикт""
 - res: ""де не де""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 7.753145
 - src: ""бенедикт""
 - res: ""де не де""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 7.820290
 - src: ""бенедикт""
 - res: ""де не де""
--------------------------------------------------------------------------------
WER: 3.000000, CER: 6.000000, loss: 8.315677
 - src: ""бенедикт""
 - res: ""не не де""
--------------------------------------------------------------------------------
I Exporting the model...
I Models exported at /opt/deepspeech/datasets/ru/results/model_export/
 99% (2295 of 2306) |######################################################################################################################################## | Elapsed Time: 1:48:31 ETA:   4:03:39
$
```
So, it train single epoch, export model and finished(but --epoch is set to 25)",current script body cat python epoch global log ensure dev test train starting script warning removed future version instead use python function eager instead easy convert eager tensor call access eager use well differentiable gradient tape warning removed future version handled automatically placer warning removed future version use instead starting optimization starting optimization training epoch time eta removed future version use standard file delete prefix time eta removed future version use standard file check prefix acoustic model time time time time test wer loss time eta removed future version use warning removed future version use wer loss wer loss wer loss wer loss wer loss wer loss wer loss wer loss wer loss wer loss model time eta train single epoch export model finished epoch set,issue,negative,positive,neutral,neutral,positive,positive
481170852,"> I paste everything from stdout before it stop?

Everything, including when it stops, because so far **I don't see it stopping**. Including ensuring the checkpoint directory is empty.",paste everything stop everything far see stopping directory empty,issue,negative,neutral,neutral,neutral,neutral,neutral
481170396,"> > --checkppoint_step 1 \
> 
> What's that ? Also, please post more complete logs, and enable more debugging, if we don't see anything we can't help you for sure.

I'm sorry It's old version of script. I change this parameter and test again. There is same results. So what logs do you need? I paste everything from stdout before it stops?",also please post complete enable see anything ca help sure sorry old version script change parameter test need paste everything,issue,positive,positive,neutral,neutral,positive,positive
481167181,">   --checkppoint_step 1 \

What's that ? Also, please post more complete logs, and enable more debugging, if we don't see anything we can't help you for sure.",also please post complete enable see anything ca help sure,issue,positive,positive,positive,positive,positive,positive
481166595,"> That's not a stop in what you pasted, it's just the validation step, and you asked for one validation step at each training step in your command-line. With those values of loss, i'd wonder if you are not triggering early stopping ? Can you try with a brand new checkpoint dir to ensure you don't have a stale checkpoint that messes around ?

This situation happen exactly with new checkpoint dir. I have try to reduce learning rate, but the result was same.

Also, I have remove some parameters in my scripts, like here

```
python -u ./DeepSpeech/DeepSpeech.py \
  --train_files $1/train/train.csv \
  --dev_files $1/dev/dev.csv \
  --test_files $1/test/test.csv \
  --train_batch_size 12 \
  --dev_batch_size 8 \
  --test_batch_size 8 \
  --n_hidden 2048 \
  --epoch 25 \
  --learning_rate 0.0001 \
  --dropout_rate 0.2367 \
  --default_stddev 0.046875 \
  --checkpoint_step 1 \
  --loglevel 0 \
  --wer_log_pattern ""GLOBAL LOG: logwer('${COMPUTE_ID}', '%s', '%s', %f)"" \
  --checkpoint_dir $1/checkpoints/ \
  --export_dir $1/results/model_export/ \
  --alphabet_config_path $1/alphabet.txt \
  --lm_binary_path $1/lm.binary \
  --lm_trie_path $1/trie \
  ""$@""
```
And run again, but the result is same. It train single epoch, and finish training with validation results. On CPU instance I have 10 epoch's completed with same dataset and script, and training process still continued.",stop pasted validation step one validation step training step loss wonder early stopping try brand new ensure stale around situation happen exactly new try reduce learning rate result also remove like python epoch global log run result train single epoch finish training validation instance epoch script training process still continued,issue,negative,negative,neutral,neutral,negative,negative
481128013,"That's not a stop in what you pasted, it's just the validation step, and you asked for one validation step at each training step in your command-line. With those values of loss, i'd wonder if you are not triggering early stopping ? Can you try with a brand new checkpoint dir to ensure you don't have a stale checkpoint that messes around ?",stop pasted validation step one validation step training step loss wonder early stopping try brand new ensure stale around,issue,negative,negative,neutral,neutral,negative,negative
481042975,"Ah-ha! It ended up being the output > input error thrown by the ctc loss function. For now, i'll just change to ignore_longer_outputs_than_inputs=True. 


`InvalidArgumentError (see above for traceback): Not enough time for target transition sequence (required: 5, available: 4)3You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[node tower_0/CTCLoss (defined at DeepSpeech.py:188)  = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](tower_0/raw_logits/_89, tower_0/DeserializeSparse, tower_0/DeserializeSparse:1, tower_0/IteratorGetNext:1)]]
	 [[{{node Mean_8/_145}} = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_714_Mean_8"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]`


I have a check for this if others experience it, but I'm pretty sure the gradient is set to 0 if this error occurs and is ignored. It uses components from your old preprocessing.py file. Unfortunately, after changing line 188 to 
`total_loss = tf.nn.ctc_loss(labels=batch_y, inputs=logits, sequence_length=batch_seq_len, ignore_longer_outputs_than_inputs=True)`




```
def map_is_this_bad_audio(audio_filename, transcript):
        r""""""
        A simple audio validation process to determine if an audio sample may be a good candidate 
        for CTC loss given audio represented as MFCC and transcript represented as vector. Poor
        audio will also be removed by determining the decibel level averages across the audio file.
        """"""
        try:
            features_len = len(audiofile_to_input_vector(audio_filename, numcep=26, numcontext=9)) - 2 * 9 #features_len
            transcript_len = len(text_to_char_array(transcript, alphabet_))
            if features_len < transcript_len:
                answer = ""CTCError""
            elif features_len <= 1:
                answer = ""TransLen<=1""
            else:
                q = pydub.AudioSegment.from_wav(audio_filename)
                if str(q.dBFS) == '-inf':
                    answer = 'dBFS-inf'
                elif q.split_to_mono()[0].max <= 500:
                    answer = ""LowAmplitude""
                else:
                    answer = ""OK""
        except:
            answer = ""FileError""
        return answer


def is_this_bad_audio(dataframe):
    r""""""star map function which takes a df
    Input: df[0] as a list of string file paths to .wav and df[1] as a ground truth transcription.
    Output: list of QC results of each files evaluation.""""""

    array = np.asarray(dataframe)
    AUTOTUNE = multiprocessing.cpu_count()

    data = [(wav_filename, transcript) for wav_filename, transcript in array]
               
    with multiprocessing.Pool(AUTOTUNE) as p:
        qc = p.starmap(map_is_this_bad_audio, data)
    return qc
```



",ended output input error thrown loss function change see enough time target transition sequence available turn error warning flag node defined node check experience pretty sure gradient set error old file unfortunately line transcript simple audio validation process determine audio sample may good candidate loss given audio transcript vector poor audio also removed decibel level across audio try transcript answer answer else answer answer else answer except answer return answer star map function input list string file ground truth transcription output list evaluation array data transcript transcript array data return,issue,negative,positive,positive,positive,positive,positive
481010507,"The `tf.train.Coordinator.stop_on_exception()` context manager is swallowing the underlying problem here, try removing it to see what is actually causing things to fail (fixed in #2023).",context manager underlying problem try removing see actually causing fail fixed,issue,negative,negative,negative,negative,negative,negative
481008748,"Commit 8053548 is only partially related to the dataset changes, but I'm including here since you're also the relevant reviewer. The motivation for removing `tf.train.Coordinator` is that it swallows every exception inside the `with coord.stop_on_exception()` block, including SyntaxError, DivisionByZero, etc. This causes the silent errors like shown here: https://github.com/mozilla/DeepSpeech/issues/2014

After the tf.data PR we no longer manage threads ourselves, so the coordinator is not used. I just check for KeyboardInterrupt directly so one is able to stop the training but still test with ctrl-c.",commit partially related since also relevant reviewer motivation removing every exception inside block silent like shown longer manage used check directly one able stop training still test,issue,negative,positive,positive,positive,positive,positive
480930202,"Thank you for the fast response! Your team is amazing! :)

I am not trying to retrain or restart. Every combination I've tried returns the exit(1) from the evaluate.py file. 
Combinations I've tried
  --checkpoint_dir 'some/custom/path_to_empty/folder/

#ommit --checkpoint_dir and allow xdg to decide, also double checked this dir was empty.

--checkpoint_dir 'some/custom/path_to_0.4.1_checkpoint_files/folder/

It looks the tf.saver isn't saving anything. And if I tried to run checkpoints incorrectly, wouldn't I trigger this from DeepSpeech.py: 
`log_error('Unable to load %s model from specified checkpoint dir'
                          ' - consider using load option ""auto"" or ""init"".' % FLAGS.load)`

Looks like I can't make it past line 473 in DeepSpeech.py:

  `                _, current_step, batch_loss, step_summary = \
                    session.run([train_op, global_step, loss, step_summaries_op],
                                feed_dict=feed_dict)`",thank fast response team amazing trying retrain restart every combination tried exit file tried allow decide also double checked empty saving anything tried run incorrectly would trigger load model consider load option auto like ca make past line loss,issue,positive,positive,neutral,neutral,positive,positive
480919424,"If you're trying to fine tune our release checkpoints, they're no longer compatible with master code due to a recent refactoring to remove distributed training. Try specifying an empty checkpoint_dir (and training from scratch), or downgrade the code to an older version.",trying fine tune release longer compatible master code due recent remove distributed training try empty training scratch downgrade code older version,issue,negative,positive,neutral,neutral,positive,positive
480918659,"@tuttlebr You don't specify any checkpoint directory, so the default one applies and should be `$HOME/.local/share/deepspeech/ldc93s1/`",specify directory default one,issue,negative,neutral,neutral,neutral,neutral,neutral
480914736,"I'm having the error stated in the OPs title, not a cuDNN error.
In reading the flags.py file in more detail, there is a [new flag](https://github.com/mozilla/DeepSpeech/blob/15adf008ae0cf93d0a167a796eb541fb1b43022a/util/flags.py#L70).  The default is auto, which attempts to figure out what I want given the contents in the directory provided. If I set this to 'init' the exit code persists, training stops.

I've also tried various combinations/omissions of checkpoint_dir, and fine_tuning_checkpints, all have same issue. 


Input: running a shell script with my hyperparameters
```bash
#!/bin/bash

set -xe
if [ ! -f DeepSpeech.py ]; then
    echo ""Assert: Hi. Please run this from deepSpeech top level directory.""
    exit 1
fi;

python3 -u DeepSpeech.py \
  --train_files '/audiodata/bucket1/AudioData/Utterances/valid-train.csv' \
  --dev_files '/audiodata/bucket1/AudioData/Utterances/valid-dev.csv' \
  --test_files '/audiodata/bucket1/AudioData/Utterances/valid-test.csv' \
  --train_batch_size 64 \
  --dev_batch_size 48 \
  --test_batch_size 48 \
  --epochs 75 \
  --dropout_rate .1 \
  --learning_rate 0.0001 \
  --export_dir '/audiodata/bucket1/AudioData/Utterances/SpeechModel/' \
  --alphabet_config_path '/audiodata/bucket1/AudioData/Utterances/SpeechModel/alphabet.txt' \
  --lm_binary_path '/audiodata/bucket1/AudioData/Utterances/SpeechModel/lm.binary' \
  --lm_trie_path '/audiodata/bucket1/AudioData/Utterances/SpeechModel/trie' \
  --report_count 10 \
  ""$@""
```


output from console:
```
+ '[' '!' -f DeepSpeech.py ']'
+ python3 -u DeepSpeech.py --train_files /audiodata/bucket1/AudioData/Utterances/valid-train.csv --dev_files /audiodata/bucket1/AudioData/Utterances/valid-dev.csv --test_files /audiodata/bucket1/AudioData/Utterances/valid-test.csv --train_batch_size 64 --dev_batch_size 48 --test_batch_size 48 --epochs 25 --dropout_rate .1 --learning_rate 0.00001 --export_dir /audiodata/bucket1/AudioData/Utterances/SpeechModel/ --checkpoint_dir /audiodata/bucket1/AudioData/Utterances/SpeechModel/checkpoints/ --alphabet_config_path /audiodata/bucket1/AudioData/Utterances/SpeechModel/alphabet.txt --lm_binary_path /audiodata/bucket1/AudioData/Utterances/SpeechModel/lm.binary --lm_trie_path /audiodata/bucket1/AudioData/Utterances/SpeechModel/trie --report_count 10
I Initializing variables...
I STARTING Optimization
I Training epoch 0...
E Checkpoint directory (/audiodata/bucket1/AudioData/Utterances/SpeechModel/checkpoints/) does not contain a valid checkpoint state.
  0% (1 of 1604) |                       | Elapsed Time: 0:00:05 ETA:   2:18:24
```

",error stated title error reading file detail new flag default auto figure want given content directory provided set exit code training also tried various issue input running shell script bash set echo assert hi please run top level directory exit fi python output console python starting optimization training epoch directory contain valid state time eta,issue,negative,positive,positive,positive,positive,positive
480816799,"> External bindings will have to be updated but they are both still on 0.4.0.

I'm planning to send PR as part of https://github.com/mozilla/DeepSpeech/issues/2006",external still send part,issue,negative,neutral,neutral,neutral,neutral,neutral
480811256,"The Java bindings use a completely different model, relying on SWIG cpointer and the Java code to manage memory rather than the bindings, and I don't know how to make sure they call appropriate free function when creating the Java String value. @lissyx any pointers?",use completely different model swig code manage memory rather know make sure call appropriate free function string value,issue,positive,positive,positive,positive,positive,positive
480799295,"Local use is:

```
pip install cardboardlint
cardboardlinter
```

Getting a pre-commit hook working requires platform-specific instructions and handling missing packages which is the reason why I decided to go with the CI approach. I'll document the steps above somewhere, maybe add a CONTRIBUTING.md file.",local use pip install getting hook working handling missing reason decided go approach document somewhere maybe add file,issue,negative,negative,neutral,neutral,negative,negative
480798448,"Also, when merging this PR, use the ""Squash and merge"" option in the GitHub UI.",also use squash merge option,issue,negative,neutral,neutral,neutral,neutral,neutral
480795555,"> system Info- Intel© Core™ i7-8700K CPU @ 3.70GHz
> GPU:- 2070 RTX 8GB
> RAM:- 32 GiB
> OS:- Linux Mint 19.1 Cinnamon
> tensorflow gpu version == 1.13.1
> 
> Everything working fine but got Following Error also i check in this (/system_path/.local/share/deepspeech/ldc93s1) directory there is no previous checkpoints i don't know why this error occur please help me:-
> 
> WARNING:tensorflow:From /home/gpu1/tmp/deepspeech-venv/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
> Instructions for updating:
> I Initializing variables...
> I STARTING Optimization
> I Training epoch 0...
> 2019-04-06 04:11:00.963684: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
> 2019-04-06 04:11:00.968836: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR

I see several errors here, can you be more specific ? I can't understand your current state. So far, if your training fails with `CUDNN_STATUS_INTERNAL_ERROR` it means your setup is wrong and it's expected there's no checkpoint created ...",system copyright core ram gib o mint cinnamon version everything working fine got following error also check directory previous know error occur please help warning removed future version starting optimization training epoch could create handle could create handle see several specific ca understand current state far training setup wrong,issue,negative,negative,neutral,neutral,negative,negative
480792652,Also okay with me. Can we still document the local use and how people should enable it by default on their pre-commit setup ?,also still document local use people enable default setup,issue,negative,neutral,neutral,neutral,neutral,neutral
480781019,"Well, since it is all on client-side, we can experiment as much as we want :). I think JSON could still be a good fit.",well since experiment much want think could still good fit,issue,positive,positive,positive,positive,positive,positive
480595593,FYI the cudnn error is unrelated to what I'm seeing. Do you have the correct nvidia driver + cuda + cudnn combo for tensorflow 1.13.1?,error unrelated seeing correct driver,issue,negative,neutral,neutral,neutral,neutral,neutral
480595320,I have a similar issue. Trying to train without any checkpoints with a script that worked previously. The error is a log out from the evaluate.py file. The call expects checkpoint DIR but the saver saves nothing so exit code. I tried with the 0.4.1 checkpoints just to see if that worked but got the same result. I think it's expecting checkpoints for model training not necessarily fine tuning. But I could be wrong. ,similar issue trying train without script worked previously error log file call saver nothing exit code tried see worked got result think model training necessarily fine tuning could wrong,issue,negative,negative,neutral,neutral,negative,negative
480587865,"The last parameter is the path of the trie file to be written, it needs to be a file, not a folder.",last parameter path file written need file folder,issue,negative,neutral,neutral,neutral,neutral,neutral
480419662,"Git pre-hooks are hard to set up and share across the team and external contributors. I've been toying with the idea of running a linter as a CI step on PRs. Here's an example of what it would look like: https://github.com/reuben/DeepSpeech/pull/6

There's two runs there, the initial one that adds the config and passes the lint check, and then a commit that adds some lint problems to trigger a failure.

It uses Travis CI and cardboardlint to run the linter on just the changes added in the PR, so nobody should get forced to correct problems in other parts of the code in their PR, but it does mean if you're touching some existing code that has problems, you'll need to fix it. I've tried to fix most of the existing problems to make this less of an issue.

@kdavis-mozilla @tilmankamp @lissyx what do you think? This should help us keep a consistent style specially with external contributors. It's also super easy to add cppcheck to also check our native code, just add the config file and another entry in the .cardboardlint.yml file.",git hard set share across team external toying idea running linter step example would look like two initial one lint check commit lint trigger failure travis run linter added nobody get forced correct code mean touching code need fix tried fix make le issue think help u keep consistent style specially external also super easy add also check native code add file another entry file,issue,positive,positive,neutral,neutral,positive,positive
480361477,OSX workers are acting up but the relevant code has been exercised in other completed tests. Merged manually to avoid starting another group here in the PR.,acting relevant code manually avoid starting another group,issue,negative,positive,positive,positive,positive,positive
480279908,"> I followed your steps and did

And yet you reopened under a new issue instead of asking / checking on discourse as I said. And you even reopened without giving the new error you got.

So yes, that's spamming.",yet new issue instead discourse said even without giving new error got yes,issue,negative,positive,positive,positive,positive,positive
480278103,"This repository is not for Git LFS support and we're not Git LFS experts. Somehow your install is broken. Try starting from scratch, including cloning DeepSpeech.",repository git support git somehow install broken try starting scratch,issue,negative,negative,negative,negative,negative,negative
480277176,"I got stuck in that and error and  you closed that issue and hence I had to reopen the issue.
Please listen to problem and then comment whether I am spamming or not.

I followed your steps and did
git lfs fetch all
git lfs checkout
It gave error at git lfs checkout 
Git cannot resolve Head
what should be done?",got stuck error closed issue hence reopen issue please listen problem comment whether git fetch git gave error git git resolve head done,issue,negative,negative,neutral,neutral,negative,negative
480232701,"> > Looks like Python installer on Windows is a pain: requires admin privileges without reason, unable to be quiet.
> 
> Ok, it does not, but 2012R2 on TC blocks `pyenv-win` from installing the official python packages, that are only bundled as an installer, no zip ... And allowing this install is supposed to just be flipping the value of `DisableMSI` in the registry, but right now setting that value seems to have broken the windows instances badly

Ok, now we have build setup mostly okay, but we won't be able to get packages for Python < 3.5, because that depends on MSVC++ 9.0/10.0 and it's going to be way too much work to take care of that. So it's only going to be Python 3.5, 3.6 and 3.7 for amd64 arch.",like python installer pain without reason unable quiet official python installer zip install supposed value registry right setting value broken badly build setup mostly wo able get python going way much work take care going python arch,issue,negative,negative,neutral,neutral,negative,negative
480226098,"> Remote Disk
> Thank you the issue is solved when I started the training again.

Right, so maybe network issue or something. Nothing we can help, but good to know it's working. I'm going to close this then. For further help, please use Discourse.",remote disk thank issue training right maybe network issue something nothing help good know working going close help please use discourse,issue,negative,positive,positive,positive,positive,positive
480225905,"> terminate called after throwing an instance of 'lm::FormatLoadException'
> what(): ../kenlm/lm/read_arpa.cc:65 in void lm::ReadARPACounts(util::FilePiece&, std::vector&) threw FormatLoadException.
> first non-empty line was ""version https://git-lfs.github.com/spec/v1"" not \data. Byte: 43
> Aborted
> 
> What should be done
> *-I have install git lfs

Obviously, it's not properly installed / it failed to checkout properly the data. Please `git lfs fetch && git lfs checkout`.",terminate throwing instance void threw first line version aborted done install git obviously properly properly data please git fetch git,issue,negative,positive,positive,positive,positive,positive
480224329,"Remote Disk 
Thank you the issue is solved when I started the training again.

 But it gave this error:


Preprocessing ['/app/cv-valid-train.csv']
Preprocessing done
Preprocessing ['/app/cv-valid-dev.csv']
Preprocessing done
W Parameter --validation_step needs to be >0 for early stopping to work
Preprocessing ['/app/cv-valid-test.csv']
Preprocessing done
Loading the LM will be faster if you build a binary file.
Reading data/lm/lm.binary
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
terminate called after throwing an instance of 'lm::FormatLoadException'
  what():  ../kenlm/lm/read_arpa.cc:65 in void lm::ReadARPACounts(util::FilePiece&, std::vector<long unsigned int>&) threw FormatLoadException.
first non-empty line was ""version https://git-lfs.github.com/spec/v1"" not \data\. Byte: 43
Aborted

What should be done
*-I have install git lfs

",remote disk thank issue training gave error done done parameter need early stopping work done loading faster build binary file reading terminate throwing instance void long unsigned threw first line version aborted done install git,issue,negative,positive,neutral,neutral,positive,positive
479923508,"> Looks like Python installer on Windows is a pain: requires admin privileges without reason, unable to be quiet.

Ok, it does not, but 2012R2 on TC blocks `pyenv-win` from installing the official python packages, that are only bundled as an installer, no zip ... And allowing this install is supposed to just be flipping the value of `DisableMSI` in the registry, but right now setting that value seems to have broken the windows instances badly",like python installer pain without reason unable quiet official python installer zip install supposed value registry right setting value broken badly,issue,negative,negative,negative,negative,negative,negative
479847302,"Also what is `/app` ? How do you run training, bare-metal ? Containers ? Remote disk ?",also run training remote disk,issue,negative,negative,neutral,neutral,negative,negative
479845772,"> You are asking for hard drive space or RAM ?

Drive, not RAM. `Errno 5` is 99.999% a space issue, and since you don't provide more details, we can't help. Maybe `/tmp`, maybe `/` ... ?",hard drive space ram drive ram space issue since provide ca help maybe maybe,issue,negative,negative,negative,negative,negative,negative
479842622,You are asking for hard drive space or RAM ?,hard drive space ram,issue,negative,negative,negative,negative,negative,negative
479772680,"I have checked it but Space can't be the problem I have 1 Tb of free space, and as I mentioned I have used batch size also 5 only...
",checked space ca problem free space used batch size also,issue,negative,positive,positive,positive,positive,positive
479770581,"Did you searched for ""Input/Ouput Error""? It's very likely a space issue ",error likely space issue,issue,negative,neutral,neutral,neutral,neutral,neutral
479761968,"Sorry I can't get you 
Preprocessing ['/app/cv-valid-train.csv']
Preprocessing done
Preprocessing ['/app/cv-valid-dev.csv']
Preprocessing done
W Parameter --validation_step needs to be >0 for early stopping to work
I STARTING Optimization
I Training epoch 55...
I Training of Epoch 55 - loss: 190.732836
I Training epoch 56...
I Training of Epoch 56 - loss: 193.679107
I Training epoch 57...
I Training of Epoch 57 - loss: 193.652214
I Training epoch 58...
I Training of Epoch 58 - loss: 193.667971
I Training epoch 59...
I Training of Epoch 59 - loss: 193.587716
I Training epoch 60...
I Training of Epoch 60 - loss: 193.726443
I Training epoch 61...
I Training of Epoch 61 - loss: 193.645015
I Training epoch 62...
E [Errno 5] Input/output error

This was the error what I got",sorry ca get done done parameter need early stopping work starting optimization training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss training epoch training epoch loss training epoch error error got,issue,negative,negative,negative,negative,negative,negative
479761593,"> :-->E [Errno 5] Input/output error
> what should be done?

Giving more context, first ?",error done giving context first,issue,negative,positive,positive,positive,positive,positive
479745935,"Thank you the issue is solved and trainning is started but
after 55 epochs error occured

:---->E [Errno 5] Input/output error

What is this error and what should be done?
",thank issue error error error done,issue,negative,neutral,neutral,neutral,neutral,neutral
479697542,"@reuben - you were right, lot's of duplicated info in head README and native_client README

Please review the current docs.

(1) moved BUILD.md to README.md
(2) updated head README.md",right lot head please review current head,issue,negative,positive,positive,positive,positive,positive
479500859,"@lissyx could you take a look at the test changes I had to make to handle the versioning code?

@kdavis-mozilla things are working and tests are green, so this PR should not change going forward, and I will not force push anymore, so feel free to review.",could take look test make handle code working green change going forward force push feel free review,issue,positive,positive,neutral,neutral,positive,positive
479487230,"Looks like Python installer on Windows is a pain: requires admin privileges without reason, unable to be quiet.",like python installer pain without reason unable quiet,issue,negative,negative,negative,negative,negative,negative
479417900,"So, resulting `deepspeech-gpu-0.5.0-alpha.4.tgz` is 75MB, will give us some more room",resulting give u room,issue,negative,neutral,neutral,neutral,neutral,neutral
479130522,"Happy to take a look, but won't be able to for a couple of weeks.",happy take look wo able couple,issue,positive,positive,positive,positive,positive,positive
479103874,"> As well as confidence, it would be handy to have a list of words it could also be. That may be more of a client feature though.

Hey @dabinat, do you want to try and add confidence exposure at first ? ",well confidence would handy list could also may client feature though hey want try add confidence exposure first,issue,positive,positive,positive,positive,positive,positive
479086784,"As well as confidence, it would be handy to have a list of words it could also be. That may be more of a client feature though.",well confidence would handy list could also may client feature though,issue,positive,positive,positive,positive,positive,positive
479066679,"Yes, should be super simple to add now, just add to the existing structures.",yes super simple add add,issue,positive,positive,positive,positive,positive,positive
479059838,@reuben we could build on top of the changes from @dabinat to build that ?,could build top build,issue,negative,positive,positive,positive,positive,positive
479032311,"Mostly fixed by recent changes to master, plus tf.data simplification, will probably get better if/when we introduce TF eager functionality.",mostly fixed recent master plus simplification probably get better introduce eager functionality,issue,positive,positive,positive,positive,positive,positive
479008466,#1988 added this feature. It checkpoints the best validating epoch and supports different ways to resume - see `load` command-line parameter.,added feature best epoch different way resume see load parameter,issue,positive,positive,positive,positive,positive,positive
479005554,Obsolete as LXD based Snakepit service creates virtual network interfaces that are under full control of the tasks.,obsolete based service virtual network full control,issue,negative,positive,positive,positive,positive,positive
478981631,"For now we will just stick to CUDA compute compatibility 3.5, all the testing I could perform reveal it works with no noticeable perf regression",stick compute compatibility testing could perform reveal work noticeable regression,issue,negative,neutral,neutral,neutral,neutral,neutral
478939036,"Thanks a lot @kdavis-mozilla it worked,and I did not used requirements.txt
but I landed in another error 
Traceback (most recent call last):
  File ""./DeepSpeech.py"", line 934, in <module>
    tf.app.run(main)
  File ""/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""./DeepSpeech.py"", line 886, in main
    train()
  File ""./DeepSpeech.py"", line 424, in train
    gradients, loss = get_tower_results(model_feeder, optimizer, dropout_rates)
  File ""./DeepSpeech.py"", line 256, in get_tower_results
    avg_loss = calculate_mean_edit_distance_and_loss(model_feeder, i, dropout_rates, reuse=i>0)
  File ""./DeepSpeech.py"", line 186, in calculate_mean_edit_distance_and_loss
    logits, _ = BiRNN(batch_x, batch_seq_len, dropout, reuse)
  File ""./DeepSpeech.py"", line 88, in BiRNN
    layer_1 = tf.nn.dropout(layer_1, rate=dropout[0])
TypeError: dropout() got an unexpected keyword argument 'rate'
Can You help it out?",thanks lot worked used landed another error recent call last file line module main file line run main file line main train file line train loss file line file line dropout reuse file line dropout got unexpected argument help,issue,negative,positive,positive,positive,positive,positive
478933141,"Maybe, but I don't think it would have fixed this problem. LuciferA678 didn't use requirements.txt but used an anaconda package with a pre-installed pandas.",maybe think would fixed problem use used anaconda package,issue,negative,positive,neutral,neutral,positive,positive
478929837,"> That's the problem.
> 
> This bug was fixed two years ago in Pandas 0.20.0 , see this [issue](https://github.com/pandas-dev/pandas/issues/15055). Could you update to a recent, Pandas.

Maybe we should enforce `pandas >= 0.20.0` in `requirements.txt` ?",problem bug fixed two ago see issue could update recent maybe enforce,issue,negative,positive,neutral,neutral,positive,positive
478925333,"That's the problem.

This bug was fixed two years ago in Pandas 0.20.0 , see this [issue](https://github.com/pandas-dev/pandas/issues/15055). Could you update to a recent, Pandas.",problem bug fixed two ago see issue could update recent,issue,negative,positive,neutral,neutral,positive,positive
478812592,"For the TFLite model there's no easy solution right now. The model file has a description field that's currently unused, but the TFLite converter API doesn't expose it, so it's not easy to use. For now I'll focus on the protobuf model since that's what we run the prod tests with.",model easy solution right model file description field currently unused converter expose easy use focus model since run prod,issue,positive,positive,positive,positive,positive,positive
478722350,"Test failures were just version checks due to missing tags in your fork, merging.",test version due missing fork,issue,negative,negative,negative,negative,negative,negative
478690847,"Trying again with an alternative approach, using protobuf but with messages built-in to TensorFlow, so minimal effort.",trying alternative approach minimal effort,issue,negative,negative,neutral,neutral,negative,negative
478665452,"We already have such a check, I don't know why it wasn't triggered in your case. Maybe there's a deeper problem?

https://github.com/mozilla/DeepSpeech/blob/a009361e470b591f20562214122944d9811592ba/util/preprocess.py#L25-L26",already check know triggered case maybe problem,issue,negative,neutral,neutral,neutral,neutral,neutral
478662950,"@JRMeyer I would say yes, preprocessing or separate script, or part of importers ... ?",would say yes separate script part,issue,negative,neutral,neutral,neutral,neutral,neutral
478662520,"All your comments make sense, so the question is, should we have a preprocessing step that checks length of transcript vs. length of utterance at import time?

@kdavis-mozilla @reuben @lissyx ?",make sense question step length transcript length utterance import time,issue,negative,neutral,neutral,neutral,neutral,neutral
478542183,You got the point. This PR is essentially my short-term reaction to the CV2 import issues. We won't have to merge it - albeit it's good to have more options and it lists all the problematic samples. As you can see from the code it is off by default (will fail).,got point essentially reaction import wo merge albeit good problematic see code default fail,issue,negative,positive,neutral,neutral,positive,positive
478540879,"@tilmankamp Just so I understand, what's the use case for this?

I know it will make training ""just work"", but my real question is: Is it desirable to ignore, without being forced to examine, invalid data?",understand use case know make training work real question desirable ignore without forced examine invalid data,issue,negative,negative,neutral,neutral,negative,negative
478510497,"Thanks for your feedback! Based on it we should do the following:

1. Adding Unicode normalization of diacritics to the CV2 importer
2. Adding an option for alphabet-based character filtering to the CV2 importer (second option from question)",thanks feedback based following normalization importer option character filtering importer second option question,issue,negative,positive,neutral,neutral,positive,positive
478507368,"We try to reserve issues for bugs or feature enhancements, and as this does not appear to be a bug or feature enhancement (more a discussion of the code), we ask that you move this discussion to [Discourse](https://discourse.mozilla.org/c/deep-speech) please. Thank you.",try reserve feature appear bug feature enhancement discussion code ask move discussion discourse please thank,issue,positive,neutral,neutral,neutral,neutral,neutral
478475032,I tend to agree with @reuben and @lissyx. Generally it's better to fail and know there exists a data problem than to silently pass over the problem which will lead to downstream problems that are harder to debug.,tend agree generally better fail know data problem silently pas problem lead downstream harder,issue,negative,negative,neutral,neutral,negative,negative
478382913,"Looks like your training set has an empty file, or a proper WAV file but with zero samples.

-- reuben

> On 29 Mar 2019, at 03:10, Ashutosh Pednekar <notifications@github.com> wrote:
> 
> Here's my stack trace: -
> 
> (friday) ubuntu@ip-172-31-27-16:~/fri/DeepSpeech$ sh run.sh 
> + [ ! -f DeepSpeech.py ]
> + python -u DeepSpeech.py --train_files /home/ubuntu/fri/train/train.csv --dev_files /home/ubuntu/fri/dev/dev.csv --test_files /home/ubuntu/test/test.csv --train_batch_size 80 --dev_batch_size 80 --test_batch_size 40 --n_hidden 375 --epoch 33 --validation_step 1 --early_stop True --earlystop_nsteps 6 --estop_mean_thresh 0.1 --estop_std_thresh 0.1 --dropout_rate 0.22 --learning_rate 0.00095 --report_count 100 --use_seq_length False --export_dir /home/ubuntu/fri/results/model_export/ --checkpoint_dir /home/ubuntu/fri/checkout/ --decoder_library_path /home/ubuntu/fri/DeepSpeech/libdeepspeech.so --alphabet_config_path /home/ubuntu/fri/DeepSpeech/data/alphabet.txt --lm_binary_path /home/ubuntu/fri/DeepSpeech/data/lm/lm.binary --lm_trie_path /home/ubuntu/fri/DeepSpeech/data/lm/trie
> Preprocessing ['/home/ubuntu/fri/train/train.csv']
> Traceback (most recent call last):
>   File ""DeepSpeech.py"", line 941, in <module>
>     tf.app.run(main)
>   File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
>     _sys.exit(main(argv))
>   File ""DeepSpeech.py"", line 893, in main
>     train()
>   File ""DeepSpeech.py"", line 388, in train
>     hdf5_cache_path=FLAGS.train_cached_features_path)
>   File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 69, in preprocess
>     out_data = pmap(step_fn, source_data.iterrows())
>   File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 13, in pmap
>     results = pool.map(fun, iterable)
>   File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 288, in map
>     return self._map_async(func, iterable, mapstar, chunksize).get()
>   File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 670, in get
>     raise self._value
>   File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
>     result = (True, func(*args, **kwds))
>   File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 44, in mapstar
>     return list(map(*args))
>   File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 21, in process_single_file
>     features = audiofile_to_input_vector(file.wav_filename, numcep, numcontext)
>   File ""/home/ubuntu/fri/DeepSpeech/util/audio.py"", line 18, in audiofile_to_input_vector
>     features = mfcc(audio, samplerate=fs, numcep=numcep, winlen=0.032, winstep=0.02, winfunc=np.hamming)
>   File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/base.py"", line 28, in mfcc
>     feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)
>   File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/base.py"", line 54, in fbank
>     signal = sigproc.preemphasis(signal,preemph)
>   File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/sigproc.py"", line 118, in preemphasis
>     return numpy.append(signal[0],signal[1:]-coeff*signal[:-1])
> IndexError: index 0 is out of bounds for axis 0 with size 0
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
",like training set empty file proper file zero mar wrote stack trace sh python epoch true false recent call last file line module main file line run main file line main train file line train file line file line fun iterable file line map return iterable file line get raise file line worker result true file line return list map file line file line audio file line feat energy signal file line signal signal file line return signal signal signal index axis size thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
478318678,"I second what @reuben suggested, unicode normalization in the importer.

The Common Voice data set can validly contain accents, e.g. in English café is a valid word. So removing them in the Common Voice data set isn't an option. You have to remember Common Voice is used for more than Deep Speech.",second normalization importer common voice data set validly contain valid word removing common voice data set option remember common voice used deep speech,issue,negative,negative,negative,negative,negative,negative
478307015,"In other importers we used unicode normalization to remove the diacritics and leave the underlying ASCII character, for example: https://github.com/mozilla/DeepSpeech/blob/a009361e470b591f20562214122944d9811592ba/bin/import_fisher.py#L112-L113

For loan words, I think it's acceptable to do something similar in our CV2 importer since it's a DeepSpeech-specific restriction. So I would vote for making the importer deal with this, either ignoring samples or trying to fix them.",used normalization remove leave underlying ascii character example loan think acceptable something similar importer since restriction would vote making importer deal either trying fix,issue,negative,neutral,neutral,neutral,neutral,neutral
478297201,It depends how quickly you need them. I can take on Python and JavaScript but won’t be able to for a couple of weeks.,quickly need take python able couple,issue,negative,positive,positive,positive,positive,positive
478295960,"@lissyx my research team moved to use a motion based feature from video and taken a step back from using word prediction from the audio so I haven't get the chance to dive into this feature. Should we come back to the idea of using key word prediction, I may get time to work on it. In the mean time no substantial PR from me. Thanks!",research team use motion based feature video taken step back word prediction audio get chance dive feature come back idea key word prediction may get time work mean time substantial thanks,issue,positive,negative,neutral,neutral,negative,negative
478290656,"All green, thanks for the hard work @dabinat ! Now that this gets merged, you can improve our existing bindings (Python, JavaScript, Java/Android) as well as the rust ones https://github.com/RustAudio/deepspeech-rs and go ones https://github.com/asticode/go-astideepspeech by exposing the new feature :)",green thanks hard work improve python well rust go new feature,issue,positive,negative,neutral,neutral,negative,negative
478285896,"> @aijianiula0601 @lissyx 我自己训练完成之后，然后用这个命令运行，我报错了，说是需要libcuda10.0,这个download下来gpu的是10.0的吗？
> python3 util/taskcluster.py --arch gpu --target ./native_client 我运行的是这个命令安装的
> ""libcudart.so.10.0 cannot open shared object file: No such file or directory"" 报这个错。
> 但是我系统只有libcudart.so.9.0 ，请问有9的GPU吗？

> @lissyx 之后，我就测试不了了，请问我什么解决方法吗？

I don't speak chinese, but you need to use CUDA 10.0 with current master binaries. Use `0.4.1` release if you are stuck with CUDA 9.0",python arch target open object file file directory speak need use current master use release stuck,issue,negative,neutral,neutral,neutral,neutral,neutral
478285837,"> --train_files /tmp/thchs30-train.csv
> --dev_files /tmp/thchs30-dev.csv
> --test_files /tmp/thchs30-test.csv

How much data is there here?

> --lm_binary_path /tmp/speechRecognition/dataset/data_thchs30/external_csv/test/lm.binary
> --lm_trie_path /tmps/speechRecognition/dataset/data_thchs30/external_csv/test/trie

Are you sure about your language model here? It might interact



> ```
> WER: 1.000000, CER: 37.000000, loss: 161.008698
>  - src: ""好 容 易 盼 来 一 位 望 望 这 一 片 荒 芜 又 扭 身 而 去""
>  - res: """"
> ```
> 
> 
> The WER is always 1.0 and res is null.

Please remember we show a subset of the worst from the test results. Depending on how your test dataset is built and its size, it may explain and your model could be okay.",much data sure language model might interact wer loss wer always null please remember show subset worst test depending test built size may explain model could,issue,negative,negative,negative,negative,negative,negative
478274058,"No worries, I'll run a last taskcluster check and merge 😊",run last check merge,issue,negative,neutral,neutral,neutral,neutral,neutral
478267945,"I fixed those two nits. If rebasing is a problem I could create a new branch and PR, but I would want to be certain there aren't any extra changes needed before I do so.",fixed two problem could create new branch would want certain extra,issue,negative,positive,positive,positive,positive,positive
478260957,"I told them there's no need to rebase as it's insignificant to our workflow, and we can always use GitHub's squash and merge/rebase and merge functionality in the PR anyway.",told need rebase insignificant always use squash merge functionality anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
478249920,"@dabinat I know you got issues with rebasing and squashing in the past, is that still the case on this PR ? 12 commits, it makes it a bit complicated, if you could rebase into one or two commits it'd be perfect.",know got past still case bit complicated could rebase one two perfect,issue,positive,positive,neutral,neutral,positive,positive
478249430,"I'm not sure, it's a symptom that you have buggy data. While I share the inconvenience, I'm not sure letting people thinking their dataset is okay when it is not is a good thing. We should rather enforce better checking at import time, IMHO.",sure symptom buggy data share inconvenience sure people thinking good thing rather enforce better import time,issue,positive,positive,positive,positive,positive,positive
478059800,"@tilmankamp We faced a similar situation for CV French, and I think a multi-stage solution is the best approach, after speaking a bit with @kdavis-mozilla:
 - fix the common voice text corpus dataset
 - if possible, enhance corpora creator: there might be cases where the strippping only makes sense for deepspeech and not other applications of voice, so this is not always possible
 - as a last resort, we could add language-specific tooling on `import_cv2.py` side to cleanup",faced similar situation think solution best approach speaking bit fix common voice text corpus possible enhance corpus creator might sense voice always possible last resort could add tooling side cleanup,issue,positive,positive,positive,positive,positive,positive
477880800,"Here's my stack trace: - 
```
(friday) ubuntu@ip-172-31-27-16:~/fri/DeepSpeech$ sh run.sh 
+ [ ! -f DeepSpeech.py ]
+ python -u DeepSpeech.py --train_files /home/ubuntu/fri/train/train.csv --dev_files /home/ubuntu/fri/dev/dev.csv --test_files /home/ubuntu/test/test.csv --train_batch_size 80 --dev_batch_size 80 --test_batch_size 40 --n_hidden 375 --epoch 33 --validation_step 1 --early_stop True --earlystop_nsteps 6 --estop_mean_thresh 0.1 --estop_std_thresh 0.1 --dropout_rate 0.22 --learning_rate 0.00095 --report_count 100 --use_seq_length False --export_dir /home/ubuntu/fri/results/model_export/ --checkpoint_dir /home/ubuntu/fri/checkout/ --decoder_library_path /home/ubuntu/fri/DeepSpeech/libdeepspeech.so --alphabet_config_path /home/ubuntu/fri/DeepSpeech/data/alphabet.txt --lm_binary_path /home/ubuntu/fri/DeepSpeech/data/lm/lm.binary --lm_trie_path /home/ubuntu/fri/DeepSpeech/data/lm/trie
Preprocessing ['/home/ubuntu/fri/train/train.csv']
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 941, in <module>
    tf.app.run(main)
  File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""DeepSpeech.py"", line 893, in main
    train()
  File ""DeepSpeech.py"", line 388, in train
    hdf5_cache_path=FLAGS.train_cached_features_path)
  File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 69, in preprocess
    out_data = pmap(step_fn, source_data.iterrows())
  File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 13, in pmap
    results = pool.map(fun, iterable)
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 288, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 670, in get
    raise self._value
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 44, in mapstar
    return list(map(*args))
  File ""/home/ubuntu/fri/DeepSpeech/util/preprocess.py"", line 21, in process_single_file
    features = audiofile_to_input_vector(file.wav_filename, numcep, numcontext)
  File ""/home/ubuntu/fri/DeepSpeech/util/audio.py"", line 18, in audiofile_to_input_vector
    features = mfcc(audio, samplerate=fs, numcep=numcep, winlen=0.032, winstep=0.02, winfunc=np.hamming)
  File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/base.py"", line 28, in mfcc
    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)
  File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/base.py"", line 54, in fbank
    signal = sigproc.preemphasis(signal,preemph)
  File ""/home/ubuntu/.virtualenvs/friday/lib/python3.6/site-packages/python_speech_features/sigproc.py"", line 118, in preemphasis
    return numpy.append(signal[0],signal[1:]-coeff*signal[:-1])
IndexError: index 0 is out of bounds for axis 0 with size 0

```",stack trace sh python epoch true false recent call last file line module main file line run main file line main train file line train file line file line fun iterable file line map return iterable file line get raise file line worker result true file line return list map file line file line audio file line feat energy signal file line signal signal file line return signal signal signal index axis size,issue,positive,positive,positive,positive,positive,positive
477740711,"I won’t have time or enough internet access to review this until Monday, but could you make sure you remove all references in READMEs and docs? Maybe nix the docs/ folder altogether? It’s severely out of date at this point.",time enough access review could make sure remove maybe nix folder altogether severely date point,issue,negative,positive,positive,positive,positive,positive
477330713,"> OK，thanks，i think it need to update tensorflow-gpu

And please ensure you at least re-export. It might even be needed to re-start training from scratch, if just re-exporting does not help.",think need update please ensure least might even training scratch help,issue,positive,negative,negative,negative,negative,negative
477104508,"OK，thanks，i think it need to update tensorflow-gpu




| |
黄贺茗
邮箱：hm876556280@163.com
|

签名由 网易邮箱大师 定制

On 03/27/2019 19:16, lissyx wrote:

no ,i do not change this file DeepSpeech.py.

why i run you improve english model can test , own model can not test ？
there environment is the same。

Well, I don't know, I'm trying to help you but you keep refusing to give the informations and to apply properly the documentation. This is obviously not a bug in DeepSpeech.

Please use the documented tensorflow-gpu version matching the DeepSpeech version you use.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or mute the thread.",think need update wrote change file run improve model test model test environment well know trying help keep refusing give apply properly documentation obviously bug please use version matching version use thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
477103441,"> no ,i do not change this file DeepSpeech.py.
> 
> why i run you improve english model can test , own model can not test ？
> there environment is the same。

Well, I don't know, I'm trying to help you but you keep refusing to give the informations and to apply properly the documentation. This is obviously not a bug in DeepSpeech.

Please use the documented `tensorflow-gpu` version matching the `DeepSpeech` version you use.",change file run improve model test model test environment well know trying help keep refusing give apply properly documentation obviously bug please use version matching version use,issue,positive,neutral,neutral,neutral,neutral,neutral
477060792,"no ,i do not change this  file DeepSpeech.py.

why i run you improve english model  can test  , own model  can not test ？
there environment is the same。",change file run improve model test model test environment,issue,negative,neutral,neutral,neutral,neutral,neutral
477060542,"> Still lacking your training infos

my training commad:

python -u /home/huangjiahong/github/DeepSpeech/DeepSpeech.py \
--train_files /tmp/thchs30-train.csv \
--dev_files /tmp/thchs30-dev.csv \
--test_files /tmp/thchs30-test.csv \
--train_batch_size 1024 \
--dev_batch_size 256 \
--test_batch_size 256 \
--beam_width 20 \
--n_hidden 100 \
--epoch 30 \
--report_count 1000 \
--validation_step 1 \
--coord_port 2502 \
--export_dir /tmp/DeepSpeech/data_thchs30/model \
--checkpoint_dir /tmp/DeepSpeech/data_thchs30/checkpoint \
--alphabet_config_path /tmp/speechRecognition/dataset/data_thchs30/external_csv/test/alphabet.txt \
--lm_binary_path /tmp/speechRecognition/dataset/data_thchs30/external_csv/test/lm.binary \
--lm_trie_path /tmps/speechRecognition/dataset/data_thchs30/external_csv/test/trie
",still training training python epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
477059122,"> i tensorflow is tensorflow-gpu 0.9.0

Please use the tensorflow version matching `requirements.txt`

Did you made any change to `DeepSpeech.py` ?",please use version matching made change,issue,negative,neutral,neutral,neutral,neutral,neutral
477056596,"i run this sh to train model:
python3 -u DeepSpeech.py \
  --train_files /home/huangheming/data/thchs30-csv/thchs30-train.csv \
  --dev_files /home/huangheming/data/thchs30-csv/thchs30-dev.csv \
  --test_files /home/huangheming/data/thchs30-csv/th200-test.csv \
  --train_batch_size 24 \
  --dev_batch_size 48 \
  --test_batch_size 48 \
  --n_hidden 2048 \
  --epoch 30 \
  --dropout_rate 0.15 \
  --validation_step 1 \
  --display_step 0 \
  --learning_rate 0.0001 \
  --export_dir /home/huangheming/test/export/ \
  --checkpoint_dir /home/huangheming/test/checkpoint_dir/ \
  --alphabet_config_path /home/huangheming/data/thchs30-csv/thchs30-alphabet.txt \
  --lm_binary_path /home/huangheming/data/thchs30-csv/thchs30-lm.binary \
  --lm_trie_path /home/huangheming/data/thchs30-csv/th30-trie \
  --log_level 0 \
  --summary_dir /home/huangheming/test/logs \
  --summary_secs 3 \
this get out_graph.pb
then i use this model  to test:
./native_client/deepspeech --model /home/huangheming/test/export/output_graph.pb --alphabet /home/huangheming/data/thchs30-csv/thchs30-alphabet.txt --lm /home/huangheming/data/thchs30-csv/thchs30-lm.binary --trie /home/huangheming/data/thchs30-csv/th30-trie --audio /home/huangheming/data/test/D12_851.wav
it have above error.

i tensorflow is tensorflow-gpu 0.9.0",run sh train model python epoch get use model test model alphabet audio error,issue,negative,neutral,neutral,neutral,neutral,neutral
476974733,"@lissyx  
i use english model deepspeech-0.4.1-models.tar.gz to test  is ok.
huangheming@iCTR-Server-2:~/test/model/models$ python3 /home/huangheming/DeepSpeech-0.4.1/native_client/python/client.py --model output_graph.pb --alphabet alphabet.txt --lm lm.binary --audio 2.wav  
Loading model from file output_graph.pb
modelName------> output_graph.pb
TensorFlow: v1.12.0-10-ge232881
DeepSpeech: v0.4.1-0-g0e40db6
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-03-27 12:51:12.804570: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-03-27 12:51:12.952268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2019-03-27 12:51:13.061010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
totalMemory: 11.90GiB freeMemory: 11.68GiB
2019-03-27 12:51:13.062078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1
2019-03-27 12:51:13.354086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-27 12:51:13.354132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 
2019-03-27 12:51:13.354139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y 
2019-03-27 12:51:13.354145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N 
2019-03-27 12:51:13.354448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11368 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-03-27 12:51:13.354805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11316 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1)
Loaded model in 0.6s.
Running inference.
why should one hall to on the way
Inference took 1.352s for 2.735s audio file.

but i test my own model also have error.",use model test python model alphabet audio loading model file ge warning reading entire model file memory transform model file graph reduce heap usage binary use found device name major minor found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability device memory physical device name bus id compute capability loaded model running inference one hall way inference took audio file test model also error,issue,negative,positive,neutral,neutral,positive,positive
476581855,"i use python3 util/taskcluster.py --branch v0.4.1 --arch gpu --target ./native_client  it work，but when i run
this command ：
./native_client/deepspeech  --model /home/huangheming/test/export/output_graph.pb --alphabet /home/huangheming/data/thchs30-csv/thchs30-alphabet.txt --lm /home/huangheming/data/thchs30-csv/thchs30-lm.binary --trie /home/huangheming/data/thchs30-csv/th30-trie --audio /home/huangheming/data/test/D12_851.wav

it also have  a  error：
TensorFlow: v1.12.0-10-ge232881
DeepSpeech: v0.4.1-0-g0e40db6
Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.
2019-03-26 18:59:57.526018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-03-26 18:59:57.697044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2019-03-26 18:59:57.802457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
totalMemory: 11.90GiB freeMemory: 11.68GiB
2019-03-26 18:59:57.803572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1
2019-03-26 18:59:58.096363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-26 18:59:58.096401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 
2019-03-26 18:59:58.096409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y 
2019-03-26 18:59:58.096415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N 
2019-03-26 18:59:58.096695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11368 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:17:00.0, compute capability: 6.1)
2019-03-26 18:59:58.097065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11316 MB memory) -> physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1)
Invalid argument: No OpKernel was registered to support Op 'Slice' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  <no registered kernels>

         [[{{node Slice}} = Slice[Index=DT_INT32, T=DT_INT32](Shape_1, Slice/begin, Slice/size)]]
Could not create model.
",use python branch arch target run command model alphabet audio also ge warning reading entire model file memory transform model file graph reduce heap usage binary use found device name major minor found device name major minor visible device interconnect strength edge matrix device memory physical device name bus id compute capability device memory physical device name bus id compute capability invalid argument registered support registered registered registered node slice slice could create model,issue,negative,positive,neutral,neutral,positive,positive
476551984,"it correct i use below command line ?
python3 util/taskcluster.py --branch v0.4.1  --arch gpu --target ./native_client      
  ",correct use command line python branch arch target,issue,negative,neutral,neutral,neutral,neutral,neutral
476550092,"I don't understand what you mean. You need to add ""--branch v0.4.1"" to the taskcluster.py call. 

Again, please provide full output so we can diagnose, and how you exported your model. Have you checked running the official English 0.4.1 model? ",understand mean need add branch call please provide full output diagnose model checked running official model,issue,negative,positive,neutral,neutral,positive,positive
476547761,"i use thchs-30   train my own model.
use DeepSpeech is DeepSpeech-0.4.1
use native client is native_client.amd64.cuda.linux.tar.xz  ,because use this  line “python3 util/taskcluster.py --arch gpu --target ./native_client”  to download deepspeech it still use libcuda10.0.so",use train model use use native client use line python arch target still use,issue,negative,neutral,neutral,neutral,neutral,neutral
476545805,Please share full output including the versions. Also document which model file you downloaded. ,please share full output also document model file,issue,positive,positive,positive,positive,positive,positive
476545414,Please avoid posting the same question in multiple issues. ,please avoid posting question multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
476494959,"we change this method  ,download zip :native_client.amd64.cuda.linux.tar.xz   
we download this package to test ,but i also have a error :
Invalid argument: No OpKernel was registered to support Op 'Slice' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  <no registered kernels>

         [[{{node Slice}} = Slice[Index=DT_INT32, T=DT_INT32](Shape_1, Slice/begin, Slice/size)]]
Could not create model.
we used:
DeepSpeech-0.4.1
native：
native_client.amd64.cuda.linux.tar.xz     i download from github。",change method zip package test also error invalid argument registered support registered registered registered node slice slice could create model used,issue,negative,neutral,neutral,neutral,neutral,neutral
476459219,"i use DeepSpeech-0.4.1  this version 。
python3 util/taskcluster.py --arch gpu --target ./native_client to install gpu deepspeech.
it also have error :
./native_client/deepspeech: error while loading shared libraries: libcudart.so.10.0: cannot open shared object file: No such file or directory
it really  fo cuda 9.0?",use version python arch target install also error error loading open object file file directory really,issue,negative,positive,neutral,neutral,positive,positive
476446489,"
| NVIDIA-SMI 384.130                Driver Version: 384.130                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            Off  | 00000000:17:00.0 Off |                  N/A |
| 29%   52C    P2    61W / 250W |  11594MiB / 12189MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN Xp            Off  | 00000000:65:00.0  On |                  N/A |
| 48%   77C    P2   245W / 250W |  11628MiB / 12188MiB |     91%      Default |
",driver version name volatile fan temp compute mib mib default mib mib default,issue,negative,neutral,neutral,neutral,neutral,neutral
476212414,Awesome! Now the PR got a backing issue.,awesome got backing issue,issue,positive,positive,positive,positive,positive,positive
476188464,"Current code relies on tensorflow r1.13 that depends on Cuda 10.0, please download earlier version, such as 0.4.1 for Cuda 9.0
",current code please version,issue,negative,neutral,neutral,neutral,neutral,neutral
476118426,"@aijianiula0601  @lissyx 我自己训练完成之后，然后用这个命令运行，我报错了，说是需要libcuda10.0,这个download下来gpu的是10.0的吗？
python3 util/taskcluster.py --arch gpu --target  ./native_client 我运行的是这个命令安装的
""libcudart.so.10.0 cannot open shared object file: No such file or directory""  报这个错。
但是我系统只有libcudart.so.9.0 ，请问有9的GPU吗？",python arch target open object file file directory,issue,negative,neutral,neutral,neutral,neutral,neutral
475890699,I've made the changes requested. Let me know if you find anything else.,made let know find anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
475678743,"Ok, I didn't expect it to be this trivial.
But now it works, thank you so much.",expect trivial work thank much,issue,negative,positive,positive,positive,positive,positive
475677163,"Actually, it doesn't cause everything below to be a comment, just ends the command right there, IIRC. If you want for the training to complete, you should see some errors about `--dev_batch_size` not being a recognized command or something like that. In any case, removing the comments should fix it :)",actually cause everything comment command right want training complete see command something like case removing fix,issue,negative,positive,positive,positive,positive,positive
475676810,"In the shell script you can't add comments after a line that ends with `\`, it causes everything below to be a comment. If you remove the `# 48`, `# 24`, etc, it should work.",shell script ca add line everything comment remove work,issue,negative,neutral,neutral,neutral,neutral,neutral
475649392,"yes,it's empty.Has anyone come across this?",yes anyone come across,issue,negative,neutral,neutral,neutral,neutral,neutral
475643217,After generating the alphabet.txt with `util/check_characters.py` it works. Thank you very much!,generating work thank much,issue,negative,positive,positive,positive,positive,positive
475593371,Looks like the test data has a character that is not in your alphabet.txt file. Take a look at `util/check_characters.py` and check if your alphabet file has all the characters needed.,like test data character file take look check alphabet file,issue,negative,neutral,neutral,neutral,neutral,neutral
475517701,"> hi,I trained “data_thcs30”.It can run and exported model file correctly,but it output nothing when i use the model to infer. I use the following command:

Can you document your training ?

> The WER is always 1.0 and res is null.

It's not `null`, it's empty",hi trained run model file correctly output nothing use model infer use following command document training wer always null null empty,issue,negative,negative,neutral,neutral,negative,negative
475515524,"I'm also facing the same issue. This is my test csv.



wav_filename | wav_filesize | transcript
-- | -- | --
/home/fyp128/account/cropped/1553229903792_9_Female_18-25_Sindhi.wav | 96078 | mere account me kitna balance hai
/home/fyp128/account/cropped/1553230310067_2_Female_18-25_Sindhi.wav | 99918 | mere account me kitna balance hai


",also facing issue test transcript mere account balance mere account balance,issue,negative,negative,negative,negative,negative,negative
475459417,"No need to rebase, extra commits fixing review comments are fine. We just need @kdavis-mozilla's review now.",need rebase extra fixing review fine need review,issue,negative,positive,positive,positive,positive,positive
475458955,I still can't get my branch to rebase so let me know when it's ready to be committed to master and I'll create a new branch and PR.,still ca get branch rebase let know ready master create new branch,issue,positive,positive,positive,positive,positive,positive
475437281,"@dabinat @reuben I triggered it on taskcluster:
```
$ git fetch upstream pull/1974/head:pr-1974
$ git push origin pr-1974
```

Then open PR and you can close it after.",triggered git fetch upstream git push origin open close,issue,negative,neutral,neutral,neutral,neutral,neutral
475435508,Can't seem to get the rebase working properly - probably because I already pushed the changes to my own repo - so I created a new branch and PR: #1974. ,ca seem get rebase working properly probably already new branch,issue,negative,positive,neutral,neutral,positive,positive
475433407,"We could also reduce the number of CUDA compute compatibilities we provide. I could measure that going from a 508MB `libdeepspeech.so` with the current list to 192MB by limiting to compute 3.5. Then, we can also use selective registration in tensorflow. With CUDA deps and runtime builtin (I need to get proper registration of the kernels), I'm around 138MB `libdeepspeech.so` for a compute 3.5 coverage.",could also reduce number compute provide could measure going current list limiting compute also use selective registration need get proper registration around compute coverage,issue,negative,neutral,neutral,neutral,neutral,neutral
475425739,"Two samples are causing the `inf` training loss problem:

|wav_filename|transcript|
|-|-|
|fisher-2004-split-wav/fe_03_00250-585.19-585.91.wav|yeah i didn't like it much actually|
|fisher-2005-split-wav/fe_03_05882-158.6-159.56.wav|you know what would you do if you had a million|

Before this PR, the corresponding audio files would create 36 and 48 time steps, respectively. Because of different rounding, the new feature computation generates 35 and 47 time steps instead, which is also exactly the length of their transcripts. The TF AudioSpectrogram op only creates full windows, dropping samples if needed, whereas `python_speech_features` uses the entire audio by padding the last window if needed.

You can reproduce the same problem but with the code on master by downloading the audio files and training with the following train CSV and `--n_hidden 2048`:

```
wav_filename,wav_filesize,transcript
fe_03_00250-585.19-585.91.wav,0,yeah i didn't like it much actuallyy
fe_03_05882-158.6-159.56.wav,1,you know what would you do if you had a millionn
```

Note that the last letter in the transcript is repeated to bring it up to the same length as the audio features. Something about these files plus a transcript that is big enough makes the model choke on it.

Some possible fixes for this:

1. Filter the data on `len(features) > len(transcript)`. (Note >, not >=). This is unfortunate because it's not a real requirement, it's just these particular samples that cause trouble, and it could remove good data.
2. Ignore `inf` loss when reducing the mean loss over samples and just pretend the sample doesn't exist. This will fix this problem now but can hide bigger issues in the future.
3. Remove those two files from the dataset.

I'm tempted towards 3 because it's the easiest without collateral damage. @kdavis-mozilla thoughts?",two causing training loss problem like much know would corresponding audio would create time respectively different rounding new feature computation time instead also exactly length full dropping whereas entire audio padding last window reproduce problem code master audio training following train transcript like much know would note last letter transcript repeated bring length audio something plus transcript big enough model choke possible filter data transcript note unfortunate real requirement particular cause trouble could remove good data ignore loss reducing mean loss pretend sample exist fix problem hide bigger future remove two towards easiest without collateral damage,issue,negative,positive,neutral,neutral,positive,positive
475067080,I meant I’ve fixed them but am waiting on those answers before I commit everything.,meant fixed waiting commit everything,issue,negative,positive,neutral,neutral,positive,positive
475059906,I’ve done all of the cleanup changes. I just need answers to my questions above on the 3ms offset and whether to get rid of isspace and then I’ll commit it.,done cleanup need offset whether get rid commit,issue,negative,neutral,neutral,neutral,neutral,neutral
474643285,I'll let @lissyx take a final look but from my side everything looks OK.,let take final look side everything,issue,negative,neutral,neutral,neutral,neutral,neutral
474628013,I cleaned everything up and moved that function private. Let me know if there's anything else.,everything function private let know anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
474601755,"For checking typos, I think argparse will throw an error. Maybe it has a more intuitive syntax for disabling booleans as well? Maybe switching to it instead of abseil is the easiest way to fix these problems.",think throw error maybe intuitive syntax well maybe switching instead easiest way fix,issue,negative,neutral,neutral,neutral,neutral,neutral
474597050,"@reuben @kdavis-mozilla -- I think this is a part of a bigger problem. 

The flag logic for `DeepSpeech.py` is obscure, and has been noted in other issues: #1460 #1540 #1931 #1730

In general, there are two big issues:

1. Flags passed at the CLI aren't checked. So, you can pass flags that don't exist, and no error is thrown. This means typos from users go unnoticed. Also, mandatory flags (such as mentioned in this issue  #1954) may be forgotten and then the user wastes a lot of time.
2. The boolean flags we use are weird (`--noFLAG` is not intuitive to turn off `--FLAG`)

I think we should give the flags some love -- I've personally been tripping over them a lot lately.
",think part bigger problem flag logic obscure noted general two big checked pas exist error thrown go unnoticed also mandatory issue may forgotten user lot time use weird intuitive turn flag think give love personally tripping lot lately,issue,negative,negative,neutral,neutral,negative,negative
474591449,"Ok, added some new commits including the client changes. I'm not sure how to detect words for every possible language, so please advise me on how to do this or if it's ok to have some languages that don't support this feature.",added new client sure detect every possible language please advise support feature,issue,positive,positive,positive,positive,positive,positive
474571781,"Because so many changes have been made so far, I thought it best to concentrate on getting the API figured out first, so that's why I only committed the API. I'll make the changes you suggested and commit the client code too.",many made far thought best concentrate getting figured first make commit client code,issue,positive,positive,positive,positive,positive,positive
474386963,It might be more complicated than expected to get EC2 infra,might complicated get infra,issue,negative,negative,negative,negative,negative,negative
474117880,@reuben @lissyx I've made the requested changes. Let me know what you think.,made let know think,issue,negative,neutral,neutral,neutral,neutral,neutral
474104620,"TF 1.14 (and, currently, nightly) now have support for variable sequence lengths in cudnn_rnn. I'm running some preliminary experiments to benchmark it, on top of the TF 1.13/tf.data changes.

Runs using 7 GPUs, with another unrelated TTS job using the 8th GPU:

||*without* CuDNN|*with* CuDNN|speedup|
|-|-|-|-|
|Time for 1st epoch|10h24min (37487 seconds)|6h58min (25120 seconds)|1.5x|
|Time for other epochs|2h (7200 seconds)|2h30min (9000 seconds)|0.8x|

I think the resource competition on the machine makes these results hard to evaluate, so I'll do some runs using all 8 GPUs taking the whole node in the future.",currently nightly support variable sequence running preliminary top another unrelated job th without st think resource competition machine hard evaluate taking whole node future,issue,negative,positive,neutral,neutral,positive,positive
474100873,"> I'm gonna check if that problem is due to the data, this tf.data code, or cudnn_rnn. I suspect it's unrelated to this PR.

Job 4298 running into the same problem, without the cudnn_rnn changes. So it's either this code or the data...",gon na check problem due data code suspect unrelated job running problem without either code data,issue,negative,negative,negative,negative,negative,negative
473892160,"Sorry, tried without command line. Now should be working.",sorry tried without command line working,issue,negative,negative,negative,negative,negative,negative
473879321,"@igorfritzsch There is still a merge commit, can you please get rid of it ?",still merge commit please get rid,issue,positive,neutral,neutral,neutral,neutral,neutral
473856442,"> I have read the current discussion, understood part of it. I did not realise `-e` was only exposed for `C++` until you pointed it out. no_mouth Is it complex/strainghtforward to expose that informotion in `python binding`, I'd like to do it.

This code is not ready, please avoid rushing on it. @dabinat Can help you exposing information once the current review comments are addressed.",read current discussion understood part exposed pointed expose python binding like code ready please avoid rushing help information current review,issue,positive,positive,neutral,neutral,positive,positive
473855850,"> > After installing above with `pip2 install --user deepspeech-0.5.0a1-cp27-cp27mu-linux_x86_64.whl` and running `deepspeech --version`:
> > > TensorFlow: v1.12.0-21-ge76355516a
> > > DeepSpeech: v0.5.0-alpha.1-52-gcdd7e05 
> Does that matches your branch ?

Yes, it does.

> > but when i run `deepspeech --model 'path/to/output_graph.pbmm' --alphabet 'path/to/alphabet.txt' --audio 'path/to/audio.wav' -e` I get following error:
> > > deepspeech: error: unrecognized arguments: -e
> > 
> > 
> > I need this to work. Is there some workaround or am I doing something wrong?
> 
> Have you read and understood the current discussion ? The current patches only expose `-e` to the `C++` `deepspeech` binary, there are no change to bindings to expose that information.

I have read the current discussion, understood part of it. I did not realise `-e` was only exposed for `C++` until you pointed it out. :no_mouth: Is it complex/strainghtforward to expose that informotion in `python binding`, I'd like to do it.
",pip install user running version branch yes run model alphabet audio get following error error unrecognized need work something wrong read understood current discussion current expose binary change expose information read current discussion understood part exposed pointed expose python binding like,issue,negative,negative,neutral,neutral,negative,negative
473855458,"@igorfritzsch Looks like we still need a rebase and merge removal, could you update your PR ?",like still need rebase merge removal could update,issue,negative,neutral,neutral,neutral,neutral,neutral
473854149,"I'm gonna check if that problem is due to the data, this tf.data code, or cudnn_rnn. I suspect it's unrelated to this PR.",gon na check problem due data code suspect unrelated,issue,negative,negative,negative,negative,negative,negative
473848336,"> which generates `deepspeech-0.5.0a1-cp27-cp27mu-linux_x86_64.whl` (How can i generate whl for python 3.6?)

Use a Python 3.6 virtualenv ?



> After installing above with `pip2 install --user deepspeech-0.5.0a1-cp27-cp27mu-linux_x86_64.whl` and running `deepspeech --version`:
> 
> > TensorFlow: v1.12.0-21-ge76355516a
> > DeepSpeech: v0.5.0-alpha.1-52-gcdd7e05

Does that matches your branch ?



> but when i run `deepspeech --model 'path/to/output_graph.pbmm' --alphabet 'path/to/alphabet.txt' --audio 'path/to/audio.wav' -e` I get following error:
> 
> > deepspeech: error: unrecognized arguments: -e
> 
> I need this to work. Is there some workaround or am I doing something wrong?

Have you read and understood the current discussion ? The current patches only expose `-e` to the `C++` `deepspeech` binary, there are no change to bindings to expose that information.",generate python use python pip install user running version branch run model alphabet audio get following error error unrecognized need work something wrong read understood current discussion current expose binary change expose information,issue,negative,negative,negative,negative,negative,negative
473847071,"I followed the steps for python binding from here: [DeepSpeech/native_client](https://github.com/dabinat/DeepSpeech/blob/master/native_client/README.md#python-bindings)

which generates `deepspeech-0.5.0a1-cp27-cp27mu-linux_x86_64.whl` (How can i generate whl for python 3.6?)

After installing above with `pip2 install --user deepspeech-0.5.0a1-cp27-cp27mu-linux_x86_64.whl` and running `deepspeech --version`:
> TensorFlow: v1.12.0-21-ge76355516a
> DeepSpeech: v0.5.0-alpha.1-52-gcdd7e05

but when i run `deepspeech --model 'path/to/output_graph.pbmm' --alphabet 'path/to/alphabet.txt' --audio 'path/to/audio.wav' -e` I get following error:
>deepspeech: error: unrecognized arguments: -e

I need this to work. Is there some workaround or am I doing something wrong?
I want to use DeepSpeech with (deepspeech-server) [https://github.com/MainRo/deepspeech-server].",python binding generate python pip install user running version run model alphabet audio get following error error unrecognized need work something wrong want use,issue,negative,negative,negative,negative,negative,negative
473841188,Seems like the training run 4290 that's testing this is having some problems. It looks like all training epochs have inf loss through the validation losses look reasonable.,like training run testing like training loss validation look reasonable,issue,negative,positive,positive,positive,positive,positive
473815957,"@stevesmit right now, i use `ARGS=""--model /path/to/output_graph.pbmm --alphabet /path/to/alphabet.txt --audio /path/to/audio/file.wav"" make run` in native_client to run deepspeech. Is there a way I can use it by calling `deepspeech` from CLI as we do after installing deepspeech with  `pip install deepspeech`?",right use model alphabet audio make run run way use calling pip install,issue,negative,positive,positive,positive,positive,positive
473573596,"@reuben EOL today, it was default python3 for debian jessie, and for ubuntu 14.04, maybe it's okay then.",today default python maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
473527084,"Given that it only fails on Python 3.4 (which reached end of life today), I'd suggest the alternative solution of dropping Python 3.4 support.",given python end life today suggest alternative solution dropping python support,issue,positive,neutral,neutral,neutral,neutral,neutral
473512818,This is the reason behind the failures of python 3.4 training tests in #1960 : https://tools.taskcluster.net/groups/GUt2zSjTQi--ubC0xzx-sQ/tasks/bkNRfcZaRtmVGgEKqj5TXg/details cc @carlfm01 ,reason behind python training,issue,negative,negative,negative,negative,negative,negative
473484405,Is there a possibility to have this be updated to work with CUDA 10.1 that has been recently deployed? Thanks!,possibility work recently thanks,issue,negative,positive,positive,positive,positive,positive
473472917,"This code should not change much between now and landing, so reviews can start already. This PR needs the r1.13 update to be merged, and since that's going slowly I'm asking for reviews already to speed things up. I'm not super happy with the way `evaluate.py` turned out, so that file may change a bit, but I won't force push until reviews are done.",code change much landing start already need update since going slowly already speed super happy way turned file may change bit wo force push done,issue,positive,positive,positive,positive,positive,positive
473421195,"> I'm not quite sure if I am installing it correctly. Could you show me how you installed it? @stevesmit

It was quite involved, but maybe this will help (use [this link](https://github.com/dabinat/DeepSpeech/blob/master/native_client/README.md) for reference):

1. Install python 3.5 on a Linux machine and make sure that is in the PATH. Easiest way is probably to use a conda environment
2. Install Bazel (go for version 0.17.something), follow their [instructions](https://docs.bazel.build/versions/master/install-ubuntu.html) on installing it (**Installing using Binary Installer**)
3. Add Bazel to the path. I guess it depends on where it gets installed, but if you follow Bazel's instructions it tells you how to add to the PATH
4. Clone [Mozilla's Tensorflow fork](https://github.com/mozilla/tensorflow/tree/r1.12) to your home (~) directory (for ease, I say). Then, `cd tensorflow` to get into the repo on your machine and `git checkout r1.12` to get to the correct branch
5. Clone @dabinat 's [deepspeech fork](https://github.com/dabinat/DeepSpeech). Again, navigate into the repo and `git checkout timing-info-api`
6. Head back into the tensorflow repo and run this command `ln -s ../DeepSpeech/native_client ./`
7. You need to then follow the instructions for [building Tensorflow](https://www.tensorflow.org/install/source). Just follow the instructions to install some pip packages. So follow the sections up to but not including the section titled **Install Bazel**
8. Then, run `./configure` to configure your build. It asks you a series of prompts - I didn't type anything and said no to everything, the first 1 or 2 prompts are about your python location, so just make sure that's correct otherwise type in the path to your python
9. From within the tensorflow repo, run `bazel build --config=monolithic -c opt --copt=-O3 --copt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie`
10. The build should run and complete. Then run `cd ../DeepSpeech/native_client` and then `make deepspeech`
11. Then, according to the guide it says you need to run - `PREFIX=/usr/local sudo make install`. I'm not sure if I did this or just added the location where the binary was installed to my PATH

That should work, I'll update anything here that isn't clear",quite sure correctly could show quite involved maybe help use link reference install python machine make sure path easiest way probably use environment install go version something follow binary installer add path guess follow add path clone fork home directory ease say get machine git get correct branch clone fork navigate git head back run command need follow building follow install pip follow section titled install run configure build series type anything said everything first python location make sure correct otherwise type path python within run build opt build run complete run make according guide need run make install sure added location binary path work update anything clear,issue,positive,positive,positive,positive,positive,positive
473415551,"> @stevesmit , congratulations! I am behind a proxy, hence bazel is giving me errors. Hope I'll get it working soon. The bazel build for TF has been going on for 40 minutes now, is it supposed to take this long or shoud I be worried?

Mine didn't take too long, maybe 10-15 minutes? I have quite a powerful machine though. I don't know much about building but as long as its running and progressing then I can't see how there's an issue 😄 ",behind proxy hence giving hope get working soon build going supposed take long worried mine take long maybe quite powerful machine though know much building long running ca see issue,issue,positive,negative,neutral,neutral,negative,negative
473393590,"> @kdavis-mozilla @reuben is it possible that dropout is not properly restored after the validation step ?

to confirm, I edited https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L279 to add
```py
    tf.summary.scalar(name='step_loss', tensor=avg_loss_across_towers, collections=['step_summaries'])
    for i, t in enumerate(dropout_rates):
        tf.summary.scalar(name='dropout_{}'.format(i), tensor=t, collections=['step_summaries'])
```
here is what I have in tensorboard:
![image](https://user-images.githubusercontent.com/2500584/54452980-a4411900-4756-11e9-897a-57a5d91c14a0.png)

_`dropout_0_1`, `dropout_1_1`, `dropout_2_1`, `dropout_3_1` , `dropout_4_1`, `dropout_5_1` correspond to `FLAGS.dropout_rate`, `FLAGS.dropout_rate2`, `FLAGS.dropout_rate3`, `FLAGS.dropout_rate4`, `FLAGS.dropout_rate5`, `FLAGS.dropout_rate6` (respectively) and I'm using `--dropout_rate 0.05 --dropout_rate6 0.5`_

=> [dropout_rates](https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L384) are properly set",possible dropout properly validation step confirm add enumerate image correspond respectively properly set,issue,negative,neutral,neutral,neutral,neutral,neutral
473349167,"@kdavis-mozilla @reuben  is it possible that dropout is not properly restored after the validation step ?
This could explain why : 
 - validation loss is much lower on the first epoch 
 - model overfits a lot after that",possible dropout properly validation step could explain validation loss much lower first epoch model lot,issue,negative,positive,positive,positive,positive,positive
473274705,"@stevesmit , congratulations! I am behind a proxy, hence bazel is giving me errors. Hope I'll get it working soon. The bazel build for TF has been going on for 40 minutes now, is it supposed to take this long or should I be worried?",behind proxy hence giving hope get working soon build going supposed take long worried,issue,negative,negative,negative,negative,negative,negative
473265359,I'm not quite sure if I am installing it correctly. Could you show me how you installed it? @stevesmit ,quite sure correctly could show,issue,negative,positive,positive,positive,positive,positive
473224237,"@carlfm01 Okay, next time we should run PR, build seems okay with v4.5, v4.6 and v4.7 https://taskcluster-artifacts.net/dpq6NZBAQYaD43hLAzwZPA/0/public/logs/live_backing.log but packaging step seems to fail, can you have a look @carlfm01 ",next time run build step fail look,issue,negative,negative,negative,negative,negative,negative
473221578,"> I also want to use this build.
> @stevesmit @LiquidPrototype, should I clone timing-info-api branch or timing-info-client branch?
> timing-info-client commit shows the -e flag option.
> Also, can someone point me where can I find the difference between api and client, and how to use api. I have been using deepspeech through the command line client (python package) so far.

Good question, I'm kinda hoping that they merge the fork onto this repo and then we can just use the binaries that they build. But I think the `timing-info-api` branch is the correct one because that's the one involved in the pull request.

*EDIT: Managed to get the branch built and running. It outputs the word timings 🎉 @CP-4 `timing-info-api` is the branch I used. ",also want use build clone branch branch commit flag option also someone point find difference client use command line client python package far good question merge fork onto use build think branch correct one one involved pull request edit get branch built running word branch used,issue,positive,positive,positive,positive,positive,positive
473181224,"I also want to use this build.
@stevesmit @LiquidPrototype, should I clone timing-info-api branch or timing-info-client branch? 
timing-info-client commit shows the -e flag option.
Also, can someone point me where can I find the difference between api and client, and how to use api. I have been using deepspeech through the command line client (python package) so far.",also want use build clone branch branch commit flag option also someone point find difference client use command line client python package far,issue,negative,positive,neutral,neutral,positive,positive
473111531,"@dabinat I believe so. I did git clone -b timing-info-api https://github.com/dabinat/DeepSpeech

Am I missing something about how to install this?
",believe git clone missing something install,issue,negative,negative,negative,negative,negative,negative
473036596,"Mostly green, just needs the Dockerfile to be updated and the Windows CUDA worker update to be deployed.",mostly green need worker update,issue,negative,negative,negative,negative,negative,negative
472893787,@GeorgeFedoseev Thanks. Any idea about how to clean-up the image after build?,thanks idea image build,issue,negative,positive,positive,positive,positive,positive
472799100,"@kdavis-mozilla  I'm not sure I can reproduce with another dataset since it seems to be related to difference of distribution of my `train` and `dev` sets (not so uncommon though).

NB: If you ignore run#1, run#2 to run#5 use the same datasets, the same batch sizes and, IMHO, decreasing learning rate between runs cannot explain the observed variations on itself.",sure reproduce another since related difference distribution train dev uncommon though ignore run run run use batch size decreasing learning rate explain,issue,negative,positive,positive,positive,positive,positive
472785410,"@kdavis-mozilla I will look into it but shuffling batches could be a good idea anyway.

@reuben  what do you think ?",look shuffling could good idea anyway think,issue,negative,positive,positive,positive,positive,positive
472782832,"@nicolaspanel I think as you've such a complicated setup, different data sets, different learning rates, different GPU's, different batch sizes.... to actually determine if this is or is not a bug.

Is there anyway you can create a much simpler example that exhibits this effect? Maybe just on Common Voice data so we can rule out some unknowns.",think complicated setup different data different learning different different batch size actually determine bug anyway create much simpler example effect maybe common voice data rule,issue,negative,negative,neutral,neutral,negative,negative
472779015,BTW: I have no idea what cause the `high validation loss` - `low validation loss` - `high validation loss` - `low validation loss` - ... pattern  or why first epoch of each run is always better than others,idea cause high validation loss low validation loss high validation loss low validation loss pattern first epoch run always better,issue,negative,positive,positive,positive,positive,positive
472777159,"@kdavis-mozilla thank you for your answer

> I feel it's hard to conclude anything from the information presented.
> 
> For example there are many questions you leave un-answered...
> 
> 1. Were the sm and md training sets drawn from the same distribution

see details below

> 2. Were the sm an md dev sets drawn from the same distribution

see details below

> 3. Why are you switching batch size between sm and md

The original goal was to speedup training since I switched from a 12G GPU to a 16G (I wasn't expected such improvement on both training and validation loss)


> 5. Why are you switching the learning rate between runs

I was just testing

> 6. Were the sm training and dev sets drawn from the same distribution

see below

> 7. Were the md training and dev sets drawn from the same distribution
>    8...

see below

> 
> > dev does not match exactly the train set distribution. dev set records are shorter and are more noisy.
> 
> Why are you doing this? This does not make sense to me.

My task focus on conversational audio (noisy / badly pronounced / etc.). This is why I use it exclusively for `dev`/`test` evaluations.  This come from the fact that I do not have enough annotated conversational data (~20k exemples, ~15h) . I then have to use data from other sources.


**dataset description**:
 - md dataset is an extension of sm dataset using data-augmentation (increased tempo for exemple). Goal is to reduce variance through more data
 - train: 330k samples. 20% [CV data](https://voice.mozilla.org) / 50%  [TS data](https://github.com/nicolaspanel/TrainingSpeech) (audio books, very low number of speaker) / 30% conversational speech
   durations distributions
   ![train_durations](https://user-images.githubusercontent.com/2500584/54345586-9a7ac100-4643-11e9-9aa8-bf0ae6a6154a.png)

 - dev: 2k samples. 100% conversational (sampled randomly from entire dataset)
   durations distribution
   ![dev_durations](https://user-images.githubusercontent.com/2500584/54343106-59cc7900-463e-11e9-8037-786dc8ec400b.png)

 - test: 2k samples. 100% conversational (sampled randomly from entire dataset)
   durations distribution
   ![test_durations](https://user-images.githubusercontent.com/2500584/54343166-82547300-463e-11e9-8db1-d70615ecd27c.png)


NOTABENE: 

> 4. Why within a run of sm or md does the validation error oscillate (On our data this never happens to this extent)



**My guess is:**
As far as I understand data feeding mechanism, batches are always run in the same order (short recordings first)

since TS has ""longer"" audio recordings than other source, the batches that are processed last (from 8 to 10 seconds audio) are ~85% from [TS data](https://github.com/nicolaspanel/TrainingSpeech)  (audiobooks), ~5% from [CV data](https://voice.mozilla.org) and ~10 from ""conversational"" dataset

Training is then very focus on working well on audiobooks data, which is not the goal here.

One option to prevent this could be to shuffle batches order while keeping recording of the same size together to prevent unecessary zero-padding.

Another option could be to remove 8 to 10 second data from TS to ensure the end of the training focus on conversational data…",thank answer feel hard conclude anything information example many leave training drawn distribution see dev drawn distribution see switching batch size original goal training since switched improvement training validation loss switching learning rate testing training dev drawn distribution see training dev drawn distribution see dev match exactly train set distribution dev set shorter noisy make sense task focus conversational audio noisy badly pronounced use exclusively dev test come fact enough conversational data use data description extension tempo goal reduce variance data train data data audio low number speaker conversational speech dev conversational randomly entire distribution test conversational randomly entire distribution within run validation error oscillate data never extent guess far understand data feeding mechanism always run order short first since longer audio source last audio data data conversational training focus working well data goal one option prevent could shuffle order keeping recording size together prevent another option could remove second data ensure end training focus conversational,issue,negative,positive,neutral,neutral,positive,positive
472719429,"Hello @ambigus9!
Yep, most probably you can strip image to a smaller size by cleaning up after build. I didn't look into this.",hello yep probably strip image smaller size cleaning build look,issue,negative,neutral,neutral,neutral,neutral,neutral
472719367,"I feel it's hard to conclude anything from the information presented.

For example there are many questions you leave un-answered...

1. Were the sm and md training sets drawn from the same distribution
2. Were the sm an md dev sets drawn from the same distribution
3. Why are you switching batch size between sm and md
4. Why within a run of sm or md does the validation error oscillate (On our data this never happens to this extent)
5. Why are you switching the learning rate between runs
6. Were the sm training and dev sets drawn from the same distribution
7. Were the md training and dev sets drawn from the same distribution
8...

Just saw that in the second post you answer the train vs dev distribution question for (both?) data sets when you say

> dev does not match exactly the train set distribution. dev set records are shorter and are more noisy.

Why are you doing this? This does not make sense to me.",feel hard conclude anything information example many leave training drawn distribution dev drawn distribution switching batch size within run validation error oscillate data never extent switching learning rate training dev drawn distribution training dev drawn distribution saw second post answer train dev distribution question data say dev match exactly train set distribution dev set shorter noisy make sense,issue,negative,positive,positive,positive,positive,positive
472619242,"@stevesmit I also get the same error when I try to add that flag.  

",also get error try add flag,issue,negative,neutral,neutral,neutral,neutral,neutral
472532782,"some additional details:
 - `dev` set is pretty small (~2000 samples)
 - `dev` does not match exactly the `train` set distribution. `dev` set records are shorter and are more noisy.

trainning logs:
```
****previous outputs removed****

Training of Epoch 18 - loss: 10.782960
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:02 Time:  0:33:02
I Validating epoch 18...
I Validation of Epoch 18 - loss: 44.131589
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 19...
I Training of Epoch 19 - loss: 10.719870
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:00 Time:  0:33:00
I Validating epoch 19...
I Validation of Epoch 19 - loss: 30.047718
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 20...
I Training of Epoch 20 - loss: 10.510714
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:00 Time:  0:33:00
I Validating epoch 20...
I Validation of Epoch 20 - loss: 44.507151
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 21...
I Training of Epoch 21 - loss: 10.487166
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 21...
I Validation of Epoch 21 - loss: 31.637611
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 22...
I Training of Epoch 22 - loss: 10.505370
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:00 Time:  0:33:00
I Validating epoch 22...
I Validation of Epoch 22 - loss: 45.537667
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 23...
I Training of Epoch 23 - loss: 10.350520
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:00 Time:  0:33:00
I Validating epoch 23...
I Validation of Epoch 23 - loss: 31.660463
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 24...
I Training of Epoch 24 - loss: 10.268184
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:01 Time:  0:33:01
I Validating epoch 24...
I Validation of Epoch 24 - loss: 47.216556
I Early stop triggered as (for last 10 steps) validation loss: 47.216556 with standard deviation: 8.930504 and mean: 35.083293
I FINISHED Optimization - training time: 5:30:46
100% (24 of 24) |###############################################| Elapsed Time: 0:00:02 Time:  0:00:02

****hide test details****
****start new run****

root@xxx:/DeepSpeech# python DeepSpeech.py  [...]
('Preprocessing', ['/data/train.csv'])
top('Loaded from cache at', '/data/train_cache.hdf5')
('Preprocessing', ['/data/cy_2019-03-12_dev_stt.csv'])
Preprocessing done
I STARTING Optimization
I Training epoch 25...
I Training of Epoch 25 - loss: 8.752240
100% (5115 of 5115) |###########################################| Elapsed Time: 0:32:55 Time:  0:32:55
I Validating epoch 25...
I Validation of Epoch 25 - loss: 19.319501
100% (24 of 24) |###############################################| Elapsed Time: 0:00:02 Time:  0:00:02
I Training epoch 26...
I Training of Epoch 26 - loss: 8.332165
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 26...
I Validation of Epoch 26 - loss: 47.577795
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 27...
I Training of Epoch 27 - loss: 8.070539
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 27...
I Validation of Epoch 27 - loss: 31.842970
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 28...
I Training of Epoch 28 - loss: 7.798905
100% (5115 of 5115) |###########################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 28...
I Validation of Epoch 28 - loss: 48.417005
100% (24 of 24) |###############################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 29...
I Training of Epoch 29 - loss: 7.641581
100% (5115 of 5115) |######################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 29...
I Validation of Epoch 29 - loss: 33.384423
100% (24 of 24) |##########################################| Elapsed Time: 0:00:03 Time:  0:00:03
I Training epoch 30...
I Training of Epoch 30 - loss: 7.497557
100% (5115 of 5115) |######################################| Elapsed Time: 0:33:03 Time:  0:33:03
I Validating epoch 30...
I Validation of Epoch 30 - loss: 48.733190
I Early stop triggered as (for last 6 steps) validation loss: 48.733190 with standard deviation: 10.867657 and mean: 36.108339
I FINISHED Optimization - training time: 3:18:32
100% (24 of 24) |##########################################| Elapsed Time: 0:00:02 Time:  0:00:02

****hide test details****
****start new run****

root@xxx:/DeepSpeech# python DeepSpeech.py   [...]
('Preprocessing', ['/data/train.csv'])
('Loaded from cache at', '/data/train_cache.hdf5')
('Preprocessing', ['/data/cy_2019-03-12_dev_stt.csv'])
Preprocessing done
I STARTING Optimization
I Training epoch 31...
I Training of Epoch 31 - loss: 6.244256
100% (5115 of 5115) |######################################| Elapsed Time: 0:32:54 Time:  0:32:54
I Validating epoch 31...
I Validation of Epoch 31 - loss: 20.581001
100% (24 of 24) |##########################################| Elapsed Time: 0:00:02 Time:  0:00:02
I Training epoch 32...
 17% (911 of 5115) |######                                 | Elapsed Time: 0:01:59 ETA:   0:10:39
 85% (4384 of 5115) |################################      | Elapsed Time: 0:23:02 ETA:   0:07:42 85% (4385 of 5115) |################################      | Elapsed Time: 0:23:05 ETA:   0:29:54I Training of Epoch 32 - loss: 5.884225
100% (5115 of 5115) |######################################| Elapsed Time: 0:34:19 Time:  0:34:19
I Validating epoch 32...
I Validation of Epoch 32 - loss: 52.134761
100% (24 of 24) |##########################################| Elapsed Time: 0:00:04 Time:  0:00:04
I Training epoch 33...
I Training of Epoch 33 - loss: 5.564034
100% (5115 of 5115) |######################################| Elapsed Time: 0:34:33 Time:  0:34:33
I Validating epoch 33...
I Validation of Epoch 33 - loss: 39.296744
100% (24 of 24) |##########################################| Elapsed Time: 0:00:03 Time:  0:00:03
```",additional dev set pretty small dev match exactly train set distribution dev set shorter noisy previous removed training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss early stop triggered last validation loss standard deviation mean finished optimization training time time time hide test start new run root python top cache done starting optimization training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss early stop triggered last validation loss standard deviation mean finished optimization training time time time hide test start new run root python cache done starting optimization training epoch training epoch loss time time epoch validation epoch loss time time training epoch time eta time eta time eta training epoch loss time time epoch validation epoch loss time time training epoch training epoch loss time time epoch validation epoch loss time time,issue,negative,positive,neutral,neutral,positive,positive
472469081,"I don't know, I don't use Docker. @GeorgeFedoseev might be able to answer.",know use docker might able answer,issue,negative,positive,positive,positive,positive,positive
472418840,Does it still overfit properly for producing a model we can use in the tests ?,still overfit properly model use,issue,negative,neutral,neutral,neutral,neutral,neutral
472392957,"This task should have exactly the payload produced by this PR: https://tools.taskcluster.net/groups/ehgsEk_qRJyVYpEx073_Rg/tasks/HGHJYqdJQpqzmjU71ijnMw/details

It has been able to successfully upload: https://www.nuget.org/packages/DeepSpeech-GPU/0.5.0-alpha.1 https://www.nuget.org/packages/DeepSpeech/0.5.0-alpha.1",task exactly produced able successfully,issue,negative,positive,positive,positive,positive,positive
472389593,"Sadly it gives me an error `unrecognized arguments: -e` 

I am using the command line tool and calling it as follows: 

`deepspeech --model models/output_graph.pb --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio sample_audio/sample_1.wav -e`

Results of running `deepspeech --v`:  `TensorFlow: v1.12.0-rc0-1804-gbc76bad
DeepSpeech: v0.5.0-alpha.1-44-g1a73372`",sadly error unrecognized command line tool calling model alphabet audio running ga,issue,negative,negative,negative,negative,negative,negative
472257769,"Thanks! It works! Here is the code i'm using:

```
python -u DeepSpeech.py \
...
--summary_dir /home/miguel/DeepSpeech \

tensorboard --logdir=/home/miguel/DeepSpeech/
```",thanks work code python,issue,negative,positive,positive,positive,positive,positive
472239122,"Thanks. Nop it is not breaking my build. Actually it's completed:

```
Scanning dependencies of target phrase_table_vocab
[ 87%] Building CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o
[ 88%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o
[ 89%] Linking CXX executable ../../bin/phrase_table_vocab
[ 90%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o
[ 90%] Built target phrase_table_vocab
[ 91%] Building CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o
[ 92%] Linking CXX executable ../../bin/filter
[ 92%] Built target filter
[ 92%] Linking CXX executable ../tests/model_test
[ 92%] Built target model_test
[ 93%] Linking CXX static library ../../lib/libkenlm_builder.a
[ 93%] Built target kenlm_builder
Scanning dependencies of target lmplz
Scanning dependencies of target adjust_counts_test
Scanning dependencies of target count_ngrams
Scanning dependencies of target corpus_count_test
[ 94%] Building CXX object lm/builder/CMakeFiles/corpus_count_test.dir/corpus_count_test.cc.o
[ 94%] Building CXX object lm/builder/CMakeFiles/adjust_counts_test.dir/adjust_counts_test.cc.o
[ 95%] Building CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o
[ 96%] Building CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o
[ 97%] Linking CXX executable ../../tests/adjust_counts_test
[ 97%] Built target adjust_counts_test
[ 98%] Linking CXX executable ../../tests/corpus_count_test
[ 98%] Built target corpus_count_test
[ 99%] Linking CXX executable ../../bin/lmplz
[ 99%] Built target lmplz
[100%] Linking CXX executable ../../bin/count_ngrams
[100%] Built target count_ngrams
Removing intermediate container 28138ee9895a
 ---> c78c97b1ebf9
Step 73/73 : WORKDIR /DeepSpeech
 ---> Running in eb38fc54b0de
Removing intermediate container eb38fc54b0de
 ---> 76df983accfd
Successfully built 76df983accfd
```",thanks breaking build actually scanning target building object building object linking executable building object built target building object linking executable built target filter linking executable built target linking static library built target scanning target scanning target scanning target scanning target building object building object building object building object linking executable built target linking executable built target linking executable built target linking executable built target removing intermediate container step running removing intermediate container successfully built,issue,positive,positive,positive,positive,positive,positive
472236505,"Is it breaking your build? It's not ideal, but pretty much all large C++ codebases produce tons of warnings. These are in TensorFlow, so there's not much we can do about it.",breaking build ideal pretty much large produce much,issue,positive,positive,positive,positive,positive,positive
472152932,"Modulo the docker build, tests are green.",modulo docker build green,issue,negative,negative,negative,negative,negative,negative
471981253,"> Thanks. It’s done

So @myrainbowandsky did the solution suggested @myhugong worked ? Were you just missing a space ? Can we close this ?",thanks done solution worked missing space close,issue,negative,neutral,neutral,neutral,neutral,neutral
471960382,"> > I'd love to assess this version, but am unsure how to get a pre-built binary? Is there a guide on how to build @dabinat 's version?
> 
> Checkout his branch and follow the build docs ?

Managed to do this, thanks. But now I can't work out how to flag to the client to output the word timings :/ I would post this on the fork, but I can't seem post an issue there. ",love ass version unsure get binary guide build version branch follow build thanks ca work flag client output word would post fork ca seem post issue,issue,negative,positive,positive,positive,positive,positive
471767880,"If anything, I think we should do the opposite of masking with zero: print an error with the incorrect transcript and stop the training immediately.",anything think opposite zero print error incorrect transcript stop training immediately,issue,negative,neutral,neutral,neutral,neutral,neutral
471764473,"@reuben @kdavis-mozilla after further investigations, and removing ""noise"" recordings, I was still facing the `inf` loss issue.

After a closer look, I noticed a single mislabeled recording which :
1) raised `W tensorflow/core/util/ctc/ctc_loss_calculator.cc:144] No valid path found` (see https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/core/util/ctc/ctc_loss_calculator.cc#L144)
2) produced the `inf` loss

(probably the same issue as https://github.com/mozilla/DeepSpeech/issues/1910 BTW)

Since it is very frustrating to waste training/investigation hours for a single mislabeled recording, maybe It could be usefull to include a `tf.where` for replacing `inf`s with zeros [here](https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L195):
```py
total_loss = tf.nn.ctc_loss(labels=batch_y, inputs=logits, sequence_length=batch_seq_len)
# replace `inf` with 0
total_loss = tf.where(tf.is_inf(total_loss), tf.zeros_like(total_loss), total_loss)
...
```

What do you think ?",removing noise still facing loss issue closer look single recording raised valid path found see produced loss probably issue since waste single recording maybe could include replace think,issue,negative,negative,negative,negative,negative,negative
471560288,"> @nicolaspanel Wouldn't it be easier to try and use a better VAD? Maybe something like [this](https://github.com/jtkim-kaist/VAD)?

@kdavis-mozilla I am currently using webrtc-vad which have the advantage of being very fast with very few hyperparameters.
Since DS does a pretty good job already I'm not sure including a new processing step will worth the cost.
Furthermore, it is not clear how https://github.com/jtkim-kaist/VAD or alternatives will behave when people are laughing, sneezing, etc.

@reuben I will investigate further to confirm it comes from https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss
",would easier try use better maybe something like currently advantage fast since pretty good job already sure new step worth cost furthermore clear behave people laughing sneezing investigate confirm come,issue,positive,positive,positive,positive,positive,positive
471529862,@nicolaspanel Wouldn't it be easier to try and use a better VAD? Maybe something like [this](https://github.com/jtkim-kaist/VAD)?,would easier try use better maybe something like,issue,positive,positive,positive,positive,positive,positive
471529582,"Yes, that would have to be fixed in postprocessing. It's not optimal, but would be better than not being able to train the model at all.",yes would fixed optimal would better able train model,issue,positive,positive,positive,positive,positive,positive
471529315,"@reuben I think ""making the label several spaces rather than just one"" would have the unwanted effect of causing the model to now output multiple spaces if someone paused ""too long"" between words, which is also not desired.",think making label several rather one would unwanted effect causing model output multiple someone long also desired,issue,negative,negative,neutral,neutral,negative,negative
471524515,"The large difference between input length and correct label length could be making the CTC loss explode. You could try making the label several spaces rather than just one, or some other strategy like one space for every 300ms of audio and see if that solves it.",large difference input length correct label length could making loss explode could try making label several rather one strategy like one space every audio see,issue,negative,positive,positive,positive,positive,positive
471519198,"> I'm still not sure I understand the logic of including such in the training set. Is it to make the system not transcribe ""silences"", which may include background noise.
> 
> The system will learn to ignore ""silences"", which may include background noise, just from normal training data with non-trivial transcripts, as pauses between words and phrases provide training data for such.
> 

You are right. But since it is a very common situation for me I would like to use this samples as additional training data.

> Is your goal in the ""live system"" to feed such 2h audio recordings, segmented by VAD, to the system?

yes

> Do you hope that your training with empty transcripts will train the system to deal with VAD failures?

My guess is that it will lead to better silence and background noise detection and then improve global accuracy.

",still sure understand logic training set make system transcribe may include background noise system learn ignore may include background noise normal training data provide training data right since common situation would like use additional training data goal live system feed audio segmented system yes hope training empty train system deal guess lead better silence background noise detection improve global accuracy,issue,positive,positive,positive,positive,positive,positive
471515781,"I'm still not sure I understand the logic of including such in the training set. Is it to make the system not transcribe ""silences"", which may include background noise.

The system will learn to ignore ""silences"", which may include background noise, just from normal training data with non-trivial transcripts, as pauses between words and phrases provide training data for such.

Is your goal in the ""live system"" to feed such 2h audio recordings, segmented by VAD, to the system? Do you hope that your training with empty transcripts will train the system to deal with VAD failures?",still sure understand logic training set make system transcribe may include background noise system learn ignore may include background noise normal training data provide training data goal live system feed audio segmented system hope training empty train system deal,issue,negative,positive,positive,positive,positive,positive
471499532,"I'm processing long recordings (up to 2h) which are cut into sub-recordings of 1 to 10 seconds using VAD.
Since it is very common that VAD detects background noise as voice, even if nothing have been said, I'd like to include this samples to the training set.",long cut since common background noise voice even nothing said like include training set,issue,negative,negative,negative,negative,negative,negative
471489113,"Why are you including nose with the transcript """"?

The usual way to make the model robust to background noise is to have a data set with non-trivial transcripts with background noise in it already or to lay background noise over a clean(er) data set with non-trivial transcripts.",nose transcript usual way make model robust background noise data set background noise already lay background noise clean er data set,issue,positive,positive,neutral,neutral,positive,positive
471474551,"I'm going to close this, because it is the third message from the same user with no added value and no clear reply to my previous questions. Please stop spamming everywhere, this is not going to get you more help.",going close third message user added value clear reply previous please stop everywhere going get help,issue,positive,negative,neutral,neutral,negative,negative
471359367,"Ok, I’ll wait to see if any more changes are needed first before I tidy up.",wait see first tidy,issue,negative,positive,positive,positive,positive,positive
471216554,@lissyx I've made the changes - let me know if this works better for you.,made let know work better,issue,negative,positive,positive,positive,positive,positive
471160095,"> @lissyx what do you mean are okay? is there any release for Windows?

It means the changes to have them are good, it should be able to get merged soon",mean release good able get soon,issue,negative,positive,positive,positive,positive,positive
471086594,"> C++ deepspeech binary are passing, .Net Framework should soon.

Code flow for `DeepSpeechConsole.exe` is likely not the nicest one for now, I can't yet tell if it's expected or we are packaging that improperly. But anyway, in the end, I get working inference.",binary passing framework soon code flow likely one ca yet tell improperly anyway end get working inference,issue,negative,neutral,neutral,neutral,neutral,neutral
471079763,"C++ deepspeech binary are passing, .Net Framework should soon.",binary passing framework soon,issue,negative,neutral,neutral,neutral,neutral,neutral
470886137,"Thanks. It’s done

Jio <notifications@github.com>于2019年3月8日 周五14:30写道：

> @myrainbowandsky <https://github.com/myrainbowandsky> , Try to insert a
> line with a space in your alphabet.txt
> （alphabet.txt加上一行，填上个空格试试，兄弟）
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/1935#issuecomment-470821373>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/Ahcm9EsKpIk50YDUygALdNyDCVmMz0nMks5vUgOEgaJpZM4bgdlI>
> .
>
-- 
Regards,
Wentao Xu
Master of Research in regenerative medicine, University of Bath, UK
Master of Science in Industrial Economics, Royal Institute of Technology,
Sweden
Bachelor in Bioengineering, China Institute of Metrology
",thanks done try insert line space reply directly view mute thread master research regenerative medicine university bath master science industrial economics royal institute technology bachelor china institute metrology,issue,negative,positive,positive,positive,positive,positive
470821373,"@myrainbowandsky ,  Try to insert  a line with a space  in your alphabet.txt
（alphabet.txt加上一行，填上个空格试试，兄弟）

",try insert line space,issue,negative,neutral,neutral,neutral,neutral,neutral
470643810,There are no new dependencies in this version so the instructions are the same as for building the master branch.,new version building master branch,issue,negative,positive,positive,positive,positive,positive
470510324,"> I'd love to assess this version, but am unsure how to get a pre-built binary? Is there a guide on how to build @dabinat 's version?

Checkout his branch and follow the build docs ?",love ass version unsure get binary guide build version branch follow build,issue,negative,positive,positive,positive,positive,positive
470508428,"I'd love to assess this version, but am unsure how to get a pre-built binary? Is there a guide on how to build @dabinat 's version?",love ass version unsure get binary guide build version,issue,negative,positive,positive,positive,positive,positive
470488097,"@absin1 I pushed the importer, which is mostly done, to the [issue1906](https://github.com/mozilla/DeepSpeech/tree/issue1906) branch.",importer mostly done issue branch,issue,negative,positive,positive,positive,positive,positive
470310121,"> I still have a question though: is it still needed/possible to reset `LSTM`s internal state before evaluating a new batch ?

It's not needed anymore, since in that case we don't specify the `initial_state`, TF's RNN implementation will start from zero on every call.",still question though still reset internal state new batch since case specify implementation start zero every call,issue,negative,positive,neutral,neutral,positive,positive
470308934,"Hi @nicolaspanel, sorry for the delay, I was out on vacation.",hi sorry delay vacation,issue,negative,negative,negative,negative,negative,negative
470211031,"@Hafsa26 I want to know about the urdu corpus you have used. Let me know the details of it. How have you obtained it, since i don't find any publicly available corpus of that size for urdu.",want know corpus used let know since find publicly available corpus size,issue,negative,positive,positive,positive,positive,positive
470070033,"@myrainbowandsky Have you tried dumping around the error in `util/text.py`, and cross-check what was being ingested from `alphabet.txt` ?",tried dumping around error,issue,negative,neutral,neutral,neutral,neutral,neutral
470067904,"> Yes, it is in the alphabet! I am driven crazy.

Obviously, `util/text.py` think it is not, so please check. Maybe you have some dangling non-printable char messing with the code, I don't know.",yes alphabet driven crazy obviously think please check maybe dangling char messing code know,issue,negative,negative,negative,negative,negative,negative
470066794,"Yes, it is in the alphabet! I am driven crazy.

lissyx <notifications@github.com>于2019年3月6日 周三19:04写道：

> But I have triple-checked the data. They are identical! coding problem?
> But I wrote the both files in utf-8.
>
> Well, I can't judge without more informations. All I see is that your have
> a missing char in your alphabet: 我. Is this in your alphabet.txt ?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/1935#issuecomment-470066137>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/Ahcm9D2wtgCr8uz5ZyM0oPRGYjRCrpptks5vT6DGgaJpZM4bgdlI>
> .
>
-- 
Regards,
Wentao Xu
Master of Research in regenerative medicine, University of Bath, UK
Master of Science in Industrial Economics, Royal Institute of Technology,
Sweden
Bachelor in Bioengineering, China Institute of Metrology
",yes alphabet driven crazy data identical problem wrote well ca judge without see missing char alphabet reply directly view mute thread master research regenerative medicine university bath master science industrial economics royal institute technology bachelor china institute metrology,issue,negative,negative,negative,negative,negative,negative
470066137,"> But I have triple-checked the data. They are identical! coding problem? But I wrote the both files in utf-8.

Well, I can't judge without more informations. All I see is that your have a missing char in your  alphabet: `我`. Is this in your `alphabet.txt` ?",data identical problem wrote well ca judge without see missing char alphabet,issue,negative,negative,negative,negative,negative,negative
470061179,But I have triple-checked the data. They are identical! coding problem? But I wrote the both files in  utf-8.,data identical problem wrote,issue,negative,neutral,neutral,neutral,neutral,neutral
470044787,"@myrainbowandsky And yet the error is very clear, you have a character that appears in your dataset and that is not in your alphabet.",yet error clear character alphabet,issue,negative,positive,positive,positive,positive,positive
469981210,"@kdavis-mozilla I had an email conversation with the founders of the project and they suggested a better way forward is to collaborate directly into the project, I can share the email thread with you if you share your email address.",conversation project better way forward collaborate directly project share thread share address,issue,positive,positive,positive,positive,positive,positive
469846357,My original motive for creating this was as a way of making the output easier to parse. But when the timing info patch lands I’ll just be dealing with the JSON output so there’s no need unless someone else can think of a use for it.,original motive way making output easier parse timing patch dealing output need unless someone else think use,issue,positive,positive,positive,positive,positive,positive
469844840,"Sorry for the confusion, I was viewing the command-line client as a single entity rather than as a separate API and client.

I’ll make these changes later this week.",sorry confusion client single entity rather separate client make later week,issue,negative,negative,negative,negative,negative,negative
469840548,"@dabinat Thanks for this patch, it's really important, and I hope the changes I'm suggesting makes it easier. I'm eager that we can use that feature.",thanks patch really important hope suggesting easier eager use feature,issue,positive,positive,positive,positive,positive,positive
469678161,"@pvanickova Deep Speech is purely speech-to-text, any auxiliary functionality will limit it's applicability.

In particular, adding a sentence boundary detector will require an additional model, and thus additional memory and compute, and thus limit the small platform devices it can be deployed on.

Adding a sentence boundary detector will require obtaining data to train the sentence boundary detector on. For example, if we wished to target simplified Chinese Mandarin, we would have to obtain a data set tagged with sentence boundaries which adds another dependency to the data sets required and a further delay to others not interested in detecting sentence boundaries.

Furthermore, there are many Deep Speech applications, e.g. command and control, that do not require sentence boundaries. Requiring such applications to install a sentence boundary detector that is not used seems inefficient.

That said, downstream products should feel free to integrate a sentence boundary detector.",deep speech purely auxiliary functionality limit applicability particular sentence boundary detector require additional model thus additional memory compute thus limit small platform sentence boundary detector require data train sentence boundary detector example wished target simplified mandarin would obtain data set tagged sentence another dependency data delay interested sentence furthermore many deep speech command control require sentence install sentence boundary detector used inefficient said downstream feel free integrate sentence boundary detector,issue,positive,positive,positive,positive,positive,positive
469671271,"@lissyx  I'd argue that adding sentence boundaries to the transcript is a part of an ASR system as many following NLP tasks depend on the speech segmentation to sentences. Also some of the acoustic properties, such as silence gaps between individual words, could be helpful in producing accurate punctuation. (btw. commercial solutions such as google speech API or IBM's speech to text provide this functionality as well). 

If the text-only based solutions recommended above prove to be accurate enough, having an external component that would add the punctuation to the Deepspeech generated stream of words would be less cumbersome. 

Still I'd be an enthusiastic user of the feature if it was provided by Deepspeech out of the box:).  ",argue sentence transcript part system many following depend speech segmentation also acoustic silence individual could helpful accurate punctuation commercial speech speech text provide functionality well based prove accurate enough external component would add punctuation stream would le cumbersome still enthusiastic user feature provided box,issue,positive,positive,positive,positive,positive,positive
469664115,@pvanickova Sorry if it feels like a dumb question but I'm wondering if it's really something that should fit into the scope of the project ?,sorry like dumb question wondering really something fit scope project,issue,negative,negative,neutral,neutral,negative,negative
469593407,"We have made a conscious choice to use a single LSTM layer; we want the model to be as lightweight as possible to allow targeting as many devices as possible, despite some of the devices being resource constrained.

However, that said if you want to discuss your multi-layer LSTM experiments we encourage and invite your input on our [discourse form](discourse) as we'd be very much interested in your results.",made conscious choice use single layer want model lightweight possible allow many possible despite resource constrained however said want discus encourage invite input discourse form discourse much interested,issue,positive,positive,positive,positive,positive,positive
469446290,"Current status is that we have `libdeepspeech.so` and the `.Net Framework` examples building properly on TC, targetting CPU. Some packaging needs to be adjusted. Regarding CUDA builds, it's more or less solved, just dependent on some TaskCluster re-deployment.",current status framework building properly need regarding le dependent,issue,negative,neutral,neutral,neutral,neutral,neutral
469445875,"> Ce sera parfait si l'on peut entraîner aussi sur Windows.

It's going to be a bit more complicated, now we depend on `ds_ctcdecoder`, so we would need to build that on Windows",ce serum parfait si sur going bit complicated depend would need build,issue,negative,negative,negative,negative,negative,negative
469233089,"@absin1 I would love to have you help, but I need to make sure that the owners of the data set are agreeable first.",would love help need make sure data set agreeable first,issue,positive,positive,positive,positive,positive,positive
469216238,"Right, so `.mp3` missing is confirmed to be a bug on Common Voice side. Given there are also beta and other previous dataset in the wild with the proper `.mp3` extension, it'd be really a better approach to check if the filename does have a `.mp3` extension and only add it if missing. cc @qboot @kremnik ",right missing confirmed bug common voice side given also beta previous wild proper extension really better approach check extension add missing,issue,negative,positive,neutral,neutral,positive,positive
469212244,"> BTW I have another example file that I made based on that one which turns on the microphone and feeds the recording into DeepSpeech. Is that something you might want in the examples also? It would just add one more JavaScript file and one additional dependency.

I know we have some doing the same with  Python and I think one with NodeJS + ffmpeg, but if yours adds any different value it's welcome.",another example file made based one turn microphone recording something might want also would add one file one additional dependency know python think one different value welcome,issue,positive,positive,positive,positive,positive,positive
469194950,"Thanks for your comments.
Yes, `.mp3` extension is not included in the last french CV dataset that I've downloaded yesterday.
And for the `+x` I just use the same as other importers.

Do I have to do something more in this PR ?",thanks yes extension included last yesterday use something,issue,positive,positive,neutral,neutral,positive,positive
469191989,"I'm new to github. Have pushed updates now, not sure if this pull request will update automatically.",new sure pull request update automatically,issue,negative,positive,positive,positive,positive,positive
469168160,"Put stuff in ```/tmp```, note the leading forward slash",put stuff note leading forward slash,issue,negative,neutral,neutral,neutral,neutral,neutral
469162331,"I would like to assist, can you point me to the work in progress file. Hindi transcription is of importance to me.",would like assist point work progress file transcription importance,issue,positive,neutral,neutral,neutral,neutral,neutral
469159922,A better fix would be to change the target directory to something local on the node(s).,better fix would change target directory something local node,issue,negative,positive,positive,positive,positive,positive
469117226,"@reuben is right, you should consider changing frame rate form 22khz to 16khz. It will solve your warning.",right consider frame rate form solve warning,issue,negative,positive,positive,positive,positive,positive
469086862,"I’ve tested the 3ms offset on more files and found it to be effective. I also updated the code to include word durations and combined PR #1893 into this one to make reviewing easier.

This is ready for review now, @reuben.",tested offset found effective also code include word combined one make easier ready review,issue,positive,positive,positive,positive,positive,positive
469082166,"> @dsteinman Could you squash all commits into one before I merge? Thanks!

No problem, it's done.

BTW I have another example file that I made based on that one which turns on the microphone and feeds the recording into DeepSpeech.  Is that something you might want in the examples also?  It would just add one more JavaScript file and one additional dependency.",could squash one merge thanks problem done another example file made based one turn microphone recording something might want also would add one file one additional dependency,issue,negative,positive,positive,positive,positive,positive
469077464,@dsteinman Could you squash all commits into one before I merge? Thanks!,could squash one merge thanks,issue,negative,positive,positive,positive,positive,positive
469063715,"> > * Missing `.mp3` extension
> 
> There's no reason this is needed.
> 
> > * Permission 644 -> 755
> 
> Similar, there's no good reason to justify ?

Nevermind, looks like all ther other `import_*.py` are also `+x` ...",missing extension reason permission similar good reason justify like also,issue,negative,positive,positive,positive,positive,positive
469053665,"> * Missing `.mp3` extension

There's no reason this is needed.

> 
> * Permission 644 -> 755

Similar, there's no good reason to justify ?",missing extension reason permission similar good reason justify,issue,negative,positive,positive,positive,positive,positive
469012680,"> > at least from my point of view and understanding, covered by the docs.
> 
> There is no documentation, and the example provided doesn't work as-is.
> 
> > npm install deepspeech
> > See client.js for an example of how to use the bindings.
> 
> That's it. That's the entire extent of the NodeJS documentation. And to a new user some ""unknown"" amount of work will be required to modify that client.js and figure out how to get it working. And who knows if they will succeed, or that it's possible to get it working?

Okay, now I get what you struggled with

> 
> It would be a lot more re-assuring to download code that is known to work, and has a clear step-by-step procedure, and then use that as the starting point. Right now, there is no starting point, the developers are forced to _**derive**_ their own example based on one that they probably don't have working and maybe aren't sure they will be able to get working.
> 
> ```
> npm install deepspeech
> wget https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/client.js
> [INSERT INSTRUCTIONS HERE]
> ```
> 
> If it's as easy as you think, why not try to complete the rest of instructions such that anyone can download it as-is, and run it, in as few steps as possible?

Well, that's where you feedback is useful, we did not got into thinking of that wget step, for us it was obvious ""read the code and adapt"".",least point view understanding covered documentation example provided work install see example use entire extent documentation new user unknown amount work modify figure get working succeed possible get working get would lot code known work clear procedure use starting point right starting point forced derive example based one probably working maybe sure able get working install insert easy think try complete rest anyone run possible well feedback useful got thinking step u obvious read code adapt,issue,positive,positive,neutral,neutral,positive,positive
468969775,">  at least from my point of view and understanding, covered by the docs.

There is no documentation, and the example provided doesn't work as-is.

> npm install deepspeech
> See client.js for an example of how to use the bindings.

That's it.  That's the entire extent of the NodeJS documentation.  And to a new user some ""unknown"" amount of work will be required to modify that client.js and figure out how to get it working.  And who knows if they will succeed, or that it's possible to get it working?

It would be a lot more re-assuring to download code that is known to work, and has a clear step-by-step procedure, and then use that as the starting point.  Right now, there is no starting point, the developers are forced to ***derive*** their own example based on one that they probably don't have working and maybe aren't sure they will be able to get working.

```
npm install deepspeech
wget https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/client.js
[INSERT INSTRUCTIONS HERE]
```

If it's as easy as you think, why not try to complete the rest of instructions such that anyone can download it as-is, and run it, in as few steps as possible?",least point view understanding covered documentation example provided work install see example use entire extent documentation new user unknown amount work modify figure get working succeed possible get working would lot code known work clear procedure use starting point right starting point forced derive example based one probably working maybe sure able get working install insert easy think try complete rest anyone run possible,issue,positive,positive,neutral,neutral,positive,positive
468964676,"> I'm not sure what else I can say other than the docs were not sufficient for me.

Sorry if I feel to insist, but we are more than open to improvements on the docs, if I felt this was a useless request I would have closed the PR.

So if you say they were not sufficient, could you elaborate based on the links above ? Those were really put together with newcomer in mind, so if it's not clear, we are failing somehow, and it's not good.

> Perhaps close the PR, and revisit at a later time if other developers have the same problems.

Except others may not take the time to give feedback, that's why I really want to understand what's missing / unclear in our current docs, because everything you explained so far is, at least from my point of view and understanding, covered by the docs. Maybe not at the place you would have expected, maybe wording unclear, maybe overwhelmed by too much infos, all those are understandable.

But you took time to test, to give feedback, so it's really important we avoid wasting your time.",sure else say sufficient sorry feel insist open felt useless request would closed say sufficient could elaborate based link really put together newcomer mind clear failing somehow good perhaps close revisit later time except may take time give feedback really want understand missing unclear current everything far least point view understanding covered maybe place would maybe wording unclear maybe much understandable took time test give feedback really important avoid wasting time,issue,negative,positive,neutral,neutral,positive,positive
468961849,"I'm not sure what else I can say other than the docs were not sufficient for me.  Perhaps close the PR, and revisit at a later time if other developers have the same problems.",sure else say sufficient perhaps close revisit later time,issue,negative,positive,positive,positive,positive,positive
468960144,"> If that code cannot be run by hand, then why is it being provided as the starting point for newcomers? This is precisely why I was confused. It's like a catch-22 -- do I install the NPM module or do I need to build the module. It's impossible for a newcomer to know where to start because the procedure to run the code in that client.js file (or even what to do with it) is not provided.

Again, https://github.com/mozilla/DeepSpeech/blob/master/README.md#using-the-nodejs-package we document that exactly, we say the `client.js` file is an example of how to use the bindings. That should precisely address the use-case you describe.

Did you saw that when you struggled ? If so, then I guess we could welcome improvement on the wording if you think it's not clear enough or misleading.",code run hand provided starting point precisely confused like install module need build module impossible newcomer know start procedure run code file even provided document exactly say file example use precisely address describe saw guess could welcome improvement wording think clear enough misleading,issue,positive,positive,neutral,neutral,positive,positive
468954941,"> Well, again, because client.js is here to produce deepspeech npm package, as well as serve as an example, not meant to be run by hand.

If that code cannot be run by hand, then why is it being provided as the starting point for newcomers?  This is precisely why I was confused.  It's like a catch-22 -- do I install the NPM module or do I need to build the module.  It's impossible for a newcomer to know where to start because the procedure to run the code in that client.js file (or even what to do with it) is not provided.",well produce package well serve example meant run hand code run hand provided starting point precisely confused like install module need build module impossible newcomer know start procedure run code file even provided,issue,positive,negative,negative,negative,negative,negative
468951790,"> There should be a step-by-step list of commands to get the code running

And we have that on the front page / README: https://github.com/mozilla/DeepSpeech/blob/master/README.md#getting-the-pre-trained-model https://github.com/mozilla/DeepSpeech/blob/master/README.md#using-the-model",list get code running front page,issue,negative,neutral,neutral,neutral,neutral,neutral
468951507,"> What's missing is what ""exactly"" to do with ""client.js"". There should be a step-by-step list of commands to get the code running. Getting the example code running should be the first step of any documentation.

Well, again, because `client.js` is here to produce `deepspeech` npm package, as well as serve as an example, not meant to be run by hand.



> So right off the bat I am starting with what appears like ""broken"" code and I have to figure out what code does and how to ""fix"" it. And there's 120 lines of code to look through, links to other things, it has an environment script #!/usr/bin/env and references to command line arguments, and I have to install various packages like sox-stream, node-wav, and I have to replace the reference to `const Ds = require('./index.js');` with an import of `deepspeech`.
> 
> It will take a great deal more than 8 commands to get it running, and every developer who tries the Deepspeech module will have to know or figure out what to do.

And if you `npm install deepspeech` you get the bindings installed and the deps as well: https://github.com/mozilla/DeepSpeech/blob/master/README.md#using-the-nodejs-package

And we refer there to `client.js` as an example of code.",missing exactly list get code running getting example code running first step documentation well produce package well serve example meant run hand right bat starting like broken code figure code fix code look link environment script command line install various like replace reference require import take great deal get running every developer module know figure install get well refer example code,issue,positive,positive,positive,positive,positive,positive
468949860,"> I'd really like to understand what's missing / unclear in our current codebase.

What's missing is what ""exactly"" to do with ""client.js"".  There should be a step-by-step list of commands to get the code running.  Getting the example code running should be the first step of any documentation.

You keep referring to how similar the code is, but what's different is the procedure to install everything and run it is simple and straightfoward:

```
git clone https://github.com/dsteinman/deepspeech-simple.git
cd deepspeech-simple
pip3 install deepspeech
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.4.1/deepspeech-0.4.1-models.tar.gz
tar xvfz deepspeech-0.4.1-models.tar.gz
brew install sox
npm install
node index.js
```

No command line arguments, no editing, and it has a test audio.wav file already there.  Anyone who follows these procedures can get it working and can immediately begin changing it to do whatever they want.

But now try to do the same thing with the native_client code `client.js`:

```
https://github.com/mozilla/DeepSpeech/blob/master/native_client/javascript/client.js
```

If I try to run it with node I get an error:

`node client.js`

```
node client.js 
module.js:550
    throw err;
    ^

Error: Cannot find module 'sox-stream'
    at Function.Module._resolveFilename (module.js:548:15)
    at Function.Module._load (module.js:475:25)
    at Module.require (module.js:597:17)
    at require (internal/module.js:11:18)
    at Object.<anonymous> (.../client.js:4:13)
    at Module._compile (module.js:653:30)
    at Object.Module._extensions..js (module.js:664:10)
    at Module.load (module.js:566:32)
    at tryModuleLoad (module.js:506:12)
    at Function.Module._load (module.js:498:3)
```

So right off the bat I am starting with what appears like ""broken"" code and I have to figure out what code does and how to ""fix"" it.  And there's 120 lines of code to look through, links to other things, it has an environment script #!/usr/bin/env and references to command line arguments, and I have to install various packages like sox-stream, node-wav, and I have to replace the reference to `const Ds = require('./index.js');` with an import of `deepspeech`.

It will take a great deal more than 8 commands to get it running, and every developer who tries the Deepspeech module will have to know or figure out what to do.",really like understand missing unclear current missing exactly list get code running getting example code running first step documentation keep similar code different procedure install everything run simple git clone pip install tar brew install install node command line test file already anyone get working immediately begin whatever want try thing code try run node get error node node throw err error find module require anonymous right bat starting like broken code figure code fix code look link environment script command line install various like replace reference require import take great deal get running every developer module know figure,issue,negative,positive,neutral,neutral,positive,positive
468943810,"@reuben as discussed [here](https://github.com/mozilla/DeepSpeech/issues/1923#issuecomment-468737499), I removed state related stuffs.

I still have a question though: is it still needed/possible to reset `LSTM`s internal state before evaluating a new batch ?",removed state related still question though still reset internal state new batch,issue,negative,positive,neutral,neutral,positive,positive
468934390,"> > it looks to be exactly the same code as the client.js in the bindings
> 
> Have you ever actually tried to download client.js, just start completely from scratch, and write down each thing you need to do to get it working? Although it may seem obvious to those who are already familiar with DeepSpeech, it was not obvious to me.

Can you understand that I'm asking questions in a way that is not to trick or diminish the value of your PR ? As you said, we are very used to the code and it's harder for us to have a newcomer point of view.

What is unclear to me is how complex it is to follow our current codebase. This `native_client/javascript/` is **only** here to produce the `deepspeech` npm package. That's why there's all the logic. But the content of `client.js` also documents how to use it, since it's making use of it.

So, again, I'm asking because besides the `argparse` changes, as expected, your example is really very close to the same code (which is expected), and thus I don't understand how it improves the first newcomer experience.

> When I looked at the code, it wasn't clear whether compiling the code in /native_client was necessary and it didn't make sense why an NPM package would also require me to download and compile the same code just to get a simple example working.
> 
> There are a few important steps of work required between `npm install deepspeech` downloading `client.js` and actually get it working. So my pull request reflects the changes I had to make.

Right, so maybe we should rather improve our documentation ?

Don't get me wrong, I like PR and I like that you took time to send it and discuss it, and I'd really like to understand what's missing / unclear in our current codebase.

Maybe @reuben or @kdavis-mozilla could weight their opinion or maybe they understand it better than I do?",exactly code ever actually tried start completely scratch write thing need get working although may seem obvious already familiar obvious understand way trick diminish value said used code harder u newcomer point view unclear complex follow current produce package logic content also use since making use besides example really close code thus understand first newcomer experience code clear whether code necessary make sense package would also require compile code get simple example working important work install actually get working pull request make right maybe rather improve documentation get wrong like like took time send discus really like understand missing unclear current maybe could weight opinion maybe understand better,issue,positive,positive,neutral,neutral,positive,positive
468918304,"> it looks to be exactly the same code as the client.js in the bindings

Have you ever actually tried to download client.js, just start completely from scratch, and write down each thing you need to do to get it working?  Although it may seem obvious to those who are already familiar with DeepSpeech, it was not obvious to me.  When I looked at the code, it wasn't clear whether compiling the code in /native_client was necessary and it didn't make sense why an NPM package would also require me to download and compile the same code just to get a simple example working.

There are a few important steps of work required between `npm install deepspeech` downloading `client.js` and actually get it working.  So my pull request reflects the changes I had to make.",exactly code ever actually tried start completely scratch write thing need get working although may seem obvious already familiar obvious code clear whether code necessary make sense package would also require compile code get simple example working important work install actually get working pull request make,issue,positive,positive,positive,positive,positive,positive
468913254,"> No worries, it was suggested by someone in the thread to make a pull request. But feel free to close it if it's unnecessary.

Yeah, I even suggested sending a PR, I'm just wondering what's the added value right now, besides being another set of examples to maintain. Given it looks to be exactly the same code as the `client.js` in the bindings, I'm unsure it's really useful. Maybe I am missing something? Or maybe writing it helped you?",someone thread make pull request feel free close unnecessary yeah even sending wondering added value right besides another set maintain given exactly code unsure really useful maybe missing something maybe writing,issue,positive,positive,positive,positive,positive,positive
468788997,"there is no such target built, please use `--arch cpu`, there's nothing GPU specific on this binary.",target built please use arch nothing specific binary,issue,negative,neutral,neutral,neutral,neutral,neutral
468785789,My training machine has no monitor and boots in the console mode. So ssh to the machine I don't see any logging or errors. I since added a monitor and all is now functioning well. ,training machine monitor boot console mode machine see logging since added monitor well,issue,negative,neutral,neutral,neutral,neutral,neutral
468755178,"@reuben  good point!
see https://github.com/mozilla/DeepSpeech/pull/1926
tested, it works like a charm :+1: ",good point see tested work like charm,issue,positive,positive,positive,positive,positive,positive
468737499,Do you really need the batch_size placeholder? If you enforce n_steps=-1 then you avoid all of the state stuff which depends on the batch size.,really need enforce avoid state stuff batch size,issue,negative,positive,positive,positive,positive,positive
468736570,"> I think the easiest first step would be to add optional support for dynamic batch size, not caring about the native clients, and just make sure not to change our defaults. 

ok

> Batch size > 1 with the streaming graph is really complicated and not really useful, since the streaming graph optimizes for latency rather than throughput, so I don't think we'll add support for that.

ok

> But having the ability to export a model that handles variable batch sizes would be nice.

ok. I'll work on the PR then.

Implementation will look like
```py
def create_inference_graph(batch_size=1, n_steps=16, tflite=False):
    ...
    if batch_size <= 0:
        if tflite:
            raise NotImplementedError('...')
        batch_size = tf.placeholder(tf.int32, name=""batch_size"")
        .... 
        return (
            {
                'batch_size': batch_size,
                'input': input_tensor,
                'input_lengths': seq_length,
            },
            {
                'outputs': logits,
                'initialize_state': initialize_state,
            },
            layers
        )
    elif not tflite:
        ... # same as before
    else:
        ... # same as before
```",think easiest first step would add optional support dynamic batch size native make sure change batch size streaming graph really complicated really useful since streaming graph latency rather throughput think add support ability export model variable batch size would nice work implementation look like raise return else,issue,positive,positive,positive,positive,positive,positive
468717053,"I think the easiest first step would be to add optional support for dynamic batch size, not caring about the native clients, and just make sure not to change our defaults. Batch size > 1 with the streaming graph is really complicated and not really useful, since the streaming graph optimizes for latency rather than throughput, so I don't think we'll add support for that. But having the ability to export a model that handles variable batch sizes would be nice.",think easiest first step would add optional support dynamic batch size native make sure change batch size streaming graph really complicated really useful since streaming graph latency rather throughput think add support ability export model variable batch size would nice,issue,positive,positive,positive,positive,positive,positive
468679175,"@reuben thanks

For my use case it would be even better if `batch_size` could be dynamic (ie None).

I can work on the PR but I need some guidelines since it will impact the inference graph",thanks use case would even better could dynamic ie none work need since impact inference graph,issue,positive,positive,positive,positive,positive,positive
468673776,"@reuben @lissyx flag already exists but is not used. see https://github.com/mozilla/DeepSpeech/blame/master/util/flags.py#L65
",flag already used see,issue,negative,neutral,neutral,neutral,neutral,neutral
468642171,"Yep, would gladly take this PR. This use case is already tested (by evaluate.py) and it works fine, I see no reason to expose it to outside consumers.",yep would gladly take use case already tested work fine see reason expose outside,issue,positive,positive,positive,positive,positive,positive
468638023,"Oh, you just add the parameter? I guess it's r+ then, maybe an opinion @reuben ?",oh add parameter guess maybe opinion,issue,negative,neutral,neutral,neutral,neutral,neutral
468637821,"Thanks @lissyx for the quick reply
Since default value will still be `1`, this will have no impact on existing clients (such as libdeepspeech.so).",thanks quick reply since default value still impact,issue,positive,positive,positive,positive,positive,positive
468633267,"The current inference graph is really tailored for `libdeepspeech.so`, which does not take care of batching. If we can keep the current lib code (or with few changes), maybe it's worth?",current inference graph really take care keep current code maybe worth,issue,positive,positive,positive,positive,positive,positive
468621894,I built https://github.com/bedapudi6788/deepsegment for this purpose (sentence segmentation without punctuation). You can find a demo at http://bpraneeth.com/projects,built purpose sentence segmentation without punctuation find,issue,negative,neutral,neutral,neutral,neutral,neutral
468620774,"I've seen the prosodic featues such as the silence gaps mentioned in a few papers e.g. http://www.cs.tut.fi/~huangg/papers/2014_IS/xu2014deep.pdf or https://arxiv.org/pdf/1610.00211.pdf. 

Do you have a recommendation for another text only based method?",seen prosodic silence recommendation another text based method,issue,negative,neutral,neutral,neutral,neutral,neutral
468611822,"@pvanickova even without the silence gap, sentence end detection should work well in general. Which ones did you try with?",even without silence gap sentence end detection work well general try,issue,negative,positive,neutral,neutral,positive,positive
468370413,"For now, let's focus on getting at least `libdeepspeech.so` for CPU and GPU on `x64` platform, as well as the `.Net` bindings and the `NuGet` package. Early testing shows it's going to be a bit more painful to get Python / NodeJS bindings there.",let focus getting least platform well package early testing going bit painful get python,issue,negative,negative,negative,negative,negative,negative
468294885,"It's the format used by the TED-LIUM corpus, which we no longer use due to licensing constraints.

http://www1.icsi.berkeley.edu/Speech/docs/sctk-1.2/infmts.htm#stm_fmt_name_0",format used corpus longer use due,issue,negative,negative,negative,negative,negative,negative
468197662,"@igorfritzsch Thanks, but please rebase and avoid merges :)",thanks please rebase avoid,issue,negative,positive,positive,positive,positive,positive
468078647,"What building and installation sections are you talking about exactly? In general, it's because you can:

1) Install pre-built binaries published by us; or

2) Build your own binaries and install them",building installation talking exactly general install u build install,issue,negative,positive,neutral,neutral,positive,positive
468075080,"@reuben --- this README seems to double itself... do we really need separate ""Building"" and ""Installation"" sections?

I can't tell because I don't understand well enough, but this README is still super confusing to me.",double really need separate building installation ca tell understand well enough still super,issue,positive,positive,positive,positive,positive,positive
467967261,"I never found the means to capture directly from a microphone at 16/16. I shopped everywhere but all mics I found were either 44100 or 48000.

Thank for the issue on audioop.

The training is still in process, so I don't have a result yet. That is why I looking for a way to determine where deepspeech is in its training process.
",never found capture directly microphone everywhere found either thank issue training still process result yet looking way determine training process,issue,negative,positive,neutral,neutral,positive,positive
467960301,"If possible capture at 16 bit 16K mono.

Also, audioop does not convert to 16 bit 16K mono correctly, see for example this [issue](https://github.com/mozilla/DeepSpeech/issues/1726).

What is print out when you train?",possible capture bit mono also convert bit mono correctly see example issue print train,issue,negative,neutral,neutral,neutral,neutral,neutral
467956943,"Captured with Blue Snowball mic at 44100 rate then used both numpy or audioop to convert to 16 bit 16K rate save to a wave file and passed to the deepspeech-server.

DeepSpeech train is still processing the CV files but I attempting to determine its effeciency. I still have not found ""the log, which indicates which epoch is running"". You don't mean the checkpoint files?

",blue snowball rate used convert bit rate save wave file train still determine still found log epoch running mean,issue,negative,negative,negative,negative,negative,negative
467924012,"I was attempting to train common voice dataset. now I'm back to deepspeech
because I want to add on.

On Wed, Feb 27, 2019, 10:58 AM Kelly Davis <notifications@github.com> wrote:

> @raspi-three <https://github.com/raspi-three> Why were you mentioning ""Is
> there anyway to detect the percentage of training completed?"" This sounds
> like you've trained your own model.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/1812#issuecomment-467918914>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AsJBaRHHmXLFU3vaz60lUeXDKmbP-dXGks5vRqsygaJpZM4ZlltY>
> .
>
",train common voice back want add wed kelly wrote anyway detect percentage training like trained model reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
467918914,"@raspi-three Why were you mentioning ""Is there anyway to detect the percentage of training completed?"" This sounds like you've trained your own model.",anyway detect percentage training like trained model,issue,negative,neutral,neutral,neutral,neutral,neutral
467905143,@kdavis-mozilla I can't seem to find the default location of the deepspeech log files. I assume it would be in one of the util files but I don't see it.,ca seem find default location log assume would one see,issue,negative,neutral,neutral,neutral,neutral,neutral
467903271,I am using deepspeech 0.4.1 on ds-server. The pi is running again that server right now.,pi running server right,issue,negative,positive,positive,positive,positive,positive
467901321,@raspi-three Are you using our release model or a model of your own making?,release model model making,issue,negative,neutral,neutral,neutral,neutral,neutral
467900247,@bjtommychen I use raspi 3 B+ with 1TB external drive. The speed is very good but not the accuracy.,use external drive speed good accuracy,issue,negative,positive,positive,positive,positive,positive
467836119,"> HTOP via ssh shows Mem: 7.75G and Swp: 2.0G available. Yes, 8 processes are running. The system is running in the text mode. I have no idea were to go from here.
> 
> LOL I got deepspeech running on my raspberry pi with no issues!
> 
@raspi-three  Hi, would you tell me which Pi board you use ? and how is the deepspeech inference speed? thanks.",via mem available yes running system running text mode idea go got running raspberry pi hi would tell pi board use inference speed thanks,issue,positive,positive,positive,positive,positive,positive
467777570,"As this is not a but or a feature request, could you take the discussion to our [discourse forum](https://discourse.mozilla.org/c/deep-speech)? Thanks.",feature request could take discussion discourse forum thanks,issue,negative,positive,positive,positive,positive,positive
467771094,"I assume you see the log, which indicates which epoch is running, and you know how many epochs are to be run, I assume. So, is that enough?",assume see log epoch running know many run assume enough,issue,negative,positive,positive,positive,positive,positive
467709118,"I've tried lots of different things and I think the best interim solution is to simply offset backwards by a certain number of milliseconds. I've gotten good results with a 3 ms offset but I need to test it with more files first.

This addresses situations where the character was discovered only at the end of its utterance. For situations where the character is drawn out, I think it's acceptable as long as you can hear the character clearly at the provided timestep and discern what it is.

For future features like detecting the end of sentences, this may not be accurate enough and may need more work later on, but for now it's certainly more than accurate enough for my use-case. I really don't think anyone would actually notice unless they compared it directly to the zoomed-in waveform.",tried lot different think best interim solution simply offset backwards certain number gotten good offset need test first character discovered end utterance character drawn think acceptable long hear character clearly provided discern future like end may accurate enough may need work later certainly accurate enough really think anyone would actually notice unless directly,issue,positive,positive,positive,positive,positive,positive
467669190,"Just an update. After I upgraded my RAM memory to 16GB, everything is running fine. System is using 12.1GB and zero of 5GB in Swap. There are numerous files now in the checkpoint folder.

One quick question. Is there anyway to detect the percentage of training completed?
 ",update ram memory everything running fine system zero swap numerous folder one quick question anyway detect percentage training,issue,negative,positive,positive,positive,positive,positive
467624427,"I tried setting the timestamp to the timestamp of the first child in PathTrie::get_path_trie but this barely made a difference. I noticed that it seems to occur more often with words where the first letter is drawn out, which may mean that enough of that letter's sound was in that timestep band for it to infer it and so it didn't need any of the data that came before it. I don't really know what the solution to that is, although maybe it will improve as the model improves?",tried setting first child barely made difference occur often first letter drawn may mean enough letter sound band infer need data came really know solution although maybe improve model,issue,positive,positive,positive,positive,positive,positive
467594715,"Thank you for your time reviewing, @lissyx , I will do some testing with `sox` next week and get back to you.",thank time testing next week get back,issue,negative,neutral,neutral,neutral,neutral,neutral
467574968,"You're right, it records the timestep at the peak probability of the character. I don't have any ideas off the top of my head on how to make that more precise, but I'd try to tweak the logic in the decoder (PathTrie::get_path_trie) to see if it's possible to make it match the behavior you're looking for.",right peak probability character top head make precise try tweak logic see possible make match behavior looking,issue,negative,positive,positive,positive,positive,positive
467572762,"I was looking to incorporate word durations so I did some more digging and it would appear that the timesteps value returned from the CTC decoder is not the time when the letter first begins but the time at which it determines what kind of letter it actually is. So it could be halfway through the letter or at the end of the letter.

We're talking about millisecond-level differences here so I think the current code as-is is still accurate enough to pull into the repo but it would still be nice to get it as accurate as possible, especially for future features like sentence detection.

Any thoughts on how to do this @reuben, @lissyx ?",looking incorporate word digging would appear value returned time letter first time kind letter actually could halfway letter end letter talking think current code still accurate enough pull would still nice get accurate possible especially future like sentence detection,issue,positive,positive,positive,positive,positive,positive
467530732,"How about a README that says exactly what you just wrote? I agree we don't need full-length documentation, but for a newcomer to DeepSpeech, they peek into this dir and it's not at all obvious what the contents are for.

I can make a PR with a README.md with the following contents:

```
# taskcluster

A task execution framework for Mozilla's CI system. Please consult the [existing taskcluster documentation](https://docs.taskcluster.net/docs).
```",exactly wrote agree need documentation newcomer peek obvious content make following content task execution framework system please consult documentation,issue,positive,positive,neutral,neutral,positive,positive
467420797,"No worries, it was suggested by someone in the thread to make a pull request.  But feel free to close it if it's unnecessary.",someone thread make pull request feel free close unnecessary,issue,positive,neutral,neutral,neutral,neutral,neutral
467414225,"@dsteinman I don't want to hurt anyone's feeling, but it's really exactly the same code. Again, except the removal of `argparse` and loading of the LM, it's just copy / paste, so I'm really having a hard time understanding how it improves understanding how to use the `libdeepspeech` bindings.",want hurt anyone feeling really exactly code except removal loading copy paste really hard time understanding understanding use,issue,negative,negative,neutral,neutral,negative,negative
467409760,"The code in the native client directory is not really a proper example that someone can quickly download and run.  Fortunately the devs who answered my questions were able to point me in the right direction and get it working:

https://github.com/mozilla/DeepSpeech/issues/1898

So I've simplified the code into a single example file with no build process and no external dependencies (except deepspeech and the model files).  The command line arguments aren't necessary for a simple example because it's very likely that a NodeJS developer is building a web service rather than a command line tool, so the args have to be stripped out anyways.

I also published the example code here if you don't want to include it in the project:

https://github.com/dsteinman/deepspeech-simple",code native client directory really proper example someone quickly run fortunately able point right direction get working simplified code single example file build process external except model command line necessary simple example likely developer building web service rather command line tool stripped anyways also example code want include project,issue,negative,positive,positive,positive,positive,positive
467372966,@dsteinman Would you mind elaborating a bit on the added value of this ?,would mind bit added value,issue,negative,neutral,neutral,neutral,neutral,neutral
467372705,"@dsteinman Thanks for that, though I don't see a huge difference from the `native_client/javascript/client.js`, besides removal of the `argparse` part.",thanks though see huge difference besides removal part,issue,positive,positive,positive,positive,positive,positive
467347801,Why should we document taskcluster here? It's a task execution framework for Mozilla's CI system. It be much better simply to reference the [existing taskcluster documentation](https://docs.taskcluster.net/docs).,document task execution framework system much better simply reference documentation,issue,negative,positive,positive,positive,positive,positive
466621646,"Please review the past points @reuben @lissyx . I wish I could test with more configurations but I just can't, it literally takes hours on my 6 core vm. ",please review past wish could test ca literally core,issue,positive,negative,negative,negative,negative,negative
466520418,"> Here's my example code:
> 
> https://github.com/dsteinman/deepspeech-simple
> 
> Just one JS file and one WAV file, and I removed all the ""args"" stuff which was making everything look more complicated than it actually is. Thanks for the help, guys. You can close this ticket.

Do not hesitate if you feel the need to send a PR augmenting docs / examples, it's always welcome !",example code one file one file removed stuff making everything look complicated actually thanks help close ticket hesitate feel need send always welcome,issue,positive,positive,positive,positive,positive,positive
466494971,"Here's my example code:

https://github.com/dsteinman/deepspeech-simple

Just one JS file and one WAV file, and I removed all the ""args"" stuff which was making everything look more complicated than it actually is.  Thanks for the help, guys.  You can close this ticket.",example code one file one file removed stuff making everything look complicated actually thanks help close ticket,issue,positive,negative,negative,negative,negative,negative
466484715,"> Another example is here [ffmpeg_vad_streaming](https://github.com/mozilla/DeepSpeech/tree/master/examples/ffmpeg_vad_streaming) which includes a [package.json](https://github.com/mozilla/DeepSpeech/blob/master/examples/ffmpeg_vad_streaming/package.json) with all the info on dependencies.

Ah okay, between examining that and the other file I've got a simplified example working.  I'll publish a git repo for you to consider adding to the examples directory.",another example ah examining file got simplified example working publish git consider directory,issue,negative,neutral,neutral,neutral,neutral,neutral
466461986,"The script imports other dependencies such as:

```
const Ds = require('./index.js');
...
var model = new Ds.Model(args['model'], N_FEATURES, N_CONTEXT, args['alphabet'], BEAM_WIDTH);
```

So if I use client.js as an example I can't just use it because I get errors and I have to have some detailed knowledge about what the dependencies are, and know which I can remove or replace. Even just running that example code as-is isn't clearly documented at:

https://github.com/mozilla/DeepSpeech/blob/master/native_client/README.md

Perhaps is there any example of a simplified ""single file"" script without any extraneous dependencies and gyp building?",script require model new use example ca use get detailed knowledge know remove replace even running example code clearly perhaps example simplified single file script without extraneous gyp building,issue,negative,positive,positive,positive,positive,positive
466454618,"You're not supposed to do anything with the file, just read it. It's an example of a script that uses the bindings, it has comments and informative console messages. The script *is* the step-by-step instructions.",supposed anything file read example script informative console script,issue,negative,neutral,neutral,neutral,neutral,neutral
466367839,"@baerbock What's the exact bazel command you issue?

You just said it's
`bazel build --config=monolithic -c opt --copt=-O3`

but you have to specify a target with // at the end of the command as well. 

E.g.

`bazel build --config=monolithic -c opt --copt=-O3 //native_client:libdeepspeech.so //native_client:generate_trie`",exact command issue said build opt specify target end command well build opt,issue,negative,positive,positive,positive,positive,positive
465925845,"@jorxster To maybe get you started.

When I fixed the problem for the importer I used `soundfile` + `librosa`. See the PR [here](https://github.com/mozilla/DeepSpeech/commit/81b16002b7016e10940c66a7f442fcfea6339244). But there I only had to write to disk.",maybe get fixed problem importer used see write disk,issue,negative,positive,neutral,neutral,positive,positive
465924073,"> Could you use another means to re-sample other than audioop?
> 
> We have found that audioop leaves artifacts. (See the discussion [here](https://github.com/mozilla/DeepSpeech/issues/1726#issue-381125846).) So we are trying to steer clear of audioop.

Thank you @kdavis-mozilla , I'll have to do some digging and try to find a better way to resample.
",could use another found leaf see discussion trying steer clear thank digging try find better way resample,issue,positive,positive,positive,positive,positive,positive
465604357,"@cmhashim  Thank you! 
Let me know if I can help you in any possible way. All the best. 
",thank let know help possible way best,issue,positive,positive,positive,positive,positive,positive
465591183,"Removing transpose and using `input_reshaped:0` as input node yields:
```
AssertionError: Strided Slice case not handled. Input shape = [16, 1, 2048], output shape = [1, 2048]
```",removing transpose input node slice case handled input shape output shape,issue,negative,neutral,neutral,neutral,neutral,neutral
465588197,"@Hafsa26 Here is the reply of kdavis to a  [similar query](https://discourse.mozilla.org/t/information-on-training-and-inferring-audio-file-length/30646) 
I respected that reply and am trying to shorten the train audio files, also its a burden on GPU, takes weeks.",reply similar query reply trying shorten train audio also burden,issue,negative,neutral,neutral,neutral,neutral,neutral
465587704,"@Hafsa26 If you GPU  has the memory, you can train on audio as log as you like. :-)


However, basically all commercial GPU's available today don't have enough memory to train on batches containing audio clips of length 1 min.",memory train audio log like however basically commercial available today enough memory train audio clip length min,issue,negative,positive,positive,positive,positive,positive
465584272,"@cmhashim Have you tried to change the hyper parameters ? Do hit and trial method as suggested by kdavis. 
",tried change hyper hit trial method,issue,negative,neutral,neutral,neutral,neutral,neutral
465583361,"@kdavis-mozilla Can't we use audio more than 10 second length ?
or Is there any other to do it for longer audios ?
",ca use audio second length longer,issue,negative,neutral,neutral,neutral,neutral,neutral
465579125,"> @cmhashim Have you prepared the demo ? Which version you are working on ?

@Hafsa26 I did the training with 3 hrs of data, but WER was high like your case. The issue is i have used audio of length greater than 10 sec, like 30 sec to 1 min. Hence i am now segmenting the audio to length less than 10 sec.
Version v0.3.0",prepared version working training data wer high like case issue used audio length greater sec like sec min hence audio length le sec version,issue,positive,positive,neutral,neutral,positive,positive
465573532,"So, contrary to Android, we can use StridedSlice, but then it fails:
```
[...]
131/402: Analysing op name: previous_state_h ( type:  Placeholder )
Skipping name of placeholder
132/402: Analysing op name: previous_state_c ( type:  Placeholder )
Skipping name of placeholder
133/402: Analysing op name: input_node ( type:  Placeholder )
Skipping name of placeholder
134/402: Analysing op name: transpose ( type:  Transpose )
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 971, in <module>
    tf.app.run(main)
  File ""/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""DeepSpeech.py"", line 964, in main
    export()
  File ""DeepSpeech.py"", line 855, in export
    'previous_state_h:0': [1,2048],
  File ""/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.5/site-packages/tfcoreml/_tf_coreml_converter.py"", line 586, in convert
    custom_conversion_functions=custom_conversion_functions)
  File ""/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.5/site-packages/tfcoreml/_tf_coreml_converter.py"", line 337, in _convert_pb_to_mlmodel
    convert_ops_to_layers(context)
  File ""/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.5/site-packages/tfcoreml/_ops_to_layers.py"", line 178, in convert_ops_to_layers
    translator(op, context)
  File ""/home/alexandre/Documents/codaz/Mozilla/DeepSpeech/tf-venv/lib/python3.5/site-packages/tfcoreml/_layers.py"", line 992, in transpose
    assert axes[0] == 0, ""only works for 4D tensor without batch axis""
AssertionError: only works for 4D tensor without batch axis
```",contrary android use name type skipping name name type skipping name name type skipping name name transpose type transpose recent call last file line module main file line run main file line main export file line export file line convert file line context file line translator context file line transpose assert ax work tensor without batch axis work tensor without batch axis,issue,negative,positive,neutral,neutral,positive,positive
465566012,"I can beta test for you :)

On Wed 20. Feb 2019 at 13:53, lissyx <notifications@github.com> wrote:

> Well, except I have no iOS device to test that after :)
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/mozilla/DeepSpeech/issues/642#issuecomment-465561846>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ACN_j4eIvXuEFfW4SBqbUTI3_itCV71Bks5vPUVkgaJpZM4OAOny>
> .
>
",beta test wed wrote well except device test thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
465561846,"Well, except I have no iOS device to test that after :)",well except device test,issue,negative,neutral,neutral,neutral,neutral,neutral
465561008,">   --decoder_library_path /home/ubuntu/ashu/bbuddy-training/libdeepspeech.so  \

This make no sense, `--decoder-library-path` is not being used anymore, instead you need to install the `ds_ctcdecoder` python module.",make sense used instead need install python module,issue,negative,neutral,neutral,neutral,neutral,neutral
465560322,"@Chidhambararajan That being said, we already have streaming for the audio feeding, and on desktop with decent CPU or a GPU it should be faster than realtime, as well as on mid-range Android smartphone with TFLite quantized model.

So you can build realtime transcription, not perfectly yet, and it should be more perfect once we have streaming decoder (soon).",said already streaming audio feeding decent faster well android model build transcription perfectly yet perfect streaming soon,issue,positive,positive,positive,positive,positive,positive
465559003,"Closing for lack of activity, and being unable to reproduce.",lack activity unable reproduce,issue,negative,negative,negative,negative,negative,negative
465556571,"@Hafsa26 Can you share some details about the 300 hours of data you have. As i am also sailing in the same boat, training with 150 hours of data, lets collaborate to bring best of it.",share data also sailing boat training data collaborate bring best,issue,positive,positive,positive,positive,positive,positive
465492261,Thank you so much! I will update soon about Urdu language model results. ,thank much update soon language model,issue,negative,positive,positive,positive,positive,positive
465490590,"# Hyperparameters for fine-tuning

The hyperparameters used to train the model are useful for fine tuning. Thus, we document them here along with the hardware used, a server with 8 TitanX Pascal GPUs (12GB of VRAM).

  * `train_files` [Fisher](https://pdfs.semanticscholar.org/a723/97679079439b075de815553c7b687ccfa886.pdf), [LibriSpeech](http://www.danielpovey.com/files/2015_icassp_librispeech.pdf), [Switchboard](http://ieeexplore.ieee.org/document/225858/) training corpora, as well as a pre-release snapshot of the English Common Voice training corpus.
  * `dev_files` [LibriSpeech](http://www.danielpovey.com/files/2015_icassp_librispeech.pdf) clean and other dev corpora, as well as a pre-release snapshot of the English Common Voice validation corpus.
  * `test_files` [LibriSpeech](http://www.danielpovey.com/files/2015_icassp_librispeech.pdf) clean test corpus
  * `train_batch_size` 24
  * `dev_batch_size` 48
  * `test_batch_size` 48
  * `epoch` 30
  * `learning_rate` 0.0001
  * `display_step` 0
  * `validation_step` 1
  * `dropout_rate` 0.15
  * `checkpoint_step` 1
  * `n_hidden` 2048
  * `lm_alpha` 0.75
  * `lm_beta` 1.85

The weights with the best validation loss were selected at the end of the 30 epochs.",used train model useful fine tuning thus document along hardware used server fisher switchboard training corpus well snapshot common voice training corpus clean dev corpus well snapshot common voice validation corpus clean test corpus epoch best validation loss selected end,issue,positive,positive,positive,positive,positive,positive
465490200,"@Hafsa26 Trial and error honestly. 

However, I'd start with parameters near what we have for the release model[[1](https://github.com/mozilla/DeepSpeech/releases/tag/v0.4.1)]",trial error honestly however start near release model,issue,negative,positive,positive,positive,positive,positive
465489876,"> I will. I will be using 300 hours of data next then I will be adjusting hyper-parameters accordingly.
> Is there any guide for adjusting hyper-parameters?

No, you need to run multiple explorative tests",data next accordingly guide need run multiple explorative,issue,negative,neutral,neutral,neutral,neutral,neutral
465489457,"I will. I will be using 300 hours of data next then I will be adjusting hyper-parameters accordingly. 
Is there any guide for adjusting hyper-parameters? ",data next accordingly guide,issue,negative,neutral,neutral,neutral,neutral,neutral
465488661,"> When I trained model for one hour, loss is gradually decreasing but after 14 epochs, its increasing for some epochs and decreasing for some epochs.
> What do you suggest in such scenario?

Not surprising with only one hour, nothing to conclude. You will have to adjust hyper-parameters, eventually, anyway.",trained model one hour loss gradually decreasing increasing decreasing suggest scenario surprising one hour nothing conclude adjust eventually anyway,issue,negative,positive,positive,positive,positive,positive
465488280,"When I trained model for one hour, loss is gradually decreasing but after 14 epochs, its increasing for some epochs and decreasing for some epochs. 
What do you suggest in such scenario? ",trained model one hour loss gradually decreasing increasing decreasing suggest scenario,issue,negative,neutral,neutral,neutral,neutral,neutral
465486076,"I am not planning to use it on Android yet but I need, I will surely do it. Thank you for helping all the way. ",use android yet need surely thank helping way,issue,positive,positive,positive,positive,positive,positive
465485521,"If there is anything you can share to make it better, I would love to know. ",anything share make better would love know,issue,positive,positive,positive,positive,positive,positive
465484124,"@lissyx  yes, I would surely share soon. Up till now, I worked on 1 hour of data and the system is working fine. Though, I am getting 100% WER yet but I will tweak the model once I started working on 300 hours data. I initially have to prepare demo of DeepSpeech for Urdu Language. 
",yes would surely share soon till worked hour data system working fine though getting wer yet tweak model working data initially prepare language,issue,positive,positive,positive,positive,positive,positive
465482928,"@dabinat Thanks, though you could have made it only one PR with two commits :)",thanks though could made one two,issue,negative,positive,positive,positive,positive,positive
465480952,Do you mind sharing figures on how well your model performs? You also might want to export it to tflite format for Android support. ,mind well model also might want export format android support,issue,positive,neutral,neutral,neutral,neutral,neutral
465054906,"I did.  to check the model, I need output_graph.pbmm but I got output_graph.pb
Do I need to make some changes to get .pbmm graph rather than .pb graph.
",check model need got need make get graph rather graph,issue,negative,neutral,neutral,neutral,neutral,neutral
465040469,"@lissyx  Hi, How to convert output_graph.pb model into .pbmm model ?
I got my Urdu language model with .pb extension. Is there any way to convert into .pbmm ?

Thank you! ",hi convert model model got language model extension way convert thank,issue,negative,neutral,neutral,neutral,neutral,neutral
465031469,"@baerbock Bazel, as stated before ? You ripped out all the template for reporting bugs, we don't even know if you are starting that from the correct directory.",stated template even know starting correct directory,issue,negative,neutral,neutral,neutral,neutral,neutral
465031202,@dabinat Can you open a PR ? And make sure you separate adding that to the API from exposing / using it in clients.,open make sure separate,issue,negative,positive,positive,positive,positive,positive
464679773,`path/to/target/directory` is meant to be a placeholder for the directory you want to target. It is not meant to be used as the actual target directory. You need to create and use your own target directory.,meant directory want target meant used actual target directory need create use target directory,issue,negative,neutral,neutral,neutral,neutral,neutral
464597927,"I have a new commit up with JSON output.

The output from the -e flag now looks like this:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```

metadata_from_output now returns a vector of mapped strings (i.e. an array of dictionaries) which makes it pretty easy for other apps to use via the API as you can just call object[""word""] to get the word or any other key.

json_output_from_metadata prints it as JSON (pretty-printed). It iterates through the keys as if they were an array instead of hard-coding them.

So what this means is that in future additional metadata keys can be added (like word duration, confidence) without breaking any other code and without needing to modify the JSON output function. That's why I chose to do it this way instead of using structs or objects.

One question: is pretty-printing the JSON output going to cause anyone problems?",new commit output output flag like file duration time word time word time word time word time word time word life time word time word time word studio time word time word time word prime time word minister time word time word make time word good time word morning time word time word lin time word enter time word time word time word time word agree time word time word start time word time word time word time word one time word thing time word time word time word deserving time word time word time word time word time word said time word time word going time word time word time word time word time word time word important time word election time word time word time word son time word time word bite time word time word absolutely time word crucial time word time word time word time word time word time word think time word time word time word simple vector array pretty easy use via call object word get word key array instead future additional added like word duration confidence without breaking code without needing modify output function chose way instead one question output going cause anyone,issue,positive,positive,positive,positive,positive,positive
464563363,"> The only ones that weren't quite right were for words DeepSpeech mistranscribed

I can confirm the same behavior for Spanish, for the output below with WER 0% all the timings are correct.
```
file duration: 8
word: que, timestep: 50, time: 0.985222
word: cerraban, timestep: 55, time: 1.08374
word: perspectiva, timestep: 79, time: 1.55665
word: al, timestep: 147, time: 2.89655
word: otro, timestep: 156, time: 3.07389
word: lado, timestep: 164, time: 3.23153
word: de, timestep: 174, time: 3.42857
word: los, timestep: 179, time: 3.52709
word: cristales, timestep: 185, time: 3.64532
word: ligeramente, timestep: 217, time: 4.27586
word: turbios, timestep: 252, time: 4.96552
word: por, timestep: 272, time: 5.35961
word: la, timestep: 280, time: 5.51724
word: humedad, timestep: 285, time: 5.61576
word: exterior, timestep: 299, time: 5.89163
```",quite right confirm behavior output wer correct file duration word time word time word time word al time word time word time word de time word time word time word time word time word time word la time word time word exterior time,issue,negative,positive,positive,positive,positive,positive
464553772,"@dabinat Nice work! I'll test it for Spanish, also I'll change the .Net client to add this awesome feature 👍 ",nice work test also change client add awesome feature,issue,positive,positive,positive,positive,positive,positive
464548694,"Yes, I did it that way because the API already outputs the text. But I can split it up so there's a function that returns the data and a function that prints it. That way you can get it in whatever format you want.",yes way already text split function data function way get whatever format want,issue,negative,neutral,neutral,neutral,neutral,neutral
464541939,"Re-reading my comment, I think if we expose the timing data in the API, then the client doesn't have to worry about producing machine readable output, since those cases can just call the API directly.",comment think expose timing data client worry machine readable output since call directly,issue,negative,positive,neutral,neutral,positive,positive
464541443,"This is super cool, thanks for sharing!

> I have the following questions / requests for feedback before submitting a PR:
> 
>     1. Is the current output acceptable or would something like JSON be preferred?

A machine readable result would be nicer to have. Or at least something like CSV or TSV which balances machine/human readability.

>     2. My background is primarily with Objective-C, not C++ and std, so optimization suggestions are appreciated.

Rather than generating the formatted output in the native client library, it'd be cleaner to expose the timing information in the API, by creating a method that returns it in a data structure, and then format the output in the client. That way other users of the timing information don't need to parse the output, they can just use it directly.

>     3. I only speak English so don't have the ability to test with other languages. It'd be helpful if someone can test with non-English languages and let me know how well it works.

@lissyx might be able to help here.",super cool thanks following feedback current output acceptable would something like preferred machine readable result would least something like readability background primarily optimization rather generating output native client library cleaner expose timing information method data structure format output client way timing information need parse output use directly speak ability test helpful someone test let know well work might able help,issue,positive,positive,positive,positive,positive,positive
464539636,"That's not the actual problem, you're probably using audio with a different framerate than 16kHz. From the error it looks like it could be 22050 Hz audio?",actual problem probably audio different error like could audio,issue,negative,neutral,neutral,neutral,neutral,neutral
464401551,"```
$ python util/check_characters.py --csv data/ldc93s1/ldc93s1.csv -alpha
### Reading in the following transcript files: ###
['data/ldc93s1/ldc93s1.csv']
### The following unique characters were found in your transcripts: ###



a
 
c
e
d
i
h
k
l
o
n
p
s
r
u
t

y
### ^^^ You can copy-paste these into data/alphabet.txt ###
```",python reading following transcript following unique found,issue,negative,positive,positive,positive,positive,positive
463872392,"> _[Please close the issue right-away if does not qualify, the reason for posting here instead of discourse is that I need quick help thanks]_ :/

So we answered the same day, and there's no reaction. Closing.",please close issue qualify reason posting instead discourse need quick help thanks day reaction,issue,positive,positive,positive,positive,positive,positive
463806197,"I'm going to close this ---  given that the output `*.csv` files from `CorporaCreator` will be packaged with `Common Voice` data for download, the paths must be relative. ",going close given output common voice data must relative,issue,negative,negative,negative,negative,negative,negative
463742629,Here: the Output structure also has a probability field which corresponds to the language model confidence in the transcription: https://discourse.mozilla.org/t/word-letter-timestamp-with-deep-speech/34981/5?u=reuben,output structure also probability field language model confidence transcription,issue,positive,neutral,neutral,neutral,neutral,neutral
463741651,"Well, no, since we import the code directly into our repo and change it significantly. I'm pretty sure I've described in high level terms how one would modify the code to expose this, but I don't remember where...",well since import code directly change significantly pretty sure high level one would modify code expose remember,issue,positive,positive,positive,positive,positive,positive
463737891,"IIRC there was a restriction in the cluster that required us to use relative paths in the CSVs, you should double check with @tilmankamp if this is not going to break things.",restriction cluster u use relative double check going break,issue,negative,neutral,neutral,neutral,neutral,neutral
463734623,"Hi, how can you use ctcdecode to obtain the confidence values?",hi use obtain confidence,issue,positive,neutral,neutral,neutral,neutral,neutral
463718311,"Given the low WER impact and the high performances increase, let's enable that.",given low wer impact high increase let enable,issue,negative,positive,neutral,neutral,positive,positive
463508359,"That's work, thank you @reuben , I did install the wrong progressbar2 package",work thank install wrong package,issue,negative,negative,negative,negative,negative,negative
463337228,"Doesn't have anything to do with the file format, looks like you installed the wrong version of the progressbar2 package? Try reinstalling it with `pip install -U progressbar2`",anything file format like wrong version package try pip install,issue,negative,negative,negative,negative,negative,negative
463264373,"TF model v0.4.1, testing on LibriSpeech test-clean dataset:
```
Test - WER: 0.084925, CER: 0.035407, loss: 0.000000

real    46m7,826s
user    1282m18,824s
sys     101m11,893s
```",model testing test wer loss real user,issue,negative,positive,positive,positive,positive,positive
463226848,"Non quantized TFLite model, v0.4.1, testing on LibriSpeech test-clean dataset:
```
Test - WER: 0.104306, CER: 0.044113, loss: 0.000000

real    52m54,435s
user    1610m25,233s
sys     2m26,146s
```",non model testing test wer loss real user,issue,negative,positive,positive,positive,positive,positive
463184944,As explained in the review comment the version numbers are to help with our support requests. Currently you can already silence the numbers by redirecting stderr to /dev/null or just looking at stdout. Is there still value in adding the `-q` flag even if we can't remove the call in `deepspeech.cc`?,review comment version help support currently already silence looking still value flag even ca remove call,issue,positive,neutral,neutral,neutral,neutral,neutral
462792981,"Looks like this was solved, feel free to reopen otherwise.",like feel free reopen otherwise,issue,positive,positive,positive,positive,positive,positive
462774717,"Chiming in again- I didn't have access to `evaluate.py` since we were on an old 0.2.0 alpha release. But having updated to 0.4.1, I've been very pleased by `evaluate.py`'s performance. 5 hours to transcribe 300 hours of audio on one GPU machine, bloody awesome.

So consider me happy, where this is concerned.",access since old alpha release performance transcribe audio one machine bloody awesome consider happy concerned,issue,positive,positive,positive,positive,positive,positive
462761500,We recently removed that function in favor of `tf.contrib.layers.dense_to_sparse`. f3613da82ae7c7439d2674460a0f671e9848fb22,recently removed function favor,issue,negative,neutral,neutral,neutral,neutral,neutral
462760879,"Right, but you can augment to disk and keep the files within a size that fits in memory.",right augment disk keep within size memory,issue,negative,positive,positive,positive,positive,positive
462760470,"The error means the length of the transcripts in your test data add up to zero, which doesn't make much sense given the test data you shared. Try printing the value of `originals` and `results` in `wer_cer_batch` to understand what's going on.",error length test data add zero make much sense given test data try printing value understand going,issue,negative,positive,positive,positive,positive,positive
462735930,"> @nicolaspanel I'm definitely interested in having this feature. Do you have an idea of what the batch API would look like?

@reuben @kdavis-mozilla  since everyone here seems interested by such feature, maybe we could include it in incoming releases (https://github.com/mozilla/DeepSpeech/projects). What do you think ?

Like I said, I can contribute if needed",definitely interested feature idea batch would look like since everyone interested feature maybe could include incoming think like said contribute,issue,positive,positive,positive,positive,positive,positive
462398607,"@renepeinl Sorry, but this was published with no more than best-effort for those brave enough to play. Honestly, the OpenCL support of TensorFlow does not looks like a huge priority upstream, so we are focusing efforts elsewhere.",sorry brave enough play honestly support like huge priority upstream elsewhere,issue,positive,positive,positive,positive,positive,positive
462396827,speaking about outdated versions: the ccpp branch on github looks quite outdated. Is it still the best starting point for getting GPU support on Intel GPUs to work? ,speaking outdated branch quite outdated still best starting point getting support work,issue,positive,positive,neutral,neutral,positive,positive
462345663,"I see; in any case, I will move the discussion to the Discourse, I've just been occupied by other things",see case move discussion discourse,issue,negative,neutral,neutral,neutral,neutral,neutral
462203537,Too recent version of bazel? Too recent version of Java? Broken bazel cache? This doesn't seem to be a problem with our code. Are you able to build e.g. TensorFlow or do you run into the same problem?,recent version recent version broken cache seem problem code able build run problem,issue,negative,positive,neutral,neutral,positive,positive
462063189,"Nobody is working on it AFAIK. Feel free to work on it! If you have any questions you can ask here or over on our IRC channel, #machinelearning at irc.mozilla.org: https://wiki.mozilla.org/IRC",nobody working feel free work ask channel,issue,positive,positive,positive,positive,positive,positive
462012461,"is anyone working on this? or has this been fixed? 
would like to pick this up! -H",anyone working fixed would like pick,issue,negative,positive,neutral,neutral,positive,positive
461733709,"As this is not a bug and/or request for enhancement could you please move this request to our [discourse channel](https://discourse.mozilla.org/c/deep-speech)? Also, could you supply a link to the LDC corpus, I can't seem to find LDC93SI. Thanks.",bug request enhancement could please move request discourse channel also could supply link corpus ca seem find thanks,issue,positive,positive,positive,positive,positive,positive
461733545,"Sure.. This  is just a sample data,... so the file's small enough to be pasted here.
```
wav_filename,wav_filesize,transcript
available benefits of smart account_en-GB_Giorgio.wav,65742,available benefits of smart account
need info on available benefits of ISIC Student account_en-GB-WLS_Joanna.wav,103758,need info on available benefits of isic student account
can you talk about profit rate of banoon Childrens account_en-US_Karl.wav,119886,can you talk about profit rate of banoon childrens account
show me profit rate of banoon children account_en-GB-WLS_Seoyeon.wav,101454,show me profit rate of banoon children account
free debit isic student account_en-IN_Kimberly.wav,62286,free debit isic student account
benefits isic student account_en-GB-WLS_Zhiyu.wav,81870,benefits isic student account
what are the account products of your bank_en-GB-WLS_Vitoria.wav,104910,what are the account products of your bank
how can i change my savings account to a jointaccount_en-US_Matthew.wav,89934,how can i change my savings account to a jointaccount
i am looking for benefits of isic student account_en-GB_Ivy.wav,89934,i am looking for benefits of isic student account
tell me about profit rate of short term investment account_en-AU_Aditi.wav,117582,tell me about profit rate of short term investment account
```
Thanks in advance...",sure sample data file small enough pasted transcript available smart smart account need available student available student account talk profit rate talk profit rate account show profit rate profit rate account free debit student debit student account student student account account account bank change account change account looking student looking student account tell profit rate short term investment profit rate short term investment account thanks advance,issue,positive,positive,positive,positive,positive,positive
461710866,@ashupednekar Could you post a link to the `test.csv` file?,could post link file,issue,negative,neutral,neutral,neutral,neutral,neutral
461395739,"@Giles754128704 

1. just download the `pretrained models` from [here 0.4.1](https://github.com/mozilla/DeepSpeech/releases/download/v0.4.1/deepspeech-0.4.1-models.tar.gz)
2. extract the `tar` file in a folder
3. create a virtual environment
4. pip install deepspeech
5. Activate the virtual env `source virtualenvironment/bin/activate`
6. now **`cd folder/you/extracted/the/models`**
7. now run the below command
**`deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav`**
8. Just change your audio file / file path .
prerequisites : 
python 3.5 +
virtualenv
Hope it helps....!! me too was bit confused while beginning : )  👍 ",extract tar file folder create virtual environment pip install activate virtual source run command model alphabet audio change audio file file path python hope bit confused beginning,issue,negative,negative,negative,negative,negative,negative
461324862,"As we try to reserve issues for bugs and/or feature requests, would you mind moving this query to our [discourse form](https://discourse.mozilla.org/c/deep-speech). Thanks you.",try reserve feature would mind moving query discourse form thanks,issue,negative,positive,positive,positive,positive,positive
461021520,"@nbraud It's standard that different models are required for different accents.

For example Google's speech-to-text service[[1](https://cloud.google.com/speech-to-text/)] has different models for Australian English, Canadian English, Ghanaian English....",standard different different example service different,issue,negative,neutral,neutral,neutral,neutral,neutral
461015707,"@abhijeet3922 sorry for missing your message. Can you try this patch? 
[shape.diff.txt](https://github.com/mozilla/DeepSpeech/files/2836425/shape.diff.txt)

",sorry missing message try patch,issue,negative,negative,negative,negative,negative,negative
460992005,"About using several language models. I am wondering if it is possible to use two language models in the **decoding**. The idea is for using a word-based LM (like the current one) together with a char-based LM.


Edit: This is discussed in some recent papers, like the following one:

- Hori et al. **Multilevel language modeling and decoding for open vocabulary end-to-end speech recognition**",several language wondering possible use two language idea like current one together edit recent like following one al language modeling open vocabulary speech recognition,issue,positive,neutral,neutral,neutral,neutral,neutral
460808403,"@kdavis-mozilla I would consider not working with non-native speakers to be a bug, but whatever.",would consider working bug whatever,issue,negative,neutral,neutral,neutral,neutral,neutral
460785621,As this is neither a bug nor feature request and necessitates a discussion could you please move this to our [discourse form](https://discourse.mozilla.org/c/deep-speech).,neither bug feature request discussion could please move discourse form,issue,negative,neutral,neutral,neutral,neutral,neutral
460778223,"PS: The audio source is 44.1kHz WAV, 16b, resampled to 16kHz for DeepSpeech.
    The recording pipeline and resampling is the same on both tracks (one track per speaker)",audio source recording pipeline one track per speaker,issue,negative,neutral,neutral,neutral,neutral,neutral
460592935,"Looking at our ReadTheDocs docs[[1](https://deepspeech.readthedocs.io/en/latest/?badge=latest)], I don't think they are worth saving. It's likely better, for now, to cut our losses.",looking think worth saving likely better cut,issue,negative,positive,positive,positive,positive,positive
460381060,"> 's a good way to combine probability from multiple language models, this might be implemented as an additional on-the-fly generated mini language model with high probabilities of the injected phrases perhaps
@pvanickova Have you got the required phrase hints done? I am also in search for the same. Please help me out! Thanks!!!!

",good way combine probability multiple language might additional language model high perhaps got phrase done also search please help thanks,issue,positive,positive,positive,positive,positive,positive
459759259,"@kdavis-mozilla I've tested it on Welsh and Kyrgyz, with no hiccups, so hopefully it can scale well:)",tested welsh hopefully scale well,issue,positive,neutral,neutral,neutral,neutral,neutral
459723547,"I'll have to look at it again, but it might be possible. 
The problem with smaller HDF5 caches is that you can't data augment on the fly because you no longer have the access to the waveforms ",look might possible problem smaller ca data augment fly longer access,issue,negative,positive,positive,positive,positive,positive
459722845,"Correct. That would be reverting to our previous setup which is much slower on our systems. Is there a middle ground where we cache features in several HDF5 files and load them as needed? If there's a way to make DeepSpeech work transparently with several smaller caches or just one big file, that's a PR I'd gladly take.",correct would previous setup much middle ground cache several load way make work transparently several smaller one big file gladly take,issue,negative,positive,neutral,neutral,positive,positive
459721328,"so am I right to assume that we're largely not interested in a PR to only store the file names in memory and not the processed data for the network? 

(this would also eliminate the ability and need to cache stuff as hdf5)",right assume largely interested store file memory data network would also eliminate ability need cache stuff,issue,positive,positive,positive,positive,positive,positive
459695207,"@bernardohenz We've a roughly a speed up of a factor of 4.

Previously we used two nodes of our cluster to train a model and it took about 8 days to train. Now we can do the same on one node in 4 days.",roughly speed factor previously used two cluster train model took day train one node day,issue,negative,negative,negative,negative,negative,negative
459687387,@kdavis-mozilla I am currently training using more than 900h on a 16gb RAM. I would like to ask if you have performed a benchmark for checking the speed-up gained with this preprocessing step?,currently training ram would like ask step,issue,negative,neutral,neutral,neutral,neutral,neutral
459650360,"What we're planning on doing is creating a training data set on disk with noise and the like via [voice-corpus-tool](https://github.com/mozilla/voice-corpus-tool), then allowing the current preprocessing step to run.

This doesn't however, solve the problem of a data set being too large to fit in memory. We haven't, fingers crossed, run in to that problem yet. However, I assume that day of reckoning will come. 

Out of curiosity, how many hours of audio are you working with and how much RAM do you have?",training data set disk noise like via current step run however solve problem data set large fit memory crossed run problem yet however assume day reckoning come curiosity many audio working much ram,issue,negative,positive,positive,positive,positive,positive
459647757,"The data used to be loaded and processed on the fly, so I suspect that this new preprocessing step must had improved the performance.

But I agree with you, not only this would allow larger training sets, this would support the use of online (on-the-fly) data augs (like speed/pitch variation on the audio).",data used loaded fly suspect new step must performance agree would allow training would support use data like variation audio,issue,positive,positive,positive,positive,positive,positive
459433220,"This is already documented in the output of `--helpfull`, where else do you think we should have it?

```
  --[no]early_stop: enable early stopping mechanism over validation dataset. Make sure that dev FLAG is enabled for this to work
    (default: 'true')
```",already output else think enable early stopping mechanism validation make sure dev flag work default,issue,negative,positive,positive,positive,positive,positive
459375594,What command line arguments did you use to create your Russian language model?,command line use create language model,issue,negative,neutral,neutral,neutral,neutral,neutral
458098920,"You should probably ask the author of that code :)

Our use of `ctc_label_dense_to_sparse` is still working fine on 1.12.0.",probably ask author code use still working fine,issue,negative,positive,positive,positive,positive,positive
458097912,"OK, I indeed don't know how to use this. I just referred  to a code from the github [https://github.com/carlini/audio_adversarial_examples/blob/master/attack.py](url) (lines 132).  The code originally worked on tensorflow 1.8.0. I want to run it on tensorflow 1.12.0. However, I encountered the errors above.

Do you know how to solve this? ",indeed know use code code originally worked want run however know solve,issue,negative,positive,positive,positive,positive,positive
458090949,"It looks like you're misunderstanding the purpose of that function. It's used on the input side to convert a dense batch created by a `tf.PaddingFIFOQueue` into a `tf.SparseTensor`. On the output side, you can just fetch the logits directly and extract the sequences with the known sequence lengths, no need to convert them into a sparse tensor.",like misunderstanding purpose function used input side convert dense batch output side fetch directly extract known sequence need convert sparse tensor,issue,negative,positive,neutral,neutral,positive,positive
457566576,"Pipenv is nice at some things but terrible at others, we're probably better off sticking to a simple requirements.txt for now.",nice terrible probably better sticking simple,issue,negative,positive,neutral,neutral,positive,positive
457564824,"Seems like this can be closed, feel free to reopen if needed.",like closed feel free reopen,issue,positive,positive,positive,positive,positive,positive
457564077,This was eventually fixed in evaluate.py by simply sticking to a single tower/GPU model since the cost of test epochs is completely dominated by the decoding step.,eventually fixed simply sticking single model since cost test completely dominated step,issue,negative,positive,neutral,neutral,positive,positive
457563672,While these are interesting experiments I don't think we have any plans to work on it in this repo. Probably a fork would be the best way to organize such an effort.,interesting think work probably fork would best way organize effort,issue,positive,positive,positive,positive,positive,positive
457563280,"Is this already fixed? Right now we have this layout:

```
data=""${DATA_ROOT}/shared/data""
fis=""${data}/LDC/fisher""
swb=""${data}/LDC/LDC97S62/swb""
lbs=""${data}/OpenSLR/LibriSpeech/librivox""
```

Which is already under a `organization/corpus` folder structure.",already fixed right layout data data data already folder structure,issue,negative,positive,positive,positive,positive,positive
457562951,"Our only training dependency on native client code is now the ctcdecoder, which is [installed from TaskCluster](https://github.com/mozilla/DeepSpeech/blob/8f2c3f0f0080e2bdf1f715ec06a340ddafc1282a/.install#L10-L11), so closing this. Feel free to reopen if it's still relevant.",training dependency native client code feel free reopen still relevant,issue,positive,positive,positive,positive,positive,positive
457562296,"Should be fairly simple, just add instrumentation around this call: https://github.com/mozilla/DeepSpeech/blob/8f2c3f0f0080e2bdf1f715ec06a340ddafc1282a/DeepSpeech.py#L595-L596",fairly simple add instrumentation around call,issue,negative,neutral,neutral,neutral,neutral,neutral
457552894,"For the sake of simplicity, let's rely on `deepspeech` python module and just run a bunch in parallel with python's multiprocess. This requires a non android `libdeepspeech.so` built with `TFLite`:
 - change `native_client/BUILD` and add a `select()` clause similar to the android one for the `""//tensorflow/contrib/lite/kernels:builtin_ops""` dep, but against `""//tensorflow:linux_x86_64""`
 - `bazel build [...] --copt=-DUSE_TFLITE [...] //native_client:libdeepspeech.so`",sake simplicity let rely python module run bunch parallel python non android built change add select clause similar android one build,issue,negative,neutral,neutral,neutral,neutral,neutral
457257462,Produced artifact could properly be uploaded and it's usable to build and run !,produced artifact could properly usable build run,issue,negative,neutral,neutral,neutral,neutral,neutral
457256938,"scriptWorker is done, uploading and able to re-upload, properly pushing README and release notes.",done able properly pushing release,issue,negative,positive,positive,positive,positive,positive
456995183,"Nope, none of my local builds had the DeepSpeech version in the past.",nope none local version past,issue,negative,negative,negative,negative,negative,negative
456910210,Looks like we also need sources jar ?,like also need jar,issue,negative,neutral,neutral,neutral,neutral,neutral
456903770,"Non-quantized VS Quantized model on LePotato:
```
lepotato@lepotato:~/ds$ ./lite_benchmark_model --graph=output_graph_non_quant.tflite --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048 --output_layer=logits,new_state_c,new_state_h                                                                                                                                                                                                                 
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Num runs: [50]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Warmup runs: [1]
Graph: [output_graph_non_quant.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Loaded model output_graph_non_quant.tflite
resolved reporter
Initialized session in 5.257ms
Running benchmark for 1 iterations
count=1 curr=1887383

Running benchmark for 50 iterations
count=50 first=1791325 curr=1790110 min=1787146 max=1792665 avg=1.78988e+06 std=1173

Average inference timings in us: Warmup: 1.88738e+06, Init: 5257, no stats: 1.78988e+06
lepotato@lepotato:~/ds$ ./lite_benchmark_model --graph=output_graph_quant.tflite --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048 --output_layer=logits,new_state_c,new_state_h 
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Num runs: [50]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Warmup runs: [1]
Graph: [output_graph_quant.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Loaded model output_graph_quant.tflite
resolved reporter
Initialized session in 4.922ms
Running benchmark for 1 iterations 
count=1 curr=711037

Running benchmark for 50 iterations 
count=50 first=650351 curr=650633 min=650351 max=651962 avg=651087 std=386

Average inference timings in us: Warmup: 711037, Init: 4922, no stats: 651087
```",model float float starting number must match number example input delay name output prefix graph input input use loaded model resolved reporter session running running average inference u float float starting number must match number example input delay name output prefix graph input input use loaded model resolved reporter session running running average inference u,issue,negative,negative,neutral,neutral,negative,negative
456863089,"Accuracy example with native client:
```
walleye:/data/local/tmp/arm64 $ LD_LIBRARY_PATH=/data/local/tmp/arm64/ ./deepspeech --model /sdcard/deepspeech/output_graph_non_quant.tflite --alphabet /sdcard/deepspeech/alphabet.txt --audio ../test-alex.en.wav -t
TensorFlow: v1.12.0-10-ge232881
DeepSpeech: v0.4.1-18-g5d842c2
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=116000
i headlor hendo helow
cpu_time_overall=7.89830
walleye:/data/local/tmp/arm64 $ LD_LIBRARY_PATH=/data/local/tmp/arm64/ ./deepspeech --model /sdcard/deepspeech/output_graph_quant.tflite --alphabet /sdcard/deepspeech/alphabet.txt --audio ../test-alex.en.wav -t    
TensorFlow: v1.12.0-10-ge232881
DeepSpeech: v0.4.1-18-g5d842c2
audio_format=1
num_channels=1
sample_rate=16000
bits_per_sample=16
res.buffer_size=116000
a hearlor helo helo
cpu_time_overall=3.01929
walleye:/data/local/tmp/arm64 $
```",accuracy example native client walleye model alphabet audio ge walleye model alphabet audio ge walleye,issue,negative,neutral,neutral,neutral,neutral,neutral
456862077,"With `post_training_quantize=True` in ToCo, on Google Pixel 2 device :
```
walleye:/data/local/tmp $ ./lite_benchmark_model --graph=output_graph_non_quant.tflite --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048>
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Num runs: [50]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Warmup runs: [1]
Graph: [output_graph_non_quant.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Loaded model output_graph_non_quant.tflite
resolved reporter
Initialized session in 38.631ms
Running benchmark for 1 iterations 
count=1 curr=581397

Running benchmark for 50 iterations 
count=50 first=480581 curr=480893 min=470353 max=487364 avg=479385 std=3728

Average inference timings in us: Warmup: 581397, Init: 38631, no stats: 479385
walleye:/data/local/tmp $ ./lite_benchmark_model --graph=output_graph_quant.tflite  --show_flops --input_layer=input_node,previous_state_c,previous_state_h --input_layer_type=float,float,float --input_layer_shape=1,16,19,26:1:1,2048:1,2048 --ou
STARTING!
The number of items in --input_layer_shape (1,16,19,26:1:1,2048:1,2048, with 4 items) must match the number of items in --input_layer (input_node,previous_state_c,previous_state_h, with 3 items). For example --input_layer=input1,input2 --input_layer_shape=1,224,224,4:1,20
Num runs: [50]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Warmup runs: [1]
Graph: [output_graph_quant.tflite]
Input layers: [input_node,previous_state_c,previous_state_h]
Input shapes: [1,16,19,26:1:1,2048:1,2048]
Use nnapi : [0]
Loaded model output_graph_quant.tflite
resolved reporter
Initialized session in 36.913ms
Running benchmark for 1 iterations 
count=1 curr=288370

Running benchmark for 50 iterations 
count=50 first=121900 curr=123450 min=121673 max=126796 avg=122527 std=1159

Average inference timings in us: Warmup: 288370, Init: 36913, no stats: 122527
```",toco device walleye float float starting number must match number example input delay name output prefix graph input input use loaded model resolved reporter session running running average inference u walleye float float starting number must match number example input delay name output prefix graph input input use loaded model resolved reporter session running running average inference u,issue,negative,negative,neutral,neutral,negative,negative
456819056,"Upload target path should be: `org/mozilla/deepspeech/libdeepspeech/<VERSION>`
Uploading at least .pom and .aar file from the `uploadArchives` gradle target.",target path version least file target,issue,negative,negative,negative,negative,negative,negative
456748964,"Did you see the READEME with the command line example?

```bash
deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio my_audio_file.wav
```",see command line example bash model alphabet audio,issue,negative,neutral,neutral,neutral,neutral,neutral
456748831,"> The files in the example are too difficult . How to run a simple demo?

Please explain why it's difficult, since we think it is not.",example difficult run simple please explain difficult since think,issue,negative,negative,negative,negative,negative,negative
456720590,I think it all boils down to the fact that the decoding step is not yet streamable,think fact step yet,issue,negative,neutral,neutral,neutral,neutral,neutral
456427624,We check a `status` that makes no senes. Proper error checking should be: https://github.com/mozilla/tensorflow/blob/r1.12/tensorflow/contrib/lite/examples/label_image/label_image.cc#L96-L113,check status proper error,issue,negative,neutral,neutral,neutral,neutral,neutral
456402512,"> ImportError: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.18' not found (required by /home/santhosh_3.6/DeepSpeech/$/home/santhosh_3.6/virtualenvironment/lib/python3.6/site-packages/deepspeech/lib/libdeepspeech.so)

Looks like some old system. Can you describe more your setup ?",version found like old system describe setup,issue,negative,positive,neutral,neutral,positive,positive
456386437,"> A few comments, but looks good to me.
> 
> What is it about Android 8.0 and 9.0 that make the tests more intermittent?
> 
> Maybe it's time to consider splitting `tc-tests-utils.sh` which is already over 800 lines? There's not a lot of interaction between the added Android code and the existing testing code other than the standard variables, so it shouldn't be too hard to split. I don't feel too strongly about it though, your call.

Not something I plan to fix right now, but yeah, sooner than later.",good android make intermittent maybe time consider splitting already lot interaction added android code testing code standard hard split feel strongly though call something plan fix right yeah sooner later,issue,positive,positive,positive,positive,positive,positive
456380860,"> A few comments, but looks good to me.
> 
> What is it about Android 8.0 and 9.0 that make the tests more intermittent?
> 
> Maybe it's time to consider splitting `tc-tests-utils.sh` which is already over 800 lines? There's not a lot of interaction between the added Android code and the existing testing code other than the standard variables, so it shouldn't be too hard to split. I don't feel too strongly about it though, your call.

Looks like more services are running (`adb shell service list` is bigger), and I had an intermittence level of ~50% on those with UnresponsiveShellException throwing.",good android make intermittent maybe time consider splitting already lot interaction added android code testing code standard hard split feel strongly though call like running shell service list bigger intermittence level throwing,issue,positive,positive,positive,positive,positive,positive
456264356,"If that's true it probably makes more sense to assign different labels for different sounds, this seems harder than I considered though.",true probably sense assign different different harder considered though,issue,negative,positive,neutral,neutral,positive,positive
456069176,"> @lissyx
> Hi, In the lastest version v0.4.1.
> I used the vocabulary and the alphabet from @ailurus1991 to test. https://github.com/ailurus1991/ds_files/blob/master/thchs30-vocabulary.txt
> https://github.com/ailurus1991/ds_files/blob/master/thchs30-alphabet.txt
> 
> The trie file is generated. But, I do not think this file is right. Because the size of this file is too small, only 45KB.
> 
> Is it an another bug?

That seems pretty obvious that this is not a bug. When working on that I got similar small files, I think it's fine.",hi version used vocabulary alphabet test file think file right size file small another bug pretty obvious bug working got similar small think fine,issue,positive,positive,neutral,neutral,positive,positive
455968212,"@lissyx
 Hi, In the lastest version v0.4.1.
I used the vocabulary and  the alphabet  from @ailurus1991 to test. https://github.com/ailurus1991/ds_files/blob/master/thchs30-vocabulary.txt
https://github.com/ailurus1991/ds_files/blob/master/thchs30-alphabet.txt

The trie file is generated. But, I do not think this file is right. Because the size of this file is too small, only 45KB.

Is it an another bug? 

",hi version used vocabulary alphabet test file think file right size file small another bug,issue,negative,positive,neutral,neutral,positive,positive
455874469,Phonemes differ slightly between languages. By that I mean the sound of a particular phoneme may be slightly different in different languages.,differ slightly mean sound particular phoneme may slightly different different,issue,negative,positive,neutral,neutral,positive,positive
455758026,"@kdavis-mozilla I think @Chidhambararajan is referring to the ability of being able to get the transcription as soon as we get enough accumulated logits to do so.
For example: I've tried to use the .NET client to stream the Windows audio output to get the transcriptions and show it on the screen like most of the subtitles works. Which is the problem with my case? We can stream the audio but we can't get the transcriptions from the stream without stoping it.
I tried to do somthing like ""intermediateDecodeAndRelease"" It will excecute the decoding and throw away the old logits, due to my limited knowledge in C++ it did not work :( 

Related to #1757",think ability able get transcription soon get enough example tried use client stream audio output get show screen like work problem case stream audio ca get stream without stoping tried like throw away old due limited knowledge work related,issue,negative,positive,neutral,neutral,positive,positive
454395617,"With 0.4.0 comes from 0.3.0 but was then trained further on Italian data. If it's working better for you, then try using 0.3.0. I recommend using 0.4.1 for any experiments, as it has a lot of small improvements that add up to a higher quality model.",come trained data working better try recommend lot small add higher quality model,issue,positive,positive,positive,positive,positive,positive
454393824,"@reuben  thanks for that info but just wanted to give one example
 In 0.4.0 the transcription is : 
- it isn't just the economy there
In 0.4.1 the same sentence transcription is : 
- it is in justicium there

So its just that the wrong model is giving correct and better result. So should we wait for the next release(would that be happening soon) or train with this because if we train and again get the similar mistakes with 0.4.1 then training job from scratch will cost us in aws and wont get a good model also. 

Sorry for asking again but 
do you recommend using 0.4.1 to train from scratch or just to transfer learn?
or do you recommend to wait for next release?

Thanks ",thanks give one example transcription economy sentence transcription wrong model giving correct better result wait next release would happening soon train train get similar training job scratch cost u wont get good model also sorry recommend train scratch transfer learn recommend wait next release thanks,issue,positive,positive,neutral,neutral,positive,positive
454386211,"Don't use 0.4.0 for anything, we uploaded the wrong checkpoint and model, from a completely unrelated training job. Either use 0.3.0, or 0.4.1.",use anything wrong model completely unrelated training job either use,issue,negative,negative,negative,negative,negative,negative
454380793,"@lissyx  Sorry for not linking my earlier post: 
https://github.com/mozilla/DeepSpeech/issues/1817#issuecomment-454357117

the files are in that post and the examples(which are exerpts) are also in that post

Yes i used only native_client . deepspeech command from cmd.

Ya i dont know if this is because its a bad example or not because some of the parts which were correct in 0.4.0 now became wrong with 0.4.1

I was telling you so that you know about the problem. So it can be corrected if you see a bug.

And because i am not sure which model to do my  training(transfer learning) on that is also why i wanted to let you know the problems with the current version we are having . i am thinking of doing on 0.4.0 but Which model version do you suggest and why. 

And if i train from scratch from the common voice data . Which version is better to train on. Should i use 0.4.0 files or 0.4.1 files because we were thinking of using 0.4.0 for training because it had better transcription . Is that a correct metric?",sorry linking post post also post yes used command ya dont know bad example correct wrong telling know problem corrected see bug sure model training transfer learning also let know current version thinking model version suggest train scratch common voice data version better train use thinking training better transcription correct metric,issue,positive,negative,neutral,neutral,negative,negative
454375741,"> @lissyx So i thought all the other details i mentioned are in the earlier posts about the system. i thought i have already given them.But again i ll mention.

Thing is you tested a lot of different combination, it's hard to know exactly what's your current status if you don't describe it.


> examples are small protions from both transcripts which are attached in my first comment today

Here again, it's complicated to track ""first comment today"", either explicit it, or link to it. We are not all on the same timezone, your ""today"" might be different than mine.


> So i have used both 0.4.0 and 0.4.1 on different virtual environments.both deep speech gpu

So only `native_client` code, no use of any of the VAD-backed stuff ?


> examples i gave are for the same youtube video converted by youtube-dl package and then directly from m4a to wav16k file. ( https://www.youtube.com/watch?v=qvR3PEPqX9A )

At some point, I'm starting to wonder if this video is just a bad case, maybe the audio contains inaudible noise that breaks our current models ?",thought system thought already given mention thing tested lot different combination hard know exactly current status describe small attached first comment today complicated track first comment today either explicit link today might different mine used different virtual deep speech code use stuff gave video converted package directly file point starting wonder video bad case maybe audio inaudible noise current,issue,negative,negative,neutral,neutral,negative,negative
454371609,"@lissyx  So i thought all the other details i mentioned are in the earlier posts about the system. i thought i have already given them.But again i ll mention. 

I didnt know i have to write the information with every post.Details below:

- So i have used both 0.4.0 and 0.4.1 on different virtual environments.both deep speech gpu
- I have not used any models trained by me. Have used both of the pre trained models provided by you in the above test
- examples i gave are for the same youtube video converted by youtube-dl package and then directly from m4a to wav16k file. ( https://www.youtube.com/watch?v=qvR3PEPqX9A )
- examples are small protions from both transcripts which are attached in my first comment today

everything of the setup is as you had told me to do .
Do you require any other information please tell

thanks
",thought system thought already given mention didnt know write information every used different virtual deep speech used trained used trained provided test gave video converted package directly file small attached first comment today everything setup told require information please tell thanks,issue,positive,positive,neutral,neutral,positive,positive
454369654,"I'm sorry, but your bug is really too messy right now, you refer to a lot of different trials, I have absolutely no idea of your system setup / training status at this point. Forget about `0.4.0`, it was wrong.",sorry bug really messy right refer lot different absolutely idea system setup training status point forget wrong,issue,negative,negative,negative,negative,negative,negative
454368758,"> >  Once you say it's okay, then you say it's not.

if you are refering to my earlier messages(before the ones i wrote today) where i said there is not much change between 0.4.0 and 0.4.1 . At that time i didnt change the models folder. So that was wrong feedback. 

",say say wrote today said much change time didnt change folder wrong feedback,issue,negative,negative,negative,negative,negative,negative
454367897,"@lissyx So i am saying that some places where 0.4.0 was correct is now wrongly tanscribed. Some places have become correct which were earlier wrong(This has a lesser frequency than the correct words becoming wrong)

I hope the examples format are clear to understand where 0.4.0 was correct has now become wrong with 0.4.1

So i dont know what the exact problem is. Shouldn't it be like the older transcription should become better with the new version without damaging the earlier correctly transcribed parts.",saying correct wrongly become correct wrong lesser frequency correct becoming wrong hope format clear understand correct become wrong dont know exact problem like older transcription become better new version without correctly,issue,negative,negative,neutral,neutral,negative,negative
454360573,"> I dont know if this is a bug but there is some problem that has been introduced in the new version.

There's way too much noise on your message for me to be able to understand anything. Once you say it's okay, then you say it's not.",dont know bug problem new version way much noise message able understand anything say say,issue,negative,positive,positive,positive,positive,positive
454358506,Or at least mention line endings in the messages printed by `check_characters.py`? Sounds like a good idea.,least mention line printed like good idea,issue,positive,positive,positive,positive,positive,positive
454357117,"@lissyx i think there is a bug. I ll post the rest of the queestions on discourse.
Bug:
I had tried with 0.4.1 but with the old models . I didnt realise it was stable so new models will be there. So with 0.4.1 the transcription has become worse. Correct words being transcribed earlier correctly are being wrongly transcribed.

So the file that i tested are as below:
https://www.youtube.com/watch?v=qvR3PEPqX9A

The old transcription files and new transcription files are being attached . 

You will be able to see most of the correct part is transcribed wrongly with the new version.

Only very small things like chinaman converts to china man or tradeetions has become correctly trade tensions but other things have gone wrong 

attachments below:
[0-4-0transcription.txt](https://github.com/mozilla/DeepSpeech/files/2759383/0-4-0transcription.txt)
[0-4-1transcription.txt](https://github.com/mozilla/DeepSpeech/files/2759384/0-4-1transcription.txt)

I ll give examples:

1.  

- Correct transcription - i want to dig in specifically to the trends you are seeing in china because you you say something interesting which it isn't just the economy there
- 0.4.0 transcription - i went against specifically to the trenors chinaman because you you say something interesting which it isn't just the economy there
- 0.4.1 transcription -i went agin pacifically to the trenger sing and china man because you you say something interesting which it is in justicium there
 

2. 
- Correct transcription --  traffic in our channel partner stores ah the reports of the smart phone industry ah contracting
- 0.4.0 transcription - traffic in our channel partner stones at the report of the smart pony industry or contracting
- 0.4.1 transcription - traffic in er channel partner stones ah the reports of the smart fondants try a contracting

I dont know if this is a bug but there is some problem that has been introduced in the new version.",think bug post rest discourse bug tried old didnt stable new transcription become worse correct correctly wrongly file tested old transcription new transcription attached able see correct part wrongly new version small like china man become correctly trade gone wrong give correct transcription want dig specifically seeing china say something interesting economy transcription went specifically say something interesting economy transcription went pacifically sing china man say something interesting correct transcription traffic channel partner ah smart phone industry ah transcription traffic channel partner report smart pony industry transcription traffic er channel partner ah smart try dont know bug problem new version,issue,positive,positive,positive,positive,positive,positive
453973872,"@raghavk92 All those questions would need to be on Discourse, Github issues are really only dedicated to bugs / features in the codebase.",would need discourse really,issue,negative,positive,positive,positive,positive,positive
453972255,"@lissyx  Hi,
Ya the transcription is greatly improved with the new 0.4.0 update that i tested. I also tested with 0.4.1 but dont know if that has an improvement over 0.4.0 as i didnt find much difference there.Thanks for the updates.

I have 3 questions regarding a few problems i am facing : 

1.  We tried to do transfer learning on the model with a few of our samples(4 large audio samples (technical talks) converted to 740 (around 5 sec chunks and 500 training samples and 100 for dev and 140 for test) that we created with around 5 sec audio with transcription in the csv file created from voice activity detection.

So some transcriptions got better some got worse.
So how many files are needed for a good transfer learning to happen?

2. While transcribing with 04.0 i found that when the person speaks fast the transcription goes wrong either two words merge and form a wrong word or to seperate wrong words. So how do i improve this or this will also happen with transfer learning with people speaking fast and how many samples are ideal

3. I tried transcribing with files with background music but got around 75% accuracy. I removed the noise with audacity:
procedure : 
- remove voice from audio
- get noise profile
- and remove noise from original sample with noise profile

The accuracy was 85% after this.

But i tried to automate this with sox package for ubuntu
procedure:
- remove voice
sox audio.wav music.wav oops

- create noise profile
sox music.wav -n noiseprof noise.prof

- Remove noise from wav using profile
sox audio.wav output.wav noisered noise.prof 0.21

(i also tried with different levels of aggressivness like 0.3,0.05,0.1 etc but not much change in transcription)

The trancription became bad. I think it damaged the voice audio while noise reducing with sox.Do you know a better way for noise reduction and get better transscription.? And if i need to better  transcribe a file which has background music is there any other way(like would training help and how many samples would i be needing)?

Thanks
",hi ya transcription greatly new update tested also tested dont know improvement didnt find much difference regarding facing tried transfer learning model large audio technical converted around sec training dev test around sec audio transcription file voice activity detection got better got worse many good transfer learning happen found person fast transcription go wrong either two merge form wrong word wrong improve also happen transfer learning people speaking fast many ideal tried background music got around accuracy removed noise audacity procedure remove voice audio get noise profile remove noise original sample noise profile accuracy tried package procedure remove voice create noise profile remove noise profile also tried different like much change transcription bad think voice audio noise reducing know better way noise reduction get better need better transcribe file background music way like would training help many would needing thanks,issue,positive,positive,positive,positive,positive,positive
453936404,You could try implementing the work in the cited paper.,could try work paper,issue,negative,neutral,neutral,neutral,neutral,neutral
453936087,"@kdavis-mozilla  Do you do any other optimization suggestion？ It’s really a problem for me....  
I have set the beam_width to 128, but shows no positive effect

",optimization really problem set positive effect,issue,positive,positive,positive,positive,positive,positive
453929038,"This is not surprising as the number of elements in the alphabet increases dramatically from the case of English, where the problem is not noticeable.

What were are starting to experiment is an implementation of [Bytes are All You Need: End-to-End Multilingual Speech Recognition and Synthesis with Bytes](https://arxiv.org/abs/1811.09021) which would have the CTC always output to 256 elements independent of language.",surprising number alphabet dramatically case problem noticeable starting experiment implementation need multilingual speech recognition synthesis would always output independent language,issue,negative,positive,positive,positive,positive,positive
453838191,"@raghavk92 Ok, we now have released a new 0.4.1, could you re-test on your side ? Early testing here shows it improves.",new could side early testing,issue,negative,positive,positive,positive,positive,positive
453838140,"> that seems to have fixed the problem.

I'll close the issue then, thanks!",fixed problem close issue thanks,issue,negative,positive,positive,positive,positive,positive
453838096,"> I can make a pull request for this if wanted.

@kristiank I guess that would be the perfect way to have a better wording",make pull request guess would perfect way better wording,issue,positive,positive,positive,positive,positive,positive
453829958,"Right, so we had some issues when the 0.4.1 release happened, somehow it looks like the rpi3 package was half-uploaded and in an error state, once I removed that manually from the release, re-upload could proceed.",right release somehow like package error state removed manually release could proceed,issue,negative,positive,positive,positive,positive,positive
453793230,"@lissyx I have scripts that pull specific versions for CI, so having one version to pull for all required platforms is best. If 0.4.1 could be uploaded for RPi3 that would be optimal. Thanks.",pull specific one version pull best could would optimal thanks,issue,positive,positive,positive,positive,positive,positive
453793139,Though the 0.4.1 is really just changing the model so the rpi3 tarball from 0.4.0 should work well,though really model work well,issue,negative,positive,positive,positive,positive,positive
453601337,"Oh, that makes sense :-). Maybe we should check line endings? @reuben",oh sense maybe check line,issue,negative,neutral,neutral,neutral,neutral,neutral
453550754,"@lissyx @reuben thanks for helping. I've resolved that error. Problem was in my alphabet file, i  am using Linux terminal on Windows and editing alphabet file in Windows text editor, when i checked it in Linux terminal its shows characters arrangement entirety different. Its very strange to me but at least its done. Now i am getting error in decoding, hopefully will resolve it also.",thanks helping resolved error problem alphabet file terminal alphabet file text editor checked terminal arrangement entirety different strange least done getting error hopefully resolve also,issue,negative,negative,neutral,neutral,negative,negative
453500585,"git-lfs is needed for the language model, not common voice. There's no specific command needed, install it and git should be able to pick it. For the wording, a PR clarifying is always welcome, current sentence seems okay to us, but it can always be better :-) ",language model common voice specific command install git able pick wording always welcome current sentence u always better,issue,positive,positive,positive,positive,positive,positive
453451875,"@lissyx The readme now states that `git-lfs` is needed, but none of the git commands never use it. This is also confusing. Is `git-lfs` only a requirement when working with the Common Voice dataset?",none git never use also requirement working common voice,issue,negative,negative,negative,negative,negative,negative
453450749,"@lissyx and @JRMeyer Another solution would be to simply rewrite the sentence
> Please be aware that this requires at least 70GB of free disk space and quite some time to conclude.
like this
> Please be aware that training with the Common Voice corpus archive requires at least 70GB of free disk space and quite some time to conclude.

I can make a pull request for this if wanted.",another solution would simply rewrite sentence please aware least free disk space quite time conclude like please aware training common voice corpus archive least free disk space quite time conclude make pull request,issue,positive,positive,neutral,neutral,positive,positive
453449882,"@JRMeyer this is a great idea! Since it will take me more than a month before I can do a training with Votic language, I can't volunteer either.

@lissyx it was under the heading ""Common Voice training data"" that the following phrase confused me

> Please be aware that this requires at least 70GB of free disk space and quite some time to conclude.

Now re-reading the whole thing it all makes sense to me. The only solution I can come up with making it more clear would be to state the size of the download in the previous sentence:

> If you already downloaded the Common Voice corpus archive from here, you can simply run the import script on the directory where the corpus is located.

I checked the download is 12 GB now.

My logic for this is that it makes it very clear that it is the downloaded stuff that will get expanded to 70 GB and not something that is necessary for training with another data set.",great idea since take month training language ca volunteer either heading common voice training data following phrase confused please aware least free disk space quite time conclude whole thing sense solution come making clear would state size previous sentence already common voice corpus archive simply run import script directory corpus checked logic clear stuff get expanded something necessary training another data set,issue,positive,positive,neutral,neutral,positive,positive
453116311,"> > > Your alphabet file has two blank lines at the top, not sure this is expected nor what it might produce ?
> > 
> > 
> > i've also checked by removing blank lines.
> 
> Care to share full command lines of your:
> 
> * `util/check_characters.py` use
> * training

Sure i'll share it once reach home as now i am traveling out station",alphabet file two blank top sure might produce also checked removing blank care share full command use training sure share reach home traveling station,issue,positive,positive,positive,positive,positive,positive
453115559,"No, I just had to ensure I had **all** characters in the alphabet, and I ran into some tricky ones, but no code change at all.",ensure alphabet ran tricky code change,issue,negative,neutral,neutral,neutral,neutral,neutral
453113705,"> > @lissyx Yes now i am running every thing under Python 3.
> > Yes ran the character checking many times on all CSV files. and i am 100% sure about parsing correct files. I've also shared small subset example of my training data so you can believe me :)
> > https://drive.google.com/open?id=1_875pTb1YVDcWVYfgkR8A9QnFk_qPv06
> 
> I'm sorry, but I really don't have any time to investigate your dataset, and Urdu is nothing more specific than other language, and we could train with a lot of languages using non ASCII chars, including Kabyle for example in my case :)

So do you need to change any thing in code like in `util/text.py` for Kabyle language ?",yes running every thing python yes ran character many time sure correct also small subset example training data believe sorry really time investigate nothing specific language could train lot non ascii example case need change thing code like language,issue,positive,positive,neutral,neutral,positive,positive
453113451,"> > Your alphabet file has two blank lines at the top, not sure this is expected nor what it might produce ?
> 
> i've also checked by removing blank lines.

Care to share full command lines of your:
 - `util/check_characters.py` use
 - training",alphabet file two blank top sure might produce also checked removing blank care share full command use training,issue,positive,positive,positive,positive,positive,positive
453112910,"> Your alphabet file has two blank lines at the top, not sure this is expected nor what it might produce ?

i've also checked by removing blank lines. ",alphabet file two blank top sure might produce also checked removing blank,issue,negative,positive,positive,positive,positive,positive
453104563,"Your alphabet file has two blank lines at the top, not sure this is expected nor what it might produce ?",alphabet file two blank top sure might produce,issue,negative,positive,positive,positive,positive,positive
453104405,"> @lissyx Yes now i am running every thing under Python 3.
> Yes ran the character checking many times on all CSV files. and i am 100% sure about parsing correct files. I've also shared small subset example of my training data so you can believe me :)
> 
> https://drive.google.com/open?id=1_875pTb1YVDcWVYfgkR8A9QnFk_qPv06

I'm sorry, but I really don't have any time to investigate your dataset, and Urdu is nothing more specific than other language, and we could train with a lot of languages using non ASCII chars, including Kabyle for example in my case :)",yes running every thing python yes ran character many time sure correct also small subset example training data believe sorry really time investigate nothing specific language could train lot non ascii example case,issue,positive,positive,neutral,neutral,positive,positive
453102414,"@lissyx  Yes now i am running every thing under Python 3.
Yes ran the character checking many times on all CSV files. and i am 100% sure about parsing correct files. I've also shared small subset example of my training data so you can believe me  :)

https://drive.google.com/open?id=1_875pTb1YVDcWVYfgkR8A9QnFk_qPv06",yes running every thing python yes ran character many time sure correct also small subset example training data believe,issue,positive,positive,positive,positive,positive,positive
453098351,"Okay, since there was some Python 2 playing that I missed (should not reply when I need to sleep), can you make sure you run everything under only Python 3 ?

Have you ran the character checking tool on **all** the CSV files you are passing ? Are you sure you are not passing wrong files ? (happened to me ...)",since python reply need sleep make sure run everything python ran character tool passing sure passing wrong,issue,negative,positive,positive,positive,positive,positive
453091491,"> > I tried with python 3 and below are results which are ok. but still getting error while training.
> 
> Have you added this list of characters to your alphabet? Have you checked all your CSVs with this tool ?
> 
> ```
> ['ق', 'r', 'ح', 'ے', 'ں', 'ک', 'گ', 'ص', 'غ', 's', 'ا', 'پ', 'ہ', 'ذ', 'i', 'ل', 'ھ', 'م', 'ز', 'ر', 'n', 'c', 'چ', 'ڑ', 'ع', 'خ', 'ٹ', 'ن', 'ث', 'ظ', 'س', 'p', 't', 'a', 'ڈ', 'ف', 'و', 'ض', 'ط', 'ش', 'ی', 'ج', 'د', 'ب', ' ', 'ت', 'آ']
> ```

Yes i've carefully added all characters in my alphabet file. and checked all my csv's also.
here is my alphabet file looks like
https://pastebin.com/jbWnMfxC",tried python still getting error training added list alphabet checked tool yes carefully added alphabet file checked also alphabet file like,issue,negative,negative,neutral,neutral,negative,negative
453083712,"> I tried with python 3 and below are results which are ok. but still getting error while training.

Have you added this list of characters to your alphabet? Have you checked all your CSVs with this tool ?

```
['ق', 'r', 'ح', 'ے', 'ں', 'ک', 'گ', 'ص', 'غ', 's', 'ا', 'پ', 'ہ', 'ذ', 'i', 'ل', 'ھ', 'م', 'ز', 'ر', 'n', 'c', 'چ', 'ڑ', 'ع', 'خ', 'ٹ', 'ن', 'ث', 'ظ', 'س', 'p', 't', 'a', 'ڈ', 'ف', 'و', 'ض', 'ط', 'ش', 'ی', 'ج', 'د', 'ب', ' ', 'ت', 'آ']
```",tried python still getting error training added list alphabet checked tool,issue,negative,neutral,neutral,neutral,neutral,neutral
453076957,"@lissyx - some confusion is caused by the README's assumption that training DeepSpeech means ""training DeepSpeech on Common Voice"". I think a great addition would be a section on ""How to Train DeepSpeech for your own data"". However, that will take a lot of time to write up, and I can't volunteer to do it in the near future:/",confusion assumption training training common voice think great addition would section train data however take lot time write ca volunteer near future,issue,negative,positive,positive,positive,positive,positive
453076907,"> Looks like it's a Python 2 specific problem, Python 2 strings are treated as byte sequences, while Python 3 strings are treated as Unicode codepoint sequences. (Are there multi-codepoint graphemes in any languages?)
> 
> Try running `util/check_characters.py` with Python 3 on the same data.

@reuben 
yes it was the issue wuth python 2. I tried with python 3 and below are results which are ok. but still getting error while training. 

waqas@SID-245:~/DeepSpeech/DeepSpeech$ python3 util/check_characters.py trans_urdu/cv-valid-train.csv
### Reading in the following transcript files: ###
['trans_urdu/cv-valid-train.csv']
### The following unique characters were found in your transcripts: ###
['ق', 'r', 'ح', 'ے', 'ں', 'ک', 'گ', 'ص', 'غ', 's', 'ا', 'پ', 'ہ', 'ذ', 'i', 'ل', 'ھ', 'م', 'ز', 'ر', 'n', 'c', 'چ', 'ڑ', 'ع', 'خ', 'ٹ', 'ن', 'ث', 'ظ', 'س', 'p', 't', 'a', 'ڈ', 'ف', 'و', 'ض', 'ط', 'ش', 'ی', 'ج', 'د', 'ب', ' ', 'ت', 'آ']
### All these characters should be in your data/alphabet.txt file ###",like python specific problem python python try running python data yes issue python tried python still getting error training python reading following transcript following unique found file,issue,negative,positive,neutral,neutral,positive,positive
453073732,Have somebody work on it? It will be a big help. ,somebody work big help,issue,negative,neutral,neutral,neutral,neutral,neutral
453064214,"Looks like it's a Python 2 specific problem, Python 2 strings are treated as byte sequences, while Python 3 strings are treated as Unicode codepoint sequences. (Are there multi-codepoint graphemes in any languages?)

Try running `util/check_characters.py` with Python 3 on the same data.",like python specific problem python python try running python data,issue,negative,neutral,neutral,neutral,neutral,neutral
453063548,"Looks like `util/check_characters.py` is broken for multi-byte characters. For example, 'ک' is `\xDA\xA9` in UTF-8, but the output is suggesting you add `\xDA` and `\xA9` individually, which is incorrect.",like broken example output suggesting add individually incorrect,issue,negative,negative,negative,negative,negative,negative
453048434,"@lissyx  I've added the above list got from `util/check_characters.py`  to my alphabet, still getting the same output.  ",added list got alphabet still getting output,issue,negative,neutral,neutral,neutral,neutral,neutral
453019258,"> > > @lissyx
> > > You can check my csv file as it is properly UTF-8 encoded ?
> > 
> > 
> > Why ? You already have all the elements to fix it ...
> 
> What i suppose to do to fix it ? As error shows its reading Urdu characters properly **KeyError: 'ک'** and all the csv transcript characters are available in my alphabet.txt file so i don't expect UTF-8 is the problem here.

Did you read the error and the output correctly ? It states that you have missing characters in your alphabet. And `util/check_characters.py` just gave you the list ... Add this list to your alphabet, not much to do.

There's no UTF-8 issue here.",check file properly already fix suppose fix error reading properly transcript available file expect problem read error output correctly missing alphabet gave list add list alphabet much issue,issue,negative,positive,neutral,neutral,positive,positive
453000694,"> > @lissyx
> > You can check my csv file as it is properly UTF-8 encoded ?
> 
> Why ? You already have all the elements to fix it ...

What i suppose to do to fix it ?  As error shows its reading Urdu characters properly **KeyError: 'ک'** and all the csv transcript characters are available in my alphabet.txt file so i don't expect UTF-8 is the problem here.
",check file properly already fix suppose fix error reading properly transcript available file expect problem,issue,negative,positive,positive,positive,positive,positive
452993380,"> @lissyx
> You can check my csv file as it is properly UTF-8 encoded ?

Why ? You already have all the elements to fix it ...",check file properly already fix,issue,negative,neutral,neutral,neutral,neutral,neutral
452971815,"and while training its giving me this error:

```
Preprocessing ['trans_urdu/cv-valid-train.csv']
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 1959, in <module>
    tf.app.run(main)
  File ""/home/waqas/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""DeepSpeech.py"", line 1915, in main
    train()
  File ""DeepSpeech.py"", line 1464, in train
    hdf5_cache_path=FLAGS.train_cached_features_path)
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/preprocess.py"", line 68, in preprocess
    out_data = pmap(step_fn, source_data.iterrows())
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/preprocess.py"", line 13, in pmap
    results = pool.map(fun, iterable)
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 288, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 670, in get
    raise self._value
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/usr/lib/python3.6/multiprocessing/pool.py"", line 44, in mapstar
    return list(map(*args))
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/preprocess.py"", line 22, in process_single_file
    transcript = text_to_char_array(file.transcript, alphabet)
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/text.py"", line 41, in text_to_char_array
    return np.asarray([alphabet.label_from_string(c) for c in original])
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/text.py"", line 41, in <listcomp>
    return np.asarray([alphabet.label_from_string(c) for c in original])
  File ""/home/waqas/DeepSpeech/DeepSpeech/util/text.py"", line 31, in label_from_string
    return self._str_to_label[string]
KeyError: 'ک'
```",training giving error recent call last file line module main file line run main file line main train file line train file line file line fun iterable file line map return iterable file line get raise file line worker result true file line return list map file line transcript alphabet file line return original file line return original file line return string,issue,positive,positive,positive,positive,positive,positive
452970878,"> @waqasr6 Check `util/check_characters.py` ?

Yes i've checked earlier. Its giving me some strange results

### Reading in the following transcript files: ###
['trans_urdu/cv-valid-train.csv']
### The following unique characters were found in your transcripts: ###
['\x81', '\x82', '\x85', '\x84', '\x86', '\x88', '\x8c', '\x91', '\x92', ' ', '\xa2', '\xa7', '\xa9', '\xa8', '\xab', '\xaa', '\xad', '\xac', '\xaf', '\xae', '\xb1', '\xb0', '\xb3', '\xb2', '\xb5', '\xb4', '\xb7', '\xb6', '\xb9', '\xb8', '\xba', '\xbe', '\xd9', '\xd8', '\xdb', '\xda', 'a', 'c', 'i', 'n', 'p', 's', 'r', 't']
### All these characters should be in your data/alphabet.txt file ###",check yes checked giving strange reading following transcript following unique found file,issue,positive,positive,neutral,neutral,positive,positive
452884836,"> Hi dear, I am getting the same issue while training for my Urdu language model.
> I am sharing a small subset example of my training data so you can help me figure it out.

I'm asking again, what is not clear in the error message ?",hi dear getting issue training language model small subset example training data help figure clear error message,issue,positive,negative,neutral,neutral,negative,negative
452868174,"@lissyx 
Hi dear, I am getting the same issue while training for my Urdu language model.
I am sharing a small subset example of my training data so you can help me figure it out.

https://drive.google.com/open?id=1_875pTb1YVDcWVYfgkR8A9QnFk_qPv06",hi dear getting issue training language model small subset example training data help figure,issue,positive,negative,negative,negative,negative,negative
452840429,@kristiank Do you mind explaining what's unclear? We clearly states it is for Common Voice dataset. Not for the git clone.,mind explaining unclear clearly common voice git clone,issue,negative,negative,negative,negative,negative,negative
452751596,"I noticed the wave file loading code had changed slightly in the reference client.py script. I updated my code to use the same method, and that seems to have fixed the problem. It seems the `scipy.io.wavfile` and `wave` modules aren't compatible.",wave file loading code slightly reference script code use method fixed problem wave compatible,issue,negative,negative,neutral,neutral,negative,negative
452743897,"I just plugged in the new alpha and beta parameters to my script, but I got same low accuracy scores.",plugged new alpha beta script got low accuracy,issue,negative,positive,neutral,neutral,positive,positive
452739860,"@chrisspen One more thing we just found with the release model is that it's not the final model we wanted to use, we're currently creating a 0.4.1 release with the update which hopefully should be done today.",one thing found release model final model use currently release update hopefully done today,issue,negative,neutral,neutral,neutral,neutral,neutral
452737833,"Embedding hyperparameters into the model is issue #1770. It shouldn’t make the model completely unusable, I don’t think that’s all of the problem here, but it’s hard to diagnose without testing with the same audio files. I’ll take a look after I come back from vacation next week.",model issue make model completely unusable think problem hard diagnose without testing audio take look come back vacation next week,issue,negative,negative,neutral,neutral,negative,negative
452736242,"Which alpha and beta values are you referring to? Are those values passed into `enableDecoderWithLM()`. From my notes in the code, the beta parameter was removed several versions ago. However, I can't find any documentation for this function on readthedocs.

If the model becomes unusable without those parameters, shouldn't those parameters be integrated into the model?",alpha beta code beta parameter removed several ago however ca find documentation function model becomes unusable without model,issue,negative,neutral,neutral,neutral,neutral,neutral
452620285,"Looks like you're using the old decoder hyperparameter values in your code, which could at least partially explain a drop in accuracy. Try using the new values (alpha=0.75, beta=1.85). I've updated the release notes to list those hyperparameters as well.",like old code could least partially explain drop accuracy try new release list well,issue,negative,negative,neutral,neutral,negative,negative
452573714,"From our benchmarking it actually improved. So I'd guess there's some problem in your setup.

Could you describe in detail how you set up your system?",actually guess problem setup could describe detail set system,issue,negative,neutral,neutral,neutral,neutral,neutral
452379976,"Thanks but we want to avoid forks, and ot seems the most active codebase is ComputeCpp one, yet its quite outdated (1.8 last time, coriander is 0.18 so it's even much older).",thanks want avoid active one yet quite outdated last time coriander even much older,issue,positive,negative,neutral,neutral,negative,negative
452365851, [TF-coriander](https://github.com/hughperkins/tf-coriander) may be of interest as an OpenCL version of Tensor flow,may interest version tensor flow,issue,negative,neutral,neutral,neutral,neutral,neutral
452295332,"@kristiank Neither `virtualenv` nor `conda` are part of this project. So if they don't interact well, we can't help. We suggest using _only_ `virtualenv`.",neither part project interact well ca help suggest,issue,positive,neutral,neutral,neutral,neutral,neutral
452286137,"The 70GB are if you work with the Common Voice dataset, the readme is very clear, please explain why you think its unclear? ",work common voice clear please explain think unclear,issue,negative,negative,neutral,neutral,negative,negative
452285971,Care to be more descriptive? There's not even STR or error messages documenting what's broken. Isnt conda already setting up virtualenv anyway? ,care descriptive even error broken already setting anyway,issue,negative,negative,negative,negative,negative,negative
452002814,"I've added my comments for the multiple language model feature in its thread.

Having the option to provide a list of expected phrases for the context still would be very useful in my scenario (pulling subset of hint phrases from a frequently updated dictionary based on the source of the call) . 

Once there's a good way to combine probability from multiple language models, this might be implemented as an additional on-the-fly generated mini language model with high probabilities of the injected phrases perhaps?",added multiple language model feature thread option provide list context still would useful scenario subset hint frequently dictionary based source call good way combine probability multiple language might additional language model high perhaps,issue,positive,positive,positive,positive,positive,positive
451998081,"Here are my thoughts on the multiple language model features:

1. could I specify which LM models are used at inference time for decoding?  (e.g. use general english and department1 lm for one call and use general english and department2 lm for another one)

2. could I specify priority or relative weights of the lm models somehow? (e.g. if you find a hit above minimal threshold from department1 lm, it beats general english model hypothesis)

3. this feature doesn't resolve the case where a custom phrase is embedded in general English if used in isolated decodings as suggested above (e.g. general english + medical terminology lms: dear mr smith i suspect you have ""compound multiple fracture"" and we have to fix it), all models would need to be used in parallel during the beam search for that case",multiple language model could specify used inference time use general department one call use general department another one could specify priority relative somehow find hit minimal threshold department general model hypothesis feature resolve case custom phrase general used isolated general medical terminology dear smith suspect compound multiple fracture fix would need used parallel beam search case,issue,negative,positive,neutral,neutral,positive,positive
451988600,"Good point.

One of the things we are thinking about if the ability to dynamically change language models, see #1678 (Allow use of several decoders (language models) with a single model in the API). Would that be a close enough fit to your use case? (I know you'd still have to create several language models which may be too much of a pain.)

The reason I'm asking is we are trying to decide how to best add just this functionality.",good point one thinking ability dynamically change language see allow use several language single model would close enough fit use case know still create several language may much pain reason trying decide best add functionality,issue,positive,positive,positive,positive,positive,positive
451986838,"The context may change dynamically - something that is a context for one inference wouldn't be a context for another one, e.g. different departments are using different terminology, different shops have different inventory, different parts of an app may have different context options, ...

Rebuilding the language model for each case would mean a lot of language models and very frequent update of the models with new phrases.

Plus sufficiently updating a general English language model with just few high probability phrases would require a lot of dummy text generation to assign the phrase enough probability (just guessing about this one). ",context may change dynamically something context one inference would context another one different different terminology different different inventory different may different context language model case would mean lot language frequent update new plus sufficiently general language model high probability would require lot dummy text generation assign phrase enough probability guessing one,issue,negative,positive,neutral,neutral,positive,positive
451980310,Couldn't this be addressed by a custom language model?,could custom language model,issue,negative,neutral,neutral,neutral,neutral,neutral
451952371,"@raghavk92 A good point mentionned by @reuben and that I forgot: features computations changed, so model from the link you have with binaries 0.4.0-alpha.3 will produce broken output.

So if you could include the full output **including** versions, we would all win some time ...",good point forgot model link produce broken output could include full output would win time,issue,positive,positive,positive,positive,positive,positive
451951704,"> Is building not supposed to work with the latest bazel-0.21.0?

Bazel dependencies are a requirements from TensorFlow itself, not us. @TTTJJJWWW just explained above that you need Bazel 0.5.4.",building supposed work latest u need,issue,negative,positive,positive,positive,positive,positive
451927999,Even extracting the first 10 secs of audio converted directly from the AAC does not help.,even first audio converted directly help,issue,negative,positive,positive,positive,positive,positive
451924458,"> I ll try the ffmpeg_vad_streaming but like do you want me to pass the audio file like
> `node ./index.js --audio <AUDIO_FILE> --model $HOME/models/output_graph.pbmm --alphabet $HOME/models/alphabet.txt`
> (any wav file with any sample rate will work or does this also take 16k input)

Help yourself and read the documenation, as well as the code, `index.js` is short and will reply to all your questions.",try like want pas audio file like node audio model alphabet file sample rate work also take input help read well code short reply,issue,positive,neutral,neutral,neutral,neutral,neutral
451923763,"are you reffering to this: https://github.com/mozilla/DeepSpeech/tree/master/examples/ffmpeg_vad_streaming

I havent tried the above link but i have tried this below:
https://github.com/mozilla/DeepSpeech/blob/master/examples/vad_transcriber/audioTranscript_cmd.py

I ll try the ffmpeg_vad_streaming but like do you want me to pass the audio file like 
`node ./index.js --audio <AUDIO_FILE> --model $HOME/models/output_graph.pbmm --alphabet $HOME/models/alphabet.txt`
(any wav file with any sample rate will work or does this also take 16k input)

or do you want me to do this rtmp stream like:
`node ./index.js  --audio rtmp://<IP>:1935/live/teststream --model $HOME/models/output_graph.pbmm --alphabet $HOME/models/alphabet.txt
`
 but how do i stream the youtube audio to rtmp stream?

",havent tried link tried try like want pas audio file like node audio model alphabet file sample rate work also take input want stream like node audio model alphabet stream audio stream,issue,positive,neutral,neutral,neutral,neutral,neutral
451920405,"Honestly, I don't know. Maybe there's some weird unaudible noise in the original recording / from the original upload that breaks us ? Have you tested the ffmpeg-based VAD tool ?",honestly know maybe weird unaudible noise original recording original u tested tool,issue,positive,positive,positive,positive,positive,positive
451916364,"@lissyx  I run this command and got the transcription :

`deepspeech --model models_updated/output_graph.pbmm --alphabet models_updated/alphabet.txt --lm models_updated/lm.binary --trie models_updated/trie --audio  audiofiles/output16k.wav`

I am using the general way of running a transcription in virtual environment. deepspeech 0.4.0 alpha 3. I am not sure if this is what you asked for . If i gave wrong information , Please tell ..i ll give whatever i can.

With no change i mean i compared both the transcription(the earlier one which i have in the earlier post and the one that i attached now) . I read both and compared them side by side. Didnt compare programmatically but just compared by reading both and their seems to be no change in the transcription by directly converting from m4a to 16k wav file)",run command got transcription model alphabet audio general way running transcription virtual environment alpha sure gave wrong information please tell give whatever change mean transcription one post one attached read side side didnt compare programmatically reading change transcription directly converting file,issue,negative,negative,neutral,neutral,negative,negative
451915908,"Sorry the binary file to be built is quantized and had pointer compression. Thats what I did. 
Previously, my lm.binary has probe hash tables, now I changed it to trie along quantization and pointer compression. ",sorry binary file built pointer compression thats previously probe hash table along quantization pointer compression,issue,negative,negative,negative,negative,negative,negative
451915455,"I read that. 
I got from the code that trie file is quantized as well as has pointer compression; and then trie is build. 
",read got code file well pointer compression build,issue,negative,neutral,neutral,neutral,neutral,neutral
451915378,"> I am attaching the output in a file but the output transcription has no change than with the previous file. Please suggest if i should try something differently

Can you please be more exhaustive when you say ""no change"" ? How did you run the transcription ?",output file output transcription change previous file please suggest try something differently please exhaustive say change run transcription,issue,negative,negative,neutral,neutral,negative,negative
451914469," @lissyx  I tried with converting directly from m4a file to wav 16k file with the command:
ffmpeg -i Watch\ CNBC\'s\ full\ interview\ with\ Apple\ CEO\ Tim\ Cook-qvR3PEPqX9A.f140.m4a -acodec  pcm_s16le -ac 1 -ar 16000 output16k.wav

I am attaching the output in a file but the output transcription has no change than with the previous file. Please suggest if i should try something differently

[timcookcnbcinterview.txt](https://github.com/mozilla/DeepSpeech/files/2732651/timcookcnbcinterview.txt)
",tried converting directly file file command output file output transcription change previous file please suggest try something differently,issue,negative,negative,neutral,neutral,negative,negative
451913403,This should be fixed with the latest master. Please reopen this issue if you still see the bug with the new code.,fixed latest master please reopen issue still see bug new code,issue,negative,positive,positive,positive,positive,positive
451912859,">  Using given link : https://yidatao.github.io/2017-05-31/kenlm-ngram/

I've already said that this is not the proper documentation to follow. If you insist on using unrelated documentation when we have the proper one in the tree under `data/lm/README.md`, we cannot continue to help you.",given link already said proper documentation follow insist unrelated documentation proper one tree continue help,issue,negative,neutral,neutral,neutral,neutral,neutral
451912528,"> Am I on the right track to get the trie file ?

No, but that's because you don't want to read the documenation. You are passing too many arguments to `generate_trie` ...",right track get file want read passing many,issue,negative,positive,positive,positive,positive,positive
451912191,"Am I on the right track to get the trie file ?
",right track get file,issue,negative,positive,positive,positive,positive,positive
451912037,@lissyx  Okay. I'm gonna check it. Thanks!,gon na check thanks,issue,negative,positive,positive,positive,positive,positive
451910915,">  **Invalid label ﻿**

This usually means there's some missing character in the alphabet.",invalid label usually missing character alphabet,issue,negative,negative,negative,negative,negative,negative
451907178,Let me know if something is missing in order to identify the error. I will give more details about that then. Thank you! @lissyx ,let know something missing order identify error give thank,issue,negative,negative,negative,negative,negative,negative
451906978,"A text trie file  is made in the result of below command only 1 is written in it.
/home/rc//Downloads/DeepSpeech-master/native_client/generate_trie /home/rc/Downloads/DeepSpeech-master/data/alphabet.txt /home/rc/Downloads/DeepSpeech-master/data/lm/lm.binary /home/rc/Downloads/DeepSpeech-master/data/vocab.txt /home/rc/Downloads/DeepSpeech-master/data/trie
@lissyx 

",text file made result command written,issue,negative,neutral,neutral,neutral,neutral,neutral
451904809,"@lissyx  My all other files with Urdu language data are also prepared. 
Help me in it. 
Thank you! 
",language data also prepared help thank,issue,positive,neutral,neutral,neutral,neutral,neutral
451904446,"
I am using Deepspeech current Master 0.2.1.Alpha 0 and installed all its requirements. My installations worked finely with Common voice data sets. I did training as well of that datatset. 
Now, I am working on Urdu Language dataset cointaing 708 sentences. 
I prepared different directory of test, train and dev as well as .csv files of these audio files along their transcription/ the standard way of preparing data for deepspeech. 
I have created the Urdu language, language model in binary format.
Using given link : https://yidatao.github.io/2017-05-31/kenlm-ngram/
next, I want to generate trie. I have native client in deepspeech current master.
I was getting an error 
****terminate called after throwing an instance of 'lm::FormatLoadException'
  what():  native_client/kenlm/lm/binary_format.cc:131 in void lm::ngram::MatchCheck(lm::ngram::ModelType, unsigned int, const lm::ngram::Parameters&) threw FormatLoadException.
The binary file was built for probing hash tables but the inference code is trying to load trie with quantization and array-compressed pointers'
Aborted (core dumped)****
I removed this error by changing binary file into 
./build/bin/build_binary trie -a 64 -q 8 -b 7  urdu_3gram.arpa lm.binary 
using https://kheafield.com/code/kenlm/structures/ 
Now, The build lm.binary has quantization and pointer compression. 
But now, I am getting an error of
**Invalid label ﻿
Aborted (core dumped)**

Kindly help. or identify my mistake.
Thank you!",current master alpha worked finely common voice data training well working language prepared different directory test train dev well audio along standard way data language language model binary format given link next want generate native client current master getting error terminate throwing instance void unsigned threw binary file built hash table inference code trying load quantization aborted core removed error binary file build quantization pointer compression getting error invalid label aborted core kindly help identify mistake thank,issue,positive,positive,neutral,neutral,positive,positive
451886902,"@raghavk92 Well, that's exactly what's I'm saying. Youtube-dl fetches raw audio in the m4a and it's AAC:
```
$ mediainfo Watch\ CNBC\'s\ full\ interview\ with\ Apple\ CEO\ Tim\ Cook-qvR3PEPqX9A.f140.m4a 
General
Complete name                            : Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.f140.m4a
Format                                   : dash
Codec ID                                 : dash (iso6/mp41)
File size                                : 13.0 MiB
Duration                                 : 13 min 59 s
Overall bit rate                         : 129 kb/s
Encoded date                             : UTC 2019-01-03 02:40:16
Tagged date                              : UTC 2019-01-03 02:40:16

Audio
ID                                       : 1
Format                                   : AAC
Format/Info                              : Advanced Audio Codec
Format profile                           : LC
Codec ID                                 : mp4a-40-2
Duration                                 : 13 min 59 s
Bit rate                                 : 128 kb/s
Channel(s)                               : 2 channels
Channel positions                        : Front: L R
Sampling rate                            : 44.1 kHz
Frame rate                               : 43.066 FPS (1024 SPF)
Compression mode                         : Lossy
Stream size                              : 12.8 MiB (99%)
Title                                    : ISO Media file produced by Google Inc. Created on: 01/02/2019.
Language                                 : English
Encoded date                             : UTC 2019-01-03 02:40:16
Tagged date                              : UTC 2019-01-03 02:40:16
```

And then when you ask for `WAV` it extracts:
```
$ mediainfo Watch\ CNBC\'s\ full\ interview\ with\ Apple\ CEO\ Tim\ Cook-qvR3PEPqX9A.wav                                                                                                                            
General
Complete name                            : Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.wav
Format                                   : Wave
File size                                : 141 MiB
Duration                                 : 13 min 59 s
Overall bit rate mode                    : Constant
Overall bit rate                         : 1 411 kb/s
Writing application                      : Lavf58.12.100

Audio
Format                                   : PCM
Format settings                          : Little / Signed
Codec ID                                 : 1
Duration                                 : 13 min 59 s
Bit rate mode                            : Constant
Bit rate                                 : 1 411.2 kb/s
Channel(s)                               : 2 channels
Sampling rate                            : 44.1 kHz
Bit depth                                : 16 bits
Stream size                              : 141 MiB (100%)
```

And in the current description of the issue, you are using that last result WAV to again convert. You should try to do the ffmpeg conversion from the m4a.",well exactly saying raw audio general complete name watch full interview apple format dash id dash file size mib duration min overall bit rate date tagged date audio id format advanced audio format profile id duration min bit rate channel channel front sampling rate frame rate compression mode stream size mib title iso medium file produced language date tagged date ask general complete name watch full interview apple format wave file size mib duration min overall bit rate mode constant overall bit rate writing application audio format format little id duration min bit rate mode constant bit rate channel sampling rate bit depth stream size mib current description issue last result convert try conversion,issue,negative,positive,neutral,neutral,positive,positive
451884882,"This the exact output of the youtube-dl package. 
```
[youtube] qvR3PEPqX9A: Downloading webpage
[youtube] qvR3PEPqX9A: Downloading video info webpage
[youtube] qvR3PEPqX9A: Extracting video information
WARNING: unable to extract uploader nickname
[download] Destination: Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.m4a
[download] 100% of 12.96MiB in 06:44
[ffmpeg] Correcting container in ""Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.m4a""
[ffmpeg] Destination: Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.wav
Deleting original file Watch CNBC's full interview with Apple CEO Tim Cook-qvR3PEPqX9A.m4a (pass -k to keep)

```
according to this output it seems that it is downloading m4a file with the help of the extractor as i have given below and then converting to wav with the post processor using ffmpeg for which i have provided the link below.So i dont think AAC stereo file is being fetched but m4a file is  and i think its being converting with ffmpeg. Do you want me to convert m4a to wav myself with ffmpeg? Or am i not understanding something that you said..please explain if i am wrong...please suggest what to do.

i think the extractor being used is from this link https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/extractor/youtube.py

and the post processor for audio extraction is ffmpeg from this link : https://github.com/rg3/youtube-dl/blob/4bede0d8f5b6fc8d8e46ee240f808935e03eafa2/youtube_dl/postprocessor/ffmpeg.py

",exact output package video video information warning unable extract nickname destination watch full interview apple correcting container watch full interview apple destination watch full interview apple original file watch full interview apple pas keep according output file help extractor given converting post processor provided link dont think stereo file fetched file think converting want convert understanding something said please explain wrong please suggest think extractor used link post processor audio extraction link,issue,positive,positive,positive,positive,positive,positive
451882105,"Ah - seems like the progress-bar was not tested for multi-process training.
@PiotrowskiD Please try running with `--noshow_progressbar`.",ah like tested training please try running,issue,positive,neutral,neutral,neutral,neutral,neutral
451880441,">     3\. The link for the file : https://www.youtube.com/watch?v=qvR3PEPqX9A&t and transcription:

`youtube-dl` fetches some AAC stereo 44.1kHz audio. According to `youtube-dl` manpage, the `--extract-audio` depends on `ffmpeg` / `libavcodec`, so it's already torturing the audio stream. As expected, it extracts PCM LE16 as stereo 44.1kHz.

AAC being lossy, we're likely getting some artifacts. @raghavk92 Could you give a try by **not** passing `--extract-audio --audio-format wav` and use ffmpeg to directly extract the original AAC into proper mono 16kHz pcm audio ?",link file transcription stereo audio according already torturing audio stream stereo likely getting could give try passing use directly extract original proper mono audio,issue,negative,positive,positive,positive,positive,positive
451871878,"> youtube-dl package for converting video to audio and like youtube-dl --extract-audio --audio-format wav
> ffmpeg -i inputfile.wav -acodec pcm_s16le -ac 1 -ar 16000 output16k.wav

Interesting. I know we did some demo of some live youtube video transcription taking audio output from the system directly, and getting pretty good results with the streamng, likely much better. This was using the streaming API, but with some other VAD.

Also, I don't know what `youtube-dl` does when you extract audio that way. Is it copying the raw stream or doing something?",package converting video audio like interesting know live video transcription taking audio output system directly getting pretty good likely much better streaming also know extract audio way raw stream something,issue,positive,positive,positive,positive,positive,positive
451866834,"Thanks, that's much more readable, though transcriptions could have been in a separate gist :)",thanks much readable though could separate gist,issue,negative,positive,positive,positive,positive,positive
451865766,"@lissyx 
I can't generate the trie file.
you can check the lm.binary and the arpa file.

[arpa_and_binary.tar.gz](https://github.com/mozilla/DeepSpeech/files/2732054/arpa_and_binary.tar.gz)
",ca generate file check file,issue,negative,neutral,neutral,neutral,neutral,neutral
451863580,"@lissyx  sorry for not formatting it well. Please have a look at the details below:

I used the latest alpha release of deep speech 0.4.0-alpha.3
As i wrote above I use the files from following links:

- output graph from reuben's release:
https://github.com/reuben/DeepSpeech/releases/tag/v0.2.0-prod-ctcdecode

- lm and trie from the github repo:
link- https://github.com/mozilla/DeepSpeech/tree/master/data/lm

- alphabet.txt from https://github.com/mozilla/DeepSpeech/tree/master/data

- i run the vad transcriber file at link: https://github.com/mozilla/DeepSpeech/blob/master/examples/vad_transcriber/audioTranscript_cmd.py

- i dont think vad transcriber was creating any problem in transcription . I think even if it did create problems because of vad it would have been at the start and end points of audio(where the audio was divided) but not within the segment . But the audio part in between the segment was also giving wrong transcription.And also vad transcriber was helping keep the audio length around 5sec . I also tried segmenting audio myself but that had very less effect or did not better the transcription in a very meaningful way.

To convert the audio i was using:
youtube-dl package for converting video to audio and like youtube-dl --extract-audio --audio-format wav <video URL>
ffmpeg -i inputfile.wav -acodec pcm_s16le -ac 1 -ar 16000 output16k.wav

- So now i tested without vad transcriber(the normal way) and the transcription is below:
The example  command: 
deepspeech --model models_updated/output_graph.pbmm --alphabet models_updated/alphabet.txt --lm models_updated/lm.binary --trie models_updated/trie --audio ../timcook16k.wav


1. The audio file is an apple watch video with background music which i get it if it had a bad transcription because of the background music.
The link for the file : https://www.youtube.com/watch?v=6EiI5_-7liQ and transcription:
` e e e   in i an n an a enemple agh seres for is more than an evil lution erepresents a fundamental redesin anryengineering of apple watchrtaining the riginal i comicg designveloped ury find the for olsimanaging to make it fine be new display is now oven birty percen larger and is seemlessly integrated into the product the interface as been read deigned fron you tiplay providing more information with rich a detail the heard wore hand the software combine to define a very new and truly intergrated singular design novigating with the digital crown olready one of the most intricat makhalisms wit ever created has been intirely igreengineeredwith hapti feeback dilivering a presise ecannical field as idrol in addition to an obtea hasanco the is a new applepizine ilectrical hars and se to the lousutitake in electra cardia graham or easy ge to share with your doctor a momnentesichievement for a were of a divice placing a finger on the tigital crownd i eeplose cerkid with a lectrods on the bank providing dater the easy g busesanaliz your harid whole understanding hea health is a sential to ou well bei aditional features in in harmsmans in courag es ti live and overall healther or tantive life the excela romiter girescove an alfliter allow you to recall youtypes of workelse measure runs withincreased presision and tra your all day activity with great accuracy in hart selilar connectiv ity in tabu something prulyliberating the obility distaklinected with just your wach fon case music streaming and even a mergency essistence ol immediately evolable from your restch eries for is a device so powerful so postnal so liperating i con change the way ou liveach day
Inference took 61.270s for 182.370s audio file.`

2. The other video is jonathan ive speech . majorly clear but somethimes in between people are laughing.
The link for the file : https://www.youtube.com/watch?v=GnGI76__sSA and the transcription:
`let stevis to em saye to me and  heused to save is a lot i jonny is it tog pe idea and sometimes they wore really do' pe sometimes they would truly dreadful but sometimes they took the air from the room a neylifted poth completely silent bold crazy maginicicen ideas or quiet simple wones which in thi sufflety bed detail they were uttery profound in just ac steeve loved ydeas and loved makan stuff he treated the prosess a creative atty with a rare an a wonderful reverence is the i think he better than any one understood the wile ideas altimately con be so powerful they begin as fratile bery form thoughts so easily missed so easily compromised so isily jusquift in  i loved the way tha he listened so intendly a loved his peception his remarkaple sensitiveity and his surtily creisopinion i really believe there was a beauty in houe singular how ken his insihtwas even though sometimes it could stey as im surmany of iu know steve didn't confind his sensiv excellent to make him products yon a wo me travel together we would check in and i goup to my room an at leave my bags very needly by the door and i would nompact and i woul go in so under bad i would gon to un the bed next to the phone an i would wait for the inevitable pone col e tony this hadtell supsless go used to chok the the lunitics had taken over the assilemas we shared a giddiesinment spending months and months working on a part of a product that nobody would ever see on the wit her eyes but we did it because we because we really believed that it was right because we cared he believed that there was a gramity almost ascensive civic ressponsibility to care way beyond any sot of tunctional imperative no ale the work hopefully appeared in evi table appeared simple easy it really cost e costasoldin i but you know what he cost him most he cared to most he weried the most deeply he constantly quistioned isis good enough is dhis riht u dispite al his successis all his achievements he never presumed he never assumed thet we would get there i the end when the ideas didn't come and when the prote types failed it was with great intent with faith he decided to believe we would iventually make something great but the joy of getting map i loved is inthusiasm his simple delight oftan atin mixed with therilief but the year we got there we got ther in the end and he was good you cancee smiled conyou the celebration of making something grat for everybody enjoying the defeat of cinisism the rejection of reason the rejection of being told a hundred times and condo that so his i think was a victri forbety fa perity an it he would say forgivin at dam he was my closesst and wo most loae friend we wore together fornelly fifteen years and he still laughed to the way ic said aliminionfr the past to weeks wi a wing struggling to find wast to sake good by this morning i simply ant to wend by saink thank youstath thank you for your remarkable vision which is ounited an inspired this extraordinary group of people for the all the weak of mun from you and for all thet we will continue to learn from each other thank ousta
`
3. This is a tim cook interview. choose this because he speaks slowly and also two people speaking and silence in between. majorly no background noise.
The link for the file : https://www.youtube.com/watch?v=qvR3PEPqX9A&t and transcription:
`tempegir so much particnar tire le shar we ppreciated thenk yiu for colin on i wantod dig right into the results tim and i tol revenues specifically pos is is yumention that was lower than expected an tat o gaid fir for the revenue short fall here and i went togainst pecifically it the trenger sing an shina mam because you you say something interesting which it isn't just the aconomy there it's also es rising trade tentions what did you mean by that tem year if if you look at our results oh our short fall is ah over huntred persent froit pi ton in its primarily and greater child its ok with as we' look at what's going on in china the it's clear that the economy began to slow there for the second half and when i believe to be the case is the trade tentions between e nited states an china put a disinal pressure on their tonomy and so we saw as the quarter wint on a things like god traffic in our retal stores traffic an our channel parter stonees ah the report of the smart pondi indistry ah contracting ah inparticularly bad in nevembered i haven't seem to dicember never yet but i would i would guess the vacnodon be good ither and so ah des what we san and um now thrl wat o things we can do to ah turn our atu to it sort of turn our ah business around and interms of the amoth in china in imore a generally ah a cross were focusing on it if you look at i fon more an a mackral lovel i di dhe storyan i found is in a dition to the emerging market weekness which is priarily in chinon it's tead oh there's not as any subsidies is there used to be for a charrier pointi yer and were that didn't all happen yesterday for if you've been out of the market for two or three years and you come back it looks like that to you i f acts was a big challenge in the corter as i interestrate heighes of stordi ne ie state there's more fore capital cunning in that makes the dollar much stronger in i de translation in we knew that with going to be a factor it effected usto a by bac two hundred bases points i in it in then it' sort of ina in addition to those to things we started a programe erealide ah were we drematically lowered the battery replacement price and so we we had fort of the collection of items going on some that are mackro economic and some that ere appes pecific and were not going to sit around witing for the mac rob to change i hop that a dies in im actually octennis tiv ah but we'e gong to focus ah really i deeply on the things we can control and let inters e things perhaps here littl be adier hintrolo to mi i just wet touch o yan as pecifically ut to back to that because the trad tentions are having a secture seing iconoy there but but you see evidence that perhaps apples also getting caugh in the cross by orntems of  is her evinens tha chine consumer to say you know whether's te dipute there's tention in their takin at on apple an some way as well will i certainly oh apple has not been targueted by the government and so loono me turtake wa any kind of doubt of that right up tap vhere  arl reports ah sort of sparatic reports abowd uh somebody talking about not bying a products ah because we're american may be som a little bit on social media maybe a guy standing in front of store something my my personal since sis that this sa small ah kicking myn ne chinas not monelistic just like a nerica not min alissin he have people wilh different views an different ideas and so do i think anybody alected ah not to by because of that i'm sure some people did but but my sens is thof much lorgyour issue is thi slowing of the conomy and in this a betray tention thats furher pressured and gi tat od given it this is a headwin and enman more than you expect to have you taught hem just intersted to present trum or members uninistration is is a big important american aconomy and your singlisten this trade dispute as really impacting our busets have you have you recently talked to those mevers in isration at enconveyed that you know i i'm telling our investrous first about what we sal ah last quarter into inets bat is the way of should be a but i've had obioustly many manu discussions over ah the course of many mods to to be constructive and to give sort of my prespective on trade in the importance of i to the american acconomy as well and ah i i i feel my come that i'm being listened to an in that respect and so ii'm actually incouraged by what i've heard a most recent ly coming from the us and from china and ah hoefally will sie some change togivn it those trea tentions tim tin an they do remain heated um given the pressur seeing isyu speak a tray ors in desters in vusiness people now in the cours ahead con you ben nanigate this well you you you fokutso whath you can control and so wit what i look at this i say ah wut de ar there's some weakness outside of tin as well i would have liked tove done better and some of our developed markets and so how can we do that will the subsidies have or or fewer these days that's true but we can stort e or we had sorted a trade in per graham and wich cert it panarly eeas drehe th invironment you o keeps a yunit with some one that that wants it in the person o want o new and gits one as well and it's great for developers and in so ford this well but but we have no't really marketed at very much and that  truth is to a consumer the tradian looks like a subsidy because it lowers the price of you the fone that you want and sir jus the min of an example of that and so the the h the rechal price of the ah i ponten ar inunited states is sevel foty no ah but if you havebeen to detot to trade am some plaus which many people are in order to to get that the price goes all the way down to for forty nine or loss and i and so there is a substantial venefit economic and inviromental from tradin werl so working on oh placing a ability to do mutly charges an and so it begins til look like more the traditional way of paing thor it through the carrier by peno taking the the rates out for for twenty for months or so and se you wind up getting a i incredilig ny pond it so much beter th what you've had for twenty thirty dollars a month tor so and ah and so we're doing that we're all so uppiing a lot of focus on the service side are stores are unbelievable at service and the at dibility people for rewaryng about transfering te dayda in o the very word to the snow fan there be something that they lost in the process and so wer rere putting a lot of temphasis on doing that indoing that well and so those are just somethings the other things ah which are not different than we fawg but did affect or revenue in the carter are things like whid ome supply constrates when an unpresedented number of new products during the carter we had new watches and ah we had on new i pe prose both of these were constraing for all or most of the corter did you think un looking back in you theatm do you think ou try to introduce too much new two fast no i think you you you know our arstale jode is we were lestings when the ready and and i that's the way it should be if if you ever stort worring about cantiblizing yourself you can talk torself into not do an molth thas in so i were allive our products were ready over that period now wold i have lihed a simidom to be ready a few unts erlierof course i would onways like that but but gunerally were it wore we're still goin o ned match yon the roadf of a shivping is een a rat and ten eask you too madis wilise in deser's get a lot of information an metrixs but i a as you guys fell outlessners going to b some changes in disclosure you're not young get the number of i tonship to y more you guys don't see at his a relevant metric so much as in the past um if that isn't the date a points thid investrshol be folks on what ore the dat o points yea invester she fult a good a wettion look what we did years ar go actually without the watch we'v never dislosire and so wid fy it was a just because we were secret a people it's it we looked at this in you the watches were wide range and turns of priceing it we knew that a ventually we would have a selilar wadch withere's a stainless stell verses in alominum a there's even an adition and so you begin to say what vou you is there in adding pace things up i made the comparison it sort of like you and i go into the grocery store in putting things in our cart and coming up tohe register and the person sang how many agod it dust makes sis to admam together any more because the price ranges are so wide so we didn't do it on ah watchfen the beginning we' never done it on i pad as we now sten back from lo from the fone we have fhonds being sold in eemerging markets ah like a ifhen six as for renthry hundred dolars and so you got a range from three hundred two a thousand or orin some paces over a thousand depending u pon your selection of of af d ah flash and so forth anstad this thing has lostits meaning an so we felt that at the end of the day ah we were giving andvesters in sort of pointing down to something as if it had this incredible importance to it will be on what it does that doesn't mean were never going to com ind anunit again if we think thit we can better explain resolts with talking about youts i tek i deci something about hem but but jinerally to have it onn a you know every ninety day clock of releasing this ii i don't i think it does the indvestor a discervic frankly but now we are making aditional discosures as well like for example we're going to give the gross morgen or services business you know we've never done that before services has ag grong you know an predible a mout ah we're over t we're going to have over port over ten point eght billion and when we wereport later the smot for a last corder that u new racor and what what drove that to may colorgaves a we ask towar was at news ig is is this is ah this is a cut of exciting for os decause so many things hit records in are the abstore ded apple music hit a ne rackors apple pay hit a new ractor our ah searchad product from the absore kit a new ractord ah a i cloud hiddene raggord and so you know it's very wide and each of the gographry es a gography's hid a porterly racer so even in china they abstore hit o cordly racer whys that it's because its driven by the installed base and aren't stall base ih grew oh young knicely yeurover yer and china is well and an as i say in the letter ah wevh picked up a hundred more milion active divices over the last wile months alone said the visisaning credible number and itwill have we get some interesting things in the pipe line i inservices ar a course we do on products is well and ah so mats fort of another way too ah grow the company to find a question ti es ounger to end the cuartier a hundred thirty billion in nhet cash that's hri am o apple has a history  do um a lot of backquisition they tend to be thoe smaller m tiggest is tree billion for beats um do you think maybe given that cash position um would apple be open to maybe shiftin out thinks about acquisitions in doing aquisitions that may be investers with think or biger or more meingful you you know before for us ah we've never changed our vinacropact positions we've never said thy shelt lot by  ig compinat or tha shalt love my medium company or iit has to only be indiscountry that country we always looked at it from astrategict point ef view an as what is it due for the postomer what is it di for the uther and sod the vast majority of ours had been technology and people that we think would bring a better user experieence that there's a feature or something that that we could do in the future in the vacat help on doing that but that doesit i i always been very clear is we look at it many many companies including vory large companaes we've al lukeed so for not to do those because we haven't found one that we say wile that's o that's a knice ir suchal table but i i'v never well wouldow am wet we do have a lot of a neckcash an i believe the firthecompanies ar stock as an appredale galue and in so ah yi you can dethit ah we're going to be bind sumstock under of the plan that we pad aut therefore quite some time i tenfhenu to much ror taxa you generous eet ti yo its ho galow toar jawe rall im mi he
Inference took 368.070s for 839.401s audio file.`

Now my questions:
1. How do i get  a better transcription for all these files (the one with background noise and the ones without)?

2. How should i train and with which checkpoints and other files to get a better transcription.

3. What should i do differently in training for files with background noise to get a better transcription and what should i do in training to get better transcription for no noise in background?

4. What is the best way to convert so that conversion doesnt affect the transcription?

5. Is there anything else that i missed that i should try .Please tell.

I still have to use evaluate.py . I ll use it and update my comment.

Hopefully this is better formatting.


Thanks in advance",sorry well please look used latest alpha release deep speech wrote use following link output graph release run transcriber file link dont think transcriber problem transcription think even create would start end audio audio divided within segment audio part segment also giving wrong also transcriber helping keep audio length around sec also tried audio le effect better transcription meaningful way convert audio package converting video audio like video tested without transcriber normal way transcription example command model alphabet audio audio file apple watch video background music get bad transcription background music link file transcription evil fundamental apple find make fine new display oven product interface read providing information rich detail wore hand combine define new truly singular design digital crown one wit ever field addition new se cardia graham easy ge share doctor finger bank providing dater easy whole understanding health well e ti live overall life allow recall measure tra day activity great accuracy hart tabu something case music streaming even immediately device powerful con change way day inference took audio video speech clear people laughing link file transcription let em save lot tog idea sometimes wore really sometimes would truly dreadful sometimes took air room completely silent bold crazy quiet simple bed detail profound steeve stuff creative rare wonderful reverence think better one understood wile con powerful begin form easily easily way tha really believe beauty singular ken even though sometimes could stey know excellent make yon wo travel together would check goup room leave needly door would go bad would gon un bed next phone would wait inevitable pone col tony go used taken spending working part product nobody would ever see wit really right almost ascensive civic care way beyond sot imperative ale work hopefully table simple easy really cost know cost deeply constantly good enough al never never assumed would get end come prote great intent faith decided believe would make something great joy getting map simple delight mixed year got got end good celebration making something grat everybody enjoying defeat rejection reason rejection told hundred time think fa would say dam wo friend wore together fifteen still way said past wi wing struggling find wast sake good morning simply ant wend thank thank remarkable vision inspired extraordinary group people weak mun continue learn thank cook interview choose slowly also two people speaking silence background noise link file transcription much tire colin dig right tol specifically lower tat fir revenue short fall went sing say something interesting also e rising trade mean year look oh short fall ah pi ton primarily greater child look going china clear economy slow second half believe case trade china put pressure saw quarter wint like god traffic traffic channel parter ah report smart ah ah bad seem never yet would would guess good ither ah san um wat ah turn sort turn ah business around china generally ah cross look di found market tead oh used yer happen yesterday market two three come back like big challenge ne ie state fore capital cunning dollar much de translation knew going factor bac two hundred base sort addition ah battery replacement price fort collection going economic ere going sit around mac rob change hop actually ah gong focus ah really deeply control let perhaps mi wet touch yan ut back see evidence perhaps also getting cross tha chine consumer say know whether te tention takin apple way well certainly oh apple government wa kind doubt right tap ah sort somebody talking ah may little bit social medium maybe guy standing front store something personal since si sa small ah kicking ne like min people different different think anybody ah sure people thof much issue betray tention thats tat od given expect taught hem present big important trade dispute really recently know telling first sal ah last quarter bat way many ah course many constructive give sort trade importance well ah feel come respect actually recent ly coming u china ah sie change tin remain um given seeing speak tray people ahead con ben well control wit look say ah wut de ar weakness outside tin well would done better day true sorted trade per graham th one person want new one well great ford well really much truth consumer like subsidy price want sir min example rechal price ah ar ah trade many people order get price go way forty nine loss substantial economic working oh ability til look like traditional way carrier taking twenty se wind getting pond much th twenty thirty month tor ah lot focus service side unbelievable service people te word snow fan something lost process wer lot well ah different affect revenue carter like whid supply number new carter new ah new prose think un looking back think try introduce much new two fast think know ready way ever talk ready period wold ready course would like wore still match yon rat ten get lot information fell going disclosure young get number see relevant metric much past um date ore yea good look ar go actually without watch never wid secret people wide range turn knew would stainless stell even begin say pace made comparison sort like go grocery store cart coming register person sang many dust si together price wide ah beginning never done pad sten back lo sold ah like six hundred got range three hundred two thousand thousand depending pon selection ah flash forth thing meaning felt end day ah giving sort pointing something incredible importance mean never going think better explain talking something hem know every ninety day clock think frankly making well like example going give gross morgen business know never done know mout ah going port ten point billion later last corder new drove may ask news ah cut exciting o many hit apple music hit ne apple pay hit new ah product kit new ah cloud know wide e porterly racer even china hit racer driven base stall base grew oh young yer china well say letter ah picked hundred active last wile alone said credible number get interesting pipe line ar course well ah fort another way ah grow company find question ti e end hundred thirty billion cash apple history um lot tend smaller tree billion um think maybe given cash position um would apple open maybe may think know u ah never never said thy lot tha shalt love medium company country always point view due di sod vast majority technology people think would bring better user feature something could future help always clear look many many large al found one say wile table never well wet lot believe ar stock ah ah going bind plan pad therefore quite time much generous ti yo ho mi inference took audio get better transcription one background noise without train get better transcription differently training background noise get better transcription training get better transcription noise background best way convert conversion doesnt affect transcription anything else try tell still use use update comment hopefully better thanks advance,issue,positive,positive,positive,positive,positive,positive
451856343,"> > `lmplz -o 2 --text vocabulary.txt --arpa words.arpa`
> > `build_binary -T -s words.arpa lm.binary`
> 
> This is just plain wrong, please checkout the documentation on how to rebuild a language model: https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md

Ok, with proper arguments for `build_binary` I reproduce the segfault, and at the same place.",text plain wrong please documentation rebuild language model proper reproduce place,issue,negative,negative,negative,negative,negative,negative
451854929,"> `lmplz -o 2 --text vocabulary.txt --arpa words.arpa`
> `build_binary -T -s words.arpa lm.binary`

This is just plain wrong, please checkout the documentation on how to rebuild a language model: https://github.com/mozilla/DeepSpeech/blob/master/data/lm/README.md",text plain wrong please documentation rebuild language model,issue,negative,negative,negative,negative,negative,negative
451854122,"I'm not even able to reproduce your `lm.binary`:
```
alexandre@serveur:~/tmp/KenLM/issue1756$ ../kenlm-build/bin/lmplz -o 2 --text vocabulary.issue1756.txt --arpa words.arpa
=== 1/5 Counting and sorting n-grams ===
Reading /home/alexandre/tmp/KenLM/issue1756/vocabulary.issue1756.txt
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 6 types 6
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:72 2:53974548480
/home/alexandre/tmp/KenLM/kenlm/lm/builder/adjust_counts.cc:52 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `s.n[j] == 0'.
Could not calculate Kneser-Ney discounts for 1-grams with adjusted count 4 because we didn't observe any 1-grams with adjusted count 3; Is this small or artificial data?
Try deduplicating the input.  To override this error for e.g. a class-based model, rerun with --discount_fallback

Abandon
```

Ok, one need `--discount_fallback` as well.",even able reproduce text counting reading calculating chain size void anonymous threw could calculate count observe count small artificial data try input override error model rerun abandon one need well,issue,negative,negative,negative,negative,negative,negative
451844069,"> @lissyx what files?
> 
> you can try with vocabulary.txt and alphabet.txt I uploaded.
> and download the native client with command `python util/taskcluster.py --branch v0.4.0-alpha.3 --target ~/native_client/` and the latest kenlm.
> 
> [alphabet.txt](https://github.com/mozilla/DeepSpeech/files/2731115/alphabet.txt)
> [vocabulary.txt](https://github.com/mozilla/DeepSpeech/files/2731116/vocabulary.txt)

I would also like to have **yours** `lm.binary` and `trie`",try native client command python branch target latest would also like,issue,negative,positive,positive,positive,positive,positive
451796196,"@lissyx what files?

you can try with vocabulary.txt and alphabet.txt I uploaded.
and download the native client with command `python util/taskcluster.py --branch v0.4.0-alpha.3 --target ~/native_client/` and the latest kenlm.

[alphabet.txt](https://github.com/mozilla/DeepSpeech/files/2731115/alphabet.txt)
[vocabulary.txt](https://github.com/mozilla/DeepSpeech/files/2731116/vocabulary.txt)

",try native client command python branch target latest,issue,negative,positive,positive,positive,positive,positive
451785612,"Last I remember, @tilmankamp mentionned `run-cluster.sh` might not be useful anymore?",last remember might useful,issue,negative,positive,positive,positive,positive,positive
451725293,"@lissyx I meet the same error here.

1. vocabulary.txt
```
我
你 我
他
我
你
```
2. alphabet2.txt
```
我
你
他
```

```
lmplz -o 2 --text vocabulary.txt --arpa words.arpa
build_binary -T -s words.arpa  lm.binary
generate_trie alphabet.txt lm.binary trie
```
last I meet the same error.

```
439388 segmentation fault  ~/native_client/generate_trie alphabet.txt lm.binary trie
```
then I run this command in gdb and get some debug info.

```
Program received signal SIGSEGV, Segmentation fault.
0x0000000000412431 in Scorer::save_dictionary(std::string const&) ()
```",meet error text last meet error segmentation fault run command get program received signal segmentation fault scorer,issue,negative,neutral,neutral,neutral,neutral,neutral
451594136,"> @lissyx i converted the exact same way as specified in one of the discourse posts....with parameters -acodec pcm_s16le -ac 1 -ar 16000 . And i get it if noisy sample is giving errors but i have checked on atleast 15 samples witg interviews of tim cook and elon musk....clear non noisy data but still there is spelling error like here becomes hear and evolution is evil lution. Above i only gave two samples one noisy background and one without noisy background.
> 
> How do i improve this result. And i also want to know if you could tell me when i train on the pre trained model what all files do i need to give in checkpoint_dir.... Which version of the checkpoint( as suggested by kdavis i can wait till monday for the latest checkpoint as you would release 0.4.0) and does it need to contain lm and trie or do i need to give thembas seperate arguments because in the readme it shows that i only need to give checkpoint_dir. And as i am new to training i wanted to know if i am thinking correctly that i cant train on top of output graph file but i can only train on the checkpoint file right?

Can you please start by explaining exactly how you run things ? And use proper formatting ? Your first post is barely readable, it's painful to distinguish between your statements, your questions, and your console output.

Can you verify with the basic tools, like `evaluate.py` and native client ? You mention `VAD Transcriber`, this is another element modifying the behavior ...",converted exact way one discourse get noisy sample giving checked cook musk clear non noisy data still spelling error like becomes hear evolution evil gave two one noisy background one without noisy background improve result also want know could tell train trained model need give version wait till latest would release need contain need give need give new training know thinking correctly cant train top output graph file train file right please start explaining exactly run use proper first post barely readable painful distinguish console output verify basic like native client mention transcriber another element behavior,issue,negative,positive,neutral,neutral,positive,positive
451593426,"> Can you please point out, what else configuration is required to run the model?

it's documented at multiple places, including releases pages.",please point else configuration run model multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
451588520,"Yes, next time I will it only in virtual environment.

@lissyx: As you pointed out, looks like I don't have AVX. Attached is the the output for /proc/cpuinfo. 

Can you please point out, what else configuration is required to run the model?

[Output.txt](https://github.com/mozilla/DeepSpeech/files/2728769/Output.txt)
",yes next time virtual environment pointed like attached output please point else configuration run model,issue,positive,neutral,neutral,neutral,neutral,neutral
451568015,"@lissyx i converted the exact same way as specified in one of the discourse posts....with parameters -acodec pcm_s16le -ac 1 -ar 16000 . And i get it if noisy sample is giving errors but i have checked on atleast 15 samples witg interviews of tim cook and elon musk....clear non noisy data but still there is spelling error like here becomes hear and evolution is evil lution. Above i only gave two samples one noisy background and one without noisy background.

How do i improve this result. And i also want to know if you could tell me when i train on the pre trained model what all files do i need to give in checkpoint_dir.... Which version of the checkpoint( as suggested by kdavis i can wait till monday for the latest checkpoint as you would release 0.4.0) and does it need to contain lm and trie or do i need to give thembas seperate arguments because in the readme it shows that i only need to give checkpoint_dir. And as i am new to training i wanted to know if i am thinking correctly that i cant train on top of output graph file but i can only train on the checkpoint file right?",converted exact way one discourse get noisy sample giving checked cook musk clear non noisy data still spelling error like becomes hear evolution evil gave two one noisy background one without noisy background improve result also want know could tell train trained model need give version wait till latest would release need contain need give need give new training know thinking correctly cant train top output graph file train file right,issue,negative,positive,positive,positive,positive,positive
451521347,"> RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz
> 
> And the converted audio with ffmpeg(specs) - RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 16000 Hz

So you have noisy, music background PCM 16-bits stereo 44.1kHz converted to PCM 16-bits mono 16kHz ? Devil's lies in details, it might also come from how you perform the ffmpeg conversion. Check on Discourse there are some good examples.",riff data wave audio bit stereo converted audio spec riff data wave audio bit mono noisy music background stereo converted mono devil might also come perform conversion check discourse good,issue,negative,positive,positive,positive,positive,positive
451520714,"> root@speech:~/DeepSpeech# deepspeech -h
> Illegal instruction (core dumped)

First, it's a bad habit to run that kind of userland process as root. There's 0 reason deepspeech needs to run as root.

Second, that's likely missing AVX, or other kind of CPU extensions. Please check `/proc/cpuinfo`.",root speech illegal instruction core first bad habit run kind process root reason need run root second likely missing kind please check,issue,negative,positive,neutral,neutral,positive,positive
451520306,"> The next morning, training was still being done.

That's not clear to me. It seems it's still pre-processing audio files, not yet training. Now, as to why it takes that much memory, I'm a bit surprised, but we only run that on systems that have much more than what you have.

Honestly, training a big amount of audio data on a GTX1070 is going to take a lot of time itself, and preprocessing being slow will be the least of your concerns, at some point.

Still, preprocessing is mostly python code callling sox, I don't get why it would feel that much of memory. It might help if you could track better memory usage:
 - which processes are growing ?
 - is it really used memory or file cache ?",next morning training still done clear still audio yet training much memory bit run much honestly training big amount audio data going take lot time slow least point still mostly python code get would feel much memory might help could track better memory usage growing really used memory file cache,issue,positive,positive,positive,positive,positive,positive
451505833,"I increased the Swap size to 5GB. That appears to fix one issue. The preprocessing (valid and dev files) did complete using only RAM/Swap Memory. When it finished training did revert to the GPU. Since I only have 8GB of RAM, i will upgrade to 16GB (max for this machine). That should provide overall better performance during preprocessing. Much better than the use of a swap file.

However, I still think there is a issue with preprocessing, at least in my case. Here is what I observed with HTOP via SSH. The training machine was booted in the console mode.

After 30 minutes: Mem: 5GB/7.76GB  Swp: 0/5.0GB
After 40 minutes: Mem: 6.77GB/7.76GB  Swp:268KB/5.0GB
After 60 minutes: Mem: 7.57GB/7.76GB  Swp: 285MB/5.0GB
After 90 minutes: Mem: 7.57GB/7.76GB  Swp: 1.12GB\5.0GB
After 120 minutes: Mem: 7.59GB\7.76GB  Swp: 2.14GB\5.0GB
Within a few minutes later the preprocessing displayed Done and Training began.
This is where it got interesting.
After 150 minutes: Mem: 7.54GB\7.76GB  Swp: 4.46GB\5.0GB
After 7 hours: Mem: 7.56GB\7.76GB  Swp: 4.74GB\5.0GB

The next morning, training was still being done. The GPU processing observed in NVTOP via SSH looked normal and processing was being done as recorded in the checkpoint directory but RAM Mem was still indicating a continual 91.6% usage. If at this point, the only processing that should be happening is file retrieval for training and should not be that high or continuous. HTOP is showing 20-25 processes still in what appears to be in the preprocessing stage even though it displayed Done in the terminal window.

Your thoughts?
",swap size fix one issue valid dev complete memory finished training revert since ram upgrade machine provide overall better performance much better use swap file however still think issue least case via training machine booted console mode mem mem mem mem mem within later displayed done training got interesting mem mem next morning training still done via normal done directory ram mem still continual usage point happening file retrieval training high continuous showing still stage even though displayed done terminal window,issue,positive,positive,positive,positive,positive,positive
451440009,"As you look to have a mix-and-match model, what might be easier, instead of tracking down the problem, is to just wait until Monday when we are planning on doing the 0.4.0 release, then use that.",look model might easier instead problem wait release use,issue,negative,neutral,neutral,neutral,neutral,neutral
451438898,"@lissyx  i didnt use the 0.3.0 model because it gave that error no softmax layer. I used the reuben release 0.2.0-ctc-decode which i got from another github issue. The link for the model is https://github.com/reuben/DeepSpeech/releases/tag/v0.2.0-prod-ctcdecode

All the other files lm, trie i have given links to which i used.

And the original audio that i downloaded from youtube and converted to audio with youtube-dl package - RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, stereo 44100 Hz

And the converted audio with ffmpeg(specs) -  RIFF (little-endian) data, WAVE audio, Microsoft PCM, 16 bit, mono 16000 Hz

and i also want to know if conversion can mess up recognition where and how do i get the audio specs deep speech will work with . I mean like how do i convert because mostly audio i have will be in a different sample rate mostly 44100k than 16k and even if i train i will train with the converted samples only. and if converted samples create problem how to resolve this

Also one more thing i want to ask i was trying to train but i couldnt find the checkpoint for the reuben's release so how to train and what to put in checkpoint_dir to train from pre release model? do i have to put 0.2.0 checkpoint or the output_graph files can be used for training above them . And how to use output_graph to train if that is possible because in the readme its written only to give the checkpoint directory?",didnt use model gave error layer used release got another issue link model given link used original audio converted audio package riff data wave audio bit stereo converted audio spec riff data wave audio bit mono also want know conversion mess recognition get audio spec deep speech work mean like convert mostly audio different sample rate mostly even train train converted converted create problem resolve also one thing want ask trying train find release train put train release model put used training use train possible written give directory,issue,negative,positive,positive,positive,positive,positive
451403925,"> I used the latest alpha release of deep speech 0.4.0-alpha.3 as the stable release was giving really bad results. I used output_graph from reuben’s release because the 0.3.0 was giving very bad results as it was just gibberish and nothing of vcalue was there in the transcription for 0.3.0 models and this fix was providing in the github issue #1156

Please elaborate. You took 0.3.0 model `as-is` and used it with `0.4.0-alpha.3` binaries ? Or did you made any extra step ? The 0.3.0 out-of-the-box model would output gibberish with those binaries because of no `softmax` later, so one need to re-export to make it compatible.

> I actually extracted audio from an apple ad where jonathan ive speaks with a really clear voice but has background music.I converted to 16000 samples a second as required by deepspeech I found a lot of spelling errors.

What are the exact original and converted audio specs ? Conversion could add artifacts that messes up with recognition.",used latest alpha release deep speech stable release giving really bad used release giving bad gibberish nothing transcription fix providing issue please elaborate took model used made extra step model would output gibberish later one need make compatible actually extracted audio apple ad really clear voice background converted second found lot spelling exact original converted audio spec conversion could add recognition,issue,positive,positive,neutral,neutral,positive,positive
451156914,"I also separated the wget example in the README into two commands since the piped version doesn't allow one to resume a partial download, and people have run into that in the past.",also example two since piped version allow one resume partial people run past,issue,negative,negative,negative,negative,negative,negative
450945428,"@reuben 

by online I was meaning to perform data aug on-the-fly. I am already having performance issues for performing swap (when training on large training datasets that do not fit into the memory); that's why I do not like the idea of increasing even more the memory usage.",meaning perform data already performance swap training large training fit memory like idea increasing even memory usage,issue,positive,positive,positive,positive,positive,positive
450931083,"Our current preprocessing pipeline is offline due to high filesystem access costs in our cluster, so for now offline augmentation is the easiest path. I want to experiment with the new tf.data APIs at some point to get a more flexible input pipeline, but I probably won't have bandwidth for it anytime soon.",current pipeline due high access cluster augmentation easiest path want experiment new point get flexible input pipeline probably wo soon,issue,positive,positive,neutral,neutral,positive,positive
