id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1961479665,"Can you provide more details, please?
Can you provide a picture/screenshot of what you get, a picture/screenshot of what you would expect?",provide please provide get would expect,issue,negative,neutral,neutral,neutral,neutral,neutral
1820296810,have you made sure that the filenames array is sorted?,made sure array sorted,issue,negative,positive,positive,positive,positive,positive
1751956492,"Normalization takes place by the framework(s) automatically - it's done at runtime, including resizing with/without considering aspect-ratio when (re-)training the model: the train/val images have a resolution of 480x270, but the training happens with `imgsz=640`.",normalization place framework automatically done considering training model resolution training,issue,negative,neutral,neutral,neutral,neutral,neutral
1624011436,"Hi LolLouis

Could you demonstrate how to use  cv2.estimateAffinePartial2D()  to replace the old method?

Thanks!",hi could demonstrate use replace old method thanks,issue,negative,positive,positive,positive,positive,positive
1598588835,"Raspberry pi 4 with bullseye os, opencv 4.5.1 c++10, looked in the header file and it appears they only support CSRT and KCF with this version and I don't  want to downgrade.",raspberry pi o header file support version want downgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
1597663200,"Can you provide more details about your environment, please?
What versions (Operating System, OpenCV, build tools) do you use? Natively, in a container, in a virt-env?
Is there a specific sample code you are referring to?
Python, C, C++? Make, CMake?",provide environment please operating system build use natively container specific sample code python make,issue,negative,neutral,neutral,neutral,neutral,neutral
1595747846,"Now I tried it under MS-Win10 in a Python virt-env using thhe Jupyter notebook as well.
I got a `cv2.error: Unknown C++ exception` with the instruction `net.setInput(inpBlob)`.

Via Google search I found e.g. this pointer: ""https://stackoverflow.com/questions/75334101/layeroutputs-net-forwardoutput-layers-names-cv2-error-unknown-c-exception""

Yes, I had manually installed `pip3 install opencv-python`, and now manually installed `pip3 install opencv-python==4.6.0.66`.

With this version I got the Jupyter notebook to run successfully:

![image](https://github.com/spmallick/learnopencv/assets/29976962/bb84bcdf-f2af-4eaa-a037-5b784f6fe4e6)

![image](https://github.com/spmallick/learnopencv/assets/29976962/f9f58ef6-501a-4ee7-8a23-e10d48e67c7b)

![image](https://github.com/spmallick/learnopencv/assets/29976962/2aa3b0a6-0351-40fd-9e62-62db76398247)
",tried python notebook well got unknown exception instruction via search found pointer yes manually pip install manually pip install version got notebook run successfully image image image,issue,positive,positive,positive,positive,positive,positive
1595721264,"I have simply run the notebook below:
https://github.com/spmallick/learnopencv/blob/master/OpenPose-Multi-Person/multi-person-openpose.ipynb
with protoFile and weightFile as given. I kept the input also the same. 
The Openpose vesion is 4.7.0
",simply run notebook given kept input also,issue,negative,neutral,neutral,neutral,neutral,neutral
1595662606,"Looks like the code doesn't match to the model (anylonger).
Which version of the code/notebook/repo and which version of the model do you use? Do you use the original model of the sample, or used your own retrieved one?
Can you add a few print-log-messages of the provided input-shape and of the expected input-shape? You might check the model via a model-viewer like ""Netron"" and check the expected input-shape.",like code match model version version model use use original model sample used one add provided might check model via like check,issue,positive,positive,positive,positive,positive,positive
1584444942,Would you want to check level of.... Blur... Of an image.. ?? ,would want check level blur image,issue,negative,neutral,neutral,neutral,neutral,neutral
1584386415,"I'm also having trouble understanding where the mapIdx comes from aswell...
Is there an explanation about this already?",also trouble understanding come aswell explanation already,issue,negative,negative,negative,negative,negative,negative
1566245354,"(But I do face issues with `github.com` right now, from home, via land-line - running into timeouts when resolving Â´github.comÂ´)",face right home via running,issue,negative,positive,positive,positive,positive,positive
1566245221,"Pfff. I guess Iâ€™m an idiot.

There is: (Sorry about that, but we canâ€™t show files that are this big right now.) and I thought the file is missing.

Sorry for this, I will try to get some lessons in reading ðŸ˜‰

 

From: Markus Broghammer ***@***.***> 
Sent: Sunday, May 28, 2023 9:47 PM
To: spmallick/learnopencv ***@***.***>
Cc: Udo-A ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] opencv_face_detector_uint8.pb missing (Issue #825)

 

Via both provided links I currently can access and download the mentioned file successfully - under MS-WIn10 using Chrome browser:
 <https://user-images.githubusercontent.com/29976962/241583447-dea5e392-1018-4ba0-9145-066360a95576.png> 

 <https://user-images.githubusercontent.com/29976962/241583605-980a3e93-0a07-4e08-899c-0175e78af389.png> 

Around 2.6MB in size.
Doesn't look like Git-LFS is involved.

Can you access and download the file via web-browser, too?

â€”
Reply to this email directly, view it on GitHub <https://github.com/spmallick/learnopencv/issues/825#issuecomment-1566243052> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ARR6ABARIK5BL4FEXWT56CDXIOTU5ANCNFSM6AAAAAAYR2DRAU> .
You are receiving this because you authored the thread.  <https://github.com/notifications/beacon/ARR6ABGCUT43LMEH5L7USH3XIOTU5A5CNFSM6AAAAAAYR2DRAWWGG33NNVSW45C7OR4XAZNMJFZXG5LFINXW23LFNZ2KUY3PNVWWK3TUL5UWJTS5LL4OY.gif> Message ID: ***@***.*** ***@***.***> >

",guess idiot sorry show big right thought file missing sorry try get reading sent may author subject missing issue via provided link currently access file successfully chrome browser around size look like involved access file via reply directly view thread message id,issue,negative,negative,negative,negative,negative,negative
1566243052,"Via both provided links I currently can access and download the mentioned file successfully - under MS-WIn10 using Chrome browser:
![image](https://github.com/spmallick/learnopencv/assets/29976962/dea5e392-1018-4ba0-9145-066360a95576)

![image](https://github.com/spmallick/learnopencv/assets/29976962/980a3e93-0a07-4e08-899c-0175e78af389)

Around 2.6MB in size.
Doesn't look like Git-LFS is involved.

Can you access and download the file via web-browser, too?",via provided link currently access file successfully chrome browser image image around size look like involved access file via,issue,positive,positive,positive,positive,positive,positive
1566226406,"Hi Markus,

 

i got this Link from an example https://github.com/spmallick/learnopencv/blob/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb

There is nothing, but the file is listed here: https://github.com/spmallick/learnopencv/tree/master/FaceDetectionComparison/models

 

Udo

 

From: Markus Broghammer ***@***.***> 
Sent: Sunday, May 28, 2023 3:53 PM
To: spmallick/learnopencv ***@***.***>
Cc: Udo-A ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] opencv_face_detector_uint8.pb missing (Issue #825)

 

Can you provide more details, please? Which sample are you referring to?

What does your environment look like (which versions, how installed)?

What have you tried, how are you using the code (like command line parameters, input files), any errors, logs printed?

â€”
Reply to this email directly, view it on GitHub <https://github.com/spmallick/learnopencv/issues/825#issuecomment-1566148825> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ARR6ABHCGG2YXSC4CNOA773XINKFBANCNFSM6AAAAAAYR2DRAU> .
You are receiving this because you authored the thread.  <https://github.com/notifications/beacon/ARR6ABGI4AABOKA2GWHAE33XINKFBA5CNFSM6AAAAAAYR2DRAWWGG33NNVSW45C7OR4XAZNMJFZXG5LFINXW23LFNZ2KUY3PNVWWK3TUL5UWJTS5LGENS.gif> Message ID: ***@***.*** ***@***.***> >

",hi got link example nothing file listed udo sent may author subject missing issue provide please sample environment look like tried code like command line input printed reply directly view thread message id,issue,positive,negative,neutral,neutral,negative,negative
1566148825,"Can you provide more details, please? Which sample are you referring to?

What does your environment look like (which versions, how installed)?

What have you tried, how are you using the code (like command line parameters, input files), any errors, logs printed?",provide please sample environment look like tried code like command line input printed,issue,positive,neutral,neutral,neutral,neutral,neutral
1560243197,"Could be a version conflict (e.g. version and/or supported layers and/or operations of the model) between the used framework (Tensorflow) and the model.

Maybe additional logs during loading of DNN might help via `enableModelDiagnostics()`:
https://docs.opencv.org/4.x/d6/d0f/group__dnn.html#ga9c06b170a462e97b413163aadb9869f9

Not every example documents the needed requirements (or documentation or `requirements.txt` is outdated), or sample-resources (like model-file) (like ""the model-file X was created/trained/exported using Framework Y in version Z"").",could version conflict version model used framework model maybe additional loading might help via every example documentation outdated like like framework version,issue,positive,negative,negative,negative,negative,negative
1560150717,"I built OpenCV 4.7 on Windows using CMake for GCC. However, I couldn't build Caffe. I installed TensorFlow on GCC and successfully ran a test program with it. But when I run the examples from this repository, the program gets stuck at the net.forward line without any error.

That's why I installed Microsoft Visual Studio 2022 Community and I want to install and configure OpenCV 4.7 for it. The reason I asked these questions here was to make sure that I have done everything correctly.

Since I don't have an NVIDIA graphics card, I want to use DNN with CPU.",built however could build successfully ran test program run repository program stuck line without error visual studio community want install configure reason make sure done everything correctly since graphic card want use,issue,positive,positive,positive,positive,positive,positive
1560009296,"Other than MS-Windows and C++ - do you have something specific in mind?

Have you tried following e.g. ""https://docs.opencv.org/4.7.0/d3/d52/tutorial_windows_install.html"" (for e.g. version v4.7 or any other version to select from the drop-down field in the upper-left corner)?

Do you need or have to build from source on your own?

Do you need a specific backend (like for NVIDIA-GPUs or Intel-GPUs/CPUs/VPUs, like using OpenVINO)?

When it is about an Intel-based environment (like CPU, GPU, VPU, FPGA), would it be possible for you to use OpenVINO (build from source or pre-built) (in the latest versions of OpenVINO there is no OpenCV contained anymore, but providing instructions for how to get it, how to install, which version to use as a specific version of OpenVINO is validated using a specific version of OpenCV)?",something specific mind tried following version version select field corner need build source need specific like like environment like would possible use build source latest providing get install version use specific version specific version,issue,positive,positive,neutral,neutral,positive,positive
1559718385,"I think that may be the issue. When installing the requirements tf-nightly-gpu got depreciated so I ended up installing tensorflow==2.6.2. From the documentation in the Autograph Code link it looks like those functions are in a different place after tf2.0â€¦

Reid T. Powell, PhD | Research Assistant Professor
Center for Translational Cancer Research, Institute of Biosciences & Technology | Texas A&M University
2121 W. Holcombe Blvd. Rm 911 | Houston, TX 77030
ph: 713.677.7474 | fax: 713.677.7474 | ***@***.******@***.***>

From: Rohit Dhankar ***@***.***>
Sent: Monday, May 22, 2023 2:13 PM
To: spmallick/learnopencv ***@***.***>
Cc: Powell, Reid T ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] VAE_Cartoon_Tensorflow Training (Issue #822)

Please do correct me if im wrong ..â€Š. i may end up confusing you then providing a solution Presuming you are using this code -- VAE_Cartoon_TensorFlow.â€Šipynb Where are you getting this bit of code ..â€Š.â€Šprobably from a TEMP FILE of KERAS or TF.â€ŠAutograph
ZjQcmQRYFpfptBannerStart
This Message Is From an External Sender
This message came from outside your organization.
ZjQcmQRYFpfptBannerEnd

Please do correct me if im wrong ... i may end up confusing you then providing a solution

Presuming you are using this code -- VAE_Cartoon_TensorFlow.ipynb<https://urldefense.com/v3/__https:/github.com/spmallick/learnopencv/blob/master/Variational-Autoencoder-TensorFlow/VAE_Cartoon_TensorFlow.ipynb__;!!KwNVnqRv!He6-MTe5RtUe6LK_aj3IySmhezX5LEvHky596PEn8VAz_PX7IQjHBUpgbkKF9-yRNT0X_gRjKdLbGLaFwSIW4evyow$>

Where are you getting this bit of code ...probably from a TEMP FILE of KERAS or TF.Autograph origin thats letting us know that the Notebook cells you have run have missed a continuous Kernel run ...
So while it needs that variable value -- kl_loss , its not getting that within the -- Autograph Code -- https://www.tensorflow.org/api_docs/python/tf/autograph<https://urldefense.com/v3/__https:/www.tensorflow.org/api_docs/python/tf/autograph__;!!KwNVnqRv!He6-MTe5RtUe6LK_aj3IySmhezX5LEvHky596PEn8VAz_PX7IQjHBUpgbkKF9-yRNT0X_gRjKdLbGLaFwSIiSL9_Qw$>

File ~\AppData\Local\Temp\__autograph_generated_filem_niztwx.py:11, in outer_factory.<locals>.inner_factory.<locals>.tf__vae_loss(y_true, y_pred, mean, var) 9 retval_ = ag__.UndefinedReturnValue() 10 r_loss = ag__.converted_call(ag__.ld(mse_loss), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope) ---> 11 kl_loss = ag__.converted_call(ag__.ld(kl_loss), (ag__.ld(mean), ag__.ld(log_var)), None, fscope)

â€”
Reply to this email directly, view it on GitHub<https://urldefense.com/v3/__https:/github.com/spmallick/learnopencv/issues/822*issuecomment-1557785172__;Iw!!KwNVnqRv!He6-MTe5RtUe6LK_aj3IySmhezX5LEvHky596PEn8VAz_PX7IQjHBUpgbkKF9-yRNT0X_gRjKdLbGLaFwSI0zOEoNA$>, or unsubscribe<https://urldefense.com/v3/__https:/github.com/notifications/unsubscribe-auth/APOLEE26A6NUVBDDBCTOQW3XHO3C5ANCNFSM6AAAAAAYJUXIPA__;!!KwNVnqRv!He6-MTe5RtUe6LK_aj3IySmhezX5LEvHky596PEn8VAz_PX7IQjHBUpgbkKF9-yRNT0X_gRjKdLbGLaFwSJoByBzdg$>.
You are receiving this because you authored the thread.Message ID: ***@***.******@***.***>>
",think may issue got ended documentation autograph code link like different place research assistant professor center translational cancer research institute technology university sent may author subject training issue please correct wrong may end providing solution presuming code getting bit code probably temp file autograph message external sender message came outside organization please correct wrong may end providing solution presuming code getting bit code probably temp file origin thats u know notebook run continuous kernel run need variable value getting within autograph code file mean none mean none reply directly view id,issue,negative,negative,negative,negative,negative,negative
1557785172,"Please do correct me if im wrong ... i may end up confusing you then providing a solution 

Presuming you are using this code -- [VAE_Cartoon_TensorFlow.ipynb](https://github.com/spmallick/learnopencv/blob/master/Variational-Autoencoder-TensorFlow/VAE_Cartoon_TensorFlow.ipynb)

Where are you getting this bit of code ...probably from a TEMP FILE of KERAS or **TF.Autograph** origin thats letting us know that the Notebook cells you have run have missed a continuous Kernel run ... 
So while it needs that variable value -- kl_loss , its not getting that within the -- **Autograph Code** -- https://www.tensorflow.org/api_docs/python/tf/autograph

`File ~\AppData\Local\Temp\__autograph_generated_filem_niztwx.py:11, in outer_factory.<locals>.inner_factory.<locals>.tf__vae_loss(y_true, y_pred, mean, var)
      9 retval_ = ag__.UndefinedReturnValue()
     10 r_loss = ag__.converted_call(ag__.ld(mse_loss), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope)
---> 11 kl_loss = ag__.converted_call(ag__.ld(kl_loss), (ag__.ld(mean), ag__.ld(log_var)), None, fscope)`",please correct wrong may end providing solution presuming code getting bit code probably temp file origin thats u know notebook run continuous kernel run need variable value getting within autograph code file mean none mean none,issue,negative,negative,negative,negative,negative,negative
1557196049,"Thanks for the prompt response, and sorry for the vague description of the error. The full trace back is:


---------------------------------------------------------------------------
UnboundLocalError                         Traceback (most recent call last)
Cell In[36], line 1
----> 1 train(normalized_ds, 30)

Cell In[34], line 8, in train(dataset, epochs)
      6 for image_batch in dataset:
      7     i += 1
----> 8     loss = train_step(image_batch)
      9     #loss_.append(loss)
     10
     11 #print(""Loss"",np.mean(loss_))
     12 seed = image_batch[:25]

File C:\Anaconda3\envs\tensorflow29\lib\site-packages\tensorflow\python\util\traceback_utils.py:153, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    151 except Exception as e:
    152   filtered_tb = _process_traceback_frames(e.__traceback__)
--> 153   raise e.with_traceback(filtered_tb) from None
    154 finally:
    155   del filtered_tb

File ~\AppData\Local\Temp\__autograph_generated_file3_wyyupw.py:14, in outer_factory.<locals>.inner_factory.<locals>.tf__train_step(images)
     12     latent = ag__.converted_call(ag__.ld(final), ([ag__.ld(mean), ag__.ld(log_var)],), None, fscope)
     13     generated_images = ag__.converted_call(ag__.ld(dec), (ag__.ld(latent),), dict(training=True), fscope)
---> 14     loss = ag__.converted_call(ag__.ld(vae_loss), (ag__.ld(images), ag__.ld(generated_images), ag__.ld(mean), ag__.ld(log_var)), None, fscope)
     15 gradients_of_enc = ag__.converted_call(ag__.ld(encoder).gradient, (ag__.ld(loss), ag__.ld(enc).trainable_variables), None, fscope)
     16 gradients_of_dec = ag__.converted_call(ag__.ld(decoder).gradient, (ag__.ld(loss), ag__.ld(dec).trainable_variables), None, fscope)

File ~\AppData\Local\Temp\__autograph_generated_filem_niztwx.py:11, in outer_factory.<locals>.inner_factory.<locals>.tf__vae_loss(y_true, y_pred, mean, var)
      9 retval_ = ag__.UndefinedReturnValue()
     10 r_loss = ag__.converted_call(ag__.ld(mse_loss), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope)
---> 11 kl_loss = ag__.converted_call(ag__.ld(kl_loss), (ag__.ld(mean), ag__.ld(log_var)), None, fscope)
     12 try:
     13     do_return = True

UnboundLocalError: in user code:

    File ""C:\Users\rpowell\AppData\Local\Temp\ipykernel_793660\144731484.py"", line 11, in train_step  *
        loss = vae_loss(images, generated_images, mean, log_var)
    File ""C:\Users\rpowell\AppData\Local\Temp\ipykernel_793660\2804652454.py"", line 11, in vae_loss  *
        kl_loss = kl_loss(mean, log_var)

    UnboundLocalError: local variable 'kl_loss' referenced before assignment


I did run the following block before training:
def mse_loss(y_true, y_pred):
    r_loss = K.mean(K.square(y_true - y_pred), axis = [1,2,3])
    return 1000 * r_loss

def kl_loss(mean, log_var):
    kl_loss =  -0.5 * K.sum(1 + log_var - K.square(mean) - K.exp(log_var), axis = 1)
    return kl_loss

def vae_loss(y_true, y_pred, mean, var):
    r_loss = mse_loss(y_true, y_pred)
    kl_loss = kl_loss(mean, log_var)
    return  r_loss + kl_loss

and I could comment out the k1_loss in the vae_loss function to get it to run. So I am thinking something is wrong with the function, but I am admittingly niave in this space.


Reid T. Powell, PhD | Research Assistant Professor
Center for Translational Cancer Research, Institute of Biosciences & Technology | Texas A&M University
2121 W. Holcombe Blvd. Rm 911 | Houston, TX 77030
ph: 713.677.7474 | fax: 713.677.7474 | ***@***.******@***.***>

________________________________
From: Rohit Dhankar ***@***.***>
Sent: Sunday, May 21, 2023 9:38 PM
To: spmallick/learnopencv ***@***.***>
Cc: Powell, Reid T ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] VAE_Cartoon_Tensorflow Training (Issue #822)

Apparently the loss variable is being accessed in code before it's getting initialised â€” Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.â€ŠMessage ID: <spmallick/learnopencv/issues/822/1556432382@â€Šgithub.â€Šcom>
ZjQcmQRYFpfptBannerStart
This Message Is From an External Sender
This message came from outside your organization.

ZjQcmQRYFpfptBannerEnd

Apparently the loss variable is being accessed in code before it's getting initialised

â€”
Reply to this email directly, view it on GitHub<https://urldefense.com/v3/__https://github.com/spmallick/learnopencv/issues/822*issuecomment-1556432382__;Iw!!KwNVnqRv!EiPJ-fvYlMTWVLsNlFk_XrS_NgJVV46eqVWGKt5ofG47Rnb_P6pxHIGx_dbkcpGZAswWxaMpG1X8-5C-hIMMyG07MA$>, or unsubscribe<https://urldefense.com/v3/__https://github.com/notifications/unsubscribe-auth/APOLEEYEAQHMLVYHRYDDPE3XHLGSJANCNFSM6AAAAAAYJUXIPA__;!!KwNVnqRv!EiPJ-fvYlMTWVLsNlFk_XrS_NgJVV46eqVWGKt5ofG47Rnb_P6pxHIGx_dbkcpGZAswWxaMpG1X8-5C-hIMowv-lUQ$>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",thanks prompt response sorry vague description error full trace back recent call last cell line train cell line train loss loss print loss seed file except exception raise none finally file latent final mean none latent loss mean none loss none loss none file mean none mean none try true user code file line loss mean file line mean local variable assignment run following block training axis return mean mean axis return mean mean return could comment function get run thinking something wrong function space research assistant professor center translational cancer research institute technology university sent may author subject training issue apparently loss variable code getting reply directly view thread message id message external sender message came outside organization apparently loss variable code getting reply directly view id,issue,negative,negative,negative,negative,negative,negative
1556432382,Apparently the loss variable is being accessed in code before it's getting initialised,apparently loss variable code getting,issue,negative,positive,neutral,neutral,positive,positive
1555019649,"Here are the results i've got on WIDER FACE val dataset. [Notebook](https://colab.research.google.com/drive/1Jh4dZ_8qgOMkVM5F9gFyHf4gLyX09t_b): you need to download the dataset and labels from the [benchmark site](http://shuoyang1213.me/WIDERFACE/) to run the code
<html xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:w=""urn:schemas-microsoft-com:office:word""
xmlns:m=""http://schemas.microsoft.com/office/2004/12/omml""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=Word.Document>
<meta name=Generator content=""Microsoft Word 15"">
<meta name=Originator content=""Microsoft Word 15"">
<link rel=File-List
href=""file:////Users/fanaev/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_filelist.xml"">
<link rel=themeData
href=""file:////Users/fanaev/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_themedata.thmx"">
<link rel=colorSchemeMapping
href=""file:////Users/fanaev/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_colorschememapping.xml"">
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Normal</w:View>
  <w:Zoom>0</w:Zoom>
  <w:TrackMoves/>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>RU</w:LidThemeOther>
  <w:LidThemeAsian>X-NONE</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
  </w:Compatibility>
  <w:DoNotOptimizeForBrowser/>
  <m:mathPr>
   <m:mathFont m:val=""Cambria Math""/>
   <m:brkBin m:val=""before""/>
   <m:brkBinSub m:val=""&#45;-""/>
   <m:smallFrac m:val=""off""/>
   <m:dispDef/>
   <m:lMargin m:val=""0""/>
   <m:rMargin m:val=""0""/>
   <m:defJc m:val=""centerGroup""/>
   <m:wrapIndent m:val=""1440""/>
   <m:intLim m:val=""subSup""/>
   <m:naryLim m:val=""undOvr""/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState=""false"" DefUnhideWhenUsed=""false""
  DefSemiHidden=""false"" DefQFormat=""false"" DefPriority=""99""
  LatentStyleCount=""376"">
  <w:LsdException Locked=""false"" Priority=""0"" QFormat=""true"" Name=""Normal""/>
  <w:LsdException Locked=""false"" Priority=""9"" QFormat=""true"" Name=""heading 1""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 2""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 3""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 4""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 5""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 6""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 7""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 8""/>
  <w:LsdException Locked=""false"" Priority=""9"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""heading 9""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 6""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 7""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 8""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index 9""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 1""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 2""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 3""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 4""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 5""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 6""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 7""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 8""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""toc 9""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Normal Indent""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""footnote text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""annotation text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""header""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""footer""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""index heading""/>
  <w:LsdException Locked=""false"" Priority=""35"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""caption""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""table of figures""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""envelope address""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""envelope return""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""footnote reference""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""annotation reference""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""line number""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""page number""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""endnote reference""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""endnote text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""table of authorities""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""macro""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""toa heading""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Bullet""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Number""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Bullet 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Bullet 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Bullet 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Bullet 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Number 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Number 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Number 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Number 5""/>
  <w:LsdException Locked=""false"" Priority=""10"" QFormat=""true"" Name=""Title""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Closing""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Signature""/>
  <w:LsdException Locked=""false"" Priority=""1"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""Default Paragraph Font""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text Indent""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Continue""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Continue 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Continue 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Continue 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""List Continue 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Message Header""/>
  <w:LsdException Locked=""false"" Priority=""11"" QFormat=""true"" Name=""Subtitle""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Salutation""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Date""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text First Indent""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text First Indent 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Note Heading""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text Indent 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Body Text Indent 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Block Text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Hyperlink""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""FollowedHyperlink""/>
  <w:LsdException Locked=""false"" Priority=""22"" QFormat=""true"" Name=""Strong""/>
  <w:LsdException Locked=""false"" Priority=""20"" QFormat=""true"" Name=""Emphasis""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Document Map""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Plain Text""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""E-mail Signature""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Top of Form""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Bottom of Form""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Normal (Web)""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Acronym""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Address""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Cite""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Code""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Definition""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Keyboard""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Preformatted""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Sample""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Typewriter""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""HTML Variable""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Normal Table""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""annotation subject""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""No List""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Outline List 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Outline List 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Outline List 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Simple 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Simple 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Simple 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Classic 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Classic 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Classic 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Classic 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Colorful 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Colorful 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Colorful 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Columns 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Columns 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Columns 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Columns 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Columns 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 6""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 7""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Grid 8""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 4""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 5""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 6""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 7""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table List 8""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table 3D effects 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table 3D effects 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table 3D effects 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Contemporary""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Elegant""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Professional""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Subtle 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Subtle 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Web 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Web 2""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Web 3""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Balloon Text""/>
  <w:LsdException Locked=""false"" Priority=""39"" Name=""Table Grid""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Table Theme""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" Name=""Placeholder Text""/>
  <w:LsdException Locked=""false"" Priority=""1"" QFormat=""true"" Name=""No Spacing""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 1""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" Name=""Revision""/>
  <w:LsdException Locked=""false"" Priority=""34"" QFormat=""true""
   Name=""List Paragraph""/>
  <w:LsdException Locked=""false"" Priority=""29"" QFormat=""true"" Name=""Quote""/>
  <w:LsdException Locked=""false"" Priority=""30"" QFormat=""true""
   Name=""Intense Quote""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""60"" Name=""Light Shading Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""61"" Name=""Light List Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""62"" Name=""Light Grid Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""63"" Name=""Medium Shading 1 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""64"" Name=""Medium Shading 2 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""65"" Name=""Medium List 1 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""66"" Name=""Medium List 2 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""67"" Name=""Medium Grid 1 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""68"" Name=""Medium Grid 2 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""69"" Name=""Medium Grid 3 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""70"" Name=""Dark List Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""71"" Name=""Colorful Shading Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""72"" Name=""Colorful List Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""73"" Name=""Colorful Grid Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""19"" QFormat=""true""
   Name=""Subtle Emphasis""/>
  <w:LsdException Locked=""false"" Priority=""21"" QFormat=""true""
   Name=""Intense Emphasis""/>
  <w:LsdException Locked=""false"" Priority=""31"" QFormat=""true""
   Name=""Subtle Reference""/>
  <w:LsdException Locked=""false"" Priority=""32"" QFormat=""true""
   Name=""Intense Reference""/>
  <w:LsdException Locked=""false"" Priority=""33"" QFormat=""true"" Name=""Book Title""/>
  <w:LsdException Locked=""false"" Priority=""37"" SemiHidden=""true""
   UnhideWhenUsed=""true"" Name=""Bibliography""/>
  <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true""
   UnhideWhenUsed=""true"" QFormat=""true"" Name=""TOC Heading""/>
  <w:LsdException Locked=""false"" Priority=""41"" Name=""Plain Table 1""/>
  <w:LsdException Locked=""false"" Priority=""42"" Name=""Plain Table 2""/>
  <w:LsdException Locked=""false"" Priority=""43"" Name=""Plain Table 3""/>
  <w:LsdException Locked=""false"" Priority=""44"" Name=""Plain Table 4""/>
  <w:LsdException Locked=""false"" Priority=""45"" Name=""Plain Table 5""/>
  <w:LsdException Locked=""false"" Priority=""40"" Name=""Grid Table Light""/>
  <w:LsdException Locked=""false"" Priority=""46"" Name=""Grid Table 1 Light""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark""/>
  <w:LsdException Locked=""false"" Priority=""51"" Name=""Grid Table 6 Colorful""/>
  <w:LsdException Locked=""false"" Priority=""52"" Name=""Grid Table 7 Colorful""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""Grid Table 1 Light Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""Grid Table 2 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""Grid Table 3 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""Grid Table 4 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""Grid Table 5 Dark Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""Grid Table 6 Colorful Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""Grid Table 7 Colorful Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""46"" Name=""List Table 1 Light""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark""/>
  <w:LsdException Locked=""false"" Priority=""51"" Name=""List Table 6 Colorful""/>
  <w:LsdException Locked=""false"" Priority=""52"" Name=""List Table 7 Colorful""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 1""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 2""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 3""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 4""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 5""/>
  <w:LsdException Locked=""false"" Priority=""46""
   Name=""List Table 1 Light Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""47"" Name=""List Table 2 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""48"" Name=""List Table 3 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""49"" Name=""List Table 4 Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""50"" Name=""List Table 5 Dark Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""51""
   Name=""List Table 6 Colorful Accent 6""/>
  <w:LsdException Locked=""false"" Priority=""52""
   Name=""List Table 7 Colorful Accent 6""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Mention""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Smart Hyperlink""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Hashtag""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Unresolved Mention""/>
  <w:LsdException Locked=""false"" SemiHidden=""true"" UnhideWhenUsed=""true""
   Name=""Smart Link""/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:""Cambria Math"";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1107305727 0 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520082689 -1073697537 9 0 511 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"""";
	margin:0cm;
	mso-pagination:widow-orphan;
	font-size:14.0pt;
	mso-bidi-font-size:12.0pt;
	font-family:""Times New Roman"",serif;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-bidi-font-family:""Times New Roman"";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-family:""Calibri"",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:Calibri;
	mso-fareast-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:""Times New Roman"";
	mso-bidi-theme-font:minor-bidi;
	mso-font-kerning:0pt;
	mso-ligatures:none;
	mso-fareast-language:EN-US;}
@page WordSection1
	{size:612.0pt 792.0pt;
	margin:2.0cm 42.5pt 2.0cm 3.0cm;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:""ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°"";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"""";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:""Calibri"",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:""Times New Roman"";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
table.MsoTableGrid
	{mso-style-name:""Ð¡ÐµÑ‚ÐºÐ° Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹"";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-priority:39;
	mso-style-unhide:no;
	border:solid windowtext 1.0pt;
	mso-border-alt:solid windowtext .5pt;
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-border-insideh:.5pt solid windowtext;
	mso-border-insidev:.5pt solid windowtext;
	mso-para-margin:0cm;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:""Calibri"",sans-serif;
	mso-ascii-font-family:Calibri;
	mso-ascii-theme-font:minor-latin;
	mso-hansi-font-family:Calibri;
	mso-hansi-theme-font:minor-latin;
	mso-bidi-font-family:""Times New Roman"";
	mso-bidi-theme-font:minor-bidi;
	mso-fareast-language:EN-US;}
</style>
<![endif]-->
</head>

<body lang=RU style='tab-interval:35.4pt;word-wrap:break-word'>
<!--StartFragment-->



ÐœÐ¾Ð´ÐµÐ»ÑŒ (Ð‘Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ°) | Wider Face VAL   mAP 0.5:0.95 | FPS (Google   Colab CPU, 427 x 640)
-- | -- | --
HaarCascade   (opencv) | 0.511 | ~6.58
Dlib (dlib) | 0.468 | ~15.63
SSD   (opencv) | 0.579 | ~17.24
MTCNN   (mtcnn) | 0.715 | ~0.79
DSFD (face   detection/torch) | 0.975 | ~0.10
RetinaFace-ResNet50   (face detection/torch) | 0.945 | ~0.76
RetinaFace-MobileNetV1   (face detection/torch) | 0.853 | ~11.76
MediaPipe   (mediapipe) | 0.166 | ~25
YuNet   (opencv) | 0.890 | ~27.78



<!--EndFragment-->
</body>

</html>
",got face notebook need site run code urn office office urn office word head meta meta word meta word link file link file link file view normal view zoom zoom false false false compatibility compatibility math false false false false false true normal false true heading false true true true heading false true true true heading false true true true heading false true true true heading false true true true heading false true true true heading false true true true heading false true true true heading false true true index false true true index false true true index false true true index false true true index false true true index false true true index false true true index false true true index false true true false true true false true true false true true false true true false true true false true true false true true false true true false true true normal indent false true true footnote text false true true annotation text false true true header false true true footer false true true index heading false true true true caption false true true table false true true envelope address false true true envelope return false true true footnote reference false true true annotation reference false true true line number false true true page number false true true reference false true true text false true true table false true true macro false true true toa heading false true true list false true true list bullet false true true list number false true true list false true true list false true true list false true true list false true true list bullet false true true list bullet false true true list bullet false true true list bullet false true true list number false true true list number false true true list number false true true list number false true title false true true false true true signature false true true default paragraph font false true true body text false true true body text indent false true true list continue false true true list continue false true true list continue false true true list continue false true true list continue false true true message header false true subtitle false true true salutation false true true date false true true body text first indent false true true body text first indent false true true note heading false true true body text false true true body text false true true body text indent false true true body text indent false true true block text false true true false true true false true strong false true emphasis false true true document map false true true plain text false true true signature false true true top form false true true bottom form false true true normal web false true true acronym false true true address false true true cite false true true code false true true definition false true true keyboard false true true false true true sample false true true typewriter false true true variable false true true normal table false true true annotation subject false true true list false true true outline list false true true outline list false true true outline list false true true table simple false true true table simple false true true table simple false true true table classic false true true table classic false true true table classic false true true table classic false true true table colorful false true true table colorful false true true table colorful false true true table false true true table false true true table false true true table false true true table false true true table grid false true true table grid false true true table grid false true true table grid false true true table grid false true true table grid false true true table grid false true true table grid false true true table list false true true table list false true true table list false true true table list false true true table list false true true table list false true true table list false true true table list false true true table effect false true true table effect false true true table effect false true true table contemporary false true true table elegant false true true table professional false true true table subtle false true true table subtle false true true table web false true true table web false true true table web false true true balloon text false table grid false true true table theme false true text false true spacing false light shading false light list false light grid false medium shading false medium shading false medium list false medium list false medium grid false medium grid false medium grid false dark list false colorful shading false colorful list false colorful grid false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false true revision false true list paragraph false true quote false true intense quote false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false light shading accent false light list accent false light grid accent false medium shading accent false medium shading accent false medium list accent false medium list accent false medium grid accent false medium grid accent false medium grid accent false dark list accent false colorful shading accent false colorful list accent false colorful grid accent false true subtle emphasis false true intense emphasis false true subtle reference false true intense reference false true book title false true true bibliography false true true true heading false plain table false plain table false plain table false plain table false plain table false grid table light false grid table light false grid table false grid table false grid table false grid table dark false grid table colorful false grid table colorful false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false grid table light accent false grid table accent false grid table accent false grid table accent false grid table dark accent false grid table colorful accent false grid table colorful accent false list table light false list table false list table false list table false list table dark false list table colorful false list table colorful false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false list table light accent false list table accent false list table accent false list table accent false list table dark accent false list table colorful accent false list table colorful accent false true true mention false true true smart false true true false true true unresolved mention false true true smart link style font math variable swiss variable style yes margin time new serif time new yes time new none page size margin page style style yes time new border solid solid solid solid time new body face map face face face,issue,positive,negative,neutral,neutral,negative,negative
1551855485,"Now I just tried `simple-scan.py` under MS-Win10, using Python v3.8.8 - tested in a virt-env.
I needed to modify `requirements.txt` - to use `opencv-contrib-python` instead of `opencv-contrib-python-headless`.

Also needed to create a folder `inputs` under the folder `outputs`.

Using the sample input `scanned-form.jpg` - then I get the following (downscaled and cut screenshot):

![image](https://github.com/spmallick/learnopencv/assets/29976962/e06cf255-53a7-4b7e-a018-6bac2f747901)

What output do you get @orcohen9826 ?",tried python tested modify use instead also create folder folder sample input get following cut image output get,issue,negative,neutral,neutral,neutral,neutral,neutral
1551828924,"Can you provide more information, @orcohen9826 please?

Are you talking about ""https://github.com/spmallick/learnopencv/tree/master/Automatic-Document-Scanner"" or ""https://github.com/spmallick/learnopencv/tree/master/Document-Scanner-Custom-Semantic-Segmentation-using-PyTorch-DeepLabV3""?

Have you looked closer into the blog under ""https://learnopencv.com/automatic-document-scanner-using-opencv/""?

In which step of the different phases do you see differences?

Have you done any changes to the code or the pictures?

Could it be due to the used OS, versions of Python, OpenCV, image-codecs? Can you comment on the used OS, Python, OpenCV, please?
How have you installed your environment, ""natively"", in a container, in a virt-env?

Which inputs - and especially which output do you get?",provide information please talking closer step different phase see done code could due used o python comment used o python please environment natively container especially output get,issue,positive,negative,neutral,neutral,negative,negative
1541487610,"I got it installed with CUDA enabled following someone else's blog but forgot to point the Python to my miniconda python so get no module CV2 and then have to pip install opencv-python into each conda environment I use.  Oh well I'm guess the global install that succeeded is good for C++ development if I ever need to.  One thing I know is that the C++ documentation was better than Python's before version 4 when I took a computational photography class at school.  Anyways I'm googling how to change the python for opencv to point to my miniconda python rather than the WSL2 system Python as it is now but if you know how to do this, please let me know.  I'm not even sure if this a solution.  I'm also not sure if pip installing opencv-python in each conda env is going be CUDA enabled.nn

Get Outlook for Android<https://aka.ms/AAb9ysg>
________________________________
From: Markus Broghammer ***@***.***>
Sent: Wednesday, May 10, 2023 4:10:59 PM
To: spmallick/learnopencv ***@***.***>
Cc: Kim, Nobutaka ***@***.***>; Comment ***@***.***>
Subject: Re: [spmallick/learnopencv] Update OpenCV 4 source installation Ubuntu blog. (#559)


Have you tried following the blog referenced above and have encountered problems? Which?

What environment (in WSL2) do you look for (like you want or have to build OpenCV from source due to configs, changes, patches; using OpenCV under Python3 as well as under C++)??

â€”
Reply to this email directly, view it on GitHub<https://github.com/spmallick/learnopencv/pull/559#issuecomment-1541467323>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGAFZKNP45CDNHJIIZKSUXLXFM5QHANCNFSM4ZKQHPRQ>.
You are receiving this because you commented.Message ID: ***@***.***>
",got following someone else forgot point python python get module pip install environment use oh well guess global install good development ever need one thing know documentation better python version took computational photography class school anyways change python point python rather system python know please let know even sure solution also sure pip going get outlook android sent may kim comment subject update source installation tried following environment look like want build source due python well reply directly view id,issue,positive,positive,positive,positive,positive,positive
1541467323,"Have you tried following the blog referenced above and have encountered problems? Which?

What environment (in WSL2) do you look for (like you want or have to build OpenCV from source due to configs, changes, patches; using OpenCV under Python3 as well as under C++)??",tried following environment look like want build source due python well,issue,positive,negative,neutral,neutral,negative,negative
1541357517,What about for Ubuntu 22.04 WSL2?  What tutorial can I follow to have OpenCV installed so I can use both C++ and Python3?,tutorial follow use python,issue,negative,neutral,neutral,neutral,neutral,neutral
1538474130,Hi @ brmarkus appreciate the fast response. I also figured out it was a CWD issue. Instead of ../data/stereo_rectify_maps.xml I just needed a direct path data/stereo_rectify_maps.xml. ,hi appreciate fast response also figured issue instead direct path,issue,negative,positive,positive,positive,positive,positive
1538464003,"Can you check if you have the file locale ""somewhere"" below the repo's root folder?

@ZalvinZ can you confirm it is about this file of this project:

https://github.com/spmallick/learnopencv/tree/bfa948fff83c80a9e6e5885410098060f196a1c4/Depth-Perception-Using-Stereo-Camera/data
",check file locale somewhere root folder confirm file project,issue,negative,neutral,neutral,neutral,neutral,neutral
1538255147,Hi @aaronlsmiles I'm having the same issue. How did you end up solving this issue?,hi issue end issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1495897734,"heiio,is there any MPI training model.




------------------&nbsp;åŽŸå§‹é‚®ä»¶&nbsp;------------------
å‘ä»¶äºº:                                                                                                                        ""spmallick/learnopencv""                                                                                    ***@***.***&gt;;
å‘é€æ—¶é—´:&nbsp;2023å¹´3æœˆ27æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ5:05
***@***.***&gt;;
***@***.******@***.***&gt;;
ä¸»é¢˜:&nbsp;Re: [spmallick/learnopencv] æ±‚è§£ (Issue #809)





 
Which application do you mean?
 
You have stalled OpenCV in version ""4.7.0"" and running under Microsoft Windows?
 How have you installed OpenCV - have you built it from source-code or have you downloaded a pre-built installation package?
 
Which application, which source-code do you use, how do you use it, have you changed anything (using different images, videos, parameters, command-lines)?
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",training model issue application mean version running built installation package application use use anything different reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1486352475,"i met the same problem when i run the python code as following:
_(base) ubuntu@ubuntu-XPS-8930:~/heop_devel_kit/volume/visionanalyticsAI$ python yolov5.py
Traceback (most recent call last):
  File ""yolov5.py"", line 120, in <module>
    net = cv2.dnn.readNet(modelWeights)
cv2.error: OpenCV(4.2.0) /io/opencv/modules/dnn/src/onnx/onnx_importer.cpp:110: error: (-215:Assertion failed) !tensor_pr                                                                                                                                                            oto.raw_data().empty() || !tensor_proto.float_data().empty() || !tensor_proto.double_data().empty() || !tensor_proto.int6                                                                                                                                                            4_data().empty() in function 'getMatFromTensor'_
i solved it when i run the code by
_(base) ubuntu@ubuntu-XPS-8930:~/heop_devel_kit/volume/visionanalyticsAI$ python3.6 yolov5.py
Inference time: 300.82 ms_",met problem run python code following base python recent call last file line module net error assertion function run code base python inference time,issue,negative,negative,negative,negative,negative,negative
1484783362,"In&nbsp;pycharm&nbsp;software,&nbsp;download&nbsp;openpose&nbsp;file,&nbsp;create&nbsp;a&nbsp;new&nbsp;project&nbsp;and&nbsp;copy&nbsp;the&nbsp;running&nbsp;program




------------------&nbsp;åŽŸå§‹é‚®ä»¶&nbsp;------------------
å‘ä»¶äºº:                                                                                                                        ""spmallick/learnopencv""                                                                                    ***@***.***&gt;;
å‘é€æ—¶é—´:&nbsp;2023å¹´3æœˆ27æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ5:05
***@***.***&gt;;
***@***.******@***.***&gt;;
ä¸»é¢˜:&nbsp;Re: [spmallick/learnopencv] æ±‚è§£ (Issue #809)





 
Which application do you mean?
 
You have stalled OpenCV in version ""4.7.0"" and running under Microsoft Windows?
 How have you installed OpenCV - have you built it from source-code or have you downloaded a pre-built installation package?
 
Which application, which source-code do you use, how do you use it, have you changed anything (using different images, videos, parameters, command-lines)?
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",file create new project copy running program issue application mean version running built installation package application use use anything different reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1484775029,"Which application do you mean?

You have stalled OpenCV in version ""4.7.0"" and running under Microsoft Windows?
How have you installed OpenCV - have you built it from source-code or have you downloaded a pre-built installation package?

Which application, which source-code do you use, how do you use it, have you changed anything (using different images, videos, parameters, command-lines)?",application mean version running built installation package application use use anything different,issue,negative,negative,negative,negative,negative,negative
1484763534,"Download&nbsp;the&nbsp;source&nbsp;application&nbsp;on&nbsp;Github&nbsp;and&nbsp;then&nbsp;run&nbsp;it&nbsp;with&nbsp;the&nbsp;above&nbsp;error




------------------&nbsp;åŽŸå§‹é‚®ä»¶&nbsp;------------------
å‘ä»¶äºº:                                                                                                                        ""spmallick/learnopencv""                                                                                    ***@***.***&gt;;
å‘é€æ—¶é—´:&nbsp;2023å¹´3æœˆ27æ—¥(æ˜ŸæœŸä¸€) ä¸‹åˆ4:47
***@***.***&gt;;
***@***.******@***.***&gt;;
ä¸»é¢˜:&nbsp;Re: [spmallick/learnopencv] æ±‚è§£ (Issue #809)





 
Can you provide more information, please?
 Which sample/demo/code have you noticed the mentioned ""cv2.error""? What were you running, how have you used it, which command line, which input, which model have you used?
 What does your environment (HW and SW) look like?
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",source application run error issue provide information please running used command line input model used environment look like reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1484749133,"Can you provide more information, please?
Which sample/demo/code have you noticed the mentioned ""cv2.error""? What were you running, how have you used it, which command line, which input, which model have you used?
What does your environment (HW and SW) look like?",provide information please running used command line input model used environment look like,issue,positive,neutral,neutral,neutral,neutral,neutral
1484480111,"cv2.error: OpenCV(4.7.0) d:\a\opencv-python\opencv-python\opencv\modules\dnn\src\net_impl.hpp:108: error: (-2:Unspecified error) Can't create layer ""nms"" of type ""Nms"" in function 'cv::dnn::dnn4_v20221220::Net::Impl::getLayerInstance'
",error unspecified error ca create layer type function,issue,negative,neutral,neutral,neutral,neutral,neutral
1479056319,"Hi,gopig.

Because of your method does not fit the paraments, so it can not use that method 'cv::estimateAffinePartial2D'

Here are two method to solve the problem.

Firstly, you can use cv2.estimateAffinePartial2D() to instead the old method.
Secondly, you can degrade your OpenCV version.

In my view, i actually adverse your to solve the problem with method1. 

I wish it can help u.

Lil louis -2023.3.22 China",hi method fit use method two method solve problem firstly use instead old method secondly degrade version view actually adverse solve problem method wish help china,issue,negative,positive,positive,positive,positive,positive
1455316609,"We are investigating this kind of issues, and your answer will be of great help to our work. Can you take a look? Thank you in advance! @Dovyski @zubairahmed-ai @najlepsiwebdesigner ",investigating kind answer great help work take look thank advance,issue,positive,positive,positive,positive,positive,positive
1427733977,"Can you provide more details - for allowing to reproduce the behavior?
Which sample are you referring to, how have you prepared your environment (which versions of Python/C/C++/TensorFlow, etc, which installations, which operating-system, which command-line, which source-code, which hardware, running the application natively/in virtualenv/in container)?
Have you applied local changes, using your own input (picture/video/camera)?",provide reproduce behavior sample prepared environment hardware running application container applied local input,issue,negative,neutral,neutral,neutral,neutral,neutral
1406241783,"Dear Markus

Thanks for keeping the line warm. I am sorry that I have not had the time to follow up and test (exams this and the coming week).

I will, and keep you posted on how it goes, and if I have more questions.

Enjoy your weekend

Cheers
Hans

From: Markus Broghammer ***@***.***>
Reply to: spmallick/learnopencv ***@***.***>
Date: Friday, 27 January 2023 at 08.58
To: spmallick/learnopencv ***@***.***>
Cc: Hans Skov-Petersen ***@***.***>, Author ***@***.***>
Subject: Re: [spmallick/learnopencv] Morph intermediate images (Issue #794)


Any open questions left?
Feel free to close this issue.

â€”
Reply to this email directly, view it on GitHub<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fspmallick%2Flearnopencv%2Fissues%2F794%23issuecomment-1406141226&data=05%7C01%7Chsp%40ign.ku.dk%7C9e36c2f9dd624cce6fc308db003c48e0%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638104031138659935%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=pBbDicHHinxjKEGSIF%2BzAs%2BExqcIdM22sVftfPWUyak%3D&reserved=0>, or unsubscribe<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAAE2XBIPTA7FP5R44AN3TM3WUN52NANCNFSM6AAAAAAUE4WRSI&data=05%7C01%7Chsp%40ign.ku.dk%7C9e36c2f9dd624cce6fc308db003c48e0%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638104031138659935%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Zn6Ds1UW7SPV9Vzu6zAsjK7XU6P6kGP%2F7ogCwSxKFnE%3D&reserved=0>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",dear thanks keeping line warm sorry time follow test coming week keep posted go enjoy weekend reply date author subject morph intermediate issue open left feel free close issue reply directly view id,issue,positive,positive,positive,positive,positive,positive
1406141226,"Any open questions left?
Feel free to close this issue.",open left feel free close issue,issue,positive,positive,positive,positive,positive,positive
1403466746,"You mean e.g. EXIF data (like GPS, longitude or latitude) in JPGs of TIFF files?

After `cv2.imread()` you get a matrix with the ""raw data"" only, decompressed raw pixel data, without any metadata.

But look into e.g. ""https://stackoverflow.com/questions/56699941/how-can-i-insert-exif-other-metadata-into-a-jpeg-stored-in-a-memory-buffer"" for how to extract and add-back EXIF using additional packages (in Python).",mean data like longitude latitude tiff get matrix raw data raw data without look extract additional python,issue,negative,negative,negative,negative,negative,negative
1403416553,"great. Thanks. . I am looking forward resting.

BTW Are geoheaders maintained in jpg's and tif files?

/H

Sent from Outlook for Android<https://aka.ms/AAb9ysg>
________________________________
From: Markus Broghammer ***@***.***>
Sent: Wednesday, January 25, 2023 11:27:45 AM
To: spmallick/learnopencv ***@***.***>
Cc: Hans Skov-Petersen ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] Morph intermediate images (Issue #794)


With a slider/trackbar:
[image]<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fuser-images.githubusercontent.com%2F29976962%2F214539582-ed2cca9f-4b0f-41a5-b7a5-3cc1ed83b47b.png&data=05%7C01%7Chsp%40ign.ku.dk%7Cb26847fd48494d337d3a08dafebecd39%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102392684323462%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=m7OnUJcFd%2BD6aJIsHvWuooacDhPYhW4v27%2BnYCHMTr4%3D&reserved=0>
[image]<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fuser-images.githubusercontent.com%2F29976962%2F214539632-afc91945-5e3b-4b66-ace6-347841b820cb.png&data=05%7C01%7Chsp%40ign.ku.dk%7Cb26847fd48494d337d3a08dafebecd39%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102392684323462%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oSKSu8GIHBzA6yApjrsgklqYgm4dzLr2NADOdTFOz4k%3D&reserved=0>
[image]<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fuser-images.githubusercontent.com%2F29976962%2F214539688-ed12bf63-d6bf-4057-84f1-9b73ca79f606.png&data=05%7C01%7Chsp%40ign.ku.dk%7Cb26847fd48494d337d3a08dafebecd39%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102392684323462%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=XZNCl18M68%2Bz2W6h01z%2FAUekpuXroFDX4zHZVHvRxck%3D&reserved=0>

â€”
Reply to this email directly, view it on GitHub<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fspmallick%2Flearnopencv%2Fissues%2F794%23issuecomment-1403394806&data=05%7C01%7Chsp%40ign.ku.dk%7Cb26847fd48494d337d3a08dafebecd39%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102392684323462%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=YrpcoSRj9QA4k5fb2YGN0MKIBwYGjckrRu3E%2BiHmKXg%3D&reserved=0>, or unsubscribe<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAAE2XBO2VVHRAWWTSQU6NO3WUD52DANCNFSM6AAAAAAUE4WRSI&data=05%7C01%7Chsp%40ign.ku.dk%7Cb26847fd48494d337d3a08dafebecd39%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102392684323462%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=EEb19Op6ug%2BlpRvsNp55%2FPK%2BSsd3R%2Fkcoing3W2mKew%3D&reserved=0>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",great thanks looking forward resting sent outlook android sent author subject morph intermediate issue image image image reply directly view id,issue,positive,positive,positive,positive,positive,positive
1403342897,"I certainly will.
Thanks a lot.


Hans Skov-Petersen
Professor i Geoinformatik

KÃ¸benhavns Universitet
Institut for Geovidenskab og Naturforvaltning
Landskabsarkitektur og PlanlÃ¦gning
Rolighedsvej 23
1958 Frederiksberg


DIR 35 33 18 16
MOB 23 82 80 45
***@***.******@***.***>

[Title: SD_Logo]

***@***.***<https://www.facebook.com/universitet> ***@***.*** <https://www.instagram.com/university_of_copenhagen>  ***@***.*** <https://www.linkedin.com/company/university-of-copenhagen>  ***@***.*** <https://twitter.com/koebenhavns_uni>  ***@***.*** <https://www.futurity.org/university/university-of-copenhagen/>  ***@***.*** <https://theconversation.com/institutions/university-of-copenhagen-1186>  ***@***.*** <http://www.ku.dk/>

SÃ¥dan beskytter vi persondata<https://informationssikkerhed.ku.dk/persondatabeskyttelse/privatlivspolitik/>



From: Markus Broghammer ***@***.***>
Sent: 25. januar 2023 10:40
To: spmallick/learnopencv ***@***.***>
Cc: Hans Skov-Petersen ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] Morph intermediate images (Issue #794)


Have a look at the embedded Youtube video, at this time-position: ""https://youtu.be/pqpS6BN0_7k?t=45<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fyoutu.be%2FpqpS6BN0_7k%3Ft%3D45&data=05%7C01%7Chsp%40ign.ku.dk%7C4aa2762dd8b048706bc808dafeb83334%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102364338617244%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=wxsy0M0keRjNhBgvGaZj9%2FIJp%2FSfbMYxBCYiPiatG3k%3D&reserved=0>""
=> ""Change the morphing parameter alpha for animation""
=> referring to equation (2)

â€”
Reply to this email directly, view it on GitHub<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fspmallick%2Flearnopencv%2Fissues%2F794%23issuecomment-1403335210&data=05%7C01%7Chsp%40ign.ku.dk%7C4aa2762dd8b048706bc808dafeb83334%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102364338773465%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=98za67SwBBHP%2BQVkos2JaL%2BH8rflPCGKwGQKS0Q8pAA%3D&reserved=0>, or unsubscribe<https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAAE2XBJZSBSMM3SKOV56YTLWUDYI3ANCNFSM6AAAAAAUE4WRSI&data=05%7C01%7Chsp%40ign.ku.dk%7C4aa2762dd8b048706bc808dafeb83334%7Ca3927f91cda14696af898c9f1ceffa91%7C0%7C0%7C638102364338773465%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=JnKLlG1u1KNGcHI3yJMrGns%2Bh598GLbO7otoXXNKtjI%3D&reserved=0>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",certainly thanks lot professor mob title sent author subject morph intermediate issue look video change parameter alpha animation equation reply directly view id,issue,positive,positive,neutral,neutral,positive,positive
1403335210,"Have a look at the embedded Youtube video, at this time-position: ""https://youtu.be/pqpS6BN0_7k?t=45""
=> ""Change the morphing parameter alpha for animation""
=> referring to equation (2)",look video change parameter alpha animation equation,issue,negative,neutral,neutral,neutral,neutral,neutral
1402013850,"I looked at them all, but it seem (at least to me) that they all result in a single 'final morphed image'.
I am looking for ways to reveal a series of additional, images, in between.",seem least result single image looking way reveal series additional,issue,negative,negative,negative,negative,negative,negative
1401844215,"Are you referring to the sample ""https://github.com/spmallick/learnopencv/tree/master/FaceMorph"" and the blog ""https://learnopencv.com/face-morph-using-opencv-cpp-python/"", and experimented with the referenced equation ""(2)"" under ""https://learnopencv.com/face-morph-using-opencv-cpp-python/#id1540306373"" within the section ""Alpha blend warped images""?",sample experimented equation within section alpha blend warped,issue,negative,neutral,neutral,neutral,neutral,neutral
1375326743,"Can you provide more details about your environment, please?
Which version of this repo do you use, which version of OpenCV do you use? Using OpenCV as pre-built or manually built from source-code?
Which input/picture/video do you use, can you share command-lines you used, please?",provide environment please version use version use manually built use share used please,issue,positive,neutral,neutral,neutral,neutral,neutral
1365549261,"It happened to me when my PC had dependencies issue. For the temporary approach, you would be ok to downgrade torchmetrics==0.6.0. But, you would end up being reinstall the virtual environment in your PC or restart the runtime in Colab to install every package you need for this set up. (i.e.) requirements.txt. Otherwise, other library would be crushed while running the other code.",issue temporary approach would downgrade would end reinstall virtual environment restart install every package need set otherwise library would crushed running code,issue,negative,negative,neutral,neutral,negative,negative
1357115192,"Can you provide any documentation, a blog, a readme, any description, please?",provide documentation description please,issue,negative,neutral,neutral,neutral,neutral,neutral
1314168473,"sorry my bad, thought adding issues would automatically link it to your project I was on - the colorization learningopencv - https://github.com/spmallick/learnopencv/tree/master/Colorization - many of the first links in the getModels.sh don't work anymore..

I have made an update my end.. and confirmed works..

mkdir models
wget https://github.com/mlhubber/colorize/raw/master/data/pts_in_hull.npy -O ./pts_in_hull.npy
wget https://raw.githubusercontent.com/alexellis/faas-colorization/master/function/models/colorization_deploy_v2.prototxt -O ./models/colorization_deploy_v2.prototxt
wget http://eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v2/colorization_release_v2.caffemodel -O ./models/colorization_release_v2.caffemodel
wget http://eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v2/colorization_release_v2_norebal.caffemodel -O ./models/colorization_release_v2_norebal.caffemodel
",sorry bad thought would automatically link project colorization many first link work made update end confirmed work,issue,negative,negative,neutral,neutral,negative,negative
1308087275,"Apologies if my question wasn't clear. I understand that the code tries 9 arguments, what I'm asking is how to combine those parameters that are left and right, so that I will be able to give `projectPoints` 5 arguments.",question clear understand code combine left right able give,issue,negative,positive,positive,positive,positive,positive
1305106629,"The (C++)API ""projectPoints()"" supports max. 8 parameters, but your code tries to use 9 parameters...

See the documentation for different publicly available versions of OpenCV:

https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga1019495a2c8d1743ed5cc23fa0daff8c
https://docs.opencv.org/4.5.0/d9/d0c/group__calib3d.html#ga1019495a2c8d1743ed5cc23fa0daff8c
https://docs.opencv.org/4.6.0/d9/d0c/group__calib3d.html#ga1019495a2c8d1743ed5cc23fa0daff8c

Are you sure you are using the API in the correct way?",code use see documentation different publicly available sure correct way,issue,negative,positive,positive,positive,positive,positive
1302850753,Hey thanks @brmarkus it was an issue with the CWD. Appreciate the help! Cheers ðŸ‘,hey thanks issue appreciate help,issue,positive,positive,positive,positive,positive,positive
1301746189,"Can you try with a clean environment (e.g. on your local machine, using a Python-virtual-env), again?
In your shared Colab I see a few errors (e.g. ""destination path 'learnopencv' already exists and is not an empty directory."", ""tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible"")",try clean environment local machine see destination path already empty directory incompatible,issue,negative,positive,neutral,neutral,positive,positive
1301737836,"I referencing the sample Human Action Recognition using Detectron2 and LSTM, 
and use the the colab notebook: 
https://colab.research.google.com/drive/1mr3wJUeS1mFJVgMoo3TgnyMSmwPtwCvR?usp=sharing 
Thanks
",sample human action recognition use notebook thanks,issue,negative,positive,positive,positive,positive,positive
1301733593,"Which sample, which application are you referencing?
Which environment using which versions of the requirements have you installed?
(the samples in this repo are maintained not so frequently, they can become outdated quickly with the frequent updates of the operating systems, updates of Pytorch, etc.)",sample application environment frequently become outdated quickly frequent operating,issue,negative,negative,neutral,neutral,negative,negative
1298489324,"Can you double-check the current-working-directory CWD, please?
From where you start your application - is the relative path `""../data/stereo_rectify_maps.xml""` still valid?
Do you call your application from within a script - which maybe spawns a new shell? Or your application changes the CWD?",please start application relative path still valid call application within script maybe new shell application,issue,negative,positive,neutral,neutral,positive,positive
1297954724,"Yeah the file exists and I can open it in other tools and read the contents similar to the original file.

In fact the same error is returned when I run the code with the original file (referenced above) and the path as it was in the code.",yeah file open read content similar original file fact error returned run code original file path code,issue,negative,positive,positive,positive,positive,positive
1296611045,"Are you sure the file exists?
If the file exists in the file-system and the relative path is correct (you might be in a different current-working-dir CWD and then the relative path isn't correct anymore: `""../data/stereo_rectify_maps.xml""`) - can you open the file with any other tool?

This is the referenced file:
https://github.com/spmallick/learnopencv/blob/master/Depth-Perception-Using-Stereo-Camera/data/stereo_rectify_maps.xml
I can display it even in the browser:

```
<?xml version=""1.0""?>
<opencv_storage>
<Left_Stereo_Map_x type_id=""opencv-matrix"">
  <rows>480</rows>
  <cols>640</cols>
  <dt>""2s""</dt>
  <data>
    -25 -5 -24 -5 -23 -5 -22 -5 -21 -5 -20 -5 -19 -5 -18 -5 -17 -5 -16
    -5 -15 -5 -14 -5 -13 -5 -12 -5 -11 -5 -10 -5 -9 -5 -8 -5 -7 -6 -6 -6
    -5 -6 -4 -6 -3 -6 -2 -6 -1 -6 0 -6 1 -6 2 -6 3 -6 4 -6 5 -6 6 -6 7
    -6 8 -6 9 -6 10 -6 11 -6 12 -6 13 -6 14 -6 15 -6 16 -6 17 -6 18 -6
    19 -6 20 -6 21 -6 22 -6 23 -6 24 -6 25 -5 26 -5 27 -5 28 -5 29 -5 30
... ...
```
It doesn't look like you would need to have ""git-lfs"" installed locally on your machine as the referenced file is huge (7.5MB?), the file is directly part of the repo.",sure file file relative path correct might different relative path correct open file tool file display even browser data look like would need locally machine file huge file directly part,issue,positive,positive,positive,positive,positive,positive
1292016912,I heard but I did not apply. I tried it and I like it. Thank you. I close.,apply tried like thank close,issue,positive,neutral,neutral,neutral,neutral,neutral
1291899368,"Not sure which sample, which code of this project you are referring to...

Can you provide more information about which code, which version, what you tried so far, which command line parameters, which files/videos/devices are you using?",sure sample code project provide information code version tried far command line,issue,negative,positive,positive,positive,positive,positive
1291508371,"Have you heard, have you tried, are you familiar with OpenVINO and its open-model-zoo? There you can find plenty of more or less complex samples for e.g. object-detection scenarios (which might get minor adaptions for the YoloV7 input's and output's requirements).

@magicsoft75 Anything left otherwise? Feel free to close this issue.",tried familiar find plenty le complex might get minor input output anything left otherwise feel free close issue,issue,positive,positive,neutral,neutral,positive,positive
1290419238,"What have you tried so far?
Which ""Yolov7 repository"" do you mean?
What is ""simple enough"" ;-) ?

Have you tried removing unneeded parts (like removing additional imported modules, remove support for all-files-in-a-directory and just keep the support for e.g. a single image or a single video, remove measurements&statistics, etc.).

I converted some of the YoloV7 models to e.g. ONNX (using e.g. ""python3 export.py ... ... .."") - and then used various OpenVINO samples from the Open-Model-Zoo.",tried far repository mean simple enough tried removing unneeded like removing additional remove support keep support single image single video remove statistic converted python used various,issue,positive,negative,neutral,neutral,negative,negative
1274523429,"A non-const reference parameter, such as an Mat&, can only refer to an ""lvalue"" that is a named variable. You need to allocate the `frame.clone()` to a variable before you pass it to the function.
```c++
	Mat cloned_frame = frame.clone();
	Mat img = post_process( cloned_frame, detections, class_list );
```",reference parameter mat refer variable need allocate variable pas function mat mat,issue,negative,neutral,neutral,neutral,neutral,neutral
1243038761,"Yes, I'm talking about it. Thank you so much @brmarkus !",yes talking thank much,issue,positive,positive,positive,positive,positive,positive
1243024834,"You are talking about this blog-post, aren't you?
https://learnopencv.com/gaze-tracking/

There is no code mentioned in the blog, only papers - and the blog references papers and references to follow-up.
""Products"" as well as ""datasets"" are referenced in the blog post.

You might want to have a look into the sample ""https://docs.openvino.ai/latest/omz_demos_gaze_estimation_demo_cpp.html"" from OpenVINO in the Open Model Zoo.",talking code well post might want look sample open model zoo,issue,negative,neutral,neutral,neutral,neutral,neutral
1243014097,I'm too looking for gaze tracking source code. @SaddamBInSyed If you find it and if possible can you please share it with me.,looking gaze source code find possible please share,issue,positive,neutral,neutral,neutral,neutral,neutral
1240645927,You might want to align with e.g. this recent PullRequest as template: https://github.com/spmallick/learnopencv/pull/740,might want align recent template,issue,negative,neutral,neutral,neutral,neutral,neutral
1240489456,"Can you provide more details, more context, please? Which sample/example, which file (which path, folder, URL)? Have you changed the sample/example-code, how have you used the code (e.g. using command-line parameters)?",provide context please file path folder used code,issue,negative,neutral,neutral,neutral,neutral,neutral
1240293851,"Okay, I will add README and some code descriptions soon... Thank you.",add code soon thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1240229028,"You might want to check other PullRequests of how to get new examples&demos added - like providing a README, description, having a blog-post behind.

Do you have something more in mind than just showing how to use an OpenCV-API-call, like code-examples shown under ""https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html""?",might want check get new demo added like providing description behind something mind showing use like shown,issue,positive,negative,negative,negative,negative,negative
1236538424,"Can you provide more details, please?
From looking into this issue it is not clear which ""getModels.sh"" you are referring to.
Which samples/examples are you looking into, what have you tried so far, what have you installed, do you get any output, any error message?",provide please looking issue clear looking tried far get output error message,issue,negative,positive,neutral,neutral,positive,positive
1232077310,"I have just figured out that the issue is due to my GTX 1660 SUPER
",figured issue due super,issue,positive,positive,positive,positive,positive,positive
1197734405,"Can you try using an absolute path for ""yolo5n.onnx""? Are you sure it is in the ""current working directory CWD""?",try absolute path sure current working directory,issue,negative,positive,positive,positive,positive,positive
1191991800,"Me too :)

```
ValueError                                Traceback (most recent call last)
[<ipython-input-6-0002a54cd2a0>](https://localhost:8080/#) in <module>()
    122         # Process image.
    123         detections = pre_process(frame, net)
--> 124         img = post_process(frame.copy(), detections)
    125 
    126         # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)

[<ipython-input-6-0002a54cd2a0>](https://localhost:8080/#) in post_process(input_image, outputs)
     69 
     70                 # Discard bad detections and continue.
---> 71                 if confidence >= CONFIDENCE_THRESHOLD:
     72                         classes_scores = row[5:]
     73 
```

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",recent call last module process image frame net put efficiency information function overall time inference discard bad continue confidence row truth value array one element ambiguous use,issue,positive,negative,negative,negative,negative,negative
1183098142,I will close this PR and do it separately. Thank you sir.,close separately thank sir,issue,negative,neutral,neutral,neutral,neutral,neutral
1182906339,Still recommend to separate the topics into separate pull-requests.,still recommend separate separate,issue,negative,neutral,neutral,neutral,neutral,neutral
1182888648,"> Then I would suggest you remove all those other files/commits not related to ""Motion and object tracker for a video"". If this your PullRequest would be accepted and merged then all those other resources for the other topics (barcode, page-scanner, etc.) would be taken-over.

Actually, I have made separate folders for each of the projects, even if you merge, everything will be added separately. Thay will not lead to any mixup.",would suggest remove related motion object tracker video would accepted would actually made separate even merge everything added separately lead,issue,negative,neutral,neutral,neutral,neutral,neutral
1182850388,"Then I would suggest you remove all those other files/commits not related to ""Motion and object tracker for a video"".
If this your PullRequest would be accepted and merged then all those other resources for the other topics (barcode, page-scanner, etc.) would be taken-over.",would suggest remove related motion object tracker video would accepted would,issue,negative,neutral,neutral,neutral,neutral,neutral
1182840732,"> Can you provide an overview and description what the ""Motion and object tracker for a video"" is about, please? Are you intending to add topics like ""PageScanner.py"" and ""Barcode detection from an image"" under ""motion and object tracker for a video""...?

""Motion and Object tracker will track the moving objects like, persons in the video file test.avi that is provided. It can be applied to other videos with moving objects as well. 

No I would like to make separate repos for Page Scanner Application and Barcode Detector as they are a different projects/applications of the OpenCV.

If you want any improvements in the pull requests. please suggest.
",provide overview description motion object tracker video please intending add like detection image motion object tracker video motion object tracker track moving like video file provided applied moving well would like make separate page scanner application detector different want pull please suggest,issue,positive,neutral,neutral,neutral,neutral,neutral
1182769221,"Can you provide an overview and description what the ""Motion and object tracker for a video"" is about, please? Are you intending to add topics like ""PageScanner.py"" and ""Barcode detection from an image"" under ""motion and object tracker for a video""...?",provide overview description motion object tracker video please intending add like detection image motion object tracker video,issue,positive,neutral,neutral,neutral,neutral,neutral
1182131414,"Sir/Ma'am, will you mind merging my pull requests? You can suggest me to explain or improvements, much appreciated.",mind pull suggest explain much,issue,negative,positive,positive,positive,positive,positive
1169581546,"I also have the same problem:
`Traceback (most recent call last):
  File ""/Users/abc/PycharmProjects/yolo/yolov5/fps.py"", line 124, in <module>
    img = post_process(frame.copy(), detections)
  File ""/Users/abc/PycharmProjects/yolo/yolov5/fps.py"", line 71, in post_process
    if confidence >= CONFIDENCE_THRESHOLD:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()`

How to fix this .
thanks

",also problem recent call last file line module file line confidence truth value array one element ambiguous use fix thanks,issue,positive,positive,neutral,neutral,positive,positive
1163305669,"The issue is solved finally !!
when testing on single class we should change:
`// Jump to the next column `
`data += 85;`
into 
`// Jump to the next column`
`data += 6;` ",issue finally testing single class change jump next column data jump next column data,issue,negative,negative,neutral,neutral,negative,negative
1162947849,"Maybe you have installed multiple different versions of OpenCV now?
Can you check that the correct version is used and linked (static or dynamic linking), like calling `ldd my_application`?",maybe multiple different check correct version used linked static dynamic linking like calling,issue,positive,positive,positive,positive,positive,positive
1162659463,"As part of the issue ""https://github.com/spmallick/learnopencv/issues/674"" I was able to run the demo successfully, but needed to make sure to use newer version of OpenCV; with the version ""v4.5.5"" it was working for me.",part issue able run successfully make sure use version version working,issue,positive,positive,positive,positive,positive,positive
1162641592,"Hello, I tried the pre-trained model in ONNX format (yolov5s.onnx) that was readily available online. Even with that weight file I am still not getting any detections ",hello tried model format readily available even weight file still getting,issue,negative,positive,positive,positive,positive,positive
1161571483,"i faced a similar issue with c++ sample but instead of giving no detection it gave crazy detections that are not False positives #690 
note that this issue happened only with my custom model that i converted from .pt to .onnx and doesn't happen with the pretrained model on coco that i converted to .onnx 
Any Help ? ",faced similar issue sample instead giving detection gave crazy false note issue custom model converted happen model coco converted help,issue,negative,negative,negative,negative,negative,negative
1160293238,"Yes I used the same code available from this repo under LearnOpenCV. I modified the code to fix bugs that are solved in issues. (for example: Instead of --> `Mat img =  post_process(frame.clone(), detections, class_list);`
I used --> `Mat img = post_process(frame, detections, class_list);)`

I used already available weights ""yolov5s.onnx"", and also used converted weights from ""yolov5s.pt"" to ""yolov5s.onnx"",
but I got the same issue.

And lastly, It is available in python script, --> [https://github.com/spmallick/learnopencv/blob/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/yolov5.py](url)
",yes used code available code fix example instead mat used mat frame used already available also used converted got issue lastly available python script,issue,negative,positive,positive,positive,positive,positive
1160262565,"Do you use an existing sample&demo from this repo under LearnOpenCV? If yes, which? Have you modified existing code?
Have you changed the model ""yolov5s.onnx"", like retrained, or converted?
Is the code you use also available as e.g. Python script, have you tried it, is it working?",use sample yes code model like converted code use also available python script tried working,issue,positive,positive,positive,positive,positive,positive
1159623730,"Conversion completed, but I get arrays of NaN in my final matrix.
:unamused:",conversion get nan final matrix unamused,issue,negative,neutral,neutral,neutral,neutral,neutral
1158582484,"hi @brmarkus 
i trained my custom model on a single class dataset to detect passanger planes using yolov5-master github code and using the following command : `python train.py --data data/pass-plane.yaml --weights yolov5s.pt --img 640 --epochs 230 --batch-size 16 --device 0`
it resulted in best.pt in the runs/train/exp/weights folder which i tested on yolov5-master and it worked very good

i converted best.pt into best.onnx using export.py script : `python export.py --weights best.pt --include onnx --data data/pass-plane.yaml --device 0 --imgsz 640 640
`
i used the samples found in https://github.com/spmallick/learnopencv/tree/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python , without any changes except change the name of the model to 'best.onnx' and the .names file to 'plane.names' the results are as shown below, and both samples have the same parameters

**yolv5.py**

![result](https://user-images.githubusercontent.com/72201377/174247139-77a32603-dd78-4933-8850-bf0366c9bdb0.jpg)

**yolov5.cpp**

![result-cpp](https://user-images.githubusercontent.com/72201377/174247671-c944ffa3-9550-4a72-ac67-0e63f864ac33.jpg)

**yolov5.cpp using yolov5s.onnx converted from yolov5s.pt pre-trained on coco**

![result-cpp](https://user-images.githubusercontent.com/72201377/174248770-e0c03b59-e589-4a25-8170-d86fd19de0da.jpg)

note that i'm using opencv 4.5.5 
",hi trained custom model single class detect code following command python data device folder tested worked good converted script python include data device used found without except change name model file shown result converted coco note,issue,negative,positive,positive,positive,positive,positive
1158473029,"Can you provide any details about your model, how you trained it, how you converted it, examples of input- and output-images? Could you even share your model?
Have you done any changes to the source-code, how have you used it, using which command-line?
Are you sure the C++ sample (which sample, which sub-folder?) performs the Non-Max-Suppression algorithm? Do both, the Python-code and the C++ code use the same command line parameters, maybe one uses default-values for some parameters where the other does not.",provide model trained converted could even share model done used sure sample sample algorithm code use command line maybe one,issue,positive,positive,positive,positive,positive,positive
1133625391,"the solution looks to be here:
https://github.com/pjreddie/darknet/issues/1419

I'm waiting for the training to be complete.
Any idea of the CPU renders time...

Any prebuilt model for this sample, I just want to convert the code.
Where did I put my RTX3090...",solution waiting training complete idea time model sample want convert code put,issue,negative,positive,neutral,neutral,positive,positive
1133618040,"Okey tried again in python this time, and I get the following error:

```bash
./darknet detector train /home/uriel/learnopencv/YOLOv3-Training-Snowman-Detector/darknet.data /home/uriel/learnopencv/YOLOv3-Training-Snowman-Detector/darknet-yolov3.cfg ./darknet53.conv.74 > train.log

layer     filters    size              input                output
    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32  0.299 BFLOPs
    1 conv     64  3 x 3 / 2   416 x 416 x  32   ->   208 x 208 x  64  1.595 BFLOPs
    2 conv     32  1 x 1 / 1   208 x 208 x  64   ->   208 x 208 x  32  0.177 BFLOPs
    3 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64  1.595 BFLOPs
    4 res    1                 208 x 208 x  64   ->   208 x 208 x  64
    5 conv    128  3 x 3 / 2   208 x 208 x  64   ->   104 x 104 x 128  1.595 BFLOPs
    6 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64  0.177 BFLOPs
    7 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128  1.595 BFLOPs
    8 res    5                 104 x 104 x 128   ->   104 x 104 x 128
    9 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64  0.177 BFLOPs
   10 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128  1.595 BFLOPs
   11 res    8                 104 x 104 x 128   ->   104 x 104 x 128
   12 conv    256  3 x 3 / 2   104 x 104 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   13 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   14 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   15 res   12                  52 x  52 x 256   ->    52 x  52 x 256
   16 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   17 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   18 res   15                  52 x  52 x 256   ->    52 x  52 x 256
   19 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   20 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   21 res   18                  52 x  52 x 256   ->    52 x  52 x 256
   22 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   23 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   24 res   21                  52 x  52 x 256   ->    52 x  52 x 256
   25 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   26 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   27 res   24                  52 x  52 x 256   ->    52 x  52 x 256
   28 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   29 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   30 res   27                  52 x  52 x 256   ->    52 x  52 x 256
   31 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   32 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   33 res   30                  52 x  52 x 256   ->    52 x  52 x 256
   34 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128  0.177 BFLOPs
   35 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256  1.595 BFLOPs
   36 res   33                  52 x  52 x 256   ->    52 x  52 x 256
   37 conv    512  3 x 3 / 2    52 x  52 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   38 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   39 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   40 res   37                  26 x  26 x 512   ->    26 x  26 x 512
   41 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   42 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   43 res   40                  26 x  26 x 512   ->    26 x  26 x 512
   44 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   45 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   46 res   43                  26 x  26 x 512   ->    26 x  26 x 512
   47 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   48 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   49 res   46                  26 x  26 x 512   ->    26 x  26 x 512
   50 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   51 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   52 res   49                  26 x  26 x 512   ->    26 x  26 x 512
   53 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   54 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   55 res   52                  26 x  26 x 512   ->    26 x  26 x 512
   56 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   57 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   58 res   55                  26 x  26 x 512   ->    26 x  26 x 512
   59 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   60 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   61 res   58                  26 x  26 x 512   ->    26 x  26 x 512
   62 conv   1024  3 x 3 / 2    26 x  26 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   63 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   64 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   65 res   62                  13 x  13 x1024   ->    13 x  13 x1024
   66 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   67 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   68 res   65                  13 x  13 x1024   ->    13 x  13 x1024
   69 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   70 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   71 res   68                  13 x  13 x1024   ->    13 x  13 x1024
   72 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   73 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   74 res   71                  13 x  13 x1024   ->    13 x  13 x1024
   75 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   76 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   77 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   78 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   79 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512  0.177 BFLOPs
   80 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024  1.595 BFLOPs
   81 conv     18  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x  18  0.006 BFLOPs
   82 yolo
   83 route  79
   84 conv    256  1 x 1 / 1    13 x  13 x 512   ->    13 x  13 x 256  0.044 BFLOPs
   85 upsample            2x    13 x  13 x 256   ->    26 x  26 x 256
   86 route  85 61
   87 conv    256  1 x 1 / 1    26 x  26 x 768   ->    26 x  26 x 256  0.266 BFLOPs
   88 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   89 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   90 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   91 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256  0.177 BFLOPs
   92 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512  1.595 BFLOPs
   93 conv     18  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x  18  0.012 BFLOPs
   94 yolo
   95 route  91
   96 conv    128  1 x 1 / 1    26 x  26 x 256   ->    26 x  26 x 128  0.044 BFLOPs
   97 upsample            4x    26 x  26 x 128   ->   104 x 104 x 128
   98 route  97 11
   99 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs
  100 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs
  101 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs
  102 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs
  103 conv    128  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x 128  0.709 BFLOPs
  104 conv    256  3 x 3 / 1   104 x 104 x 128   ->   104 x 104 x 256  6.380 BFLOPs
  105 conv     18  1 x 1 / 1   104 x 104 x 256   ->   104 x 104 x  18  0.100 BFLOPs
  106 yolo
Loading weights from ./darknet53.conv.74...Done!
Floating point exception
```
Running in a ubuntu WSL 22.04
",tried python time get following error bash detector train layer size input output route route route route loading done floating point exception running,issue,negative,neutral,neutral,neutral,neutral,neutral
1125803192,"Just follow the original example from here:
""https://github.com/spmallick/learnopencv/tree/master/YOLOv3-Training-Snowman-Detector""
which includes downloading a pre-trained model - but then running the training.
After that you have the weights-file locally on your machine.",follow original example model running training locally machine,issue,negative,positive,positive,positive,positive,positive
1124438914,"Since the ""resnet50.onnx"" in the repository is a LFG pointer rather than a real onnx file, you need `git lfs pull` or execute the python script ""pytorch_model.py"" in the same directory before running this CPP program.",since repository pointer rather real file need git pull execute python script directory running program,issue,negative,positive,positive,positive,positive,positive
1114049280,"I have successfully downloaded and compiled darknet on **Windows 11, CUDA 11.6 and cuDNN 8.4** using the simple instructions of darknet readme.
```
CUDA-version: 11060 (11060), cuDNN: 8.4.0, GPU count: 1
OpenCV version: 4.5.5
```
Using the settings described hereinabove, based on the guidance in the Notebook, training was successfully completed:
```
Set -points flag:
 `-points 101` for MS COCO
 `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data)
 `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset

 mean_average_precision (mAP@0.50) = 0.897842
Saving weights to ./checkpoint/yolov4-obj_6000.weights
Saving weights to ./checkpoint/yolov4-obj_last.weights
Saving weights to ./checkpoint/yolov4-obj_final.weights
If you want to train from the beginning, then use flag in the end of training command: -clear
```

It could be that my WSL2/Ubuntu 18.04 having CUDA 10.2 has some issues with darkent that used to get stuck. The underlying Windows 11 training is very suitable. (I am keeping the WSL2/Ubuntu with CUDA 10.2 chDNN 7.6.5 for Tensorflow 14).

So for now, all is good.",successfully simple count version hereinabove based guidance notebook training successfully set flag coco difficult custom map saving saving saving want train beginning use flag end training command could used get stuck underlying training suitable keeping good,issue,positive,positive,positive,positive,positive,positive
1113311228,"General Setup:
```
GPU RTX3070ti
Cuda 11.6
Cudnn 8.4.0
OpenCV 4.5.5
```

So, My model was trained in Google Colab with the Roboflow settings. (https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ) I have one Object class to detect (humans). Neural Network size is changed to 256x256 (before training so i didnt just change it afterwards).  When i trained my Model for the Darknet format (Yolov4, Yolov4-tiny) I could successfully load it into Opencv and use it (Different way of getting the Detection boxes etc) so the model itself or the lack of labeled data cant really be the issue. My Dataset has 15k labeled images. The Trained Yolov5s model was also tested in detect.py from (https://github.com/ultralytics/yolov5).

**CONVERSION:**
https://github.com/ultralytics/yolov5 export.py. 
Command i used:
```
python export.py --weights model.pt --img 256 256 --include onnx
python export.py --weights model.pt --img 256 256 --include onnx --simplify
```
Both commands successfully converted the PyTorch model to ONNX and both gave me the same Output in VS22


**INFERENCE CODE:**
https://github.com/spmallick/learnopencv/blob/master/Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/yolov5.cpp 
I used the Example : ""Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python"" and there i used the C++ Code. 
```
const float INPUT_WIDTH = 256;
const float INPUT_HEIGHT = 256;
```
i loaded my model (yolov5s) and the images i give the neural network are all 256x256 like the neural network input size. blob size is also 256x256. Color format is BGR but i also tried RGB color Format but same issues.
After starting the Code from VS22 in Debug mode i get following errors/warnings:

```
[ INFO:0@0.200] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (726) cv::dnn::dnn4_v20211220::ONNXImporter::populateNet DNN/ONNX: loading ONNX v7 model produced by 'pytorch':1.11.0. Number of nodes = 259, initializers = 213, inputs = 1, outputs = 1
[ INFO:0@0.202] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (642) cv::dnn::dnn4_v20211220::ONNXImporter::parseOperatorSet DNN/ONNX: ONNX opset version = 12
[ INFO:0@0.336] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_208)
[ INFO:0@0.341] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_211)
[ INFO:0@0.342] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_214)
[ INFO:0@0.342] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_217)
[ INFO:0@0.343] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_220)
[ INFO:0@0.348] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_229)
[ INFO:0@0.349] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_232)
[ INFO:0@0.350] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_235)
[ INFO:0@0.350] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_238)
[ INFO:0@0.351] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_241)
[ INFO:0@0.352] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_245)
[ INFO:0@0.352] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_248)
[ INFO:0@0.353] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_252)
[ INFO:0@0.353] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_255)
[ INFO:0@0.355] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_264)
[ INFO:0@0.356] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_267)
[ INFO:0@0.356] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_270)
[ INFO:0@0.357] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_273)
[ INFO:0@0.357] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_276)
[ INFO:0@0.358] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_280)
[ INFO:0@0.359] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_283)
[ INFO:0@0.359] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_287)
[ INFO:0@0.360] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_290)
[ INFO:0@0.361] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_299)
[ INFO:0@0.362] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_302)
[ INFO:0@0.363] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_305)
[ INFO:0@0.368] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_312)
[ INFO:0@0.369] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_315)
[ INFO:0@0.370] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_318)
[ INFO:0@0.371] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_321)
[ INFO:0@0.372] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_329)
[ INFO:0@0.373] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_332)
[ INFO:0@0.375] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_341)
[ INFO:0@0.376] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_344)
[ INFO:0@0.376] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_347)
[ INFO:0@0.378] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_355)
[ INFO:0@0.379] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_358)
[ INFO:0@0.380] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_367)
[ INFO:0@0.381] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_370)
[ INFO:0@0.382] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_373)
[ INFO:0@0.383] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_381)
[ INFO:0@0.384] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_384)
[ INFO:0@0.386] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_388)
[ INFO:0@0.387] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_391)
[ INFO:0@0.387] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_394)
[ INFO:0@0.389] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_402)
[ INFO:0@0.389] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_405)
[ INFO:0@0.390] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_409)
[ INFO:0@0.391] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_412)
[ INFO:0@0.392] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_415)
[ INFO:0@0.393] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(onnx::Mul_423)
[ INFO:0@0.395] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(y)
[ INFO:0@0.401] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(y.3)
[ INFO:0@0.403] global D:\OPENCV\opencv-4.5.5\modules\dnn\src\onnx\onnx_importer.cpp (2891) cv::
![test](https://user-images.githubusercontent.com/52799640/165961834-25f0b611-f73a-48b6-8b5c-5a516f76d41c.jpg)
dnn::dnn4_v20211220::ONNXImporter::parseCustomLayer DNN/ONNX: unknown node type, try using custom handler for node with 1 inputs and 1 outputs: [Sigmoid]:(y.7)
```
If you could test my model with the given image i'd be happy maybe someone knows how to fix my issues: 
https://www.mediafire.com/file/i2o09rl2b2qm8cy/best.onnx/file Yolov5s model onnx format
https://www.mediafire.com/view/45l4kuya07iqkwo/test.jpg/file TestImage",general setup model trained one object class detect neural network size training didnt change afterwards trained model format could successfully load use different way getting detection model lack data cant really issue trained model also tested conversion command used python include python include simplify successfully converted model gave output inference code used example used code float float loaded model give neural network like neural network input size blob size also color format also tried color format starting code mode get following global loading model produced number global version global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global unknown node type try custom handler node sigmoid global test unknown node type try custom handler node sigmoid could test model given image happy maybe someone fix model format,issue,positive,negative,neutral,neutral,negative,negative
1112868358,"Can you provide more details about your model, please? You are based on a YoloV5s model, but retrained it?
Can you describe your code, please?
Do you use the example ""Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python"", or another application?
Have you done any changes or are you using your own application?

Depending on the used code and which APIs are called the input resolution will be upscaled or downscaled to the NN's expected resolution.
If you provide an input picture of 256x256 (and three color-channels) then - depending on which code is used, which APIs are called - it will be upscaled to 640x640 (and three color-channels).
It's important to know whether the model expects the color-channel in RGB or BGR order.

Can you maybe share your model and your code and example input files - and then show the output you get and explain, what you think is wrong?",provide model please based model describe code please use example another application done application depending used code input resolution resolution provide input picture three depending code used three important know whether model order maybe share model code example input show output get explain think wrong,issue,positive,negative,neutral,neutral,negative,negative
1112863575,But it works in the detect.py inference file from yolov5 repo. I tested also simplifying the onnx export with onnx-simplifier but that also didnâ€™t help. Thatâ€™s why Iâ€™m sure itâ€™s Opencv related. On yolov5 repo I also saw people having problems loading an exported model (onnx) into Opencv but they just said that they donâ€™t provide any examples to load it in Opencv dnn framework,work inference file tested also export also help sure related also saw people loading model said provide load framework,issue,positive,positive,positive,positive,positive,positive
1112568199,You might want to create an issue under Â´https://github.com/ultralytics/yolov5Â´ and ask there for explanations.,might want create issue ask,issue,negative,neutral,neutral,neutral,neutral,neutral
1110873759,"Well, it died in the middle on colan with K80 GPU. I changed subdivisions to 32. Forget Colab - no chance to get a GPU for more that 30 minutes.

I am also compiling darknet to 2080 TI by uncommenting the correct row in the Makefile to check again on my 2080.

Got sutck here:
 (next mAP calculation at 3200 iterations) 

 Tensor Cores are used.
 Last accuracy mAP@0.50 = 67.72 %, best = 68.84 % 
 3177: 0.635285, 0.473156 avg loss, 0.001000 rate, 3.053653 seconds, 203328 images, 2.409412 hours left

**Cant get the training completed.** Software is ""hard stuck"" and does not respond to cntl/c.
Any idea what can cause this?
Machine has 64GB and 32 cores and RTX 2080 TI which was 50% of memory use.

Question: is there any log that can show anything?",well middle forget chance get also ti uncommenting correct row check got next map calculation tensor used last accuracy map best loss rate left cant get training hard stuck respond idea cause machine ti memory use question log show anything,issue,positive,positive,positive,positive,positive,positive
1110796395,"I also had to change the line 167 ,,frame.clone()'' to just frame. It worked and i also have Opencv 4.5.4 So this version also runs fine.",also change line frame worked also version also fine,issue,negative,positive,positive,positive,positive,positive
1108909001,"Training still ""dies"" in the middle. I will try it with colab on the larger GPU just to see it training all the way to the end.
I do not have a memory issue when changing to subdivisions=32/64. could be heating, but I saw no indication of this (an I have water cooling on the RTX 2080TI. I see 225W/265W in nvidia-smi).",training still middle try see training way end memory issue could heating saw indication water cooling ti see,issue,negative,neutral,neutral,neutral,neutral,neutral
1108178363,"Sorry!
I was using OpenCV in version 4.5.3 (from an OpenVINO v2021.4.2).
Using a Python virtual-env, now I'm using v4.5.5 and see the Python version ""yolov5.py"" working.

I cloned opencv and opencv_contrib from the branch ""4.5.5"", built it.
And can confirm the C++ variant ""yolov5.cpp"" is working now as well:
![image](https://user-images.githubusercontent.com/29976962/165040461-8f41542b-6774-40c7-861e-3af6932f6de9.png)

But I needed to adapt line 168 to make a separate copy/clone, as the method `post_process()` expects a non-const-reference.",sorry version python see python version working branch built confirm variant working well image adapt line make separate method,issue,negative,negative,negative,negative,negative,negative
1108124583,are you using the latest version of OpenCV? I think the code works if the version is > 4.5.4,latest version think code work version,issue,negative,positive,positive,positive,positive,positive
1108093238,"Are you talking about the sample `Object-Detection-using-YOLOv5-and-OpenCV-DNN-in-CPP-and-Python/yolov5.cpp`?

It did not even compile for me, needed to adapt line 168 to make a separate copy/clone, as the method `post_process()`expects a non-const-reference.

After this I get a runtime-exception in `pre_process()` while `net.forward(outputs, net.getUnconnectedOutLayersNames());`:

```
terminate called after throwing an instance of 'ngraph::NodeValidationFailure'
  what():  Check 'PartialShape::broadcast_merge_into( pshape, node->get_input_partial_shape(i), autob)' failed at core/src/op/util/elementwise_args.cpp:40:
While validating node 'v1::Multiply Multiply_546 (470[0]:f32{1,3,80,80,2}, Constant_545[0]:f32{1,38400,1,1,1}) -> (dynamic?)' with friendly_name 'Multiply_546':
Argument shapes are inconsistent.

```

Can you describe your code-changes, please?
",talking sample even compile adapt line make separate method get terminate throwing instance check node dynamic argument inconsistent describe please,issue,negative,neutral,neutral,neutral,neutral,neutral
1101165762,"Your referenced article says these:

> But it is very easy to find a few point correspondences. For morphing two dissimilar objects, like a catâ€™s face and a humanâ€™s face, we can click on a few points on the two images to establish correspondences and interpolate the results for the rest of the pixels.

As well as using Facial-Landmark-detection:

> I used [dlib](http://dlib.net/) to detect 68 corresponding points. Next, I added four more points ( one on the right hand side ear, one on the neck, and two on the shoulders ). Finally, I added the corners of the image and half way points between those corners as corresponding points as well. Needless to say, one can add a few more points around the head and neck to get even better results, or remove the manually clicked points to get slightly worse ( but fully automatic ) results.

And then, referring to the Delaunay Triangulation article, you call `subdiv.getTriangleList()` and store the list in the file. (or keep it in memory and continue with the morphing).",article easy find point two dissimilar like cat face human face click two establish interpolate rest well used detect corresponding next added four one right hand side ear one neck two finally added image half way corresponding well needle say one add around head neck get even better remove manually get slightly worse fully automatic triangulation article call store list file keep memory continue,issue,positive,positive,neutral,neutral,positive,positive
1100794944,"Hello,
I am trying to morph 2 pictures from my own,
I read the blog post[Face Morph Using OpenCV â€” C++ / Python](https://learnopencv.com/face-morph-using-opencv-cpp-python/).
Howerver, I don't know how to get the tri.txt by performing [Delaunay Triangulation](https://learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/).
I appreciated for your help.",hello trying morph read post face morph python know get triangulation help,issue,negative,neutral,neutral,neutral,neutral,neutral
1096159423,"These errors are all because memory keeps running out, try increasing the subdivisions more.",memory running try increasing,issue,negative,neutral,neutral,neutral,neutral,neutral
1088605584,"Can you provide more details, please? Which link do you mean, where have you found the reference, which (sub-)folder, which sample?
Do you get an error when trying to open the link, which error?",provide please link mean found reference folder sample get error trying open link error,issue,negative,negative,negative,negative,negative,negative
1087857038,"After 6h it is still at:
```
 Tensor Cores are disabled until the first 3000 iterations are reached.
 (next mAP calculation at 2900 iterations) 
 2820: 0.278743, 0.474088 avg loss, 0.001000 rate, 2.213002 seconds, 180480 images, 2.936276 hours left
Resizing, random_coef = 1.40 

 416 x 416 
 try to allocate additional workspace_size = 82.58 MB 
 CUDA allocate done! 
```
no further progress can be seen.

I rebooted, changed subdivisions=32 and it ran for some time and got stuck again:
```
Tensor Cores are disabled until the first 3000 iterations are reached.

 544: 1.236107, 1.296011 avg loss, 0.000088 rate, 2.285857 seconds, 34816 images, 3.919907 hours left
```

I rebooted, cleaned ./darknet/checkpoint. It got stuck again at 3608 with loss=0.4.",still tensor disabled first next map calculation loss rate left try allocate additional allocate done progress seen ran time got stuck tensor disabled first loss rate left got stuck,issue,negative,positive,neutral,neutral,positive,positive
1087413993,"Increasing the value in ./darknet/cfg/yolov4-obj.cfg file to subdivisions=32 works ! It is running now.
GPU memory use is now down to `6GB (from 10.5GB with subdivisions=16.
GPU utilization is now 50-80%

```
Every 2.0s: nvidia-smi               MICKEY-2080TI-wsl: Mon Apr  4 14:04:41 2022
Mon Apr  4 14:04:42 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 512.15       CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:0A:00.0  On |                  N/A |
| 55%   68C    P2   250W / 260W |   6104MiB / 11264MiB |     78%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     11842      C   /darknet                        N/A      |
|    0   N/A  N/A     32718      C   /python3.7                      N/A      |
+-----------------------------------------------------------------------------+
```",increasing value file work running memory use utilization every mon mon driver version version name volatile fan temp compute mig mib mib default type process name memory id id usage,issue,positive,neutral,neutral,neutral,neutral,neutral
1087250951,"I have cuda 10.0 and 11.0. will check reducing subdivisions as suggested.
________________________________
From: sanyam83 ***@***.***>
Sent: Monday, April 4, 2022 10:18:26 AM
To: spmallick/learnopencv ***@***.***>
Cc: tadam98 ***@***.***>; Author ***@***.***>
Subject: Re: [spmallick/learnopencv] learnopencv/ALPR/ is not working (Issue #658)


For this error :

  1.  Check if CUDA and cuDNN are of the required versions. According to darknet<https://github.com/AlexeyAB/darknet> requirements, CUDA >= 10.2 and cuDNN >= 8.0.2 should be installed.
  2.  Try reducing subdivisions in yolov4-obj.cfg file to 32 or 64.

â€”
Reply to this email directly, view it on GitHub<https://github.com/spmallick/learnopencv/issues/658#issuecomment-1087202036>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFBMCTYWZ7BI5SEIVFTPS23VDKJUFANCNFSM5RMC43WQ>.
You are receiving this because you authored the thread.Message ID: ***@***.***>
",check reducing sent author subject working issue error check according try reducing file reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1087202036,"For this error :

1. Check if CUDA and cuDNN are of the required versions. According to [darknet](https://github.com/AlexeyAB/darknet) requirements, CUDA >= 10.2 and cuDNN >= 8.0.2 should be installed.
2. Try increasing `subdivisions ` value in yolov4-obj.cfg file to 32 or 64.",error check according try increasing value file,issue,negative,neutral,neutral,neutral,neutral,neutral
1087125274,"Can you try with a local JupyterNotebook - and add your ""secret"" to ""app.py"" and try again?

> app = Flask(__name__)
> UPLOAD_FOLDER = './'
> app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
> app.secret_key = ""**secret key**""
",try local add secret try flask secret key,issue,negative,negative,negative,negative,negative,negative
1086942355,"Hi,

OK, I followed [https://learnopencv.com/automatic-license-plate-recognition-using-deep-learning/?ck_subscriber_id=452195442](url)

And decided to try training.
Initial steps are fine.

Then, under Dataset, after ""import math"" three more imports are needed.
```
import math
import os
import matplotlib.image as image 
import matplotlib.pyplot as plt
```

Make sure the cdw is darknet
`%cd darknet`
Now the images show nice in the plt.

Under ""Training"" you skipped the location for data.names.
Also the contents are wrong:
# place in darknet/data
```
classes = 1
train = ./darknet/data/obj/train.txt
valid = ./darknet/data/obj/test.txt
names = /content/gdrive/MyDrive/yolov4-darknet/darknet/data/obj.names
backup = ./checkpoint
```
# Change to:
```
classes = 1
train = ./data/obj/train.txt
valid = ./data/obj/test.txt
names = ./data/obj.names
backup = ./checkpoint
```
 You had remains of colab and the path should not have ""darknet"" in it.

# correct train.txt
the downloaded train.txt is for colab and has oto be updated from:
/content/gdrive/My Drive/yolov4-darknet/darknet/data/obj/train/3fe012d7a03f9927.jpg
to:
./data/obj/train/3fe012d7a03f9927.jpg

# checkdir
You fogot to mention that ""checkdir"" should be created under darknet
`!mkdir checkpoint`

# yolo4.conv.137
You forgot to mention that yolov4.conv.137 should be under ./darknet

Now the traing command works:
`!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map`

It executed fine and then gave the message below: "" Error: cuDNN isn&apos;t found FWD algo for convolution"" 

<pre> Tensor Cores are disabled until the first 3000 iterations are reached.
 (next mAP calculation at 1000 iterations) 
 10: -nan, -nan avg loss, 0.000000 rate, 9.552273 seconds, 640 images, 6.814552 hours left
Resizing, random_coef = 1.40 

 512 x 512 
 Error: cuDNN isn&apos;t found FWD algo for convolution.</pre>
 Tensor Cores are disabled until the first 3000 iterations are reached.
 (next mAP calculation at 1000 iterations) 
 10: -nan, -nan avg loss, 0.000000 rate, 9.552273 seconds, 640 images, 6.814552 hours left
Resizing, random_coef = 1.40 

 512 x 512 
 Error: cuDNN isn't found FWD algo for convolution.
[ALPR_inference_my2.ipynb.txt](https://github.com/spmallick/learnopencv/files/8405395/ALPR_inference_my2.ipynb.txt)

I have checked cudnn8 with the nvidia procedure:
```
cd cudnn_samples_v8
cd mnistCUDNN
make clean && make
./mnistCUDNN
```
Executing: mnistCUDNN
cudnnGetVersion() : 8303 , CUDNN_VERSION from cudnn.h : 8303 (8.3.3)
Host compiler version : GCC 9.4.0

There are 1 CUDA capable devices on your machine :
device 0 : sms 68  Capabilities 7.5, SmClock 1650.0 Mhz, MemSize (Mb) 11263, MemClock 7000.0 Mhz, Ecc=0, boardGroupID=0
Using device 0
Resulting weights from Softmax:
0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 
Result of classification: 1 3 5
Test passed!

# summary
I have followed the procedure for training.
Made some corrections to make it start
Something is not working.
will wait a few hours as it appears to be running, but GPU load is at 1-2%.
Sun Apr  3 23:22:57 2022       
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.60.02    Driver Version: 512.15       CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  On   | 00000000:0A:00.0  On |                  N/A |
| 25%   33C    P8     7W / 260W |  10141MiB / 11264MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      4258      C   /darknet                        N/A      |
|    0   N/A  N/A     32718      C   /python3.7                      N/A      |
+-----------------------------------------------------------------------------+
```
# Will any of these help:
https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in ",hi decided try training initial fine import math three import math import o import image import make sure show nice training location also content wrong place class train valid backup change class train valid backup remains path correct mention forgot mention command work detector train executed fine gave message error found convolution tensor disabled first next map calculation loss rate left error found tensor disabled first next map calculation loss rate left error found convolution checked procedure make clean make host compiler version capable machine device device resulting result classification test summary procedure training made make start something working wait running load sun driver version version name volatile fan temp compute mig mib mib default type process name memory id id usage help,issue,negative,positive,positive,positive,positive,positive
1086871995,"I am also having the exact same issue as described above with the same error ERR_Ngrok_6022. I tried to restart the runtime after completing the download and authtoken with Ngrok. And I also tried to run this on MS Edge and Google Chrome without any success.

Any help with this is much appreciated. ",also exact issue error tried restart also tried run edge chrome without success help much,issue,negative,positive,positive,positive,positive,positive
1081427950,"If you are downloading the code from here, you need to set paths accordingly like `./License-plate-detection/darknet/` and the darknet folder under this is the right one. Otherwise, if cloning the darknet and other codes like shown in the notebook or the [blog post](https://learnopencv.com/automatic-license-plate-recognition-using-deep-learning), you will not face any errors.",code need set accordingly like folder right one otherwise like shown notebook post face,issue,positive,positive,positive,positive,positive,positive
1081061480,"Hi, 

You have removed:
```
from google.colab import drive
drive.mount('/content/gdrive')
```
So I guess it is planned to run on my local GPU-Ubuntu-18.04.
I downloaded the complete folder of https://github.com/spmallick/learnopencv/tree/master/ALPR to my local GPU-Ubuntu-18.04.
Started my conda environment that has what is needed (including the requirememts.txt).
With the new ALPR_inference.ipynb the first 7 steps work as documented.
Step [8], first step of the Detector section fails.

%cd ./darknet **fails**.
There is a darknet folder under ./License-plate-detection but I do not think it is the right one.

(Just to be sure, I did all the steps on colab. Same failure.)
I am also wondering about the first OCR step of:
`%cd ../`
which on colab changes the cwd to ""/content"" which is **very** unusual.",hi removed import drive guess run local complete folder local environment new first work step first step detector section folder think right one sure failure also wondering first step unusual,issue,negative,positive,positive,positive,positive,positive
1078868504,"Hello,
The issue is rectified now and other errors are also rectified, please refer to the notebooks again.
In your case, the folder name ""tools"" is clashing with another folder with the same name, Hence the error. Try renaming the folder, you will be able to successfully import then.

For example - After renaming the folder,  
`from tools_deepsort import generate_detections as gdet`",hello issue rectified also rectified please refer case folder name another folder name hence error try folder able successfully import example folder import,issue,negative,positive,positive,positive,positive,positive
1078687334,"You might contact ""https://github.com/GilLevi/AgeGenderDeepLearning"" and check ""https://talhassner.github.io/home/publication/2015_CVPR"" for which material was used to train the model. It could mean that the selected data is not representative enough.",might contact check material used train model could mean selected data representative enough,issue,negative,negative,negative,negative,negative,negative
1078681781,"Sounds like gstreamer's ""multifilesrc"" is used underneath, expecting a series of files:
From ""https://gstreamer.freedesktop.org/documentation/multifile/multifilesrc.html?gi-language=c"":

    gst-launch-1.0 multifilesrc location=""img.%04d.png""  ...",like used underneath series,issue,negative,neutral,neutral,neutral,neutral,neutral
1077020555,"Hi @tadam98, I have added a notebook for the same. Please check.",hi added notebook please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1076205622,"Without trying on my own - as I don't have an APPLE available right now - looks like ""__APPLE__"" is not set, is not defined, so going into the ""#else"" branch.

Can you check whether you have the file ""allheaders.h"" somewhere in your file-system?",without trying apple available right like set defined going else branch check whether file somewhere,issue,negative,positive,positive,positive,positive,positive
1063706926,"Cannot comment on the age-network's precision or what material was used for training, whether it used ""representative"" images, including Asian faces of women in different ages...
Can you try other images showing different men, woman of different age, please?

Random examples:
https://upload.wikimedia.org/wikipedia/commons/2/2d/Angela_Merkel_Juli_2010_-_3zu4.jpg
https://upload.wikimedia.org/wikipedia/commons/a/af/Claudia_Schiffer_C%C3%A9sars_1993.jpg",comment precision material used training whether used representative different try showing different men woman different age please random,issue,negative,negative,negative,negative,negative,negative
1063695265,"i used python3.8
opencv 4.5.3.56
i downloaded age_net.caffemodel and  gender_net.caffemodel and then putted under AgeGender
else did not change anything
then i used python AgeGender.py --input ""C:\\Users\\xxx\\Pictures\\2110021F20422A.jpg""
show this",used python else change anything used python input show,issue,negative,neutral,neutral,neutral,neutral,neutral
1063692104,"Excuse me, can you rephrase your question, please?
Can you describe what you see, what you have expected instead?
Which application do you use, how have you called it, which parameter have you used, have you changed something, do you use the same NN-model underneath?",excuse rephrase question please describe see instead application use parameter used something use underneath,issue,negative,negative,neutral,neutral,negative,negative
1037048254," I saw your article in website:[https://learnopencv.com/optical-flow-in-opencv/#disqus_thread]
![DenseOpticalFlow](https://user-images.githubusercontent.com/66824173/153702254-b4ce20f3-c7f5-4f96-bc16-d49ceb291368.jpg)
, there is a special image in the part of algorithm visualization of Dense Optical Flow, which used lines to draw optical flow. I don't know whether can you see this image or not. And the code in your personal website can not get this image. can you answer my question? Thank you!",saw article special image part algorithm visualization dense optical flow used draw optical flow know whether see image code personal get image answer question thank,issue,positive,positive,positive,positive,positive,positive
1028816952,"I had the same problem. It was because I built it with the wrong CC indeed. However, I was also missing this:

`CUDA_GENERATION=Auto`

So my whole command is

```
cmake -D CMAKE_BUILD_TYPE=RELEASE \
-D CMAKE_INSTALL_PREFIX=/usr/local \
-D WITH_TBB=ON \
-D ENABLE_FAST_MATH=1 \
-D CUDA_FAST_MATH=1 \
-D CUDA_GENERATION=AUTO \
-D WITH_CUBLAS=1 \
-D WITH_CUDA=ON \
-D BUILD_opencv_cudacodec=OFF \
-D WITH_CUDNN=ON \
-D OPENCV_DNN_CUDA=ON \
-D CUDA_ARCH_BIN=8.6 \
-D CUDA_GENERATION=Auto \
-D WITH_V4L=ON \
-D WITH_QT=OFF \
-D WITH_OPENGL=ON \
-D WITH_GSTREAMER=ON \
-D OPENCV_GENERATE_PKGCONFIG=ON \
-D OPENCV_PC_FILE_NAME=opencv.pc \
-D OPENCV_ENABLE_NONFREE=ON \
-D OPENCV_EXTRA_MODULES_PATH=../opencv_contrib-4.x/modules ../opencv-4.x \
-D INSTALL_PYTHON_EXAMPLES=OFF \
-D INSTALL_C_EXAMPLES=OFF \
-D BUILD_EXAMPLES=OFF ..
```

I know the issue is marked to be closed but I figure this could help someone who had the same problem as I did :)

Also remember to `rm -rf *` in `build` directory before running the conf and build again just to make sure everything goes correctly.",problem built wrong indeed however also missing whole command know issue marked closed figure could help someone problem also remember build directory running build make sure everything go correctly,issue,negative,positive,neutral,neutral,positive,positive
1006079933,"What did work for me:
```
git clone --recursive https://github.com/andrewssobral/bgslibrary.git
cd bgslibrary
OpenCV_DIR=../opencv/build pip install .
```",work git clone recursive pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
997085954,"This is perhaps happening because the corner detector was not able to track the keypoints (corners) in the new image. Hence, p1 came out to be None. You should handle this case by using try/Except.",perhaps happening corner detector able track new image hence came none handle case,issue,negative,positive,positive,positive,positive,positive
986518825,"Are you referring to a specific blog, can you share the URL, please?
Or do you have a question to a specific demo application, can you share the details, please, like file-name, folder-name?
Are you using head-revision of this repo?
What have you done so far, do you get error- or warning-messages?",specific share please question specific application share please like done far get,issue,positive,positive,neutral,neutral,positive,positive
985283025,"Greetings,
This is the pull request with Automatic Document Scanner. 
Regards",pull request automatic document scanner,issue,negative,neutral,neutral,neutral,neutral,neutral
954574335,My problem solved by reducing the size of the input video.. ,problem reducing size input video,issue,negative,neutral,neutral,neutral,neutral,neutral
952663237,"There is a "" blog post "" mentioned, pointing to ""https://learnopencv.com/face-morph-using-opencv-cpp-python/"".
In the section ""1. Find Point Correspondences using Facial Feature Detection"" the following is mentioned:

> I used dlib to detect 68 corresponding points. Next, I added four more points ( one on the right hand side ear, one on the neck, and two on the shoulders ). Finally, I added the corners of the image and half way points between those corners as corresponding points as well.

This results in a list of 80 coordinates.
use these 80 coordinates and write it into a file.

Following the mentioned blog also mentions another set of 149 points - which is expected by the sample-code in a file called ""tri.txt"".",post pointing section find point facial feature detection following used detect corresponding next added four one right hand side ear one neck two finally added image half way corresponding well list use write file following also another set file,issue,positive,positive,neutral,neutral,positive,positive
951569305,"Can you provide more details and pointers about which sample and which problem you are talking about? What have you tried so far? Were you following a specific post, specific instructions?",provide sample problem talking tried far following specific post specific,issue,negative,positive,neutral,neutral,positive,positive
949083726,Would be great to see a master license (MIT?) applied to the whole repo to clear this up.,would great see master license applied whole clear,issue,positive,positive,positive,positive,positive,positive
945066020,"@exowanderer I have moved it into xcode project and I could make it work. If you still need it, I can hand it over :)",project could make work still need hand,issue,negative,neutral,neutral,neutral,neutral,neutral
940626055,"If you check [this](https://learnopencv.com/how-to-use-opencv-dnn-module-with-nvidia-gpu-on-windows/) blog, specifically the last section, you can see how the dnn module speeds up the inference with the help of gpu support.",check specifically last section see module inference help support,issue,positive,neutral,neutral,neutral,neutral,neutral
940156317,"Yes, the problem is OpenCV DNN doesn't work with NVidia GPU. 
I found that out the hard way.

If you have NVidia GPU try deep learning with other platforms, such as TensorFlow.",yes problem work found hard way try deep learning,issue,negative,negative,negative,negative,negative,negative
939918911,"I think the installation error should now be fixed. Ref: https://github.com/opencv/opencv/issues/20706

@vikasgupta-github we can close it",think installation error fixed ref close,issue,negative,positive,neutral,neutral,positive,positive
926042570,"@brmarkus The issue was resolved after I chose smaller dataset of 200 images from CalebA Dataset. Earlier I was using around 2000 images to train but after I reduced the size to 200 images which eventually reduced size of pcaParams.yml, the issue didnt pop up!",issue resolved chose smaller around train reduced size eventually reduced size issue didnt pop,issue,negative,neutral,neutral,neutral,neutral,neutral
926030135,"Can you provide more details, please?
Which code, with demo, which sample were you running into the problem with?
Could you share at least a code-snippet?
Which result specifically did you get?",provide please code sample running problem could share least result specifically get,issue,negative,negative,negative,negative,negative,negative
912245911,"To short,
1. update the resnet50.onnx file by running 'python3 ./pytorch_model.py' in the terminal.
2. change the function named ""parseOnnxModel""
from
`TRTUniquePtr<nvinfer1::INetworkDefinition> network{builder->createNetwork()};`
to
`
const auto explicitBatch = 1U << static_cast<uint32_t>(nvinfer1::NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);
TRTUniquePtr<nvinfer1::INetworkDefinition> network{builder->createNetworkV2(explicitBatch)};
`
3. change the function named ""preprocessImage""
from 
`
auto input_width = dims.d[2];
auto input_height = dims.d[1];
auto channels = dims.d[0];
`
to
`
auto input_width = dims.d[2];
auto input_height = dims.d[3];
auto channels = dims.d[1];
`
4. make it and run
`
$ cmake -DOpenCV_DIR=/workspace/shared_data/opencv/opencv-4.5.1 -DTensorRT_DIR=/workspace/tensorrt ..
$ make -j8
$ ./trt_sample ../resnet50.onnx ../turkish_coffee.jpg
`
checked it on Ubuntu18.04 LTS, CUDA11.1, cuDNN8.1, OpenCV4.5.1 with cuda in nvidia-docker tensorrt20.10 image.",short update file running terminal change function network auto network change function auto auto auto auto auto auto make run make checked image,issue,negative,neutral,neutral,neutral,neutral,neutral
910803660,"Nope, I was never able to solve the issue despite spending 2 weeks on it. The solution proposed above removed the spots from some images but not all. It's some dumb issue.",nope never able solve issue despite spending solution removed dumb issue,issue,negative,negative,negative,negative,negative,negative
910698149,"@EklavyaFCB I realize I am a year late to this thread, but where you ever able to resolve this issue? I have the same problem and the masking technique suggested seems like a bit of a cop-out. I appreciate any insight!",realize year late thread ever able resolve issue problem technique like bit appreciate insight,issue,positive,positive,neutral,neutral,positive,positive
907684628,"> I would like to add a feature that can blur the faces in a picture or a video as it has various use cases and also I will be adding a feature where the blurry images and be deblurred into a clean image regaining the facial details with the help of end-to-end CNN with the help of Keras.
> 
> **Any suggestions would be really helpful :-)**
> 
> ## Deblurring Example
> ![Deblur](https://user-images.githubusercontent.com/78999467/115102584-8fee2c80-9f6b-11eb-8db9-068dc3ab2ff6.png)

Seems a useful case scenario.
All the best.",would like add feature blur picture video various use also feature blurry clean image facial help help would really helpful example useful case scenario best,issue,positive,positive,positive,positive,positive,positive
898237648,"sir i have tried but its showing the same error can you edit the code ? it will be ver helpful for me 
",sir tried showing error edit code helpful,issue,negative,neutral,neutral,neutral,neutral,neutral
898231790,"It could depend on the image content.
It could be that your image requires another stopping criteria - to let the algorithm converge ""later""?
Have you ""visually"" checked your input images ""manually""- is there something strange that requires certain pre-processing (e.g. ""an initial transformation that roughly aligns the images"")?
Or adding consistency-checks to the code to catch ""outliers"".",could depend image content could image another stopping criterion let algorithm converge later visually checked input manually something strange certain initial transformation roughly code catch,issue,negative,positive,neutral,neutral,positive,positive
898227955,"can you tell me what changes should i do in this code 


    
'''

import cv2
import numpy as np

def get_gradient(im) :
    # Calculate the x and y gradients using Sobel operator
    grad_x = cv2.Sobel(im,cv2.CV_32F,1,0,ksize=3)
    grad_y = cv2.Sobel(im,cv2.CV_32F,0,1,ksize=3)
    # Combine the two gradients
    grad = cv2.addWeighted(np.absolute(grad_x), 0.5, np.absolute(grad_y), 0.5, 0)
    return grad


if __name__ == '__main__':
    
    
    # Read 8-bit color image.
    # This is an image in which the three channels are
    # concatenated vertically.
    
    im =  cv2.imread(""images/emir.jpg"", cv2.IMREAD_GRAYSCALE);

    # Find the width and height of the color image
    sz = im.shape
    print sz
    height = int(sz[0] / 3);
    width = sz[1]

    # Extract the three channels from the gray scale image
    # and merge the three channels into one color image
    im_color = np.zeros((height,width,3), dtype=np.uint8 )
    for i in xrange(0,3) :
        im_color[:,:,i] = im[ i * height:(i+1) * height,:]

    # Allocate space for aligned image
    im_aligned = np.zeros((height,width,3), dtype=np.uint8 )

    # The blue and green channels will be aligned to the red channel.
    # So copy the red channel
    im_aligned[:,:,2] = im_color[:,:,2]

    # Define motion model
    warp_mode = cv2.MOTION_HOMOGRAPHY

    # Set the warp matrix to identity.
    if warp_mode == cv2.MOTION_HOMOGRAPHY :
            warp_matrix = np.eye(3, 3, dtype=np.float32)
    else :
            warp_matrix = np.eye(2, 3, dtype=np.float32)

    # Set the stopping criteria for the algorithm.
    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000,  1e-10)

    # Warp the blue and green channels to the red channel
    for i in xrange(0,2) :
        (cc, warp_matrix) = cv2.findTransformECC (get_gradient(im_color[:,:,2]), get_gradient(im_color[:,:,i]),warp_matrix, warp_mode, criteria)
    
        if warp_mode == cv2.MOTION_HOMOGRAPHY :
            # Use Perspective warp when the transformation is a Homography
            im_aligned[:,:,i] = cv2.warpPerspective (im_color[:,:,i], warp_matrix, (width,height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)
        else :
            # Use Affine warp when the transformation is not a Homography
            im_aligned[:,:,i] = cv2.warpAffine(im_color[:,:,i], warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);
        print warp_matrix

    # Show final output
    cv2.imshow(""Color Image"", im_color)
    cv2.imshow(""Aligned Image"", im_aligned)
    cv2.waitKey(0)",tell code import import calculate operator combine two grad return grad read color image image three vertically find width height color image print height width extract three gray scale image merge three one color image height width height height allocate space image height width blue green red channel copy red channel define motion model set warp matrix identity else set stopping criterion algorithm criterion warp blue green red channel criterion use perspective warp transformation homography width height else use affine warp transformation homography width height print show final output color image image,issue,negative,negative,neutral,neutral,negative,negative
898226708,"Please have a look at the API's documentation, e.g. here:
https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga1aa357007eaec11e9ed03500ecbcbe47

> Unlike findHomography and estimateRigidTransform, the function findTransformECC implements an area-based alignment that builds on intensity similarities. In essence, the function updates the initial transformation that roughly aligns the images. If this information is missing, the identity warp (unity matrix) is used as an initialization. Note that if images undergo strong displacements/rotations, an initial transformation that roughly aligns the images is necessary (e.g., a simple euclidean/similarity transform that allows for the images showing the same image content approximately). Use inverse warping in the second image to take an image close to the first one, i.e. use the flag WARP_INVERSE_MAP with warpAffine or warpPerspective. See also the OpenCV sample image_alignment.cpp that demonstrates the use of the function. **_Note that the function throws an exception if algorithm does not converges._**

You might need to add exception-handling to catch this exception and react to it - after-the-fact.
Or you might need to pre-process the images as mentioned above.",please look documentation unlike function alignment intensity essence function initial transformation roughly information missing identity warp unity matrix used note undergo strong initial transformation roughly necessary simple transform showing image content approximately use inverse warping second image take image close first one use flag see also sample use function function exception algorithm might need add catch exception react might need,issue,positive,negative,neutral,neutral,negative,negative
867057308,@huaze555  i am also facing same issue have you fund any solution to this . ,also facing issue fund solution,issue,negative,neutral,neutral,neutral,neutral,neutral
849014437,"@ChetanPatil28  please add requirements.txt and readme too.

Please add the nb to the readme

Refer sovit's and taha's  readme.

",please add please add refer taha,issue,positive,neutral,neutral,neutral,neutral,neutral
841045642,"Can you provide the callstack of the exception, please? What is the console-output?
Which ""getting started with cuda"" do you mean, can you provide a link, please?",provide exception please getting mean provide link please,issue,positive,negative,negative,negative,negative,negative
835716654,"auto input_width = dims.d[2];
auto input_height = dims.d[3];
auto channels = dims.d[1];

A change like above should solve the problem.",auto auto auto change like solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
795051081,"[This link](https://docs.microsoft.com/en-us/windows/security/threat-protection/microsoft-defender-smartscreen/microsoft-defender-smartscreen-overview) explains how the Windows SmartScreen works. Basically, if your app is not signed, you will get this warning screen.",link work basically get warning screen,issue,negative,neutral,neutral,neutral,neutral,neutral
791362659,"I understand because it is relatively new,
of course I trust the site.
Thanks for your swift response
Nickums

On Thu, 4 Mar 2021 at 19:36, Vikas Gupta <notifications@github.com> wrote:

> It shows that warning since the software has not been installed by a large
> number of people yet. It is 'safe' to be installed if you would trust us :)
>
> @xlabd <https://github.com/xlabd> can you share some links which show
> this is not a unique case?
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/555#issuecomment-790875996>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADYVMFITDMTOMSMYQ54OOQTTB7OMRANCNFSM4YTZ4VTQ>
> .
>


-- 
Nick ""Mac"" McElwaine
",understand relatively new course trust site thanks swift response mar wrote warning since large number people yet would trust u share link show unique case thread reply directly view nick mac,issue,positive,positive,positive,positive,positive,positive
790875996,"It shows that warning since the software is not signed ( which costs us). It is 'safe' to be installed if you would trust us :) 

@xlabd can you share some links which show this is not a unique case?",warning since u would trust u share link show unique case,issue,negative,positive,positive,positive,positive,positive
772703257,"Ah, fair enough, I wanted licensing info about https://github.com/spmallick/learnopencv/tree/master/barcode-QRcodeScanner, but it doesn't seem like there are licenses involved with this. ",ah fair enough seem like involved,issue,positive,positive,positive,positive,positive,positive
771618289,"Some samples have their own license information, like (from Google-search):
- https://github.com/spmallick/learnopencv/blob/master/UI-cvui/LICENSE.md
- https://github.com/spmallick/learnopencv/blob/master/Colorization/LICENSE

I found a screenshot of the license shown when installing OpenCV (with the samples):
https://learnopencv.com/installer-license/

But not sure about the ""fallback license"" when just referencing and citing some of the samples not having its own license file...",license information like found license shown sure fallback license license file,issue,positive,positive,positive,positive,positive,positive
768363090,"firstly check all the installed packages if any package is missing then install them and if all packages are installed successfully then make sure that in 
C:\Python\Lib\site-packages\cv2 directory 
there is a file named cv2.cp37 type file with extension .pyd is present, if is not, then install it after installing in the same directory I hope your program 'MultiObjectTracker' will run successfully.",firstly check package missing install successfully make sure directory file type file extension present install directory hope program run successfully,issue,positive,positive,positive,positive,positive,positive
767346291,"> **Hello, I want to test on my own trained model. I changed the string of textGraph and modelWeights and recompile it:**
> 
> String textGraph = ""./mask_rcnn_x/mask_rcnn_x.pbtxt"";
> String modelWeights = ""./mask_rcnn_x/frozen_inference_graph.pb"";]
> 
> **here comes errors:**
> 
> terminate called after throwing an instance of 'cv::Exception'
> what(): OpenCV(4.0.0) /home/wangqianyun/opencv/modules/dnn/src/tensorflow/tf_importer.cpp:535: error: (-2:Unspecified error) Input [FirstStageFeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D/paddings] for node [FirstStageFeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/SpaceToBatchND] not found in function 'getConstBlob'
> 
> Aborted (core dumped)
> 
> **Any help would be highly appreciated!**

Excuse me, Have you solved this problem? How can get the pbtxt files? 
Looking for ward to your reply.",hello want test trained model string recompile string string come terminate throwing instance error unspecified error input node found function aborted core help would highly excuse problem get looking ward reply,issue,negative,negative,neutral,neutral,negative,negative
766654191,"From the OpenCV documentation I can find e.g. ""https://docs.opencv.org/3.4/d8/d77/classcv_1_1MultiTracker.html"", but when changing the OpenCV version in the upper-left drop-down field to v4.5.1 the API documentation can't be resolved...
It works up to version v4.5.0...
https://docs.opencv.org/4.5.0/d8/d77/classcv_1_1MultiTracker.html

The documentation https://docs.opencv.org/4.5.1/d8/d77/classcv_1_1MultiTracker.html leads to

```
Not Found
The requested URL /4.5.1/d8/d77/classcv_1_1MultiTracker.html was not found on this server.
```
",documentation find version field documentation ca resolved work version documentation found found server,issue,negative,neutral,neutral,neutral,neutral,neutral
766640078," 
> Can you provide a bit more information?
> Do you have multiple versions of Python installed? How have you installed them, under which operating-system? Have you installed a binary package or from source-code?
**I installed python3.8 through anaconda, under windows 10 system.**
> How have you started the multi-object-tracker example?
**i enter the directory and run $python multiTracker.py**
> Started with ""python multiTracker.py"" or ""python3 multiTracker.py""?
**I use python multiTracker.py because I only installed python3.8**
> From the OpenCV documentation it looks like ""MultiTracker_create"" is for OpenCV version 3.x only...?
**""MultiTracker_create"" is not available for OpenCV 4? I build opencv 4.5.1 from source** 
",provide bit information multiple python binary package python anaconda system example enter directory run python python python use python python documentation like version available build source,issue,negative,positive,positive,positive,positive,positive
766620155,"Can you provide a bit more information?
Do you have multiple versions of Python installed? How have you installed them, under which operating-system? Have you installed a binary package or from source-code?
How have you started the multi-object-tracker example?
Started with ""python multiTracker.py"" or ""python3 multiTracker.py""?
From the OpenCV documentation it looks like ""MultiTracker_create"" is for OpenCV version 3.x only...?",provide bit information multiple python binary package example python python documentation like version,issue,negative,neutral,neutral,neutral,neutral,neutral
721252494,"I'm getting exactly this error for a small, simple convolutional neural network (no dropout, no max pooling, no batch normalization) after freezing the graph and optimizing it for inference in tensorflow.

I've done this so many different ways I can't even think straight anymore. Is there any reason getTensorContent() would return empty when it shouldn't? I'm completely at a loss. I've spent days on this. It needs to work.",getting exactly error small simple convolutional neural network dropout batch normalization freezing graph inference done many different way ca even think straight reason would return empty completely loss spent day need work,issue,negative,positive,neutral,neutral,positive,positive
720995312,"I'm very sorry, I didn't understand your explanation. My environment is Win10 and opencv is installed in the system, and I consume a lot of CPU when running HandPose, so do I need to modify the video decoder?",sorry understand explanation environment win system consume lot running need modify video,issue,positive,positive,positive,positive,positive,positive
720991744,"Can you provide some description about your environment (SW and HW), please?
Is the video maybe decoded using a SW-decoder because no HW-accelerated video decoding available in HW or no driver installed?
Is the system load high (high CPU-load, high GPU-load) in the background?
Have you build OpenCV on your own from source, or installed it via your OperatingSystem?
Can I assume your OpenCV is using gstreamer as the backend for video decoding? Can you try to decode the video using e.g. a gstreamer command line in a terminal? Do you see the same latency?",provide description environment please video maybe video available driver system load high high high background build source via assume video try decode video command line terminal see latency,issue,negative,positive,positive,positive,positive,positive
719761339,Did you ever get this figured out? I am stuck with the same issue.,ever get figured stuck issue,issue,negative,neutral,neutral,neutral,neutral,neutral
707268400,Hello @vikasgupta-github I confirm the code works fine,hello confirm code work fine,issue,negative,positive,positive,positive,positive,positive
706825291,Hi @lxdv Can you confirm if the code works fine. It has been 4 months since this PR was raised. Please recheck the code and update the PR if required.,hi confirm code work fine since raised please recheck code update,issue,negative,positive,positive,positive,positive,positive
700272595,Added files for the post - Understanding Lens DIstortion.,added post understanding lens distortion,issue,negative,neutral,neutral,neutral,neutral,neutral
698372102,"If you check the OpenCV documentation, e.g. for OpenCV in version v4.4.0 here: ""https://docs.opencv.org/4.4.0/de/daa/group__xphoto.html#ga51a091aa54e26b3546316ce2c1df190b"" the ""namespace"" looks like this:

    retval	=	cv.xphoto.createTonemapDurand(	[, gamma[, contrast[, saturation[, sigma_color[, sigma_space]]]]]	)

Are you referring to old source code, maybe the module/namespace has changed to ""xphoto"" in the meantime?",check documentation version like gamma contrast saturation old source code maybe,issue,negative,positive,neutral,neutral,positive,positive
696629919,"opencv3.4.6
tensorflow1.14.0
 I get this error
error: (-2:Unspecified error) Can't create layer ""feature_fusion/truediv"" of type ""RealDiv"" in function 'getLayerInstance'
how can solve it? thank  you! @vikasgupta-github 
",get error error unspecified error ca create layer type function solve thank,issue,negative,neutral,neutral,neutral,neutral,neutral
689620928,The packages and `GLU.h` are useful if you want to build OpenCV with OpenGL interoperability code. It's not needed in ordinary cases.,useful want build code ordinary,issue,negative,positive,neutral,neutral,positive,positive
680717048,"Can you share with us where you have found the link, which document, which sample, which readme, please?
Have you tried to download from alternative links, e.g.

https://github.com/foss-for-synopsys-dwc-arc-processors/synopsys-caffe-models/blob/master/caffe_models/openpose/caffe_model/pose_iter_440000.caffemodel
?",share u found link document sample please tried alternative link,issue,positive,neutral,neutral,neutral,neutral,neutral
678911557,"Hi @vishwas1234567 
xeus-cling is not your regular CPP compiler. xeus-cling interprets the CPP code. 
You can learn more about xeus-cling [here](https://github.com/jupyter-xeus/xeus-cling).",hi regular compiler code learn,issue,negative,neutral,neutral,neutral,neutral,neutral
678138312,"Can you describe how you have tried to test the ""one euro filter""?
Have you tried to use Kalman filter?",describe tried test one filter tried use filter,issue,negative,neutral,neutral,neutral,neutral,neutral
678137884,Stabilization? Have you tried to use a Kalman filter?,stabilization tried use filter,issue,negative,neutral,neutral,neutral,neutral,neutral
675430638,"I added alternative solution several days ago: https://github.com/spmallick/learnopencv/pull/453. M.b. we need to align the images or use one for both cases?
",added alternative solution several day ago need align use one,issue,negative,neutral,neutral,neutral,neutral,neutral
675343324,"Thank You so much.  Are there any libraries that read QR code faster than
this? My application is to scan a QR code printed in a Mask. But it takes a
lot of time to read that and also I have to keep it near to the camera.
Regards ,
Deepak Radhakrishnan
IoT | Robotics | AI | Aeromodelling | Electrophysiology
www.deepakradhakrishnan.in | 7012899400


On Tue, 18 Aug 2020 at 13:09, Alexander Smorkalov <notifications@github.com>
wrote:

> QRCodeDetector is available in OpenCV since version 4.0 in master branch
> and 3.4.4 in 3.4 branch, including Python bindings. Documentation:
> https://docs.opencv.org/4.4.0/de/dc3/classcv_1_1QRCodeDetector.html.
> Please check OpenCV verison you use with cv.getBuildInformation() call.
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/469#issuecomment-675313552>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AESGEWDJPCEYQ6L5B2UOYBLSBIV4PANCNFSM4P3JL7QA>
> .
>
",thank much read code faster application scan code printed mask lot time read also keep near camera ai electrophysiology tue wrote available since version master branch branch python documentation please check use call thread reply directly view,issue,positive,positive,positive,positive,positive,positive
675338120,"This is a general-purpose docker image with Python 3, CPP, and OpenCV 4.4.0 installed.
Sample code is for the users to check whether the image runs correctly. 
This image will be updated in the [blog post](https://www.learnopencv.com/install-opencv-docker-image-ubuntu-macos-windows/)",docker image python sample code check whether image correctly image post,issue,negative,neutral,neutral,neutral,neutral,neutral
675313552,"`QRCodeDetector` is available in OpenCV since version 4.0 in master branch and 3.4.4 in 3.4 branch, including Python bindings. Documentation: https://docs.opencv.org/4.4.0/de/dc3/classcv_1_1QRCodeDetector.html. Please check OpenCV verison you use with `cv.getBuildInformation()` call.",available since version master branch branch python documentation please check use call,issue,negative,positive,positive,positive,positive,positive
675301033,@ideis Could you add `getModel.sh` or `getModel.py` script to download all required models with one call. It's already done in many places and is very useful for CI and automation.,could add script one call already done many useful,issue,negative,positive,positive,positive,positive,positive
674449292,"@lipi17dpatnaik Hey, could you kindly tell me which version of `dlib` you were using ?",hey could kindly tell version,issue,negative,positive,positive,positive,positive,positive
674250195,"Hey @vikasgupta-github, 
I did the changes as mentioned by you here.
Let me know if this is considerable or requires any more changes.
I'll make another PR with the use of calcHist() and vector instead of simply using arrays and complex calculations.",hey let know considerable make another use vector instead simply complex,issue,negative,negative,neutral,neutral,negative,negative
672886448,"@asmorkalov if this fixes all issues in #150 then please edit the commit message above to add this text:
```
Fixes #150 
```
GitHub will then ___autoclose___ issue #150 when this pull request is merged.",please edit commit message add text issue pull request,issue,positive,neutral,neutral,neutral,neutral,neutral
672877304,It's frame rate of tracker algorithm.,frame rate tracker algorithm,issue,negative,neutral,neutral,neutral,neutral,neutral
672870425,"`blob` is not standard OpenCV image, but tt's array of floating point values prepared for DNN inference. `imshow` cannot show it as it's not image.",blob standard image array floating point prepared inference show image,issue,negative,neutral,neutral,neutral,neutral,neutral
672856382,I just checked both Image and Video cases and both works correctly with OpenCV 4.4.,checked image video work correctly,issue,negative,neutral,neutral,neutral,neutral,neutral
672855996,It looks like the model was not loaded by script. Please download weights files with `getModels.sh` if you use Linux or Mac or using links in Readme.md if you run Windows.,like model loaded script please use mac link run,issue,positive,neutral,neutral,neutral,neutral,neutral
672850789,"`cv.imwrite()` does it in OpenCV. Please ensure that the frame is not empty and data format is uint8, but not float. Documentation: https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce",please ensure frame empty data format float documentation,issue,negative,negative,neutral,neutral,negative,negative
672845443,"Python package provides just pre-built OpenCV with python bindings, but not development files for C++ like CMake configuration files or C/C++ headers. You have to build OpenCV from sources to work with C++ code.",python package python development like configuration build work code,issue,negative,neutral,neutral,neutral,neutral,neutral
672839893,"According to file name the model is designed for input 300x300. You need to downscale the image to expected resolution and apply proper prepossessing or apply the model to sub-images. The second approach allows to find smaller faces, but obviously cannot handle the big ones.",according file name model designed input need image resolution apply proper prepossessing apply model second approach find smaller obviously handle big,issue,negative,neutral,neutral,neutral,neutral,neutral
672837204,"DNN weighs are large and not stored in get repository. Please download them before the code execution. In case if you use Linux or Mac you can run `getModels.sh` script to do it automatically. Please download files manually with link in Readme.md, if you run code on Windows.",large get repository please code execution case use mac run script automatically please manually link run code,issue,positive,positive,positive,positive,positive,positive
672834755,`checkVector` function checks if Mat or vector satisfies the requirements. In your case `points` parameter of `fillConvexPoly` is empty or has wrong dimentions or data type. See docs: https://docs.opencv.org/master/d3/d63/classcv_1_1Mat.html#a167a8e0a3a3d86e84b70e33483af4466,function mat vector case parameter empty wrong data type see,issue,negative,negative,negative,negative,negative,negative
672832678,@malepurakesh  According to the logs you have 2 instances of OpenCV installed: 4.3.0-dev and 4.2.0. The sample code finds the first one and uses it. The first OpenCv instance is build without FFmpeg or camera support that triggers the issue. The simplest way to check your OpenCV version on your application is to call cv::getBuildInformation (cv.getBuildInformation for python). See docs: https://docs.opencv.org/master/db/de0/group__core__utils.html#ga0ae377100bc03ce22322926bba7fdbb5,according sample code first one first instance build without camera support issue way check version application call python see,issue,negative,positive,positive,positive,positive,positive
672827531,It looks like your OpenCV instance is build on other host or for another version of Ubuntu. Please re-build OpenCV to fix the issue.,like instance build host another version please fix issue,issue,positive,neutral,neutral,neutral,neutral,neutral
672712204,"hi ,

i run that comparison of zbar and opencv in python. and there is a line
creating object of QRCodeDetector . There I am getting this error . In mac
os it is running fine. and when I am running it on raspberry pi , I am
getting this error .
Regards ,
Deepak Radhakrishnan
IoT | Robotics | AI | Aeromodelling | Electrophysiology
www.deepakradhakrishnan.in | 7012899400


On Wed, 12 Aug 2020 at 10:21, brmarkus <notifications@github.com> wrote:

> Can you provide more context, please? What is your environment looking
> like? C++ or Python? Do you have OpenCV as well as opencv_contrib
> installed/built? Which file do you see the problem in?
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/469#issuecomment-672571332>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AESGEWBNQVFXT7RXS53NXFLSAINVBANCNFSM4P3JL7QA>
> .
>
",hi run comparison python line object getting error mac o running fine running raspberry pi getting error ai electrophysiology wed wrote provide context please environment looking like python well file see problem thread reply directly view,issue,negative,positive,positive,positive,positive,positive
672571332,"Can you provide more context, please? What is your environment looking like? C++ or Python? Do you have OpenCV as well as opencv_contrib installed/built? Which file do you see the problem in?",provide context please environment looking like python well file see problem,issue,negative,neutral,neutral,neutral,neutral,neutral
671217384,"The file has been renamed. 

The link in the readme is as that of the blog. But since it hasn't been published, it won't be visible to others yet.

There is no GitHub code. Everything was done on the notebook.",file link since wo visible yet code everything done notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
668368021,"j'ai le mÃªme problÃ¨me mais je ne sais pas encore comment le resourdre
     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
  0% 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved
  FutureWarning)
     0/299     13.3G      4.74      4.03         0      8.78        24       576:  62% 20/32 [00:37<00:16,  1.39s/it]Traceback (most recent call last):
  File ""train.py"", line 414, in <module>
    train(hyp)  # train normally
  File ""train.py"", line 264, in train
    pred = model(imgs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/content/drive/My Drive/2020_Julio_Yolo_projet/yolov3/models.py"", line 238, in forward
    return self.forward_once(x)
  File ""/content/drive/My Drive/2020_Julio_Yolo_projet/yolov3/models.py"", line 292, in forward_once
    x = module(x)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py"", line 117, in forward
    input = module(input)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py"", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py"", line 419, in forward
    return self._conv_forward(input, self.weight)
  File ""/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py"", line 416, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.73 GiB total capacity; 13.57 GiB already allocated; 17.88 MiB free; 13.72 GiB reserved in total by PyTorch)
     0/299     13.3G      4.74      4.03         0      8.78        24       576:  62% 20/32 [00:40<00:24,  2.01s/it]",ne encore comment epoch total recent call last file line module train hyp train normally file line train model file line result input file line forward return file line module file line result input file line forward input module input file line result input file line forward return input file line memory tried allocate mib gib total capacity gib already mib free gib reserved total,issue,positive,positive,neutral,neutral,positive,positive
665768087,improper branch name used by me,improper branch name used,issue,negative,neutral,neutral,neutral,neutral,neutral
665673514,"Ugh, the black lip spot is still present when I run the algorithm on different images. It's hard to compile a statistic but it seems like every 2nd picture has the spot. 

I tried changing the value in the `if`-statement in `calculateDelaunayTriangles` but it makes spots appear on another picture if it fixes the current one ...",ugh black lip spot still present run algorithm different hard compile statistic like every picture spot tried value appear another picture current one,issue,negative,negative,neutral,neutral,negative,negative
665058588,"You can use a simple binary masking technique so that wherever there is 0 (black) in the new image, you can directly take the corresponding pixel from the original image (on which you want to morph). Think of it like a bitwise operation.",use simple binary technique wherever black new image directly take corresponding original image want morph think like bitwise operation,issue,positive,positive,neutral,neutral,positive,positive
665056415,"@lipi17dpatnaik Thank you, I'm able to run it and get the same results as mine.

Do you know how to complete the morph i.e. have the face on rest of the body and not on a black background, as given on examples on this post: https://www.learnopencv.com/face-morph-using-opencv-cpp-python/ ",thank able run get mine know complete morph face rest body black background given post,issue,negative,positive,positive,positive,positive,positive
665051963,"@EklavyaFCB please find attached the revised Python code. Change the landmark model path as required.
[OpenCV_Morph.zip](https://github.com/spmallick/learnopencv/files/4988698/OpenCV_Morph.zip)

",please find attached python code change landmark model path,issue,negative,neutral,neutral,neutral,neutral,neutral
665024563,"Ah, changing the if condition in the calculateDelaunayTriangles function to `if(abs(pt[j][0] - points[k][0]) < 0.1 and abs(pt[j][1] - points[k][1]) < 0.5)` like you'd mentioned earlier fixed it !

I don't get what these parameters represent. ",ah condition function like fixed get represent,issue,negative,positive,neutral,neutral,positive,positive
665022672,"@lipi17dpatnaik I get the landmarks points from `dlib` but still get the black spot :sleepy:. What value did you use for  `alpha`? 

![Morphed_Face](https://user-images.githubusercontent.com/11503378/88668020-60984680-d0e2-11ea-9b2c-e99caabd7250.jpg)

Can you please share you code ?

Here is my modified code:

```
def main():
    # Variables
    filename1 = '../../../Data/Facelab_London/neutral_front/Raw/007_03.jpg'
    filename2 = '../../../Data/Facelab_London/neutral_front/Raw/009_03.jpg'
    alpha = 0.5

    # Define window names
    win_delaunay = 'Delaunay Triangulation'
    win_voronoi = 'Voronoi Diagram'

    # Define colors for drawing.
    d_col = (255, 255, 255)
    p_col = (0, 0, 255)

    # Read images
    img1 = cv.imread(filename1)
    img2 = cv.imread(filename2)

    img1_copy = cv.imread(filename1)
    img2_copy = cv.imread(filename2)

    # Read array of corresponding points
    #points1 = readPoints(filename1[:-4] + '.tem')
    #points2 = readPoints(filename2[:-4] + '.tem')

    # Read points using dlib
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')
    
    rects1 = detector(img1, 1)
    rects2 = detector(img2, 1)
    
    points1 = predictor(img1, rects1[0])
    points2 = predictor(img2, rects2[0])

    points1 = face_utils.shape_to_np(points1)
    points2 = face_utils.shape_to_np(points2)

    points = []

    # Compute weighted average point coordinates
    for i in range(0, len(points1)):
        x = (1 - alpha) * points1[i][0] + alpha * points2[i][0]
        y = (1 - alpha) * points1[i][1] + alpha * points2[i][1]
        points.append((x, y))

    # Draw points
    (x, y, w, h) = face_utils.rect_to_bb(rects1[0])
    for (x, y) in points1:
        cv.circle(img1, (x, y), 2, p_col, -1)

    (x, y, w, h) = face_utils.rect_to_bb(rects2[0])
    for (x, y) in points2:
        cv.circle(img2, (x, y), 2, p_col, -1)

    # Allocate space for final output
    imgMorph = np.zeros(img1_copy.shape, dtype=img1_copy.dtype)

    # Rectangle to be used with Subdiv2D
    size = img1_copy.shape
    rect = (0, 0, size[1],  size[0])

    # Create an instance of Subdiv2D
    subdiv = cv.Subdiv2D(rect)

    # Calculate and draw delaunay triangles
    delaunayTri = calculateDelaunayTriangles(rect, subdiv, points, img1_copy, win_delaunay, d_col, draw=False)

    # Allocate space for Voronoi Diagram
    img_voronoi = np.zeros(img1_copy.shape, dtype=img1_copy.dtype)

    # Draw Voronoi diagram
    draw_voronoi(img_voronoi, subdiv)

    # Morph by reading calculated triangles
    for line in delaunayTri:
        x, y, z = line

        x = int(x)
        y = int(y)
        z = int(z)

        t1 = [points1[x], points1[y], points1[z]]
        t2 = [points2[x], points2[y], points2[z]]
        t  = [points[x],  points[y],  points[z]]

        # Morph one triangle at a time.
        morphTriangle(img1_copy, img2_copy, imgMorph, t1, t2, t, alpha)

    # Resize images
    desired_size = (860, 860)
    img1_copyS   = cv.resize(img1_copy,   desired_size)
    img2_copyS   = cv.resize(img2_copy,   desired_size)
    img1S        = cv.resize(img1,        desired_size)
    img2S        = cv.resize(img2,        desired_size)
    img_voronoiS = cv.resize(img_voronoi, desired_size)
    imgMorphS    = cv.resize(imgMorph,    desired_size)

    # Save Images
    cv.imwrite(""Image_1.jpg"", img1S)
    cv.imwrite(""Image_2.jpg"", img2S)
    cv.imwrite(""Image_1_copy.jpg"", img1_copyS)
    cv.imwrite(""Image_2_copy.jpg"", img2_copyS)
    cv.imwrite(""Morphed_Face.jpg"", imgMorphS)
```",get still get black spot sleepy value use alpha please share code code main alpha define window define color drawing read read array corresponding read detector predictor detector detector predictor predictor compute weighted average point range alpha alpha alpha alpha draw allocate space final output rectangle used size rect size size create instance rect calculate draw rect allocate space diagram draw diagram morph reading calculated line line morph one triangle time alpha resize save,issue,positive,negative,neutral,neutral,negative,negative
664493086,"I see, thank you. Perhaps the additional number of facial landmarks conflicts with triangulation in some way ... Could you kindly send the code for extracting the `dlib` landmarks please ?

Also, how would one then put this face back onto the original image, i.e. to obtain the final image (with background, neck, etc) ?",see thank perhaps additional number facial triangulation way could kindly send code please also would one put face back onto original image obtain final image background neck,issue,positive,positive,positive,positive,positive,positive
664475568,"Hi @EklavyaFCB that's correct. After replacing your points with the facial landmarks obtained using 68 point model, the results obtained are perfectly correct. So the issue is not with your code, but it is actually with the landmark points. Please find attached the image obtained after landmark detection.
![116431932_326762335395755_2472149376955306684_n](https://user-images.githubusercontent.com/40713338/88562512-66444c80-d04e-11ea-8059-ca9fe711fed4.jpg)
",hi correct facial point model perfectly correct issue code actually landmark please find attached image landmark detection,issue,positive,positive,positive,positive,positive,positive
664444821,"Sure, thanks for letting me know. Perhaps one should try extracting the facial landmarks through `dlib` and see if that works for some reason. I don't know if the black spots seem are related to the facial landmarks - the code does read in 189 of them from the `.tem` files, but doesn't seem to be able to complete the morph on any 2 pairs of image I give it from this dataset.",sure thanks know perhaps one try facial see work reason know black seem related facial code read seem able complete morph image give,issue,positive,positive,positive,positive,positive,positive
664346569,"Changing `alpha` to 0.8, and the if condition in the calculateDelaunayTriangles function to `if(abs(pt[j][0] - points[k][0]) < 0.1 and abs(pt[j][1] - points[k][1]) < 0.5)` improves the result slightly. The black spot in the lip is still present. Still working on it.

![115804699_311343546897268_5707697926527434264_n](https://user-images.githubusercontent.com/40713338/88537974-2e2c1200-d02c-11ea-8c3c-bf9e06d11371.jpg)
",alpha condition function result slightly black spot lip still present still working,issue,negative,negative,neutral,neutral,negative,negative
663573423,Thanks! I will look into it and get back to you.,thanks look get back,issue,negative,positive,neutral,neutral,positive,positive
663573052,"Hi, sorry was different versions. Here is the definitive one.

I just execute the code below (you'll just have to change the `filename1` and `filename2` variable paths:

```
import numpy as np
import cv2 as cv
import random
import sys


def readPoints(path):
    '''Read points from .tem file'''
    # Create an array of points.
    points = []
    # Read points
    with open(path) as file:
        no_lines = int(file.readline())
        for i, line in enumerate(file):
            if 0 <= i < no_lines:
                x, y = line.split()
                points.append((int(float(x)), int(float(y))))

    return points


def applyAffineTransform(src, srcTri, dstTri, size):
    '''Apply affine transform calculated using srcTri and dstTri to src and output an image of size.'''
    # Given a pair of triangles, find the affine transform.
    warpMat = cv.getAffineTransform(np.float32(srcTri), np.float32(dstTri))

    # Apply the Affine Transform just found to the src image
    dst = cv.warpAffine(src, warpMat, (size[0], size[1]), None,
                        flags=cv.INTER_LINEAR, borderMode=cv.BORDER_REFLECT_101)

    return dst


def morphTriangle(img1, img2, img, t1, t2, t, alpha):
    '''Warps and alpha blends triangular regions from img1 and img2 to img'''
    # Find bounding rectangle for each triangle
    r1 = cv.boundingRect(np.float32([t1]))
    r2 = cv.boundingRect(np.float32([t2]))
    r = cv.boundingRect(np.float32([t]))

    # Offset points by left top corner of the respective rectangles
    t1Rect = []
    t2Rect = []
    tRect = []

    for i in range(0, 3):
        tRect.append(((t[i][0] - r[0]), (t[i][1] - r[1])))
        t1Rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))
        t2Rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))

    # Get mask by filling triangle
    mask = np.zeros((r[3], r[2], 3), dtype=np.float32)
    cv.fillConvexPoly(mask, np.int32(tRect), (1.0, 1.0, 1.0), 16, 0)

    # Apply warpImage to small rectangular patches
    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]
    img2Rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]

    size = (r[2], r[3])
    warpImage1 = applyAffineTransform(img1Rect, t1Rect, tRect, size)
    warpImage2 = applyAffineTransform(img2Rect, t2Rect, tRect, size)

    # Alpha blend rectangular patches
    imgRect = (1.0 - alpha) * warpImage1 + alpha * warpImage2

    # Copy triangular region of the rectangular patch to the output image
    img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1] +
                                              r[3], r[0]:r[0]+r[2]] * (1 - mask) + imgRect * mask


def rect_contains(rect, point):
    '''Check if a point is inside a rectangle'''
    if point[0] < rect[0]:
        return False
    elif point[1] < rect[1]:
        return False
    elif point[0] > rect[2]:
        return False
    elif point[1] > rect[3]:
        return False
    return True


def draw_point(img, p, color):
    '''Draw a point'''
    cv.circle(img, p, 2, color, cv.FILLED, cv.LINE_AA, 0)


def draw_voronoi(img, subdiv):
    '''Draw voronoi diagram'''
    (facets, centers) = subdiv.getVoronoiFacetList([])

    for i in range(0, len(facets)):
        ifacet_arr = []
        for f in facets[i]:
            ifacet_arr.append(f)

        ifacet = np.array(ifacet_arr, np.int)
        color = (random.randint(0, 255), random.randint(
            0, 255), random.randint(0, 255))

        cv.fillConvexPoly(img, ifacet, color, cv.LINE_AA, 0)
        ifacets = np.array([ifacet])
        cv.polylines(img, ifacets, True, (0, 0, 0), 1, cv.LINE_AA, 0)
        cv.circle(img, (centers[i][0], centers[i][1]),
                  3, (0, 0, 0), cv.FILLED, cv.LINE_AA, 0)


def draw_delaunay(img, subdiv, delaunay_color):
    '''Draw delaunay triangles'''
    triangleList = subdiv.getTriangleList()
    size = img.shape
    r = (0, 0, size[1], size[0])

    for t in triangleList:
        pt1 = (t[0], t[1])
        pt2 = (t[2], t[3])
        pt3 = (t[4], t[5])

        if rect_contains(r, pt1) and rect_contains(r, pt2) and rect_contains(r, pt3):
            cv.line(img, pt1, pt2, delaunay_color, 1, cv.LINE_AA, 0)
            cv.line(img, pt2, pt3, delaunay_color, 1, cv.LINE_AA, 0)
            cv.line(img, pt3, pt1, delaunay_color, 1, cv.LINE_AA, 0)


def calculateDelaunayTriangles(rect, subdiv, points, img, win_delaunay, delaunay_color, draw=False):
    '''Calculate delanauy triangle'''

    # Insert points into subdiv
    for p in points:
        subdiv.insert((p[0], p[1]))

    # List of triangles. Each triangle is a list of 3 points (6 numbers)
    triangleList = subdiv.getTriangleList()
    print('triangleList', len(triangleList))

    # Find the indices of triangles in the points array
    delaunayTri = []

    for t in triangleList:
        pt = []
        pt.append((t[0], t[1]))
        pt.append((t[2], t[3]))
        pt.append((t[4], t[5]))

        pt1 = (t[0], t[1])
        pt2 = (t[2], t[3])
        pt3 = (t[4], t[5])

        if rect_contains(rect, pt1) and rect_contains(rect, pt2) and rect_contains(rect, pt3):
            ind = []
            for j in range(0, 3):
                for k in range(0, len(points)):
                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):
                        ind.append(k)

            if len(ind) == 3:
                delaunayTri.append((ind[0], ind[1], ind[2]))

            # Draw lines
            if draw:
                cv.line(img, pt1, pt2, delaunay_color, 1, cv.LINE_AA, 0)
                cv.line(img, pt2, pt3, delaunay_color, 1, cv.LINE_AA, 0)
                cv.line(img, pt3, pt1, delaunay_color, 1, cv.LINE_AA, 0)
                imgS = cv.resize(img, (413, 531))

    return delaunayTri


def main():
    # Variables
    filename1 = '../../../Data/Facelab_London/neutral_front/Raw/007_03.jpg'
    filename2 = '../../../Data/Facelab_London/neutral_front/Raw/009_03.jpg'
    alpha = 0.5

    # Define window names
    win_delaunay = 'Delaunay Triangulation'
    win_voronoi = 'Voronoi Diagram'

    # Define colors for drawing.
    d_col = (255, 255, 255)
    p_col = (0, 0, 255)

    # Read images
    img1 = cv.imread(filename1)
    img2 = cv.imread(filename2)

    img1_copy = cv.imread(filename1)
    img2_copy = cv.imread(filename2)

    # Read array of corresponding points
    points1 = readPoints(filename1[:-4] + '.tem')
    points2 = readPoints(filename2[:-4] + '.tem')
    points = []

    # Compute weighted average point coordinates
    for i in range(0, len(points1)):
        x = (1 - alpha) * points1[i][0] + alpha * points2[i][0]
        y = (1 - alpha) * points1[i][1] + alpha * points2[i][1]
        points.append((x, y))

    # Allocate space for final output
    imgMorph = np.zeros(img1.shape, dtype=img1.dtype)

    # Rectangle to be used with Subdiv2D
    size = img1.shape
    rect = (0, 0, size[1],  size[0])

    # Create an instance of Subdiv2D
    subdiv = cv.Subdiv2D(rect)

    # Calculate and draw delaunay triangles
    delaunayTri = calculateDelaunayTriangles(rect, subdiv, points, img1_copy, win_delaunay, d_col, draw=False)

    # Allocate space for Voronoi Diagram
    img_voronoi = np.zeros(img1.shape, dtype=img1.dtype)

    # Draw Voronoi diagram
    draw_voronoi(img_voronoi, subdiv)

    # Morph by reading calculated triangles
    for line in delaunayTri:
        x, y, z = line

        x = int(x)
        y = int(y)
        z = int(z)

        t1 = [points1[x], points1[y], points1[z]]
        t2 = [points2[x], points2[y], points2[z]]
        t  = [points[x],  points[y],  points[z]]

        # Morph one triangle at a time.
        morphTriangle(img1, img2, imgMorph, t1, t2, t, alpha)

    # Resize images
    desired_size = (860, 860)
    img1_copyS   = cv.resize(img1_copy,   desired_size)
    img2_copyS   = cv.resize(img2_copy,   desired_size)
    img1S        = cv.resize(img1,        desired_size)
    img2S        = cv.resize(img2,        desired_size)
    img_voronoiS = cv.resize(img_voronoi, desired_size)
    imgMorphS    = cv.resize(imgMorph,    desired_size)

    # Save Images
    cv.imwrite(""Image_1.jpg"", img1S)
    cv.imwrite(""Image_2.jpg"", img2S)
    cv.imwrite(""Image_1_copy.jpg"", img1_copyS)
    cv.imwrite(""Image_2_copy.jpg"", img2_copyS)
    cv.imwrite(""Morphed_Face.jpg"", imgMorphS)

if __name__ == ""__main__"":
    main()

```",hi sorry different definitive one execute code change variable import import import random import path file create array read open path file line enumerate file float float return size affine transform calculated output image size given pair find affine transform apply affine transform found image size size none return alpha alpha triangular find bounding rectangle triangle offset left top corner respective range get mask filling triangle mask mask apply small rectangular size size size alpha blend rectangular alpha alpha copy triangular region rectangular patch output image mask mask rect point point inside rectangle point rect return false point rect return false point rect return false point rect return false return true color point color diagram range color color true size size size rect triangle insert list triangle list print find index array rect rect rect range range draw draw return main alpha define window define color drawing read read array corresponding compute weighted average point range alpha alpha alpha alpha allocate space final output rectangle used size rect size size create instance rect calculate draw rect allocate space diagram draw diagram morph reading calculated line line morph one triangle time alpha resize save main,issue,positive,negative,neutral,neutral,negative,negative
663571862,Can you also share your complete Python code for face morphing that you are using? ,also share complete python code face,issue,negative,positive,neutral,neutral,positive,positive
663570472,"I mean in the code I've given above, I should be calling `calculateDelaunayTriangles` with `points`, which contains the average mean of `points1` and `points2`, rather than on these two.

Nonetheless, even when calling it on `points`,  I get an incomplete morph ...
Modified the `delaunayTri` part, see:

```
def main():
    # Variables
    filename1 = '../../../Data/Facelab_London/neutral_front/Raw/007_03.jpg'
    filename2 = '../../../Data/Facelab_London/neutral_front/Raw/009_03.jpg'
    alpha = 0.5

    # Define window names
    win_delaunay = 'Delaunay Triangulation'
    win_voronoi = 'Voronoi Diagram'

    # Define colors for drawing.
    d_col = (255, 255, 255)
    p_col = (0, 0, 255)

    # Read images
    img1 = cv.imread(filename1)
    img2 = cv.imread(filename2)

    img1_copy = cv.imread(filename1)
    img2_copy = cv.imread(filename2)

    # Read array of corresponding points
    points1 = readPoints(filename1[:-4] + '.tem')
    points2 = readPoints(filename2[:-4] + '.tem')
    points = []

    # Compute weighted average point coordinates
    for i in range(0, len(points1)):
        x = (1 - alpha) * points1[i][0] + alpha * points2[i][0]
        y = (1 - alpha) * points1[i][1] + alpha * points2[i][1]
        points.append((x, y))

    # Allocate space for final output
    imgMorph = np.zeros(img1.shape, dtype=img1.dtype)

    # Rectangle to be used with Subdiv2D
    size = img1.shape
    rect = (0, 0, size[1],  size[0])

    # Create an instance of Subdiv2D
    subdiv = cv.Subdiv2D(rect)

    # Calculate and draw delaunay triangles
    delaunayTri = calculateDelaunayTriangles(rect, subdiv, points, img1_copy, win_delaunay, d_col, draw=False)

    # Allocate space for Voronoi Diagram
    img_voronoi = np.zeros(img1.shape, dtype=img1.dtype)

    # Draw Voronoi diagram
    draw_voronoi(img_voronoi, subdiv)

    # Morph by reading calculated triangles
    for line in delaunayTri:
        x, y, z = line

        x = int(x)
        y = int(y)
        z = int(z)

        t1 = [points1[x], points1[y], points1[z]]
        t2 = [points2[x], points2[y], points2[z]]
        t  = [points[x],  points[y],  points[z]]

        # Morph one triangle at a time.
        morphTriangle(img1, img2, imgMorph, t1, t2, t, alpha)

    # Resize images
    desired_size = (860, 860)
    img1_copyS   = cv.resize(img1_copy,   desired_size)
    img2_copyS   = cv.resize(img2_copy,   desired_size)
    img1S        = cv.resize(img1,        desired_size)
    img2S        = cv.resize(img2,        desired_size)
    img_voronoiS = cv.resize(img_voronoi, desired_size)
    imgMorphS    = cv.resize(imgMorph,    desired_size)

    # Save Images
    cv.imwrite(""Image_1.jpg"", img1S)
    cv.imwrite(""Image_2.jpg"", img2S)
    cv.imwrite(""Image_1_copy.jpg"", img1_copyS)
    cv.imwrite(""Image_2_copy.jpg"", img2_copyS)
    cv.imwrite(""Morphed_Face.jpg"", imgMorphS)
```
",mean code given calling average mean rather two nonetheless even calling get incomplete morph part see main alpha define window define color drawing read read array corresponding compute weighted average point range alpha alpha alpha alpha allocate space final output rectangle used size rect size size create instance rect calculate draw rect allocate space diagram draw diagram morph reading calculated line line morph one triangle time alpha resize save,issue,positive,negative,negative,negative,negative,negative
663565011,"Sure, here you go:

[Tem.zip](https://github.com/spmallick/learnopencv/files/4972432/Tem.zip)

EDIT: added both the `.tem` and the `.jpg` files.",sure go edit added,issue,negative,positive,positive,positive,positive,positive
663563804,"Hi

Can you provide the corresponding tem files so that we can replicate and try to resolve the issue?",hi provide corresponding replicate try resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
663088302,"It seems the triangulation on the first image was correct, but not the second one . 

By creating a new `rect2` and `subdiv2` to parse into `calculateDelaunayTriangles(rect2, subdiv2, points2, img2_copy, win_delaunay, (255, 255, 255), draw=True)`, I was able to get the correct triangulation on the 2nd image.

![Image_1_copy](https://user-images.githubusercontent.com/11503378/88308290-29561e00-cd0d-11ea-9137-b4997750ca52.jpg)
![Image_2_copy](https://user-images.githubusercontent.com/11503378/88308292-29eeb480-cd0d-11ea-965e-0a2c667adc97.jpg)

Now the list returned by `calculateDelaunayTriangles` with both sets of inputs (rect & subdiv, and rect2 & subdiv2) and the list returned by `subdiv.getTriangleList()` seems to be both different:

```
triangleList 353
triangleList 359
delaunayTri 1: 331
delaunayTri 2: 351
```

The final morphed image is thus still incomplete:

![Morphed_Face](https://user-images.githubusercontent.com/11503378/88308343-370ba380-cd0d-11ea-9a5b-7d3ff7f7806b.jpg)

",triangulation first image correct second one new rect parse rect able get correct triangulation image list returned rect rect list returned different final image thus still incomplete,issue,negative,positive,positive,positive,positive,positive
662815761,"> 
> 
> Hi, Satya
> This is Julia from Xperience.ai. Please review my code for the article:
> https://www.learnopencv.com/how-to-run-inference-using-tensorrt-c-api/
> 
> Thanks

The article link is unavailable (not found).",hi please review code article thanks article link unavailable found,issue,positive,positive,positive,positive,positive,positive
660618816,"Thanks a lot for sharing. I will try it out.
I would suggest that this bit of suggestion for windows users can be added into the notebook as a comment.",thanks lot try would suggest bit suggestion added notebook comment,issue,negative,positive,positive,positive,positive,positive
660091481,"I am getting the following error on running the code on my system.

```
Translation to CoreML spec completed. Now compiling the CoreML model.
Model Compilation done.
Traceback (most recent call last):
  File ""torch_to_coreml.py"", line 153, in <module>
    main(args)
  File ""torch_to_coreml.py"", line 130, in main
    onnx_model, model_name, torch_model=torch_model, input_data=dummy_input,
  File ""torch_to_coreml.py"", line 105, in convert_onnx_to_coreml
    check_coreml_model(coreml_filename, torch_model, input_data)
  File ""torch_to_coreml.py"", line 43, in check_coreml_model
    pred = coreml_model.predict({""input"": input_data})
  File ""/opt/anaconda3/envs/coremltest/lib/python3.7/site-packages/coremltools/models/model.py"", line 336, in predict
    return self.__proxy__.predict(data, useCPUOnly)
RuntimeError: {
    NSLocalizedDescription = ""Neural Network (<=version 3) inputs can only be of size 1, 3, or 5."";
}
```

I have installed the requirements.txt file.",getting following error running code system translation spec model model compilation done recent call last file line module main file line main file line file line input file line predict return data neural network size file,issue,negative,positive,neutral,neutral,positive,positive
658530592,"Hi, can you merge this pull request?",hi merge pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
657541200,"unsubscribe



At 2020-07-13 20:00:00, ""TahaAnwar"" <notifications@github.com> wrote:

Its added

On Mon, Jul 13, 2020, 3:58 PM brmarkus <notifications@github.com> wrote:

> Will you provide a blog as well?
>
> Yes
>
> Can you add the URL pointing to the blog to the README.md, please?
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/pull/444#issuecomment-657490794>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AINDBVF6QVV3NRIRUWDS6JLR3LSG7ANCNFSM4OXS72QQ>
> .
>


â€”
You are receiving this because you commented.
Reply to this email directly, view it on GitHub, or unsubscribe.",wrote added mon wrote provide well yes add pointing please thread reply directly view reply directly view,issue,positive,positive,neutral,neutral,positive,positive
657518493,"Its added

On Mon, Jul 13, 2020, 3:58 PM brmarkus <notifications@github.com> wrote:

> Will you provide a blog as well?
>
> Yes
>
> Can you add the URL pointing to the blog to the README.md, please?
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/pull/444#issuecomment-657490794>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AINDBVF6QVV3NRIRUWDS6JLR3LSG7ANCNFSM4OXS72QQ>
> .
>
",added mon wrote provide well yes add pointing please thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
657513467,"> > > Will you provide a blog as well?
> > 
> > 
> > Yes
> 
> Can you add the URL pointing to the blog to the `README.md`, please?

done",provide well yes add pointing please done,issue,positive,neutral,neutral,neutral,neutral,neutral
657498122,"> > unsubscribe At 2020-07-13 18:06:05, ""TahaAnwar"" [notifications@github.com](mailto:notifications@github.com) wrote: Can you document the dependencies/requirements, please? What in which version would be required to be installed (like a requirements.txt, used via pip install)? Hi, that's not necessary, the code will work with any OpenCV 3 + version and Tensorflow 2.0 although I think older versions would also work, all the details are explained in the Blog post, which is ready to be published. Satya just needs to upload some videos to youtube and provide me with the link so I can put them inside the post. Then you hit publish. â€” You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.
> 
> Hi It's added

I can confirm it's working for me now, thank you.",wrote document please version would like used via pip install hi necessary code work version although think older would also work post ready need provide link put inside post hit publish thread reply directly view hi added confirm working thank,issue,positive,positive,positive,positive,positive,positive
657490794,"> > Will you provide a blog as well?
> 
> Yes

Can you add the URL pointing to the blog to the `README.md`, please?",provide well yes add pointing please,issue,positive,neutral,neutral,neutral,neutral,neutral
657485309,"> unsubscribe At 2020-07-13 18:06:05, ""TahaAnwar"" <notifications@github.com> wrote: Can you document the dependencies/requirements, please? What in which version would be required to be installed (like a requirements.txt, used via pip install)? Hi, that's not necessary, the code will work with any OpenCV 3 + version and Tensorflow 2.0 although I think older versions would also work, all the details are explained in the Blog post, which is ready to be published. Satya just needs to upload some videos to youtube and provide me with the link so I can put them inside the post. Then you hit publish. â€” You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or unsubscribe.

Hi It's added",wrote document please version would like used via pip install hi necessary code work version although think older would also work post ready need provide link put inside post hit publish thread reply directly view hi added,issue,positive,positive,positive,positive,positive,positive
657475564,"unsubscribe



At 2020-07-13 18:06:05, ""TahaAnwar"" <notifications@github.com> wrote:

Can you document the dependencies/requirements, please? What in which version would be required to be installed (like a requirements.txt, used via pip install)?

Hi, that's not necessary, the code will work with any OpenCV 3 + version and Tensorflow 2.0 although I think older versions would also work, all the details are explained in the Blog post, which is ready to be published. Satya just needs to upload some videos to youtube and provide me with the link so I can put them inside the post. Then you hit publish.

â€”
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub, or unsubscribe.",wrote document please version would like used via pip install hi necessary code work version although think older would also work post ready need provide link put inside post hit publish thread reply directly view,issue,positive,positive,positive,positive,positive,positive
657465191,"> The reason why I ask for the dependencies is that I cannot load the model, but get an exception `ValueError: ('Unrecognized keyword arguments:', dict_keys(['ragged']))`, which might be raised due to incompatible API-changes from TF1.14 to TF1.15, so you might recommend to use specific versions, maybe recommend to use a virtual-environment.

Didn't knew that, since I used TF 2.0 so maybe the model can be only be loaded using TF 2.0 + versions only. Also the model is optional and its recommended that everyone trains their own model for their own backgrounds.

I would add the instruction for the user to use TF 2.0 in the blog post.",reason ask load model get exception might raised due incompatible might recommend use specific maybe recommend use knew since used maybe model loaded also model optional everyone model would add instruction user use post,issue,positive,negative,neutral,neutral,negative,negative
657463135,"> Can you document the dependencies/requirements, please? What in which version would be required to be installed (like a `requirements.txt`, used via `pip install`)?

Hi, that's not necessary, the code will workÂ with any OpenCV 3Â + version and Tensorflow 2.0 although I think older versions would also work, all the details are explained in the Blog post, which is ready to be published. Satya just needs to upload some videos to youtube and provide me with the link so I can put them inside the post. Then you hit publish.

I've added this line to the post:

**_>  You should have Tensorflow 2.2, OpenCV 4x, and scikit-learn 0.23x installed in your system._**",document please version would like used via pip install hi necessary code work version although think older would also work post ready need provide link put inside post hit publish added line post,issue,positive,positive,positive,positive,positive,positive
657463055,"The reason why I ask for the dependencies is that I cannot load the model, but get an exception `ValueError: ('Unrecognized keyword arguments:', dict_keys(['ragged']))`, which might be raised due to incompatible API-changes from TF1.14 to TF1.15, so you might recommend to use specific versions, maybe recommend to use a virtual-environment.",reason ask load model get exception might raised due incompatible might recommend use specific maybe recommend use,issue,positive,negative,neutral,neutral,negative,negative
657456928,"Can you document the dependencies/requirements, please? What in which version would be required to be installed (like a `requirements.txt`, used via `pip install`)?",document please version would like used via pip install,issue,positive,neutral,neutral,neutral,neutral,neutral
652500227,"@krishnakatyal , thanks for picking up this issue.
I am not sure which page to use.
Can't we just create a fork, make the changes and submit the PR?
Or am I missing something here?",thanks issue sure page use ca create fork make submit missing something,issue,positive,positive,positive,positive,positive,positive
651785885,"> When will the blog under `https://www.learnopencv.com/image-matting-with-state-of-the-art-method-f-b-alpha-matting/` be made public?

@brmarkus
Thanks for your instrest! It is under review now",made public thanks review,issue,negative,positive,neutral,neutral,positive,positive
650809330,can you please provide me the github page where i can do the change and submit a PR,please provide page change submit,issue,negative,neutral,neutral,neutral,neutral,neutral
650775870,@vikasgupta-github Can we close this issue? #49 is also being closed,close issue also closed,issue,negative,negative,neutral,neutral,negative,negative
650775463,"@pranavlal Did these headers helped to resolve your issue?
#include <fstream>
#include <sstream>
#include <iostream>",resolve issue include include include,issue,negative,neutral,neutral,neutral,neutral,neutral
650771740,"@vikasgupta-github This can be added in our document for reference. This issue can be closed.
Thank you @prsolucoes for this example.",added document reference issue closed thank example,issue,negative,negative,neutral,neutral,negative,negative
650771208,@vikasgupta-github This issue can be closed. There's a similar issue for the same: [#143 ](https://github.com/spmallick/learnopencv/issues/143),issue closed similar issue,issue,negative,negative,neutral,neutral,negative,negative
650770827,I think this link will help you : [link](https://www.pyimagesearch.com/2020/02/10/opencv-dnn-with-nvidia-gpus-1549-faster-yolo-ssd-and-mask-r-cnn/),think link help link,issue,negative,neutral,neutral,neutral,neutral,neutral
647504846,"Thank you for answering @Kan630 

We can close this issue @vikasgupta-github ",thank kan close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
647499814,"Thank you for helping @aananya27 

Depending on your OpenCV version, `cv2.findContours` has different return values. You can learn more about that on OpenCV documentation. [Here's the link to it.](https://docs.opencv.org/trunk/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0)


@vikasgupta-github we can close this issue.",thank helping depending version different return learn documentation link close issue,issue,positive,neutral,neutral,neutral,neutral,neutral
647492928,"We won't be able to help you with this problem.

@vikasgupta-github we can close this issue.",wo able help problem close issue,issue,negative,positive,positive,positive,positive,positive
647491986,"Thank you for pointing that out.

@vikasgupta-github we can close this issue",thank pointing close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
647329503,"The installation scripts are for everyone's convenience. The script installs OpenCV with minimum requirements. If you want the CUDA support, you can make changes to your script.

You can find CUDA MAKE commands from here: https://github.com/opencv/opencv/blob/master/CMakeLists.txt

@vikasgupta-github we can close this issue",installation everyone convenience script minimum want support make script find make close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
645354951,"Yes, those and also if you think we can add some more subheadings then please add those as well. It makes the code more readable. Most people just read the headings and skip the text part.",yes also think add please add well code readable people read skip text part,issue,positive,neutral,neutral,neutral,neutral,neutral
645351441,"Could you, please, specify, should I return the headings as it was in the previous version? For example: ""Create your own model and train the network"" and others (https://github.com/spmallick/learnopencv/blob/master/Keras-Transfer-Learning/transfer-learning-vgg.ipynb).",could please specify return previous version example create model train network,issue,positive,negative,negative,negative,negative,negative
644824179,"I had the same error, after downloading pose_deploy.prototxt file, it worked, you should have the model and this file, both in your folder. ",error file worked model file folder,issue,negative,neutral,neutral,neutral,neutral,neutral
644797166,"@brmarkus, sorry for that, I've added new requirements.txt file with the[ latest commit ](https://github.com/spmallick/learnopencv/pull/426/commits/34980652b4644ea497a2191e1b9046ad2602185d)",sorry added new file latest commit,issue,negative,positive,neutral,neutral,positive,positive
644729468,"The blog ""https://www.learnopencv.com/efficient-image-loading/"" mentions a ""requirement.txt"" to ""install the required libraries"".
Where can this file be found in the context of ""efficient image loading""?",install file found context efficient image loading,issue,negative,neutral,neutral,neutral,neutral,neutral
643657928,"Try replacing the line of lsigma_best with  < lsigma_best = np.sqrt((negsqsum/(negcount + 1.0/255))) >

Since the negcount may be zero sometimes which may account to this issue.
Hope it helps.",try line since may zero sometimes may account issue hope,issue,negative,neutral,neutral,neutral,neutral,neutral
643657571,"This error only occurs due to the negative pixel values, not present in the image.",error due negative present image,issue,negative,negative,negative,negative,negative,negative
643657474,"I did not get the same warnings but nan (no a number) instead, which indicated there is a division by zero or similar sort of bug somewhere, so while writing the code replacing the lsigma_best calculation by < lsigma_best = np.sqrt((negsqsum/(negcount + 1.0/255))) >, it served the purpose for me, you may try as well.
Hope it helps.",get nan number instead division zero similar sort bug somewhere writing code calculation purpose may try well hope,issue,positive,neutral,neutral,neutral,neutral,neutral
641128686,"The exception message contains ""OpenCV(4.3.0-dev)"" where your ""cmake summary"" says ""OpenCV 4.2.0"", do you have multiple different versions of OpenCV installed?
(I installed ""opencv-contrib-python"" as I also use ""extensions"" of OpenCV)

Can you analyze your file ""bird.jpg""? Can other tools (mediainfo, ffmpeg, gstreamer) open and view it? Can you try another image, maybe even in another format (e.g. png, bmp)?",exception message summary multiple different also use analyze file open view try another image maybe even another format,issue,negative,neutral,neutral,neutral,neutral,neutral
641087212,"I have installed using pip.
pip3 install opencv-python

here is the info,

General configuration for OpenCV 4.2.0 =====================================
  Version control:               4.2.0

  Platform:
    Timestamp:                   2020-04-04T14:19:38Z
    Host:                        Linux 4.15.0-1028-gcp x86_64
    CMake:                       3.9.0
    CMake generator:             Unix Makefiles
    CMake build tool:            /usr/bin/gmake
    Configuration:               Release

  CPU/HW features:
    Baseline:                    SSE SSE2 SSE3
      requested:                 SSE3
    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX
      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX
      SSE4_1 (14 files):         + SSSE3 SSE4_1
      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2
      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX
      AVX (4 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX

  C/C++:
    Built as dynamic libs?:      NO
    C++ Compiler:                /usr/lib/ccache/compilers/c++  (ver 4.8.2)
    C++ flags (Release):         -Wl,-strip-all   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-comment -Wno-missing-field-initializers -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -O3 -DNDEBUG  -DNDEBUG
    C++ flags (Debug):           -Wl,-strip-all   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wsign-promo -Wuninitialized -Winit-self -Wno-delete-non-virtual-dtor -Wno-comment -Wno-missing-field-initializers -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -fvisibility-inlines-hidden -g  -O0 -DDEBUG -D_DEBUG
    C Compiler:                  /usr/lib/ccache/compilers/cc
    C flags (Release):           -Wl,-strip-all   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wuninitialized -Winit-self -Wno-comment -Wno-missing-field-initializers -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -O3 -DNDEBUG  -DNDEBUG
    C flags (Debug):             -Wl,-strip-all   -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wuninitialized -Winit-self -Wno-comment -Wno-missing-field-initializers -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -ffunction-sections -fdata-sections  -msse -msse2 -msse3 -fvisibility=hidden -g  -O0 -DDEBUG -D_DEBUG
    Linker flags (Release):      -L/root/ffmpeg_build/lib  -Wl,--gc-sections  
    Linker flags (Debug):        -L/root/ffmpeg_build/lib  -Wl,--gc-sections  
    ccache:                      YES
    Precompiled headers:         NO
    Extra dependencies:          ade /opt/Qt4.8.7/lib/libQtGui.so /opt/Qt4.8.7/lib/libQtTest.so /opt/Qt4.8.7/lib/libQtCore.so /lib64/libz.so dl m pthread rt
    3rdparty dependencies:       ittnotify libprotobuf libjpeg-turbo libwebp libpng libtiff libjasper IlmImf quirc

  OpenCV modules:
    To be built:                 calib3d core dnn features2d flann gapi highgui imgcodecs imgproc ml objdetect photo python3 stitching video videoio
    Disabled:                    world
    Disabled by dependency:      -
    Unavailable:                 java js python2 ts
    Applications:                -
    Documentation:               NO
    Non-free algorithms:         NO

  GUI: 
    QT:                          YES (ver 4.8.7 EDITION = OpenSource)
      QT OpenGL support:         NO
    GTK+:                        NO
    VTK support:                 NO

  Media I/O: 
    ZLib:                        /lib64/libz.so (ver 1.2.3)
    JPEG:                        libjpeg-turbo (ver 2.0.2-62)
    WEBP:                        build (ver encoder: 0x020e)
    PNG:                         build (ver 1.6.37)
    TIFF:                        build (ver 42 - 4.0.10)
    JPEG 2000:                   build (ver 1.900.1)
    OpenEXR:                     build (ver 2.3.0)
    HDR:                         YES
    SUNRASTER:                   YES
    PXM:                         YES
    PFM:                         YES

  Video I/O:
    DC1394:                      NO
    FFMPEG:                      YES
      avcodec:                   YES (58.65.103)
      avformat:                  YES (58.35.101)
      avutil:                    YES (56.38.100)
      swscale:                   YES (5.6.100)
      avresample:                NO
    GStreamer:                   NO
    v4l/v4l2:                    YES (linux/videodev2.h)

  Parallel framework:            pthreads

  Trace:                         YES (with Intel ITT)

  Other third-party libraries:
    Lapack:                      NO
    Eigen:                       NO
    Custom HAL:                  NO
    Protobuf:                    build (3.5.1)

  OpenCL:                        YES (no extra features)
    Include path:                /io/opencv/3rdparty/include/opencl/1.2
    Link libraries:              Dynamic load

  Python 3:
    Interpreter:                 /opt/python/cp36-cp36m/bin/python (ver 3.6.10)
    Libraries:                   libpython3.6m.a (ver 3.6.10)
    numpy:                       /opt/python/cp36-cp36m/lib/python3.6/site-packages/numpy/core/include (ver 1.11.3)
    install path:                python

  Python (for build):            /opt/python/cp36-cp36m/bin/python

  Java:                          
    ant:                         NO
    JNI:                         NO
    Java wrappers:               NO
    Java tests:                  NO

  Install to:                    /io/_skbuild/linux-x86_64-3.6/cmake-install
-----------------------------------------------------------------
",pip pip install general configuration version control platform host generator build tool configuration release code generation built dynamic compiler release compiler release linker release linker yes extra ade built core photo python stitching video disabled world disabled dependency unavailable python documentation yes edition support support medium build build tiff build build build yes yes yes yes video yes yes yes yes yes yes parallel framework trace yes custom build yes extra include path link dynamic load python interpreter install path python python build ant install,issue,positive,negative,neutral,neutral,negative,negative
641051331,"Can you describe your setup, please? Which operating system do you have, how have you installed e.g. OpenCV, which version of OpenCV do you use (""OpenCV(4.3.0-dev)"", which branch, which commitid), built by source?
When building by source-code then e.g. the output of ""cmake ."" gives an interesting summary about the detected components, dependencies, features enabled.

Can you provide details about your `bird.jpg`, like looking into the ""image codec"" via a tool like ""mediainfo"" or similar? Do you have JPG decoders installed, was OpenCV built with various image-codecs being detected? Maybe it is a special JPG codec like JPG2000?",describe setup please operating system version use branch built source building output interesting summary provide like looking image via tool like similar built various maybe special like,issue,positive,positive,positive,positive,positive,positive
638358293,"Hi, I just tried the smooth version of the handPoseVideo.py code. It works well. 
However, in my case, the ""cv2.waitkey(0)"" in line 129 should be deleted otherwise it will only show the first frame of the result stream and the output video file cannot be generated successfully either.",hi tried smooth version code work well however case line otherwise show first frame result stream output video file successfully either,issue,positive,positive,positive,positive,positive,positive
636115972,"@lxdv overall comment - your approach with global variables seems to be broken for the multi-instance case. We need at least HUGE warning on this, I suppose.
@tkhanova, what do you think?",overall comment approach global broken case need least huge warning suppose think,issue,negative,negative,neutral,neutral,negative,negative
634252782,These model files are corrupt or not suitable for new version of OpenCV. You can download these model files from somewhere else. ,model corrupt suitable new version model somewhere else,issue,negative,positive,neutral,neutral,positive,positive
633601168,"Hey, I had the same problem as you. This post (https://towardsdatascience.com/cuda-error-device-side-assert-triggered-c6ae1c8fa4c3) solved mine, I hope it'll solve yours.",hey problem post mine hope solve,issue,negative,neutral,neutral,neutral,neutral,neutral
633386064,"Which ""code"" have you tried? The code embedded in the JupyterNotebook? In which section of the JupyterNotebook did the assertion occur? Did you run all the sections manually, from top to bottom?
Have you followed ""https://www.learnopencv.com/creating-a-virtual-pen-and-eraser-with-opencv/"", especially the part with

> Note: All these values of different thresholds that Iâ€™ve chosen will depend upon your environment so please tune them first, instead of trying to make my values work.",code tried code section assertion occur run manually top bottom especially part note different chosen depend upon environment please tune first instead trying make work,issue,negative,positive,positive,positive,positive,positive
610345037,"Check your folder pathï¼Œand try â€œassert not isinstance(frame, type(None)), 'image not found' â€ this code",check folder try assert frame type none found code,issue,negative,neutral,neutral,neutral,neutral,neutral
602366218,"you could try to replace ""shell = False"" with â€œshell = Trueâ€ in
subprocess.py->class Popen(object) ->def init(...,shell = False,...)",could try replace shell false shell true class object shell false,issue,negative,negative,negative,negative,negative,negative
601833330,"I tested this with the example in FaceDetectionComparison/face_detection_opencv_dnn.cpp modified to use high resolution stills. It fails to detect most faces. Changeing the confidence treshold will give many false postives. Is this model not suitable for high resolution stills?
",tested example use high resolution detect confidence give many false model suitable high resolution,issue,positive,positive,positive,positive,positive,positive
598118606,"Hey @The-Gupta , were you able to resolve the issue?? I am having similar problems and would love some help
",hey able resolve issue similar would love help,issue,positive,positive,positive,positive,positive,positive
597400553,"Hi QiangZiBro,

These variables are declared in ""calib3d_c.h"";
![image](https://user-images.githubusercontent.com/8676098/76373177-a5f9e880-637a-11ea-8c54-0b887f2625e5.png)
![image](https://user-images.githubusercontent.com/8676098/76373582-be1e3780-637b-11ea-8a73-04c8d57c3b35.png)

So if we add #include <opencv2/calib3d/calib3d_c.h> to the code, we can compile it successfully.

---------------------------------------------------------------------------------------------------------
Best regards,
Xue Wen
ShenZhen, China",hi declared image image add include code compile successfully best wen china,issue,positive,positive,positive,positive,positive,positive
593849628,"The problem I ran into was, after compiling the files they were scattered, I found a couple folders in my user dir and others in the programs and programs 32. Also I had to move the protoc and test files into the lib folder, for some reason they were not connecting till I did that. After moving the files I hit test it ran right through all of them.    ",problem ran scattered found couple user also move test folder reason till moving hit test ran right,issue,negative,positive,positive,positive,positive,positive
586696791,Same for me. Someone should look into this. This made GOTURN useless.,someone look made useless,issue,negative,negative,negative,negative,negative,negative
584309208,even after the c++ codes was a copied one from the online source.,even copied one source,issue,negative,neutral,neutral,neutral,neutral,neutral
580163949,"If like me you are using linux you can just install AWS CLI:
`sudo apt-get update`
`sudo apt-get install awscli`

[https://linuxhint.com/install_aws_cli_ubuntu/](url)",like install update install,issue,negative,neutral,neutral,neutral,neutral,neutral
555203666,"@spmallick I have to read that paper on ECC because if it s not feature-based, I am unsure what it is based on.  ",read paper unsure based,issue,negative,neutral,neutral,neutral,neutral,neutral
545003125,"> do it fresh.
> sudo apt-get update
> sudo apt-get upgrade
> install (pip3)
> pip3 install opencv-python
> pip3 install opencv-contrib-python.
> let me know if you get error.

Well, i found the answer to my problem with this solution plus a virtual environment created with Anaconda.
Thanks ",fresh update upgrade install pip pip install pip install let know get error well found answer problem solution plus virtual environment anaconda thanks,issue,negative,positive,positive,positive,positive,positive
544997920,"> You need to install opencv with opencv_contrib
> [â€¦](#)
> On Wed, Aug 15, 2018 at 8:21 PM Shikha Agarwal ***@***.***> wrote: Can someone help it out? â€” You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#106>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ABo_iPFyco4ech-Xh6Pw75v9vu7zt9Pqks5uROUqgaJpZM4V_Isc> .

Hi everybody,

I am so sorry for this question. Does anyone try with virtual environment Anaconda, I did install a virtual environment with python 3.5 and openCV 3.4.2 but there is a problem that certain function is not implemented, something basic like cv.imshow(winName, frame) and cv.waitKey(3000).

Any idea is welcome
Thanks in advance
Cesar",need install wed agarwal wrote someone help thread reply directly view mute thread hi everybody sorry question anyone try virtual environment anaconda install virtual environment python problem certain function something basic like frame idea welcome thanks advance,issue,positive,positive,positive,positive,positive,positive
544223824,"assertion ""0"" failed: file ""./src/utils.c"", line 256, function: error
      0 [main] darknet 7532 cygwin_exception::open_stackdumpfile: Dumping stack trace to darknet.exe.stackdump

I am facing this error. Can you let me know your inputs",assertion file line function error main dumping stack trace facing error let know,issue,negative,positive,positive,positive,positive,positive
537521248,"I've solved it by arranging the points of the lips vertically.

In the createFaceAverage functions you had to sort the lip coordinates vertically. Sometimes some upper lip points were below the lower lip points and vice versa.

  
`    # Warp images and trasnform landmarks to output coordinate system,
    # and find average of transformed landmarks.
    
    for i in range(0, numImages):

        points1 = list(allPoints[i])
        
        # Corners of the eye in input image
        eyecornerSrc = [allPoints[i][36], allPoints[i][45]] 
        
        # select all lip indices and subtract 1
        lipIdcs = list([[50,61,60],[51,62,68,59],[52,63,67,58],[53,64,66,57],[54,65,56]])
        lipIdcs = [[j - 1 for j in ar] for ar in lipIdcs]

        # select the (x,y) points of the lip indices
        lips = [[points1[j] for j in ar] for ar in lipIdcs]
        # sort the lips vertically
        lips = [sorted(ar, key=itemgetter(1)) for ar in lips]
        
        # return the rearranged lips to the points1 list
        for j in range(len(lipIdcs)):
            for k in range(len(lipIdcs[j])):
                idx = lipIdcs[j][k]
                points1[idx] = lips[j][k]
`",vertically sort lip vertically sometimes upper lip lower lip vice warp output system find average range list eye input image select lip index subtract list ar ar select lip index ar ar sort vertically sorted ar ar return list range range,issue,negative,negative,neutral,neutral,negative,negative
536372933,"Yes please do it. We will be happy to review and publish it.

On Mon, Sep 30, 2019, 7:29 AM vishalseshagiri <notifications@github.com>
wrote:

> The research paper for the same can be found here -
> https://docs.opencv.org/4.1.1/dd/d65/classcv_1_1ximgproc_1_1EdgeBoxes.html
> .
> I can help with a rough draft. It'll be great if you could give it some
> finishing touches and post it out there for the community to view. It's
> falls in the class of algorithms with a similar objective as selective
> search.
>
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/363?email_source=notifications&email_token=AB34COE6E7ZN7ZCUSJGMJM3QMFMQVA5CNFSM4I3VCOW2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HONRY2Q>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AB34COBTUR6F62MCDQR7ZU3QMFMQVANCNFSM4I3VCOWQ>
> .
>
",yes please happy review publish mon wrote research paper found help rough draft great could give finishing post community view class similar objective selective search thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
535439928,"I had the same error.
The number of classes is wrong here :

`# Number of classes
num_classes = len(os.listdir(valid_directory))`",error number class wrong number class,issue,negative,negative,negative,negative,negative,negative
534577713,"I've finally managed to run the example with my configuration ( Opencv 4.1.1/ Python 2.7) !

Changes:
* ```scalefactor``` in [cv.dnn.blobFromImage](https://docs.opencv.org/4.1.1/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7) should be float, not integer
* replaced ```round()``` to ```int()``` for sizes

Here is the patch [1.txt](https://github.com/spmallick/learnopencv/files/3647620/1.txt)
Best wishes :)





",finally run example configuration python float integer round size patch best,issue,positive,positive,positive,positive,positive,positive
534560770,"> I have the same issue.
> Opencv 4.1.1
> Python 2.7

Opencv is amazing, we can't see the implementation inside the functionï¼
Or you can succeed with the following environment
python3.6
opencv3.4.1 
opencv-contrib3.4.1",issue python amazing ca see implementation inside succeed following environment python,issue,positive,positive,positive,positive,positive,positive
534179486,"I sent a fix to Vishwesh.
Itâ€™s attached.

Larry

[ac logo]
marcom, creative services, web & software development
Larry Kimminau
408.483.4078
http://www.analyticconcepts.com<http://www.analyticconcepts.com/>

From: Jason Stone <notifications@github.com>
Sent: Sunday, September 22, 2019 7:37 AM
To: spmallick/learnopencv <learnopencv@noreply.github.com>
Cc: Larry Kimminau <larrykimminau@msn.com>; Manual <manual@noreply.github.com>
Subject: Re: [spmallick/learnopencv] openimages downloader error (#250)


I think the issue is that rm and mkdir are a linux commands. We need the del /f/s and cd commands for Windows instead.
subprocess.run(['del', '/f/s', run_mode],shell=True)
subprocess.run(['cd', run_mode],shell=True)

Not sure yet what to do about command.split().

â€”
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fspmallick%2Flearnopencv%2Fissues%2F250%3Femail_source%3Dnotifications%26email_token%3DABQG5HH63N2G4EDCBWWGDJ3QK57IXA5CNFSM4GU6MKFKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7JHTMA%23issuecomment-533887408&data=02%7C01%7C%7C0f7b1c410d5a4e036ee108d73f6a53c4%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637047598205961833&sdata=C5OpMRG%2BkveAWXd2naEVr6kIQT1Ux15MRrORBcmFhqk%3D&reserved=0>, or mute the thread<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FABQG5HBD4ZJYM6WH55QABWLQK57IXANCNFSM4GU6MKFA&data=02%7C01%7C%7C0f7b1c410d5a4e036ee108d73f6a53c4%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637047598205961833&sdata=zQvILWby5dTDweVZg8vv311ZfTWgQGtZAWT%2BbSS53Ck%3D&reserved=0>.
",sent fix attached larry creative web development larry stone sent larry manual manual subject error think issue need instead sure yet thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
533887408,"I think the issue is that rm and mkdir are a linux commands.  We need the del /f/s and cd commands for Windows instead.  
subprocess.run(['del', '/f/s', run_mode],shell=True)
subprocess.run(['md', run_mode],shell=True)

Not sure yet what to do about command.split(). ",think issue need instead sure yet,issue,negative,positive,positive,positive,positive,positive
532964687,And do you think I can use the code for video or webcam or network camera not only the images?,think use code video network camera,issue,negative,neutral,neutral,neutral,neutral,neutral
532964515,"I mean not using pytorchvision.models, but using my own new trained model such as .hdf5.",mean new trained model,issue,negative,negative,neutral,neutral,negative,negative
526942456,"I had the same problem for my project. I solved it by updating PyTorch. If you use pip try this:
` pip3 install torchvision -U`
My old version was 1.0.0, on version 1.2.0 it works fine.",problem project use pip try pip install old version version work fine,issue,negative,positive,positive,positive,positive,positive
508963595,"Hello @srikar8 , thanks alot for Helping.
It works for me.",hello thanks helping work,issue,positive,positive,positive,positive,positive,positive
508507799,Not yet. let me know if you or someone else solve the problem. Thank you very much.,yet let know someone else solve problem thank much,issue,negative,positive,positive,positive,positive,positive
508442060,"Hi @changbaishan , I get the same error, did you manage to solve this? Thanks!",hi get error manage solve thanks,issue,negative,positive,positive,positive,positive,positive
506247786,"Hi @imSrbh , It is because of Opencv version.

change line 
 _, contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE
to
 **contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE**


opencv 3.4 - https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
opencv 4.1 - https://docs.opencv.org/master/d4/d73/tutorial_py_contours_begin.html
",hi version change line,issue,negative,neutral,neutral,neutral,neutral,neutral
504130718,"Yes. Indeed. 
Thanks very much for your help, manansaxena.
",yes indeed thanks much help,issue,positive,positive,positive,positive,positive,positive
504015933,"-change the mask_rcnn.py 
-at line 54 remove im2(because of the output of cv.findContours() )
-then it should work fine",line remove output work fine,issue,negative,positive,positive,positive,positive,positive
500118710,"replace initcv2() with initbv(). 
The error appeared as it was searching for void initbv() but didnot find any such fucntion.   
line 1793   extern ""C"" CV_EXPORTS void initbv(); // initcv2();
line1795   void initbv()  // initcv2()",replace error searching void find line extern void line void,issue,negative,neutral,neutral,neutral,neutral,neutral
498232295,I have added the notebook for Image Classification using pre-trained models as well.,added notebook image classification well,issue,negative,neutral,neutral,neutral,neutral,neutral
496505200,"Hi,

I am also curious about the EAST text detector licence.

Could you please provide information regarding that?",hi also curious east text detector could please provide information regarding,issue,positive,negative,neutral,neutral,negative,negative
495961650,"Also for the people that were trying to implement *age and gender* classification program (***AgeGender.py***).
>replace this
```
faceProto = ""opencv_face_detector.pbtxt""
faceModel = ""opencv_face_detector_uint8.pb""

ageProto = ""age_deploy.prototxt""
ageModel = ""age_net.caffemodel""

genderProto = ""gender_deploy.prototxt""
genderModel = ""gender_net.caffemodel""

```
>with this

```
faceProto = ""opencv_face_detector.pbtxt.txt""
faceModel = ""opencv_face_detector_uint8.pb""

ageProto = ""age_deploy.prototxt.txt""
ageModel = ""age_net.caffemodel""

genderProto = ""gender_deploy.prototxt.txt""
genderModel = ""gender_net.caffemodel""
```",also people trying implement age gender classification program replace,issue,negative,neutral,neutral,neutral,neutral,neutral
495958334,">Replace this
```
mask_rcnn_inception_v2_coco_2018_01_28.pbtxt
```
>by this
```
mask_rcnn_inception_v2_coco_2018_01_28.pbtxt.txt
```
in short, let the program know that the extension of the protofile being called is .txt- ",replace short let program know extension,issue,negative,neutral,neutral,neutral,neutral,neutral
495120620,"Need environment setting, otherwise could not run on jupyter with GPU.

import os
os.environ['CUDA_LAUNCH_BLOCKING'] = ""1""",need environment setting otherwise could run import o,issue,negative,neutral,neutral,neutral,neutral,neutral
490298004,I'm having the same issue. Has anyone successfully used downloadOI.py on Windows?,issue anyone successfully used,issue,negative,positive,positive,positive,positive,positive
487491484,"I just checked on some other images. The results are decent but the accuracy isn't very impressive. @gulshan-mittal can you do a thorough check with different images and get back on this? We can have a nice blog on this if it is good enough.

P.S : the below image was classified as **happy** ( should be sad )
![sad](https://user-images.githubusercontent.com/7848248/56884219-b832a700-6a86-11e9-95b9-b14dae0de936.jpg)

This was classified as **sad** ( should be surprise )
![surprise](https://user-images.githubusercontent.com/7848248/56884285-e9ab7280-6a86-11e9-8e03-c54651ae0358.jpg)

Correct results : 
![neutral](https://user-images.githubusercontent.com/7848248/56884310-034cba00-6a87-11e9-921f-5f6843f90a30.jpg)
**Neutral**
![smiling](https://user-images.githubusercontent.com/7848248/56884319-0778d780-6a87-11e9-9131-a40fd71d5663.jpg)
**Happy**",checked decent accuracy impressive thorough check different get back nice good enough image classified happy sad sad classified sad surprise surprise correct neutral neutral smiling happy,issue,positive,positive,positive,positive,positive,positive
487433030,@gulshan-mittal Your code looks fine. Please rename the folder to `Facial-Emotion-Detection` or `Facial_Emotion_Detection`.,code fine please rename folder,issue,negative,positive,positive,positive,positive,positive
477866878,I am not sure. Can you let me know the details of the system? Let me see if I can get access to one.,sure let know system let see get access one,issue,negative,positive,positive,positive,positive,positive
477721146,"Interestingly, I first had to uninstall, and then reinstall.

Do you also have a script to cross compile this for the PI on a more powerful system?

As it takes forever on a PI 3 B+ :-)

",interestingly first reinstall also script cross compile pi powerful system forever pi,issue,positive,positive,positive,positive,positive,positive
477407104,"Can you please close issues - #288 , #287 , #286 , #285 ?

We will continue our discussion here.",please close continue discussion,issue,negative,neutral,neutral,neutral,neutral,neutral
477406855,"Hi @Ziriax 

Try this please. First install wheel:

`pip install wheel`

Then try running the script.",hi try please first install wheel pip install wheel try running script,issue,negative,positive,positive,positive,positive,positive
472701528,"In case of the face landmarks, the output will be a 71 point array. There are no POSE_PAIRS as such. You can check [this diagram](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md#face-output-format) for the output format. Alternatively, you can also display the points on the image and check for yourself.",case face output point array check diagram output format alternatively also display image check,issue,negative,neutral,neutral,neutral,neutral,neutral
470649865,We have mentioned that the code takes .22 seconds which is ~4.5 FPS? I really don't understand what the problem here is!,code really understand problem,issue,negative,positive,positive,positive,positive,positive
470641935,"@vikasguptaiisc 
Such big claims in bold big fonts should mean something useful. Don't forget to add 4 FPS on CPU and that too using 4 CPU i7 cores. 

That post was unnecessary. Stop trolling.",big bold big mean something useful forget add post unnecessary stop trolling,issue,negative,negative,neutral,neutral,negative,negative
470114786,It's clearly written that OpenCV is faster than DarkNet on CPU. Please read carefully before using harsh words on a public platform.,clearly written faster please read carefully harsh public platform,issue,negative,negative,neutral,neutral,negative,negative
470113269,"Where did you find this information? In our blogs, we have compared the speed on the CPU. You would obviously get higher speed on the GPU since opencv does not use GPUs.",find information speed would obviously get higher speed since use,issue,negative,positive,positive,positive,positive,positive
469532142,You can always fine tune the model to improve the accuracy.,always fine tune model improve accuracy,issue,positive,positive,positive,positive,positive,positive
469485011,"@spmallick Works fine.

@ghimiredhikura Thanks for the enhancement.",work fine thanks enhancement,issue,positive,positive,positive,positive,positive,positive
469481343,"@spmallick Works fine. We can merge this.

@saumyakswain Thanks for the fix.",work fine merge thanks fix,issue,positive,positive,positive,positive,positive,positive
467361994,"i had the same problem on windows 10

Traceback (most recent call last):
  File ""downloadOI.py"", line 39, in <module>
    subprocess.run('rm -rf run_mode')
  File ""C:\Users\BlackBoy\Anaconda3\lib\subprocess.py"", line 403, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""C:\Users\BlackBoy\Anaconda3\lib\subprocess.py"", line 709, in __init__
    restore_signals, start_new_session)
  File ""C:\Users\BlackBoy\Anaconda3\lib\subprocess.py"", line 997, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] The system cannot find the file specified",problem recent call last file line module file line run process file line file line system find file,issue,negative,neutral,neutral,neutral,neutral,neutral
465934413,"Hi @gerk59 
Thanks. Can you make the listed changes and create a PR for the same? Please tag me so that I can verify everything and merge it quickly.

Thanks",hi thanks make listed create please tag verify everything merge quickly thanks,issue,positive,positive,positive,positive,positive,positive
465877509,"@gerk59 Please create a separate PR with the following changes made:

- [ ] Change `$cvVersion` to `""$cvVersion""`.
- [ ] Update README.md for `InstallScripts` directory -> change `3.4.4` to `3.4.x`.
- [ ] For `OpenCV-4.0.x` installations, you can retain your fix (`git checkout master` to `git checkout ""$cvVersion""`)  

Thanks for the PR.",please create separate following made change update directory change retain fix git master git thanks,issue,positive,positive,neutral,neutral,positive,positive
465877105,"> Either change cvVersion to ""3.4.x"" or apply suggested fix.

I will change it to 3.4.x",either change apply fix change,issue,negative,neutral,neutral,neutral,neutral,neutral
465876979,"Disagree: version string put into python lib is OpenCV-3.4.4-py3,
installation folder lists OpenCV-3.4.4.
OPencv version (without the changes) reports opencv-3.4.5-dev.

This is not consistent.

=> Either change cvVersion to ""3.4.x"" or apply suggested fix.

On Thu, Feb 21, 2019 at 7:15 AM vishwesh5 <notifications@github.com> wrote:

> *@vishwesh5* commented on this pull request.
>
> Not required. Changing to 3.4.4 will not include changes (mainly features
> and bug fixes) present in *3.4* branch.
>
> â€”
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/pull/260#pullrequestreview-206137568>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABvko8CHf14wI6Iiz0AwpBneUvEUwQ0sks5vPjmRgaJpZM4bFiHb>
> .
>


-- 

met vriendelijke groeten

Ger Kersten
",disagree version string put python installation folder version without consistent either change apply fix wrote pull request include mainly bug present branch thread reply directly view mute thread met ger,issue,negative,positive,positive,positive,positive,positive
465876691,Branch 3.4 contains the latest bug fixes and feature requests and that's why we are using that instead of `$cvVersion`.,branch latest bug feature instead,issue,negative,positive,positive,positive,positive,positive
465874590,Please confirm that you have tested this. I will merge after you say YES. ,please confirm tested merge say yes,issue,positive,neutral,neutral,neutral,neutral,neutral
465607524,"This issue probably is present in other install scripts.
",issue probably present install,issue,negative,neutral,neutral,neutral,neutral,neutral
461145178,"I figured it out, nVal needed to be divisible by batch size 150 % 20 = 10, but when I changed it to 160, 160 % 20 = 0, so it worked.",figured divisible batch size worked,issue,negative,neutral,neutral,neutral,neutral,neutral
458977344,"when i use this command line 
""textDetection.exe --input=F:\WORK\LPR\newtraining\new_plates\test\ee1.jpg --model=frozen_east_text_detection.pb --width=320 --height=320  --thr=0.5  --nms=0.4 ""
i get this error 
feature_fusion/Shape:Shape(resnet_v1_50/block4/unit_3/bottleneck_v1/Relu)
out_type:[ ]
T:0
OpenCV(3.4.1) Error: Unspecified error (Unknown layer type Shape in op feature_fusion/Shape) in cv::dnn::experimental_dnn_v4::`anonymous-namespace'::TFImporter::populateNet, file F:\WORK\opencv-3.4.1\modules\dnn\src\tensorflow\tf_importer.cpp, line 1582",use command line get error shape error unspecified error unknown layer type shape file line,issue,negative,negative,neutral,neutral,negative,negative
458972082,can you help me with command line that you use to run this project?,help command line use run project,issue,negative,neutral,neutral,neutral,neutral,neutral
458963411,"get this Error 
OpenCV(3.4.1) Error: Unspecified error (FAILED: fs.is_open(). Can't open ""true"") in cv::dnn::ReadProtoFromTextFile, file F:\WORK\opencv-3.4.1\modules\dnn\src\caffe\caffe_io.cpp, line 1119",get error error unspecified error ca open true file line,issue,negative,positive,positive,positive,positive,positive
458959419,"well, if you are using readNetFromTensorflow then how can it give this error. Please cross-check",well give error please,issue,negative,neutral,neutral,neutral,neutral,neutral
458957283,"i used this function ""readNetFromTensorflow"" and get the error.",used function get error,issue,negative,neutral,neutral,neutral,neutral,neutral
458954999,"Ok I see that you are using OpenCV 3.4.1.
You need OpenCV 3.4.3 for this.
Otherwise change  `readNet` to `readNetFromTensorflow`",see need otherwise change,issue,negative,neutral,neutral,neutral,neutral,neutral
458953521,"i downloaded it!
the problem in this line  Net net = readNet(model);
there is no function named ""readNet""
",problem line net net model function,issue,negative,neutral,neutral,neutral,neutral,neutral
458931985,"Please install PIL
```
pip install PIL
```",please install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
458930959,We have not tried tflite models yet. Will give it a try. Thanks for the idea!,tried yet give try thanks idea,issue,negative,positive,positive,positive,positive,positive
458930542,"You need to download the file and put it in the same folder as the code.
Download link https://www.dropbox.com/s/r2ingd0l3zt8hxs/frozen_east_text_detection.tar.gz?dl=1
",need file put folder code link,issue,negative,neutral,neutral,neutral,neutral,neutral
457450961,"84      # Read array of corresponding points
85       points1 = readPoints(filename1 + '.txt')
86       points2 = readPoints(filename2 + '.txt')


theses are the codes that should be corrected",read array corresponding thesis corrected,issue,negative,neutral,neutral,neutral,neutral,neutral
453725107,"@ldfinfontainebleau @vikasguptaiisc i tried to run the handpose code but i run into this error ""output = net.forward()
cv2.error: /io/opencv/modules/dnn/src/dnn.cpp:1430: error: (-215) output_slice.isContinuous() && output_slice.size == curr_output.size in function fuseLayers"" , when i did an survey on this error it was mentioned that we have give proper channels in the image based on the prototxt, but even i give the proper image i get this 
can you share some pointers on this ??",tried run code run error output error function survey error give proper image based even give proper image get share,issue,negative,neutral,neutral,neutral,neutral,neutral
453724956,@vikasguptaiisc is there an optimization on the code so that we can use it on CPU with medium fps,optimization code use medium,issue,negative,neutral,neutral,neutral,neutral,neutral
451095897,"Compile it as a native library (i.e. a C++ DLL), and place it in the plugins folder of your Unity project, selecting the appropriate build architecture it should be used with (i.e. x86/x64). Then, create a Unity C# script that exposes the method in the C++ using the DLLImport attribute.

There's examples in the Unity documentation, here: https://docs.unity3d.com/Manual/NativePlugins.html

 ",compile native library place folder unity project appropriate build architecture used create unity script method attribute unity documentation,issue,negative,positive,positive,positive,positive,positive
446716306,Can you try and run the code again? Let me know if it doesn't work.,try run code let know work,issue,negative,neutral,neutral,neutral,neutral,neutral
446390093,Because the file doesn't exist. CMakeLists.txt is looking for huMoments and the file is named HuMoments.cpp (notice the upper case H); same thing with py script as well,file exist looking file notice upper case thing script well,issue,negative,neutral,neutral,neutral,neutral,neutral
446277633,The processing is indeed slow on a CPU. You can use the original OpenPose code if you are working on a GPU.,indeed slow use original code working,issue,negative,positive,neutral,neutral,positive,positive
446277159,"Yes, you can use other image sizes. The processing time will take a hit in that case.",yes use image size time take hit case,issue,negative,neutral,neutral,neutral,neutral,neutral
446275771,"Are you using python2?

Use Python 3 or add `from __future__ import print_function` at the top of the code",python use python add import top code,issue,negative,positive,positive,positive,positive,positive
446271093,Getting the hand segmented might have better results.,getting hand segmented might better,issue,positive,positive,positive,positive,positive,positive
445117185,"This is most probably because of your OpenCV Version. 

In OpenCV 3.4.4-dev `findContours()` function returns modified image as well. While in OpenCV 4.0.0-dev `findContours()` function doesn't return the modified image.

Check out the below links for more information: 

1. **OpenCV 3.4.4-dev:** https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html
2. **OpenCV 4.0.0-dev:** https://docs.opencv.org/master/d4/d73/tutorial_py_contours_begin.html",probably version function image well function return image check link information,issue,negative,neutral,neutral,neutral,neutral,neutral
442506741,It would need OpenCV 3.4.1 and above.You need to upgrade to run this code.,would need need upgrade run code,issue,negative,neutral,neutral,neutral,neutral,neutral
442497856,"yes, solved. i run with python3 successfully.",yes run python successfully,issue,positive,positive,positive,positive,positive,positive
434218617,"Is your training datasets open ? Or have you used flip function on your training data? Nowadays, I did some comparative experiments and the results show that points on left hand are easier to be found. Hope your responds. Thank u!",training open used flip function training data nowadays comparative show left hand easier found hope thank,issue,positive,neutral,neutral,neutral,neutral,neutral
434177572,"hey thanks for the suggestion. I did using boundingRect, I got exact output which is needed.",hey thanks suggestion got exact output,issue,negative,positive,positive,positive,positive,positive
434166137,"Have you calculate the ratio(size of object decetion machine's output image divide by size which is your training data  ) ? It is just a thought, I think it maybe means something.",calculate ratio size object machine output image divide size training data thought think maybe something,issue,negative,neutral,neutral,neutral,neutral,neutral
433875277,I did using python I got the output but am facing difficulty in c++. can you please help me with that.,python got output facing difficulty please help,issue,negative,neutral,neutral,neutral,neutral,neutral
433874890,"hey, thanks for the reply but I want convert this python code to c++ . 
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = tuple(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])",hey thanks reply want convert python code,issue,negative,positive,positive,positive,positive,positive
433680281,yess..it works vikas. i have used another .prototxt file thats why i face index error. thanks for the help.,work used another file thats face index error thanks help,issue,negative,positive,positive,positive,positive,positive
433675106,"https://github.com/spmallick/learnopencv/tree/master/Mask-RCNN

This network. I need to get her to recognize various traffic signals. With this training she only recognizes a stop sign.

Thanks! ",network need get recognize various traffic training stop sign thanks,issue,negative,positive,neutral,neutral,positive,positive
433280985,Okay thanks for the help. Let me check it again,thanks help let check,issue,positive,positive,positive,positive,positive,positive
433279316,There is no mapIdx for hand. It is a different model and doesnt have the PAFs.,hand different model doesnt,issue,negative,neutral,neutral,neutral,neutral,neutral
433279075,You will have to use the same file provided with the code. The PAFs are used to find the connections between limbs when multiple person are present. Everything is given in the blog. Please refer to that.,use file provided code used find multiple person present everything given please refer,issue,negative,neutral,neutral,neutral,neutral,neutral
433276247,"So will i have to change the whole file or i can make changes in my existing prototxt??
Can you tell me the exact parameters and use of PAFs because i am unable to understand its use. ",change whole file make tell exact use unable understand use,issue,negative,negative,neutral,neutral,negative,negative
433275837,"Yes, In that file, the PAFs are commented out. Thus you are getting index error.",yes file thus getting index error,issue,negative,neutral,neutral,neutral,neutral,neutral
433275543,"Vikas, actually i took the prototxt file from another repository but it looks exactly same. Do you think that the error occurred due to this?? ",actually took file another repository exactly think error due,issue,negative,positive,neutral,neutral,positive,positive
433272883,Please mention which code or blog you are talking about?,please mention code talking,issue,negative,neutral,neutral,neutral,neutral,neutral
433272207,Thanks for pointing it out. Not all code is tested for Python 3. Will fix them soon,thanks pointing code tested python fix soon,issue,negative,positive,positive,positive,positive,positive
433271823,"Which prototxt file are you using? Did you make any changes to the code?

I just ran the code and it runs fine.
",file make code ran code fine,issue,negative,positive,positive,positive,positive,positive
432646971,"I too would like to know how to run this on my GPU via Python.

Thank you for putting together this great resource and your help!",would like know run via python thank together great resource help,issue,positive,positive,positive,positive,positive,positive
429721224,"You can simply use pip install opencv-python to install if you want to use
only python

On Mon, Oct 15, 2018, 11:45 AM trekcampy <notifications@github.com> wrote:

> Thanks Sathish,
>
> I use a MAC running Sierra with Anaconda. I believe I will have to clone
> source, build and install 3.4.3. Is there a script or cheatsheet on how to
> do that?
>
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/144#issuecomment-429720824>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AHfBOBO7GullVFWhP8N5juMYRzt-Fy7cks5ulCgbgaJpZM4XLqgm>
> .
>
",simply use pip install install want use python mon wrote thanks use mac running sierra anaconda believe clone source build install script thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
429720824,"Thanks Sathish,

I use a MAC running Sierra with Anaconda. I believe I will have to clone source,  build and install 3.4.3. Is there a script or cheatsheet on how to do that?
",thanks use mac running sierra anaconda believe clone source build install script,issue,negative,positive,positive,positive,positive,positive
428796930,Could anyone can sovle this problom ?I also miss it ,could anyone also miss,issue,negative,neutral,neutral,neutral,neutral,neutral
428444263,"You need to upgrade openCV to 3.4.3. That is the minimum requirement to run this example.

Thanks,
Sathish",need upgrade minimum requirement run example thanks,issue,negative,positive,positive,positive,positive,positive
428171375,it was a basic error. The path to model-weights and text-graph was wrong. ,basic error path wrong,issue,negative,negative,negative,negative,negative,negative
428170603,"I'm having the exact same error can anyone help
",exact error anyone help,issue,negative,positive,positive,positive,positive,positive
425952986,"Sorry. Now that i read that i need the models for both python and c++, but the description is only on python part.",sorry read need python description python part,issue,negative,negative,negative,negative,negative,negative
425766810,"Looks like you have provided a string where a char* is needed. Use `str.c_str()` on the line 85 string, that converts it from c++ string to c style char*.  

But if you use these headers with a c++11 compiler, it should accept strings

    #include <fstream>
    #include <sstream>
    #include <iostream>
     ",like provided string char use line string string style char use compiler accept include include include,issue,positive,neutral,neutral,neutral,neutral,neutral
422077552,"see https://github.com/AlexeyAB/darknet  

there is an exensive write-up on training with custom objects.. and a few other ""optimizations"" as well..",see training custom well,issue,negative,neutral,neutral,neutral,neutral,neutral
418013814,"You can either install wget, or you can simply look into the script and download the files manually. wget  simply allows you do download the files. ",either install simply look script manually simply,issue,negative,neutral,neutral,neutral,neutral,neutral
417647828,"Try to change the values of some parameters in yolo3.cfg,  for example
ignore_thresh, which is 0.7 by default.",try change example default,issue,negative,neutral,neutral,neutral,neutral,neutral
417607233,"okay, thank you.
I am asking about, maybe, settings of algorithm, like sensetivity. i want to decrease false negative by false positives. hope you can undestand me",thank maybe algorithm like want decrease false negative false hope,issue,positive,negative,negative,negative,negative,negative
417606493,"do it fresh.
sudo apt-get update
sudo apt-get upgrade
install (pip3)
pip3 install opencv-python
pip3 install opencv-contrib-python.
let me know if you get error.",fresh update upgrade install pip pip install pip install let know get error,issue,negative,positive,positive,positive,positive,positive
417605360,"if you want a perfect one, then you have to train one for yourself. read about threshold, and confidence. it can also help.
but at the end algorithm can't do everything, for practical scenario, you have to take care of image, size of object, exposure are and all that.  ",want perfect one train one read threshold confidence also help end algorithm ca everything practical scenario take care image size object exposure,issue,positive,positive,positive,positive,positive,positive
417570126,"sir, can you put anu counter in your code which check the condition if detected class is person.
I tried to understand the code, but couldn't do it.
for temporary, I need to do it. 
can you explain, where we're checking the classes.?",sir put counter code check condition class person tried understand code could temporary need explain class,issue,negative,neutral,neutral,neutral,neutral,neutral
417566419,"I succeed , I used  cv2 to iterate through the folder. and It's working. but still I am struggling to count just one class( person). 
It would be a great help. ",succeed used iterate folder working still struggling count one class person would great help,issue,positive,positive,positive,positive,positive,positive
417440221,"Ok, I need to make it a priority to test it on windows and linux. My apologies. ",need make priority test,issue,negative,neutral,neutral,neutral,neutral,neutral
417439591,"You will have to train your own person detector. Here is one example 

https://medium.com/@manivannan_data/how-to-train-yolov3-to-detect-custom-objects-ccbcafeb13d2",train person detector one example,issue,negative,neutral,neutral,neutral,neutral,neutral
417326053,"thanx @sturkmen72  
It would be great if you help me with detecting just one class. thank you...",would great help one class thank,issue,positive,positive,positive,positive,positive,positive
417186708,"@sturkmen72 , I want to detect only one class person .
can you help me with it?",want detect one class person help,issue,negative,neutral,neutral,neutral,neutral,neutral
416944143,"see https://github.com/spmallick/learnopencv/pull/49

i wonder why @spmallick  did not consider it valuable to merge yet",see wonder consider valuable merge yet,issue,negative,neutral,neutral,neutral,neutral,neutral
416019460,Great! Glad that the issue was resolved :) ,great glad issue resolved,issue,positive,positive,positive,positive,positive,positive
416019441,"@vishwesh5 

My bad, I didn't download the models first. Both python and C++ code can run now. Thanks",bad first python code run thanks,issue,negative,negative,neutral,neutral,negative,negative
416018703,"@KeepRaamAndCarryOn 
Can you try the Python code? If that works, we can figure out the issue with C++ code as well.
",try python code work figure issue code well,issue,negative,neutral,neutral,neutral,neutral,neutral
416018477,"@vishwesh5 made the change in line 75 and 85. Compiled successfully. Thanks!

However I'm facing this when I tried to run: 
```
./object_detection_yolo.out --image=bird.jpg
```

Is it an unrelated issue?

Error:
```
terminate called after throwing an instance of 'cv::Exception'
  what():  OpenCV(3.4.2) /opt/opencv/modules/dnn/src/darknet/darknet_io.cpp:784: error: (-212:Parsing error) Failed to parse NetParameter file: yolov3.cfg in function 'ReadNetParamsFromCfgFileOrDie'

Aborted (core dumped)
```",made change line successfully thanks however facing tried run unrelated issue error terminate throwing instance error error parse file function aborted core,issue,negative,positive,positive,positive,positive,positive
416018048,"@vishwesh5 
Tried: 
```
g++ -ggdb object_detection_yolo.cpp `pkg-config --cflags --libs /usr/local/lib/pkgconfig/opencv.pc` -o object_detection_yolo.out
```

Error: 
```
object_detection_yolo.cpp:75:31: error: no matching function for call to â€˜std::basic_ifstream<char>::basic_ifstream(std::__cxx11::string&)â€™
             ifstream ifile(str);
```",tried error error matching function call char,issue,negative,neutral,neutral,neutral,neutral,neutral
415687362,"you should use OpenCV3.4.2 to try it.
OpenCV3.4.1 may be not support YOLOv3.",use try may support,issue,negative,neutral,neutral,neutral,neutral,neutral
413532280,"Can't find output blob ""image"" in function addInput
i am not able to get dis error as the previous error has been resolved.",ca find output blob image function able get dis error previous error resolved,issue,negative,positive,positive,positive,positive,positive
413422892,"You need to install opencv with opencv_contrib

On Wed, Aug 15, 2018 at 8:21 PM Shikha Agarwal <notifications@github.com>
wrote:

> Can someone help it out?
>
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/106>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABo_iPFyco4ech-Xh6Pw75v9vu7zt9Pqks5uROUqgaJpZM4V_Isc>
> .
>
",need install wed agarwal wrote someone help thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
410017520,"If the algorithm does not converge, it means it may not be the right one for these set of images. You should check our feature-based image alignment. 

https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/",algorithm converge may right one set check image alignment,issue,negative,positive,positive,positive,positive,positive
410004626,@wutao720912 have the same problem. How to ignore the error. It broken progress.,problem ignore error broken progress,issue,negative,negative,negative,negative,negative,negative
409895725,"Cecking again, the correct flow should be
```

	color = color * 255;
	color.convertTo(color, CV_8U);
        imwrite(str, color);
```",correct flow color color color color,issue,negative,neutral,neutral,neutral,neutral,neutral
399777637,"Check the following

1. Is your image read properly.
2. Is it already grayscale

On Sun, Jun 24, 2018 at 11:27 AM m7ammad7assan <notifications@github.com>
wrote:

> this error, happens
>
> im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)
>
> error:
> C:\ci\opencv_1512688052760\work\modules\imgproc\src\color.cpp:11048: error:
> (-215) scn == 3 || scn == 4 in function cv::cvtColor
>
> any soluation ?
>
> â€”
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/spmallick/learnopencv/issues/77>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABo_iHFxTqPSAgUNSbwvKvRPpJFH5_iRks5t_9oEgaJpZM4U1QCb>
> .
>
",check following image read properly already sun wrote error error error function thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
394073195,"@Luca96 your previous comment worked for me finally. This was indeed an issue with gnu and libc++ stl. But I had to modify this
`set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fexceptions -std=gnustl"")`

to

`set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fexceptions -std=gnu++11"")`


",previous comment worked finally indeed issue gnu modify set set,issue,negative,negative,neutral,neutral,negative,negative
393480190,"Sorry! I assumed this repository had Python 3 code and I thought I was updating the code.
It is not backward compatible with Python 2.x. 
I just made a small change anyway. I will close this PR.",sorry assumed repository python code thought code backward compatible python made small change anyway close,issue,negative,negative,negative,negative,negative,negative
393203649,Maybe you can try to recompile OpenCV with `libc++` instead of `gnustl`.,maybe try recompile instead,issue,negative,neutral,neutral,neutral,neutral,neutral
393044594,"Hi, from the official docs (https://developer.android.com/ndk/guides/cpp-support.html) the gnustl is deprecated from ndk16 and will be removed.

```
gnustl

The GNU C++ Library is called gnustl on Android to differentiate it from the system runtime. This runtime is the libstdc++ available on a GNU/Linux system.

This runtime is tightly coupled to GCC, which is no longer supported in the NDK. As such, it has not received updates for several releases. The version in the NDK only supports C++11, and some portions of this library are incompatible with Clang.

Note: This library will be deprecated and removed in a future NDK release. Beginning with NDK r16, you should use libc++ instead.
```


I'm having the same issue for couple of days now.",hi official removed gnu library android differentiate system available system tightly coupled longer received several version library incompatible clang note library removed future release beginning use instead issue couple day,issue,negative,positive,neutral,neutral,positive,positive
392924410,"You should make sure you are using the correct versions. 

You should make the title of this issue less long :)",make sure correct make title issue le long,issue,negative,positive,positive,positive,positive,positive
392923671,this method might be cumbersome: SLAM based localization in 3D world then measure distance between head and feet feature points,method might cumbersome slam based localization world measure distance head feature,issue,negative,neutral,neutral,neutral,neutral,neutral
392921333,"Gait energy image is the resultant of a function applied on a series of segmented images of the gait of a person. Here: "" https://pdfs.semanticscholar.org/33f6/4132ab2eefb61681dcd75186cdfaafa93c89.pdf ""
Points obtained through open pose estimation can be used for gait analysis by analyzing the movement of all points of different individuals. And classifying these individuals on the basis of the pattern of the movement of points.",gait energy image resultant function applied series segmented gait person open pose estimation used gait analysis movement different basis pattern movement,issue,negative,neutral,neutral,neutral,neutral,neutral
392918623,Gait energy image? Does that somehow calculate the mechanical potential and kinetic energy of the gait (coordinates of leg points) in 3D?,gait energy image somehow calculate mechanical potential kinetic energy gait leg,issue,negative,neutral,neutral,neutral,neutral,neutral
392397543,"Thanks. Can you please make sure, it is backward compatible with Python 2.x? 
",thanks please make sure backward compatible python,issue,positive,positive,positive,positive,positive,positive
391109181,"Hi  @alexander-zou, maybe your problem is about the standard c++ library. 
What i mean is that OpenCV use the `gnustl_shared` standard library, so if you don't use this library in your android project, the compiler will complain with every methods that has string or vector as argument.

If you use CMake you can add this snippet in your build.gradle under `android->defaultConfig`:
```java
externalNativeBuild {
            cmake {
                cppFlags ""-std=c++11 -fexceptions""
                abiFilters 'x86', 'x86_64', 'armeabi', 'armeabi-v7a', 'arm64-v8a'  //keep only supported arch by your app
                arguments ""-DANDROID_PLATFORM=android-15"",  // change with your min api level
                        ""-DANDROID_TOOLCHAIN=clang"",
                        ""-DANDROID_STL=gnustl_shared"", // the standard lib
                        ""-DANDROID_CPP_FEATURES=rtti exceptions""
            }
        }
```
and in your `CMakeLists` you have to add something like this:
`set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fexceptions -std=gnustl"")`

that is, i hope it works!",hi maybe problem standard library mean use standard library use library android project compiler complain every string vector argument use add snippet arch change min level standard add something like set hope work,issue,negative,negative,neutral,neutral,negative,negative
390596670,"I am desperate with the same problem in my android project, may I ask how did you solve it? Thank you so much!",desperate problem android project may ask solve thank much,issue,negative,negative,negative,negative,negative,negative
375959272,"Hi, 

Check the code and if you like it, please accept pull request",hi check code like please accept pull request,issue,positive,neutral,neutral,neutral,neutral,neutral
375523681,"Thanks to @SM-Wistful , I was able to get to the bottom of this. Was pulling my hair out trying to figure that part out! 

It's like a tutorial...with the most important part missing without it. ",thanks able get bottom hair trying figure part like tutorial important part missing without,issue,positive,positive,positive,positive,positive,positive
366131587,"If you're using C++, check the closed Issues -- he responded there with the code. If you're using Python 3 like me, something like [this should work](https://gist.github.com/SM-Wistful/748ad30d3c7637710dcec75786e9e91a) (WARNING: really messy code, mostly for personal use).",check closed code python like something like work warning really messy code mostly personal use,issue,negative,negative,negative,negative,negative,negative
364263967,"Take a look at the file. There are 68 facial landmarks (x,y) from face detection inside the file.",take look file facial face detection inside file,issue,negative,neutral,neutral,neutral,neutral,neutral
345300652,"Resolved itself after visiting  https://s3.amazonaws.com, master certificate approved it.",resolved visiting master certificate,issue,negative,neutral,neutral,neutral,neutral,neutral
333372091,I used OpenCV 3.2.0 to run this example inside windows. Working quite fine. Need any help? Write me here mufadeveloper@gmail.com. ,used run example inside working quite fine need help write,issue,positive,positive,positive,positive,positive,positive
330445979,"Thank you ,PhantomClick, I think a classifier can be added to  Selective search and it can pick up the true regions and get the right class.",thank think classifier added selective search pick true get right class,issue,positive,positive,positive,positive,positive,positive
330442826,Using this technique you don't need to use sliding window techniques which very exhaustive. Selective Search proposes you a few region that can have object. Using these regions you can detect and localize object(s) in an image,technique need use sliding window exhaustive selective search region object detect localize object image,issue,negative,neutral,neutral,neutral,neutral,neutral
320826051,"I got same problem for Tracking example. It reports below error. I guess it is related with opencv version.

I'm using opencv 3.3, ubuntu 16.04

```
$ g++ -std=c++11 tracker.cpp 
tracker.cpp: In function â€˜int main(int, char**)â€™:
tracker.cpp:20:41: error: â€˜endâ€™ is not a member of â€˜stdâ€™
     vector <string> trackerTypes(types, std::end(types));
                                         ^
tracker.cpp:24:28: error: â€˜createâ€™ is not a member of â€˜cv::Trackerâ€™
     Ptr<Tracker> tracker = Tracker::create(trackerType);
```

",got problem example error guess related version function main char error end member vector string error create member tracker tracker tracker,issue,negative,positive,neutral,neutral,positive,positive
312160098,How to  buy school of ai course--Computer Vision for Faces  ï¼Ÿ,buy school ai course computer vision,issue,negative,neutral,neutral,neutral,neutral,neutral
312157237,sorry  alpha will control this !  thanks very much,sorry alpha control thanks much,issue,negative,negative,neutral,neutral,negative,negative
312155234,"Does your FaceMore implement have the corresponding paper ?  i strongly want to have a read !  And in FaceMorph , if we give two pictures a.jpg and b.jpg , we combine a and b to generate c.jpg,, but c.jpg is main determined by a  or b ? or we can control  the weight of a  and b ?",implement corresponding paper strongly want read give two combine generate main determined control weight,issue,positive,positive,positive,positive,positive,positive
298417316,@leoneckert Finally figured it out! It was similar but not the same. You were right that the masks were overlapping by a pixel. I just set each mask to 0 wherever image data was already in the output.,finally figured similar right set mask wherever image data already output,issue,negative,positive,neutral,neutral,positive,positive
298409559,"@conradhappeliv I find it hard to believe you would do the exact same mistake, but as far as I remember I just mixed up one of the operators in the line below, using a ""+"" instead of a ""*"" in one spot... 
```
# Copy triangular region of the rectangular patch to the output image
img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * ( 1 - mask ) + imgRect * mask
```
same problem?",find hard believe would exact mistake far remember mixed one line instead one spot copy triangular region rectangular patch output image mask mask problem,issue,negative,positive,neutral,neutral,positive,positive
298408658,@leoneckert can you post what the problem/solution was? I am also having the same issue and I'd like to know how you fixed it. :tired_face: ,post also issue like know fixed,issue,negative,positive,neutral,neutral,positive,positive
287629469,No problem! Glad that you figured it out yourself. I am traveling and so was not able to get back to you. ,problem glad figured traveling able get back,issue,negative,positive,positive,positive,positive,positive
287575568,":D :D i am glad you didn't reply yet, found the error myself and feeling oh so good. 
it was a typo that I could only find after understanding everything about masks that I didn't understand before -- I learned a lot. thanks and sorry for the many messages here!",glad reply yet found error feeling oh good typo could find understanding everything understand learned lot thanks sorry many,issue,positive,positive,positive,positive,positive,positive
287568150,am I likely to have a rounding error somewhere? int vs float? I tried everything :D,likely rounding error somewhere float tried everything,issue,negative,neutral,neutral,neutral,neutral,neutral
287565960,"I tried to hack together a solution by adding a 127 grey line to the masks, but that's not a good solution....
<img width=""702"" alt=""screen shot 2017-03-18 at 14 39 40"" src=""https://cloud.githubusercontent.com/assets/14130931/24074931/bafcd108-0be8-11e7-82bd-b7fa1b5c823c.png"">
",tried hack together solution grey line good solution screen shot,issue,positive,positive,positive,positive,positive,positive
283737848,Please go ahead. Just provide a reference to learnopencv.com,please go ahead provide reference,issue,negative,neutral,neutral,neutral,neutral,neutral
283736500,Sorry fixed it. I probably overwrote my python code. Will need to rewrite it :(,sorry fixed probably python code need rewrite,issue,negative,negative,negative,negative,negative,negative
280979150,"@mikeyny I don't think that's the answer. For every image included in the repo there's a txt file with coordinates. If we want to use our own image, how do we generate that file?",think answer every image included file want use image generate file,issue,negative,neutral,neutral,neutral,neutral,neutral
237498488,"@crosofg If you mean the haar cascade classifier xml file ,here is how to generate your own [train haar cascade](http://coding-robin.de/2013/07/22/train-your-own-opencv-haar-classifier.html) , you can also download them [here](https://github.com/opencv/opencv/tree/master/data/haarcascades)
",mean cascade classifier file generate train cascade also,issue,negative,negative,negative,negative,negative,negative
224467392,"Thanks @Mayur-RD for your explanation. Yes, I figured it out as what @anandsinghkunwar mention. If I want to use this two lines 

```
cv2.line(frame, (0,100), (500,100), (255, 0, 0), 2)
cv2.line(frame, (0,200), (500,200), (255, 0, 0), 2)
```

I need to modify return of 

```
line1(x,y)
return y - 100
```

```
line2(x,y)
return y - 200
```
",thanks explanation yes figured mention want use two frame frame need modify return line return line return,issue,positive,positive,positive,positive,positive,positive
224354271,"I think @easternmie figured it out that day itself. Thanks for the clarification @Mayur-RD
",think figured day thanks clarification,issue,negative,positive,positive,positive,positive,positive
224260154,"def line1(x,y):
    global m,line_start
    return y - m*x - line_start[1]

def line2(x,y):
    global m1,line_start1
    return y - m1*x - line_start1[1]

line_start=(0,100)
line_end=(500,100)
line_start1=(0,200)
line_end1=(500,200)
crossedAbove = 0
crossedBelow = 0
m=(line_end[1]-line_start[1])/(line_end[0]-line_start[0])
m1=(line_end1[1]-line_start1[1])/(line_end1[0]-line_start1[0])
",line global return line global return,issue,negative,neutral,neutral,neutral,neutral,neutral
